Sender: LSF System <lsfadmin@eu-g2-05>
Subject: Job 202625088: <w2_jelinek_0.11_-0.01_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#1> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:48:38 2022
Job was executed on host(s) <eu-g2-05>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:48:42 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:48:42 2022
Terminated at Tue Feb  1 04:48:59 2022
Results reported at Tue Feb  1 04:48:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72941.00 sec.
    Max Memory :                                 6047 MB
    Average Memory :                             3606.72 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13953.00 MB
    Max Swap :                                   56 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72017 sec.
    Turnaround time :                            72021 sec.

The output (if any) follows:

2022-01-31 08:48:50 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:48:50 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:48:51 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1438/36718 [00:00<00:02, 14368.81it/s]  8%|▊         | 2875/36718 [00:00<00:02, 13813.03it/s] 12%|█▏        | 4474/36718 [00:00<00:02, 14784.99it/s] 17%|█▋        | 6120/36718 [00:00<00:01, 15437.22it/s] 21%|██        | 7667/36718 [00:00<00:01, 14627.75it/s] 25%|██▍       | 9138/36718 [00:00<00:01, 14465.98it/s] 29%|██▉       | 10590/36718 [00:00<00:01, 14324.96it/s] 33%|███▎      | 12088/36718 [00:00<00:01, 14523.67it/s] 37%|███▋      | 13556/36718 [00:00<00:01, 14569.86it/s] 41%|████      | 15032/36718 [00:01<00:01, 14627.19it/s] 45%|████▍     | 16497/36718 [00:01<00:01, 14244.56it/s] 49%|████▉     | 17975/36718 [00:01<00:01, 14395.26it/s] 53%|█████▎    | 19549/36718 [00:01<00:01, 14789.80it/s] 57%|█████▋    | 21031/36718 [00:01<00:01, 14360.89it/s] 61%|██████    | 22472/36718 [00:01<00:00, 14299.85it/s] 66%|██████▌   | 24087/36718 [00:01<00:00, 14839.70it/s] 70%|██████▉   | 25656/36718 [00:01<00:00, 15088.88it/s] 74%|███████▍  | 27168/36718 [00:01<00:00, 14402.67it/s] 78%|███████▊  | 28717/36718 [00:01<00:00, 14713.60it/s] 82%|████████▏ | 30196/36718 [00:02<00:00, 14356.62it/s] 86%|████████▌ | 31638/36718 [00:02<00:00, 14111.83it/s] 90%|█████████ | 33054/36718 [00:02<00:00, 13738.19it/s] 94%|█████████▍| 34542/36718 [00:02<00:00, 14063.34it/s] 98%|█████████▊| 35953/36718 [00:02<00:00, 13988.82it/s]100%|██████████| 36718/36718 [00:02<00:00, 14414.36it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2762/36718 [00:00<00:01, 27603.11it/s] 16%|█▌        | 5930/36718 [00:00<00:01, 29996.32it/s] 24%|██▍       | 8930/36718 [00:00<00:00, 28640.54it/s] 32%|███▏      | 11801/36718 [00:00<00:00, 28238.45it/s] 40%|███▉      | 14687/36718 [00:00<00:00, 28455.26it/s] 48%|████▊     | 17536/36718 [00:00<00:00, 28246.72it/s] 56%|█████▌    | 20461/36718 [00:00<00:00, 28567.92it/s] 64%|██████▎   | 23320/36718 [00:00<00:00, 28481.72it/s] 72%|███████▏  | 26367/36718 [00:00<00:00, 29095.63it/s] 80%|███████▉  | 29279/36718 [00:01<00:00, 28800.08it/s] 88%|████████▊ | 32161/36718 [00:01<00:00, 28047.68it/s] 95%|█████████▌| 34985/36718 [00:01<00:00, 28098.01it/s]100%|██████████| 36718/36718 [00:01<00:00, 28394.11it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.92it/s]2022-01-31 08:49:04 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:49:04 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:49:04 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:49:04 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:49:04 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:49:04 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:49:04 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:49:04 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:49:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:49:04 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-01-31 08:49:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:49:04 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:49:04 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:49:04 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint_last.pt
2022-01-31 08:49:04 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint_last.pt
2022-01-31 08:49:04 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:49:04 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:49:04 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:49:04 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:49:04 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:54:36 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.719 | ppl 26972.1 | wps 8642.1 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:54:36 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:54:36 | INFO | train | epoch 001 | loss 16.136 | ppl 71992.6 | wps 6324 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.202 | train_wall 304 | gb_free 6.1 | wall 331
KL Stats: Epoch 1 Divergences: Uniform: 0.5171106382047024 Unigram: 3.6858789449895797
2022-01-31 08:54:36 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 08:57:28 | INFO | train_inner | epoch 002:     36 / 64 loss=15.602, ppl=49731.4, wps=6509.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.623, train_wall=476, gb_free=6.1, wall=503
2022-01-31 08:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:00:06 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.729 | ppl 13581.3 | wps 8643.8 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:00:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:00:06 | INFO | train | epoch 002 | loss 14.447 | ppl 22336.3 | wps 6329.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.477 | train_wall 304 | gb_free 6.1 | wall 661
KL Stats: Epoch 2 Divergences: Uniform: 0.533560633236072 Unigram: 2.4169236367086384
2022-01-31 09:00:06 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:05:36 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.917 | ppl 7734.78 | wps 8642.2 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:05:36 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:05:36 | INFO | train | epoch 003 | loss 13.555 | ppl 12038 | wps 6328.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.19 | train_wall 304 | gb_free 6.1 | wall 991
KL Stats: Epoch 3 Divergences: Uniform: 0.5162869045801074 Unigram: 1.7356846949496483
2022-01-31 09:05:36 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:06:14 | INFO | train_inner | epoch 004:      8 / 64 loss=13.687, ppl=13186.1, wps=6193.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.219, train_wall=474, gb_free=6.1, wall=1030
2022-01-31 09:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:11:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.084 | ppl 4340.64 | wps 8645.4 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:11:06 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:11:06 | INFO | train | epoch 004 | loss 12.618 | ppl 6284.38 | wps 6329.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.947 | train_wall 304 | gb_free 6.1 | wall 1321
KL Stats: Epoch 4 Divergences: Uniform: 0.5977791940112988 Unigram: 1.1260147594738896
2022-01-31 09:11:06 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:14:36 | INFO | train_inner | epoch 005:     44 / 64 loss=12.274, ppl=4951.8, wps=6506.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.834, train_wall=476, gb_free=6.1, wall=1532
2022-01-31 09:16:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:16:36 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.571 | ppl 3042.87 | wps 8634.9 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:16:36 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:16:36 | INFO | train | epoch 005 | loss 11.834 | ppl 3651.25 | wps 6324.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.681 | train_wall 304 | gb_free 6.1 | wall 1652
KL Stats: Epoch 5 Divergences: Uniform: 0.8302719691463222 Unigram: 0.6766878780237157
2022-01-31 09:16:36 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:22:06 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.325 | ppl 2565.28 | wps 8644.6 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:22:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:22:06 | INFO | train | epoch 006 | loss 11.408 | ppl 2718.18 | wps 6327.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.581 | train_wall 304 | gb_free 6.1 | wall 1982
KL Stats: Epoch 6 Divergences: Uniform: 1.1180389069262155 Unigram: 0.4816152227226491
2022-01-31 09:22:06 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:23:22 | INFO | train_inner | epoch 007:     16 / 64 loss=11.431, ppl=2760.11, wps=6192.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.579, train_wall=474, gb_free=6.1, wall=2058
2022-01-31 09:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:27:36 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.179 | ppl 2318.3 | wps 8630.7 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:27:36 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:27:36 | INFO | train | epoch 007 | loss 11.209 | ppl 2366.67 | wps 6331.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.523 | train_wall 304 | gb_free 6.1 | wall 2312
KL Stats: Epoch 7 Divergences: Uniform: 1.3326223716701977 Unigram: 0.4965568794391444
2022-01-31 09:27:36 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:31:45 | INFO | train_inner | epoch 008:     52 / 64 loss=11.147, ppl=2267.25, wps=6506.4, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=476, gb_free=6.1, wall=2561
2022-01-31 09:32:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:33:06 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.072 | ppl 2152.22 | wps 8590.7 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:33:06 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:33:06 | INFO | train | epoch 008 | loss 11.094 | ppl 2186.43 | wps 6317.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 304 | gb_free 6.1 | wall 2642
KL Stats: Epoch 8 Divergences: Uniform: 1.441088107761361 Unigram: 0.5781758444816125
2022-01-31 09:33:06 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:38:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:38:37 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.953 | ppl 1981.77 | wps 8621.8 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:38:37 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:38:37 | INFO | train | epoch 009 | loss 10.986 | ppl 2027.84 | wps 6316.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 304 | gb_free 6.1 | wall 2973
KL Stats: Epoch 9 Divergences: Uniform: 1.48232923694785 Unigram: 0.6909154184225449
2022-01-31 09:38:37 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:38:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:40:32 | INFO | train_inner | epoch 010:     24 / 64 loss=10.976, ppl=2014.52, wps=6184.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.487, train_wall=475, gb_free=6.1, wall=3088
2022-01-31 09:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:44:07 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.845 | ppl 1839.79 | wps 8626.7 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:44:07 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:44:07 | INFO | train | epoch 010 | loss 10.873 | ppl 1875.96 | wps 6322.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 304 | gb_free 6.1 | wall 3303
KL Stats: Epoch 10 Divergences: Uniform: 1.5051192626707617 Unigram: 0.815548152644212
2022-01-31 09:44:07 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:48:55 | INFO | train_inner | epoch 011:     60 / 64 loss=10.796, ppl=1777.34, wps=6499.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=476, gb_free=6.1, wall=3591
2022-01-31 09:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:49:38 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.736 | ppl 1705.87 | wps 8613.6 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:49:38 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:49:38 | INFO | train | epoch 011 | loss 10.755 | ppl 1727.8 | wps 6317.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 304 | gb_free 6.1 | wall 3634
KL Stats: Epoch 11 Divergences: Uniform: 1.5223130737470618 Unigram: 0.9408259592847829
2022-01-31 09:49:38 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:55:09 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.625 | ppl 1579.34 | wps 8622.7 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 09:55:09 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 09:55:09 | INFO | train | epoch 012 | loss 10.636 | ppl 1591.2 | wps 6316.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.482 | train_wall 304 | gb_free 6.1 | wall 3964
KL Stats: Epoch 12 Divergences: Uniform: 1.5328654112733315 Unigram: 1.0622536844536299
2022-01-31 09:55:09 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 09:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:57:42 | INFO | train_inner | epoch 013:     32 / 64 loss=10.612, ppl=1564.61, wps=6184.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.496, train_wall=475, gb_free=6.1, wall=4118
2022-01-31 10:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:00:39 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.535 | ppl 1483.58 | wps 8607.6 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:00:39 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:00:39 | INFO | train | epoch 013 | loss 10.52 | ppl 1468.57 | wps 6321.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 304 | gb_free 6.1 | wall 4295
KL Stats: Epoch 13 Divergences: Uniform: 1.557062515511917 Unigram: 1.1693127984424936
2022-01-31 10:00:39 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:06:10 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.439 | ppl 1388.02 | wps 8593 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:06:10 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:06:10 | INFO | train | epoch 014 | loss 10.409 | ppl 1359.25 | wps 6315.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.56 | train_wall 304 | gb_free 6.1 | wall 4626
KL Stats: Epoch 14 Divergences: Uniform: 1.5836099849189593 Unigram: 1.2676935243543073
2022-01-31 10:06:10 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:06:29 | INFO | train_inner | epoch 015:      4 / 64 loss=10.431, ppl=1380.83, wps=6184.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.538, train_wall=475, gb_free=6.1, wall=4645
2022-01-31 10:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:11:40 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.369 | ppl 1322.21 | wps 8632.1 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:11:40 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:11:40 | INFO | train | epoch 015 | loss 10.296 | ppl 1257.56 | wps 6317.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.541 | train_wall 304 | gb_free 6.1 | wall 4956
KL Stats: Epoch 15 Divergences: Uniform: 1.604885217723347 Unigram: 1.3585080924798159
2022-01-31 10:11:40 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:14:52 | INFO | train_inner | epoch 016:     40 / 64 loss=10.255, ppl=1221.97, wps=6500.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.56, train_wall=476, gb_free=6.1, wall=5148
2022-01-31 10:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:17:11 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.289 | ppl 1250.83 | wps 8640.5 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:17:11 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:17:11 | INFO | train | epoch 016 | loss 10.19 | ppl 1167.96 | wps 6323.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.557 | train_wall 304 | gb_free 6.1 | wall 5287
KL Stats: Epoch 16 Divergences: Uniform: 1.6324820278276087 Unigram: 1.4446118608136946
2022-01-31 10:17:11 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:17:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:22:41 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.194 | ppl 1171.03 | wps 8636 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:22:41 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:22:41 | INFO | train | epoch 017 | loss 10.083 | ppl 1084.72 | wps 6321.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 304 | gb_free 6.1 | wall 5617
KL Stats: Epoch 17 Divergences: Uniform: 1.666492520836899 Unigram: 1.5197929693654648
2022-01-31 10:22:41 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:22:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:23:38 | INFO | train_inner | epoch 018:     12 / 64 loss=10.097, ppl=1095.43, wps=6188.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.551, train_wall=475, gb_free=6.1, wall=5674
2022-01-31 10:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:28:11 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.134 | ppl 1123.53 | wps 8644.4 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:28:11 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:28:11 | INFO | train | epoch 018 | loss 9.983 | ppl 1011.78 | wps 6332.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.569 | train_wall 304 | gb_free 6.1 | wall 5947
KL Stats: Epoch 18 Divergences: Uniform: 1.6990609249431612 Unigram: 1.594492043593805
2022-01-31 10:28:11 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:32:01 | INFO | train_inner | epoch 019:     48 / 64 loss=9.933, ppl=977.65, wps=6509.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.54, train_wall=475, gb_free=6.1, wall=6176
2022-01-31 10:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:33:41 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.057 | ppl 1065.24 | wps 8635.9 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:33:41 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:33:41 | INFO | train | epoch 019 | loss 9.879 | ppl 941.9 | wps 6325.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 304 | gb_free 6.1 | wall 6277
KL Stats: Epoch 19 Divergences: Uniform: 1.7271330018494322 Unigram: 1.6682365866592075
2022-01-31 10:33:41 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:39:11 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.973 | ppl 1004.87 | wps 8655.4 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:39:11 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:39:11 | INFO | train | epoch 020 | loss 9.783 | ppl 880.93 | wps 6329.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.548 | train_wall 304 | gb_free 6.1 | wall 6607
KL Stats: Epoch 20 Divergences: Uniform: 1.7575968569032996 Unigram: 1.7355260210888046
2022-01-31 10:39:11 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:40:47 | INFO | train_inner | epoch 021:     20 / 64 loss=9.778, ppl=877.87, wps=6194.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.545, train_wall=474, gb_free=6.1, wall=6703
2022-01-31 10:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:44:42 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.931 | ppl 976.06 | wps 8627.2 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:44:42 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:44:42 | INFO | train | epoch 021 | loss 9.689 | ppl 825.32 | wps 6320.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.53 | train_wall 304 | gb_free 6.1 | wall 6937
KL Stats: Epoch 21 Divergences: Uniform: 1.7872851899185553 Unigram: 1.8023461702925017
2022-01-31 10:44:42 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:44:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:49:10 | INFO | train_inner | epoch 022:     56 / 64 loss=9.636, ppl=795.86, wps=6496.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.541, train_wall=476, gb_free=6.1, wall=7206
2022-01-31 10:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:50:12 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.867 | ppl 933.84 | wps 8622.5 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 10:50:12 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 10:50:12 | INFO | train | epoch 022 | loss 9.6 | ppl 775.94 | wps 6314.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.55 | train_wall 305 | gb_free 6.1 | wall 7268
KL Stats: Epoch 22 Divergences: Uniform: 1.8113941170615828 Unigram: 1.8674924177854684
2022-01-31 10:50:12 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 10:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:55:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:55:43 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.803 | ppl 893.61 | wps 8634.3 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 10:55:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 10:55:43 | INFO | train | epoch 023 | loss 9.513 | ppl 730.66 | wps 6317.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.516 | train_wall 304 | gb_free 6.1 | wall 7599
KL Stats: Epoch 23 Divergences: Uniform: 1.839375828670175 Unigram: 1.9252475437142296
2022-01-31 10:55:43 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 10:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:57:57 | INFO | train_inner | epoch 024:     28 / 64 loss=9.498, ppl=723.12, wps=6184.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.531, train_wall=475, gb_free=6.1, wall=7733
2022-01-31 11:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:01:13 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.745 | ppl 857.85 | wps 8639.6 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:01:13 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:01:13 | INFO | train | epoch 024 | loss 9.43 | ppl 689.88 | wps 6329.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.564 | train_wall 304 | gb_free 6.1 | wall 7929
KL Stats: Epoch 24 Divergences: Uniform: 1.8600812712828954 Unigram: 1.978621486976207
2022-01-31 11:01:13 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:06:17 | INFO | train_inner | epoch 025:     64 / 64 loss=9.376, ppl=664.63, wps=6516.4, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.545, train_wall=474, gb_free=6.1, wall=8233
2022-01-31 11:06:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:06:43 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.715 | ppl 840.18 | wps 8635.6 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:06:43 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:06:43 | INFO | train | epoch 025 | loss 9.349 | ppl 651.95 | wps 6336.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.53 | train_wall 303 | gb_free 6.1 | wall 8258
KL Stats: Epoch 25 Divergences: Uniform: 1.88861118038125 Unigram: 2.0342098927952903
2022-01-31 11:06:43 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:12:12 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.664 | ppl 811.31 | wps 8645.2 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:12:12 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:12:12 | INFO | train | epoch 026 | loss 9.268 | ppl 616.35 | wps 6334.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.545 | train_wall 304 | gb_free 6.1 | wall 8588
KL Stats: Epoch 26 Divergences: Uniform: 1.9008871858722096 Unigram: 2.0835399930338516
2022-01-31 11:12:12 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:12:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:15:04 | INFO | train_inner | epoch 027:     36 / 64 loss=9.24, ppl=604.67, wps=6202.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.54, train_wall=475, gb_free=6.1, wall=8760
2022-01-31 11:17:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:17:42 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.631 | ppl 792.98 | wps 8656.9 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:17:42 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:17:42 | INFO | train | epoch 027 | loss 9.188 | ppl 583.25 | wps 6336.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.533 | train_wall 303 | gb_free 6.1 | wall 8918
KL Stats: Epoch 27 Divergences: Uniform: 1.9268720136236943 Unigram: 2.1285420285295604
2022-01-31 11:17:42 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:17:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:23:11 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.604 | ppl 778.42 | wps 8655.1 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:23:11 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:23:11 | INFO | train | epoch 028 | loss 9.11 | ppl 552.5 | wps 6338.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.527 | train_wall 303 | gb_free 6.1 | wall 9247
KL Stats: Epoch 28 Divergences: Uniform: 1.9558787386098861 Unigram: 2.1766612490600235
2022-01-31 11:23:11 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:23:50 | INFO | train_inner | epoch 029:      8 / 64 loss=9.125, ppl=558.51, wps=6200.9, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.532, train_wall=474, gb_free=6.1, wall=9286
2022-01-31 11:28:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:28:41 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.567 | ppl 758.66 | wps 8646.6 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:28:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:28:41 | INFO | train | epoch 029 | loss 9.031 | ppl 523.09 | wps 6332.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.525 | train_wall 304 | gb_free 6.1 | wall 9577
KL Stats: Epoch 29 Divergences: Uniform: 1.9760192409918353 Unigram: 2.2196457963808873
2022-01-31 11:28:41 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:32:11 | INFO | train_inner | epoch 030:     44 / 64 loss=8.998, ppl=511.29, wps=6516.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.516, train_wall=475, gb_free=6.1, wall=9787
2022-01-31 11:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:34:11 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.544 | ppl 746.67 | wps 8659.4 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:34:11 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:34:11 | INFO | train | epoch 030 | loss 8.954 | ppl 495.79 | wps 6337.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.523 | train_wall 303 | gb_free 6.1 | wall 9907
KL Stats: Epoch 30 Divergences: Uniform: 1.993195625183268 Unigram: 2.2669259936768267
2022-01-31 11:34:11 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:39:41 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.494 | ppl 720.96 | wps 8646.8 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:39:41 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:39:41 | INFO | train | epoch 031 | loss 8.874 | ppl 469.22 | wps 6332.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.5 | train_wall 304 | gb_free 6.1 | wall 10236
KL Stats: Epoch 31 Divergences: Uniform: 2.0115572472863126 Unigram: 2.3072716586599338
2022-01-31 11:39:41 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:40:57 | INFO | train_inner | epoch 032:     16 / 64 loss=8.875, ppl=469.65, wps=6200.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.508, train_wall=474, gb_free=6.1, wall=10313
2022-01-31 11:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:45:10 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.46 | ppl 704.15 | wps 8655.1 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 11:45:10 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 11:45:10 | INFO | train | epoch 032 | loss 8.801 | ppl 445.89 | wps 6332.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.512 | train_wall 304 | gb_free 6.1 | wall 10566
KL Stats: Epoch 32 Divergences: Uniform: 2.039364226489823 Unigram: 2.349113817485872
2022-01-31 11:45:10 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 11:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:49:19 | INFO | train_inner | epoch 033:     52 / 64 loss=8.764, ppl=434.62, wps=6515, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.515, train_wall=475, gb_free=6.1, wall=10815
2022-01-31 11:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:50:40 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.444 | ppl 696.27 | wps 8650.8 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 11:50:40 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 11:50:40 | INFO | train | epoch 033 | loss 8.726 | ppl 423.47 | wps 6334.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.514 | train_wall 304 | gb_free 6.1 | wall 10896
KL Stats: Epoch 33 Divergences: Uniform: 2.0618618398150814 Unigram: 2.397358807785163
2022-01-31 11:50:40 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 11:50:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:55:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:56:10 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.424 | ppl 686.89 | wps 8644 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 11:56:10 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 11:56:10 | INFO | train | epoch 034 | loss 8.65 | ppl 401.83 | wps 6324.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.516 | train_wall 304 | gb_free 6.1 | wall 11226
KL Stats: Epoch 34 Divergences: Uniform: 2.082294738509631 Unigram: 2.4387711432051034
2022-01-31 11:56:10 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 11:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:58:05 | INFO | train_inner | epoch 035:     24 / 64 loss=8.638, ppl=398.25, wps=6192, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.515, train_wall=475, gb_free=6.1, wall=11341
2022-01-31 12:01:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:01:40 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.396 | ppl 673.88 | wps 8635.5 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:01:40 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:01:40 | INFO | train | epoch 035 | loss 8.578 | ppl 382.13 | wps 6332.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.509 | train_wall 304 | gb_free 6.1 | wall 11556
KL Stats: Epoch 35 Divergences: Uniform: 2.103809158483506 Unigram: 2.475979529853614
2022-01-31 12:01:40 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:01:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:06:27 | INFO | train_inner | epoch 036:     60 / 64 loss=8.534, ppl=370.75, wps=6513.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.51, train_wall=475, gb_free=6.1, wall=11843
2022-01-31 12:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:07:10 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.37 | ppl 661.76 | wps 8671.8 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:07:10 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:07:10 | INFO | train | epoch 036 | loss 8.505 | ppl 363.21 | wps 6332.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.51 | train_wall 304 | gb_free 6.1 | wall 11886
KL Stats: Epoch 36 Divergences: Uniform: 2.1246713908365233 Unigram: 2.5216195951606557
2022-01-31 12:07:10 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:12:40 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.39 | ppl 670.9 | wps 8646.5 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:12:40 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:12:40 | INFO | train | epoch 037 | loss 8.435 | ppl 346.1 | wps 6332.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.513 | train_wall 304 | gb_free 6.1 | wall 12216
KL Stats: Epoch 37 Divergences: Uniform: 2.1425923121224177 Unigram: 2.564022273420494
2022-01-31 12:12:40 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:15:13 | INFO | train_inner | epoch 038:     32 / 64 loss=8.414, ppl=341.01, wps=6198.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.511, train_wall=474, gb_free=6.1, wall=12369
2022-01-31 12:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:18:10 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.369 | ppl 661.03 | wps 8675.2 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:18:10 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:18:10 | INFO | train | epoch 038 | loss 8.367 | ppl 330.06 | wps 6333.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.512 | train_wall 304 | gb_free 6.1 | wall 12546
KL Stats: Epoch 38 Divergences: Uniform: 2.171568709799728 Unigram: 2.5955388278258518
2022-01-31 12:18:10 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:23:40 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.347 | ppl 651.15 | wps 8647.6 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:23:40 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:23:40 | INFO | train | epoch 039 | loss 8.298 | ppl 314.65 | wps 6331.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.504 | train_wall 304 | gb_free 6.1 | wall 12875
KL Stats: Epoch 39 Divergences: Uniform: 2.1804200416663146 Unigram: 2.640163408085552
2022-01-31 12:23:40 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:23:59 | INFO | train_inner | epoch 040:      4 / 64 loss=8.319, ppl=319.43, wps=6198.4, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.508, train_wall=474, gb_free=6.1, wall=12895
2022-01-31 12:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:29:09 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.326 | ppl 641.68 | wps 8651.8 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint40.pt
2022-01-31 12:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint40.pt
2022-01-31 12:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.326) (writing took 4.881707265012665 seconds)
2022-01-31 12:29:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:29:14 | INFO | train | epoch 040 | loss 8.229 | ppl 300.03 | wps 6245.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.508 | train_wall 303 | gb_free 6.1 | wall 13210
KL Stats: Epoch 40 Divergences: Uniform: 2.2076651354763066 Unigram: 2.67738658187128
2022-01-31 12:29:14 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:32:25 | INFO | train_inner | epoch 041:     40 / 64 loss=8.205, ppl=295.15, wps=6454.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.506, train_wall=475, gb_free=6.1, wall=13401
2022-01-31 12:34:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:34:44 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.317 | ppl 637.77 | wps 8673.8 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.317
2022-01-31 12:34:44 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:34:44 | INFO | train | epoch 041 | loss 8.165 | ppl 286.96 | wps 6333.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.505 | train_wall 304 | gb_free 6.1 | wall 13540
KL Stats: Epoch 41 Divergences: Uniform: 2.221443738611444 Unigram: 2.712206682521822
2022-01-31 12:34:44 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:40:13 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.294 | ppl 627.71 | wps 8644.2 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.294
2022-01-31 12:40:13 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 12:40:13 | INFO | train | epoch 042 | loss 8.101 | ppl 274.49 | wps 6337.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.515 | train_wall 303 | gb_free 6.1 | wall 13869
KL Stats: Epoch 42 Divergences: Uniform: 2.237935346230051 Unigram: 2.7540435213223597
2022-01-31 12:40:13 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 12:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:41:11 | INFO | train_inner | epoch 043:     12 / 64 loss=8.107, ppl=275.71, wps=6203.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.514, train_wall=474, gb_free=6.1, wall=13926
2022-01-31 12:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:45:43 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.327 | ppl 642.05 | wps 8664.3 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.326
2022-01-31 12:45:43 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 12:45:43 | INFO | train | epoch 043 | loss 8.036 | ppl 262.4 | wps 6340.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.507 | train_wall 303 | gb_free 6.1 | wall 14199
KL Stats: Epoch 43 Divergences: Uniform: 2.261333200701914 Unigram: 2.7913128920147487
2022-01-31 12:45:43 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 12:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:49:32 | INFO | train_inner | epoch 044:     48 / 64 loss=8.002, ppl=256.33, wps=6517.4, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.513, train_wall=475, gb_free=6.1, wall=14428
2022-01-31 12:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:51:12 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.34 | ppl 648.11 | wps 8657.5 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.326
2022-01-31 12:51:12 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 12:51:12 | INFO | train | epoch 044 | loss 7.976 | ppl 251.79 | wps 6334.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.513 | train_wall 304 | gb_free 6.1 | wall 14528
KL Stats: Epoch 44 Divergences: Uniform: 2.2775280908431363 Unigram: 2.826799115233034
2022-01-31 12:51:12 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 12:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:56:42 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.316 | ppl 637.33 | wps 8673.6 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.316
2022-01-31 12:56:42 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 12:56:42 | INFO | train | epoch 045 | loss 7.913 | ppl 241.04 | wps 6331 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.515 | train_wall 304 | gb_free 6.1 | wall 14858
KL Stats: Epoch 45 Divergences: Uniform: 2.294562090570219 Unigram: 2.869581372061677
2022-01-31 12:56:42 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 12:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:58:18 | INFO | train_inner | epoch 046:     20 / 64 loss=7.913, ppl=240.97, wps=6198.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.514, train_wall=474, gb_free=6.1, wall=14954
2022-01-31 13:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:02:12 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.313 | ppl 635.98 | wps 8642.5 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.313
2022-01-31 13:02:12 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:02:12 | INFO | train | epoch 046 | loss 7.854 | ppl 231.41 | wps 6331.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.523 | train_wall 304 | gb_free 6.1 | wall 15188
KL Stats: Epoch 46 Divergences: Uniform: 2.3092151561208794 Unigram: 2.894159442310697
2022-01-31 13:02:12 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:02:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:06:40 | INFO | train_inner | epoch 047:     56 / 64 loss=7.823, ppl=226.49, wps=6512.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.51, train_wall=475, gb_free=6.1, wall=15456
2022-01-31 13:07:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:07:42 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.302 | ppl 631.18 | wps 8651.9 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.302
2022-01-31 13:07:42 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:07:42 | INFO | train | epoch 047 | loss 7.796 | ppl 222.18 | wps 6332.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.506 | train_wall 304 | gb_free 6.1 | wall 15518
KL Stats: Epoch 47 Divergences: Uniform: 2.3318123438598524 Unigram: 2.925511145136698
2022-01-31 13:07:42 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:13:11 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.294 | ppl 627.78 | wps 8685.6 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.294
2022-01-31 13:13:11 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:13:11 | INFO | train | epoch 048 | loss 7.739 | ppl 213.6 | wps 6342.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.518 | train_wall 303 | gb_free 6.1 | wall 15847
KL Stats: Epoch 48 Divergences: Uniform: 2.347705015858914 Unigram: 2.963357710594926
2022-01-31 13:13:11 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:15:25 | INFO | train_inner | epoch 049:     28 / 64 loss=7.721, ppl=211.01, wps=6209.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.517, train_wall=473, gb_free=6.1, wall=15981
2022-01-31 13:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:18:40 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.333 | ppl 645.13 | wps 8680 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.326
2022-01-31 13:18:40 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:18:40 | INFO | train | epoch 049 | loss 7.682 | ppl 205.3 | wps 6348.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.518 | train_wall 303 | gb_free 6.1 | wall 16176
KL Stats: Epoch 49 Divergences: Uniform: 2.3515043399411204 Unigram: 2.9950348147804133
2022-01-31 13:18:40 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:18:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:23:44 | INFO | train_inner | epoch 050:     64 / 64 loss=7.657, ppl=201.84, wps=6525.6, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.529, train_wall=473, gb_free=6.1, wall=16480
2022-01-31 13:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:24:10 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.347 | ppl 651.01 | wps 8659.3 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.326
2022-01-31 13:24:10 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:24:10 | INFO | train | epoch 050 | loss 7.63 | ppl 198.14 | wps 6343.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.534 | train_wall 303 | gb_free 6.1 | wall 16505
KL Stats: Epoch 50 Divergences: Uniform: 2.3674361136453816 Unigram: 3.0203142879382803
2022-01-31 13:24:10 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:24:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:29:39 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.355 | ppl 654.97 | wps 8663.2 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.326
2022-01-31 13:29:39 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:29:39 | INFO | train | epoch 051 | loss 7.574 | ppl 190.59 | wps 6344.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.519 | train_wall 303 | gb_free 6.1 | wall 16835
KL Stats: Epoch 51 Divergences: Uniform: 2.394050767778345 Unigram: 3.0478396800905134
2022-01-31 13:29:39 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:32:31 | INFO | train_inner | epoch 052:     36 / 64 loss=7.55, ppl=187.46, wps=6211.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.52, train_wall=474, gb_free=6.1, wall=17006
2022-01-31 13:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:35:08 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.344 | ppl 650.08 | wps 8685 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.326
2022-01-31 13:35:08 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 13:35:08 | INFO | train | epoch 052 | loss 7.522 | ppl 183.8 | wps 6342.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.525 | train_wall 303 | gb_free 6.1 | wall 17164
KL Stats: Epoch 52 Divergences: Uniform: 2.407123674882871 Unigram: 3.0920985578908637
2022-01-31 13:35:08 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 13:35:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:40:37 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.331 | ppl 644.16 | wps 8659.9 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.326
2022-01-31 13:40:37 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 13:40:37 | INFO | train | epoch 053 | loss 7.471 | ppl 177.37 | wps 6341.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.518 | train_wall 303 | gb_free 6.1 | wall 17493
KL Stats: Epoch 53 Divergences: Uniform: 2.4222252122360075 Unigram: 3.1153657475525254
2022-01-31 13:40:37 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 13:40:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:41:16 | INFO | train_inner | epoch 054:      8 / 64 loss=7.483, ppl=178.96, wps=6207.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.525, train_wall=473, gb_free=6.1, wall=17532
2022-01-31 13:45:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:46:07 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.364 | ppl 658.91 | wps 8651.2 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.326
2022-01-31 13:46:07 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 13:46:07 | INFO | train | epoch 054 | loss 7.42 | ppl 171.3 | wps 6338 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.526 | train_wall 303 | gb_free 6.1 | wall 17823
KL Stats: Epoch 54 Divergences: Uniform: 2.431386707625916 Unigram: 3.1426068885666076
2022-01-31 13:46:07 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 13:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:49:37 | INFO | train_inner | epoch 055:     44 / 64 loss=7.393, ppl=168.11, wps=6519.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.527, train_wall=475, gb_free=6.1, wall=18033
2022-01-31 13:51:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:51:36 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.382 | ppl 667.26 | wps 8688.4 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.326
2022-01-31 13:51:36 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 13:51:36 | INFO | train | epoch 055 | loss 7.374 | ppl 165.85 | wps 6341.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.54 | train_wall 303 | gb_free 6.1 | wall 18152
KL Stats: Epoch 55 Divergences: Uniform: 2.4412968343911676 Unigram: 3.177885878313609
2022-01-31 13:51:36 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 13:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:57:06 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.465 | ppl 706.55 | wps 8685.1 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.326
2022-01-31 13:57:06 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 13:57:06 | INFO | train | epoch 056 | loss 7.324 | ppl 160.22 | wps 6343.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.529 | train_wall 303 | gb_free 6.1 | wall 18481
KL Stats: Epoch 56 Divergences: Uniform: 2.4449243932843365 Unigram: 3.1982874194093136
2022-01-31 13:57:06 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 13:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:58:22 | INFO | train_inner | epoch 057:     16 / 64 loss=7.328, ppl=160.69, wps=6209.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.537, train_wall=473, gb_free=6.1, wall=18558
2022-01-31 14:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:02:35 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.471 | ppl 709.45 | wps 8659.3 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.326
2022-01-31 14:02:35 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:02:35 | INFO | train | epoch 057 | loss 7.277 | ppl 155.09 | wps 6339.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.541 | train_wall 303 | gb_free 6.1 | wall 18811
KL Stats: Epoch 57 Divergences: Uniform: 2.4738395278632668 Unigram: 3.235402570953911
2022-01-31 14:02:35 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:06:43 | INFO | train_inner | epoch 058:     52 / 64 loss=7.252, ppl=152.45, wps=6521.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.536, train_wall=475, gb_free=6.1, wall=19059
2022-01-31 14:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:08:04 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.49 | ppl 719.27 | wps 8653.7 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.326
2022-01-31 14:08:04 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:08:04 | INFO | train | epoch 058 | loss 7.232 | ppl 150.32 | wps 6342.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.539 | train_wall 303 | gb_free 6.1 | wall 19140
KL Stats: Epoch 58 Divergences: Uniform: 2.482570292629034 Unigram: 3.261137688260474
2022-01-31 14:08:04 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:08:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:13:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:13:34 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.54 | ppl 744.53 | wps 8659.3 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.326
2022-01-31 14:13:34 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:13:34 | INFO | train | epoch 059 | loss 7.186 | ppl 145.64 | wps 6342.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.538 | train_wall 303 | gb_free 6.1 | wall 19470
KL Stats: Epoch 59 Divergences: Uniform: 2.4963397731052948 Unigram: 3.288185482177531
2022-01-31 14:13:34 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:15:28 | INFO | train_inner | epoch 060:     24 / 64 loss=7.18, ppl=145.01, wps=6207, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.541, train_wall=473, gb_free=6.1, wall=19584
2022-01-31 14:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:19:03 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.494 | ppl 720.97 | wps 8661.4 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.326
2022-01-31 14:19:03 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:19:03 | INFO | train | epoch 060 | loss 7.141 | ppl 141.18 | wps 6339.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.55 | train_wall 303 | gb_free 6.1 | wall 19799
KL Stats: Epoch 60 Divergences: Uniform: 2.5131464301878434 Unigram: 3.3220301948543978
2022-01-31 14:19:03 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:23:49 | INFO | train_inner | epoch 061:     60 / 64 loss=7.122, ppl=139.32, wps=6522.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.552, train_wall=474, gb_free=6.1, wall=20085
2022-01-31 14:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:24:32 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.549 | ppl 748.88 | wps 8658 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.326
2022-01-31 14:24:32 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:24:32 | INFO | train | epoch 061 | loss 7.099 | ppl 137.1 | wps 6343.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.553 | train_wall 303 | gb_free 6.1 | wall 20128
KL Stats: Epoch 61 Divergences: Uniform: 2.525891462538542 Unigram: 3.3346169889105512
2022-01-31 14:24:32 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:30:02 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.514 | ppl 731.26 | wps 8660 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.326
2022-01-31 14:30:02 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 14:30:02 | INFO | train | epoch 062 | loss 7.058 | ppl 133.27 | wps 6339.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.557 | train_wall 303 | gb_free 6.1 | wall 20458
KL Stats: Epoch 62 Divergences: Uniform: 2.528594754930607 Unigram: 3.373237554412178
2022-01-31 14:30:02 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 14:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:32:35 | INFO | train_inner | epoch 063:     32 / 64 loss=7.032, ppl=130.88, wps=6205.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.554, train_wall=473, gb_free=6.1, wall=20610
2022-01-31 14:35:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:35:31 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.547 | ppl 748.13 | wps 8683.4 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.326
2022-01-31 14:35:31 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 14:35:31 | INFO | train | epoch 063 | loss 7.014 | ppl 129.21 | wps 6342.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.551 | train_wall 303 | gb_free 6.1 | wall 20787
KL Stats: Epoch 63 Divergences: Uniform: 2.549045492901148 Unigram: 3.4021279169515246
2022-01-31 14:35:31 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 14:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:41:01 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.615 | ppl 784.25 | wps 8652.6 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.326
2022-01-31 14:41:01 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 14:41:01 | INFO | train | epoch 064 | loss 6.972 | ppl 125.53 | wps 6339.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.564 | train_wall 303 | gb_free 6.1 | wall 21117
KL Stats: Epoch 64 Divergences: Uniform: 2.5551295953489017 Unigram: 3.4205264833520586
2022-01-31 14:41:01 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 14:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:41:20 | INFO | train_inner | epoch 065:      4 / 64 loss=6.998, ppl=127.86, wps=6206.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.562, train_wall=473, gb_free=6.1, wall=21136
2022-01-31 14:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:46:30 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.627 | ppl 790.78 | wps 8665.8 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.326
2022-01-31 14:46:30 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 14:46:30 | INFO | train | epoch 065 | loss 6.928 | ppl 121.77 | wps 6338.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.562 | train_wall 303 | gb_free 6.1 | wall 21446
KL Stats: Epoch 65 Divergences: Uniform: 2.563942976226502 Unigram: 3.445737368680613
2022-01-31 14:46:30 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 14:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:49:41 | INFO | train_inner | epoch 066:     40 / 64 loss=6.904, ppl=119.75, wps=6519.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.567, train_wall=475, gb_free=6.1, wall=21637
2022-01-31 14:51:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:52:00 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.639 | ppl 797.29 | wps 8664.6 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.326
2022-01-31 14:52:00 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 14:52:00 | INFO | train | epoch 066 | loss 6.888 | ppl 118.46 | wps 6341.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.563 | train_wall 303 | gb_free 6.1 | wall 21775
KL Stats: Epoch 66 Divergences: Uniform: 2.5772898308287924 Unigram: 3.471961225872827
2022-01-31 14:52:00 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 14:52:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:57:30 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.638 | ppl 796.8 | wps 8481.3 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.326
2022-01-31 14:57:30 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 14:57:30 | INFO | train | epoch 067 | loss 6.847 | ppl 115.1 | wps 6327 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.569 | train_wall 304 | gb_free 6.1 | wall 22106
KL Stats: Epoch 67 Divergences: Uniform: 2.5950305911630087 Unigram: 3.507518799528248
2022-01-31 14:57:30 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 14:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:58:28 | INFO | train_inner | epoch 068:     12 / 64 loss=6.856, ppl=115.81, wps=6186.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.563, train_wall=475, gb_free=6.1, wall=22164
2022-01-31 15:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:03:05 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.681 | ppl 820.87 | wps 8466.7 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.326
2022-01-31 15:03:05 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:03:05 | INFO | train | epoch 068 | loss 6.81 | ppl 112.18 | wps 6233.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.582 | train_wall 308 | gb_free 6.1 | wall 22441
KL Stats: Epoch 68 Divergences: Uniform: 2.6060593442497813 Unigram: 3.5349998447665416
2022-01-31 15:03:05 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:06:58 | INFO | train_inner | epoch 069:     48 / 64 loss=6.792, ppl=110.8, wps=6414.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.581, train_wall=482, gb_free=6.1, wall=22673
2022-01-31 15:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:08:40 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.681 | ppl 820.85 | wps 8465.8 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.326
2022-01-31 15:08:40 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:08:40 | INFO | train | epoch 069 | loss 6.772 | ppl 109.27 | wps 6234.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.582 | train_wall 308 | gb_free 6.1 | wall 22776
KL Stats: Epoch 69 Divergences: Uniform: 2.618332367180402 Unigram: 3.5546142788288915
2022-01-31 15:08:40 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:14:15 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.785 | ppl 882.26 | wps 8469.1 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.326
2022-01-31 15:14:15 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:14:15 | INFO | train | epoch 070 | loss 6.736 | ppl 106.58 | wps 6236.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.575 | train_wall 308 | gb_free 6.1 | wall 23110
KL Stats: Epoch 70 Divergences: Uniform: 2.6226714181201594 Unigram: 3.571775430475295
2022-01-31 15:14:15 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:15:52 | INFO | train_inner | epoch 071:     20 / 64 loss=6.73, ppl=106.18, wps=6104.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.58, train_wall=481, gb_free=6.1, wall=23207
2022-01-31 15:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:19:50 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.776 | ppl 876.47 | wps 8493.9 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.326
2022-01-31 15:19:50 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:19:50 | INFO | train | epoch 071 | loss 6.701 | ppl 104.07 | wps 6234.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.588 | train_wall 308 | gb_free 6.1 | wall 23445
KL Stats: Epoch 71 Divergences: Uniform: 2.635696134088942 Unigram: 3.5959790520174897
2022-01-31 15:19:50 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:24:21 | INFO | train_inner | epoch 072:     56 / 64 loss=6.686, ppl=102.96, wps=6415.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.584, train_wall=482, gb_free=6.1, wall=23717
2022-01-31 15:24:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:25:24 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.668 | ppl 813.59 | wps 8458.9 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.326
2022-01-31 15:25:24 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 15:25:24 | INFO | train | epoch 072 | loss 6.666 | ppl 101.56 | wps 6239.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.583 | train_wall 308 | gb_free 6.1 | wall 23780
KL Stats: Epoch 72 Divergences: Uniform: 2.6509674567939228 Unigram: 3.627942886767364
2022-01-31 15:25:24 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 15:25:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:31:00 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.777 | ppl 877.34 | wps 8474.8 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.326
2022-01-31 15:31:00 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 15:31:00 | INFO | train | epoch 073 | loss 6.634 | ppl 99.29 | wps 6228.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.582 | train_wall 309 | gb_free 6.1 | wall 24116
KL Stats: Epoch 73 Divergences: Uniform: 2.6515154245954804 Unigram: 3.641509598538551
2022-01-31 15:31:00 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 15:31:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:33:16 | INFO | train_inner | epoch 074:     28 / 64 loss=6.622, ppl=98.52, wps=6095.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.584, train_wall=482, gb_free=6.1, wall=24252
2022-01-31 15:36:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:36:35 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.728 | ppl 847.88 | wps 8495.5 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.326
2022-01-31 15:36:35 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 15:36:35 | INFO | train | epoch 074 | loss 6.6 | ppl 97.02 | wps 6231.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.585 | train_wall 309 | gb_free 6.1 | wall 24451
KL Stats: Epoch 74 Divergences: Uniform: 2.6599145195931793 Unigram: 3.6727161269901174
2022-01-31 15:36:35 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 15:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:41:44 | INFO | train_inner | epoch 075:     64 / 64 loss=6.592, ppl=96.45, wps=6416.5, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.592, train_wall=481, gb_free=6.1, wall=24760
2022-01-31 15:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:42:10 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.859 | ppl 928.85 | wps 8489.6 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.326
2022-01-31 15:42:10 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 15:42:10 | INFO | train | epoch 075 | loss 6.572 | ppl 95.13 | wps 6239.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.597 | train_wall 308 | gb_free 6.1 | wall 24785
KL Stats: Epoch 75 Divergences: Uniform: 2.6677873147311764 Unigram: 3.6916189951416234
2022-01-31 15:42:10 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 15:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:47:45 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.804 | ppl 893.85 | wps 8478.5 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.326
2022-01-31 15:47:45 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 15:47:45 | INFO | train | epoch 076 | loss 6.541 | ppl 93.14 | wps 6233.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.607 | train_wall 308 | gb_free 6.1 | wall 25120
KL Stats: Epoch 76 Divergences: Uniform: 2.676770203705105 Unigram: 3.7220396256901878
2022-01-31 15:47:45 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 15:47:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:50:39 | INFO | train_inner | epoch 077:     36 / 64 loss=6.516, ppl=91.54, wps=6102.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.606, train_wall=483, gb_free=6.1, wall=25295
2022-01-31 15:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:53:20 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.758 | ppl 865.93 | wps 8486.5 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.326
2022-01-31 15:53:20 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 15:53:20 | INFO | train | epoch 077 | loss 6.511 | ppl 91.23 | wps 6233.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.616 | train_wall 308 | gb_free 6.1 | wall 25456
KL Stats: Epoch 77 Divergences: Uniform: 2.6854287922990836 Unigram: 3.751392547575252
2022-01-31 15:53:20 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 15:53:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:58:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:58:55 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.805 | ppl 894.51 | wps 8458.5 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.326
2022-01-31 15:58:55 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 15:58:55 | INFO | train | epoch 078 | loss 6.483 | ppl 89.43 | wps 6233.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.613 | train_wall 308 | gb_free 6.1 | wall 25791
KL Stats: Epoch 78 Divergences: Uniform: 2.691453206607939 Unigram: 3.766316553036266
2022-01-31 15:58:55 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 15:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:59:34 | INFO | train_inner | epoch 079:      8 / 64 loss=6.497, ppl=90.33, wps=6100, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.617, train_wall=481, gb_free=6.1, wall=25830
2022-01-31 16:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:04:31 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.889 | ppl 948.02 | wps 8475.2 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.326
2022-01-31 16:04:31 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:04:31 | INFO | train | epoch 079 | loss 6.451 | ppl 87.51 | wps 6220.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.601 | train_wall 309 | gb_free 6.1 | wall 26126
KL Stats: Epoch 79 Divergences: Uniform: 2.6939372343324948 Unigram: 3.78126672993646
2022-01-31 16:04:31 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:04:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:08:04 | INFO | train_inner | epoch 080:     44 / 64 loss=6.435, ppl=86.53, wps=6401.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.601, train_wall=483, gb_free=6.1, wall=26340
2022-01-31 16:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:10:06 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.808 | ppl 896.48 | wps 8447.7 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.326
2022-01-31 16:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:10:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint80.pt
2022-01-31 16:10:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint80.pt
2022-01-31 16:10:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.808) (writing took 3.5603353019687347 seconds)
2022-01-31 16:10:10 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:10:10 | INFO | train | epoch 080 | loss 6.427 | ppl 86.02 | wps 6161.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.609 | train_wall 309 | gb_free 6.1 | wall 26465
KL Stats: Epoch 80 Divergences: Uniform: 2.7024125311039207 Unigram: 3.807613960436276
2022-01-31 16:10:10 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:15:45 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.903 | ppl 957.55 | wps 8470.7 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.326
2022-01-31 16:15:45 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:15:45 | INFO | train | epoch 081 | loss 6.401 | ppl 84.53 | wps 6229.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.622 | train_wall 309 | gb_free 6.1 | wall 26801
KL Stats: Epoch 81 Divergences: Uniform: 2.7187858859645067 Unigram: 3.8318851558145184
2022-01-31 16:15:45 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:17:03 | INFO | train_inner | epoch 082:     16 / 64 loss=6.408, ppl=84.92, wps=6054.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.625, train_wall=482, gb_free=6.1, wall=26879
2022-01-31 16:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:21:21 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.839 | ppl 915.94 | wps 8449.9 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.326
2022-01-31 16:21:21 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:21:21 | INFO | train | epoch 082 | loss 6.374 | ppl 82.95 | wps 6221.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.617 | train_wall 309 | gb_free 6.1 | wall 27136
KL Stats: Epoch 82 Divergences: Uniform: 2.723287194768852 Unigram: 3.8658415518810205
2022-01-31 16:21:21 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:25:33 | INFO | train_inner | epoch 083:     52 / 64 loss=6.36, ppl=82.13, wps=6401.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.627, train_wall=483, gb_free=6.1, wall=27389
2022-01-31 16:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:26:56 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.775 | ppl 876.01 | wps 8433.9 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.326
2022-01-31 16:26:56 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 16:26:56 | INFO | train | epoch 083 | loss 6.35 | ppl 81.55 | wps 6222.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.639 | train_wall 309 | gb_free 6.1 | wall 27472
KL Stats: Epoch 83 Divergences: Uniform: 2.733066352271949 Unigram: 3.8812998243823773
2022-01-31 16:26:56 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 16:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:32:32 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.843 | ppl 918.37 | wps 8479.2 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.326
2022-01-31 16:32:32 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 16:32:32 | INFO | train | epoch 084 | loss 6.323 | ppl 80.07 | wps 6220.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.625 | train_wall 309 | gb_free 6.1 | wall 27808
KL Stats: Epoch 84 Divergences: Uniform: 2.7399716252387494 Unigram: 3.8974870511599766
2022-01-31 16:32:32 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 16:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:34:28 | INFO | train_inner | epoch 085:     24 / 64 loss=6.312, ppl=79.48, wps=6091.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.626, train_wall=482, gb_free=6.1, wall=27924
2022-01-31 16:37:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:38:07 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.882 | ppl 943.79 | wps 8485.9 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.326
2022-01-31 16:38:07 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 16:38:07 | INFO | train | epoch 085 | loss 6.3 | ppl 78.79 | wps 6233.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.635 | train_wall 308 | gb_free 6.1 | wall 28143
KL Stats: Epoch 85 Divergences: Uniform: 2.7499357247638323 Unigram: 3.920821769577209
2022-01-31 16:38:07 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 16:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:42:58 | INFO | train_inner | epoch 086:     60 / 64 loss=6.297, ppl=78.64, wps=6411, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.638, train_wall=483, gb_free=6.1, wall=28434
2022-01-31 16:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:43:42 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.933 | ppl 977.34 | wps 8505 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.326
2022-01-31 16:43:42 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 16:43:42 | INFO | train | epoch 086 | loss 6.276 | ppl 77.47 | wps 6232.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.639 | train_wall 309 | gb_free 6.1 | wall 28478
KL Stats: Epoch 86 Divergences: Uniform: 2.749816638440277 Unigram: 3.9447428747330355
2022-01-31 16:43:42 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 16:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:49:17 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.93 | ppl 975.62 | wps 8471.2 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.326
2022-01-31 16:49:17 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 16:49:17 | INFO | train | epoch 087 | loss 6.254 | ppl 76.3 | wps 6228.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.656 | train_wall 309 | gb_free 6.1 | wall 28813
KL Stats: Epoch 87 Divergences: Uniform: 2.7570176675909104 Unigram: 3.9567084475405947
2022-01-31 16:49:17 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 16:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:51:53 | INFO | train_inner | epoch 088:     32 / 64 loss=6.24, ppl=75.6, wps=6097, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.653, train_wall=482, gb_free=6.1, wall=28969
2022-01-31 16:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:54:53 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.901 | ppl 955.9 | wps 8469.3 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.326
2022-01-31 16:54:53 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 16:54:53 | INFO | train | epoch 088 | loss 6.231 | ppl 75.1 | wps 6223.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.651 | train_wall 309 | gb_free 6.1 | wall 29149
KL Stats: Epoch 88 Divergences: Uniform: 2.763481384587193 Unigram: 3.9818362478568616
2022-01-31 16:54:53 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 16:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:00:29 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.911 | ppl 962.89 | wps 8469.2 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.326
2022-01-31 17:00:29 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:00:29 | INFO | train | epoch 089 | loss 6.213 | ppl 74.2 | wps 6221.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.674 | train_wall 309 | gb_free 6.1 | wall 29485
KL Stats: Epoch 89 Divergences: Uniform: 2.772029917556553 Unigram: 3.9957191701788295
2022-01-31 17:00:29 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:00:48 | INFO | train_inner | epoch 090:      4 / 64 loss=6.224, ppl=74.73, wps=6088.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.667, train_wall=482, gb_free=6.1, wall=29504
2022-01-31 17:05:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:06:04 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.974 | ppl 1005.38 | wps 8481.1 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.326
2022-01-31 17:06:04 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:06:04 | INFO | train | epoch 090 | loss 6.188 | ppl 72.91 | wps 6224.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.655 | train_wall 309 | gb_free 6.1 | wall 29820
KL Stats: Epoch 90 Divergences: Uniform: 2.7743925227094532 Unigram: 4.011171219457905
2022-01-31 17:06:04 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:09:19 | INFO | train_inner | epoch 091:     40 / 64 loss=6.17, ppl=71.99, wps=6404.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.653, train_wall=483, gb_free=6.1, wall=30014
2022-01-31 17:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:11:39 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.945 | ppl 985.5 | wps 8516 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.326
2022-01-31 17:11:39 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:11:39 | INFO | train | epoch 091 | loss 6.166 | ppl 71.78 | wps 6232.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.657 | train_wall 309 | gb_free 6.1 | wall 30155
KL Stats: Epoch 91 Divergences: Uniform: 2.7827876296722778 Unigram: 4.044986030868144
2022-01-31 17:11:39 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:11:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:17:15 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.98 | ppl 1010.04 | wps 8502.8 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.326
2022-01-31 17:17:15 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:17:15 | INFO | train | epoch 092 | loss 6.147 | ppl 70.88 | wps 6225.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.681 | train_wall 309 | gb_free 6.1 | wall 30491
KL Stats: Epoch 92 Divergences: Uniform: 2.789062773022607 Unigram: 4.062267832792022
2022-01-31 17:17:15 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:18:13 | INFO | train_inner | epoch 093:     12 / 64 loss=6.156, ppl=71.32, wps=6098, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.674, train_wall=482, gb_free=6.1, wall=30549
2022-01-31 17:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:22:50 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.911 | ppl 962.51 | wps 8476.2 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.326
2022-01-31 17:22:50 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 17:22:50 | INFO | train | epoch 093 | loss 6.129 | ppl 70 | wps 6233.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.677 | train_wall 308 | gb_free 6.1 | wall 30826
KL Stats: Epoch 93 Divergences: Uniform: 2.7930974417456613 Unigram: 4.082826242518859
2022-01-31 17:22:50 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 17:22:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:26:43 | INFO | train_inner | epoch 094:     48 / 64 loss=6.115, ppl=69.29, wps=6408.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.68, train_wall=483, gb_free=6.1, wall=31059
2022-01-31 17:28:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:28:25 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.009 | ppl 1030.45 | wps 8479.2 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.326
2022-01-31 17:28:25 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 17:28:25 | INFO | train | epoch 094 | loss 6.108 | ppl 68.96 | wps 6226.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.679 | train_wall 309 | gb_free 6.1 | wall 31161
KL Stats: Epoch 94 Divergences: Uniform: 2.794718596335257 Unigram: 4.100380602911532
2022-01-31 17:28:25 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 17:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:34:01 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.034 | ppl 1048.51 | wps 8476.3 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.326
2022-01-31 17:34:01 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 17:34:01 | INFO | train | epoch 095 | loss 6.088 | ppl 68.01 | wps 6223.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.671 | train_wall 309 | gb_free 6.1 | wall 31497
KL Stats: Epoch 95 Divergences: Uniform: 2.798401115843311 Unigram: 4.116616116594432
2022-01-31 17:34:01 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 17:34:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:35:38 | INFO | train_inner | epoch 096:     20 / 64 loss=6.087, ppl=67.98, wps=6092.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.679, train_wall=482, gb_free=6.1, wall=31594
2022-01-31 17:39:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:39:36 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.938 | ppl 981.04 | wps 8523 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.326
2022-01-31 17:39:36 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 17:39:36 | INFO | train | epoch 096 | loss 6.071 | ppl 67.21 | wps 6240.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.698 | train_wall 308 | gb_free 6.1 | wall 31832
KL Stats: Epoch 96 Divergences: Uniform: 2.8145845751205765 Unigram: 4.132888318801318
2022-01-31 17:39:36 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 17:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:44:07 | INFO | train_inner | epoch 097:     56 / 64 loss=6.065, ppl=66.94, wps=6426, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.693, train_wall=482, gb_free=6.1, wall=32103
2022-01-31 17:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:45:10 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.029 | ppl 1044.88 | wps 8505.3 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.326
2022-01-31 17:45:10 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 17:45:10 | INFO | train | epoch 097 | loss 6.054 | ppl 66.42 | wps 6248.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.694 | train_wall 308 | gb_free 6.1 | wall 32166
KL Stats: Epoch 97 Divergences: Uniform: 2.8203055707285576 Unigram: 4.15749548320711
2022-01-31 17:45:10 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 17:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:50:45 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.983 | ppl 1012.16 | wps 8495 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.326
2022-01-31 17:50:45 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 17:50:45 | INFO | train | epoch 098 | loss 6.034 | ppl 65.54 | wps 6238 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.722 | train_wall 308 | gb_free 6.1 | wall 32501
KL Stats: Epoch 98 Divergences: Uniform: 2.8204585626503125 Unigram: 4.162579997613385
2022-01-31 17:50:45 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 17:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:53:01 | INFO | train_inner | epoch 099:     28 / 64 loss=6.025, ppl=65.13, wps=6105.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.724, train_wall=481, gb_free=6.1, wall=32636
2022-01-31 17:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:56:19 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.008 | ppl 1029.95 | wps 8520.1 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.326
2022-01-31 17:56:19 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 17:56:19 | INFO | train | epoch 099 | loss 6.016 | ppl 64.72 | wps 6245.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.722 | train_wall 308 | gb_free 6.1 | wall 32835
KL Stats: Epoch 99 Divergences: Uniform: 2.826178525640231 Unigram: 4.1873297947436185
2022-01-31 17:56:19 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 17:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:01:28 | INFO | train_inner | epoch 100:     64 / 64 loss=6.019, ppl=64.83, wps=6429.3, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.723, train_wall=480, gb_free=6.1, wall=33144
2022-01-31 18:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:01:53 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.007 | ppl 1028.75 | wps 8508.5 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.326
2022-01-31 18:01:53 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:01:53 | INFO | train | epoch 100 | loss 6.001 | ppl 64.04 | wps 6250.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.727 | train_wall 308 | gb_free 6.1 | wall 33169
KL Stats: Epoch 100 Divergences: Uniform: 2.824272446985833 Unigram: 4.195015192349328
2022-01-31 18:01:53 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:07:28 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.07 | ppl 1075.1 | wps 8480.1 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.326
2022-01-31 18:07:28 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:07:28 | INFO | train | epoch 101 | loss 5.983 | ppl 63.23 | wps 6235 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.731 | train_wall 308 | gb_free 6.1 | wall 33504
KL Stats: Epoch 101 Divergences: Uniform: 2.8393487423407042 Unigram: 4.218693767713537
2022-01-31 18:07:28 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:10:23 | INFO | train_inner | epoch 102:     36 / 64 loss=5.968, ppl=62.61, wps=6105, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.731, train_wall=482, gb_free=6.1, wall=33679
2022-01-31 18:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:13:03 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 10.079 | ppl 1081.82 | wps 8472 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.326
2022-01-31 18:13:03 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:13:03 | INFO | train | epoch 102 | loss 5.968 | ppl 62.57 | wps 6235.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.729 | train_wall 308 | gb_free 6.1 | wall 33839
KL Stats: Epoch 102 Divergences: Uniform: 2.839530661642631 Unigram: 4.2357347550203786
2022-01-31 18:13:03 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:18:38 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.091 | ppl 1090.82 | wps 8544.4 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.326
2022-01-31 18:18:38 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 18:18:38 | INFO | train | epoch 103 | loss 5.949 | ppl 61.78 | wps 6231.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.721 | train_wall 309 | gb_free 6.1 | wall 34174
KL Stats: Epoch 103 Divergences: Uniform: 2.8518920019897314 Unigram: 4.2535451524161365
2022-01-31 18:18:38 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 18:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:19:17 | INFO | train_inner | epoch 104:      8 / 64 loss=5.957, ppl=62.11, wps=6102.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.722, train_wall=481, gb_free=6.1, wall=34213
2022-01-31 18:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:24:13 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.078 | ppl 1080.67 | wps 8464.8 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.326
2022-01-31 18:24:13 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 18:24:13 | INFO | train | epoch 104 | loss 5.936 | ppl 61.23 | wps 6244.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.735 | train_wall 308 | gb_free 6.1 | wall 34509
KL Stats: Epoch 104 Divergences: Uniform: 2.846316067525878 Unigram: 4.271676171900059
2022-01-31 18:24:13 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 18:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:27:46 | INFO | train_inner | epoch 105:     44 / 64 loss=5.924, ppl=60.72, wps=6418.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.741, train_wall=482, gb_free=6.1, wall=34722
2022-01-31 18:29:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:29:48 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.029 | ppl 1044.78 | wps 8514.2 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.326
2022-01-31 18:29:48 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 18:29:48 | INFO | train | epoch 105 | loss 5.921 | ppl 60.57 | wps 6236.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.745 | train_wall 308 | gb_free 6.1 | wall 34844
KL Stats: Epoch 105 Divergences: Uniform: 2.853214934408744 Unigram: 4.285304926894688
2022-01-31 18:29:48 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 18:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:35:23 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.108 | ppl 1103.91 | wps 8518.5 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.326
2022-01-31 18:35:23 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 18:35:23 | INFO | train | epoch 106 | loss 5.903 | ppl 59.84 | wps 6239.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.729 | train_wall 308 | gb_free 6.1 | wall 35178
KL Stats: Epoch 106 Divergences: Uniform: 2.8544577686616277 Unigram: 4.292459220183567
2022-01-31 18:35:23 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 18:35:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:36:40 | INFO | train_inner | epoch 107:     16 / 64 loss=5.907, ppl=60, wps=6105.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.737, train_wall=481, gb_free=6.1, wall=35256
2022-01-31 18:40:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:40:57 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.11 | ppl 1105.39 | wps 8493.8 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.326
2022-01-31 18:40:57 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 18:40:57 | INFO | train | epoch 107 | loss 5.887 | ppl 59.19 | wps 6241.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.745 | train_wall 308 | gb_free 6.1 | wall 35513
KL Stats: Epoch 107 Divergences: Uniform: 2.8634388464797724 Unigram: 4.313897806964236
2022-01-31 18:40:57 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 18:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:45:09 | INFO | train_inner | epoch 108:     52 / 64 loss=5.883, ppl=59, wps=6420.5, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.756, train_wall=482, gb_free=6.1, wall=35765
2022-01-31 18:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:46:32 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.112 | ppl 1106.8 | wps 8496.5 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.326
2022-01-31 18:46:32 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 18:46:32 | INFO | train | epoch 108 | loss 5.876 | ppl 58.74 | wps 6241.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.777 | train_wall 308 | gb_free 6.1 | wall 35848
KL Stats: Epoch 108 Divergences: Uniform: 2.867727607078569 Unigram: 4.324856370171599
2022-01-31 18:46:32 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 18:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:51:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:52:07 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.121 | ppl 1113.86 | wps 8475.8 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.326
2022-01-31 18:52:07 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 18:52:07 | INFO | train | epoch 109 | loss 5.86 | ppl 58.09 | wps 6231.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.763 | train_wall 309 | gb_free 6.1 | wall 36183
KL Stats: Epoch 109 Divergences: Uniform: 2.8681110768544635 Unigram: 4.346300518147637
2022-01-31 18:52:07 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 18:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:54:04 | INFO | train_inner | epoch 110:     24 / 64 loss=5.854, ppl=57.86, wps=6101.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.769, train_wall=481, gb_free=6.1, wall=36299
2022-01-31 18:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:57:42 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.166 | ppl 1148.73 | wps 8488.6 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.326
2022-01-31 18:57:42 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 18:57:42 | INFO | train | epoch 110 | loss 5.847 | ppl 57.54 | wps 6232.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.769 | train_wall 308 | gb_free 6.1 | wall 36518
KL Stats: Epoch 110 Divergences: Uniform: 2.8757373250647222 Unigram: 4.360464246337592
2022-01-31 18:57:42 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 18:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:02:33 | INFO | train_inner | epoch 111:     60 / 64 loss=5.846, ppl=57.51, wps=6414.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.778, train_wall=482, gb_free=6.1, wall=36809
2022-01-31 19:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:03:17 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.132 | ppl 1121.93 | wps 8488.2 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.326
2022-01-31 19:03:17 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:03:17 | INFO | train | epoch 111 | loss 5.833 | ppl 57 | wps 6238.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.783 | train_wall 308 | gb_free 6.1 | wall 36853
KL Stats: Epoch 111 Divergences: Uniform: 2.8757006983412037 Unigram: 4.379962283666537
2022-01-31 19:03:17 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:08:52 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.18 | ppl 1159.82 | wps 8490.1 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.326
2022-01-31 19:08:52 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:08:52 | INFO | train | epoch 112 | loss 5.818 | ppl 56.42 | wps 6233.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.779 | train_wall 308 | gb_free 6.1 | wall 37188
KL Stats: Epoch 112 Divergences: Uniform: 2.879814677591912 Unigram: 4.395338171490341
2022-01-31 19:08:52 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:11:27 | INFO | train_inner | epoch 113:     32 / 64 loss=5.806, ppl=55.96, wps=6109.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.778, train_wall=481, gb_free=6.1, wall=37342
2022-01-31 19:14:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:14:26 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.134 | ppl 1123.32 | wps 8505.4 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.326
2022-01-31 19:14:26 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 19:14:26 | INFO | train | epoch 113 | loss 5.803 | ppl 55.84 | wps 6252 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.773 | train_wall 308 | gb_free 6.1 | wall 37522
KL Stats: Epoch 113 Divergences: Uniform: 2.887484484654345 Unigram: 4.408567771877758
2022-01-31 19:14:26 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 19:14:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:20:01 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.158 | ppl 1142.84 | wps 8463.6 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.326
2022-01-31 19:20:01 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 19:20:01 | INFO | train | epoch 114 | loss 5.791 | ppl 55.37 | wps 6235.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.791 | train_wall 308 | gb_free 6.1 | wall 37857
KL Stats: Epoch 114 Divergences: Uniform: 2.888618008486176 Unigram: 4.419617988774367
2022-01-31 19:20:01 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 19:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:20:20 | INFO | train_inner | epoch 115:      4 / 64 loss=5.803, ppl=55.84, wps=6106.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.789, train_wall=481, gb_free=6.1, wall=37876
2022-01-31 19:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:25:36 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.163 | ppl 1146.61 | wps 8513.4 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.326
2022-01-31 19:25:36 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 19:25:36 | INFO | train | epoch 115 | loss 5.779 | ppl 54.9 | wps 6241.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.8 | train_wall 308 | gb_free 6.1 | wall 38191
KL Stats: Epoch 115 Divergences: Uniform: 2.893427841725796 Unigram: 4.43073827533578
2022-01-31 19:25:36 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 19:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:28:50 | INFO | train_inner | epoch 116:     40 / 64 loss=5.764, ppl=54.35, wps=6415.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.791, train_wall=482, gb_free=6.1, wall=38386
2022-01-31 19:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:31:11 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.127 | ppl 1118.07 | wps 8483.7 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.326
2022-01-31 19:31:11 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 19:31:11 | INFO | train | epoch 116 | loss 5.765 | ppl 54.38 | wps 6230.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.788 | train_wall 309 | gb_free 6.1 | wall 38527
KL Stats: Epoch 116 Divergences: Uniform: 2.8974294330192256 Unigram: 4.437428403736695
2022-01-31 19:31:11 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 19:31:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:36:46 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.225 | ppl 1196.82 | wps 8483.2 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.326
2022-01-31 19:36:46 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 19:36:46 | INFO | train | epoch 117 | loss 5.754 | ppl 53.98 | wps 6240.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.801 | train_wall 308 | gb_free 6.1 | wall 38861
KL Stats: Epoch 117 Divergences: Uniform: 2.896982778298606 Unigram: 4.461594135032143
2022-01-31 19:36:46 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 19:36:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:37:44 | INFO | train_inner | epoch 118:     12 / 64 loss=5.76, ppl=54.18, wps=6105.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.808, train_wall=481, gb_free=6.1, wall=38920
2022-01-31 19:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:42:20 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.171 | ppl 1153.16 | wps 8463.9 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.326
2022-01-31 19:42:20 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 19:42:20 | INFO | train | epoch 118 | loss 5.742 | ppl 53.5 | wps 6238.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.812 | train_wall 308 | gb_free 6.1 | wall 39196
KL Stats: Epoch 118 Divergences: Uniform: 2.90852886467471 Unigram: 4.4740443212743655
2022-01-31 19:42:20 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 19:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:46:13 | INFO | train_inner | epoch 119:     48 / 64 loss=5.73, ppl=53.08, wps=6416.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=482, gb_free=6.1, wall=39429
2022-01-31 19:47:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:47:55 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.157 | ppl 1141.33 | wps 8482.7 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.326
2022-01-31 19:47:55 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 19:47:55 | INFO | train | epoch 119 | loss 5.727 | ppl 52.97 | wps 6238.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.795 | train_wall 308 | gb_free 6.1 | wall 39531
KL Stats: Epoch 119 Divergences: Uniform: 2.9090011743138326 Unigram: 4.493895493027797
2022-01-31 19:47:55 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 19:47:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:53:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:53:29 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.224 | ppl 1196.03 | wps 8507.7 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.326
2022-01-31 19:53:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 19:53:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint120.pt
2022-01-31 19:53:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint120.pt
2022-01-31 19:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.224) (writing took 4.271166735037696 seconds)
2022-01-31 19:53:33 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 19:53:33 | INFO | train | epoch 120 | loss 5.718 | ppl 52.65 | wps 6181.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.841 | train_wall 307 | gb_free 6.1 | wall 39869
KL Stats: Epoch 120 Divergences: Uniform: 2.913523930948785 Unigram: 4.500055369619682
2022-01-31 19:53:33 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 19:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:55:10 | INFO | train_inner | epoch 121:     20 / 64 loss=5.72, ppl=52.72, wps=6074.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.843, train_wall=480, gb_free=6.1, wall=39966
2022-01-31 19:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:59:07 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.202 | ppl 1178.1 | wps 8494.3 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.326
2022-01-31 19:59:07 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 19:59:07 | INFO | train | epoch 121 | loss 5.708 | ppl 52.27 | wps 6247.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.832 | train_wall 308 | gb_free 6.1 | wall 40203
KL Stats: Epoch 121 Divergences: Uniform: 2.9143809572728645 Unigram: 4.514382908834228
2022-01-31 19:59:07 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 19:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:03:39 | INFO | train_inner | epoch 122:     56 / 64 loss=5.704, ppl=52.12, wps=6420, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.825, train_wall=482, gb_free=6.1, wall=40475
2022-01-31 20:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:04:42 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.184 | ppl 1163.16 | wps 8526.2 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.326
2022-01-31 20:04:42 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:04:42 | INFO | train | epoch 122 | loss 5.696 | ppl 51.83 | wps 6243.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.833 | train_wall 308 | gb_free 6.1 | wall 40538
KL Stats: Epoch 122 Divergences: Uniform: 2.91664986985025 Unigram: 4.526332197218961
2022-01-31 20:04:42 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:04:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:10:16 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.226 | ppl 1197.87 | wps 8543.8 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.326
2022-01-31 20:10:16 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 20:10:16 | INFO | train | epoch 123 | loss 5.682 | ppl 51.35 | wps 6254.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.835 | train_wall 308 | gb_free 6.1 | wall 40872
KL Stats: Epoch 123 Divergences: Uniform: 2.9160364511221504 Unigram: 4.544041454553922
2022-01-31 20:10:16 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 20:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:12:31 | INFO | train_inner | epoch 124:     28 / 64 loss=5.675, ppl=51.1, wps=6122.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.827, train_wall=480, gb_free=6.1, wall=41007
2022-01-31 20:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:15:50 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.217 | ppl 1190.37 | wps 8506 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.326
2022-01-31 20:15:50 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 20:15:50 | INFO | train | epoch 124 | loss 5.67 | ppl 50.93 | wps 6249.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.824 | train_wall 308 | gb_free 6.1 | wall 41206
KL Stats: Epoch 124 Divergences: Uniform: 2.915198025362681 Unigram: 4.5475545003580296
2022-01-31 20:15:50 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 20:15:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:20:59 | INFO | train_inner | epoch 125:     64 / 64 loss=5.675, ppl=51.09, wps=6414.7, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.834, train_wall=481, gb_free=6.1, wall=41515
2022-01-31 20:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:21:25 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.261 | ppl 1227.09 | wps 8475 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.326
2022-01-31 20:21:25 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 20:21:25 | INFO | train | epoch 125 | loss 5.661 | ppl 50.59 | wps 6231.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.831 | train_wall 308 | gb_free 6.1 | wall 41541
KL Stats: Epoch 125 Divergences: Uniform: 2.9228282789627396 Unigram: 4.566401216859982
2022-01-31 20:21:25 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 20:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:26:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:26:59 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.196 | ppl 1173.32 | wps 8480.9 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.326
2022-01-31 20:26:59 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 20:26:59 | INFO | train | epoch 126 | loss 5.65 | ppl 50.21 | wps 6253.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.825 | train_wall 307 | gb_free 6.1 | wall 41875
KL Stats: Epoch 126 Divergences: Uniform: 2.931145260506506 Unigram: 4.583903470570598
2022-01-31 20:26:59 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 20:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:29:54 | INFO | train_inner | epoch 127:     36 / 64 loss=5.638, ppl=49.81, wps=6118.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.851, train_wall=481, gb_free=6.1, wall=42049
2022-01-31 20:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:32:34 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.195 | ppl 1172.5 | wps 8494 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.326
2022-01-31 20:32:34 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 20:32:34 | INFO | train | epoch 127 | loss 5.641 | ppl 49.91 | wps 6240.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.877 | train_wall 308 | gb_free 6.1 | wall 42210
KL Stats: Epoch 127 Divergences: Uniform: 2.9329548366748117 Unigram: 4.585434422617852
2022-01-31 20:32:34 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 20:32:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:38:08 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.228 | ppl 1198.91 | wps 8528.7 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.326
2022-01-31 20:38:08 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 20:38:08 | INFO | train | epoch 128 | loss 5.629 | ppl 49.48 | wps 6245.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.868 | train_wall 308 | gb_free 6.1 | wall 42544
KL Stats: Epoch 128 Divergences: Uniform: 2.923145826054424 Unigram: 4.595537100375836
2022-01-31 20:38:08 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 20:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:38:47 | INFO | train_inner | epoch 129:      8 / 64 loss=5.636, ppl=49.74, wps=6110.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.866, train_wall=481, gb_free=6.1, wall=42583
2022-01-31 20:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:43:42 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.189 | ppl 1167.42 | wps 8558.6 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.326
2022-01-31 20:43:42 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 20:43:42 | INFO | train | epoch 129 | loss 5.622 | ppl 49.25 | wps 6260.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.888 | train_wall 307 | gb_free 6.1 | wall 42878
KL Stats: Epoch 129 Divergences: Uniform: 2.929744821625501 Unigram: 4.607004362268021
2022-01-31 20:43:42 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 20:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:47:14 | INFO | train_inner | epoch 130:     44 / 64 loss=5.609, ppl=48.82, wps=6441.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.875, train_wall=480, gb_free=6.1, wall=43090
2022-01-31 20:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:49:15 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.288 | ppl 1250.45 | wps 8523.6 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.326
2022-01-31 20:49:15 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 20:49:15 | INFO | train | epoch 130 | loss 5.608 | ppl 48.79 | wps 6263.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.865 | train_wall 307 | gb_free 6.1 | wall 43211
KL Stats: Epoch 130 Divergences: Uniform: 2.9330096932659666 Unigram: 4.628320513647819
2022-01-31 20:49:15 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 20:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:54:50 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.251 | ppl 1218.75 | wps 8499.2 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.326
2022-01-31 20:54:50 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 20:54:50 | INFO | train | epoch 131 | loss 5.601 | ppl 48.52 | wps 6244.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.894 | train_wall 308 | gb_free 6.1 | wall 43546
KL Stats: Epoch 131 Divergences: Uniform: 2.934985056698084 Unigram: 4.629325769765611
2022-01-31 20:54:50 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 20:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:56:08 | INFO | train_inner | epoch 132:     16 / 64 loss=5.603, ppl=48.6, wps=6114.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.882, train_wall=480, gb_free=6.1, wall=43623
2022-01-31 20:59:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:00:25 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.265 | ppl 1230.66 | wps 8495.7 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.326
2022-01-31 21:00:25 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:00:25 | INFO | train | epoch 132 | loss 5.589 | ppl 48.14 | wps 6234 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.885 | train_wall 308 | gb_free 6.1 | wall 43881
KL Stats: Epoch 132 Divergences: Uniform: 2.9356706579473353 Unigram: 4.653152776304161
2022-01-31 21:00:25 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:00:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:04:37 | INFO | train_inner | epoch 133:     52 / 64 loss=5.584, ppl=47.97, wps=6416.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.904, train_wall=482, gb_free=6.1, wall=44133
2022-01-31 21:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:05:59 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.282 | ppl 1245.27 | wps 8516.6 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.326
2022-01-31 21:05:59 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 21:05:59 | INFO | train | epoch 133 | loss 5.58 | ppl 47.84 | wps 6245.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.912 | train_wall 308 | gb_free 6.1 | wall 44215
KL Stats: Epoch 133 Divergences: Uniform: 2.947139322413797 Unigram: 4.658479379644619
2022-01-31 21:05:59 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 21:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:11:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:11:34 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.317 | ppl 1275.84 | wps 8499.9 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.326
2022-01-31 21:11:34 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 21:11:34 | INFO | train | epoch 134 | loss 5.571 | ppl 47.55 | wps 6236.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.926 | train_wall 308 | gb_free 6.1 | wall 44550
KL Stats: Epoch 134 Divergences: Uniform: 2.9411135552673406 Unigram: 4.677324379702118
2022-01-31 21:11:34 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 21:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:13:31 | INFO | train_inner | epoch 135:     24 / 64 loss=5.571, ppl=47.53, wps=6105.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.924, train_wall=481, gb_free=6.1, wall=44667
2022-01-31 21:16:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:17:09 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.251 | ppl 1218.18 | wps 8523.4 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.326
2022-01-31 21:17:09 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 21:17:09 | INFO | train | epoch 135 | loss 5.56 | ppl 47.19 | wps 6240.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.884 | train_wall 308 | gb_free 6.1 | wall 44885
KL Stats: Epoch 135 Divergences: Uniform: 2.950843291657266 Unigram: 4.686307114280704
2022-01-31 21:17:09 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 21:17:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:21:59 | INFO | train_inner | epoch 136:     60 / 64 loss=5.562, ppl=47.24, wps=6437.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.901, train_wall=481, gb_free=6.1, wall=45174
2022-01-31 21:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:22:42 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.327 | ppl 1284.9 | wps 8498.6 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.326
2022-01-31 21:22:42 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 21:22:42 | INFO | train | epoch 136 | loss 5.554 | ppl 46.97 | wps 6265.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.924 | train_wall 307 | gb_free 6.1 | wall 45218
KL Stats: Epoch 136 Divergences: Uniform: 2.944617387616682 Unigram: 4.688226809884727
2022-01-31 21:22:42 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 21:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:28:17 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.411 | ppl 1361.73 | wps 8502.4 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.326
2022-01-31 21:28:17 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 21:28:17 | INFO | train | epoch 137 | loss 5.543 | ppl 46.62 | wps 6242.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.913 | train_wall 308 | gb_free 6.1 | wall 45553
KL Stats: Epoch 137 Divergences: Uniform: 2.946300688395223 Unigram: 4.705965392175802
2022-01-31 21:28:17 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 21:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:30:52 | INFO | train_inner | epoch 138:     32 / 64 loss=5.534, ppl=46.34, wps=6108.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.913, train_wall=481, gb_free=6.1, wall=45708
2022-01-31 21:33:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:33:52 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.385 | ppl 1337.12 | wps 8494.1 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.326
2022-01-31 21:33:52 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 21:33:52 | INFO | train | epoch 138 | loss 5.534 | ppl 46.32 | wps 6235.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.932 | train_wall 308 | gb_free 6.1 | wall 45888
KL Stats: Epoch 138 Divergences: Uniform: 2.9470303372917734 Unigram: 4.708562935610321
2022-01-31 21:33:52 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 21:33:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:39:27 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.315 | ppl 1274.14 | wps 8430 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.326
2022-01-31 21:39:27 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 21:39:27 | INFO | train | epoch 139 | loss 5.525 | ppl 46.04 | wps 6237.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.94 | train_wall 308 | gb_free 6.1 | wall 46223
KL Stats: Epoch 139 Divergences: Uniform: 2.951840734883938 Unigram: 4.724573653060703
2022-01-31 21:39:27 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 21:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:39:46 | INFO | train_inner | epoch 140:      4 / 64 loss=5.533, ppl=46.29, wps=6105.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.946, train_wall=481, gb_free=6.1, wall=46242
2022-01-31 21:44:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:45:02 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.317 | ppl 1275.93 | wps 8484 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.326
2022-01-31 21:45:02 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 21:45:02 | INFO | train | epoch 140 | loss 5.518 | ppl 45.83 | wps 6237.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.956 | train_wall 308 | gb_free 6.1 | wall 46557
KL Stats: Epoch 140 Divergences: Uniform: 2.951970174690379 Unigram: 4.729392544407343
2022-01-31 21:45:02 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 21:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:48:15 | INFO | train_inner | epoch 141:     40 / 64 loss=5.509, ppl=45.54, wps=6418.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.949, train_wall=482, gb_free=6.1, wall=46751
2022-01-31 21:50:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:50:36 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.319 | ppl 1277.59 | wps 8521.3 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.326
2022-01-31 21:50:36 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 21:50:36 | INFO | train | epoch 141 | loss 5.508 | ppl 45.5 | wps 6245.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.936 | train_wall 308 | gb_free 6.1 | wall 46892
KL Stats: Epoch 141 Divergences: Uniform: 2.9578667965350127 Unigram: 4.747178242992836
2022-01-31 21:50:36 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 21:50:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:55:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:56:11 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.308 | ppl 1267.72 | wps 8523.7 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.326
2022-01-31 21:56:11 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 21:56:11 | INFO | train | epoch 142 | loss 5.499 | ppl 45.22 | wps 6238.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.949 | train_wall 308 | gb_free 6.1 | wall 47227
KL Stats: Epoch 142 Divergences: Uniform: 2.9559981076917383 Unigram: 4.753810440652697
2022-01-31 21:56:11 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 21:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:57:09 | INFO | train_inner | epoch 143:     12 / 64 loss=5.501, ppl=45.28, wps=6107, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.945, train_wall=481, gb_free=6.1, wall=47285
2022-01-31 22:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:01:46 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.365 | ppl 1318.93 | wps 8488.9 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.326
2022-01-31 22:01:46 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 22:01:46 | INFO | train | epoch 143 | loss 5.494 | ppl 45.06 | wps 6230.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.967 | train_wall 309 | gb_free 6.1 | wall 47562
KL Stats: Epoch 143 Divergences: Uniform: 2.9670587138393114 Unigram: 4.763425698769235
2022-01-31 22:01:46 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 22:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:05:39 | INFO | train_inner | epoch 144:     48 / 64 loss=5.489, ppl=44.92, wps=6412.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.967, train_wall=483, gb_free=6.1, wall=47795
2022-01-31 22:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:07:21 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.39 | ppl 1342.29 | wps 8479 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.326
2022-01-31 22:07:21 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 22:07:21 | INFO | train | epoch 144 | loss 5.485 | ppl 44.8 | wps 6238.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.965 | train_wall 308 | gb_free 6.1 | wall 47897
KL Stats: Epoch 144 Divergences: Uniform: 2.9577879231609985 Unigram: 4.7651672522015325
2022-01-31 22:07:21 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 22:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:12:55 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.422 | ppl 1371.71 | wps 8484.8 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.326
2022-01-31 22:12:55 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 22:12:55 | INFO | train | epoch 145 | loss 5.476 | ppl 44.51 | wps 6249.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.951 | train_wall 308 | gb_free 6.1 | wall 48231
KL Stats: Epoch 145 Divergences: Uniform: 2.967391096111726 Unigram: 4.781376787889179
2022-01-31 22:12:55 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 22:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:14:32 | INFO | train_inner | epoch 146:     20 / 64 loss=5.473, ppl=44.43, wps=6115.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.961, train_wall=480, gb_free=6.1, wall=48328
2022-01-31 22:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:18:29 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.347 | ppl 1302.37 | wps 8492.2 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.326
2022-01-31 22:18:29 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 22:18:29 | INFO | train | epoch 146 | loss 5.468 | ppl 44.26 | wps 6250.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.988 | train_wall 308 | gb_free 6.1 | wall 48565
KL Stats: Epoch 146 Divergences: Uniform: 2.963370392600854 Unigram: 4.788961304699745
2022-01-31 22:18:29 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 22:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:23:01 | INFO | train_inner | epoch 147:     56 / 64 loss=5.47, ppl=44.31, wps=6424, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.992, train_wall=482, gb_free=6.1, wall=48836
2022-01-31 22:23:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:24:04 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.319 | ppl 1277.7 | wps 8497.1 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.326
2022-01-31 22:24:04 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 22:24:04 | INFO | train | epoch 147 | loss 5.461 | ppl 44.03 | wps 6242.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.998 | train_wall 308 | gb_free 6.1 | wall 48900
KL Stats: Epoch 147 Divergences: Uniform: 2.968024547503252 Unigram: 4.795234353395235
2022-01-31 22:24:04 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 22:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:29:39 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.344 | ppl 1300.1 | wps 8489.4 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.326
2022-01-31 22:29:39 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 22:29:39 | INFO | train | epoch 148 | loss 5.451 | ppl 43.74 | wps 6235.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.981 | train_wall 308 | gb_free 6.1 | wall 49235
KL Stats: Epoch 148 Divergences: Uniform: 2.970875453483355 Unigram: 4.814836934678458
2022-01-31 22:29:39 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 22:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:31:55 | INFO | train_inner | epoch 149:     28 / 64 loss=5.447, ppl=43.62, wps=6104.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.99, train_wall=481, gb_free=6.1, wall=49370
2022-01-31 22:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:35:14 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.364 | ppl 1317.92 | wps 8479.5 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.326
2022-01-31 22:35:14 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 22:35:14 | INFO | train | epoch 149 | loss 5.447 | ppl 43.63 | wps 6237.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.03 | train_wall 308 | gb_free 6.1 | wall 49569
KL Stats: Epoch 149 Divergences: Uniform: 2.9728071771089204 Unigram: 4.820278068674547
2022-01-31 22:35:14 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 22:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:40:22 | INFO | train_inner | epoch 150:     64 / 64 loss=5.449, ppl=43.67, wps=6422.2, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.017, train_wall=481, gb_free=6.1, wall=49878
2022-01-31 22:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:40:48 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.406 | ppl 1356.62 | wps 8492.1 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.326
2022-01-31 22:40:48 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 22:40:48 | INFO | train | epoch 150 | loss 5.437 | ppl 43.32 | wps 6247.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.999 | train_wall 308 | gb_free 6.1 | wall 49904
KL Stats: Epoch 150 Divergences: Uniform: 2.973089248087477 Unigram: 4.815940756613659
2022-01-31 22:40:48 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 22:40:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:45:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:46:22 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.395 | ppl 1346.83 | wps 8488.3 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.326
2022-01-31 22:46:23 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 22:46:23 | INFO | train | epoch 151 | loss 5.429 | ppl 43.07 | wps 6242 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.012 | train_wall 308 | gb_free 6.1 | wall 50238
KL Stats: Epoch 151 Divergences: Uniform: 2.9696210993696095 Unigram: 4.833747653182327
2022-01-31 22:46:23 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 22:46:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:49:17 | INFO | train_inner | epoch 152:     36 / 64 loss=5.416, ppl=42.7, wps=6111.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.018, train_wall=482, gb_free=6.1, wall=50413
2022-01-31 22:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:51:57 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.405 | ppl 1355.57 | wps 8552.8 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.326
2022-01-31 22:51:57 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 22:51:57 | INFO | train | epoch 152 | loss 5.422 | ppl 42.86 | wps 6251.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.016 | train_wall 308 | gb_free 6.1 | wall 50572
KL Stats: Epoch 152 Divergences: Uniform: 2.9755798518472494 Unigram: 4.846741600138211
2022-01-31 22:51:57 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 22:51:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:57:30 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.447 | ppl 1396.14 | wps 8493.2 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.326
2022-01-31 22:57:30 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-31 22:57:30 | INFO | train | epoch 153 | loss 5.413 | ppl 42.61 | wps 6256.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.992 | train_wall 307 | gb_free 6.1 | wall 50906
KL Stats: Epoch 153 Divergences: Uniform: 2.976073612597483 Unigram: 4.856112391695784
2022-01-31 22:57:30 | INFO | fairseq.trainer | begin training epoch 154
2022-01-31 22:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:58:09 | INFO | train_inner | epoch 154:      8 / 64 loss=5.421, ppl=42.85, wps=6123.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.998, train_wall=480, gb_free=6.1, wall=50945
2022-01-31 23:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:03:05 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.436 | ppl 1385.55 | wps 8507.5 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.326
2022-01-31 23:03:05 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-31 23:03:05 | INFO | train | epoch 154 | loss 5.408 | ppl 42.46 | wps 6245 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.035 | train_wall 308 | gb_free 6.1 | wall 51241
KL Stats: Epoch 154 Divergences: Uniform: 2.9810862469239283 Unigram: 4.857268663601933
2022-01-31 23:03:05 | INFO | fairseq.trainer | begin training epoch 155
2022-01-31 23:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:06:38 | INFO | train_inner | epoch 155:     44 / 64 loss=5.399, ppl=42.2, wps=6426.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.036, train_wall=482, gb_free=6.1, wall=51454
2022-01-31 23:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:08:39 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.385 | ppl 1336.99 | wps 8543 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.326
2022-01-31 23:08:39 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-31 23:08:39 | INFO | train | epoch 155 | loss 5.401 | ppl 42.25 | wps 6250.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.044 | train_wall 308 | gb_free 6.1 | wall 51575
KL Stats: Epoch 155 Divergences: Uniform: 2.9841395142974716 Unigram: 4.877648546174004
2022-01-31 23:08:39 | INFO | fairseq.trainer | begin training epoch 156
2022-01-31 23:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:13:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:14:13 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.458 | ppl 1406.57 | wps 8488.6 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.326
2022-01-31 23:14:13 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-31 23:14:13 | INFO | train | epoch 156 | loss 5.394 | ppl 42.05 | wps 6261.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.054 | train_wall 307 | gb_free 6.1 | wall 51908
KL Stats: Epoch 156 Divergences: Uniform: 2.9802092739702912 Unigram: 4.878030227757643
2022-01-31 23:14:13 | INFO | fairseq.trainer | begin training epoch 157
2022-01-31 23:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:15:30 | INFO | train_inner | epoch 157:     16 / 64 loss=5.399, ppl=42.21, wps=6126.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.046, train_wall=479, gb_free=6.1, wall=51986
2022-01-31 23:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:19:47 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.442 | ppl 1391.18 | wps 8486.7 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.326
2022-01-31 23:19:47 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-31 23:19:47 | INFO | train | epoch 157 | loss 5.386 | ppl 41.82 | wps 6247.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.024 | train_wall 308 | gb_free 6.1 | wall 52243
KL Stats: Epoch 157 Divergences: Uniform: 2.984939463234879 Unigram: 4.8915829757981655
2022-01-31 23:19:47 | INFO | fairseq.trainer | begin training epoch 158
2022-01-31 23:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:23:59 | INFO | train_inner | epoch 158:     52 / 64 loss=5.38, ppl=41.65, wps=6421.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.047, train_wall=482, gb_free=6.1, wall=52495
2022-01-31 23:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:25:22 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.44 | ppl 1389.46 | wps 8518.6 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.326
2022-01-31 23:25:22 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-31 23:25:22 | INFO | train | epoch 158 | loss 5.382 | ppl 41.69 | wps 6242.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.068 | train_wall 308 | gb_free 6.1 | wall 52577
KL Stats: Epoch 158 Divergences: Uniform: 2.981100016469909 Unigram: 4.895714819510672
2022-01-31 23:25:22 | INFO | fairseq.trainer | begin training epoch 159
2022-01-31 23:25:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:30:56 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.457 | ppl 1405.15 | wps 8480.9 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.326
2022-01-31 23:30:56 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-31 23:30:56 | INFO | train | epoch 159 | loss 5.373 | ppl 41.44 | wps 6240.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.075 | train_wall 308 | gb_free 6.1 | wall 52912
KL Stats: Epoch 159 Divergences: Uniform: 2.9847001847403876 Unigram: 4.912320133637599
2022-01-31 23:30:56 | INFO | fairseq.trainer | begin training epoch 160
2022-01-31 23:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:32:52 | INFO | train_inner | epoch 160:     24 / 64 loss=5.372, ppl=41.43, wps=6110.1, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.076, train_wall=481, gb_free=6.1, wall=53028
2022-01-31 23:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:36:30 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.473 | ppl 1421.17 | wps 8518.2 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.326
2022-01-31 23:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-31 23:36:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint160.pt
2022-01-31 23:36:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint160.pt
2022-01-31 23:36:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.473) (writing took 3.596086015983019 seconds)
2022-01-31 23:36:34 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-31 23:36:34 | INFO | train | epoch 160 | loss 5.367 | ppl 41.26 | wps 6190.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.041 | train_wall 307 | gb_free 6.1 | wall 53249
KL Stats: Epoch 160 Divergences: Uniform: 2.9856770664016987 Unigram: 4.922376669516735
2022-01-31 23:36:34 | INFO | fairseq.trainer | begin training epoch 161
2022-01-31 23:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:41:24 | INFO | train_inner | epoch 161:     60 / 64 loss=5.368, ppl=41.3, wps=6382.5, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.051, train_wall=481, gb_free=6.1, wall=53540
2022-01-31 23:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:42:08 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.374 | ppl 1327.43 | wps 8509.3 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.326
2022-01-31 23:42:08 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-31 23:42:08 | INFO | train | epoch 161 | loss 5.361 | ppl 41.09 | wps 6238.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.066 | train_wall 308 | gb_free 6.1 | wall 53584
KL Stats: Epoch 161 Divergences: Uniform: 2.988834571372759 Unigram: 4.92429793933948
2022-01-31 23:42:08 | INFO | fairseq.trainer | begin training epoch 162
2022-01-31 23:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:47:43 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.457 | ppl 1405.7 | wps 8493.1 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.326
2022-01-31 23:47:43 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-31 23:47:43 | INFO | train | epoch 162 | loss 5.352 | ppl 40.86 | wps 6241.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.046 | train_wall 308 | gb_free 6.1 | wall 53919
KL Stats: Epoch 162 Divergences: Uniform: 2.9962826371986604 Unigram: 4.934040904521307
2022-01-31 23:47:43 | INFO | fairseq.trainer | begin training epoch 163
2022-01-31 23:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:50:18 | INFO | train_inner | epoch 163:     32 / 64 loss=5.34, ppl=40.5, wps=6107.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.057, train_wall=481, gb_free=6.1, wall=54074
2022-01-31 23:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:53:18 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.522 | ppl 1470.1 | wps 8532.7 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.326
2022-01-31 23:53:18 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-31 23:53:18 | INFO | train | epoch 163 | loss 5.35 | ppl 40.78 | wps 6242.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.093 | train_wall 308 | gb_free 6.1 | wall 54253
KL Stats: Epoch 163 Divergences: Uniform: 2.9887244471750205 Unigram: 4.947805474506079
2022-01-31 23:53:18 | INFO | fairseq.trainer | begin training epoch 164
2022-01-31 23:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:58:52 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.417 | ppl 1367.5 | wps 8504.3 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.326
2022-01-31 23:58:52 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-31 23:58:52 | INFO | train | epoch 164 | loss 5.341 | ppl 40.54 | wps 6240 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.1 | train_wall 308 | gb_free 6.1 | wall 54588
KL Stats: Epoch 164 Divergences: Uniform: 2.9881662757355425 Unigram: 4.949558263771067
2022-01-31 23:58:52 | INFO | fairseq.trainer | begin training epoch 165
2022-01-31 23:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:59:12 | INFO | train_inner | epoch 165:      4 / 64 loss=5.356, ppl=40.97, wps=6109.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.1, train_wall=481, gb_free=6.1, wall=54608
2022-02-01 00:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:04:26 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.468 | ppl 1416.63 | wps 8565.6 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.326
2022-02-01 00:04:26 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 00:04:26 | INFO | train | epoch 165 | loss 5.333 | ppl 40.31 | wps 6265.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.079 | train_wall 307 | gb_free 6.1 | wall 54922
KL Stats: Epoch 165 Divergences: Uniform: 2.994881500628489 Unigram: 4.9666141733507345
2022-02-01 00:04:26 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 00:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:07:39 | INFO | train_inner | epoch 166:     40 / 64 loss=5.327, ppl=40.14, wps=6442.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.102, train_wall=480, gb_free=6.1, wall=55115
2022-02-01 00:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:10:00 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.363 | ppl 1317.33 | wps 8506.3 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.326
2022-02-01 00:10:00 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 00:10:00 | INFO | train | epoch 166 | loss 5.33 | ppl 40.23 | wps 6255.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.122 | train_wall 307 | gb_free 6.1 | wall 55255
KL Stats: Epoch 166 Divergences: Uniform: 2.9992728981504 Unigram: 4.971394016326823
2022-02-01 00:10:00 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 00:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:15:34 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.359 | ppl 1313.38 | wps 8556.3 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.326
2022-02-01 00:15:34 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 00:15:34 | INFO | train | epoch 167 | loss 5.323 | ppl 40.03 | wps 6249 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.121 | train_wall 308 | gb_free 6.1 | wall 55590
KL Stats: Epoch 167 Divergences: Uniform: 2.9950113051000087 Unigram: 4.9742442550947015
2022-02-01 00:15:34 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 00:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:16:32 | INFO | train_inner | epoch 168:     12 / 64 loss=5.325, ppl=40.09, wps=6118.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.117, train_wall=480, gb_free=6.1, wall=55648
2022-02-01 00:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:21:08 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.485 | ppl 1432.75 | wps 8520 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.326
2022-02-01 00:21:08 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 00:21:08 | INFO | train | epoch 168 | loss 5.318 | ppl 39.89 | wps 6242.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.128 | train_wall 308 | gb_free 6.1 | wall 55924
KL Stats: Epoch 168 Divergences: Uniform: 3.000312554799235 Unigram: 4.978208199639454
2022-02-01 00:21:08 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 00:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:25:01 | INFO | train_inner | epoch 169:     48 / 64 loss=5.317, ppl=39.86, wps=6421.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.124, train_wall=482, gb_free=6.1, wall=56157
2022-02-01 00:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:26:43 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.442 | ppl 1390.67 | wps 8488.5 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.326
2022-02-01 00:26:43 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 00:26:43 | INFO | train | epoch 169 | loss 5.312 | ppl 39.71 | wps 6243.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.118 | train_wall 308 | gb_free 6.1 | wall 56259
KL Stats: Epoch 169 Divergences: Uniform: 2.9983674913737386 Unigram: 4.990433999394714
2022-02-01 00:26:43 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 00:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:32:17 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.483 | ppl 1431.53 | wps 8515.8 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.326
2022-02-01 00:32:17 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 00:32:17 | INFO | train | epoch 170 | loss 5.306 | ppl 39.55 | wps 6247.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.128 | train_wall 308 | gb_free 6.1 | wall 56593
KL Stats: Epoch 170 Divergences: Uniform: 3.0005937742223963 Unigram: 4.998865152537638
2022-02-01 00:32:17 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 00:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:33:54 | INFO | train_inner | epoch 171:     20 / 64 loss=5.3, ppl=39.4, wps=6112.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.137, train_wall=481, gb_free=6.1, wall=56690
2022-02-01 00:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:37:52 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.471 | ppl 1419.8 | wps 8493.5 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.326
2022-02-01 00:37:52 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 00:37:52 | INFO | train | epoch 171 | loss 5.3 | ppl 39.4 | wps 6245.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.181 | train_wall 308 | gb_free 6.1 | wall 56927
KL Stats: Epoch 171 Divergences: Uniform: 3.000937250419241 Unigram: 5.008228403168469
2022-02-01 00:37:52 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 00:37:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:42:23 | INFO | train_inner | epoch 172:     56 / 64 loss=5.303, ppl=39.48, wps=6419.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.167, train_wall=482, gb_free=6.1, wall=57199
2022-02-01 00:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:43:26 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.458 | ppl 1406.26 | wps 8495 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.326
2022-02-01 00:43:26 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 00:43:26 | INFO | train | epoch 172 | loss 5.294 | ppl 39.23 | wps 6237.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.164 | train_wall 308 | gb_free 6.1 | wall 57262
KL Stats: Epoch 172 Divergences: Uniform: 3.0039760474887784 Unigram: 5.011681364315963
2022-02-01 00:43:26 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 00:43:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:49:01 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.395 | ppl 1346.09 | wps 8481 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.326
2022-02-01 00:49:01 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 00:49:01 | INFO | train | epoch 173 | loss 5.287 | ppl 39.05 | wps 6247.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.175 | train_wall 308 | gb_free 6.1 | wall 57597
KL Stats: Epoch 173 Divergences: Uniform: 3.00334954737982 Unigram: 5.0166818895606635
2022-02-01 00:49:01 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 00:49:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:51:16 | INFO | train_inner | epoch 174:     28 / 64 loss=5.281, ppl=38.88, wps=6114.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.163, train_wall=480, gb_free=6.1, wall=57732
2022-02-01 00:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:54:35 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.473 | ppl 1421.64 | wps 8480.2 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.326
2022-02-01 00:54:35 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 00:54:35 | INFO | train | epoch 174 | loss 5.283 | ppl 38.93 | wps 6243.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.165 | train_wall 308 | gb_free 6.1 | wall 57931
KL Stats: Epoch 174 Divergences: Uniform: 3.0051567015836254 Unigram: 5.029634433378922
2022-02-01 00:54:35 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 00:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:59:44 | INFO | train_inner | epoch 175:     64 / 64 loss=5.287, ppl=39.03, wps=6421.5, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.177, train_wall=481, gb_free=6.1, wall=58240
2022-02-01 00:59:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:00:10 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.534 | ppl 1482.38 | wps 8496.7 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.326
2022-02-01 01:00:10 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 01:00:10 | INFO | train | epoch 175 | loss 5.275 | ppl 38.73 | wps 6244.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.165 | train_wall 308 | gb_free 6.1 | wall 58266
KL Stats: Epoch 175 Divergences: Uniform: 3.015325232606118 Unigram: 5.039678662076189
2022-02-01 01:00:10 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 01:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:05:44 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.52 | ppl 1468.83 | wps 8551.1 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.326
2022-02-01 01:05:44 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 01:05:44 | INFO | train | epoch 176 | loss 5.271 | ppl 38.62 | wps 6254.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.18 | train_wall 308 | gb_free 6.1 | wall 58600
KL Stats: Epoch 176 Divergences: Uniform: 3.0099425586763084 Unigram: 5.046631055147024
2022-02-01 01:05:44 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 01:05:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:08:38 | INFO | train_inner | epoch 177:     36 / 64 loss=5.258, ppl=38.27, wps=6123, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.187, train_wall=481, gb_free=6.1, wall=58774
2022-02-01 01:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:11:18 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.424 | ppl 1373.76 | wps 8500.3 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.326
2022-02-01 01:11:18 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 01:11:18 | INFO | train | epoch 177 | loss 5.265 | ppl 38.45 | wps 6251.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.217 | train_wall 307 | gb_free 6.1 | wall 58934
KL Stats: Epoch 177 Divergences: Uniform: 3.0112642756156056 Unigram: 5.050980110777996
2022-02-01 01:11:18 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 01:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:16:52 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.498 | ppl 1446.53 | wps 8488.7 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.326
2022-02-01 01:16:52 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 01:16:52 | INFO | train | epoch 178 | loss 5.262 | ppl 38.38 | wps 6245.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.203 | train_wall 308 | gb_free 6.1 | wall 59268
KL Stats: Epoch 178 Divergences: Uniform: 3.0118346679914385 Unigram: 5.055410763553868
2022-02-01 01:16:52 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 01:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:17:31 | INFO | train_inner | epoch 179:      8 / 64 loss=5.269, ppl=38.57, wps=6112.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.21, train_wall=480, gb_free=6.1, wall=59307
2022-02-01 01:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:22:26 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.44 | ppl 1388.73 | wps 8580.4 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.326
2022-02-01 01:22:26 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 01:22:26 | INFO | train | epoch 179 | loss 5.255 | ppl 38.19 | wps 6260 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.198 | train_wall 307 | gb_free 6.1 | wall 59602
KL Stats: Epoch 179 Divergences: Uniform: 3.0139144278609695 Unigram: 5.063057981593525
2022-02-01 01:22:26 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 01:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:25:59 | INFO | train_inner | epoch 180:     44 / 64 loss=5.25, ppl=38.06, wps=6433.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.203, train_wall=481, gb_free=6.1, wall=59815
2022-02-01 01:27:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:28:00 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.422 | ppl 1372.27 | wps 8484.2 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.326
2022-02-01 01:28:00 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 01:28:00 | INFO | train | epoch 180 | loss 5.251 | ppl 38.09 | wps 6241.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.222 | train_wall 308 | gb_free 6.1 | wall 59936
KL Stats: Epoch 180 Divergences: Uniform: 3.015776991050507 Unigram: 5.070970856979377
2022-02-01 01:28:00 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 01:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:33:35 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.488 | ppl 1436.01 | wps 8567.8 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.326
2022-02-01 01:33:35 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 01:33:35 | INFO | train | epoch 181 | loss 5.243 | ppl 37.87 | wps 6251.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 308 | gb_free 6.1 | wall 60270
KL Stats: Epoch 181 Divergences: Uniform: 3.0187921644685747 Unigram: 5.081654839657489
2022-02-01 01:33:35 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 01:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:34:52 | INFO | train_inner | epoch 182:     16 / 64 loss=5.244, ppl=37.91, wps=6121.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.23, train_wall=480, gb_free=6.1, wall=60347
2022-02-01 01:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:39:07 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.41 | ppl 1360.67 | wps 8552.7 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.326
2022-02-01 01:39:07 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 01:39:07 | INFO | train | epoch 182 | loss 5.241 | ppl 37.82 | wps 6275.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.241 | train_wall 306 | gb_free 6.1 | wall 60603
KL Stats: Epoch 182 Divergences: Uniform: 3.019154154032112 Unigram: 5.0797379849701
2022-02-01 01:39:07 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 01:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:43:18 | INFO | train_inner | epoch 183:     52 / 64 loss=5.239, ppl=37.77, wps=6450.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.262, train_wall=480, gb_free=6.1, wall=60854
2022-02-01 01:44:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:44:40 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.437 | ppl 1386.39 | wps 8551.7 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.326
2022-02-01 01:44:40 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 01:44:40 | INFO | train | epoch 183 | loss 5.236 | ppl 37.68 | wps 6278.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.274 | train_wall 306 | gb_free 6.1 | wall 60936
KL Stats: Epoch 183 Divergences: Uniform: 3.019949897151495 Unigram: 5.095525725492096
2022-02-01 01:44:40 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 01:44:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:50:12 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.43 | ppl 1379.62 | wps 8557.4 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.326
2022-02-01 01:50:12 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 01:50:12 | INFO | train | epoch 184 | loss 5.231 | ppl 37.55 | wps 6284.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.235 | train_wall 306 | gb_free 6.1 | wall 61268
KL Stats: Epoch 184 Divergences: Uniform: 3.0190379417477002 Unigram: 5.096809579381083
2022-02-01 01:50:12 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 01:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:52:08 | INFO | train_inner | epoch 185:     24 / 64 loss=5.231, ppl=37.54, wps=6152.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.241, train_wall=477, gb_free=6.1, wall=61384
2022-02-01 01:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:55:45 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.48 | ppl 1427.78 | wps 8584.6 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.326
2022-02-01 01:55:45 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 01:55:45 | INFO | train | epoch 185 | loss 5.226 | ppl 37.44 | wps 6283 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.283 | train_wall 306 | gb_free 6.1 | wall 61601
KL Stats: Epoch 185 Divergences: Uniform: 3.016914206825253 Unigram: 5.106786464195065
2022-02-01 01:55:45 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 01:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:00:34 | INFO | train_inner | epoch 186:     60 / 64 loss=5.227, ppl=37.46, wps=6461.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.292, train_wall=479, gb_free=6.1, wall=61890
2022-02-01 02:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:01:17 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.411 | ppl 1361.39 | wps 8558.7 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.326
2022-02-01 02:01:17 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 02:01:17 | INFO | train | epoch 186 | loss 5.223 | ppl 37.34 | wps 6280.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.29 | train_wall 306 | gb_free 6.1 | wall 61933
KL Stats: Epoch 186 Divergences: Uniform: 3.017672078005219 Unigram: 5.110796530723995
2022-02-01 02:01:17 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 02:01:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:06:49 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.482 | ppl 1430.5 | wps 8603.2 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.326
2022-02-01 02:06:49 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 02:06:49 | INFO | train | epoch 187 | loss 5.217 | ppl 37.2 | wps 6295.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.263 | train_wall 305 | gb_free 6.1 | wall 62265
KL Stats: Epoch 187 Divergences: Uniform: 3.020967771358295 Unigram: 5.118241081542562
2022-02-01 02:06:49 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 02:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:09:23 | INFO | train_inner | epoch 188:     32 / 64 loss=5.21, ppl=37.01, wps=6155.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.272, train_wall=477, gb_free=6.1, wall=62419
2022-02-01 02:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:12:22 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.476 | ppl 1424.66 | wps 8562 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.326
2022-02-01 02:12:22 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 02:12:22 | INFO | train | epoch 188 | loss 5.209 | ppl 37 | wps 6277.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.279 | train_wall 306 | gb_free 6.1 | wall 62598
KL Stats: Epoch 188 Divergences: Uniform: 3.019819845583933 Unigram: 5.126205599260394
2022-02-01 02:12:22 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 02:12:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:17:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:17:54 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.441 | ppl 1390.09 | wps 8603.1 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.326
2022-02-01 02:17:54 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 02:17:54 | INFO | train | epoch 189 | loss 5.207 | ppl 36.95 | wps 6287.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.335 | train_wall 306 | gb_free 6.1 | wall 62930
KL Stats: Epoch 189 Divergences: Uniform: 3.0199039292451917 Unigram: 5.1277280512038095
2022-02-01 02:17:54 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 02:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:18:13 | INFO | train_inner | epoch 190:      4 / 64 loss=5.213, ppl=37.08, wps=6151.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.313, train_wall=478, gb_free=6.1, wall=62949
2022-02-01 02:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:23:26 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.454 | ppl 1403.15 | wps 8536.8 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.326
2022-02-01 02:23:26 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 02:23:26 | INFO | train | epoch 190 | loss 5.201 | ppl 36.78 | wps 6286.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.3 | train_wall 306 | gb_free 6.1 | wall 63262
KL Stats: Epoch 190 Divergences: Uniform: 3.0226450112466012 Unigram: 5.1327704773761935
2022-02-01 02:23:26 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 02:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:26:39 | INFO | train_inner | epoch 191:     40 / 64 loss=5.19, ppl=36.5, wps=6459.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.293, train_wall=479, gb_free=6.1, wall=63455
2022-02-01 02:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:28:59 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.454 | ppl 1402.27 | wps 8619.7 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.326
2022-02-01 02:28:59 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 02:28:59 | INFO | train | epoch 191 | loss 5.196 | ppl 36.66 | wps 6282.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.277 | train_wall 306 | gb_free 6.1 | wall 63595
KL Stats: Epoch 191 Divergences: Uniform: 3.023339571446987 Unigram: 5.142581513866657
2022-02-01 02:28:59 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 02:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:34:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:34:31 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.476 | ppl 1424.34 | wps 8590 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.326
2022-02-01 02:34:31 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 02:34:31 | INFO | train | epoch 192 | loss 5.193 | ppl 36.58 | wps 6293.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.338 | train_wall 306 | gb_free 6.1 | wall 63926
KL Stats: Epoch 192 Divergences: Uniform: 3.0228202068906227 Unigram: 5.143725730237356
2022-02-01 02:34:31 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 02:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:35:29 | INFO | train_inner | epoch 193:     12 / 64 loss=5.199, ppl=36.74, wps=6158.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.328, train_wall=477, gb_free=6.1, wall=63984
2022-02-01 02:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:40:03 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.466 | ppl 1414.78 | wps 8596.2 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.326
2022-02-01 02:40:03 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 02:40:03 | INFO | train | epoch 193 | loss 5.19 | ppl 36.5 | wps 6278.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.343 | train_wall 306 | gb_free 6.1 | wall 64259
KL Stats: Epoch 193 Divergences: Uniform: 3.026802161403407 Unigram: 5.153601186729461
2022-02-01 02:40:03 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 02:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:43:55 | INFO | train_inner | epoch 194:     48 / 64 loss=5.186, ppl=36.39, wps=6458.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.348, train_wall=479, gb_free=6.1, wall=64490
2022-02-01 02:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:45:36 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.435 | ppl 1384.71 | wps 8576.3 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.326
2022-02-01 02:45:36 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 02:45:36 | INFO | train | epoch 194 | loss 5.184 | ppl 36.36 | wps 6277 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.369 | train_wall 306 | gb_free 6.1 | wall 64592
KL Stats: Epoch 194 Divergences: Uniform: 3.0267364787251165 Unigram: 5.155686279005651
2022-02-01 02:45:36 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 02:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:51:09 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.464 | ppl 1412.64 | wps 8548.4 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.326
2022-02-01 02:51:09 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 02:51:09 | INFO | train | epoch 195 | loss 5.18 | ppl 36.25 | wps 6278.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.361 | train_wall 306 | gb_free 6.1 | wall 64925
KL Stats: Epoch 195 Divergences: Uniform: 3.0246999717742877 Unigram: 5.161739679955399
2022-02-01 02:51:09 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 02:51:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:52:45 | INFO | train_inner | epoch 196:     20 / 64 loss=5.178, ppl=36.2, wps=6146.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.356, train_wall=478, gb_free=6.1, wall=65021
2022-02-01 02:56:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:56:41 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.431 | ppl 1380.96 | wps 8576.2 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.326
2022-02-01 02:56:41 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 02:56:41 | INFO | train | epoch 196 | loss 5.176 | ppl 36.15 | wps 6282.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.352 | train_wall 306 | gb_free 6.1 | wall 65257
KL Stats: Epoch 196 Divergences: Uniform: 3.0263476945324257 Unigram: 5.169377428131848
2022-02-01 02:56:41 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 02:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:01:11 | INFO | train_inner | epoch 197:     56 / 64 loss=5.176, ppl=36.16, wps=6462.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.379, train_wall=479, gb_free=6.1, wall=65526
2022-02-01 03:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:02:13 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.515 | ppl 1462.97 | wps 8554.1 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.326
2022-02-01 03:02:13 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 03:02:13 | INFO | train | epoch 197 | loss 5.171 | ppl 36.04 | wps 6285.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.395 | train_wall 306 | gb_free 6.1 | wall 65589
KL Stats: Epoch 197 Divergences: Uniform: 3.0288804799675466 Unigram: 5.171969335448514
2022-02-01 03:02:13 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 03:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:07:46 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.461 | ppl 1409.24 | wps 8548.7 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.326
2022-02-01 03:07:46 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 03:07:46 | INFO | train | epoch 198 | loss 5.167 | ppl 35.94 | wps 6276.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.414 | train_wall 306 | gb_free 6.1 | wall 65922
KL Stats: Epoch 198 Divergences: Uniform: 3.030845318695624 Unigram: 5.185619835106468
2022-02-01 03:07:46 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 03:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:10:01 | INFO | train_inner | epoch 199:     28 / 64 loss=5.162, ppl=35.79, wps=6144.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.397, train_wall=478, gb_free=6.1, wall=66057
2022-02-01 03:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:13:19 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.437 | ppl 1386.43 | wps 8560.7 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.326
2022-02-01 03:13:19 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 03:13:19 | INFO | train | epoch 199 | loss 5.16 | ppl 35.76 | wps 6280.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.355 | train_wall 306 | gb_free 6.1 | wall 66255
KL Stats: Epoch 199 Divergences: Uniform: 3.0302740565628885 Unigram: 5.193646351813847
2022-02-01 03:13:19 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 03:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:18:26 | INFO | train_inner | epoch 200:     64 / 64 loss=5.17, ppl=35.99, wps=6453.5, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.39, train_wall=478, gb_free=6.1, wall=66562
2022-02-01 03:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:18:52 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.491 | ppl 1438.71 | wps 8533.4 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.326
2022-02-01 03:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 03:18:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint200.pt
2022-02-01 03:18:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint200.pt
2022-02-01 03:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.491) (writing took 3.47824878297979 seconds)
2022-02-01 03:18:55 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 03:18:55 | INFO | train | epoch 200 | loss 5.158 | ppl 35.7 | wps 6203.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.404 | train_wall 307 | gb_free 6.1 | wall 66591
KL Stats: Epoch 200 Divergences: Uniform: 3.0285782648942443 Unigram: 5.1993120202370555
2022-02-01 03:18:55 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 03:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:24:28 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.494 | ppl 1441.79 | wps 8592.3 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.326
2022-02-01 03:24:28 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-01 03:24:28 | INFO | train | epoch 201 | loss 5.155 | ppl 35.63 | wps 6288.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.418 | train_wall 306 | gb_free 6.1 | wall 66923
KL Stats: Epoch 201 Divergences: Uniform: 3.027663156396804 Unigram: 5.1950693989773615
2022-02-01 03:24:28 | INFO | fairseq.trainer | begin training epoch 202
2022-02-01 03:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:27:21 | INFO | train_inner | epoch 202:     36 / 64 loss=5.14, ppl=35.27, wps=6112, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.419, train_wall=479, gb_free=6.1, wall=67097
2022-02-01 03:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:30:00 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.484 | ppl 1432.59 | wps 8541.4 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.326
2022-02-01 03:30:00 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-01 03:30:00 | INFO | train | epoch 202 | loss 5.148 | ppl 35.46 | wps 6279.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.405 | train_wall 306 | gb_free 6.1 | wall 67256
KL Stats: Epoch 202 Divergences: Uniform: 3.028541582190509 Unigram: 5.210616738014204
2022-02-01 03:30:00 | INFO | fairseq.trainer | begin training epoch 203
2022-02-01 03:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:35:33 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.443 | ppl 1391.83 | wps 8603.5 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.326
2022-02-01 03:35:33 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-01 03:35:33 | INFO | train | epoch 203 | loss 5.145 | ppl 35.37 | wps 6284.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.455 | train_wall 306 | gb_free 6.1 | wall 67588
KL Stats: Epoch 203 Divergences: Uniform: 3.0285699207730894 Unigram: 5.2168153046609245
2022-02-01 03:35:33 | INFO | fairseq.trainer | begin training epoch 204
2022-02-01 03:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:36:11 | INFO | train_inner | epoch 204:      8 / 64 loss=5.153, ppl=35.58, wps=6148.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.431, train_wall=478, gb_free=6.1, wall=67627
2022-02-01 03:40:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:41:05 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.483 | ppl 1431.1 | wps 8552.5 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.326
2022-02-01 03:41:05 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-01 03:41:05 | INFO | train | epoch 204 | loss 5.139 | ppl 35.25 | wps 6280.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.438 | train_wall 306 | gb_free 6.1 | wall 67921
KL Stats: Epoch 204 Divergences: Uniform: 3.035448135083059 Unigram: 5.221081664283911
2022-02-01 03:41:05 | INFO | fairseq.trainer | begin training epoch 205
2022-02-01 03:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:44:37 | INFO | train_inner | epoch 205:     44 / 64 loss=5.135, ppl=35.13, wps=6458.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.448, train_wall=479, gb_free=6.1, wall=68133
2022-02-01 03:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:46:38 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.495 | ppl 1443.33 | wps 8573.9 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.326
2022-02-01 03:46:38 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-01 03:46:38 | INFO | train | epoch 205 | loss 5.135 | ppl 35.14 | wps 6279 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.457 | train_wall 306 | gb_free 6.1 | wall 68254
KL Stats: Epoch 205 Divergences: Uniform: 3.0338626720616406 Unigram: 5.231691087027735
2022-02-01 03:46:38 | INFO | fairseq.trainer | begin training epoch 206
2022-02-01 03:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:52:11 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.496 | ppl 1444.49 | wps 8548.4 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.326
2022-02-01 03:52:11 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-01 03:52:11 | INFO | train | epoch 206 | loss 5.132 | ppl 35.06 | wps 6265.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.43 | train_wall 307 | gb_free 6.1 | wall 68587
KL Stats: Epoch 206 Divergences: Uniform: 3.031974173840871 Unigram: 5.23500968824743
2022-02-01 03:52:11 | INFO | fairseq.trainer | begin training epoch 207
2022-02-01 03:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:53:28 | INFO | train_inner | epoch 207:     16 / 64 loss=5.133, ppl=35.1, wps=6137.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.439, train_wall=479, gb_free=6.1, wall=68664
2022-02-01 03:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:57:44 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.515 | ppl 1463.37 | wps 8569 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.326
2022-02-01 03:57:44 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-01 03:57:44 | INFO | train | epoch 207 | loss 5.129 | ppl 35 | wps 6282.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.482 | train_wall 306 | gb_free 6.1 | wall 68919
KL Stats: Epoch 207 Divergences: Uniform: 3.033549174593652 Unigram: 5.23813205520894
2022-02-01 03:57:44 | INFO | fairseq.trainer | begin training epoch 208
2022-02-01 03:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:01:54 | INFO | train_inner | epoch 208:     52 / 64 loss=5.127, ppl=34.93, wps=6460.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.486, train_wall=479, gb_free=6.1, wall=69170
2022-02-01 04:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:03:16 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.511 | ppl 1458.84 | wps 8567.7 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.326
2022-02-01 04:03:16 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-01 04:03:16 | INFO | train | epoch 208 | loss 5.124 | ppl 34.87 | wps 6277.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.482 | train_wall 306 | gb_free 6.1 | wall 69252
KL Stats: Epoch 208 Divergences: Uniform: 3.0362536561155764 Unigram: 5.249248391620011
2022-02-01 04:03:16 | INFO | fairseq.trainer | begin training epoch 209
2022-02-01 04:03:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:08:49 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 10.495 | ppl 1443.54 | wps 8562 | wpb 2034.1 | bsz 4 | num_updates 13376 | best_loss 9.326
2022-02-01 04:08:49 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-02-01 04:08:49 | INFO | train | epoch 209 | loss 5.119 | ppl 34.76 | wps 6269.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13376 | lr 0.000273424 | gnorm 1.491 | train_wall 307 | gb_free 6.1 | wall 69585
KL Stats: Epoch 209 Divergences: Uniform: 3.035468333993972 Unigram: 5.2492926471031245
2022-02-01 04:08:49 | INFO | fairseq.trainer | begin training epoch 210
2022-02-01 04:08:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:10:45 | INFO | train_inner | epoch 210:     24 / 64 loss=5.117, ppl=34.7, wps=6139.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13400, lr=0.000273179, gnorm=1.494, train_wall=479, gb_free=6.1, wall=69701
2022-02-01 04:13:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:14:22 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 10.547 | ppl 1495.83 | wps 8563.7 | wpb 2034.1 | bsz 4 | num_updates 13440 | best_loss 9.326
2022-02-01 04:14:22 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-02-01 04:14:22 | INFO | train | epoch 210 | loss 5.117 | ppl 34.7 | wps 6275.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13440 | lr 0.000272772 | gnorm 1.531 | train_wall 306 | gb_free 6.1 | wall 69918
KL Stats: Epoch 210 Divergences: Uniform: 3.042463621350325 Unigram: 5.256209846290016
2022-02-01 04:14:22 | INFO | fairseq.trainer | begin training epoch 211
2022-02-01 04:14:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:19:11 | INFO | train_inner | epoch 211:     60 / 64 loss=5.118, ppl=34.74, wps=6465.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13500, lr=0.000272166, gnorm=1.521, train_wall=479, gb_free=6.1, wall=70206
2022-02-01 04:19:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:19:54 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 10.489 | ppl 1436.86 | wps 8565.5 | wpb 2034.1 | bsz 4 | num_updates 13504 | best_loss 9.326
2022-02-01 04:19:54 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-02-01 04:19:54 | INFO | train | epoch 211 | loss 5.112 | ppl 34.58 | wps 6293.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13504 | lr 0.000272125 | gnorm 1.501 | train_wall 305 | gb_free 6.1 | wall 70250
KL Stats: Epoch 211 Divergences: Uniform: 3.04352493207824 Unigram: 5.264611503255669
2022-02-01 04:19:54 | INFO | fairseq.trainer | begin training epoch 212
2022-02-01 04:19:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:25:27 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 10.503 | ppl 1451.35 | wps 8568.1 | wpb 2034.1 | bsz 4 | num_updates 13568 | best_loss 9.326
2022-02-01 04:25:27 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-02-01 04:25:27 | INFO | train | epoch 212 | loss 5.11 | ppl 34.53 | wps 6276 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13568 | lr 0.000271483 | gnorm 1.526 | train_wall 306 | gb_free 6.1 | wall 70583
KL Stats: Epoch 212 Divergences: Uniform: 3.041294749768321 Unigram: 5.267391502195816
2022-02-01 04:25:27 | INFO | fairseq.trainer | begin training epoch 213
2022-02-01 04:25:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:28:01 | INFO | train_inner | epoch 213:     32 / 64 loss=5.102, ppl=34.35, wps=6144.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13600, lr=0.000271163, gnorm=1.52, train_wall=478, gb_free=6.1, wall=70737
2022-02-01 04:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:31:00 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 10.51 | ppl 1458.03 | wps 8578 | wpb 2034.1 | bsz 4 | num_updates 13632 | best_loss 9.326
2022-02-01 04:31:00 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-02-01 04:31:00 | INFO | train | epoch 213 | loss 5.105 | ppl 34.42 | wps 6274.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13632 | lr 0.000270845 | gnorm 1.538 | train_wall 307 | gb_free 6.1 | wall 70916
KL Stats: Epoch 213 Divergences: Uniform: 3.040444335353359 Unigram: 5.27402073174014
2022-02-01 04:31:00 | INFO | fairseq.trainer | begin training epoch 214
2022-02-01 04:31:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:36:33 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 10.471 | ppl 1419.61 | wps 8540.2 | wpb 2034.1 | bsz 4 | num_updates 13696 | best_loss 9.326
2022-02-01 04:36:33 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-02-01 04:36:33 | INFO | train | epoch 214 | loss 5.103 | ppl 34.36 | wps 6272.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13696 | lr 0.000270211 | gnorm 1.551 | train_wall 307 | gb_free 6.1 | wall 71249
KL Stats: Epoch 214 Divergences: Uniform: 3.042019022553432 Unigram: 5.276922058117321
2022-02-01 04:36:33 | INFO | fairseq.trainer | begin training epoch 215
2022-02-01 04:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:36:52 | INFO | train_inner | epoch 215:      4 / 64 loss=5.11, ppl=34.53, wps=6140.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=13700, lr=0.000270172, gnorm=1.56, train_wall=478, gb_free=6.1, wall=71268
2022-02-01 04:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:42:06 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 10.465 | ppl 1413.03 | wps 8526.9 | wpb 2034.1 | bsz 4 | num_updates 13760 | best_loss 9.326
2022-02-01 04:42:06 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-02-01 04:42:06 | INFO | train | epoch 215 | loss 5.099 | ppl 34.27 | wps 6271.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13760 | lr 0.000269582 | gnorm 1.606 | train_wall 307 | gb_free 6.1 | wall 71582
KL Stats: Epoch 215 Divergences: Uniform: 3.039561941313627 Unigram: 5.286744911195541
2022-02-01 04:42:06 | INFO | fairseq.trainer | begin training epoch 216
2022-02-01 04:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:45:19 | INFO | train_inner | epoch 216:     40 / 64 loss=5.092, ppl=34.1, wps=6451, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13800, lr=0.000269191, gnorm=1.589, train_wall=480, gb_free=6.1, wall=71774
2022-02-01 04:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:47:39 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 10.526 | ppl 1474.35 | wps 8549.5 | wpb 2034.1 | bsz 4 | num_updates 13824 | best_loss 9.326
2022-02-01 04:47:39 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-02-01 04:47:39 | INFO | train | epoch 216 | loss 5.095 | ppl 34.17 | wps 6274.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13824 | lr 0.000268957 | gnorm 1.565 | train_wall 306 | gb_free 6.1 | wall 71914
KL Stats: Epoch 216 Divergences: Uniform: 3.0451570725472727 Unigram: 5.288855496798946
2022-02-01 04:47:39 | INFO | fairseq.trainer | begin training epoch 217
2022-02-01 04:47:39 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g2-12>
Subject: Job 202993121: <w2_jelinek_0.11_-0.01_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#1> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:04:52 2022
Job was executed on host(s) <eu-g2-12>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:05:03 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:05:03 2022
Terminated at Wed Feb  2 06:05:36 2022
Results reported at Wed Feb  2 06:05:36 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 102
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   23.32 sec.
    Max Memory :                                 3693 MB
    Average Memory :                             2512.00 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16307.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   32 sec.
    Turnaround time :                            44 sec.

The output (if any) follows:

2022-02-02 06:05:11 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 102, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 102, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:05:11 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:05:12 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1431/36718 [00:00<00:02, 14296.86it/s]  8%|▊         | 2861/36718 [00:00<00:02, 13840.91it/s] 12%|█▏        | 4474/36718 [00:00<00:02, 14863.06it/s] 17%|█▋        | 6130/36718 [00:00<00:01, 15524.56it/s] 21%|██        | 7685/36718 [00:00<00:01, 14741.10it/s] 25%|██▍       | 9167/36718 [00:00<00:01, 14503.80it/s] 29%|██▉       | 10623/36718 [00:00<00:01, 14433.38it/s] 33%|███▎      | 12127/36718 [00:00<00:01, 14620.09it/s] 37%|███▋      | 13621/36718 [00:00<00:01, 14712.95it/s] 41%|████      | 15115/36718 [00:01<00:01, 14777.52it/s] 45%|████▌     | 16595/36718 [00:01<00:01, 14293.49it/s] 49%|████▉     | 18073/36718 [00:01<00:01, 14435.86it/s] 54%|█████▎    | 19684/36718 [00:01<00:01, 14927.68it/s] 58%|█████▊    | 21181/36718 [00:01<00:01, 14671.75it/s] 62%|██████▏   | 22652/36718 [00:01<00:00, 14582.90it/s] 66%|██████▌   | 24307/36718 [00:01<00:00, 15155.75it/s] 71%|███████   | 25903/36718 [00:01<00:00, 15390.97it/s] 75%|███████▍  | 27445/36718 [00:01<00:00, 14548.37it/s] 79%|███████▉  | 29000/36718 [00:01<00:00, 14834.19it/s] 83%|████████▎ | 30493/36718 [00:02<00:00, 14661.78it/s] 87%|████████▋ | 31966/36718 [00:02<00:00, 14170.09it/s] 91%|█████████ | 33390/36718 [00:02<00:00, 13948.63it/s] 95%|█████████▌| 34934/36718 [00:02<00:00, 14375.49it/s] 99%|█████████▉| 36377/36718 [00:02<00:00, 14356.83it/s]100%|██████████| 36718/36718 [00:02<00:00, 14585.29it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2829/36718 [00:00<00:01, 28285.37it/s] 17%|█▋        | 6080/36718 [00:00<00:00, 30756.50it/s] 25%|██▍       | 9156/36718 [00:00<00:00, 29360.77it/s] 33%|███▎      | 12100/36718 [00:00<00:00, 29356.94it/s] 41%|████      | 15066/36718 [00:00<00:00, 29463.62it/s] 49%|████▉     | 18016/36718 [00:00<00:00, 29158.92it/s] 57%|█████▋    | 21019/36718 [00:00<00:00, 29437.23it/s] 66%|██████▌   | 24116/36718 [00:00<00:00, 29916.19it/s] 74%|███████▍  | 27110/36718 [00:00<00:00, 29739.99it/s] 82%|████████▏ | 30086/36718 [00:01<00:00, 29715.83it/s] 90%|█████████ | 33059/36718 [00:01<00:00, 28762.63it/s] 98%|█████████▊| 35992/36718 [00:01<00:00, 28926.16it/s]100%|██████████| 36718/36718 [00:01<00:00, 29329.91it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 83.05it/s]2022-02-02 06:05:25 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:05:25 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:05:25 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:05:25 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:05:25 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:05:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:05:25 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:05:25 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:05:25 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:05:25 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:05:25 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:05:25 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:05:25 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:05:25 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:05:25 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:05:25 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:05:25 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:05:25 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:05:25 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:05:25 | INFO | fairseq_cli.train | Start iterating over samples

/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 543, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 327, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 97, in forward
    loss, _ = self.compute_loss(model, net_output, sample, reduce=reduce)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/jelinek_mercer.py", line 132, in compute_loss
    coeffs[i, kl_stuff["idx"]] += self.alphas[j+1]*kl_stuff["val"]
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g2-08>
Subject: Job 202993220: <w2_jelinek_0.11_-0.01_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.11_-0.01_0.9_#1> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:05:43 2022
Job was executed on host(s) <eu-g2-08>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:06:03 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:06:03 2022
Terminated at Thu Feb  3 02:06:06 2022
Results reported at Thu Feb  3 02:06:06 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.11, -0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 102 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72734.00 sec.
    Max Memory :                                 6065 MB
    Average Memory :                             3678.66 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13935.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72002 sec.
    Turnaround time :                            72023 sec.

The output (if any) follows:

2022-02-02 06:06:12 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 102, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 102, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.11, -0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:06:12 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:06:13 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1432/36718 [00:00<00:02, 14317.15it/s]  8%|▊         | 2864/36718 [00:00<00:02, 13737.94it/s] 12%|█▏        | 4456/36718 [00:00<00:02, 14709.91it/s] 17%|█▋        | 6081/36718 [00:00<00:02, 15299.16it/s] 21%|██        | 7614/36718 [00:00<00:02, 14440.15it/s] 25%|██▍       | 9067/36718 [00:00<00:01, 14388.99it/s] 29%|██▊       | 10512/36718 [00:00<00:01, 14144.08it/s] 33%|███▎      | 11951/36718 [00:00<00:01, 14219.13it/s] 36%|███▋      | 13376/36718 [00:00<00:01, 14166.10it/s] 40%|████      | 14862/36718 [00:01<00:01, 14371.26it/s] 44%|████▍     | 16301/36718 [00:01<00:01, 14142.47it/s] 48%|████▊     | 17717/36718 [00:01<00:01, 14066.79it/s] 52%|█████▏    | 19239/36718 [00:01<00:01, 14404.49it/s] 56%|█████▋    | 20697/36718 [00:01<00:01, 14452.00it/s] 60%|██████    | 22144/36718 [00:01<00:01, 14063.54it/s] 65%|██████▍   | 23739/36718 [00:01<00:00, 14611.67it/s] 69%|██████▉   | 25430/36718 [00:01<00:00, 15285.76it/s] 73%|███████▎  | 26963/36718 [00:01<00:00, 14480.12it/s] 77%|███████▋  | 28422/36718 [00:01<00:00, 14271.99it/s] 81%|████████▏ | 29870/36718 [00:02<00:00, 14328.63it/s] 85%|████████▌ | 31309/36718 [00:02<00:00, 13846.57it/s] 89%|████████▉ | 32700/36718 [00:02<00:00, 13777.70it/s] 93%|█████████▎| 34082/36718 [00:02<00:00, 13765.93it/s] 97%|█████████▋| 35512/36718 [00:02<00:00, 13918.90it/s]100%|██████████| 36718/36718 [00:02<00:00, 14243.34it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2747/36718 [00:00<00:01, 27463.54it/s] 16%|█▌        | 5888/36718 [00:00<00:01, 29782.15it/s] 24%|██▍       | 8867/36718 [00:00<00:00, 28230.01it/s] 32%|███▏      | 11700/36718 [00:00<00:00, 27914.40it/s] 40%|███▉      | 14541/36718 [00:00<00:00, 28081.89it/s] 47%|████▋     | 17353/36718 [00:00<00:00, 28045.05it/s] 55%|█████▌    | 20244/36718 [00:00<00:00, 28319.13it/s] 63%|██████▎   | 23078/36718 [00:00<00:00, 28284.95it/s] 71%|███████▏  | 26176/36718 [00:00<00:00, 29117.37it/s] 79%|███████▉  | 29090/36718 [00:01<00:00, 28656.84it/s] 87%|████████▋ | 31959/36718 [00:01<00:00, 27870.58it/s] 95%|█████████▍| 34752/36718 [00:01<00:00, 27660.29it/s]100%|██████████| 36718/36718 [00:01<00:00, 28095.78it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 70.91it/s]2022-02-02 06:06:26 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:06:26 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:06:26 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:06:26 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:06:26 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:06:26 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:06:26 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:06:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:06:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:27 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-02-02 06:06:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:06:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:06:27 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:06:27 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:06:27 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:06:27 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:06:27 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:06:27 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:06:27 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:06:27 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:11:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:12:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.742 | ppl 27396.6 | wps 8014.1 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:12:18 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:12:18 | INFO | train | epoch 001 | loss 16.152 | ppl 72815.9 | wps 5970.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.087 | train_wall 322 | gb_free 6.1 | wall 351
KL Stats: Epoch 1 Divergences: Uniform: 0.5178068682081796 Unigram: 3.7124222229704875
2022-02-02 06:12:18 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:15:20 | INFO | train_inner | epoch 002:     36 / 64 loss=15.627, ppl=50612.5, wps=6140.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.559, train_wall=504, gb_free=6.1, wall=533
2022-02-02 06:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:18:08 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.728 | ppl 13571 | wps 8003.1 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:18:08 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:18:08 | INFO | train | epoch 002 | loss 14.481 | ppl 22859.8 | wps 5956.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.51 | train_wall 322 | gb_free 6.1 | wall 702
KL Stats: Epoch 2 Divergences: Uniform: 0.5280335161403397 Unigram: 2.4475084197716983
2022-02-02 06:18:08 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:23:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:23:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.918 | ppl 7739.96 | wps 8014.6 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:23:58 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:23:58 | INFO | train | epoch 003 | loss 13.578 | ppl 12227.9 | wps 5979.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.231 | train_wall 321 | gb_free 6.1 | wall 1051
KL Stats: Epoch 3 Divergences: Uniform: 0.5098794719086083 Unigram: 1.7560658537436737
2022-02-02 06:23:58 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:24:38 | INFO | train_inner | epoch 004:      8 / 64 loss=13.709, ppl=13387, wps=5840.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.259, train_wall=502, gb_free=6.1, wall=1092
2022-02-02 06:29:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:29:48 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.101 | ppl 4393.9 | wps 8015.2 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:29:48 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:29:48 | INFO | train | epoch 004 | loss 12.625 | ppl 6316.09 | wps 5956.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.977 | train_wall 322 | gb_free 6.1 | wall 1402
KL Stats: Epoch 4 Divergences: Uniform: 0.5919228680547587 Unigram: 1.1287860457123622
2022-02-02 06:29:48 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:33:31 | INFO | train_inner | epoch 005:     44 / 64 loss=12.28, ppl=4973.17, wps=6137.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.864, train_wall=504, gb_free=6.1, wall=1624
2022-02-02 06:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:35:38 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.6 | ppl 3105.03 | wps 7995.3 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:35:38 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:35:38 | INFO | train | epoch 005 | loss 11.839 | ppl 3662.71 | wps 5969.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.71 | train_wall 322 | gb_free 6.1 | wall 1751
KL Stats: Epoch 5 Divergences: Uniform: 0.8237834782056475 Unigram: 0.6608473059340577
2022-02-02 06:35:38 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:35:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:41:28 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.351 | ppl 2613 | wps 7986.9 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:41:28 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:41:28 | INFO | train | epoch 006 | loss 11.418 | ppl 2736.17 | wps 5962.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.62 | train_wall 322 | gb_free 6.1 | wall 2102
KL Stats: Epoch 6 Divergences: Uniform: 1.110926794677748 Unigram: 0.4540687710827211
2022-02-02 06:41:28 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:41:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:42:49 | INFO | train_inner | epoch 007:     16 / 64 loss=11.44, ppl=2778.29, wps=5836.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.629, train_wall=502, gb_free=6.1, wall=2183
2022-02-02 06:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:47:19 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.222 | ppl 2388.08 | wps 8026.9 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:47:19 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:47:19 | INFO | train | epoch 007 | loss 11.219 | ppl 2383.79 | wps 5948.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.566 | train_wall 323 | gb_free 6.1 | wall 2453
KL Stats: Epoch 7 Divergences: Uniform: 1.336198620779272 Unigram: 0.4775448572461043
2022-02-02 06:47:19 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:51:44 | INFO | train_inner | epoch 008:     52 / 64 loss=11.153, ppl=2276.91, wps=6115.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.512, train_wall=506, gb_free=6.1, wall=2717
2022-02-02 06:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:53:11 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.09 | ppl 2180.45 | wps 8010 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:53:11 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:53:11 | INFO | train | epoch 008 | loss 11.1 | ppl 2195.19 | wps 5948.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.503 | train_wall 323 | gb_free 6.1 | wall 2804
KL Stats: Epoch 8 Divergences: Uniform: 1.4429540234145406 Unigram: 0.5630744201206812
2022-02-02 06:53:11 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:58:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:59:00 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.978 | ppl 2016.96 | wps 7993.3 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 06:59:00 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 06:59:00 | INFO | train | epoch 009 | loss 10.992 | ppl 2037.05 | wps 5976.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.507 | train_wall 321 | gb_free 6.1 | wall 3153
KL Stats: Epoch 9 Divergences: Uniform: 1.4865526627605352 Unigram: 0.6767232000589688
2022-02-02 06:59:00 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 06:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:01:02 | INFO | train_inner | epoch 010:     24 / 64 loss=10.981, ppl=2020.65, wps=5840.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.509, train_wall=502, gb_free=6.1, wall=3275
2022-02-02 07:04:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:04:51 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.867 | ppl 1867.11 | wps 7988.2 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:04:51 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:04:51 | INFO | train | epoch 010 | loss 10.879 | ppl 1882.91 | wps 5957.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.515 | train_wall 322 | gb_free 6.1 | wall 3504
KL Stats: Epoch 10 Divergences: Uniform: 1.506006403335507 Unigram: 0.8010219408044591
2022-02-02 07:04:51 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:04:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:09:55 | INFO | train_inner | epoch 011:     60 / 64 loss=10.805, ppl=1788.69, wps=6134, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.512, train_wall=504, gb_free=6.1, wall=3808
2022-02-02 07:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:10:41 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.754 | ppl 1727.45 | wps 7979.3 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:10:41 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:10:41 | INFO | train | epoch 011 | loss 10.761 | ppl 1735.08 | wps 5963.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.5 | train_wall 322 | gb_free 6.1 | wall 3854
KL Stats: Epoch 11 Divergences: Uniform: 1.5263415373964306 Unigram: 0.9269163026526087
2022-02-02 07:10:41 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:10:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:16:32 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.631 | ppl 1585.63 | wps 8007.5 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:16:32 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:16:32 | INFO | train | epoch 012 | loss 10.643 | ppl 1599.17 | wps 5955.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.478 | train_wall 323 | gb_free 6.1 | wall 4205
KL Stats: Epoch 12 Divergences: Uniform: 1.5387071592777082 Unigram: 1.0448211225678112
2022-02-02 07:16:32 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:19:13 | INFO | train_inner | epoch 013:     32 / 64 loss=10.612, ppl=1565.1, wps=5834.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.474, train_wall=503, gb_free=6.1, wall=4367
2022-02-02 07:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:22:21 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.545 | ppl 1494.54 | wps 7978 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:22:21 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:22:21 | INFO | train | epoch 013 | loss 10.528 | ppl 1476.74 | wps 5973.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.488 | train_wall 321 | gb_free 6.1 | wall 4555
KL Stats: Epoch 13 Divergences: Uniform: 1.557273564156669 Unigram: 1.15194807796546
2022-02-02 07:22:21 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:27:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:28:12 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.452 | ppl 1400.44 | wps 8015.5 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:28:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:28:12 | INFO | train | epoch 014 | loss 10.414 | ppl 1364.45 | wps 5950.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.516 | train_wall 323 | gb_free 6.1 | wall 4906
KL Stats: Epoch 14 Divergences: Uniform: 1.576205424451849 Unigram: 1.2481798429357915
2022-02-02 07:28:12 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:28:32 | INFO | train_inner | epoch 015:      4 / 64 loss=10.443, ppl=1392.51, wps=5829.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.511, train_wall=503, gb_free=6.1, wall=4926
2022-02-02 07:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:34:02 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.362 | ppl 1316.01 | wps 8004.4 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:34:02 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:34:02 | INFO | train | epoch 015 | loss 10.299 | ppl 1260.24 | wps 5968.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.489 | train_wall 322 | gb_free 6.1 | wall 5256
KL Stats: Epoch 15 Divergences: Uniform: 1.6001897057162038 Unigram: 1.340383476010969
2022-02-02 07:34:02 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:37:25 | INFO | train_inner | epoch 016:     40 / 64 loss=10.262, ppl=1228.11, wps=6131.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.495, train_wall=504, gb_free=6.1, wall=5459
2022-02-02 07:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:39:53 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.266 | ppl 1231.47 | wps 7983.6 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:39:53 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:39:53 | INFO | train | epoch 016 | loss 10.19 | ppl 1167.84 | wps 5947.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.526 | train_wall 323 | gb_free 6.1 | wall 5607
KL Stats: Epoch 16 Divergences: Uniform: 1.635067009364982 Unigram: 1.4236523116687854
2022-02-02 07:39:53 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:45:43 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.177 | ppl 1157.28 | wps 8005.4 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:45:43 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:45:43 | INFO | train | epoch 017 | loss 10.08 | ppl 1082.26 | wps 5965.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.549 | train_wall 322 | gb_free 6.1 | wall 5957
KL Stats: Epoch 17 Divergences: Uniform: 1.6667323398209126 Unigram: 1.50333592746716
2022-02-02 07:45:43 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:46:45 | INFO | train_inner | epoch 018:     12 / 64 loss=10.09, ppl=1089.82, wps=5831.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.55, train_wall=503, gb_free=6.1, wall=6018
2022-02-02 07:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:51:34 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.113 | ppl 1107.73 | wps 8029.6 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:51:34 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:51:34 | INFO | train | epoch 018 | loss 9.972 | ppl 1004.14 | wps 5952.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.558 | train_wall 323 | gb_free 6.1 | wall 6308
KL Stats: Epoch 18 Divergences: Uniform: 1.69644000595853 Unigram: 1.5798963406220363
2022-02-02 07:51:34 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:55:37 | INFO | train_inner | epoch 019:     48 / 64 loss=9.921, ppl=969.1, wps=6136.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.556, train_wall=504, gb_free=6.1, wall=6550
2022-02-02 07:56:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:57:24 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.031 | ppl 1046.18 | wps 7994.5 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 07:57:24 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 07:57:24 | INFO | train | epoch 019 | loss 9.87 | ppl 935.88 | wps 5974.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.544 | train_wall 321 | gb_free 6.1 | wall 6657
KL Stats: Epoch 19 Divergences: Uniform: 1.7297815317796486 Unigram: 1.6560917623403917
2022-02-02 07:57:24 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 07:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:03:15 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.979 | ppl 1009.3 | wps 8023.8 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:03:15 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:03:15 | INFO | train | epoch 020 | loss 9.777 | ppl 877.22 | wps 5952.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.586 | train_wall 323 | gb_free 6.1 | wall 7008
KL Stats: Epoch 20 Divergences: Uniform: 1.757850705915909 Unigram: 1.7276898998712573
2022-02-02 08:03:15 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:03:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:04:56 | INFO | train_inner | epoch 021:     20 / 64 loss=9.77, ppl=873.39, wps=5832.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.57, train_wall=503, gb_free=6.1, wall=7109
2022-02-02 08:08:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:09:05 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.911 | ppl 962.72 | wps 7956.9 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:09:05 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:09:05 | INFO | train | epoch 021 | loss 9.684 | ppl 822.71 | wps 5968.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.53 | train_wall 322 | gb_free 6.1 | wall 7358
KL Stats: Epoch 21 Divergences: Uniform: 1.7827582231797592 Unigram: 1.7935859680810717
2022-02-02 08:09:05 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:13:49 | INFO | train_inner | epoch 022:     56 / 64 loss=9.636, ppl=795.48, wps=6134.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.556, train_wall=504, gb_free=6.1, wall=7642
2022-02-02 08:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:14:55 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.858 | ppl 928.28 | wps 7996.2 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:14:55 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:14:55 | INFO | train | epoch 022 | loss 9.598 | ppl 775.06 | wps 5959.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.576 | train_wall 322 | gb_free 6.1 | wall 7709
KL Stats: Epoch 22 Divergences: Uniform: 1.8095535395995173 Unigram: 1.8530264363202105
2022-02-02 08:14:55 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:20:45 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.806 | ppl 895.24 | wps 8013.5 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:20:45 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:20:45 | INFO | train | epoch 023 | loss 9.511 | ppl 729.48 | wps 5972.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.562 | train_wall 322 | gb_free 6.1 | wall 8058
KL Stats: Epoch 23 Divergences: Uniform: 1.8395805280577908 Unigram: 1.910964637769893
2022-02-02 08:20:45 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:23:07 | INFO | train_inner | epoch 024:     28 / 64 loss=9.495, ppl=721.78, wps=5839.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.557, train_wall=502, gb_free=6.1, wall=8200
2022-02-02 08:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:26:36 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.756 | ppl 864.58 | wps 7994.4 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:26:36 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:26:36 | INFO | train | epoch 024 | loss 9.428 | ppl 688.9 | wps 5950 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.553 | train_wall 323 | gb_free 6.1 | wall 8409
KL Stats: Epoch 24 Divergences: Uniform: 1.862487272532633 Unigram: 1.9687695695832206
2022-02-02 08:26:36 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:31:58 | INFO | train_inner | epoch 025:     64 / 64 loss=9.376, ppl=664.36, wps=6134.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.562, train_wall=503, gb_free=6.1, wall=8732
2022-02-02 08:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:32:26 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.715 | ppl 840.67 | wps 8024.6 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:32:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:32:26 | INFO | train | epoch 025 | loss 9.348 | ppl 651.72 | wps 5971.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.562 | train_wall 322 | gb_free 6.1 | wall 8759
KL Stats: Epoch 25 Divergences: Uniform: 1.8876693924955934 Unigram: 2.019245311730288
2022-02-02 08:32:26 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:32:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:38:17 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.688 | ppl 824.98 | wps 7995.4 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:38:17 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:38:17 | INFO | train | epoch 026 | loss 9.267 | ppl 616.09 | wps 5938.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.521 | train_wall 324 | gb_free 6.1 | wall 9111
KL Stats: Epoch 26 Divergences: Uniform: 1.9146365582863596 Unigram: 2.0730285105893627
2022-02-02 08:38:17 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:41:20 | INFO | train_inner | epoch 027:     36 / 64 loss=9.232, ppl=601.53, wps=5824.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.522, train_wall=505, gb_free=6.1, wall=9293
2022-02-02 08:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:44:07 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.646 | ppl 801.34 | wps 7994.5 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:44:07 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:44:07 | INFO | train | epoch 027 | loss 9.189 | ppl 583.52 | wps 5970.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.536 | train_wall 322 | gb_free 6.1 | wall 9461
KL Stats: Epoch 27 Divergences: Uniform: 1.9324420931283177 Unigram: 2.122291069056159
2022-02-02 08:44:07 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:49:58 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.599 | ppl 775.26 | wps 8007 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:49:58 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:49:58 | INFO | train | epoch 028 | loss 9.112 | ppl 553.28 | wps 5948.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.539 | train_wall 323 | gb_free 6.1 | wall 9812
KL Stats: Epoch 28 Divergences: Uniform: 1.947790915099346 Unigram: 2.16203503591772
2022-02-02 08:49:58 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:50:39 | INFO | train_inner | epoch 029:      8 / 64 loss=9.133, ppl=561.39, wps=5828.1, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.543, train_wall=503, gb_free=6.1, wall=9852
2022-02-02 08:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:55:48 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.564 | ppl 757.18 | wps 7982.5 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:55:48 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:55:48 | INFO | train | epoch 029 | loss 9.034 | ppl 524.03 | wps 5974 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.545 | train_wall 321 | gb_free 6.1 | wall 10161
KL Stats: Epoch 29 Divergences: Uniform: 1.9726564010090157 Unigram: 2.203746710361188
2022-02-02 08:55:48 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:59:32 | INFO | train_inner | epoch 030:     44 / 64 loss=8.999, ppl=511.82, wps=6134.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.534, train_wall=504, gb_free=6.1, wall=10385
2022-02-02 09:01:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:01:39 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.534 | ppl 741.52 | wps 8011.4 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 09:01:39 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 09:01:39 | INFO | train | epoch 030 | loss 8.954 | ppl 496.04 | wps 5954.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.514 | train_wall 323 | gb_free 6.1 | wall 10512
KL Stats: Epoch 30 Divergences: Uniform: 1.9950879815944396 Unigram: 2.2528944562606372
2022-02-02 09:01:39 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 09:01:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:07:29 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.514 | ppl 731.09 | wps 7987.8 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:07:29 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:07:29 | INFO | train | epoch 031 | loss 8.881 | ppl 471.59 | wps 5969.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.542 | train_wall 322 | gb_free 6.1 | wall 10862
KL Stats: Epoch 31 Divergences: Uniform: 2.018989543622724 Unigram: 2.2951172202415484
2022-02-02 09:07:29 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:08:50 | INFO | train_inner | epoch 032:     16 / 64 loss=8.882, ppl=471.84, wps=5839.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.527, train_wall=502, gb_free=6.1, wall=10943
2022-02-02 09:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:13:20 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.476 | ppl 712.33 | wps 7993 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:13:20 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:13:20 | INFO | train | epoch 032 | loss 8.805 | ppl 447.21 | wps 5951.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.514 | train_wall 323 | gb_free 6.1 | wall 11213
KL Stats: Epoch 32 Divergences: Uniform: 2.0440429344846045 Unigram: 2.3381443323159927
2022-02-02 09:13:20 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:17:43 | INFO | train_inner | epoch 033:     52 / 64 loss=8.772, ppl=437.3, wps=6132.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.535, train_wall=504, gb_free=6.1, wall=11476
2022-02-02 09:18:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:19:09 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.446 | ppl 697.66 | wps 8036.2 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:19:09 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:19:09 | INFO | train | epoch 033 | loss 8.733 | ppl 425.54 | wps 5969.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.551 | train_wall 322 | gb_free 6.1 | wall 11563
KL Stats: Epoch 33 Divergences: Uniform: 2.0576187849997205 Unigram: 2.375621211618727
2022-02-02 09:19:09 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:25:00 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.422 | ppl 685.96 | wps 7987.7 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:25:00 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:25:00 | INFO | train | epoch 034 | loss 8.658 | ppl 404.05 | wps 5953.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.52 | train_wall 323 | gb_free 6.1 | wall 11914
KL Stats: Epoch 34 Divergences: Uniform: 2.075395515427503 Unigram: 2.4191632052818193
2022-02-02 09:25:00 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:27:02 | INFO | train_inner | epoch 035:     24 / 64 loss=8.639, ppl=398.77, wps=5834, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.518, train_wall=503, gb_free=6.1, wall=12035
2022-02-02 09:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:30:50 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.412 | ppl 681.41 | wps 7963.8 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:30:50 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:30:50 | INFO | train | epoch 035 | loss 8.587 | ppl 384.44 | wps 5969.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.516 | train_wall 322 | gb_free 6.1 | wall 12264
KL Stats: Epoch 35 Divergences: Uniform: 2.1011498350066393 Unigram: 2.4618265938875257
2022-02-02 09:30:50 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:30:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:35:55 | INFO | train_inner | epoch 036:     60 / 64 loss=8.55, ppl=374.78, wps=6132.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.523, train_wall=504, gb_free=6.1, wall=12568
2022-02-02 09:36:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:36:41 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.381 | ppl 666.82 | wps 8007 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:36:41 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:36:41 | INFO | train | epoch 036 | loss 8.517 | ppl 366.23 | wps 5955.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.52 | train_wall 323 | gb_free 6.1 | wall 12614
KL Stats: Epoch 36 Divergences: Uniform: 2.126972344627499 Unigram: 2.4992858661951303
2022-02-02 09:36:41 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:42:31 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.381 | ppl 666.55 | wps 7972.4 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:42:31 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:42:31 | INFO | train | epoch 037 | loss 8.448 | ppl 349.28 | wps 5960.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.533 | train_wall 322 | gb_free 6.1 | wall 12965
KL Stats: Epoch 37 Divergences: Uniform: 2.140388563374546 Unigram: 2.535398571955803
2022-02-02 09:42:31 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:45:14 | INFO | train_inner | epoch 038:     32 / 64 loss=8.428, ppl=344.5, wps=5828.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.533, train_wall=503, gb_free=6.1, wall=13127
2022-02-02 09:47:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:48:22 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.352 | ppl 653.34 | wps 7980.4 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:48:22 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:48:22 | INFO | train | epoch 038 | loss 8.379 | ppl 332.83 | wps 5958.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.522 | train_wall 322 | gb_free 6.1 | wall 13315
KL Stats: Epoch 38 Divergences: Uniform: 2.163985825833669 Unigram: 2.575155730994606
2022-02-02 09:48:22 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:53:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:54:12 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.343 | ppl 649.51 | wps 7981.4 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:54:12 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:54:12 | INFO | train | epoch 039 | loss 8.312 | ppl 317.78 | wps 5963.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.521 | train_wall 322 | gb_free 6.1 | wall 13665
KL Stats: Epoch 39 Divergences: Uniform: 2.1844587694312856 Unigram: 2.620133311707234
2022-02-02 09:54:12 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:54:32 | INFO | train_inner | epoch 040:      4 / 64 loss=8.331, ppl=321.95, wps=5835.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.518, train_wall=502, gb_free=6.1, wall=13686
2022-02-02 09:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:00:03 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.357 | ppl 655.78 | wps 7998.5 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 10:00:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 10:00:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint40.pt
2022-02-02 10:00:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint40.pt
2022-02-02 10:00:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.357) (writing took 5.088675353676081 seconds)
2022-02-02 10:00:08 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 10:00:08 | INFO | train | epoch 040 | loss 8.245 | ppl 303.44 | wps 5872.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.518 | train_wall 322 | gb_free 6.1 | wall 14021
KL Stats: Epoch 40 Divergences: Uniform: 2.2023868841221215 Unigram: 2.656975433237014
2022-02-02 10:00:08 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 10:00:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:03:30 | INFO | train_inner | epoch 041:     40 / 64 loss=8.217, ppl=297.58, wps=6076.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.517, train_wall=504, gb_free=6.1, wall=14224
2022-02-02 10:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:05:58 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.335 | ppl 645.79 | wps 7976.8 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.335
2022-02-02 10:05:58 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:05:58 | INFO | train | epoch 041 | loss 8.178 | ppl 289.58 | wps 5963.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.515 | train_wall 322 | gb_free 6.1 | wall 14371
KL Stats: Epoch 41 Divergences: Uniform: 2.2195538135829946 Unigram: 2.699136187857752
2022-02-02 10:05:58 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:11:48 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.345 | ppl 650.36 | wps 8037.6 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.345
2022-02-02 10:11:48 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:11:48 | INFO | train | epoch 042 | loss 8.114 | ppl 277.1 | wps 5960.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.516 | train_wall 322 | gb_free 6.1 | wall 14722
KL Stats: Epoch 42 Divergences: Uniform: 2.2473537635125957 Unigram: 2.735570406204745
2022-02-02 10:11:48 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:12:49 | INFO | train_inner | epoch 043:     12 / 64 loss=8.119, ppl=277.95, wps=5831.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.517, train_wall=503, gb_free=6.1, wall=14783
2022-02-02 10:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:17:38 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.332 | ppl 644.37 | wps 7961 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.332
2022-02-02 10:17:38 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:17:38 | INFO | train | epoch 043 | loss 8.052 | ppl 265.37 | wps 5965.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.522 | train_wall 322 | gb_free 6.1 | wall 15072
KL Stats: Epoch 43 Divergences: Uniform: 2.262597737183213 Unigram: 2.773079413284051
2022-02-02 10:17:38 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:17:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:21:42 | INFO | train_inner | epoch 044:     48 / 64 loss=8.022, ppl=259.99, wps=6136.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.521, train_wall=504, gb_free=6.1, wall=15315
2022-02-02 10:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:23:29 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.322 | ppl 640.13 | wps 7989.6 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.322
2022-02-02 10:23:29 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:23:29 | INFO | train | epoch 044 | loss 7.99 | ppl 254.17 | wps 5962.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.517 | train_wall 322 | gb_free 6.1 | wall 15422
KL Stats: Epoch 44 Divergences: Uniform: 2.2857756277110592 Unigram: 2.8117139796601154
2022-02-02 10:23:29 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:29:19 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.325 | ppl 641.37 | wps 7965 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.325
2022-02-02 10:29:19 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:29:19 | INFO | train | epoch 045 | loss 7.929 | ppl 243.73 | wps 5968.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.542 | train_wall 322 | gb_free 6.1 | wall 15772
KL Stats: Epoch 45 Divergences: Uniform: 2.2966526573729737 Unigram: 2.8439146798290893
2022-02-02 10:29:19 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:31:00 | INFO | train_inner | epoch 046:     20 / 64 loss=7.926, ppl=243.19, wps=5837.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.535, train_wall=502, gb_free=6.1, wall=15874
2022-02-02 10:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:35:09 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.317 | ppl 637.92 | wps 7994 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.317
2022-02-02 10:35:09 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:35:09 | INFO | train | epoch 046 | loss 7.87 | ppl 233.9 | wps 5954 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.523 | train_wall 323 | gb_free 6.1 | wall 16123
KL Stats: Epoch 46 Divergences: Uniform: 2.3220820014232326 Unigram: 2.886103985418598
2022-02-02 10:35:09 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:39:53 | INFO | train_inner | epoch 047:     56 / 64 loss=7.84, ppl=229.08, wps=6138.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.521, train_wall=504, gb_free=6.1, wall=16406
2022-02-02 10:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:41:00 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.318 | ppl 638.26 | wps 7936.9 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.318
2022-02-02 10:41:00 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:41:00 | INFO | train | epoch 047 | loss 7.812 | ppl 224.66 | wps 5965.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.533 | train_wall 322 | gb_free 6.1 | wall 16473
KL Stats: Epoch 47 Divergences: Uniform: 2.327715408627425 Unigram: 2.9133155585076085
2022-02-02 10:41:00 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:46:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:46:49 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.353 | ppl 653.73 | wps 8068 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.353
2022-02-02 10:46:49 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:46:49 | INFO | train | epoch 048 | loss 7.754 | ppl 215.9 | wps 5969.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.516 | train_wall 322 | gb_free 6.1 | wall 16823
KL Stats: Epoch 48 Divergences: Uniform: 2.346514834756593 Unigram: 2.9456656987646976
2022-02-02 10:46:49 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:49:11 | INFO | train_inner | epoch 049:     28 / 64 loss=7.736, ppl=213.25, wps=5843.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.529, train_wall=502, gb_free=6.1, wall=16964
2022-02-02 10:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:52:38 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.36 | ppl 656.98 | wps 8038.9 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.357
2022-02-02 10:52:38 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:52:38 | INFO | train | epoch 049 | loss 7.698 | ppl 207.6 | wps 5996.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.541 | train_wall 320 | gb_free 6.1 | wall 17171
KL Stats: Epoch 49 Divergences: Uniform: 2.3743513383920383 Unigram: 2.984018615654083
2022-02-02 10:52:38 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:57:59 | INFO | train_inner | epoch 050:     64 / 64 loss=7.671, ppl=203.76, wps=6170.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.53, train_wall=500, gb_free=6.1, wall=17492
2022-02-02 10:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:58:26 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.294 | ppl 627.72 | wps 8076.4 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.294
2022-02-02 10:58:26 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:58:26 | INFO | train | epoch 050 | loss 7.641 | ppl 199.59 | wps 5998.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.525 | train_wall 320 | gb_free 6.1 | wall 17519
KL Stats: Epoch 50 Divergences: Uniform: 2.3863412107407544 Unigram: 3.0098019115034864
2022-02-02 10:58:26 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:58:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:04:14 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.309 | ppl 634.47 | wps 8030.9 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.309
2022-02-02 11:04:14 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 11:04:14 | INFO | train | epoch 051 | loss 7.588 | ppl 192.4 | wps 6001.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.543 | train_wall 320 | gb_free 6.1 | wall 17867
KL Stats: Epoch 51 Divergences: Uniform: 2.3966112273352125 Unigram: 3.0463552124702398
2022-02-02 11:04:14 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 11:04:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:07:16 | INFO | train_inner | epoch 052:     36 / 64 loss=7.565, ppl=189.39, wps=5869.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.544, train_wall=501, gb_free=6.1, wall=18049
2022-02-02 11:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:10:03 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.319 | ppl 638.57 | wps 8065.7 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.319
2022-02-02 11:10:03 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:10:03 | INFO | train | epoch 052 | loss 7.537 | ppl 185.75 | wps 5992.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.546 | train_wall 321 | gb_free 6.1 | wall 18216
KL Stats: Epoch 52 Divergences: Uniform: 2.3986527431926565 Unigram: 3.078179535101744
2022-02-02 11:10:03 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:15:51 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.347 | ppl 651.07 | wps 7995.8 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.347
2022-02-02 11:15:51 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:15:51 | INFO | train | epoch 053 | loss 7.486 | ppl 179.31 | wps 5995.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.565 | train_wall 320 | gb_free 6.1 | wall 18564
KL Stats: Epoch 53 Divergences: Uniform: 2.4261006686722393 Unigram: 3.115033470997004
2022-02-02 11:15:51 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:15:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:16:31 | INFO | train_inner | epoch 054:      8 / 64 loss=7.497, ppl=180.66, wps=5865.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.554, train_wall=500, gb_free=6.1, wall=18605
2022-02-02 11:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:21:40 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.365 | ppl 659.37 | wps 8086.9 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.357
2022-02-02 11:21:40 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:21:40 | INFO | train | epoch 054 | loss 7.435 | ppl 173 | wps 5989.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.538 | train_wall 321 | gb_free 6.1 | wall 18913
KL Stats: Epoch 54 Divergences: Uniform: 2.4457934908056282 Unigram: 3.145402149153031
2022-02-02 11:21:40 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:25:21 | INFO | train_inner | epoch 055:     44 / 64 loss=7.41, ppl=170.05, wps=6171.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.548, train_wall=501, gb_free=6.1, wall=19134
2022-02-02 11:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:27:28 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.312 | ppl 635.76 | wps 8037.3 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.312
2022-02-02 11:27:28 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:27:28 | INFO | train | epoch 055 | loss 7.388 | ppl 167.44 | wps 6002.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.555 | train_wall 320 | gb_free 6.1 | wall 19261
KL Stats: Epoch 55 Divergences: Uniform: 2.4625274385815454 Unigram: 3.1695135982630256
2022-02-02 11:27:28 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:33:16 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.344 | ppl 650.08 | wps 8060.7 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.344
2022-02-02 11:33:16 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:33:16 | INFO | train | epoch 056 | loss 7.337 | ppl 161.66 | wps 5996 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.55 | train_wall 320 | gb_free 6.1 | wall 19609
KL Stats: Epoch 56 Divergences: Uniform: 2.4684223657812057 Unigram: 3.207153252585962
2022-02-02 11:33:16 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:33:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:34:37 | INFO | train_inner | epoch 057:     16 / 64 loss=7.338, ppl=161.77, wps=5867.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.547, train_wall=500, gb_free=6.1, wall=19690
2022-02-02 11:38:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:39:04 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.361 | ppl 657.78 | wps 8056.4 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.357
2022-02-02 11:39:04 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:39:04 | INFO | train | epoch 057 | loss 7.29 | ppl 156.53 | wps 5999.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.557 | train_wall 320 | gb_free 6.1 | wall 19958
KL Stats: Epoch 57 Divergences: Uniform: 2.4817880691023757 Unigram: 3.228907017299349
2022-02-02 11:39:04 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:43:27 | INFO | train_inner | epoch 058:     52 / 64 loss=7.272, ppl=154.56, wps=6163.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.56, train_wall=502, gb_free=6.1, wall=20220
2022-02-02 11:44:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:44:53 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.322 | ppl 640.18 | wps 8089.7 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.322
2022-02-02 11:44:53 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:44:53 | INFO | train | epoch 058 | loss 7.242 | ppl 151.43 | wps 5985.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.549 | train_wall 321 | gb_free 6.1 | wall 20306
KL Stats: Epoch 58 Divergences: Uniform: 2.4949918191167337 Unigram: 3.261783258046143
2022-02-02 11:44:53 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:44:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:50:41 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.344 | ppl 650.05 | wps 8058.7 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.344
2022-02-02 11:50:41 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:50:41 | INFO | train | epoch 059 | loss 7.199 | ppl 146.9 | wps 6003.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.565 | train_wall 320 | gb_free 6.1 | wall 20654
KL Stats: Epoch 59 Divergences: Uniform: 2.5138065077387592 Unigram: 3.291839555269657
2022-02-02 11:50:41 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:52:42 | INFO | train_inner | epoch 060:     24 / 64 loss=7.187, ppl=145.69, wps=5870.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.565, train_wall=500, gb_free=6.1, wall=20776
2022-02-02 11:56:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:56:31 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.385 | ppl 668.76 | wps 7723.3 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.357
2022-02-02 11:56:31 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:56:31 | INFO | train | epoch 060 | loss 7.155 | ppl 142.54 | wps 5963.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.571 | train_wall 321 | gb_free 6.1 | wall 21005
KL Stats: Epoch 60 Divergences: Uniform: 2.5195953722165205 Unigram: 3.315044578953526
2022-02-02 11:56:31 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:56:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:01:33 | INFO | train_inner | epoch 061:     60 / 64 loss=7.134, ppl=140.45, wps=6155.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.569, train_wall=501, gb_free=6.1, wall=21307
2022-02-02 12:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:02:19 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.399 | ppl 675.25 | wps 8069.5 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.357
2022-02-02 12:02:19 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 12:02:19 | INFO | train | epoch 061 | loss 7.112 | ppl 138.31 | wps 6004.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.572 | train_wall 320 | gb_free 6.1 | wall 21352
KL Stats: Epoch 61 Divergences: Uniform: 2.543591527689101 Unigram: 3.3471108824742193
2022-02-02 12:02:19 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 12:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:08:08 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.394 | ppl 672.72 | wps 8062.6 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.357
2022-02-02 12:08:08 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:08:08 | INFO | train | epoch 062 | loss 7.072 | ppl 134.56 | wps 5993.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.592 | train_wall 321 | gb_free 6.1 | wall 21701
KL Stats: Epoch 62 Divergences: Uniform: 2.54543422097055 Unigram: 3.3773634331098306
2022-02-02 12:08:08 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:10:49 | INFO | train_inner | epoch 063:     32 / 64 loss=7.055, ppl=133.01, wps=5868.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.58, train_wall=500, gb_free=6.1, wall=21862
2022-02-02 12:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:13:55 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.425 | ppl 687.29 | wps 8044.4 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.357
2022-02-02 12:13:55 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:13:55 | INFO | train | epoch 063 | loss 7.028 | ppl 130.51 | wps 6003.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.585 | train_wall 320 | gb_free 6.1 | wall 22049
KL Stats: Epoch 63 Divergences: Uniform: 2.562502421858678 Unigram: 3.4029579456784806
2022-02-02 12:13:55 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:19:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:19:44 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.462 | ppl 705.29 | wps 8077.1 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.357
2022-02-02 12:19:44 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:19:44 | INFO | train | epoch 064 | loss 6.983 | ppl 126.54 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.582 | train_wall 321 | gb_free 6.1 | wall 22397
KL Stats: Epoch 64 Divergences: Uniform: 2.568392816248122 Unigram: 3.4210997775984087
2022-02-02 12:19:44 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:20:04 | INFO | train_inner | epoch 065:      4 / 64 loss=7.003, ppl=128.24, wps=5866.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.592, train_wall=500, gb_free=6.1, wall=22418
2022-02-02 12:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:25:34 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.426 | ppl 687.89 | wps 8045.2 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.357
2022-02-02 12:25:34 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:25:34 | INFO | train | epoch 065 | loss 6.941 | ppl 122.88 | wps 5968.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.582 | train_wall 322 | gb_free 6.1 | wall 22747
KL Stats: Epoch 65 Divergences: Uniform: 2.5848823418047924 Unigram: 3.455895147797694
2022-02-02 12:25:34 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:25:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:28:56 | INFO | train_inner | epoch 066:     40 / 64 loss=6.916, ppl=120.72, wps=6149.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.582, train_wall=503, gb_free=6.1, wall=22949
2022-02-02 12:30:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:31:22 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.501 | ppl 724.43 | wps 8068.5 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.357
2022-02-02 12:31:22 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:31:22 | INFO | train | epoch 066 | loss 6.9 | ppl 119.46 | wps 5997.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.584 | train_wall 320 | gb_free 6.1 | wall 23096
KL Stats: Epoch 66 Divergences: Uniform: 2.596729862070909 Unigram: 3.4820285223348373
2022-02-02 12:31:22 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:36:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:37:12 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.465 | ppl 706.79 | wps 8012.5 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.357
2022-02-02 12:37:12 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:37:12 | INFO | train | epoch 067 | loss 6.86 | ppl 116.2 | wps 5964.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.598 | train_wall 322 | gb_free 6.1 | wall 23446
KL Stats: Epoch 67 Divergences: Uniform: 2.6053662608053965 Unigram: 3.5082831854720777
2022-02-02 12:37:12 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:38:13 | INFO | train_inner | epoch 068:     12 / 64 loss=6.871, ppl=117.03, wps=5846, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.592, train_wall=502, gb_free=6.1, wall=23507
2022-02-02 12:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:43:03 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.454 | ppl 701.2 | wps 8063.3 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.357
2022-02-02 12:43:03 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:43:03 | INFO | train | epoch 068 | loss 6.82 | ppl 112.98 | wps 5960.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.594 | train_wall 322 | gb_free 6.1 | wall 23796
KL Stats: Epoch 68 Divergences: Uniform: 2.6146579885080663 Unigram: 3.533259642161214
2022-02-02 12:43:03 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:47:06 | INFO | train_inner | epoch 069:     48 / 64 loss=6.799, ppl=111.38, wps=6133.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.6, train_wall=504, gb_free=6.1, wall=24040
2022-02-02 12:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:48:53 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.495 | ppl 721.44 | wps 8046.2 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.357
2022-02-02 12:48:53 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:48:53 | INFO | train | epoch 069 | loss 6.783 | ppl 110.16 | wps 5970 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.601 | train_wall 322 | gb_free 6.1 | wall 24146
KL Stats: Epoch 69 Divergences: Uniform: 2.63268705627096 Unigram: 3.5580274124331757
2022-02-02 12:48:53 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:54:43 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.497 | ppl 722.33 | wps 8075.7 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.357
2022-02-02 12:54:43 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:54:43 | INFO | train | epoch 070 | loss 6.747 | ppl 107.41 | wps 5963.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.595 | train_wall 322 | gb_free 6.1 | wall 24496
KL Stats: Epoch 70 Divergences: Uniform: 2.639187862224384 Unigram: 3.585055854973452
2022-02-02 12:54:43 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:54:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:56:24 | INFO | train_inner | epoch 071:     20 / 64 loss=6.745, ppl=107.24, wps=5845.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.596, train_wall=502, gb_free=6.1, wall=24597
2022-02-02 13:00:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:00:33 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.497 | ppl 722.64 | wps 8012 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.357
2022-02-02 13:00:33 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 13:00:33 | INFO | train | epoch 071 | loss 6.71 | ppl 104.71 | wps 5970.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.599 | train_wall 322 | gb_free 6.1 | wall 24846
KL Stats: Epoch 71 Divergences: Uniform: 2.6436451628533035 Unigram: 3.6119347486398614
2022-02-02 13:00:33 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 13:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:05:17 | INFO | train_inner | epoch 072:     56 / 64 loss=6.696, ppl=103.66, wps=6128.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.599, train_wall=505, gb_free=6.1, wall=25130
2022-02-02 13:05:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:06:23 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.607 | ppl 779.73 | wps 8071.6 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.357
2022-02-02 13:06:23 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 13:06:23 | INFO | train | epoch 072 | loss 6.674 | ppl 102.1 | wps 5958.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.598 | train_wall 323 | gb_free 6.1 | wall 25197
KL Stats: Epoch 72 Divergences: Uniform: 2.6543715557838303 Unigram: 3.636449331079543
2022-02-02 13:06:23 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 13:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:11:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:12:13 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.651 | ppl 804.03 | wps 8017.7 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.357
2022-02-02 13:12:13 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:12:13 | INFO | train | epoch 073 | loss 6.642 | ppl 99.87 | wps 5971.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.6 | train_wall 322 | gb_free 6.1 | wall 25546
KL Stats: Epoch 73 Divergences: Uniform: 2.660344660361502 Unigram: 3.6648253087620706
2022-02-02 13:12:13 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:14:35 | INFO | train_inner | epoch 074:     28 / 64 loss=6.63, ppl=99.04, wps=5840.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.607, train_wall=502, gb_free=6.1, wall=25689
2022-02-02 13:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:18:04 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.58 | ppl 765.48 | wps 8046.9 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.357
2022-02-02 13:18:04 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:18:04 | INFO | train | epoch 074 | loss 6.611 | ppl 97.75 | wps 5952.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.633 | train_wall 323 | gb_free 6.1 | wall 25897
KL Stats: Epoch 74 Divergences: Uniform: 2.671718870223071 Unigram: 3.686423099046276
2022-02-02 13:18:04 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:18:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:23:27 | INFO | train_inner | epoch 075:     64 / 64 loss=6.6, ppl=97.03, wps=6135, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.636, train_wall=503, gb_free=6.1, wall=26220
2022-02-02 13:23:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:23:54 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.593 | ppl 772.33 | wps 8017 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.357
2022-02-02 13:23:54 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:23:54 | INFO | train | epoch 075 | loss 6.58 | ppl 95.68 | wps 5967.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.63 | train_wall 322 | gb_free 6.1 | wall 26247
KL Stats: Epoch 75 Divergences: Uniform: 2.679213164067512 Unigram: 3.71056302071041
2022-02-02 13:23:54 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:29:44 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.62 | ppl 786.89 | wps 8058 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.357
2022-02-02 13:29:44 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:29:44 | INFO | train | epoch 076 | loss 6.548 | ppl 93.58 | wps 5967.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.623 | train_wall 322 | gb_free 6.1 | wall 26597
KL Stats: Epoch 76 Divergences: Uniform: 2.692957682129123 Unigram: 3.7369066383168796
2022-02-02 13:29:44 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:32:45 | INFO | train_inner | epoch 077:     36 / 64 loss=6.525, ppl=92.09, wps=5848, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.625, train_wall=503, gb_free=6.1, wall=26779
2022-02-02 13:35:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:35:33 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.605 | ppl 778.6 | wps 8013.9 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.357
2022-02-02 13:35:33 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:35:33 | INFO | train | epoch 077 | loss 6.519 | ppl 91.74 | wps 5974.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.634 | train_wall 321 | gb_free 6.1 | wall 26947
KL Stats: Epoch 77 Divergences: Uniform: 2.70122491884803 Unigram: 3.76255870468607
2022-02-02 13:35:33 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:41:24 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.625 | ppl 789.39 | wps 8059.3 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.357
2022-02-02 13:41:24 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:41:24 | INFO | train | epoch 078 | loss 6.49 | ppl 89.89 | wps 5951.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.639 | train_wall 323 | gb_free 6.1 | wall 27298
KL Stats: Epoch 78 Divergences: Uniform: 2.7072818812612844 Unigram: 3.7795112229324794
2022-02-02 13:41:24 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:41:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:42:05 | INFO | train_inner | epoch 079:      8 / 64 loss=6.506, ppl=90.87, wps=5828.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.642, train_wall=504, gb_free=6.1, wall=27338
2022-02-02 13:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:47:15 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.707 | ppl 835.55 | wps 8026.1 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.357
2022-02-02 13:47:15 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:47:15 | INFO | train | epoch 079 | loss 6.461 | ppl 88.09 | wps 5965.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.638 | train_wall 322 | gb_free 6.1 | wall 27648
KL Stats: Epoch 79 Divergences: Uniform: 2.7091187902730782 Unigram: 3.8062498915528806
2022-02-02 13:47:15 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:50:58 | INFO | train_inner | epoch 080:     44 / 64 loss=6.444, ppl=87.03, wps=6125.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.638, train_wall=505, gb_free=6.1, wall=27872
2022-02-02 13:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:53:05 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.631 | ppl 793.16 | wps 8038.2 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.357
2022-02-02 13:53:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:53:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint80.pt
2022-02-02 13:53:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint80.pt
2022-02-02 13:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.631) (writing took 3.45969882234931 seconds)
2022-02-02 13:53:08 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:53:08 | INFO | train | epoch 080 | loss 6.434 | ppl 86.48 | wps 5904.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.646 | train_wall 322 | gb_free 6.1 | wall 28002
KL Stats: Epoch 80 Divergences: Uniform: 2.720326249037538 Unigram: 3.8350769623723817
2022-02-02 13:53:08 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:58:58 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.763 | ppl 868.89 | wps 8011.9 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.357
2022-02-02 13:58:58 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:58:58 | INFO | train | epoch 081 | loss 6.407 | ppl 84.86 | wps 5970.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.655 | train_wall 322 | gb_free 6.1 | wall 28351
KL Stats: Epoch 81 Divergences: Uniform: 2.72427802037198 Unigram: 3.847033216643217
2022-02-02 13:58:58 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:00:19 | INFO | train_inner | epoch 082:     16 / 64 loss=6.409, ppl=84.97, wps=5810.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.655, train_wall=502, gb_free=6.1, wall=28433
2022-02-02 14:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:04:49 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.657 | ppl 807.48 | wps 8035.4 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.357
2022-02-02 14:04:49 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 14:04:49 | INFO | train | epoch 082 | loss 6.381 | ppl 83.35 | wps 5959.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.657 | train_wall 322 | gb_free 6.1 | wall 28702
KL Stats: Epoch 82 Divergences: Uniform: 2.733896749261957 Unigram: 3.87294043703075
2022-02-02 14:04:49 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 14:04:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:09:12 | INFO | train_inner | epoch 083:     52 / 64 loss=6.37, ppl=82.7, wps=6137.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.661, train_wall=504, gb_free=6.1, wall=28965
2022-02-02 14:10:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:10:38 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.678 | ppl 818.91 | wps 7967.9 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.357
2022-02-02 14:10:38 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:10:38 | INFO | train | epoch 083 | loss 6.355 | ppl 81.86 | wps 5968.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.662 | train_wall 322 | gb_free 6.1 | wall 29052
KL Stats: Epoch 83 Divergences: Uniform: 2.7485025668747416 Unigram: 3.892400681046555
2022-02-02 14:10:38 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:10:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:16:29 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.701 | ppl 832.12 | wps 8028 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.357
2022-02-02 14:16:29 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:16:29 | INFO | train | epoch 084 | loss 6.332 | ppl 80.54 | wps 5957.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.689 | train_wall 323 | gb_free 6.1 | wall 29402
KL Stats: Epoch 84 Divergences: Uniform: 2.744235516546887 Unigram: 3.908562977685433
2022-02-02 14:16:29 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:18:31 | INFO | train_inner | epoch 085:     24 / 64 loss=6.319, ppl=79.83, wps=5827.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.681, train_wall=503, gb_free=6.1, wall=29525
2022-02-02 14:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:22:19 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.713 | ppl 839.03 | wps 7969.4 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.357
2022-02-02 14:22:19 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:22:19 | INFO | train | epoch 085 | loss 6.306 | ppl 79.11 | wps 5966.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.67 | train_wall 322 | gb_free 6.1 | wall 29752
KL Stats: Epoch 85 Divergences: Uniform: 2.7569996983646234 Unigram: 3.930171969939061
2022-02-02 14:22:19 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:27:23 | INFO | train_inner | epoch 086:     60 / 64 loss=6.302, ppl=78.89, wps=6141.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.668, train_wall=503, gb_free=6.1, wall=30057
2022-02-02 14:27:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:28:10 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.735 | ppl 852.16 | wps 8005.4 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.357
2022-02-02 14:28:10 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:28:10 | INFO | train | epoch 086 | loss 6.281 | ppl 77.75 | wps 5959.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.668 | train_wall 322 | gb_free 6.1 | wall 30103
KL Stats: Epoch 86 Divergences: Uniform: 2.764351858438728 Unigram: 3.9593626863417812
2022-02-02 14:28:10 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:33:59 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.716 | ppl 841.15 | wps 8005.7 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.357
2022-02-02 14:33:59 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:33:59 | INFO | train | epoch 087 | loss 6.258 | ppl 76.53 | wps 5982.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.661 | train_wall 321 | gb_free 6.1 | wall 30452
KL Stats: Epoch 87 Divergences: Uniform: 2.7705416539696337 Unigram: 3.976537568168115
2022-02-02 14:33:59 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:36:41 | INFO | train_inner | epoch 088:     32 / 64 loss=6.244, ppl=75.77, wps=5849.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.669, train_wall=501, gb_free=6.1, wall=30614
2022-02-02 14:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:39:48 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.717 | ppl 841.86 | wps 8031.9 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.357
2022-02-02 14:39:48 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:39:48 | INFO | train | epoch 088 | loss 6.238 | ppl 75.46 | wps 5977.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.69 | train_wall 321 | gb_free 6.1 | wall 30801
KL Stats: Epoch 88 Divergences: Uniform: 2.7763134128402935 Unigram: 3.997908520687965
2022-02-02 14:39:48 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:45:38 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.694 | ppl 828.23 | wps 8019.5 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.357
2022-02-02 14:45:38 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:45:38 | INFO | train | epoch 089 | loss 6.217 | ppl 74.37 | wps 5972.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.692 | train_wall 322 | gb_free 6.1 | wall 31151
KL Stats: Epoch 89 Divergences: Uniform: 2.78318824230487 Unigram: 4.011952148772746
2022-02-02 14:45:38 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:45:58 | INFO | train_inner | epoch 090:      4 / 64 loss=6.231, ppl=75.12, wps=5847.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.691, train_wall=502, gb_free=6.1, wall=31171
2022-02-02 14:50:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:51:26 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.724 | ppl 845.95 | wps 8043.5 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.357
2022-02-02 14:51:26 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:51:26 | INFO | train | epoch 090 | loss 6.191 | ppl 73.04 | wps 5991.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.68 | train_wall 321 | gb_free 6.1 | wall 31500
KL Stats: Epoch 90 Divergences: Uniform: 2.7878911824317387 Unigram: 4.031755363576104
2022-02-02 14:51:26 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:54:48 | INFO | train_inner | epoch 091:     40 / 64 loss=6.178, ppl=72.4, wps=6167.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.685, train_wall=501, gb_free=6.1, wall=31701
2022-02-02 14:56:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:57:15 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.773 | ppl 874.81 | wps 8017.3 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.357
2022-02-02 14:57:15 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:57:15 | INFO | train | epoch 091 | loss 6.171 | ppl 72.04 | wps 5992.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.704 | train_wall 320 | gb_free 6.1 | wall 31848
KL Stats: Epoch 91 Divergences: Uniform: 2.791530389866192 Unigram: 4.055408325186846
2022-02-02 14:57:15 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:03:04 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.757 | ppl 865.41 | wps 8058.6 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.357
2022-02-02 15:03:04 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 15:03:04 | INFO | train | epoch 092 | loss 6.152 | ppl 71.1 | wps 5981.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.704 | train_wall 321 | gb_free 6.1 | wall 32198
KL Stats: Epoch 92 Divergences: Uniform: 2.8046433382758127 Unigram: 4.078507758012307
2022-02-02 15:03:04 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 15:03:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:04:05 | INFO | train_inner | epoch 093:     12 / 64 loss=6.156, ppl=71.3, wps=5856.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.713, train_wall=501, gb_free=6.1, wall=32258
2022-02-02 15:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:08:53 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.747 | ppl 859.56 | wps 8012.7 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.357
2022-02-02 15:08:53 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 15:08:53 | INFO | train | epoch 093 | loss 6.133 | ppl 70.17 | wps 5990.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.726 | train_wall 321 | gb_free 6.1 | wall 32546
KL Stats: Epoch 93 Divergences: Uniform: 2.8133169306261085 Unigram: 4.104216624512653
2022-02-02 15:08:53 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 15:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:12:55 | INFO | train_inner | epoch 094:     48 / 64 loss=6.12, ppl=69.57, wps=6158.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.713, train_wall=502, gb_free=6.1, wall=32789
2022-02-02 15:14:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:14:42 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.857 | ppl 927.43 | wps 8058.6 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.357
2022-02-02 15:14:42 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:14:42 | INFO | train | epoch 094 | loss 6.111 | ppl 69.1 | wps 5986.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.704 | train_wall 321 | gb_free 6.1 | wall 32895
KL Stats: Epoch 94 Divergences: Uniform: 2.802835651995392 Unigram: 4.117964620966939
2022-02-02 15:14:42 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:20:31 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.795 | ppl 888.59 | wps 8025.9 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.357
2022-02-02 15:20:31 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:20:31 | INFO | train | epoch 095 | loss 6.093 | ppl 68.24 | wps 5985.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.712 | train_wall 321 | gb_free 6.1 | wall 33244
KL Stats: Epoch 95 Divergences: Uniform: 2.81172651033956 Unigram: 4.133676068390204
2022-02-02 15:20:31 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:22:12 | INFO | train_inner | epoch 096:     20 / 64 loss=6.09, ppl=68.12, wps=5856.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.707, train_wall=501, gb_free=6.1, wall=33345
2022-02-02 15:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:26:19 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.782 | ppl 880.18 | wps 8054.9 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.357
2022-02-02 15:26:19 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:26:19 | INFO | train | epoch 096 | loss 6.074 | ppl 67.36 | wps 5988.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.72 | train_wall 321 | gb_free 6.1 | wall 33593
KL Stats: Epoch 96 Divergences: Uniform: 2.82619961705993 Unigram: 4.154963002964702
2022-02-02 15:26:19 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:31:02 | INFO | train_inner | epoch 097:     56 / 64 loss=6.069, ppl=67.12, wps=6170.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.727, train_wall=501, gb_free=6.1, wall=33875
2022-02-02 15:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:32:08 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.826 | ppl 907.6 | wps 8011.9 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.357
2022-02-02 15:32:08 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:32:08 | INFO | train | epoch 097 | loss 6.057 | ppl 66.56 | wps 5991.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.734 | train_wall 320 | gb_free 6.1 | wall 33941
KL Stats: Epoch 97 Divergences: Uniform: 2.8289871025339424 Unigram: 4.159422460472219
2022-02-02 15:32:08 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:37:57 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.832 | ppl 911.22 | wps 8063.3 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.357
2022-02-02 15:37:57 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:37:57 | INFO | train | epoch 098 | loss 6.037 | ppl 65.66 | wps 5979.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.74 | train_wall 321 | gb_free 6.1 | wall 34291
KL Stats: Epoch 98 Divergences: Uniform: 2.832775564020176 Unigram: 4.178356555002401
2022-02-02 15:37:57 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:40:18 | INFO | train_inner | epoch 099:     28 / 64 loss=6.026, ppl=65.16, wps=5856.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.746, train_wall=501, gb_free=6.1, wall=34432
2022-02-02 15:43:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:43:46 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.865 | ppl 932.31 | wps 8007.8 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.357
2022-02-02 15:43:46 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:43:46 | INFO | train | epoch 099 | loss 6.02 | ppl 64.88 | wps 5995.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.751 | train_wall 320 | gb_free 6.1 | wall 34639
KL Stats: Epoch 99 Divergences: Uniform: 2.8351812065309066 Unigram: 4.201812978008827
2022-02-02 15:43:46 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:49:07 | INFO | train_inner | epoch 100:     64 / 64 loss=6.022, ppl=64.98, wps=6160.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.743, train_wall=501, gb_free=6.1, wall=34961
2022-02-02 15:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:49:34 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.885 | ppl 945.5 | wps 8043.1 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.357
2022-02-02 15:49:34 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:49:34 | INFO | train | epoch 100 | loss 6.002 | ppl 64.09 | wps 5988.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.735 | train_wall 321 | gb_free 6.1 | wall 34988
KL Stats: Epoch 100 Divergences: Uniform: 2.8439022658721003 Unigram: 4.219607396809408
2022-02-02 15:49:34 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:55:23 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.828 | ppl 908.77 | wps 8021.1 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.357
2022-02-02 15:55:23 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:55:23 | INFO | train | epoch 101 | loss 5.985 | ppl 63.33 | wps 5988.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.75 | train_wall 321 | gb_free 6.1 | wall 35337
KL Stats: Epoch 101 Divergences: Uniform: 2.844395009983501 Unigram: 4.240129893481123
2022-02-02 15:55:23 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:58:25 | INFO | train_inner | epoch 102:     36 / 64 loss=5.97, ppl=62.67, wps=5858.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.757, train_wall=502, gb_free=6.1, wall=35518
2022-02-02 16:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:01:14 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.856 | ppl 926.48 | wps 8050.9 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.357
2022-02-02 16:01:14 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 16:01:14 | INFO | train | epoch 102 | loss 5.969 | ppl 62.64 | wps 5948.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.768 | train_wall 323 | gb_free 6.1 | wall 35688
KL Stats: Epoch 102 Divergences: Uniform: 2.8461761940229326 Unigram: 4.243185503663775
2022-02-02 16:01:14 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 16:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:07:03 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.905 | ppl 958.76 | wps 8030.8 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.357
2022-02-02 16:07:03 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 16:07:03 | INFO | train | epoch 103 | loss 5.95 | ppl 61.81 | wps 5985.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.758 | train_wall 321 | gb_free 6.1 | wall 36037
KL Stats: Epoch 103 Divergences: Uniform: 2.8505541734361035 Unigram: 4.270771492231279
2022-02-02 16:07:03 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 16:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:07:44 | INFO | train_inner | epoch 104:      8 / 64 loss=5.959, ppl=62.21, wps=5834.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.761, train_wall=503, gb_free=6.1, wall=36077
2022-02-02 16:12:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:12:52 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.886 | ppl 946.06 | wps 8022.2 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.357
2022-02-02 16:12:52 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:12:52 | INFO | train | epoch 104 | loss 5.933 | ppl 61.1 | wps 5983.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.744 | train_wall 321 | gb_free 6.1 | wall 36386
KL Stats: Epoch 104 Divergences: Uniform: 2.856488761084904 Unigram: 4.281124413621939
2022-02-02 16:12:52 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:16:34 | INFO | train_inner | epoch 105:     44 / 64 loss=5.924, ppl=60.71, wps=6160.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.762, train_wall=502, gb_free=6.1, wall=36608
2022-02-02 16:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:18:42 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.869 | ppl 935.31 | wps 7970.6 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.357
2022-02-02 16:18:42 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:18:42 | INFO | train | epoch 105 | loss 5.922 | ppl 60.62 | wps 5975.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.788 | train_wall 321 | gb_free 6.1 | wall 36735
KL Stats: Epoch 105 Divergences: Uniform: 2.861074310908887 Unigram: 4.296842788835129
2022-02-02 16:18:42 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:24:31 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.925 | ppl 972.23 | wps 8054.8 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.357
2022-02-02 16:24:31 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:24:31 | INFO | train | epoch 106 | loss 5.905 | ppl 59.92 | wps 5987.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.792 | train_wall 321 | gb_free 6.1 | wall 37084
KL Stats: Epoch 106 Divergences: Uniform: 2.868193048400134 Unigram: 4.313065877026364
2022-02-02 16:24:31 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:25:51 | INFO | train_inner | epoch 107:     16 / 64 loss=5.905, ppl=59.91, wps=5851.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.797, train_wall=501, gb_free=6.1, wall=37165
2022-02-02 16:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:30:20 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.922 | ppl 969.83 | wps 8007.9 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.357
2022-02-02 16:30:20 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:30:20 | INFO | train | epoch 107 | loss 5.889 | ppl 59.26 | wps 5984.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.783 | train_wall 321 | gb_free 6.1 | wall 37433
KL Stats: Epoch 107 Divergences: Uniform: 2.8687538485816995 Unigram: 4.339264213589102
2022-02-02 16:30:20 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:30:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:34:42 | INFO | train_inner | epoch 108:     52 / 64 loss=5.885, ppl=59.11, wps=6161.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.768, train_wall=502, gb_free=6.1, wall=37695
2022-02-02 16:35:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:36:08 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.956 | ppl 993.36 | wps 8070.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.357
2022-02-02 16:36:08 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:36:08 | INFO | train | epoch 108 | loss 5.876 | ppl 58.73 | wps 5993.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.786 | train_wall 321 | gb_free 6.1 | wall 37782
KL Stats: Epoch 108 Divergences: Uniform: 2.8744989279583195 Unigram: 4.345718495961141
2022-02-02 16:36:08 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:41:57 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.952 | ppl 990.58 | wps 8017.3 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.357
2022-02-02 16:41:57 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:41:57 | INFO | train | epoch 109 | loss 5.858 | ppl 57.99 | wps 5990 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.79 | train_wall 321 | gb_free 6.1 | wall 38130
KL Stats: Epoch 109 Divergences: Uniform: 2.878763460869584 Unigram: 4.369477477964697
2022-02-02 16:41:57 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:43:58 | INFO | train_inner | epoch 110:     24 / 64 loss=5.852, ppl=57.78, wps=5858.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.805, train_wall=501, gb_free=6.1, wall=38252
2022-02-02 16:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:47:46 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.033 | ppl 1047.47 | wps 8037.5 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.357
2022-02-02 16:47:46 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:47:46 | INFO | train | epoch 110 | loss 5.845 | ppl 57.49 | wps 5984.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.811 | train_wall 321 | gb_free 6.1 | wall 38479
KL Stats: Epoch 110 Divergences: Uniform: 2.874498442972812 Unigram: 4.386072636285571
2022-02-02 16:47:46 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:52:49 | INFO | train_inner | epoch 111:     60 / 64 loss=5.844, ppl=57.45, wps=6157.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.793, train_wall=502, gb_free=6.1, wall=38782
2022-02-02 16:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:53:35 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.032 | ppl 1047.23 | wps 8005.9 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.357
2022-02-02 16:53:35 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:53:35 | INFO | train | epoch 111 | loss 5.831 | ppl 56.94 | wps 5977.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.786 | train_wall 321 | gb_free 6.1 | wall 38829
KL Stats: Epoch 111 Divergences: Uniform: 2.87816308563781 Unigram: 4.392679547819094
2022-02-02 16:53:35 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:58:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:59:24 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.973 | ppl 1004.96 | wps 8063 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.357
2022-02-02 16:59:24 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:59:24 | INFO | train | epoch 112 | loss 5.817 | ppl 56.39 | wps 5982 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.826 | train_wall 321 | gb_free 6.1 | wall 39178
KL Stats: Epoch 112 Divergences: Uniform: 2.8870424233803575 Unigram: 4.406534026476526
2022-02-02 16:59:24 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:02:05 | INFO | train_inner | epoch 113:     32 / 64 loss=5.809, ppl=56.07, wps=5857.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.82, train_wall=501, gb_free=6.1, wall=39339
2022-02-02 17:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:05:13 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.966 | ppl 1000.42 | wps 8008.7 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.357
2022-02-02 17:05:13 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 17:05:13 | INFO | train | epoch 113 | loss 5.803 | ppl 55.84 | wps 5994 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.814 | train_wall 320 | gb_free 6.1 | wall 39526
KL Stats: Epoch 113 Divergences: Uniform: 2.8838537490690648 Unigram: 4.4210888595513325
2022-02-02 17:05:13 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 17:05:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:11:01 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.999 | ppl 1023.44 | wps 8064.5 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.357
2022-02-02 17:11:01 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 17:11:01 | INFO | train | epoch 114 | loss 5.79 | ppl 55.33 | wps 5997.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.819 | train_wall 320 | gb_free 6.1 | wall 39874
KL Stats: Epoch 114 Divergences: Uniform: 2.8883662333871545 Unigram: 4.433643174287853
2022-02-02 17:11:01 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 17:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:11:21 | INFO | train_inner | epoch 115:      4 / 64 loss=5.799, ppl=55.69, wps=5865, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.818, train_wall=500, gb_free=6.1, wall=39895
2022-02-02 17:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:16:50 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.023 | ppl 1040.44 | wps 8006.7 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.357
2022-02-02 17:16:50 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:16:50 | INFO | train | epoch 115 | loss 5.781 | ppl 54.97 | wps 5993.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.856 | train_wall 320 | gb_free 6.1 | wall 40223
KL Stats: Epoch 115 Divergences: Uniform: 2.892615052260032 Unigram: 4.448002406559253
2022-02-02 17:16:50 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:16:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:20:11 | INFO | train_inner | epoch 116:     40 / 64 loss=5.764, ppl=54.34, wps=6169, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.846, train_wall=501, gb_free=6.1, wall=40424
2022-02-02 17:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:22:38 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.046 | ppl 1057.22 | wps 8070.5 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.357
2022-02-02 17:22:38 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:22:38 | INFO | train | epoch 116 | loss 5.764 | ppl 54.33 | wps 6000.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.827 | train_wall 320 | gb_free 6.1 | wall 40571
KL Stats: Epoch 116 Divergences: Uniform: 2.899158543922401 Unigram: 4.468548507622703
2022-02-02 17:22:38 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:27:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:28:26 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.059 | ppl 1067.01 | wps 8028.3 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.357
2022-02-02 17:28:26 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:28:26 | INFO | train | epoch 117 | loss 5.753 | ppl 53.93 | wps 5995.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.865 | train_wall 320 | gb_free 6.1 | wall 40919
KL Stats: Epoch 117 Divergences: Uniform: 2.893982442177723 Unigram: 4.473968859730538
2022-02-02 17:28:26 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:29:27 | INFO | train_inner | epoch 118:     12 / 64 loss=5.759, ppl=54.15, wps=5866.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.854, train_wall=500, gb_free=6.1, wall=40980
2022-02-02 17:33:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:34:17 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.04 | ppl 1052.93 | wps 7595 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.357
2022-02-02 17:34:17 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:34:17 | INFO | train | epoch 118 | loss 5.741 | ppl 53.48 | wps 5953.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.841 | train_wall 321 | gb_free 6.1 | wall 41270
KL Stats: Epoch 118 Divergences: Uniform: 2.903015203810352 Unigram: 4.484942950939952
2022-02-02 17:34:17 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:38:19 | INFO | train_inner | epoch 119:     48 / 64 loss=5.732, ppl=53.16, wps=6143, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.843, train_wall=502, gb_free=6.1, wall=41512
2022-02-02 17:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:40:05 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.052 | ppl 1061.61 | wps 8030.5 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.357
2022-02-02 17:40:05 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:40:05 | INFO | train | epoch 119 | loss 5.73 | ppl 53.08 | wps 5991.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.849 | train_wall 321 | gb_free 6.1 | wall 41619
KL Stats: Epoch 119 Divergences: Uniform: 2.908900205685835 Unigram: 4.5059713777625925
2022-02-02 17:40:05 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:45:55 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.097 | ppl 1095.15 | wps 8025.9 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.357
2022-02-02 17:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:45:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint120.pt
2022-02-02 17:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint120.pt
2022-02-02 17:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.097) (writing took 3.495152136310935 seconds)
2022-02-02 17:45:59 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:45:59 | INFO | train | epoch 120 | loss 5.716 | ppl 52.55 | wps 5911.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.836 | train_wall 322 | gb_free 6.1 | wall 41972
KL Stats: Epoch 120 Divergences: Uniform: 2.9098037896662143 Unigram: 4.517005102823853
2022-02-02 17:45:59 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:47:40 | INFO | train_inner | epoch 121:     20 / 64 loss=5.717, ppl=52.58, wps=5809.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.837, train_wall=502, gb_free=6.1, wall=42073
2022-02-02 17:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:51:48 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.046 | ppl 1057.42 | wps 8028.5 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.357
2022-02-02 17:51:48 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:51:48 | INFO | train | epoch 121 | loss 5.705 | ppl 52.16 | wps 5982.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.836 | train_wall 321 | gb_free 6.1 | wall 42321
KL Stats: Epoch 121 Divergences: Uniform: 2.910870354809446 Unigram: 4.531566306002872
2022-02-02 17:51:48 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:51:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:56:31 | INFO | train_inner | epoch 122:     56 / 64 loss=5.705, ppl=52.16, wps=6152.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.866, train_wall=503, gb_free=6.1, wall=42604
2022-02-02 17:57:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:57:37 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.069 | ppl 1073.97 | wps 8028.9 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.357
2022-02-02 17:57:37 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:57:37 | INFO | train | epoch 122 | loss 5.695 | ppl 51.8 | wps 5977.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.882 | train_wall 321 | gb_free 6.1 | wall 42671
KL Stats: Epoch 122 Divergences: Uniform: 2.917710062349525 Unigram: 4.541714346572869
2022-02-02 17:57:37 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:57:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:03:26 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.078 | ppl 1081.05 | wps 8020.6 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.357
2022-02-02 18:03:26 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 18:03:26 | INFO | train | epoch 123 | loss 5.681 | ppl 51.31 | wps 5987 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.882 | train_wall 321 | gb_free 6.1 | wall 43020
KL Stats: Epoch 123 Divergences: Uniform: 2.9182453728018474 Unigram: 4.54707755695382
2022-02-02 18:03:26 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 18:03:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:05:48 | INFO | train_inner | epoch 124:     28 / 64 loss=5.67, ppl=50.92, wps=5852.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.876, train_wall=501, gb_free=6.1, wall=43161
2022-02-02 18:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:09:16 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.072 | ppl 1076.35 | wps 8024.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.357
2022-02-02 18:09:16 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 18:09:16 | INFO | train | epoch 124 | loss 5.669 | ppl 50.88 | wps 5975.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.872 | train_wall 321 | gb_free 6.1 | wall 43369
KL Stats: Epoch 124 Divergences: Uniform: 2.925601879226542 Unigram: 4.577446050131739
2022-02-02 18:09:16 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 18:09:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:14:37 | INFO | train_inner | epoch 125:     64 / 64 loss=5.677, ppl=51.15, wps=6159, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.871, train_wall=501, gb_free=6.1, wall=43691
2022-02-02 18:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:15:05 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.089 | ppl 1088.82 | wps 8023 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.357
2022-02-02 18:15:05 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:15:05 | INFO | train | epoch 125 | loss 5.66 | ppl 50.56 | wps 5987.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.87 | train_wall 321 | gb_free 6.1 | wall 43718
KL Stats: Epoch 125 Divergences: Uniform: 2.9252559750333025 Unigram: 4.582082370414344
2022-02-02 18:15:05 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:20:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:20:55 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.078 | ppl 1080.69 | wps 8022.3 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.357
2022-02-02 18:20:55 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:20:55 | INFO | train | epoch 126 | loss 5.649 | ppl 50.17 | wps 5953.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.89 | train_wall 323 | gb_free 6.1 | wall 44069
KL Stats: Epoch 126 Divergences: Uniform: 2.924911124728491 Unigram: 4.588678587504191
2022-02-02 18:20:55 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:23:57 | INFO | train_inner | epoch 127:     36 / 64 loss=5.635, ppl=49.7, wps=5841.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.89, train_wall=504, gb_free=6.1, wall=44250
2022-02-02 18:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:26:44 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.107 | ppl 1102.55 | wps 8017.9 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.357
2022-02-02 18:26:44 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:26:44 | INFO | train | epoch 127 | loss 5.638 | ppl 49.81 | wps 5988.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.877 | train_wall 321 | gb_free 6.1 | wall 44417
KL Stats: Epoch 127 Divergences: Uniform: 2.928812609743236 Unigram: 4.60677657633213
2022-02-02 18:26:44 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:32:33 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.1 | ppl 1097.35 | wps 8001.2 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.357
2022-02-02 18:32:33 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:32:33 | INFO | train | epoch 128 | loss 5.628 | ppl 49.46 | wps 5988.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.888 | train_wall 321 | gb_free 6.1 | wall 44766
KL Stats: Epoch 128 Divergences: Uniform: 2.923074513395998 Unigram: 4.615318986187497
2022-02-02 18:32:33 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:32:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:33:13 | INFO | train_inner | epoch 129:      8 / 64 loss=5.634, ppl=49.65, wps=5856.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.88, train_wall=501, gb_free=6.1, wall=44807
2022-02-02 18:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:38:22 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.073 | ppl 1076.78 | wps 8012.4 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.357
2022-02-02 18:38:22 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:38:22 | INFO | train | epoch 129 | loss 5.617 | ppl 49.09 | wps 5985.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.889 | train_wall 321 | gb_free 6.1 | wall 45115
KL Stats: Epoch 129 Divergences: Uniform: 2.934587769015228 Unigram: 4.628401192251545
2022-02-02 18:38:22 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:42:04 | INFO | train_inner | epoch 130:     44 / 64 loss=5.614, ppl=48.96, wps=6163.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.914, train_wall=502, gb_free=6.1, wall=45337
2022-02-02 18:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:44:10 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.123 | ppl 1115.35 | wps 8075.5 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.357
2022-02-02 18:44:10 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:44:10 | INFO | train | epoch 130 | loss 5.609 | ppl 48.82 | wps 5997.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.927 | train_wall 320 | gb_free 6.1 | wall 45463
KL Stats: Epoch 130 Divergences: Uniform: 2.937016463628939 Unigram: 4.635999139022997
2022-02-02 18:44:10 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:49:59 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.136 | ppl 1125.2 | wps 8000.8 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.357
2022-02-02 18:49:59 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:49:59 | INFO | train | epoch 131 | loss 5.598 | ppl 48.43 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.932 | train_wall 320 | gb_free 6.1 | wall 45812
KL Stats: Epoch 131 Divergences: Uniform: 2.931585361626325 Unigram: 4.648680067464504
2022-02-02 18:49:59 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:51:19 | INFO | train_inner | epoch 132:     16 / 64 loss=5.597, ppl=48.41, wps=5865.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.912, train_wall=500, gb_free=6.1, wall=45893
2022-02-02 18:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:55:47 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.206 | ppl 1181.49 | wps 8057.3 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.357
2022-02-02 18:55:47 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:55:47 | INFO | train | epoch 132 | loss 5.586 | ppl 48.04 | wps 5997.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.901 | train_wall 320 | gb_free 6.1 | wall 46160
KL Stats: Epoch 132 Divergences: Uniform: 2.9381800890497987 Unigram: 4.660499336345959
2022-02-02 18:55:47 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:00:09 | INFO | train_inner | epoch 133:     52 / 64 loss=5.583, ppl=47.95, wps=6168.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.927, train_wall=501, gb_free=6.1, wall=46423
2022-02-02 19:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:01:36 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.202 | ppl 1178.16 | wps 8029.9 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.357
2022-02-02 19:01:36 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 19:01:36 | INFO | train | epoch 133 | loss 5.579 | ppl 47.8 | wps 5985.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.936 | train_wall 321 | gb_free 6.1 | wall 46509
KL Stats: Epoch 133 Divergences: Uniform: 2.9410854793367416 Unigram: 4.673215630950792
2022-02-02 19:01:36 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 19:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:07:24 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.127 | ppl 1118.01 | wps 8065.1 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.357
2022-02-02 19:07:24 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 19:07:24 | INFO | train | epoch 134 | loss 5.57 | ppl 47.5 | wps 5991.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.945 | train_wall 321 | gb_free 6.1 | wall 46858
KL Stats: Epoch 134 Divergences: Uniform: 2.9470995718037027 Unigram: 4.689831618780143
2022-02-02 19:07:24 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 19:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:09:25 | INFO | train_inner | epoch 135:     24 / 64 loss=5.566, ppl=47.38, wps=5860.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.943, train_wall=501, gb_free=6.1, wall=46979
2022-02-02 19:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:13:13 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.184 | ppl 1163.61 | wps 8014.8 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.357
2022-02-02 19:13:13 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 19:13:13 | INFO | train | epoch 135 | loss 5.559 | ppl 47.15 | wps 5987.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.923 | train_wall 321 | gb_free 6.1 | wall 47207
KL Stats: Epoch 135 Divergences: Uniform: 2.949200927655643 Unigram: 4.696683286615229
2022-02-02 19:13:13 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 19:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:18:26 | INFO | train_inner | epoch 136:     60 / 64 loss=5.561, ppl=47.2, wps=6049.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.929, train_wall=512, gb_free=6.1, wall=47519
2022-02-02 19:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:19:14 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.134 | ppl 1123.34 | wps 7622.1 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.357
2022-02-02 19:19:14 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:19:14 | INFO | train | epoch 136 | loss 5.552 | ppl 46.92 | wps 5789.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.95 | train_wall 331 | gb_free 6.1 | wall 47567
KL Stats: Epoch 136 Divergences: Uniform: 2.9478314175798372 Unigram: 4.710225216611142
2022-02-02 19:19:14 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:25:15 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.143 | ppl 1130.52 | wps 7902.3 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.357
2022-02-02 19:25:15 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:25:15 | INFO | train | epoch 137 | loss 5.54 | ppl 46.54 | wps 5778.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.93 | train_wall 333 | gb_free 6.1 | wall 47929
KL Stats: Epoch 137 Divergences: Uniform: 2.953823937027919 Unigram: 4.722133574039207
2022-02-02 19:25:15 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:28:05 | INFO | train_inner | epoch 138:     32 / 64 loss=5.532, ppl=46.25, wps=5630.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.936, train_wall=521, gb_free=6.1, wall=48098
2022-02-02 19:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:31:19 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.181 | ppl 1160.87 | wps 7628.7 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.357
2022-02-02 19:31:19 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:31:19 | INFO | train | epoch 138 | loss 5.533 | ppl 46.32 | wps 5743.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.961 | train_wall 334 | gb_free 6.1 | wall 48293
KL Stats: Epoch 138 Divergences: Uniform: 2.956721680247937 Unigram: 4.725513136974188
2022-02-02 19:31:19 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:37:22 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.135 | ppl 1124.58 | wps 7630.3 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.357
2022-02-02 19:37:22 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 19:37:22 | INFO | train | epoch 139 | loss 5.524 | ppl 46.01 | wps 5753.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 1 | train_wall 333 | gb_free 6.1 | wall 48656
KL Stats: Epoch 139 Divergences: Uniform: 2.957043174526927 Unigram: 4.741798053780398
2022-02-02 19:37:22 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 19:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:37:43 | INFO | train_inner | epoch 140:      4 / 64 loss=5.534, ppl=46.34, wps=5634.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.993, train_wall=520, gb_free=6.1, wall=48677
2022-02-02 19:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:43:23 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.217 | ppl 1190.03 | wps 7932 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.357
2022-02-02 19:43:23 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 19:43:23 | INFO | train | epoch 140 | loss 5.514 | ppl 45.71 | wps 5788.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.97 | train_wall 332 | gb_free 6.1 | wall 49016
KL Stats: Epoch 140 Divergences: Uniform: 2.951780757531557 Unigram: 4.750593372731012
2022-02-02 19:43:23 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 19:43:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:46:54 | INFO | train_inner | epoch 141:     40 / 64 loss=5.507, ppl=45.46, wps=5934.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.992, train_wall=522, gb_free=6.1, wall=49227
2022-02-02 19:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:49:28 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.194 | ppl 1171.34 | wps 7539 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.357
2022-02-02 19:49:28 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:49:28 | INFO | train | epoch 141 | loss 5.506 | ppl 45.45 | wps 5722.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.996 | train_wall 335 | gb_free 6.1 | wall 49381
KL Stats: Epoch 141 Divergences: Uniform: 2.956016110887117 Unigram: 4.758609375104976
2022-02-02 19:49:28 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:55:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:55:30 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.224 | ppl 1196.34 | wps 7680.6 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.357
2022-02-02 19:55:30 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:55:30 | INFO | train | epoch 142 | loss 5.5 | ppl 45.24 | wps 5763.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 1.009 | train_wall 333 | gb_free 6.1 | wall 49744
KL Stats: Epoch 142 Divergences: Uniform: 2.952750943789628 Unigram: 4.762657553685066
2022-02-02 19:55:30 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:55:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:56:33 | INFO | train_inner | epoch 143:     12 / 64 loss=5.499, ppl=45.22, wps=5630.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.997, train_wall=520, gb_free=6.1, wall=49806
2022-02-02 20:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:01:32 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.211 | ppl 1185.35 | wps 7809.5 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.357
2022-02-02 20:01:32 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 20:01:32 | INFO | train | epoch 143 | loss 5.49 | ppl 44.95 | wps 5770 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.986 | train_wall 333 | gb_free 6.1 | wall 50106
KL Stats: Epoch 143 Divergences: Uniform: 2.955331691254312 Unigram: 4.776177811400392
2022-02-02 20:01:32 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 20:01:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:05:45 | INFO | train_inner | epoch 144:     48 / 64 loss=5.486, ppl=44.82, wps=5920.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.995, train_wall=523, gb_free=6.1, wall=50358
2022-02-02 20:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:07:36 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.221 | ppl 1193.87 | wps 7629.4 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.357
2022-02-02 20:07:36 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 20:07:36 | INFO | train | epoch 144 | loss 5.482 | ppl 44.7 | wps 5738.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 1.011 | train_wall 334 | gb_free 6.1 | wall 50470
KL Stats: Epoch 144 Divergences: Uniform: 2.96257069626227 Unigram: 4.7887721933685725
2022-02-02 20:07:36 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 20:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:13:40 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.232 | ppl 1202.47 | wps 7617.4 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.357
2022-02-02 20:13:40 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 20:13:40 | INFO | train | epoch 145 | loss 5.475 | ppl 44.47 | wps 5743.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.995 | train_wall 334 | gb_free 6.1 | wall 50833
KL Stats: Epoch 145 Divergences: Uniform: 2.9629652688517023 Unigram: 4.804010578964849
2022-02-02 20:13:40 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 20:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:15:24 | INFO | train_inner | epoch 146:     20 / 64 loss=5.472, ppl=44.38, wps=5627.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.994, train_wall=520, gb_free=6.1, wall=50938
2022-02-02 20:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:19:41 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.174 | ppl 1155.12 | wps 7825.1 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.357
2022-02-02 20:19:41 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:19:41 | INFO | train | epoch 146 | loss 5.466 | ppl 44.19 | wps 5780.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.998 | train_wall 332 | gb_free 6.1 | wall 51195
KL Stats: Epoch 146 Divergences: Uniform: 2.9662123398414675 Unigram: 4.811418740737719
2022-02-02 20:19:41 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:24:36 | INFO | train_inner | epoch 147:     56 / 64 loss=5.467, ppl=44.22, wps=5924.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=1.004, train_wall=522, gb_free=6.1, wall=51489
2022-02-02 20:25:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:25:46 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.231 | ppl 1202.01 | wps 7574.7 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.357
2022-02-02 20:25:46 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:25:46 | INFO | train | epoch 147 | loss 5.457 | ppl 43.93 | wps 5728.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 1.005 | train_wall 335 | gb_free 6.1 | wall 51559
KL Stats: Epoch 147 Divergences: Uniform: 2.9683879748800304 Unigram: 4.819143248937737
2022-02-02 20:25:46 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:25:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:31:49 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.212 | ppl 1186.13 | wps 7655.5 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.357
2022-02-02 20:31:49 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 20:31:49 | INFO | train | epoch 148 | loss 5.451 | ppl 43.74 | wps 5748.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 1.034 | train_wall 334 | gb_free 6.1 | wall 51923
KL Stats: Epoch 148 Divergences: Uniform: 2.97177639718697 Unigram: 4.827397089770673
2022-02-02 20:31:49 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 20:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:34:16 | INFO | train_inner | epoch 149:     28 / 64 loss=5.444, ppl=43.53, wps=5620.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=1.014, train_wall=521, gb_free=6.1, wall=52069
2022-02-02 20:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:37:51 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.224 | ppl 1195.65 | wps 8014.3 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.357
2022-02-02 20:37:51 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 20:37:51 | INFO | train | epoch 149 | loss 5.444 | ppl 43.53 | wps 5775.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.022 | train_wall 333 | gb_free 6.1 | wall 52284
KL Stats: Epoch 149 Divergences: Uniform: 2.9710169456505637 Unigram: 4.838286878159985
2022-02-02 20:37:51 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 20:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:43:26 | INFO | train_inner | epoch 150:     64 / 64 loss=5.449, ppl=43.69, wps=5926.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.046, train_wall=521, gb_free=6.1, wall=52619
2022-02-02 20:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:43:54 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.251 | ppl 1218.2 | wps 7636.8 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.357
2022-02-02 20:43:54 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 20:43:54 | INFO | train | epoch 150 | loss 5.436 | ppl 43.28 | wps 5744.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 1.036 | train_wall 334 | gb_free 6.1 | wall 52648
KL Stats: Epoch 150 Divergences: Uniform: 2.967793387621707 Unigram: 4.842648424892705
2022-02-02 20:43:54 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 20:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:49:57 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.223 | ppl 1195.03 | wps 7700 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.357
2022-02-02 20:49:57 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 20:49:57 | INFO | train | epoch 151 | loss 5.431 | ppl 43.13 | wps 5753.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.072 | train_wall 334 | gb_free 6.1 | wall 53011
KL Stats: Epoch 151 Divergences: Uniform: 2.969493580668755 Unigram: 4.853414949077635
2022-02-02 20:49:57 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 20:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:53:07 | INFO | train_inner | epoch 152:     36 / 64 loss=5.415, ppl=42.68, wps=5627.4, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.056, train_wall=522, gb_free=6.1, wall=53200
2022-02-02 20:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:56:00 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.267 | ppl 1231.81 | wps 7985.9 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.357
2022-02-02 20:56:00 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:56:00 | INFO | train | epoch 152 | loss 5.421 | ppl 42.84 | wps 5768.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.032 | train_wall 334 | gb_free 6.1 | wall 53373
KL Stats: Epoch 152 Divergences: Uniform: 2.973688681285433 Unigram: 4.863436717326727
2022-02-02 20:56:00 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:02:04 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.27 | ppl 1234.49 | wps 7586.8 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.357
2022-02-02 21:02:04 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 21:02:04 | INFO | train | epoch 153 | loss 5.413 | ppl 42.59 | wps 5731.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 1.054 | train_wall 335 | gb_free 6.1 | wall 53737
KL Stats: Epoch 153 Divergences: Uniform: 2.9772057501517346 Unigram: 4.8739873580915685
2022-02-02 21:02:04 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 21:02:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:02:46 | INFO | train_inner | epoch 154:      8 / 64 loss=5.422, ppl=42.86, wps=5624.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=1.045, train_wall=522, gb_free=6.1, wall=53780
2022-02-02 21:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:08:07 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.216 | ppl 1189.22 | wps 7608.6 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.357
2022-02-02 21:08:07 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 21:08:07 | INFO | train | epoch 154 | loss 5.407 | ppl 42.43 | wps 5757.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.069 | train_wall 333 | gb_free 6.1 | wall 54100
KL Stats: Epoch 154 Divergences: Uniform: 2.9741307838302795 Unigram: 4.882847773039336
2022-02-02 21:08:07 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 21:08:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:11:58 | INFO | train_inner | epoch 155:     44 / 64 loss=5.4, ppl=42.22, wps=5917.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.066, train_wall=522, gb_free=6.1, wall=54332
2022-02-02 21:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:14:09 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.262 | ppl 1227.92 | wps 7996.7 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.357
2022-02-02 21:14:09 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 21:14:09 | INFO | train | epoch 155 | loss 5.4 | ppl 42.24 | wps 5762.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.066 | train_wall 334 | gb_free 6.1 | wall 54463
KL Stats: Epoch 155 Divergences: Uniform: 2.981180049449245 Unigram: 4.896499832524123
2022-02-02 21:14:09 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 21:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:20:13 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.274 | ppl 1238.25 | wps 7551.8 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.357
2022-02-02 21:20:13 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 21:20:13 | INFO | train | epoch 156 | loss 5.394 | ppl 42.05 | wps 5743 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.1 | train_wall 334 | gb_free 6.1 | wall 54826
KL Stats: Epoch 156 Divergences: Uniform: 2.981723644444533 Unigram: 4.895949940865589
2022-02-02 21:20:13 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 21:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:21:37 | INFO | train_inner | epoch 157:     16 / 64 loss=5.392, ppl=42, wps=5632.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.09, train_wall=521, gb_free=6.1, wall=54911
2022-02-02 21:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:26:16 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.218 | ppl 1191.03 | wps 7673.1 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.357
2022-02-02 21:26:16 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:26:16 | INFO | train | epoch 157 | loss 5.386 | ppl 41.82 | wps 5757.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.07 | train_wall 333 | gb_free 6.1 | wall 55189
KL Stats: Epoch 157 Divergences: Uniform: 2.9896146339995564 Unigram: 4.907468443598368
2022-02-02 21:26:16 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:30:49 | INFO | train_inner | epoch 158:     52 / 64 loss=5.386, ppl=41.83, wps=5925.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.085, train_wall=522, gb_free=6.1, wall=55462
2022-02-02 21:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:32:18 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.276 | ppl 1240.3 | wps 7924.1 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.357
2022-02-02 21:32:18 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 21:32:18 | INFO | train | epoch 158 | loss 5.378 | ppl 41.59 | wps 5766.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.088 | train_wall 334 | gb_free 6.1 | wall 55551
KL Stats: Epoch 158 Divergences: Uniform: 2.98736811266229 Unigram: 4.914574611467412
2022-02-02 21:32:18 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 21:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:38:23 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.234 | ppl 1204.33 | wps 7618.8 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.357
2022-02-02 21:38:23 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 21:38:23 | INFO | train | epoch 159 | loss 5.372 | ppl 41.42 | wps 5721.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.083 | train_wall 335 | gb_free 6.1 | wall 55916
KL Stats: Epoch 159 Divergences: Uniform: 2.983686426825593 Unigram: 4.918666436626707
2022-02-02 21:38:23 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 21:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:40:29 | INFO | train_inner | epoch 160:     24 / 64 loss=5.37, ppl=41.36, wps=5622, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.091, train_wall=522, gb_free=6.1, wall=56042
2022-02-02 21:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:44:26 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.251 | ppl 1218.3 | wps 7619.7 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.357
2022-02-02 21:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 21:44:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint160.pt
2022-02-02 21:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint160.pt
2022-02-02 21:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.251) (writing took 3.713251791894436 seconds)
2022-02-02 21:44:30 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 21:44:30 | INFO | train | epoch 160 | loss 5.366 | ppl 41.24 | wps 5689.5 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.097 | train_wall 334 | gb_free 6.1 | wall 56283
KL Stats: Epoch 160 Divergences: Uniform: 2.9890330086482453 Unigram: 4.932483087684438
2022-02-02 21:44:30 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 21:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:49:45 | INFO | train_inner | epoch 161:     60 / 64 loss=5.367, ppl=41.26, wps=5878.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.127, train_wall=522, gb_free=6.1, wall=56598
2022-02-02 21:50:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:50:31 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.248 | ppl 1216.05 | wps 8020.2 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.357
2022-02-02 21:50:31 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 21:50:31 | INFO | train | epoch 161 | loss 5.361 | ppl 41.09 | wps 5782.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.156 | train_wall 333 | gb_free 6.1 | wall 56645
KL Stats: Epoch 161 Divergences: Uniform: 2.9873193878625903 Unigram: 4.944901755053998
2022-02-02 21:50:31 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 21:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:56:36 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.263 | ppl 1228.42 | wps 7564.8 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.357
2022-02-02 21:56:36 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 21:56:36 | INFO | train | epoch 162 | loss 5.351 | ppl 40.82 | wps 5723.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.105 | train_wall 335 | gb_free 6.1 | wall 57010
KL Stats: Epoch 162 Divergences: Uniform: 2.9902697261365 Unigram: 4.951805816773992
2022-02-02 21:56:36 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 21:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:59:23 | INFO | train_inner | epoch 163:     32 / 64 loss=5.345, ppl=40.66, wps=5634.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.114, train_wall=521, gb_free=6.1, wall=57177
2022-02-02 22:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:02:39 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.256 | ppl 1222.56 | wps 7662.8 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.357
2022-02-02 22:02:39 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 22:02:39 | INFO | train | epoch 163 | loss 5.348 | ppl 40.72 | wps 5752.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.114 | train_wall 334 | gb_free 6.1 | wall 57373
KL Stats: Epoch 163 Divergences: Uniform: 2.9903961224816293 Unigram: 4.966127271182369
2022-02-02 22:02:39 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 22:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:08:41 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.302 | ppl 1262.87 | wps 7991.3 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.357
2022-02-02 22:08:41 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 22:08:41 | INFO | train | epoch 164 | loss 5.343 | ppl 40.59 | wps 5767.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.149 | train_wall 334 | gb_free 6.1 | wall 57735
KL Stats: Epoch 164 Divergences: Uniform: 2.99058784308351 Unigram: 4.967150206678029
2022-02-02 22:08:41 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 22:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:09:03 | INFO | train_inner | epoch 165:      4 / 64 loss=5.349, ppl=40.76, wps=5619.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.134, train_wall=523, gb_free=6.1, wall=57757
2022-02-02 22:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:14:45 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.317 | ppl 1275.47 | wps 7600.7 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.357
2022-02-02 22:14:45 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 22:14:45 | INFO | train | epoch 165 | loss 5.335 | ppl 40.37 | wps 5739.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.124 | train_wall 334 | gb_free 6.1 | wall 58099
KL Stats: Epoch 165 Divergences: Uniform: 2.9925367564452365 Unigram: 4.9757997031958965
2022-02-02 22:14:45 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 22:14:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:18:14 | INFO | train_inner | epoch 166:     40 / 64 loss=5.33, ppl=40.21, wps=5928.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.138, train_wall=521, gb_free=6.1, wall=58308
2022-02-02 22:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:20:48 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.315 | ppl 1274.3 | wps 7681.9 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.357
2022-02-02 22:20:48 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 22:20:48 | INFO | train | epoch 166 | loss 5.33 | ppl 40.23 | wps 5756.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.165 | train_wall 333 | gb_free 6.1 | wall 58462
KL Stats: Epoch 166 Divergences: Uniform: 2.9953500992766076 Unigram: 4.978459072070708
2022-02-02 22:20:48 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 22:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:26:48 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.35 | ppl 1305.46 | wps 8012.9 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.357
2022-02-02 22:26:48 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:26:48 | INFO | train | epoch 167 | loss 5.322 | ppl 39.99 | wps 5799.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.133 | train_wall 332 | gb_free 6.1 | wall 58822
KL Stats: Epoch 167 Divergences: Uniform: 2.9907209234030256 Unigram: 4.9933428245811955
2022-02-02 22:26:48 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:27:52 | INFO | train_inner | epoch 168:     12 / 64 loss=5.324, ppl=40.05, wps=5648.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.152, train_wall=520, gb_free=6.1, wall=58885
2022-02-02 22:32:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:32:51 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.355 | ppl 1309.96 | wps 7579 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.357
2022-02-02 22:32:51 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 22:32:51 | INFO | train | epoch 168 | loss 5.316 | ppl 39.84 | wps 5751.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.182 | train_wall 333 | gb_free 6.1 | wall 59185
KL Stats: Epoch 168 Divergences: Uniform: 2.988979728392268 Unigram: 4.9998302476648435
2022-02-02 22:32:51 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 22:32:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:37:03 | INFO | train_inner | epoch 169:     48 / 64 loss=5.313, ppl=39.77, wps=5925.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.177, train_wall=521, gb_free=6.1, wall=59437
2022-02-02 22:38:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:38:55 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.322 | ppl 1280.07 | wps 7645.7 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.357
2022-02-02 22:38:55 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 22:38:55 | INFO | train | epoch 169 | loss 5.313 | ppl 39.75 | wps 5748.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.188 | train_wall 334 | gb_free 6.1 | wall 59548
KL Stats: Epoch 169 Divergences: Uniform: 3.0008815423785133 Unigram: 5.0038251106441685
2022-02-02 22:38:55 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 22:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:44:58 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.388 | ppl 1340.15 | wps 7988.5 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.357
2022-02-02 22:44:58 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 22:44:58 | INFO | train | epoch 170 | loss 5.304 | ppl 39.49 | wps 5748.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.185 | train_wall 335 | gb_free 6.1 | wall 59911
KL Stats: Epoch 170 Divergences: Uniform: 2.9916624773146574 Unigram: 5.01236049090816
2022-02-02 22:44:58 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 22:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:46:44 | INFO | train_inner | epoch 171:     20 / 64 loss=5.3, ppl=39.39, wps=5606.7, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.192, train_wall=524, gb_free=6.1, wall=60018
2022-02-02 22:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:51:03 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.363 | ppl 1317.3 | wps 7648.7 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.357
2022-02-02 22:51:03 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 22:51:03 | INFO | train | epoch 171 | loss 5.3 | ppl 39.39 | wps 5728.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.212 | train_wall 335 | gb_free 6.1 | wall 60276
KL Stats: Epoch 171 Divergences: Uniform: 2.9983876357859525 Unigram: 5.019035272898803
2022-02-02 22:51:03 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 22:51:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:55:58 | INFO | train_inner | epoch 172:     56 / 64 loss=5.305, ppl=39.53, wps=5908.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.228, train_wall=523, gb_free=6.1, wall=60571
2022-02-02 22:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:57:07 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.349 | ppl 1304.52 | wps 7610.7 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.357
2022-02-02 22:57:07 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 22:57:07 | INFO | train | epoch 172 | loss 5.295 | ppl 39.27 | wps 5730.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.215 | train_wall 335 | gb_free 6.1 | wall 60641
KL Stats: Epoch 172 Divergences: Uniform: 3.0006864528046466 Unigram: 5.039179674953659
2022-02-02 22:57:07 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 22:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:03:08 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.356 | ppl 1310.81 | wps 7901.3 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.357
2022-02-02 23:03:08 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 23:03:08 | INFO | train | epoch 173 | loss 5.287 | ppl 39.03 | wps 5783.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.163 | train_wall 333 | gb_free 6.1 | wall 61002
KL Stats: Epoch 173 Divergences: Uniform: 2.9985795581917523 Unigram: 5.039511371600697
2022-02-02 23:03:08 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 23:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:05:37 | INFO | train_inner | epoch 174:     28 / 64 loss=5.28, ppl=38.86, wps=5630.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.171, train_wall=521, gb_free=6.1, wall=61150
2022-02-02 23:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:09:14 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.396 | ppl 1347.07 | wps 7565.8 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.357
2022-02-02 23:09:14 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 23:09:14 | INFO | train | epoch 174 | loss 5.283 | ppl 38.94 | wps 5714.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.2 | train_wall 336 | gb_free 6.1 | wall 61367
KL Stats: Epoch 174 Divergences: Uniform: 3.0049764976679247 Unigram: 5.041136794972832
2022-02-02 23:09:14 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 23:09:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:14:48 | INFO | train_inner | epoch 175:     64 / 64 loss=5.29, ppl=39.12, wps=5912.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.199, train_wall=521, gb_free=6.1, wall=61701
2022-02-02 23:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:15:16 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.339 | ppl 1294.85 | wps 7702.6 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.357
2022-02-02 23:15:16 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 23:15:16 | INFO | train | epoch 175 | loss 5.277 | ppl 38.78 | wps 5760.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.203 | train_wall 333 | gb_free 6.1 | wall 61730
KL Stats: Epoch 175 Divergences: Uniform: 3.005864811324565 Unigram: 5.056446069513381
2022-02-02 23:15:16 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 23:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:20:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:21:18 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.412 | ppl 1362.7 | wps 7837.4 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.357
2022-02-02 23:21:18 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 23:21:18 | INFO | train | epoch 176 | loss 5.271 | ppl 38.6 | wps 5782.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.205 | train_wall 332 | gb_free 6.1 | wall 62091
KL Stats: Epoch 176 Divergences: Uniform: 3.0050588329262697 Unigram: 5.059053827803028
2022-02-02 23:21:18 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 23:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:24:27 | INFO | train_inner | epoch 177:     36 / 64 loss=5.261, ppl=38.34, wps=5639.1, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.23, train_wall=522, gb_free=6.1, wall=62281
2022-02-02 23:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:27:22 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.34 | ppl 1295.74 | wps 7599.5 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.357
2022-02-02 23:27:22 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 23:27:22 | INFO | train | epoch 177 | loss 5.268 | ppl 38.54 | wps 5737.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.234 | train_wall 334 | gb_free 6.1 | wall 62455
KL Stats: Epoch 177 Divergences: Uniform: 3.008064326528862 Unigram: 5.066958068901838
2022-02-02 23:27:22 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 23:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:33:26 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.389 | ppl 1340.68 | wps 7687.3 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.357
2022-02-02 23:33:26 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 23:33:26 | INFO | train | epoch 178 | loss 5.261 | ppl 38.34 | wps 5728.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.233 | train_wall 335 | gb_free 6.1 | wall 62820
KL Stats: Epoch 178 Divergences: Uniform: 3.009085013715098 Unigram: 5.073295937185546
2022-02-02 23:33:26 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 23:33:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:34:08 | INFO | train_inner | epoch 179:      8 / 64 loss=5.269, ppl=38.57, wps=5615, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.215, train_wall=522, gb_free=6.1, wall=62861
2022-02-02 23:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:39:27 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.381 | ppl 1333.52 | wps 7901.2 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.357
2022-02-02 23:39:27 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 23:39:27 | INFO | train | epoch 179 | loss 5.255 | ppl 38.18 | wps 5792 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.227 | train_wall 332 | gb_free 6.1 | wall 63180
KL Stats: Epoch 179 Divergences: Uniform: 3.0061301936375213 Unigram: 5.084329951566112
2022-02-02 23:39:27 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 23:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:43:09 | INFO | train_inner | epoch 180:     44 / 64 loss=5.247, ppl=37.96, wps=6043.9, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.269, train_wall=512, gb_free=6.1, wall=63402
2022-02-02 23:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:45:15 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.393 | ppl 1344.64 | wps 8090.6 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.357
2022-02-02 23:45:15 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 23:45:15 | INFO | train | epoch 180 | loss 5.251 | ppl 38.09 | wps 5989.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.306 | train_wall 321 | gb_free 6.1 | wall 63529
KL Stats: Epoch 180 Divergences: Uniform: 3.010391513876951 Unigram: 5.090214237445098
2022-02-02 23:45:15 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 23:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:51:03 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.394 | ppl 1345.73 | wps 8069.8 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.357
2022-02-02 23:51:03 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 23:51:03 | INFO | train | epoch 181 | loss 5.244 | ppl 37.91 | wps 6005 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.3 | train_wall 320 | gb_free 6.1 | wall 63877
KL Stats: Epoch 181 Divergences: Uniform: 3.015657701018224 Unigram: 5.102990319344715
2022-02-02 23:51:03 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 23:51:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:52:24 | INFO | train_inner | epoch 182:     16 / 64 loss=5.247, ppl=37.99, wps=5869.9, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.286, train_wall=500, gb_free=6.1, wall=63958
2022-02-02 23:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:56:52 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.343 | ppl 1299.1 | wps 8077.4 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.357
2022-02-02 23:56:52 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 23:56:52 | INFO | train | epoch 182 | loss 5.239 | ppl 37.76 | wps 5987.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.245 | train_wall 321 | gb_free 6.1 | wall 64226
KL Stats: Epoch 182 Divergences: Uniform: 3.011766732135879 Unigram: 5.1102201675130585
2022-02-02 23:56:52 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 23:56:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:01:15 | INFO | train_inner | epoch 183:     52 / 64 loss=5.234, ppl=37.65, wps=6161.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.267, train_wall=502, gb_free=6.1, wall=64488
2022-02-03 00:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:02:41 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.412 | ppl 1362.25 | wps 8083.8 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.357
2022-02-03 00:02:41 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-03 00:02:41 | INFO | train | epoch 183 | loss 5.235 | ppl 37.66 | wps 5990 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.308 | train_wall 321 | gb_free 6.1 | wall 64574
KL Stats: Epoch 183 Divergences: Uniform: 3.0159692997092202 Unigram: 5.114037317960886
2022-02-03 00:02:41 | INFO | fairseq.trainer | begin training epoch 184
2022-02-03 00:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:08:29 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.359 | ppl 1313.25 | wps 8080.7 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.357
2022-02-03 00:08:29 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-03 00:08:29 | INFO | train | epoch 184 | loss 5.231 | ppl 37.56 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.306 | train_wall 321 | gb_free 6.1 | wall 64923
KL Stats: Epoch 184 Divergences: Uniform: 3.0134872052598625 Unigram: 5.120103867806385
2022-02-03 00:08:29 | INFO | fairseq.trainer | begin training epoch 185
2022-02-03 00:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:10:30 | INFO | train_inner | epoch 185:     24 / 64 loss=5.229, ppl=37.5, wps=5866.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.307, train_wall=500, gb_free=6.1, wall=65044
2022-02-03 00:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:14:17 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.381 | ppl 1333.26 | wps 8070.5 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.357
2022-02-03 00:14:17 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-03 00:14:17 | INFO | train | epoch 185 | loss 5.226 | ppl 37.43 | wps 6000.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.308 | train_wall 320 | gb_free 6.1 | wall 65271
KL Stats: Epoch 185 Divergences: Uniform: 3.0195513446755373 Unigram: 5.130924020827319
2022-02-03 00:14:17 | INFO | fairseq.trainer | begin training epoch 186
2022-02-03 00:14:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:19:20 | INFO | train_inner | epoch 186:     60 / 64 loss=5.231, ppl=37.55, wps=6165.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.318, train_wall=502, gb_free=6.1, wall=65574
2022-02-03 00:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:20:06 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.363 | ppl 1316.75 | wps 8084.5 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.357
2022-02-03 00:20:06 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-03 00:20:06 | INFO | train | epoch 186 | loss 5.221 | ppl 37.31 | wps 5987.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.307 | train_wall 321 | gb_free 6.1 | wall 65620
KL Stats: Epoch 186 Divergences: Uniform: 3.017695901238331 Unigram: 5.134026421582069
2022-02-03 00:20:06 | INFO | fairseq.trainer | begin training epoch 187
2022-02-03 00:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:25:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:25:54 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.381 | ppl 1333.04 | wps 8061.2 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.357
2022-02-03 00:25:54 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-03 00:25:54 | INFO | train | epoch 187 | loss 5.217 | ppl 37.2 | wps 6003.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.335 | train_wall 320 | gb_free 6.1 | wall 65968
KL Stats: Epoch 187 Divergences: Uniform: 3.020597693023817 Unigram: 5.142420432221556
2022-02-03 00:25:54 | INFO | fairseq.trainer | begin training epoch 188
2022-02-03 00:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:28:36 | INFO | train_inner | epoch 188:     32 / 64 loss=5.207, ppl=36.95, wps=5869.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.342, train_wall=500, gb_free=6.1, wall=66129
2022-02-03 00:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:31:43 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.414 | ppl 1364.22 | wps 8041.4 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.357
2022-02-03 00:31:43 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 00:31:43 | INFO | train | epoch 188 | loss 5.212 | ppl 37.06 | wps 5988 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.328 | train_wall 321 | gb_free 6.1 | wall 66316
KL Stats: Epoch 188 Divergences: Uniform: 3.022065720238582 Unigram: 5.145445088413203
2022-02-03 00:31:43 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 00:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:37:31 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.36 | ppl 1313.99 | wps 8041.1 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.357
2022-02-03 00:37:31 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 00:37:31 | INFO | train | epoch 189 | loss 5.209 | ppl 36.98 | wps 5998.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.346 | train_wall 320 | gb_free 6.1 | wall 66665
KL Stats: Epoch 189 Divergences: Uniform: 3.018336986045651 Unigram: 5.1483419558444234
2022-02-03 00:37:31 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 00:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:37:51 | INFO | train_inner | epoch 190:      4 / 64 loss=5.218, ppl=37.23, wps=5866.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.335, train_wall=500, gb_free=6.1, wall=66685
2022-02-03 00:42:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:43:20 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.381 | ppl 1333.55 | wps 8078 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.357
2022-02-03 00:43:20 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 00:43:20 | INFO | train | epoch 190 | loss 5.201 | ppl 36.79 | wps 5980.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.357 | train_wall 321 | gb_free 6.1 | wall 67014
KL Stats: Epoch 190 Divergences: Uniform: 3.0202811951643618 Unigram: 5.157466285238253
2022-02-03 00:43:20 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 00:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:46:42 | INFO | train_inner | epoch 191:     40 / 64 loss=5.192, ppl=36.55, wps=6162.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.364, train_wall=502, gb_free=6.1, wall=67215
2022-02-03 00:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:49:08 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.386 | ppl 1337.99 | wps 8084 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.357
2022-02-03 00:49:08 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 00:49:08 | INFO | train | epoch 191 | loss 5.197 | ppl 36.68 | wps 6003.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.376 | train_wall 320 | gb_free 6.1 | wall 67362
KL Stats: Epoch 191 Divergences: Uniform: 3.020971135144968 Unigram: 5.167237962874316
2022-02-03 00:49:08 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 00:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:54:57 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.395 | ppl 1346.7 | wps 8044.1 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.357
2022-02-03 00:54:57 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 00:54:57 | INFO | train | epoch 192 | loss 5.193 | ppl 36.59 | wps 5986.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.377 | train_wall 321 | gb_free 6.1 | wall 67711
KL Stats: Epoch 192 Divergences: Uniform: 3.028680406567048 Unigram: 5.169905332581393
2022-02-03 00:54:57 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 00:54:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:55:58 | INFO | train_inner | epoch 193:     12 / 64 loss=5.199, ppl=36.72, wps=5863.9, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.371, train_wall=500, gb_free=6.1, wall=67771
2022-02-03 01:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:00:45 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.417 | ppl 1366.82 | wps 8062.3 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.357
2022-02-03 01:00:45 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 01:00:45 | INFO | train | epoch 193 | loss 5.188 | ppl 36.46 | wps 5996.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.393 | train_wall 320 | gb_free 6.1 | wall 68059
KL Stats: Epoch 193 Divergences: Uniform: 3.029824647276972 Unigram: 5.182178309161664
2022-02-03 01:00:45 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 01:00:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:04:48 | INFO | train_inner | epoch 194:     48 / 64 loss=5.184, ppl=36.36, wps=6162.4, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.396, train_wall=502, gb_free=6.1, wall=68301
2022-02-03 01:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:06:34 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.402 | ppl 1352.86 | wps 8069.4 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.357
2022-02-03 01:06:34 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 01:06:34 | INFO | train | epoch 194 | loss 5.185 | ppl 36.38 | wps 5985.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.378 | train_wall 321 | gb_free 6.1 | wall 68408
KL Stats: Epoch 194 Divergences: Uniform: 3.031730622330931 Unigram: 5.1853428424542285
2022-02-03 01:06:34 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 01:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:11:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:12:22 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.4 | ppl 1351.03 | wps 8065.8 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.357
2022-02-03 01:12:22 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 01:12:22 | INFO | train | epoch 195 | loss 5.18 | ppl 36.25 | wps 6004.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.363 | train_wall 320 | gb_free 6.1 | wall 68756
KL Stats: Epoch 195 Divergences: Uniform: 3.0229776306677225 Unigram: 5.185917271014271
2022-02-03 01:12:22 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 01:12:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:14:03 | INFO | train_inner | epoch 196:     20 / 64 loss=5.18, ppl=36.26, wps=5870.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.364, train_wall=500, gb_free=6.1, wall=68857
2022-02-03 01:17:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:18:11 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.383 | ppl 1335.06 | wps 8061.6 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.357
2022-02-03 01:18:11 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 01:18:11 | INFO | train | epoch 196 | loss 5.177 | ppl 36.19 | wps 5981.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.39 | train_wall 321 | gb_free 6.1 | wall 69105
KL Stats: Epoch 196 Divergences: Uniform: 3.024253375996921 Unigram: 5.190988179582307
2022-02-03 01:18:11 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 01:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:22:54 | INFO | train_inner | epoch 197:     56 / 64 loss=5.178, ppl=36.19, wps=6162.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.397, train_wall=502, gb_free=6.1, wall=69387
2022-02-03 01:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:24:00 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.38 | ppl 1332.97 | wps 8083.5 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.357
2022-02-03 01:24:00 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 01:24:00 | INFO | train | epoch 197 | loss 5.172 | ppl 36.06 | wps 5998.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.402 | train_wall 320 | gb_free 6.1 | wall 69453
KL Stats: Epoch 197 Divergences: Uniform: 3.0266729844605926 Unigram: 5.201883692980553
2022-02-03 01:24:00 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 01:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:29:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:29:48 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.432 | ppl 1381.58 | wps 8079.9 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.357
2022-02-03 01:29:48 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 01:29:48 | INFO | train | epoch 198 | loss 5.169 | ppl 35.97 | wps 5987.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.482 | train_wall 321 | gb_free 6.1 | wall 69802
KL Stats: Epoch 198 Divergences: Uniform: 3.0271497192882295 Unigram: 5.2049910077189425
2022-02-03 01:29:48 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 01:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:32:09 | INFO | train_inner | epoch 199:     28 / 64 loss=5.161, ppl=35.78, wps=5864.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.472, train_wall=500, gb_free=6.1, wall=69943
2022-02-03 01:35:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:35:36 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.402 | ppl 1353.5 | wps 8083.4 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.357
2022-02-03 01:35:36 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 01:35:36 | INFO | train | epoch 199 | loss 5.164 | ppl 35.86 | wps 6002.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.462 | train_wall 320 | gb_free 6.1 | wall 70150
KL Stats: Epoch 199 Divergences: Uniform: 3.032796714129154 Unigram: 5.211868035756266
2022-02-03 01:35:36 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 01:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:40:58 | INFO | train_inner | epoch 200:     64 / 64 loss=5.172, ppl=36.04, wps=6164.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.445, train_wall=501, gb_free=6.1, wall=70472
2022-02-03 01:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:41:25 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.366 | ppl 1319.32 | wps 8078.8 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.357
2022-02-03 01:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 01:41:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint200.pt
2022-02-03 01:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint200.pt
2022-02-03 01:41:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.11_-0.01_0.9_#1/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.366) (writing took 3.6665921453386545 seconds)
2022-02-03 01:41:29 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 01:41:29 | INFO | train | epoch 200 | loss 5.159 | ppl 35.72 | wps 5923 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.433 | train_wall 321 | gb_free 6.1 | wall 70502
KL Stats: Epoch 200 Divergences: Uniform: 3.0339240861690366 Unigram: 5.226096839202122
2022-02-03 01:41:29 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 01:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:47:17 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.389 | ppl 1340.65 | wps 8047.4 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.357
2022-02-03 01:47:17 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 01:47:17 | INFO | train | epoch 201 | loss 5.156 | ppl 35.64 | wps 6002.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.486 | train_wall 320 | gb_free 6.1 | wall 70850
KL Stats: Epoch 201 Divergences: Uniform: 3.033285319831601 Unigram: 5.227502433025091
2022-02-03 01:47:17 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 01:47:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:50:19 | INFO | train_inner | epoch 202:     36 / 64 loss=5.145, ppl=35.38, wps=5831, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.465, train_wall=501, gb_free=6.1, wall=71032
2022-02-03 01:52:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:53:06 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.418 | ppl 1367.96 | wps 8064 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.357
2022-02-03 01:53:06 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 01:53:06 | INFO | train | epoch 202 | loss 5.151 | ppl 35.53 | wps 5986.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.451 | train_wall 321 | gb_free 6.1 | wall 71199
KL Stats: Epoch 202 Divergences: Uniform: 3.0315892136578446 Unigram: 5.233749796007666
2022-02-03 01:53:06 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 01:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:58:54 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.411 | ppl 1361.34 | wps 8062.2 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.357
2022-02-03 01:58:54 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 01:58:54 | INFO | train | epoch 203 | loss 5.148 | ppl 35.45 | wps 5993.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.501 | train_wall 321 | gb_free 6.1 | wall 71548
KL Stats: Epoch 203 Divergences: Uniform: 3.0340804872754092 Unigram: 5.241155307768082
2022-02-03 01:58:54 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 01:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:59:35 | INFO | train_inner | epoch 204:      8 / 64 loss=5.152, ppl=35.54, wps=5864, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.498, train_wall=500, gb_free=6.1, wall=71588
2022-02-03 02:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:04:43 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.417 | ppl 1367.03 | wps 8079.1 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.357
2022-02-03 02:04:43 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 02:04:43 | INFO | train | epoch 204 | loss 5.143 | ppl 35.34 | wps 5994.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.483 | train_wall 320 | gb_free 6.1 | wall 71896
KL Stats: Epoch 204 Divergences: Uniform: 3.0317747511442534 Unigram: 5.242816312758594
2022-02-03 02:04:43 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 02:04:43 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
