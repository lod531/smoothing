Sender: LSF System <lsfadmin@eu-g3-028>
Subject: Job 207345549: <w103_size_0.0625_fp16_label_smoothing_0.02_#2> in cluster <euler> Done

Job <w103_size_0.0625_fp16_label_smoothing_0.02_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 12:50:40 2022
Job was executed on host(s) <eu-g3-028>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 12:51:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 12:51:15 2022
Terminated at Tue Mar  8 06:08:37 2022
Results reported at Tue Mar  8 06:08:37 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.02 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575612 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147687.89 sec.
    Max Memory :                                 8143 MB
    Average Memory :                             3780.20 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11857.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   148642 sec.
    Turnaround time :                            148677 sec.

The output (if any) follows:

2022-03-06 12:51:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575612, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.02, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 12:51:23 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-06 12:51:25 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 12:51:25 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 12:51:25 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 12:51:25 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-06 12:51:28 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 12:51:28 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 12:51:28 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 12:51:28 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-06 12:51:28 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 12:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:51:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 12:51:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 12:51:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 12:51:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 12:52:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 12:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 12:56:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.609 | nll_loss 14.543 | ppl 23866.9 | wps 44211.3 | wpb 510.9 | bsz 1 | num_updates 92
2022-03-06 12:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 92 updates
2022-03-06 12:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 12:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 12:56:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 1 @ 92 updates, score 14.609) (writing took 5.423498405143619 seconds)
2022-03-06 12:56:38 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 12:56:38 | INFO | train | epoch 001 | loss 16.267 | nll_loss 16.235 | ppl 77114 | wps 21917 | ups 0.33 | wpb 65489.2 | bsz 127.9 | num_updates 92 | lr 1.15977e-05 | gnorm 3.509 | loss_scale 4 | train_wall 277 | gb_free 8.1 | wall 310
2022-03-06 12:56:38 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 12:56:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:57:00 | INFO | train_inner | epoch 002:      8 / 97 loss=16.139, nll_loss=16.104, ppl=70445.2, wps=21994.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=100, lr=1.25975e-05, gnorm=3.372, loss_scale=4, train_wall=298, gb_free=8.1, wall=333
2022-03-06 13:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:01:18 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.863 | nll_loss 12.76 | ppl 6937.52 | wps 44433.7 | wpb 510.9 | bsz 1 | num_updates 189 | best_loss 12.863
2022-03-06 13:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 189 updates
2022-03-06 13:01:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:01:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:01:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 2 @ 189 updates, score 12.863) (writing took 5.51367653766647 seconds)
2022-03-06 13:01:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:01:23 | INFO | train | epoch 002 | loss 13.94 | nll_loss 13.861 | ppl 14882.6 | wps 22224.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 189 | lr 2.37203e-05 | gnorm 1.609 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 596
2022-03-06 13:01:23 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:01:55 | INFO | train_inner | epoch 003:     11 / 97 loss=13.765, nll_loss=13.683, ppl=13150, wps=22253.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=200, lr=2.5095e-05, gnorm=1.564, loss_scale=8, train_wall=261, gb_free=8.1, wall=627
2022-03-06 13:05:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:06:04 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.216 | nll_loss 11.068 | ppl 2147.56 | wps 44564.4 | wpb 510.9 | bsz 1 | num_updates 286 | best_loss 11.216
2022-03-06 13:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 286 updates
2022-03-06 13:06:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:06:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:06:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 3 @ 286 updates, score 11.216) (writing took 5.446631679777056 seconds)
2022-03-06 13:06:09 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:06:09 | INFO | train | epoch 003 | loss 12.093 | nll_loss 11.972 | ppl 4017.49 | wps 22213.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 286 | lr 3.58429e-05 | gnorm 1.065 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 881
2022-03-06 13:06:09 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:06:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:06:49 | INFO | train_inner | epoch 004:     14 / 97 loss=11.881, nll_loss=11.754, ppl=3454.09, wps=22239.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=300, lr=3.75925e-05, gnorm=1, loss_scale=16, train_wall=262, gb_free=8.1, wall=921
2022-03-06 13:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:10:50 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.421 | nll_loss 10.239 | ppl 1208.46 | wps 43789.3 | wpb 510.9 | bsz 1 | num_updates 383 | best_loss 10.421
2022-03-06 13:10:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 383 updates
2022-03-06 13:10:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:10:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 4 @ 383 updates, score 10.421) (writing took 5.336876523215324 seconds)
2022-03-06 13:10:55 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:10:55 | INFO | train | epoch 004 | loss 10.799 | nll_loss 10.636 | ppl 1591.36 | wps 22231.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 383 | lr 4.79654e-05 | gnorm 0.616 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 1167
2022-03-06 13:10:55 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:44 | INFO | train_inner | epoch 005:     17 / 97 loss=10.678, nll_loss=10.51, ppl=1457.79, wps=22250.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=400, lr=5.009e-05, gnorm=0.563, loss_scale=32, train_wall=262, gb_free=8.1, wall=1216
2022-03-06 13:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:15:36 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.063 | nll_loss 9.86 | ppl 928.99 | wps 44375.1 | wpb 510.9 | bsz 1 | num_updates 480 | best_loss 10.063
2022-03-06 13:15:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 480 updates
2022-03-06 13:15:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 5 @ 480 updates, score 10.063) (writing took 5.270452036056668 seconds)
2022-03-06 13:15:41 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:15:41 | INFO | train | epoch 005 | loss 10.243 | nll_loss 10.051 | ppl 1060.88 | wps 22227.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 480 | lr 6.0088e-05 | gnorm 0.497 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 1453
2022-03-06 13:15:41 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:16:38 | INFO | train_inner | epoch 006:     20 / 97 loss=10.168, nll_loss=9.972, ppl=1004.17, wps=22250.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=500, lr=6.25875e-05, gnorm=0.511, loss_scale=32, train_wall=262, gb_free=8.1, wall=1510
2022-03-06 13:17:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:20:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:20:22 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.789 | nll_loss 9.573 | ppl 761.51 | wps 44283.4 | wpb 510.9 | bsz 1 | num_updates 576 | best_loss 9.789
2022-03-06 13:20:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 576 updates
2022-03-06 13:20:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:20:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 6 @ 576 updates, score 9.789) (writing took 5.11631561582908 seconds)
2022-03-06 13:20:27 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:20:27 | INFO | train | epoch 006 | loss 9.908 | nll_loss 9.7 | ppl 831.76 | wps 21992.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 576 | lr 7.20856e-05 | gnorm 0.551 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 1739
2022-03-06 13:20:27 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:21:35 | INFO | train_inner | epoch 007:     24 / 97 loss=9.84, nll_loss=9.629, ppl=791.92, wps=22030.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=600, lr=7.5085e-05, gnorm=0.562, loss_scale=32, train_wall=264, gb_free=8.1, wall=1807
2022-03-06 13:23:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:25:07 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.539 | nll_loss 9.315 | ppl 636.96 | wps 44243.3 | wpb 510.9 | bsz 1 | num_updates 672 | best_loss 9.539
2022-03-06 13:25:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 672 updates
2022-03-06 13:25:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:25:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 7 @ 672 updates, score 9.539) (writing took 5.021376448217779 seconds)
2022-03-06 13:25:12 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:25:12 | INFO | train | epoch 007 | loss 9.624 | nll_loss 9.405 | ppl 677.89 | wps 22014.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 672 | lr 8.40832e-05 | gnorm 0.603 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2025
2022-03-06 13:25:12 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:26:32 | INFO | train_inner | epoch 008:     28 / 97 loss=9.551, nll_loss=9.329, ppl=643.31, wps=22060.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=700, lr=8.75825e-05, gnorm=0.638, loss_scale=32, train_wall=264, gb_free=8.1, wall=2104
2022-03-06 13:29:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:29:53 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.316 | nll_loss 9.084 | ppl 542.7 | wps 44371.3 | wpb 510.9 | bsz 1 | num_updates 769 | best_loss 9.316
2022-03-06 13:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 769 updates
2022-03-06 13:29:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:29:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:29:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 8 @ 769 updates, score 9.316) (writing took 5.0453254529275 seconds)
2022-03-06 13:29:58 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:29:58 | INFO | train | epoch 008 | loss 9.36 | nll_loss 9.132 | ppl 560.92 | wps 22243.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 769 | lr 9.62058e-05 | gnorm 0.711 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2310
2022-03-06 13:29:58 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:30:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:31:29 | INFO | train_inner | epoch 009:     32 / 97 loss=9.282, nll_loss=9.051, ppl=530.36, wps=22055.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=800, lr=0.00010008, gnorm=0.745, loss_scale=32, train_wall=264, gb_free=8.1, wall=2401
2022-03-06 13:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:34:38 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.119 | nll_loss 8.879 | ppl 470.88 | wps 44409 | wpb 510.9 | bsz 1 | num_updates 865 | best_loss 9.119
2022-03-06 13:34:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 865 updates
2022-03-06 13:34:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:34:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 9 @ 865 updates, score 9.119) (writing took 5.0925235310569406 seconds)
2022-03-06 13:34:44 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:34:44 | INFO | train | epoch 009 | loss 9.116 | nll_loss 8.879 | ppl 470.88 | wps 22021 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 865 | lr 0.000108203 | gnorm 0.799 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2596
2022-03-06 13:34:44 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:36:23 | INFO | train_inner | epoch 010:     35 / 97 loss=9.037, nll_loss=8.797, ppl=444.82, wps=22274.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=900, lr=0.000112578, gnorm=0.812, loss_scale=32, train_wall=262, gb_free=8.1, wall=2695
2022-03-06 13:36:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:39:24 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.922 | nll_loss 8.671 | ppl 407.68 | wps 44365.1 | wpb 510.9 | bsz 1 | num_updates 961 | best_loss 8.922
2022-03-06 13:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 961 updates
2022-03-06 13:39:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:39:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:39:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 10 @ 961 updates, score 8.922) (writing took 4.994125965051353 seconds)
2022-03-06 13:39:29 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:39:29 | INFO | train | epoch 010 | loss 8.894 | nll_loss 8.648 | ppl 401.27 | wps 22030 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 961 | lr 0.000120201 | gnorm 0.845 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2881
2022-03-06 13:39:29 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:41:20 | INFO | train_inner | epoch 011:     39 / 97 loss=8.814, nll_loss=8.566, ppl=378.91, wps=22066.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=1000, lr=0.000125075, gnorm=0.878, loss_scale=32, train_wall=264, gb_free=8.1, wall=2992
2022-03-06 13:43:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:44:10 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.767 | nll_loss 8.513 | ppl 365.42 | wps 44217.9 | wpb 510.9 | bsz 1 | num_updates 1057 | best_loss 8.767
2022-03-06 13:44:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1057 updates
2022-03-06 13:44:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 11 @ 1057 updates, score 8.767) (writing took 4.976533887907863 seconds)
2022-03-06 13:44:15 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:44:15 | INFO | train | epoch 011 | loss 8.691 | nll_loss 8.438 | ppl 346.84 | wps 22012.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1057 | lr 0.000132199 | gnorm 0.917 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3167
2022-03-06 13:44:15 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:46:17 | INFO | train_inner | epoch 012:     43 / 97 loss=8.606, nll_loss=8.351, ppl=326.4, wps=22051.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=1100, lr=0.000137573, gnorm=0.906, loss_scale=32, train_wall=264, gb_free=8.1, wall=3289
2022-03-06 13:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:48:55 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.624 | nll_loss 8.362 | ppl 328.98 | wps 44485.6 | wpb 510.9 | bsz 1 | num_updates 1154 | best_loss 8.624
2022-03-06 13:48:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1154 updates
2022-03-06 13:48:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:48:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:49:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 12 @ 1154 updates, score 8.624) (writing took 4.906406907830387 seconds)
2022-03-06 13:49:00 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:49:00 | INFO | train | epoch 012 | loss 8.503 | nll_loss 8.244 | ppl 303.12 | wps 22256.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1154 | lr 0.000144321 | gnorm 0.901 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3452
2022-03-06 13:49:00 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:49:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:51:14 | INFO | train_inner | epoch 013:     47 / 97 loss=8.424, nll_loss=8.162, ppl=286.49, wps=22054.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1200, lr=0.00015007, gnorm=0.902, loss_scale=32, train_wall=264, gb_free=8.1, wall=3586
2022-03-06 13:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:53:41 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.497 | nll_loss 8.232 | ppl 300.69 | wps 44506 | wpb 510.9 | bsz 1 | num_updates 1250 | best_loss 8.497
2022-03-06 13:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1250 updates
2022-03-06 13:53:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:53:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 13 @ 1250 updates, score 8.497) (writing took 4.927841059863567 seconds)
2022-03-06 13:53:46 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:53:46 | INFO | train | epoch 013 | loss 8.328 | nll_loss 8.062 | ppl 267.3 | wps 22012.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1250 | lr 0.000156319 | gnorm 0.913 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3738
2022-03-06 13:53:46 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:08 | INFO | train_inner | epoch 014:     50 / 97 loss=8.236, nll_loss=7.967, ppl=250.27, wps=22280.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1300, lr=0.000162568, gnorm=0.929, loss_scale=64, train_wall=262, gb_free=8.1, wall=3880
2022-03-06 13:56:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:58:26 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.386 | nll_loss 8.116 | ppl 277.34 | wps 44319.7 | wpb 510.9 | bsz 1 | num_updates 1346 | best_loss 8.386
2022-03-06 13:58:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1346 updates
2022-03-06 13:58:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:58:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 13:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 14 @ 1346 updates, score 8.386) (writing took 4.988848935812712 seconds)
2022-03-06 13:58:31 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:58:31 | INFO | train | epoch 014 | loss 8.163 | nll_loss 7.891 | ppl 237.4 | wps 22026.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1346 | lr 0.000168316 | gnorm 0.94 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4023
2022-03-06 13:58:31 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:01:05 | INFO | train_inner | epoch 015:     54 / 97 loss=8.081, nll_loss=7.807, ppl=223.95, wps=22053.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1400, lr=0.000175065, gnorm=0.956, loss_scale=32, train_wall=264, gb_free=8.1, wall=4177
2022-03-06 14:03:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:03:12 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.28 | nll_loss 8.006 | ppl 257.01 | wps 44514.5 | wpb 510.9 | bsz 1 | num_updates 1443 | best_loss 8.28
2022-03-06 14:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1443 updates
2022-03-06 14:03:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:03:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 15 @ 1443 updates, score 8.28) (writing took 4.92730107717216 seconds)
2022-03-06 14:03:17 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 14:03:17 | INFO | train | epoch 015 | loss 8.002 | nll_loss 7.725 | ppl 211.53 | wps 22226.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1443 | lr 0.000180439 | gnorm 0.945 | loss_scale 64 | train_wall 254 | gb_free 8.1 | wall 4309
2022-03-06 14:03:17 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 14:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:04:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:06:02 | INFO | train_inner | epoch 016:     58 / 97 loss=7.906, nll_loss=7.626, ppl=197.5, wps=22055.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1500, lr=0.000187563, gnorm=0.947, loss_scale=32, train_wall=264, gb_free=8.1, wall=4474
2022-03-06 14:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:07:57 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.187 | nll_loss 7.907 | ppl 240.07 | wps 44510.9 | wpb 510.9 | bsz 1 | num_updates 1539 | best_loss 8.187
2022-03-06 14:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1539 updates
2022-03-06 14:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 16 @ 1539 updates, score 8.187) (writing took 4.865302951075137 seconds)
2022-03-06 14:08:02 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 14:08:02 | INFO | train | epoch 016 | loss 7.842 | nll_loss 7.559 | ppl 188.61 | wps 22041 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1539 | lr 0.000192437 | gnorm 0.952 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4594
2022-03-06 14:08:02 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 14:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:10:56 | INFO | train_inner | epoch 017:     61 / 97 loss=7.743, nll_loss=7.457, ppl=175.72, wps=22285.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1600, lr=0.00020006, gnorm=0.959, loss_scale=64, train_wall=262, gb_free=8.1, wall=4768
2022-03-06 14:11:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:12:43 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.108 | nll_loss 7.823 | ppl 226.43 | wps 44304 | wpb 510.9 | bsz 1 | num_updates 1635 | best_loss 8.108
2022-03-06 14:12:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1635 updates
2022-03-06 14:12:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:12:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 17 @ 1635 updates, score 8.108) (writing took 4.868551817722619 seconds)
2022-03-06 14:12:48 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 14:12:48 | INFO | train | epoch 017 | loss 7.688 | nll_loss 7.4 | ppl 168.87 | wps 22027.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1635 | lr 0.000204434 | gnorm 0.968 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4880
2022-03-06 14:12:48 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 14:12:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:15:52 | INFO | train_inner | epoch 018:     65 / 97 loss=7.586, nll_loss=7.294, ppl=156.94, wps=22061.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1700, lr=0.000212558, gnorm=0.949, loss_scale=32, train_wall=264, gb_free=8.1, wall=5065
2022-03-06 14:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:17:28 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.014 | nll_loss 7.722 | ppl 211.13 | wps 44215.3 | wpb 510.9 | bsz 1 | num_updates 1732 | best_loss 8.014
2022-03-06 14:17:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1732 updates
2022-03-06 14:17:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:17:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 18 @ 1732 updates, score 8.014) (writing took 4.88466827897355 seconds)
2022-03-06 14:17:33 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 14:17:33 | INFO | train | epoch 018 | loss 7.534 | nll_loss 7.241 | ppl 151.22 | wps 22243.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1732 | lr 0.000216557 | gnorm 0.943 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 5165
2022-03-06 14:17:33 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 14:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:20:50 | INFO | train_inner | epoch 019:     69 / 97 loss=7.433, nll_loss=7.136, ppl=140.66, wps=22048.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1800, lr=0.000225055, gnorm=0.928, loss_scale=32, train_wall=264, gb_free=8.1, wall=5362
2022-03-06 14:21:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:22:14 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.96 | nll_loss 7.665 | ppl 202.89 | wps 44568.7 | wpb 510.9 | bsz 1 | num_updates 1827 | best_loss 7.96
2022-03-06 14:22:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1827 updates
2022-03-06 14:22:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:22:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 19 @ 1827 updates, score 7.96) (writing took 4.952054733876139 seconds)
2022-03-06 14:22:19 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 14:22:19 | INFO | train | epoch 019 | loss 7.385 | nll_loss 7.086 | ppl 135.83 | wps 21786 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 1827 | lr 0.000228429 | gnorm 0.953 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 5451
2022-03-06 14:22:19 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 14:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:25:46 | INFO | train_inner | epoch 020:     73 / 97 loss=7.278, nll_loss=6.975, ppl=125.81, wps=22068.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=1900, lr=0.000237553, gnorm=0.973, loss_scale=16, train_wall=264, gb_free=8.1, wall=5658
2022-03-06 14:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:26:59 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.899 | nll_loss 7.603 | ppl 194.39 | wps 44375.4 | wpb 510.9 | bsz 1 | num_updates 1924 | best_loss 7.899
2022-03-06 14:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1924 updates
2022-03-06 14:26:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:27:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 20 @ 1924 updates, score 7.899) (writing took 4.848392712883651 seconds)
2022-03-06 14:27:04 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:27:04 | INFO | train | epoch 020 | loss 7.239 | nll_loss 6.935 | ppl 122.37 | wps 22259 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1924 | lr 0.000240552 | gnorm 0.95 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 5736
2022-03-06 14:27:04 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:30:40 | INFO | train_inner | epoch 021:     76 / 97 loss=7.129, nll_loss=6.82, ppl=113.01, wps=22271.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=2000, lr=0.00025005, gnorm=0.934, loss_scale=32, train_wall=262, gb_free=8.1, wall=5952
2022-03-06 14:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:31:45 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.838 | nll_loss 7.537 | ppl 185.76 | wps 44214.5 | wpb 510.9 | bsz 1 | num_updates 2021 | best_loss 7.838
2022-03-06 14:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2021 updates
2022-03-06 14:31:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:31:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 21 @ 2021 updates, score 7.838) (writing took 4.829595926217735 seconds)
2022-03-06 14:31:50 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:31:50 | INFO | train | epoch 021 | loss 7.096 | nll_loss 6.786 | ppl 110.36 | wps 22247.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2021 | lr 0.000252674 | gnorm 0.947 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6022
2022-03-06 14:31:50 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:34:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:35:37 | INFO | train_inner | epoch 022:     80 / 97 loss=6.989, nll_loss=6.675, ppl=102.21, wps=22067.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2100, lr=0.000262548, gnorm=0.968, loss_scale=32, train_wall=264, gb_free=8.1, wall=6249
2022-03-06 14:36:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:36:30 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.769 | nll_loss 7.464 | ppl 176.51 | wps 44528.7 | wpb 510.9 | bsz 1 | num_updates 2117 | best_loss 7.769
2022-03-06 14:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2117 updates
2022-03-06 14:36:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:36:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 22 @ 2117 updates, score 7.769) (writing took 4.95554958935827 seconds)
2022-03-06 14:36:35 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:36:35 | INFO | train | epoch 022 | loss 6.957 | nll_loss 6.643 | ppl 99.91 | wps 22024.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2117 | lr 0.000264672 | gnorm 0.96 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6307
2022-03-06 14:36:35 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:31 | INFO | train_inner | epoch 023:     83 / 97 loss=6.845, nll_loss=6.526, ppl=92.14, wps=22278.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2200, lr=0.000275045, gnorm=0.94, loss_scale=32, train_wall=262, gb_free=8.1, wall=6543
2022-03-06 14:41:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:41:16 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.752 | nll_loss 7.448 | ppl 174.62 | wps 44528.7 | wpb 510.9 | bsz 1 | num_updates 2214 | best_loss 7.752
2022-03-06 14:41:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2214 updates
2022-03-06 14:41:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:41:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:41:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 23 @ 2214 updates, score 7.752) (writing took 4.8439953392371535 seconds)
2022-03-06 14:41:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:41:20 | INFO | train | epoch 023 | loss 6.824 | nll_loss 6.504 | ppl 90.78 | wps 22261.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2214 | lr 0.000276795 | gnorm 0.947 | loss_scale 64 | train_wall 254 | gb_free 8.1 | wall 6593
2022-03-06 14:41:21 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:41:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:45:28 | INFO | train_inner | epoch 024:     87 / 97 loss=6.712, nll_loss=6.388, ppl=83.75, wps=22069.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2300, lr=0.000287543, gnorm=0.944, loss_scale=32, train_wall=264, gb_free=8.1, wall=6840
2022-03-06 14:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:46:01 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.718 | nll_loss 7.411 | ppl 170.19 | wps 44283.7 | wpb 510.9 | bsz 1 | num_updates 2310 | best_loss 7.718
2022-03-06 14:46:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2310 updates
2022-03-06 14:46:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:46:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 24 @ 2310 updates, score 7.718) (writing took 4.845688758883625 seconds)
2022-03-06 14:46:06 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:46:06 | INFO | train | epoch 024 | loss 6.691 | nll_loss 6.366 | ppl 82.46 | wps 22024.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2310 | lr 0.000288792 | gnorm 0.944 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6878
2022-03-06 14:46:06 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:48:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:50:25 | INFO | train_inner | epoch 025:     91 / 97 loss=6.574, nll_loss=6.244, ppl=75.8, wps=22058.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2400, lr=0.00030004, gnorm=0.97, loss_scale=32, train_wall=264, gb_free=8.1, wall=7137
2022-03-06 14:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:50:47 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.736 | nll_loss 7.426 | ppl 171.97 | wps 44629.9 | wpb 510.9 | bsz 1 | num_updates 2406 | best_loss 7.718
2022-03-06 14:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2406 updates
2022-03-06 14:50:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 14:50:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 14:50:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 25 @ 2406 updates, score 7.736) (writing took 2.0946118109859526 seconds)
2022-03-06 14:50:49 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:50:49 | INFO | train | epoch 025 | loss 6.567 | nll_loss 6.237 | ppl 75.45 | wps 22238 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2406 | lr 0.00030079 | gnorm 0.966 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 7161
2022-03-06 14:50:49 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:55:16 | INFO | train_inner | epoch 026:     94 / 97 loss=6.452, nll_loss=6.118, ppl=69.44, wps=22512.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2500, lr=0.000312538, gnorm=0.965, loss_scale=64, train_wall=262, gb_free=8.1, wall=7428
2022-03-06 14:55:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:55:29 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.706 | nll_loss 7.394 | ppl 168.14 | wps 44420.7 | wpb 510.9 | bsz 1 | num_updates 2503 | best_loss 7.706
2022-03-06 14:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2503 updates
2022-03-06 14:55:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt
2022-03-06 14:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_best.pt (epoch 26 @ 2503 updates, score 7.706) (writing took 4.5873188292607665 seconds)
2022-03-06 14:55:34 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:55:34 | INFO | train | epoch 026 | loss 6.443 | nll_loss 6.109 | ppl 69 | wps 22296.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2503 | lr 0.000312912 | gnorm 0.965 | loss_scale 64 | train_wall 254 | gb_free 8.1 | wall 7446
2022-03-06 14:55:34 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:55:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:59:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:00:14 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.765 | nll_loss 7.452 | ppl 175.14 | wps 44376.3 | wpb 510.9 | bsz 1 | num_updates 2598 | best_loss 7.706
2022-03-06 15:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2598 updates
2022-03-06 15:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 27 @ 2598 updates, score 7.765) (writing took 2.176736888010055 seconds)
2022-03-06 15:00:16 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 15:00:16 | INFO | train | epoch 027 | loss 6.322 | nll_loss 5.983 | ppl 63.25 | wps 22017 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 2598 | lr 0.000324785 | gnorm 0.986 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 7728
2022-03-06 15:00:16 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 15:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:22 | INFO | train_inner | epoch 028:      2 / 97 loss=6.324, nll_loss=5.985, ppl=63.33, wps=21370.2, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=2600, lr=0.000325035, gnorm=0.981, loss_scale=16, train_wall=267, gb_free=8.1, wall=7734
2022-03-06 15:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:04:57 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.726 | nll_loss 7.413 | ppl 170.38 | wps 43708.8 | wpb 510.9 | bsz 1 | num_updates 2695 | best_loss 7.706
2022-03-06 15:04:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2695 updates
2022-03-06 15:04:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:04:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 28 @ 2695 updates, score 7.726) (writing took 2.114996908698231 seconds)
2022-03-06 15:04:59 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:04:59 | INFO | train | epoch 028 | loss 6.205 | nll_loss 5.861 | ppl 58.13 | wps 22482.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2695 | lr 0.000336908 | gnorm 0.952 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 8011
2022-03-06 15:04:59 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:05:13 | INFO | train_inner | epoch 029:      5 / 97 loss=6.198, nll_loss=5.854, ppl=57.83, wps=22502.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2700, lr=0.000337533, gnorm=0.951, loss_scale=16, train_wall=262, gb_free=8.1, wall=8025
2022-03-06 15:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:09:39 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.792 | nll_loss 7.479 | ppl 178.39 | wps 44286.9 | wpb 510.9 | bsz 1 | num_updates 2792 | best_loss 7.706
2022-03-06 15:09:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2792 updates
2022-03-06 15:09:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:09:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 29 @ 2792 updates, score 7.792) (writing took 2.0868085171096027 seconds)
2022-03-06 15:09:42 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:09:42 | INFO | train | epoch 029 | loss 6.091 | nll_loss 5.742 | ppl 53.52 | wps 22460.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2792 | lr 0.00034903 | gnorm 0.982 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 8294
2022-03-06 15:09:42 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:10:04 | INFO | train_inner | epoch 030:      8 / 97 loss=6.081, nll_loss=5.731, ppl=53.12, wps=22477.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2800, lr=0.00035003, gnorm=0.981, loss_scale=32, train_wall=262, gb_free=8.1, wall=8316
2022-03-06 15:12:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:13:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:14:22 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.794 | nll_loss 7.475 | ppl 177.87 | wps 44375.9 | wpb 510.9 | bsz 1 | num_updates 2887 | best_loss 7.706
2022-03-06 15:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2887 updates
2022-03-06 15:14:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:14:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:14:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 30 @ 2887 updates, score 7.794) (writing took 2.1289982739835978 seconds)
2022-03-06 15:14:25 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:14:25 | INFO | train | epoch 030 | loss 5.979 | nll_loss 5.626 | ppl 49.38 | wps 21985.1 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 2887 | lr 0.000360903 | gnorm 1.036 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 8577
2022-03-06 15:14:25 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:14:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:02 | INFO | train_inner | epoch 031:     13 / 97 loss=5.961, nll_loss=5.607, ppl=48.75, wps=22036.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2900, lr=0.000362528, gnorm=1.032, loss_scale=16, train_wall=267, gb_free=8.1, wall=8614
2022-03-06 15:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:19:05 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.832 | nll_loss 7.519 | ppl 183.39 | wps 44343.2 | wpb 510.9 | bsz 1 | num_updates 2984 | best_loss 7.706
2022-03-06 15:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 2984 updates
2022-03-06 15:19:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 31 @ 2984 updates, score 7.832) (writing took 2.1563931358978152 seconds)
2022-03-06 15:19:08 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:19:08 | INFO | train | epoch 031 | loss 5.866 | nll_loss 5.508 | ppl 45.51 | wps 22442.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2984 | lr 0.000373025 | gnorm 0.976 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 8860
2022-03-06 15:19:08 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:19:53 | INFO | train_inner | epoch 032:     16 / 97 loss=5.849, nll_loss=5.49, ppl=44.95, wps=22460.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3000, lr=0.000375025, gnorm=0.974, loss_scale=16, train_wall=262, gb_free=8.1, wall=8905
2022-03-06 15:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:23:48 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.859 | nll_loss 7.541 | ppl 186.19 | wps 44481.3 | wpb 510.9 | bsz 1 | num_updates 3081 | best_loss 7.706
2022-03-06 15:23:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3081 updates
2022-03-06 15:23:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:23:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:23:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 32 @ 3081 updates, score 7.859) (writing took 2.1590441772714257 seconds)
2022-03-06 15:23:50 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:23:50 | INFO | train | epoch 032 | loss 5.757 | nll_loss 5.394 | ppl 42.05 | wps 22465.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3081 | lr 0.000385148 | gnorm 1 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 9142
2022-03-06 15:23:50 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:24:44 | INFO | train_inner | epoch 033:     19 / 97 loss=5.737, nll_loss=5.373, ppl=41.45, wps=22483.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3100, lr=0.000387523, gnorm=1.035, loss_scale=32, train_wall=262, gb_free=8.1, wall=9197
2022-03-06 15:26:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:28:31 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.877 | nll_loss 7.555 | ppl 188.01 | wps 44282.7 | wpb 510.9 | bsz 1 | num_updates 3177 | best_loss 7.706
2022-03-06 15:28:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3177 updates
2022-03-06 15:28:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:28:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 33 @ 3177 updates, score 7.877) (writing took 2.1813714941963553 seconds)
2022-03-06 15:28:33 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:28:33 | INFO | train | epoch 033 | loss 5.647 | nll_loss 5.28 | ppl 38.85 | wps 22245.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3177 | lr 0.000397146 | gnorm 1.02 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 9425
2022-03-06 15:28:33 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:29:38 | INFO | train_inner | epoch 034:     23 / 97 loss=5.619, nll_loss=5.25, ppl=38.06, wps=22279.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3200, lr=0.00040002, gnorm=1.007, loss_scale=32, train_wall=264, gb_free=8.1, wall=9491
2022-03-06 15:32:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:33:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:33:13 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.967 | nll_loss 7.642 | ppl 199.71 | wps 44589.6 | wpb 510.9 | bsz 1 | num_updates 3272 | best_loss 7.706
2022-03-06 15:33:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3272 updates
2022-03-06 15:33:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:33:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 34 @ 3272 updates, score 7.967) (writing took 2.133171979803592 seconds)
2022-03-06 15:33:16 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:33:16 | INFO | train | epoch 034 | loss 5.544 | nll_loss 5.172 | ppl 36.05 | wps 22024.9 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 3272 | lr 0.000409018 | gnorm 1.056 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 9708
2022-03-06 15:33:16 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:33:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:34:35 | INFO | train_inner | epoch 035:     28 / 97 loss=5.509, nll_loss=5.135, ppl=35.14, wps=22074.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3300, lr=0.000412518, gnorm=1.055, loss_scale=16, train_wall=267, gb_free=8.1, wall=9787
2022-03-06 15:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:37:56 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.953 | nll_loss 7.627 | ppl 197.63 | wps 44293.6 | wpb 510.9 | bsz 1 | num_updates 3369 | best_loss 7.706
2022-03-06 15:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3369 updates
2022-03-06 15:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:37:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:37:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 35 @ 3369 updates, score 7.953) (writing took 2.1826368058100343 seconds)
2022-03-06 15:37:58 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:37:58 | INFO | train | epoch 035 | loss 5.442 | nll_loss 5.065 | ppl 33.47 | wps 22469.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3369 | lr 0.000421141 | gnorm 1.059 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 9990
2022-03-06 15:37:58 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:39:26 | INFO | train_inner | epoch 036:     31 / 97 loss=5.41, nll_loss=5.031, ppl=32.71, wps=22479.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3400, lr=0.000425015, gnorm=1.045, loss_scale=32, train_wall=262, gb_free=8.1, wall=10079
2022-03-06 15:39:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:42:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:42:39 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.006 | nll_loss 7.683 | ppl 205.45 | wps 44437.4 | wpb 510.9 | bsz 1 | num_updates 3465 | best_loss 7.706
2022-03-06 15:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3465 updates
2022-03-06 15:42:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:42:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:42:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 36 @ 3465 updates, score 8.006) (writing took 2.2202641326002777 seconds)
2022-03-06 15:42:41 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:42:41 | INFO | train | epoch 036 | loss 5.335 | nll_loss 4.953 | ppl 30.98 | wps 22234.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3465 | lr 0.000433138 | gnorm 1.06 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 10273
2022-03-06 15:42:41 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:42:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:44:21 | INFO | train_inner | epoch 037:     35 / 97 loss=5.3, nll_loss=4.916, ppl=30.19, wps=22257.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3500, lr=0.000437513, gnorm=1.068, loss_scale=16, train_wall=264, gb_free=8.1, wall=10373
2022-03-06 15:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:47:22 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.003 | nll_loss 7.677 | ppl 204.64 | wps 44252.6 | wpb 510.9 | bsz 1 | num_updates 3562 | best_loss 7.706
2022-03-06 15:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3562 updates
2022-03-06 15:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:47:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 37 @ 3562 updates, score 8.003) (writing took 2.193136758171022 seconds)
2022-03-06 15:47:24 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:47:24 | INFO | train | epoch 037 | loss 5.233 | nll_loss 4.847 | ppl 28.78 | wps 22449.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3562 | lr 0.000445261 | gnorm 1.053 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 10556
2022-03-06 15:47:24 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:47:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:49:12 | INFO | train_inner | epoch 038:     38 / 97 loss=5.192, nll_loss=4.803, ppl=27.92, wps=22476.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3600, lr=0.00045001, gnorm=1.095, loss_scale=32, train_wall=262, gb_free=8.1, wall=10664
2022-03-06 15:51:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:52:05 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.063 | nll_loss 7.734 | ppl 212.86 | wps 44080.9 | wpb 510.9 | bsz 1 | num_updates 3658 | best_loss 7.706
2022-03-06 15:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3658 updates
2022-03-06 15:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:52:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:52:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 38 @ 3658 updates, score 8.063) (writing took 2.120844278950244 seconds)
2022-03-06 15:52:07 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:52:07 | INFO | train | epoch 038 | loss 5.134 | nll_loss 4.742 | ppl 26.76 | wps 22229.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3658 | lr 0.000457259 | gnorm 1.111 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 10839
2022-03-06 15:52:07 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:52:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:54:09 | INFO | train_inner | epoch 039:     43 / 97 loss=5.095, nll_loss=4.702, ppl=26.03, wps=22052.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=3700, lr=0.000462508, gnorm=1.082, loss_scale=16, train_wall=267, gb_free=8.1, wall=10961
2022-03-06 15:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:56:47 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.118 | nll_loss 7.785 | ppl 220.57 | wps 44655.7 | wpb 510.9 | bsz 1 | num_updates 3754 | best_loss 7.706
2022-03-06 15:56:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3754 updates
2022-03-06 15:56:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:56:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 15:56:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 39 @ 3754 updates, score 8.118) (writing took 2.1978650693781674 seconds)
2022-03-06 15:56:49 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:56:49 | INFO | train | epoch 039 | loss 5.036 | nll_loss 4.64 | ppl 24.93 | wps 22244.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3754 | lr 0.000469256 | gnorm 1.109 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11122
2022-03-06 15:56:49 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:56:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:59:00 | INFO | train_inner | epoch 040:     46 / 97 loss=4.985, nll_loss=4.587, ppl=24.03, wps=22499.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3800, lr=0.000475005, gnorm=1.108, loss_scale=32, train_wall=262, gb_free=8.1, wall=11252
2022-03-06 15:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:01:30 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.165 | nll_loss 7.834 | ppl 228.21 | wps 44419.4 | wpb 510.9 | bsz 1 | num_updates 3850 | best_loss 7.706
2022-03-06 16:01:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3850 updates
2022-03-06 16:01:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:01:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 40 @ 3850 updates, score 8.165) (writing took 2.112358928192407 seconds)
2022-03-06 16:01:32 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 16:01:32 | INFO | train | epoch 040 | loss 4.941 | nll_loss 4.54 | ppl 23.27 | wps 22257 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3850 | lr 0.000481254 | gnorm 1.109 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11404
2022-03-06 16:01:32 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 16:01:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:03:54 | INFO | train_inner | epoch 041:     50 / 97 loss=4.895, nll_loss=4.492, ppl=22.51, wps=22281.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3900, lr=0.000487503, gnorm=1.144, loss_scale=16, train_wall=264, gb_free=8.1, wall=11546
2022-03-06 16:06:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:06:12 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.281 | nll_loss 7.937 | ppl 245.11 | wps 44016.6 | wpb 510.9 | bsz 1 | num_updates 3946 | best_loss 7.706
2022-03-06 16:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 3946 updates
2022-03-06 16:06:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:06:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:06:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 41 @ 3946 updates, score 8.281) (writing took 2.1281969379633665 seconds)
2022-03-06 16:06:15 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:06:15 | INFO | train | epoch 041 | loss 4.845 | nll_loss 4.439 | ppl 21.69 | wps 22241.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3946 | lr 0.000493251 | gnorm 1.15 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11687
2022-03-06 16:06:15 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:08:48 | INFO | train_inner | epoch 042:     54 / 97 loss=4.793, nll_loss=4.385, ppl=20.89, wps=22259.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=4000, lr=0.0005, gnorm=1.108, loss_scale=16, train_wall=264, gb_free=8.1, wall=11840
2022-03-06 16:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:10:55 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.315 | nll_loss 7.981 | ppl 252.68 | wps 44372.5 | wpb 510.9 | bsz 1 | num_updates 4043 | best_loss 7.706
2022-03-06 16:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4043 updates
2022-03-06 16:10:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 42 @ 4043 updates, score 8.315) (writing took 2.157768421806395 seconds)
2022-03-06 16:10:58 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:10:58 | INFO | train | epoch 042 | loss 4.749 | nll_loss 4.339 | ppl 20.24 | wps 22453.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4043 | lr 0.000497334 | gnorm 1.101 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11970
2022-03-06 16:10:58 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:13:40 | INFO | train_inner | epoch 043:     57 / 97 loss=4.691, nll_loss=4.278, ppl=19.4, wps=22479.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4100, lr=0.000493865, gnorm=1.128, loss_scale=32, train_wall=262, gb_free=8.1, wall=12132
2022-03-06 16:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:15:38 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.359 | nll_loss 8.023 | ppl 260.07 | wps 44321.5 | wpb 510.9 | bsz 1 | num_updates 4140 | best_loss 7.706
2022-03-06 16:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4140 updates
2022-03-06 16:15:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:15:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 43 @ 4140 updates, score 8.359) (writing took 2.1424598381854594 seconds)
2022-03-06 16:15:40 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:15:40 | INFO | train | epoch 043 | loss 4.649 | nll_loss 4.234 | ppl 18.81 | wps 22465.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4140 | lr 0.000491473 | gnorm 1.126 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 12252
2022-03-06 16:15:40 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:15:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:18:31 | INFO | train_inner | epoch 044:     60 / 97 loss=4.587, nll_loss=4.168, ppl=17.98, wps=22486.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4200, lr=0.00048795, gnorm=1.105, loss_scale=64, train_wall=262, gb_free=8.1, wall=12423
2022-03-06 16:18:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:20:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:20:21 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.432 | nll_loss 8.09 | ppl 272.57 | wps 44257.5 | wpb 510.9 | bsz 1 | num_updates 4236 | best_loss 7.706
2022-03-06 16:20:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4236 updates
2022-03-06 16:20:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:20:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:20:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 44 @ 4236 updates, score 8.432) (writing took 2.1441621822305024 seconds)
2022-03-06 16:20:23 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:20:23 | INFO | train | epoch 044 | loss 4.544 | nll_loss 4.124 | ppl 17.44 | wps 22243.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4236 | lr 0.000485872 | gnorm 1.098 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 12535
2022-03-06 16:20:23 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:20:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:21:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:23:28 | INFO | train_inner | epoch 045:     65 / 97 loss=4.486, nll_loss=4.062, ppl=16.71, wps=22058.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4300, lr=0.000482243, gnorm=1.1, loss_scale=16, train_wall=267, gb_free=8.1, wall=12720
2022-03-06 16:24:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:25:04 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.509 | nll_loss 8.164 | ppl 286.88 | wps 43997 | wpb 510.9 | bsz 1 | num_updates 4332 | best_loss 7.706
2022-03-06 16:25:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4332 updates
2022-03-06 16:25:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:25:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 45 @ 4332 updates, score 8.509) (writing took 2.1894507501274347 seconds)
2022-03-06 16:25:06 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:25:06 | INFO | train | epoch 045 | loss 4.448 | nll_loss 4.023 | ppl 16.26 | wps 22229.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4332 | lr 0.000480458 | gnorm 1.095 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 12818
2022-03-06 16:25:06 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:28:19 | INFO | train_inner | epoch 046:     68 / 97 loss=4.386, nll_loss=3.958, ppl=15.54, wps=22485.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4400, lr=0.000476731, gnorm=1.086, loss_scale=32, train_wall=262, gb_free=8.1, wall=13011
2022-03-06 16:29:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:29:46 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.581 | nll_loss 8.236 | ppl 301.51 | wps 44426.8 | wpb 510.9 | bsz 1 | num_updates 4428 | best_loss 7.706
2022-03-06 16:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4428 updates
2022-03-06 16:29:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:29:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 46 @ 4428 updates, score 8.581) (writing took 2.138706945348531 seconds)
2022-03-06 16:29:48 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:29:48 | INFO | train | epoch 046 | loss 4.359 | nll_loss 3.93 | ppl 15.24 | wps 22246.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4428 | lr 0.000475222 | gnorm 1.099 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13100
2022-03-06 16:29:48 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:33:13 | INFO | train_inner | epoch 047:     72 / 97 loss=4.297, nll_loss=3.864, ppl=14.56, wps=22262.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4500, lr=0.000471405, gnorm=1.091, loss_scale=16, train_wall=264, gb_free=8.1, wall=13305
2022-03-06 16:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:34:29 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.644 | nll_loss 8.305 | ppl 316.33 | wps 43956.4 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 7.706
2022-03-06 16:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4525 updates
2022-03-06 16:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 47 @ 4525 updates, score 8.644) (writing took 2.146221143193543 seconds)
2022-03-06 16:34:31 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:34:31 | INFO | train | epoch 047 | loss 4.269 | nll_loss 3.834 | ppl 14.26 | wps 22443 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4525 | lr 0.0004701 | gnorm 1.074 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13384
2022-03-06 16:34:31 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:37:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:38:08 | INFO | train_inner | epoch 048:     76 / 97 loss=4.206, nll_loss=3.768, ppl=13.62, wps=22262.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4600, lr=0.000466252, gnorm=1.085, loss_scale=16, train_wall=264, gb_free=8.1, wall=13600
2022-03-06 16:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:39:12 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.737 | nll_loss 8.393 | ppl 336.05 | wps 44521.9 | wpb 510.9 | bsz 1 | num_updates 4621 | best_loss 7.706
2022-03-06 16:39:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4621 updates
2022-03-06 16:39:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 48 @ 4621 updates, score 8.737) (writing took 2.1433309791609645 seconds)
2022-03-06 16:39:14 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:39:14 | INFO | train | epoch 048 | loss 4.18 | nll_loss 3.741 | ppl 13.37 | wps 22241 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4621 | lr 0.000465192 | gnorm 1.082 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13666
2022-03-06 16:39:14 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:42:59 | INFO | train_inner | epoch 049:     79 / 97 loss=4.116, nll_loss=3.673, ppl=12.76, wps=22479.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4700, lr=0.000461266, gnorm=1.102, loss_scale=16, train_wall=262, gb_free=8.1, wall=13891
2022-03-06 16:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:43:55 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.818 | nll_loss 8.475 | ppl 355.78 | wps 44392.8 | wpb 510.9 | bsz 1 | num_updates 4718 | best_loss 7.706
2022-03-06 16:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4718 updates
2022-03-06 16:43:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:43:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 49 @ 4718 updates, score 8.818) (writing took 2.0980195640586317 seconds)
2022-03-06 16:43:57 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:43:57 | INFO | train | epoch 049 | loss 4.099 | nll_loss 3.655 | ppl 12.6 | wps 22469.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4718 | lr 0.000460385 | gnorm 1.1 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13949
2022-03-06 16:43:57 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:47:50 | INFO | train_inner | epoch 050:     82 / 97 loss=4.033, nll_loss=3.586, ppl=12.01, wps=22493.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=4800, lr=0.000456435, gnorm=1.099, loss_scale=32, train_wall=262, gb_free=8.1, wall=14182
2022-03-06 16:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:48:37 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.872 | nll_loss 8.526 | ppl 368.62 | wps 44473.2 | wpb 510.9 | bsz 1 | num_updates 4815 | best_loss 7.706
2022-03-06 16:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4815 updates
2022-03-06 16:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:48:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:48:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 50 @ 4815 updates, score 8.872) (writing took 2.1522160139866173 seconds)
2022-03-06 16:48:40 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:48:40 | INFO | train | epoch 050 | loss 4.018 | nll_loss 3.571 | ppl 11.88 | wps 22472.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4815 | lr 0.000455724 | gnorm 1.091 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 14232
2022-03-06 16:48:40 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:48:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:49:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:52:49 | INFO | train_inner | epoch 051:     86 / 97 loss=3.953, nll_loss=3.501, ppl=11.32, wps=21917.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=4900, lr=0.000451754, gnorm=1.06, loss_scale=16, train_wall=268, gb_free=8.1, wall=14481
2022-03-06 16:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:53:27 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.953 | nll_loss 8.606 | ppl 389.75 | wps 38855.8 | wpb 510.9 | bsz 1 | num_updates 4911 | best_loss 7.706
2022-03-06 16:53:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 4911 updates
2022-03-06 16:53:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:53:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:53:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 51 @ 4911 updates, score 8.953) (writing took 2.3098491448909044 seconds)
2022-03-06 16:53:29 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:53:29 | INFO | train | epoch 051 | loss 3.934 | nll_loss 3.482 | ppl 11.17 | wps 21697.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 4911 | lr 0.000451248 | gnorm 1.065 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 14521
2022-03-06 16:53:29 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:53:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:58 | INFO | train_inner | epoch 052:     89 / 97 loss=3.872, nll_loss=3.416, ppl=10.68, wps=21190.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5000, lr=0.000447214, gnorm=1.076, loss_scale=32, train_wall=275, gb_free=8.1, wall=14790
2022-03-06 16:58:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:58:28 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.085 | nll_loss 8.743 | ppl 428.33 | wps 38416.8 | wpb 510.9 | bsz 1 | num_updates 5008 | best_loss 7.706
2022-03-06 16:58:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5008 updates
2022-03-06 16:58:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 16:58:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 52 @ 5008 updates, score 9.085) (writing took 2.512878610752523 seconds)
2022-03-06 16:58:30 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:58:30 | INFO | train | epoch 052 | loss 3.863 | nll_loss 3.407 | ppl 10.61 | wps 21124 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5008 | lr 0.000446856 | gnorm 1.095 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 14822
2022-03-06 16:58:30 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:58:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:03:11 | INFO | train_inner | epoch 053:     93 / 97 loss=3.799, nll_loss=3.339, ppl=10.12, wps=20945, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5100, lr=0.000442807, gnorm=1.098, loss_scale=32, train_wall=278, gb_free=8.1, wall=15103
2022-03-06 17:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:03:28 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.114 | nll_loss 8.766 | ppl 435.37 | wps 37534.1 | wpb 510.9 | bsz 1 | num_updates 5104 | best_loss 7.706
2022-03-06 17:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5104 updates
2022-03-06 17:03:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 53 @ 5104 updates, score 9.114) (writing took 2.5652878442779183 seconds)
2022-03-06 17:03:31 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 17:03:31 | INFO | train | epoch 053 | loss 3.791 | nll_loss 3.33 | ppl 10.06 | wps 20897.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5104 | lr 0.000442634 | gnorm 1.087 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 15123
2022-03-06 17:03:31 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 17:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:07:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:08:22 | INFO | train_inner | epoch 054:     97 / 97 loss=3.725, nll_loss=3.261, ppl=9.58, wps=20995.3, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=5200, lr=0.000438529, gnorm=1.086, loss_scale=16, train_wall=277, gb_free=8.1, wall=15414
2022-03-06 17:08:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:08:28 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.185 | nll_loss 8.831 | ppl 455.33 | wps 37599 | wpb 510.9 | bsz 1 | num_updates 5200 | best_loss 7.706
2022-03-06 17:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5200 updates
2022-03-06 17:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 54 @ 5200 updates, score 9.185) (writing took 2.5001009833067656 seconds)
2022-03-06 17:08:31 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 17:08:31 | INFO | train | epoch 054 | loss 3.718 | nll_loss 3.254 | ppl 9.54 | wps 20971.6 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5200 | lr 0.000438529 | gnorm 1.084 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 15423
2022-03-06 17:08:31 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 17:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:29 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.275 | nll_loss 8.929 | ppl 487.52 | wps 37424.2 | wpb 510.9 | bsz 1 | num_updates 5297 | best_loss 7.706
2022-03-06 17:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5297 updates
2022-03-06 17:13:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 55 @ 5297 updates, score 9.275) (writing took 2.4766723229549825 seconds)
2022-03-06 17:13:32 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 17:13:32 | INFO | train | epoch 055 | loss 3.653 | nll_loss 3.184 | ppl 9.09 | wps 21106.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5297 | lr 0.000434495 | gnorm 1.076 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 15724
2022-03-06 17:13:32 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 17:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:13:41 | INFO | train_inner | epoch 056:      3 / 97 loss=3.647, nll_loss=3.179, ppl=9.06, wps=20570.7, ups=0.31, wpb=65492.9, bsz=127.9, num_updates=5300, lr=0.000434372, gnorm=1.075, loss_scale=16, train_wall=275, gb_free=8.1, wall=15733
2022-03-06 17:16:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:18:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:18:28 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.358 | nll_loss 9.009 | ppl 515.26 | wps 38971.9 | wpb 510.9 | bsz 1 | num_updates 5393 | best_loss 7.706
2022-03-06 17:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5393 updates
2022-03-06 17:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 56 @ 5393 updates, score 9.358) (writing took 2.5173262590542436 seconds)
2022-03-06 17:18:30 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 17:18:30 | INFO | train | epoch 056 | loss 3.588 | nll_loss 3.116 | ppl 8.67 | wps 21044.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5393 | lr 0.000430611 | gnorm 1.088 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 16023
2022-03-06 17:18:30 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 17:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:18:52 | INFO | train_inner | epoch 057:      7 / 97 loss=3.582, nll_loss=3.109, ppl=8.63, wps=21070.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5400, lr=0.000430331, gnorm=1.086, loss_scale=16, train_wall=276, gb_free=8.1, wall=16044
2022-03-06 17:23:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:23:28 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.475 | nll_loss 9.125 | ppl 558.48 | wps 37847.1 | wpb 510.9 | bsz 1 | num_updates 5490 | best_loss 7.706
2022-03-06 17:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5490 updates
2022-03-06 17:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:23:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:23:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 57 @ 5490 updates, score 9.475) (writing took 2.519065973814577 seconds)
2022-03-06 17:23:31 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 17:23:31 | INFO | train | epoch 057 | loss 3.526 | nll_loss 3.051 | ppl 8.29 | wps 21155.3 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5490 | lr 0.00042679 | gnorm 1.086 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 16323
2022-03-06 17:23:31 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 17:23:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:24:01 | INFO | train_inner | epoch 058:     10 / 97 loss=3.518, nll_loss=3.042, ppl=8.24, wps=21171.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5500, lr=0.000426401, gnorm=1.091, loss_scale=32, train_wall=275, gb_free=8.1, wall=16353
2022-03-06 17:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:28:28 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.537 | nll_loss 9.189 | ppl 583.8 | wps 38328.1 | wpb 510.9 | bsz 1 | num_updates 5587 | best_loss 7.706
2022-03-06 17:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5587 updates
2022-03-06 17:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:28:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 58 @ 5587 updates, score 9.537) (writing took 2.4463603608310223 seconds)
2022-03-06 17:28:30 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 17:28:30 | INFO | train | epoch 058 | loss 3.465 | nll_loss 2.985 | ppl 7.92 | wps 21215.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5587 | lr 0.000423068 | gnorm 1.079 | loss_scale 32 | train_wall 266 | gb_free 8.1 | wall 16622
2022-03-06 17:28:30 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 17:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:29:09 | INFO | train_inner | epoch 059:     13 / 97 loss=3.457, nll_loss=2.977, ppl=7.87, wps=21238, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=5600, lr=0.000422577, gnorm=1.081, loss_scale=32, train_wall=274, gb_free=8.1, wall=16661
2022-03-06 17:29:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:32:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:33:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:33:28 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.62 | nll_loss 9.275 | ppl 619.69 | wps 38371.7 | wpb 510.9 | bsz 1 | num_updates 5682 | best_loss 7.706
2022-03-06 17:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5682 updates
2022-03-06 17:33:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 59 @ 5682 updates, score 9.62) (writing took 2.462609523907304 seconds)
2022-03-06 17:33:30 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 17:33:30 | INFO | train | epoch 059 | loss 3.408 | nll_loss 2.925 | ppl 7.59 | wps 20731.8 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 5682 | lr 0.000419517 | gnorm 1.101 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 16922
2022-03-06 17:33:30 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 17:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:34:25 | INFO | train_inner | epoch 060:     18 / 97 loss=3.39, nll_loss=2.906, ppl=7.5, wps=20777, ups=0.32, wpb=65495, bsz=127.9, num_updates=5700, lr=0.000418854, gnorm=1.089, loss_scale=16, train_wall=280, gb_free=8.1, wall=16977
2022-03-06 17:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:38:28 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.68 | nll_loss 9.332 | ppl 644.57 | wps 37889.7 | wpb 510.9 | bsz 1 | num_updates 5779 | best_loss 7.706
2022-03-06 17:38:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5779 updates
2022-03-06 17:38:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:38:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:38:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 60 @ 5779 updates, score 9.68) (writing took 2.4927350520156324 seconds)
2022-03-06 17:38:30 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 17:38:30 | INFO | train | epoch 060 | loss 3.352 | nll_loss 2.866 | ppl 7.29 | wps 21177.9 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5779 | lr 0.000415981 | gnorm 1.084 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 17222
2022-03-06 17:38:30 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 17:38:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:39:34 | INFO | train_inner | epoch 061:     21 / 97 loss=3.343, nll_loss=2.856, ppl=7.24, wps=21193.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=5800, lr=0.000415227, gnorm=1.083, loss_scale=32, train_wall=275, gb_free=8.1, wall=17286
2022-03-06 17:42:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:43:27 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.744 | nll_loss 9.388 | ppl 670 | wps 37351.8 | wpb 510.9 | bsz 1 | num_updates 5875 | best_loss 7.706
2022-03-06 17:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 5875 updates
2022-03-06 17:43:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 61 @ 5875 updates, score 9.744) (writing took 2.596288813278079 seconds)
2022-03-06 17:43:29 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 17:43:29 | INFO | train | epoch 061 | loss 3.298 | nll_loss 2.809 | ppl 7.01 | wps 21014.2 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 5875 | lr 0.000412568 | gnorm 1.085 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 17521
2022-03-06 17:43:29 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 17:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:44:45 | INFO | train_inner | epoch 062:     25 / 97 loss=3.278, nll_loss=2.788, ppl=6.91, wps=21056.2, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=5900, lr=0.000411693, gnorm=1.079, loss_scale=16, train_wall=276, gb_free=8.1, wall=17597
2022-03-06 17:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:48:26 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.908 | nll_loss 9.559 | ppl 754.49 | wps 39064.8 | wpb 510.9 | bsz 1 | num_updates 5972 | best_loss 7.706
2022-03-06 17:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 5972 updates
2022-03-06 17:48:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:48:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:48:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 62 @ 5972 updates, score 9.908) (writing took 2.4756409730762243 seconds)
2022-03-06 17:48:29 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 17:48:29 | INFO | train | epoch 062 | loss 3.245 | nll_loss 2.753 | ppl 6.74 | wps 21225.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 5972 | lr 0.000409204 | gnorm 1.09 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 17821
2022-03-06 17:48:29 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 17:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:49:53 | INFO | train_inner | epoch 063:     28 / 97 loss=3.23, nll_loss=2.736, ppl=6.66, wps=21242.2, ups=0.32, wpb=65495, bsz=127.9, num_updates=6000, lr=0.000408248, gnorm=1.111, loss_scale=32, train_wall=274, gb_free=8.1, wall=17905
2022-03-06 17:51:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:53:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:53:26 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.943 | nll_loss 9.593 | ppl 772.51 | wps 37792.7 | wpb 510.9 | bsz 1 | num_updates 6068 | best_loss 7.706
2022-03-06 17:53:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6068 updates
2022-03-06 17:53:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:53:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:53:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 63 @ 6068 updates, score 9.943) (writing took 2.4681958281435072 seconds)
2022-03-06 17:53:28 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 17:53:28 | INFO | train | epoch 063 | loss 3.192 | nll_loss 2.697 | ppl 6.48 | wps 20989.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6068 | lr 0.000405954 | gnorm 1.1 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 18120
2022-03-06 17:53:28 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 17:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:55:05 | INFO | train_inner | epoch 064:     32 / 97 loss=3.176, nll_loss=2.68, ppl=6.41, wps=21004.4, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=6100, lr=0.000404888, gnorm=1.077, loss_scale=16, train_wall=277, gb_free=8.1, wall=18217
2022-03-06 17:58:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:58:25 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.019 | nll_loss 9.667 | ppl 813.13 | wps 39115.9 | wpb 510.9 | bsz 1 | num_updates 6165 | best_loss 7.706
2022-03-06 17:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6165 updates
2022-03-06 17:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 17:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 64 @ 6165 updates, score 10.019) (writing took 2.5182383921928704 seconds)
2022-03-06 17:58:27 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 17:58:27 | INFO | train | epoch 064 | loss 3.146 | nll_loss 2.647 | ppl 6.26 | wps 21257.1 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 6165 | lr 0.000402748 | gnorm 1.085 | loss_scale 32 | train_wall 266 | gb_free 8.1 | wall 18419
2022-03-06 17:58:27 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 17:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:00:12 | INFO | train_inner | epoch 065:     35 / 97 loss=3.124, nll_loss=2.624, ppl=6.16, wps=21319.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=6200, lr=0.00040161, gnorm=1.08, loss_scale=32, train_wall=273, gb_free=8.1, wall=18524
2022-03-06 18:00:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:03:24 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.121 | nll_loss 9.774 | ppl 875.39 | wps 38869.9 | wpb 510.9 | bsz 1 | num_updates 6261 | best_loss 7.706
2022-03-06 18:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6261 updates
2022-03-06 18:03:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:03:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:03:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 65 @ 6261 updates, score 10.121) (writing took 2.391150652896613 seconds)
2022-03-06 18:03:26 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 18:03:26 | INFO | train | epoch 065 | loss 3.096 | nll_loss 2.595 | ppl 6.04 | wps 21006 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6261 | lr 0.000399648 | gnorm 1.07 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 18718
2022-03-06 18:03:26 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 18:03:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:05:24 | INFO | train_inner | epoch 066:     39 / 97 loss=3.083, nll_loss=2.58, ppl=5.98, wps=21022.5, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=6300, lr=0.00039841, gnorm=1.095, loss_scale=16, train_wall=277, gb_free=8.1, wall=18836
2022-03-06 18:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:08:24 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.194 | nll_loss 9.847 | ppl 920.81 | wps 38191 | wpb 510.9 | bsz 1 | num_updates 6358 | best_loss 7.706
2022-03-06 18:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6358 updates
2022-03-06 18:08:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 66 @ 6358 updates, score 10.194) (writing took 2.6263754912652075 seconds)
2022-03-06 18:08:27 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 18:08:27 | INFO | train | epoch 066 | loss 3.054 | nll_loss 2.549 | ppl 5.85 | wps 21139.4 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 6358 | lr 0.000396588 | gnorm 1.097 | loss_scale 32 | train_wall 267 | gb_free 8.1 | wall 19019
2022-03-06 18:08:27 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 18:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:08:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:10:37 | INFO | train_inner | epoch 067:     43 / 97 loss=3.035, nll_loss=2.529, ppl=5.77, wps=20900.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=6400, lr=0.000395285, gnorm=1.083, loss_scale=16, train_wall=278, gb_free=8.1, wall=19149
2022-03-06 18:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:13:25 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.242 | nll_loss 9.89 | ppl 948.87 | wps 37861.7 | wpb 510.9 | bsz 1 | num_updates 6454 | best_loss 7.706
2022-03-06 18:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6454 updates
2022-03-06 18:13:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:13:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:13:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 67 @ 6454 updates, score 10.242) (writing took 2.573765473905951 seconds)
2022-03-06 18:13:28 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 18:13:28 | INFO | train | epoch 067 | loss 3.008 | nll_loss 2.5 | ppl 5.66 | wps 20898.7 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6454 | lr 0.000393628 | gnorm 1.08 | loss_scale 16 | train_wall 267 | gb_free 8.1 | wall 19320
2022-03-06 18:13:28 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 18:13:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:15:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:15:49 | INFO | train_inner | epoch 068:     47 / 97 loss=2.99, nll_loss=2.481, ppl=5.58, wps=21009.5, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=6500, lr=0.000392232, gnorm=1.081, loss_scale=16, train_wall=277, gb_free=8.1, wall=19461
2022-03-06 18:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:18:24 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.305 | nll_loss 9.957 | ppl 993.84 | wps 38565.9 | wpb 510.9 | bsz 1 | num_updates 6550 | best_loss 7.706
2022-03-06 18:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6550 updates
2022-03-06 18:18:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:18:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 68 @ 6550 updates, score 10.305) (writing took 2.5867317621596158 seconds)
2022-03-06 18:18:27 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 18:18:27 | INFO | train | epoch 068 | loss 2.966 | nll_loss 2.456 | ppl 5.49 | wps 21015.4 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6550 | lr 0.000390732 | gnorm 1.085 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 19619
2022-03-06 18:18:27 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 18:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:20:57 | INFO | train_inner | epoch 069:     50 / 97 loss=2.945, nll_loss=2.434, ppl=5.4, wps=21208.5, ups=0.32, wpb=65495, bsz=127.9, num_updates=6600, lr=0.000389249, gnorm=1.087, loss_scale=16, train_wall=274, gb_free=8.1, wall=19769
2022-03-06 18:23:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:23:23 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.382 | nll_loss 10.034 | ppl 1048.76 | wps 38014.7 | wpb 510.9 | bsz 1 | num_updates 6647 | best_loss 7.706
2022-03-06 18:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6647 updates
2022-03-06 18:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 69 @ 6647 updates, score 10.382) (writing took 2.781063257716596 seconds)
2022-03-06 18:23:26 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 18:23:26 | INFO | train | epoch 069 | loss 2.924 | nll_loss 2.412 | ppl 5.32 | wps 21224.8 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 6647 | lr 0.000387871 | gnorm 1.089 | loss_scale 32 | train_wall 265 | gb_free 8.1 | wall 19918
2022-03-06 18:23:26 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 18:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:25:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:26:09 | INFO | train_inner | epoch 070:     54 / 97 loss=2.905, nll_loss=2.392, ppl=5.25, wps=21034.4, ups=0.32, wpb=65490.8, bsz=127.9, num_updates=6700, lr=0.000386334, gnorm=1.086, loss_scale=16, train_wall=276, gb_free=8.1, wall=20081
2022-03-06 18:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:28:23 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.493 | nll_loss 10.147 | ppl 1133.54 | wps 38497.4 | wpb 510.9 | bsz 1 | num_updates 6743 | best_loss 7.706
2022-03-06 18:28:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6743 updates
2022-03-06 18:28:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 70 @ 6743 updates, score 10.493) (writing took 2.434581389185041 seconds)
2022-03-06 18:28:26 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 18:28:26 | INFO | train | epoch 070 | loss 2.885 | nll_loss 2.37 | ppl 5.17 | wps 20988.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6743 | lr 0.0003851 | gnorm 1.085 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 20218
2022-03-06 18:28:26 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 18:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:31:17 | INFO | train_inner | epoch 071:     57 / 97 loss=2.863, nll_loss=2.347, ppl=5.09, wps=21225.6, ups=0.32, wpb=65495, bsz=127.9, num_updates=6800, lr=0.000383482, gnorm=1.086, loss_scale=16, train_wall=274, gb_free=8.1, wall=20389
2022-03-06 18:32:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:33:23 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.549 | nll_loss 10.204 | ppl 1179.94 | wps 38675.1 | wpb 510.9 | bsz 1 | num_updates 6839 | best_loss 7.706
2022-03-06 18:33:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 6839 updates
2022-03-06 18:33:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:33:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:33:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 71 @ 6839 updates, score 10.549) (writing took 2.45758909964934 seconds)
2022-03-06 18:33:25 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 18:33:25 | INFO | train | epoch 071 | loss 2.845 | nll_loss 2.328 | ppl 5.02 | wps 20994.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 6839 | lr 0.000382388 | gnorm 1.093 | loss_scale 16 | train_wall 266 | gb_free 8.1 | wall 20517
2022-03-06 18:33:25 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 18:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:36:26 | INFO | train_inner | epoch 072:     61 / 97 loss=2.822, nll_loss=2.303, ppl=4.93, wps=21229, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=6900, lr=0.000380693, gnorm=1.093, loss_scale=16, train_wall=275, gb_free=8.1, wall=20698
2022-03-06 18:38:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:38:15 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.638 | nll_loss 10.293 | ppl 1254.16 | wps 43100.3 | wpb 510.9 | bsz 1 | num_updates 6936 | best_loss 7.706
2022-03-06 18:38:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 6936 updates
2022-03-06 18:38:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 72 @ 6936 updates, score 10.638) (writing took 2.5080942027270794 seconds)
2022-03-06 18:38:17 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 18:38:17 | INFO | train | epoch 072 | loss 2.809 | nll_loss 2.289 | ppl 4.89 | wps 21772.4 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 6936 | lr 0.000379704 | gnorm 1.098 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 20809
2022-03-06 18:38:17 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 18:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:41:21 | INFO | train_inner | epoch 073:     64 / 97 loss=2.786, nll_loss=2.265, ppl=4.81, wps=22193.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7000, lr=0.000377964, gnorm=1.087, loss_scale=32, train_wall=265, gb_free=8.1, wall=20993
2022-03-06 18:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:43:01 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.711 | nll_loss 10.37 | ppl 1323.03 | wps 42893.4 | wpb 510.9 | bsz 1 | num_updates 7033 | best_loss 7.706
2022-03-06 18:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7033 updates
2022-03-06 18:43:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 73 @ 7033 updates, score 10.711) (writing took 2.38413694081828 seconds)
2022-03-06 18:43:03 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 18:43:03 | INFO | train | epoch 073 | loss 2.771 | nll_loss 2.249 | ppl 4.75 | wps 22218.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7033 | lr 0.000377077 | gnorm 1.076 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 21095
2022-03-06 18:43:03 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 18:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:43:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:46:18 | INFO | train_inner | epoch 074:     68 / 97 loss=2.749, nll_loss=2.225, ppl=4.68, wps=22031.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7100, lr=0.000375293, gnorm=1.097, loss_scale=16, train_wall=267, gb_free=8.1, wall=21290
2022-03-06 18:47:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:47:46 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.747 | nll_loss 10.404 | ppl 1354.87 | wps 42924.2 | wpb 510.9 | bsz 1 | num_updates 7129 | best_loss 7.706
2022-03-06 18:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7129 updates
2022-03-06 18:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:47:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:47:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 74 @ 7129 updates, score 10.747) (writing took 2.350013834889978 seconds)
2022-03-06 18:47:49 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 18:47:49 | INFO | train | epoch 074 | loss 2.737 | nll_loss 2.213 | ppl 4.63 | wps 22001 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7129 | lr 0.000374529 | gnorm 1.098 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 21381
2022-03-06 18:47:49 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 18:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:51:12 | INFO | train_inner | epoch 075:     71 / 97 loss=2.713, nll_loss=2.187, ppl=4.55, wps=22262, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7200, lr=0.000372678, gnorm=1.082, loss_scale=32, train_wall=264, gb_free=8.1, wall=21584
2022-03-06 18:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:52:34 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.811 | nll_loss 10.468 | ppl 1416.05 | wps 40235.8 | wpb 510.9 | bsz 1 | num_updates 7226 | best_loss 7.706
2022-03-06 18:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7226 updates
2022-03-06 18:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:52:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 75 @ 7226 updates, score 10.811) (writing took 2.5344691197387874 seconds)
2022-03-06 18:52:37 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 18:52:37 | INFO | train | epoch 075 | loss 2.703 | nll_loss 2.177 | ppl 4.52 | wps 22057.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7226 | lr 0.000372007 | gnorm 1.087 | loss_scale 32 | train_wall 257 | gb_free 8.1 | wall 21669
2022-03-06 18:52:37 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 18:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:56:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:56:18 | INFO | train_inner | epoch 076:     75 / 97 loss=2.682, nll_loss=2.154, ppl=4.45, wps=21440.1, ups=0.33, wpb=65495, bsz=127.9, num_updates=7300, lr=0.000370117, gnorm=1.089, loss_scale=32, train_wall=273, gb_free=8.1, wall=21890
2022-03-06 18:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:57:28 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.923 | nll_loss 10.575 | ppl 1525.05 | wps 40277.1 | wpb 510.9 | bsz 1 | num_updates 7322 | best_loss 7.706
2022-03-06 18:57:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7322 updates
2022-03-06 18:57:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:57:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 18:57:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 76 @ 7322 updates, score 10.923) (writing took 2.5382888950407505 seconds)
2022-03-06 18:57:30 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 18:57:30 | INFO | train | epoch 076 | loss 2.67 | nll_loss 2.141 | ppl 4.41 | wps 21418.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 7322 | lr 0.00036956 | gnorm 1.092 | loss_scale 32 | train_wall 262 | gb_free 8.1 | wall 21962
2022-03-06 18:57:30 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 18:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:01:20 | INFO | train_inner | epoch 077:     78 / 97 loss=2.644, nll_loss=2.114, ppl=4.33, wps=21667.6, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=7400, lr=0.000367607, gnorm=1.076, loss_scale=32, train_wall=270, gb_free=8.1, wall=22192
2022-03-06 19:02:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:02:21 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.927 | nll_loss 10.585 | ppl 1535.59 | wps 39896.4 | wpb 510.9 | bsz 1 | num_updates 7419 | best_loss 7.706
2022-03-06 19:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7419 updates
2022-03-06 19:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:02:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:02:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 77 @ 7419 updates, score 10.927) (writing took 2.574059410020709 seconds)
2022-03-06 19:02:24 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 19:02:24 | INFO | train | epoch 077 | loss 2.637 | nll_loss 2.107 | ppl 4.31 | wps 21626.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 7419 | lr 0.000367136 | gnorm 1.067 | loss_scale 32 | train_wall 262 | gb_free 8.1 | wall 22256
2022-03-06 19:02:24 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 19:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:02:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:06:28 | INFO | train_inner | epoch 078:     83 / 97 loss=2.617, nll_loss=2.085, ppl=4.24, wps=21295.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=7500, lr=0.000365148, gnorm=1.11, loss_scale=16, train_wall=275, gb_free=8.1, wall=22500
2022-03-06 19:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:07:13 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.04 | nll_loss 10.691 | ppl 1653.23 | wps 43379.3 | wpb 510.9 | bsz 1 | num_updates 7514 | best_loss 7.706
2022-03-06 19:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7514 updates
2022-03-06 19:07:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:07:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:07:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 78 @ 7514 updates, score 11.04) (writing took 2.341966539155692 seconds)
2022-03-06 19:07:15 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 19:07:15 | INFO | train | epoch 078 | loss 2.605 | nll_loss 2.072 | ppl 4.21 | wps 21379.2 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 7514 | lr 0.000364808 | gnorm 1.106 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 22547
2022-03-06 19:07:15 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 19:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:10:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:11:24 | INFO | train_inner | epoch 079:     87 / 97 loss=2.582, nll_loss=2.048, ppl=4.14, wps=22084.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=7600, lr=0.000362738, gnorm=1.076, loss_scale=16, train_wall=266, gb_free=8.1, wall=22796
2022-03-06 19:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:11:58 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.097 | nll_loss 10.753 | ppl 1725.52 | wps 43400.4 | wpb 510.9 | bsz 1 | num_updates 7610 | best_loss 7.706
2022-03-06 19:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7610 updates
2022-03-06 19:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 79 @ 7610 updates, score 11.097) (writing took 2.3754870546981692 seconds)
2022-03-06 19:12:00 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 19:12:00 | INFO | train | epoch 079 | loss 2.577 | nll_loss 2.042 | ppl 4.12 | wps 22054.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7610 | lr 0.0003625 | gnorm 1.078 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 22832
2022-03-06 19:12:00 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 19:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:16:18 | INFO | train_inner | epoch 080:     90 / 97 loss=2.556, nll_loss=2.02, ppl=4.06, wps=22317.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7700, lr=0.000360375, gnorm=1.08, loss_scale=16, train_wall=263, gb_free=8.1, wall=23090
2022-03-06 19:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:16:43 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.116 | nll_loss 10.769 | ppl 1745.07 | wps 42986.7 | wpb 510.9 | bsz 1 | num_updates 7707 | best_loss 7.706
2022-03-06 19:16:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7707 updates
2022-03-06 19:16:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 80 @ 7707 updates, score 11.116) (writing took 2.4673153180629015 seconds)
2022-03-06 19:16:45 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 19:16:45 | INFO | train | epoch 080 | loss 2.55 | nll_loss 2.014 | ppl 4.04 | wps 22288.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7707 | lr 0.000360211 | gnorm 1.082 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 23117
2022-03-06 19:16:45 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 19:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:21:12 | INFO | train_inner | epoch 081:     93 / 97 loss=2.523, nll_loss=1.986, ppl=3.96, wps=22232.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7800, lr=0.000358057, gnorm=1.073, loss_scale=32, train_wall=264, gb_free=8.1, wall=23384
2022-03-06 19:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:21:29 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.182 | nll_loss 10.838 | ppl 1829.89 | wps 40067.1 | wpb 510.9 | bsz 1 | num_updates 7804 | best_loss 7.706
2022-03-06 19:21:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 7804 updates
2022-03-06 19:21:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:21:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 81 @ 7804 updates, score 11.182) (writing took 2.4843292119912803 seconds)
2022-03-06 19:21:32 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 19:21:32 | INFO | train | epoch 081 | loss 2.52 | nll_loss 1.982 | ppl 3.95 | wps 22181.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7804 | lr 0.000357966 | gnorm 1.071 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 23404
2022-03-06 19:21:32 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 19:21:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:23:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:26:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:26:23 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.267 | nll_loss 10.924 | ppl 1942.26 | wps 40241.9 | wpb 510.9 | bsz 1 | num_updates 7899 | best_loss 7.706
2022-03-06 19:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 7899 updates
2022-03-06 19:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 82 @ 7899 updates, score 11.267) (writing took 2.4816290056332946 seconds)
2022-03-06 19:26:26 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 19:26:26 | INFO | train | epoch 082 | loss 2.492 | nll_loss 1.952 | ppl 3.87 | wps 21143.6 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 7899 | lr 0.000355807 | gnorm 1.068 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 23698
2022-03-06 19:26:26 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 19:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:26:29 | INFO | train_inner | epoch 083:      1 / 97 loss=2.495, nll_loss=1.955, ppl=3.88, wps=20676.4, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=7900, lr=0.000355784, gnorm=1.07, loss_scale=16, train_wall=275, gb_free=8.1, wall=23701
2022-03-06 19:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:31:17 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.285 | nll_loss 10.943 | ppl 1968.14 | wps 39575.7 | wpb 510.9 | bsz 1 | num_updates 7996 | best_loss 7.706
2022-03-06 19:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 7996 updates
2022-03-06 19:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:31:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 83 @ 7996 updates, score 11.285) (writing took 2.5122083770111203 seconds)
2022-03-06 19:31:20 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 19:31:20 | INFO | train | epoch 083 | loss 2.467 | nll_loss 1.926 | ppl 3.8 | wps 21597 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 7996 | lr 0.000353642 | gnorm 1.064 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 23992
2022-03-06 19:31:20 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 19:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:31:32 | INFO | train_inner | epoch 084:      4 / 97 loss=2.463, nll_loss=1.922, ppl=3.79, wps=21613.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8000, lr=0.000353553, gnorm=1.062, loss_scale=16, train_wall=270, gb_free=8.1, wall=24004
2022-03-06 19:32:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:36:11 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.308 | nll_loss 10.966 | ppl 2000.36 | wps 41158.4 | wpb 510.9 | bsz 1 | num_updates 8092 | best_loss 7.706
2022-03-06 19:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8092 updates
2022-03-06 19:36:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 84 @ 8092 updates, score 11.308) (writing took 2.2634755158796906 seconds)
2022-03-06 19:36:13 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 19:36:13 | INFO | train | epoch 084 | loss 2.441 | nll_loss 1.898 | ppl 3.73 | wps 21441.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8092 | lr 0.000351538 | gnorm 1.084 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 24285
2022-03-06 19:36:13 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 19:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:36:36 | INFO | train_inner | epoch 085:      8 / 97 loss=2.437, nll_loss=1.894, ppl=3.72, wps=21500.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8100, lr=0.000351364, gnorm=1.088, loss_scale=16, train_wall=272, gb_free=8.1, wall=24309
2022-03-06 19:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:40:57 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.374 | nll_loss 11.029 | ppl 2089.87 | wps 43416.6 | wpb 510.9 | bsz 1 | num_updates 8189 | best_loss 7.706
2022-03-06 19:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8189 updates
2022-03-06 19:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 85 @ 8189 updates, score 11.374) (writing took 2.567809328902513 seconds)
2022-03-06 19:40:59 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 19:40:59 | INFO | train | epoch 085 | loss 2.415 | nll_loss 1.871 | ppl 3.66 | wps 22206.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8189 | lr 0.00034945 | gnorm 1.08 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 24571
2022-03-06 19:40:59 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 19:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:41:31 | INFO | train_inner | epoch 086:     11 / 97 loss=2.408, nll_loss=1.863, ppl=3.64, wps=22248.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8200, lr=0.000349215, gnorm=1.08, loss_scale=32, train_wall=264, gb_free=8.1, wall=24603
2022-03-06 19:45:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:45:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:45:42 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.474 | nll_loss 11.134 | ppl 2247.44 | wps 43294.8 | wpb 510.9 | bsz 1 | num_updates 8285 | best_loss 7.706
2022-03-06 19:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8285 updates
2022-03-06 19:45:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:45:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:45:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 86 @ 8285 updates, score 11.474) (writing took 2.3677202807739377 seconds)
2022-03-06 19:45:44 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 19:45:44 | INFO | train | epoch 086 | loss 2.39 | nll_loss 1.844 | ppl 3.59 | wps 22063.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8285 | lr 0.000347419 | gnorm 1.065 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 24856
2022-03-06 19:45:44 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 19:45:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:46:27 | INFO | train_inner | epoch 087:     15 / 97 loss=2.386, nll_loss=1.84, ppl=3.58, wps=22099.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8300, lr=0.000347105, gnorm=1.059, loss_scale=32, train_wall=266, gb_free=8.1, wall=24899
2022-03-06 19:46:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:50:27 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.506 | nll_loss 11.167 | ppl 2298.83 | wps 43201.4 | wpb 510.9 | bsz 1 | num_updates 8381 | best_loss 7.706
2022-03-06 19:50:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8381 updates
2022-03-06 19:50:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:50:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 87 @ 8381 updates, score 11.506) (writing took 2.384294653777033 seconds)
2022-03-06 19:50:29 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 19:50:29 | INFO | train | epoch 087 | loss 2.366 | nll_loss 1.819 | ppl 3.53 | wps 22054.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8381 | lr 0.000345424 | gnorm 1.06 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 25141
2022-03-06 19:50:29 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 19:50:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:24 | INFO | train_inner | epoch 088:     19 / 97 loss=2.358, nll_loss=1.809, ppl=3.51, wps=22051.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8400, lr=0.000345033, gnorm=1.06, loss_scale=16, train_wall=266, gb_free=8.1, wall=25196
2022-03-06 19:55:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:55:19 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.575 | nll_loss 11.238 | ppl 2414.62 | wps 39965.6 | wpb 510.9 | bsz 1 | num_updates 8478 | best_loss 7.706
2022-03-06 19:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8478 updates
2022-03-06 19:55:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 19:55:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 88 @ 8478 updates, score 11.575) (writing took 2.6324745290912688 seconds)
2022-03-06 19:55:22 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 19:55:22 | INFO | train | epoch 088 | loss 2.346 | nll_loss 1.797 | ppl 3.48 | wps 21707.2 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 8478 | lr 0.000343442 | gnorm 1.071 | loss_scale 32 | train_wall 261 | gb_free 8.1 | wall 25434
2022-03-06 19:55:22 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 19:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:56:27 | INFO | train_inner | epoch 089:     22 / 97 loss=2.34, nll_loss=1.791, ppl=3.46, wps=21633, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=8500, lr=0.000342997, gnorm=1.068, loss_scale=32, train_wall=270, gb_free=8.1, wall=25499
2022-03-06 19:59:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:59:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:00:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:14 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.617 | nll_loss 11.279 | ppl 2484.37 | wps 39909.3 | wpb 510.9 | bsz 1 | num_updates 8573 | best_loss 7.706
2022-03-06 20:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8573 updates
2022-03-06 20:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 89 @ 8573 updates, score 11.617) (writing took 2.5077915908768773 seconds)
2022-03-06 20:00:16 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 20:00:16 | INFO | train | epoch 089 | loss 2.32 | nll_loss 1.769 | ppl 3.41 | wps 21151.5 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 8573 | lr 0.000341534 | gnorm 1.059 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 25728
2022-03-06 20:00:16 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 20:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:01:36 | INFO | train_inner | epoch 090:     27 / 97 loss=2.312, nll_loss=1.762, ppl=3.39, wps=21203.6, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=8600, lr=0.000340997, gnorm=1.059, loss_scale=16, train_wall=276, gb_free=8.1, wall=25808
2022-03-06 20:05:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:05:08 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.629 | nll_loss 11.291 | ppl 2505.51 | wps 39263.8 | wpb 510.9 | bsz 1 | num_updates 8670 | best_loss 7.706
2022-03-06 20:05:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8670 updates
2022-03-06 20:05:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:05:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 90 @ 8670 updates, score 11.629) (writing took 2.5487261000089347 seconds)
2022-03-06 20:05:11 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 20:05:11 | INFO | train | epoch 090 | loss 2.301 | nll_loss 1.75 | ppl 3.36 | wps 21548.2 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 8670 | lr 0.000339618 | gnorm 1.067 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 26023
2022-03-06 20:05:11 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 20:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:06:40 | INFO | train_inner | epoch 091:     30 / 97 loss=2.294, nll_loss=1.742, ppl=3.34, wps=21563.4, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=8700, lr=0.000339032, gnorm=1.065, loss_scale=32, train_wall=271, gb_free=8.1, wall=26112
2022-03-06 20:07:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:09:58 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.745 | nll_loss 11.411 | ppl 2722.8 | wps 43369.3 | wpb 510.9 | bsz 1 | num_updates 8766 | best_loss 7.706
2022-03-06 20:09:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 8766 updates
2022-03-06 20:09:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 91 @ 8766 updates, score 11.745) (writing took 2.4484016448259354 seconds)
2022-03-06 20:10:01 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 20:10:01 | INFO | train | epoch 091 | loss 2.278 | nll_loss 1.725 | ppl 3.31 | wps 21688.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 8766 | lr 0.000337753 | gnorm 1.07 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 26313
2022-03-06 20:10:01 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 20:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:11:38 | INFO | train_inner | epoch 092:     34 / 97 loss=2.271, nll_loss=1.718, ppl=3.29, wps=21930.7, ups=0.33, wpb=65495, bsz=127.9, num_updates=8800, lr=0.0003371, gnorm=1.078, loss_scale=16, train_wall=268, gb_free=8.1, wall=26410
2022-03-06 20:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:14:44 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.744 | nll_loss 11.406 | ppl 2713.6 | wps 43163.5 | wpb 510.9 | bsz 1 | num_updates 8863 | best_loss 7.706
2022-03-06 20:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 8863 updates
2022-03-06 20:14:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 92 @ 8863 updates, score 11.744) (writing took 2.5105992150492966 seconds)
2022-03-06 20:14:46 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 20:14:46 | INFO | train | epoch 092 | loss 2.258 | nll_loss 1.704 | ppl 3.26 | wps 22263.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8863 | lr 0.0003359 | gnorm 1.062 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 26598
2022-03-06 20:14:46 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 20:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:16:32 | INFO | train_inner | epoch 093:     37 / 97 loss=2.25, nll_loss=1.695, ppl=3.24, wps=22267.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=8900, lr=0.000335201, gnorm=1.058, loss_scale=32, train_wall=264, gb_free=8.1, wall=26704
2022-03-06 20:17:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:19:29 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.802 | nll_loss 11.461 | ppl 2818.4 | wps 43248.8 | wpb 510.9 | bsz 1 | num_updates 8959 | best_loss 7.706
2022-03-06 20:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 8959 updates
2022-03-06 20:19:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:19:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:19:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 93 @ 8959 updates, score 11.802) (writing took 2.473820751067251 seconds)
2022-03-06 20:19:32 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 20:19:32 | INFO | train | epoch 093 | loss 2.238 | nll_loss 1.683 | ppl 3.21 | wps 22014.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8959 | lr 0.000334095 | gnorm 1.065 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 26884
2022-03-06 20:19:32 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 20:19:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:21:29 | INFO | train_inner | epoch 094:     41 / 97 loss=2.225, nll_loss=1.669, ppl=3.18, wps=22050.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=9000, lr=0.000333333, gnorm=1.054, loss_scale=16, train_wall=267, gb_free=8.1, wall=27001
2022-03-06 20:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:24:18 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.816 | nll_loss 11.477 | ppl 2850.83 | wps 39871.8 | wpb 510.9 | bsz 1 | num_updates 9056 | best_loss 7.706
2022-03-06 20:24:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9056 updates
2022-03-06 20:24:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:24:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:24:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 94 @ 9056 updates, score 11.816) (writing took 2.5552166160196066 seconds)
2022-03-06 20:24:20 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 20:24:20 | INFO | train | epoch 094 | loss 2.217 | nll_loss 1.66 | ppl 3.16 | wps 22010.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9056 | lr 0.000332301 | gnorm 1.063 | loss_scale 32 | train_wall 258 | gb_free 8.1 | wall 27172
2022-03-06 20:24:20 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 20:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:26:30 | INFO | train_inner | epoch 095:     44 / 97 loss=2.212, nll_loss=1.655, ppl=3.15, wps=21758.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=9100, lr=0.000331497, gnorm=1.064, loss_scale=32, train_wall=269, gb_free=8.1, wall=27302
2022-03-06 20:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:29:12 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.836 | nll_loss 11.501 | ppl 2897.62 | wps 40015.9 | wpb 510.9 | bsz 1 | num_updates 9153 | best_loss 7.706
2022-03-06 20:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9153 updates
2022-03-06 20:29:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 95 @ 9153 updates, score 11.836) (writing took 2.5496329818852246 seconds)
2022-03-06 20:29:15 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 20:29:15 | INFO | train | epoch 095 | loss 2.198 | nll_loss 1.64 | ppl 3.12 | wps 21593.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9153 | lr 0.000330536 | gnorm 1.049 | loss_scale 32 | train_wall 262 | gb_free 8.1 | wall 27467
2022-03-06 20:29:15 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 20:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:31:36 | INFO | train_inner | epoch 096:     48 / 97 loss=2.191, nll_loss=1.632, ppl=3.1, wps=21407.3, ups=0.33, wpb=65495, bsz=127.9, num_updates=9200, lr=0.00032969, gnorm=1.06, loss_scale=32, train_wall=273, gb_free=8.1, wall=27608
2022-03-06 20:33:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:34:06 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.95 | nll_loss 11.617 | ppl 3140.93 | wps 39786.2 | wpb 510.9 | bsz 1 | num_updates 9248 | best_loss 7.706
2022-03-06 20:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9248 updates
2022-03-06 20:34:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:34:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:34:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 96 @ 9248 updates, score 11.95) (writing took 2.526112113147974 seconds)
2022-03-06 20:34:09 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 20:34:09 | INFO | train | epoch 096 | loss 2.18 | nll_loss 1.621 | ppl 3.08 | wps 21128.4 | ups 0.32 | wpb 65490.6 | bsz 127.9 | num_updates 9248 | lr 0.000328834 | gnorm 1.069 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 27761
2022-03-06 20:34:09 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 20:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:36:43 | INFO | train_inner | epoch 097:     52 / 97 loss=2.17, nll_loss=1.61, ppl=3.05, wps=21361.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=9300, lr=0.000327913, gnorm=1.056, loss_scale=16, train_wall=273, gb_free=8.1, wall=27915
2022-03-06 20:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:39:00 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.005 | nll_loss 11.674 | ppl 3266.45 | wps 40872.2 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 7.706
2022-03-06 20:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9345 updates
2022-03-06 20:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:39:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:39:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 97 @ 9345 updates, score 12.005) (writing took 2.534181389026344 seconds)
2022-03-06 20:39:03 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 20:39:03 | INFO | train | epoch 097 | loss 2.162 | nll_loss 1.602 | ppl 3.04 | wps 21629 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9345 | lr 0.000327122 | gnorm 1.051 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 28055
2022-03-06 20:39:03 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 20:39:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:41:41 | INFO | train_inner | epoch 098:     55 / 97 loss=2.154, nll_loss=1.594, ppl=3.02, wps=21981, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9400, lr=0.000326164, gnorm=1.063, loss_scale=32, train_wall=266, gb_free=8.1, wall=28213
2022-03-06 20:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:43:46 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.97 | nll_loss 11.636 | ppl 3182.7 | wps 43508.2 | wpb 510.9 | bsz 1 | num_updates 9442 | best_loss 7.706
2022-03-06 20:43:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9442 updates
2022-03-06 20:43:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:43:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 98 @ 9442 updates, score 11.97) (writing took 2.6088003548793495 seconds)
2022-03-06 20:43:49 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 20:43:49 | INFO | train | epoch 098 | loss 2.145 | nll_loss 1.584 | ppl 3 | wps 22216.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9442 | lr 0.000325438 | gnorm 1.055 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 28341
2022-03-06 20:43:49 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 20:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:45:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:46:38 | INFO | train_inner | epoch 099:     59 / 97 loss=2.132, nll_loss=1.57, ppl=2.97, wps=22059.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=9500, lr=0.000324443, gnorm=1.048, loss_scale=16, train_wall=266, gb_free=8.1, wall=28510
2022-03-06 20:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:48:31 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.013 | nll_loss 11.68 | ppl 3281.48 | wps 43291.8 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 7.706
2022-03-06 20:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9538 updates
2022-03-06 20:48:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:48:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:48:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 99 @ 9538 updates, score 12.013) (writing took 2.4526321557350457 seconds)
2022-03-06 20:48:34 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 20:48:34 | INFO | train | epoch 099 | loss 2.127 | nll_loss 1.565 | ppl 2.96 | wps 22039.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9538 | lr 0.000323796 | gnorm 1.055 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 28626
2022-03-06 20:48:34 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 20:48:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:51:32 | INFO | train_inner | epoch 100:     62 / 97 loss=2.121, nll_loss=1.559, ppl=2.95, wps=22278.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9600, lr=0.000322749, gnorm=1.06, loss_scale=32, train_wall=264, gb_free=8.1, wall=28804
2022-03-06 20:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:53:17 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.101 | nll_loss 11.768 | ppl 3488.03 | wps 40180.5 | wpb 510.9 | bsz 1 | num_updates 9635 | best_loss 7.706
2022-03-06 20:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9635 updates
2022-03-06 20:53:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:53:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:53:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 100 @ 9635 updates, score 12.101) (writing took 2.5745973219163716 seconds)
2022-03-06 20:53:20 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 20:53:20 | INFO | train | epoch 100 | loss 2.111 | nll_loss 1.548 | ppl 2.92 | wps 22215.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9635 | lr 0.000322162 | gnorm 1.058 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 28912
2022-03-06 20:53:20 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 20:53:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:56:31 | INFO | train_inner | epoch 101:     65 / 97 loss=2.097, nll_loss=1.534, ppl=2.9, wps=21849.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=9700, lr=0.000321081, gnorm=1.05, loss_scale=32, train_wall=268, gb_free=8.1, wall=29103
2022-03-06 20:57:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:58:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:58:11 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.095 | nll_loss 11.763 | ppl 3475.34 | wps 39948.2 | wpb 510.9 | bsz 1 | num_updates 9730 | best_loss 7.706
2022-03-06 20:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9730 updates
2022-03-06 20:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:58:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 20:58:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 101 @ 9730 updates, score 12.095) (writing took 2.5498321121558547 seconds)
2022-03-06 20:58:14 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 20:58:14 | INFO | train | epoch 101 | loss 2.092 | nll_loss 1.528 | ppl 2.88 | wps 21183.5 | ups 0.32 | wpb 65536 | bsz 128 | num_updates 9730 | lr 0.000320585 | gnorm 1.044 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 29206
2022-03-06 20:58:14 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 20:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:01:40 | INFO | train_inner | epoch 102:     70 / 97 loss=2.086, nll_loss=1.521, ppl=2.87, wps=21209.2, ups=0.32, wpb=65533.9, bsz=128, num_updates=9800, lr=0.000319438, gnorm=1.058, loss_scale=16, train_wall=276, gb_free=8.1, wall=29412
2022-03-06 21:03:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:03:05 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.095 | nll_loss 11.759 | ppl 3466.03 | wps 39895.5 | wpb 510.9 | bsz 1 | num_updates 9827 | best_loss 7.706
2022-03-06 21:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 9827 updates
2022-03-06 21:03:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 102 @ 9827 updates, score 12.095) (writing took 2.554976494051516 seconds)
2022-03-06 21:03:08 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 21:03:08 | INFO | train | epoch 102 | loss 2.079 | nll_loss 1.514 | ppl 2.86 | wps 21600.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 9827 | lr 0.000318999 | gnorm 1.06 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 29500
2022-03-06 21:03:08 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 21:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:05:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:06:47 | INFO | train_inner | epoch 103:     74 / 97 loss=2.066, nll_loss=1.5, ppl=2.83, wps=21388.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=9900, lr=0.000317821, gnorm=1.054, loss_scale=16, train_wall=273, gb_free=8.1, wall=29719
2022-03-06 21:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:08:00 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.188 | nll_loss 11.856 | ppl 3707.49 | wps 39961.1 | wpb 510.9 | bsz 1 | num_updates 9923 | best_loss 7.706
2022-03-06 21:08:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 9923 updates
2022-03-06 21:08:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 103 @ 9923 updates, score 12.188) (writing took 2.5799702838994563 seconds)
2022-03-06 21:08:03 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 21:08:03 | INFO | train | epoch 103 | loss 2.061 | nll_loss 1.495 | ppl 2.82 | wps 21338.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 9923 | lr 0.000317452 | gnorm 1.059 | loss_scale 16 | train_wall 263 | gb_free 8.1 | wall 29795
2022-03-06 21:08:03 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 21:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:11:47 | INFO | train_inner | epoch 104:     77 / 97 loss=2.053, nll_loss=1.486, ppl=2.8, wps=21788.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10000, lr=0.000316228, gnorm=1.055, loss_scale=32, train_wall=268, gb_free=8.1, wall=30019
2022-03-06 21:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:12:49 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.173 | nll_loss 11.838 | ppl 3660.7 | wps 42903.5 | wpb 510.9 | bsz 1 | num_updates 10020 | best_loss 7.706
2022-03-06 21:12:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10020 updates
2022-03-06 21:12:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:12:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 104 @ 10020 updates, score 12.173) (writing took 2.4185459092259407 seconds)
2022-03-06 21:12:52 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 21:12:52 | INFO | train | epoch 104 | loss 2.047 | nll_loss 1.48 | ppl 2.79 | wps 21952.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10020 | lr 0.000315912 | gnorm 1.05 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 30084
2022-03-06 21:12:52 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 21:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:15:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:16:44 | INFO | train_inner | epoch 105:     81 / 97 loss=2.034, nll_loss=1.467, ppl=2.76, wps=22058.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=10100, lr=0.000314658, gnorm=1.048, loss_scale=16, train_wall=266, gb_free=8.1, wall=30316
2022-03-06 21:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:17:35 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.217 | nll_loss 11.886 | ppl 3783.5 | wps 42943.7 | wpb 510.9 | bsz 1 | num_updates 10116 | best_loss 7.706
2022-03-06 21:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10116 updates
2022-03-06 21:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:17:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 105 @ 10116 updates, score 12.217) (writing took 2.4020017026923597 seconds)
2022-03-06 21:17:37 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 21:17:37 | INFO | train | epoch 105 | loss 2.031 | nll_loss 1.464 | ppl 2.76 | wps 22026 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10116 | lr 0.000314409 | gnorm 1.048 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 30369
2022-03-06 21:17:37 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 21:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:21:38 | INFO | train_inner | epoch 106:     84 / 97 loss=2.022, nll_loss=1.454, ppl=2.74, wps=22263.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10200, lr=0.000313112, gnorm=1.046, loss_scale=16, train_wall=264, gb_free=8.1, wall=30610
2022-03-06 21:22:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:22:20 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.263 | nll_loss 11.931 | ppl 3903.44 | wps 42978 | wpb 510.9 | bsz 1 | num_updates 10213 | best_loss 7.706
2022-03-06 21:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10213 updates
2022-03-06 21:22:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:22:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 106 @ 10213 updates, score 12.263) (writing took 2.4969321340322495 seconds)
2022-03-06 21:22:23 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 21:22:23 | INFO | train | epoch 106 | loss 2.016 | nll_loss 1.447 | ppl 2.73 | wps 22240.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10213 | lr 0.000312913 | gnorm 1.037 | loss_scale 32 | train_wall 256 | gb_free 8.1 | wall 30655
2022-03-06 21:22:23 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 21:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:23:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:26:39 | INFO | train_inner | epoch 107:     88 / 97 loss=2.007, nll_loss=1.438, ppl=2.71, wps=21808.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10300, lr=0.000311588, gnorm=1.061, loss_scale=16, train_wall=269, gb_free=8.1, wall=30911
2022-03-06 21:27:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:27:10 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.316 | nll_loss 11.983 | ppl 4047.64 | wps 40097 | wpb 510.9 | bsz 1 | num_updates 10309 | best_loss 7.706
2022-03-06 21:27:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10309 updates
2022-03-06 21:27:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:27:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 107 @ 10309 updates, score 12.316) (writing took 2.5471995691768825 seconds)
2022-03-06 21:27:13 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 21:27:13 | INFO | train | epoch 107 | loss 2.004 | nll_loss 1.434 | ppl 2.7 | wps 21680.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 10309 | lr 0.000311452 | gnorm 1.065 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 30945
2022-03-06 21:27:13 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 21:27:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:31:41 | INFO | train_inner | epoch 108:     91 / 97 loss=1.989, nll_loss=1.419, ppl=2.67, wps=21649.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10400, lr=0.000310087, gnorm=1.035, loss_scale=32, train_wall=270, gb_free=8.1, wall=31213
2022-03-06 21:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:32:04 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.33 | nll_loss 11.999 | ppl 4092.62 | wps 40208 | wpb 510.9 | bsz 1 | num_updates 10406 | best_loss 7.706
2022-03-06 21:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10406 updates
2022-03-06 21:32:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 108 @ 10406 updates, score 12.33) (writing took 2.5581268812529743 seconds)
2022-03-06 21:32:07 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 21:32:07 | INFO | train | epoch 108 | loss 1.988 | nll_loss 1.418 | ppl 2.67 | wps 21633.1 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10406 | lr 0.000309997 | gnorm 1.035 | loss_scale 32 | train_wall 262 | gb_free 8.1 | wall 31239
2022-03-06 21:32:07 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 21:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:35:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:36:46 | INFO | train_inner | epoch 109:     95 / 97 loss=1.981, nll_loss=1.41, ppl=2.66, wps=21449.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=10500, lr=0.000308607, gnorm=1.046, loss_scale=16, train_wall=273, gb_free=8.1, wall=31518
2022-03-06 21:36:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:36:58 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.404 | nll_loss 12.078 | ppl 4322.9 | wps 40311 | wpb 510.9 | bsz 1 | num_updates 10502 | best_loss 7.706
2022-03-06 21:36:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10502 updates
2022-03-06 21:36:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:37:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:37:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 109 @ 10502 updates, score 12.404) (writing took 2.655466774944216 seconds)
2022-03-06 21:37:00 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 21:37:00 | INFO | train | epoch 109 | loss 1.976 | nll_loss 1.405 | ppl 2.65 | wps 21411 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 10502 | lr 0.000308577 | gnorm 1.044 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 31532
2022-03-06 21:37:00 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 21:37:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:41:51 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.362 | nll_loss 12.037 | ppl 4201.06 | wps 40885 | wpb 510.9 | bsz 1 | num_updates 10599 | best_loss 7.706
2022-03-06 21:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10599 updates
2022-03-06 21:41:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:41:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:41:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 110 @ 10599 updates, score 12.362) (writing took 2.443234126549214 seconds)
2022-03-06 21:41:54 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 21:41:54 | INFO | train | epoch 110 | loss 1.963 | nll_loss 1.392 | ppl 2.62 | wps 21662.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10599 | lr 0.000307162 | gnorm 1.045 | loss_scale 32 | train_wall 262 | gb_free 8.1 | wall 31826
2022-03-06 21:41:54 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 21:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:57 | INFO | train_inner | epoch 111:      1 / 97 loss=1.963, nll_loss=1.391, ppl=2.62, wps=21108.4, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=10600, lr=0.000307148, gnorm=1.045, loss_scale=32, train_wall=270, gb_free=8.1, wall=31829
2022-03-06 21:41:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:46:37 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.44 | nll_loss 12.113 | ppl 4429.13 | wps 43107.3 | wpb 510.9 | bsz 1 | num_updates 10695 | best_loss 7.706
2022-03-06 21:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10695 updates
2022-03-06 21:46:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:46:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:46:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 111 @ 10695 updates, score 12.44) (writing took 2.4508337611332536 seconds)
2022-03-06 21:46:39 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 21:46:39 | INFO | train | epoch 111 | loss 1.948 | nll_loss 1.376 | ppl 2.6 | wps 21987.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10695 | lr 0.00030578 | gnorm 1.029 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32111
2022-03-06 21:46:39 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 21:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:46:54 | INFO | train_inner | epoch 112:      5 / 97 loss=1.945, nll_loss=1.373, ppl=2.59, wps=22026.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10700, lr=0.000305709, gnorm=1.028, loss_scale=16, train_wall=267, gb_free=8.1, wall=32126
2022-03-06 21:48:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:51:22 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.441 | nll_loss 12.114 | ppl 4432.71 | wps 43441.6 | wpb 510.9 | bsz 1 | num_updates 10791 | best_loss 7.706
2022-03-06 21:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 10791 updates
2022-03-06 21:51:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 112 @ 10791 updates, score 12.441) (writing took 2.424744931049645 seconds)
2022-03-06 21:51:25 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 21:51:25 | INFO | train | epoch 112 | loss 1.936 | nll_loss 1.364 | ppl 2.57 | wps 22055.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10791 | lr 0.000304417 | gnorm 1.045 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32397
2022-03-06 21:51:25 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 21:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:51:50 | INFO | train_inner | epoch 113:      9 / 97 loss=1.933, nll_loss=1.36, ppl=2.57, wps=22089, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10800, lr=0.00030429, gnorm=1.043, loss_scale=16, train_wall=266, gb_free=8.1, wall=32422
2022-03-06 21:55:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:56:07 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.528 | nll_loss 12.199 | ppl 4703.19 | wps 43122.9 | wpb 510.9 | bsz 1 | num_updates 10887 | best_loss 7.706
2022-03-06 21:56:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 10887 updates
2022-03-06 21:56:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:56:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 21:56:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 113 @ 10887 updates, score 12.528) (writing took 2.392939460929483 seconds)
2022-03-06 21:56:10 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 21:56:10 | INFO | train | epoch 113 | loss 1.923 | nll_loss 1.35 | ppl 2.55 | wps 22039.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10887 | lr 0.000303072 | gnorm 1.037 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 32682
2022-03-06 21:56:10 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 21:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:56:47 | INFO | train_inner | epoch 114:     13 / 97 loss=1.92, nll_loss=1.346, ppl=2.54, wps=22063.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10900, lr=0.000302891, gnorm=1.037, loss_scale=16, train_wall=266, gb_free=8.1, wall=32719
2022-03-06 22:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:00:59 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.503 | nll_loss 12.172 | ppl 4615.96 | wps 39910 | wpb 510.9 | bsz 1 | num_updates 10984 | best_loss 7.706
2022-03-06 22:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 10984 updates
2022-03-06 22:00:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:01:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:01:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 114 @ 10984 updates, score 12.503) (writing took 2.536229328252375 seconds)
2022-03-06 22:01:01 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 22:01:01 | INFO | train | epoch 114 | loss 1.91 | nll_loss 1.337 | ppl 2.53 | wps 21794.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 10984 | lr 0.000301731 | gnorm 1.035 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 32973
2022-03-06 22:01:01 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 22:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:01:48 | INFO | train_inner | epoch 115:     16 / 97 loss=1.907, nll_loss=1.332, ppl=2.52, wps=21736.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11000, lr=0.000301511, gnorm=1.033, loss_scale=16, train_wall=269, gb_free=8.1, wall=33021
2022-03-06 22:02:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:05:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:05:53 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.543 | nll_loss 12.213 | ppl 4748.3 | wps 40020 | wpb 510.9 | bsz 1 | num_updates 11080 | best_loss 7.706
2022-03-06 22:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11080 updates
2022-03-06 22:05:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:05:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:05:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 115 @ 11080 updates, score 12.543) (writing took 2.475244774017483 seconds)
2022-03-06 22:05:55 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 22:05:55 | INFO | train | epoch 115 | loss 1.9 | nll_loss 1.325 | ppl 2.51 | wps 21385.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11080 | lr 0.000300421 | gnorm 1.032 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 33267
2022-03-06 22:05:55 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 22:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:06:54 | INFO | train_inner | epoch 116:     20 / 97 loss=1.895, nll_loss=1.32, ppl=2.5, wps=21425.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=11100, lr=0.00030015, gnorm=1.026, loss_scale=16, train_wall=273, gb_free=8.1, wall=33326
2022-03-06 22:09:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:10:46 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.547 | nll_loss 12.221 | ppl 4773.53 | wps 40063.8 | wpb 510.9 | bsz 1 | num_updates 11176 | best_loss 7.706
2022-03-06 22:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11176 updates
2022-03-06 22:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:10:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 116 @ 11176 updates, score 12.547) (writing took 2.640075286850333 seconds)
2022-03-06 22:10:49 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 22:10:49 | INFO | train | epoch 116 | loss 1.889 | nll_loss 1.314 | ppl 2.49 | wps 21421.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11176 | lr 0.000299128 | gnorm 1.027 | loss_scale 16 | train_wall 262 | gb_free 8.1 | wall 33561
2022-03-06 22:10:49 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 22:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:12:00 | INFO | train_inner | epoch 117:     24 / 97 loss=1.887, nll_loss=1.312, ppl=2.48, wps=21447.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11200, lr=0.000298807, gnorm=1.034, loss_scale=16, train_wall=273, gb_free=8.1, wall=33632
2022-03-06 22:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:15:39 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.569 | nll_loss 12.245 | ppl 4852.65 | wps 41739.2 | wpb 510.9 | bsz 1 | num_updates 11273 | best_loss 7.706
2022-03-06 22:15:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 11273 updates
2022-03-06 22:15:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:15:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:15:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 117 @ 11273 updates, score 12.569) (writing took 2.6644684337079525 seconds)
2022-03-06 22:15:42 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 22:15:42 | INFO | train | epoch 117 | loss 1.878 | nll_loss 1.303 | ppl 2.47 | wps 21682.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 11273 | lr 0.000297838 | gnorm 1.035 | loss_scale 16 | train_wall 261 | gb_free 8.1 | wall 33854
2022-03-06 22:15:42 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 22:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:16:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:17:02 | INFO | train_inner | epoch 118:     28 / 97 loss=1.872, nll_loss=1.296, ppl=2.46, wps=21688.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=11300, lr=0.000297482, gnorm=1.036, loss_scale=16, train_wall=270, gb_free=8.1, wall=33934
2022-03-06 22:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:20:24 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.548 | nll_loss 12.224 | ppl 4783.49 | wps 39638.4 | wpb 510.9 | bsz 1 | num_updates 11369 | best_loss 7.706
2022-03-06 22:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 11369 updates
2022-03-06 22:20:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 118 @ 11369 updates, score 12.548) (writing took 2.319196651224047 seconds)
2022-03-06 22:20:26 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 22:20:26 | INFO | train | epoch 118 | loss 1.864 | nll_loss 1.287 | ppl 2.44 | wps 22093.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11369 | lr 0.000296578 | gnorm 1.017 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 34138
2022-03-06 22:20:26 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 22:20:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:21:57 | INFO | train_inner | epoch 119:     31 / 97 loss=1.86, nll_loss=1.284, ppl=2.43, wps=22195.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11400, lr=0.000296174, gnorm=1.004, loss_scale=16, train_wall=264, gb_free=8.1, wall=34229
2022-03-06 22:23:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:25:14 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.642 | nll_loss 12.316 | ppl 5098.7 | wps 42880.3 | wpb 510.9 | bsz 1 | num_updates 11465 | best_loss 7.706
2022-03-06 22:25:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 11465 updates
2022-03-06 22:25:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:25:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 119 @ 11465 updates, score 12.642) (writing took 2.338130746036768 seconds)
2022-03-06 22:25:16 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 22:25:16 | INFO | train | epoch 119 | loss 1.854 | nll_loss 1.278 | ppl 2.42 | wps 21685.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11465 | lr 0.000295334 | gnorm 1.02 | loss_scale 16 | train_wall 260 | gb_free 8.1 | wall 34428
2022-03-06 22:25:16 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 22:25:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:26:58 | INFO | train_inner | epoch 120:     35 / 97 loss=1.851, nll_loss=1.274, ppl=2.42, wps=21720.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=11500, lr=0.000294884, gnorm=1.02, loss_scale=16, train_wall=270, gb_free=8.1, wall=34530
2022-03-06 22:29:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:30:03 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.679 | nll_loss 12.355 | ppl 5239.81 | wps 40538.4 | wpb 510.9 | bsz 1 | num_updates 11561 | best_loss 7.706
2022-03-06 22:30:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 11561 updates
2022-03-06 22:30:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:30:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:30:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 120 @ 11561 updates, score 12.679) (writing took 2.3630706262774765 seconds)
2022-03-06 22:30:06 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 22:30:06 | INFO | train | epoch 120 | loss 1.843 | nll_loss 1.266 | ppl 2.4 | wps 21713 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11561 | lr 0.000294105 | gnorm 1.006 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 34718
2022-03-06 22:30:06 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 22:30:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:31:59 | INFO | train_inner | epoch 121:     39 / 97 loss=1.837, nll_loss=1.26, ppl=2.39, wps=21748.9, ups=0.33, wpb=65495, bsz=127.9, num_updates=11600, lr=0.00029361, gnorm=1.017, loss_scale=16, train_wall=270, gb_free=8.1, wall=34831
2022-03-06 22:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:34:53 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.639 | nll_loss 12.315 | ppl 5095.28 | wps 40937.6 | wpb 510.9 | bsz 1 | num_updates 11658 | best_loss 7.706
2022-03-06 22:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 11658 updates
2022-03-06 22:34:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 121 @ 11658 updates, score 12.639) (writing took 2.3278821241110563 seconds)
2022-03-06 22:34:55 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 22:34:55 | INFO | train | epoch 121 | loss 1.834 | nll_loss 1.256 | ppl 2.39 | wps 21933.3 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 11658 | lr 0.000292879 | gnorm 1.023 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 35007
2022-03-06 22:34:55 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 22:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:36:57 | INFO | train_inner | epoch 122:     42 / 97 loss=1.83, nll_loss=1.253, ppl=2.38, wps=21968.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11700, lr=0.000292353, gnorm=1.013, loss_scale=32, train_wall=267, gb_free=8.1, wall=35129
2022-03-06 22:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:39:42 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.695 | nll_loss 12.372 | ppl 5299.1 | wps 42547.8 | wpb 510.9 | bsz 1 | num_updates 11754 | best_loss 7.706
2022-03-06 22:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 11754 updates
2022-03-06 22:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 122 @ 11754 updates, score 12.695) (writing took 2.355266878847033 seconds)
2022-03-06 22:39:44 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 22:39:44 | INFO | train | epoch 122 | loss 1.822 | nll_loss 1.244 | ppl 2.37 | wps 21755.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11754 | lr 0.00029168 | gnorm 1.021 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 35296
2022-03-06 22:39:44 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 22:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:41:58 | INFO | train_inner | epoch 123:     46 / 97 loss=1.816, nll_loss=1.238, ppl=2.36, wps=21768.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=11800, lr=0.000291111, gnorm=1.02, loss_scale=16, train_wall=270, gb_free=8.1, wall=35430
2022-03-06 22:44:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:44:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:44:31 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.739 | nll_loss 12.416 | ppl 5466.27 | wps 40983.2 | wpb 510.9 | bsz 1 | num_updates 11850 | best_loss 7.706
2022-03-06 22:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 11850 updates
2022-03-06 22:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:44:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:44:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 123 @ 11850 updates, score 12.739) (writing took 2.3902040058746934 seconds)
2022-03-06 22:44:34 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 22:44:34 | INFO | train | epoch 123 | loss 1.813 | nll_loss 1.234 | ppl 2.35 | wps 21726.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 11850 | lr 0.000290496 | gnorm 1.016 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 35586
2022-03-06 22:44:34 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 22:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:46:59 | INFO | train_inner | epoch 124:     50 / 97 loss=1.81, nll_loss=1.231, ppl=2.35, wps=21782.8, ups=0.33, wpb=65495, bsz=127.9, num_updates=11900, lr=0.000289886, gnorm=1.024, loss_scale=16, train_wall=269, gb_free=8.1, wall=35731
2022-03-06 22:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:49:21 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 12.713 | nll_loss 12.39 | ppl 5366.28 | wps 41008.3 | wpb 510.9 | bsz 1 | num_updates 11947 | best_loss 7.706
2022-03-06 22:49:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 11947 updates
2022-03-06 22:49:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 124 @ 11947 updates, score 12.713) (writing took 2.2406063890084624 seconds)
2022-03-06 22:49:23 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 22:49:23 | INFO | train | epoch 124 | loss 1.803 | nll_loss 1.224 | ppl 2.34 | wps 21968.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11947 | lr 0.000289315 | gnorm 1.017 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 35875
2022-03-06 22:49:23 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 22:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:51:57 | INFO | train_inner | epoch 125:     53 / 97 loss=1.798, nll_loss=1.219, ppl=2.33, wps=21977.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=12000, lr=0.000288675, gnorm=1.01, loss_scale=32, train_wall=267, gb_free=8.1, wall=36029
2022-03-06 22:52:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:54:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:54:10 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 12.768 | nll_loss 12.445 | ppl 5577.01 | wps 40677.4 | wpb 510.9 | bsz 1 | num_updates 12043 | best_loss 7.706
2022-03-06 22:54:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12043 updates
2022-03-06 22:54:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:54:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:54:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 125 @ 12043 updates, score 12.768) (writing took 2.25171453692019 seconds)
2022-03-06 22:54:12 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 22:54:12 | INFO | train | epoch 125 | loss 1.794 | nll_loss 1.215 | ppl 2.32 | wps 21751.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12043 | lr 0.000288159 | gnorm 1.01 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 36164
2022-03-06 22:54:12 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 22:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:56:58 | INFO | train_inner | epoch 126:     57 / 97 loss=1.789, nll_loss=1.209, ppl=2.31, wps=21765.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12100, lr=0.00028748, gnorm=1.018, loss_scale=16, train_wall=270, gb_free=8.1, wall=36330
2022-03-06 22:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:58:59 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 12.795 | nll_loss 12.476 | ppl 5697.03 | wps 40890.6 | wpb 510.9 | bsz 1 | num_updates 12140 | best_loss 7.706
2022-03-06 22:58:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12140 updates
2022-03-06 22:58:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 22:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 126 @ 12140 updates, score 12.795) (writing took 2.3341064741835 seconds)
2022-03-06 22:59:01 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 22:59:01 | INFO | train | epoch 126 | loss 1.785 | nll_loss 1.205 | ppl 2.31 | wps 21945.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12140 | lr 0.000287006 | gnorm 1.018 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 36454
2022-03-06 22:59:01 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 22:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:01:59 | INFO | train_inner | epoch 127:     61 / 97 loss=1.778, nll_loss=1.198, ppl=2.29, wps=21760.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12200, lr=0.000286299, gnorm=1.01, loss_scale=16, train_wall=270, gb_free=8.1, wall=36631
2022-03-06 23:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:03:49 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.792 | nll_loss 12.471 | ppl 5675.65 | wps 40953.9 | wpb 510.9 | bsz 1 | num_updates 12236 | best_loss 7.706
2022-03-06 23:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 12236 updates
2022-03-06 23:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 127 @ 12236 updates, score 12.792) (writing took 2.2577856462448835 seconds)
2022-03-06 23:03:51 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 23:03:51 | INFO | train | epoch 127 | loss 1.774 | nll_loss 1.194 | ppl 2.29 | wps 21723.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12236 | lr 0.000285878 | gnorm 1.017 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 36743
2022-03-06 23:03:51 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 23:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:06:57 | INFO | train_inner | epoch 128:     64 / 97 loss=1.771, nll_loss=1.191, ppl=2.28, wps=21974.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12300, lr=0.000285133, gnorm=1.013, loss_scale=32, train_wall=267, gb_free=8.1, wall=36929
2022-03-06 23:07:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:08:38 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 12.795 | nll_loss 12.474 | ppl 5689.83 | wps 40559.9 | wpb 510.9 | bsz 1 | num_updates 12332 | best_loss 7.706
2022-03-06 23:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 12332 updates
2022-03-06 23:08:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 128 @ 12332 updates, score 12.795) (writing took 2.289316042792052 seconds)
2022-03-06 23:08:40 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 23:08:40 | INFO | train | epoch 128 | loss 1.764 | nll_loss 1.183 | ppl 2.27 | wps 21750.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12332 | lr 0.000284763 | gnorm 1.008 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 37032
2022-03-06 23:08:40 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 23:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:11:57 | INFO | train_inner | epoch 129:     68 / 97 loss=1.758, nll_loss=1.178, ppl=2.26, wps=21786, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12400, lr=0.000283981, gnorm=1.021, loss_scale=16, train_wall=269, gb_free=8.1, wall=37229
2022-03-06 23:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:27 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 12.871 | nll_loss 12.555 | ppl 6016.42 | wps 40711 | wpb 510.9 | bsz 1 | num_updates 12429 | best_loss 7.706
2022-03-06 23:13:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 12429 updates
2022-03-06 23:13:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:13:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 129 @ 12429 updates, score 12.871) (writing took 2.331877768971026 seconds)
2022-03-06 23:13:29 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 23:13:29 | INFO | train | epoch 129 | loss 1.756 | nll_loss 1.175 | ppl 2.26 | wps 21955.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12429 | lr 0.000283649 | gnorm 1.017 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 37321
2022-03-06 23:13:29 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 23:13:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:15:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:16:58 | INFO | train_inner | epoch 130:     72 / 97 loss=1.751, nll_loss=1.17, ppl=2.25, wps=21757, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12500, lr=0.000282843, gnorm=0.999, loss_scale=16, train_wall=270, gb_free=8.1, wall=37530
2022-03-06 23:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:16 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 12.922 | nll_loss 12.606 | ppl 6236.23 | wps 40967.8 | wpb 510.9 | bsz 1 | num_updates 12525 | best_loss 7.706
2022-03-06 23:18:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 12525 updates
2022-03-06 23:18:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 130 @ 12525 updates, score 12.922) (writing took 2.2346221059560776 seconds)
2022-03-06 23:18:19 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 23:18:19 | INFO | train | epoch 130 | loss 1.746 | nll_loss 1.164 | ppl 2.24 | wps 21735.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12525 | lr 0.00028256 | gnorm 0.994 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 37611
2022-03-06 23:18:19 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 23:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:21:57 | INFO | train_inner | epoch 131:     75 / 97 loss=1.738, nll_loss=1.157, ppl=2.23, wps=21969.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12600, lr=0.000281718, gnorm=1.002, loss_scale=16, train_wall=267, gb_free=8.1, wall=37829
2022-03-06 23:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:23:06 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 12.879 | nll_loss 12.56 | ppl 6037.32 | wps 40678.1 | wpb 510.9 | bsz 1 | num_updates 12622 | best_loss 7.706
2022-03-06 23:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 12622 updates
2022-03-06 23:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:23:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 131 @ 12622 updates, score 12.879) (writing took 2.4310858179815114 seconds)
2022-03-06 23:23:08 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 23:23:08 | INFO | train | epoch 131 | loss 1.738 | nll_loss 1.156 | ppl 2.23 | wps 21946.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12622 | lr 0.000281472 | gnorm 0.998 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 37900
2022-03-06 23:23:08 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 23:23:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:25:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:26:58 | INFO | train_inner | epoch 132:     79 / 97 loss=1.733, nll_loss=1.151, ppl=2.22, wps=21753.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12700, lr=0.000280607, gnorm=0.99, loss_scale=16, train_wall=270, gb_free=8.1, wall=38130
2022-03-06 23:27:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:55 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 12.91 | nll_loss 12.588 | ppl 6158.83 | wps 40254.6 | wpb 510.9 | bsz 1 | num_updates 12718 | best_loss 7.706
2022-03-06 23:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 12718 updates
2022-03-06 23:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:27:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:27:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 132 @ 12718 updates, score 12.91) (writing took 2.270544036757201 seconds)
2022-03-06 23:27:58 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 23:27:58 | INFO | train | epoch 132 | loss 1.73 | nll_loss 1.148 | ppl 2.22 | wps 21715.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12718 | lr 0.000280408 | gnorm 0.998 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 38190
2022-03-06 23:27:58 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 23:27:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:31:56 | INFO | train_inner | epoch 133:     82 / 97 loss=1.725, nll_loss=1.143, ppl=2.21, wps=21955.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12800, lr=0.000279508, gnorm=1.004, loss_scale=32, train_wall=267, gb_free=8.1, wall=38428
2022-03-06 23:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:45 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 12.889 | nll_loss 12.575 | ppl 6099.84 | wps 40999.3 | wpb 510.9 | bsz 1 | num_updates 12815 | best_loss 7.706
2022-03-06 23:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 12815 updates
2022-03-06 23:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 133 @ 12815 updates, score 12.889) (writing took 2.273051213938743 seconds)
2022-03-06 23:32:47 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 23:32:47 | INFO | train | epoch 133 | loss 1.721 | nll_loss 1.139 | ppl 2.2 | wps 21947 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12815 | lr 0.000279345 | gnorm 0.998 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 38479
2022-03-06 23:32:47 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 23:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:34:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:36:57 | INFO | train_inner | epoch 134:     86 / 97 loss=1.717, nll_loss=1.134, ppl=2.2, wps=21783.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=12900, lr=0.000278423, gnorm=0.993, loss_scale=16, train_wall=270, gb_free=8.1, wall=38729
2022-03-06 23:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:34 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 12.937 | nll_loss 12.621 | ppl 6298.82 | wps 40780.1 | wpb 510.9 | bsz 1 | num_updates 12911 | best_loss 7.706
2022-03-06 23:37:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 12911 updates
2022-03-06 23:37:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:37:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:37:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 134 @ 12911 updates, score 12.937) (writing took 2.293184761889279 seconds)
2022-03-06 23:37:36 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 23:37:36 | INFO | train | epoch 134 | loss 1.715 | nll_loss 1.132 | ppl 2.19 | wps 21747.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 12911 | lr 0.000278304 | gnorm 0.995 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 38768
2022-03-06 23:37:36 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 23:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:40:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:41:58 | INFO | train_inner | epoch 135:     90 / 97 loss=1.71, nll_loss=1.127, ppl=2.18, wps=21756.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13000, lr=0.00027735, gnorm=1.009, loss_scale=16, train_wall=270, gb_free=8.1, wall=39030
2022-03-06 23:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:42:23 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 12.921 | nll_loss 12.602 | ppl 6218.2 | wps 40581.2 | wpb 510.9 | bsz 1 | num_updates 13007 | best_loss 7.706
2022-03-06 23:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13007 updates
2022-03-06 23:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 135 @ 13007 updates, score 12.921) (writing took 2.2432503108866513 seconds)
2022-03-06 23:42:25 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 23:42:25 | INFO | train | epoch 135 | loss 1.706 | nll_loss 1.124 | ppl 2.18 | wps 21728.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13007 | lr 0.000277275 | gnorm 1.007 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 39057
2022-03-06 23:42:25 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 23:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:45:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 23:46:58 | INFO | train_inner | epoch 136:     94 / 97 loss=1.699, nll_loss=1.116, ppl=2.17, wps=21778.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13100, lr=0.000276289, gnorm=0.996, loss_scale=8, train_wall=270, gb_free=8.1, wall=39330
2022-03-06 23:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:47:12 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 12.953 | nll_loss 12.639 | ppl 6377.39 | wps 41028.2 | wpb 510.9 | bsz 1 | num_updates 13103 | best_loss 7.706
2022-03-06 23:47:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13103 updates
2022-03-06 23:47:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 136 @ 13103 updates, score 12.953) (writing took 2.2858662689104676 seconds)
2022-03-06 23:47:15 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 23:47:15 | INFO | train | epoch 136 | loss 1.697 | nll_loss 1.114 | ppl 2.16 | wps 21748.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13103 | lr 0.000276258 | gnorm 0.996 | loss_scale 8 | train_wall 259 | gb_free 8.1 | wall 39347
2022-03-06 23:47:15 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 23:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:56 | INFO | train_inner | epoch 137:     97 / 97 loss=1.691, nll_loss=1.107, ppl=2.15, wps=21983.1, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=13200, lr=0.000275241, gnorm=0.986, loss_scale=16, train_wall=267, gb_free=8.1, wall=39628
2022-03-06 23:51:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:02 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 12.907 | nll_loss 12.592 | ppl 6176.04 | wps 40470.5 | wpb 510.9 | bsz 1 | num_updates 13200 | best_loss 7.706
2022-03-06 23:52:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 13200 updates
2022-03-06 23:52:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:52:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 137 @ 13200 updates, score 12.907) (writing took 2.3255191282369196 seconds)
2022-03-06 23:52:04 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 23:52:04 | INFO | train | epoch 137 | loss 1.688 | nll_loss 1.105 | ppl 2.15 | wps 21956.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13200 | lr 0.000275241 | gnorm 0.984 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 39636
2022-03-06 23:52:04 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 23:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:51 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 12.939 | nll_loss 12.622 | ppl 6302.74 | wps 40341.3 | wpb 510.9 | bsz 1 | num_updates 13297 | best_loss 7.706
2022-03-06 23:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 13297 updates
2022-03-06 23:56:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:56:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-06 23:56:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 138 @ 13297 updates, score 12.939) (writing took 2.2447002776898444 seconds)
2022-03-06 23:56:53 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 23:56:53 | INFO | train | epoch 138 | loss 1.683 | nll_loss 1.1 | ppl 2.14 | wps 21934.7 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 13297 | lr 0.000274235 | gnorm 0.991 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 39925
2022-03-06 23:56:53 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 23:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:57:02 | INFO | train_inner | epoch 139:      3 / 97 loss=1.681, nll_loss=1.097, ppl=2.14, wps=21390.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13300, lr=0.000274204, gnorm=0.99, loss_scale=16, train_wall=267, gb_free=8.1, wall=39934
2022-03-06 23:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:40 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 12.982 | nll_loss 12.667 | ppl 6504.54 | wps 41381.1 | wpb 510.9 | bsz 1 | num_updates 13393 | best_loss 7.706
2022-03-07 00:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 13393 updates
2022-03-07 00:01:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 139 @ 13393 updates, score 12.982) (writing took 2.240325569640845 seconds)
2022-03-07 00:01:43 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-07 00:01:43 | INFO | train | epoch 139 | loss 1.674 | nll_loss 1.091 | ppl 2.13 | wps 21739.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13393 | lr 0.000273251 | gnorm 0.993 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 40215
2022-03-07 00:01:43 | INFO | fairseq.trainer | begin training epoch 140
2022-03-07 00:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:03 | INFO | train_inner | epoch 140:      7 / 97 loss=1.672, nll_loss=1.088, ppl=2.13, wps=21780.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13400, lr=0.000273179, gnorm=0.991, loss_scale=16, train_wall=270, gb_free=8.1, wall=40235
2022-03-07 00:05:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:30 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.009 | nll_loss 12.694 | ppl 6627.5 | wps 40416.4 | wpb 510.9 | bsz 1 | num_updates 13489 | best_loss 7.706
2022-03-07 00:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 13489 updates
2022-03-07 00:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:06:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:06:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 140 @ 13489 updates, score 13.009) (writing took 2.2687207399867475 seconds)
2022-03-07 00:06:32 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-07 00:06:32 | INFO | train | epoch 140 | loss 1.665 | nll_loss 1.082 | ppl 2.12 | wps 21745.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13489 | lr 0.000272276 | gnorm 0.966 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 40504
2022-03-07 00:06:32 | INFO | fairseq.trainer | begin training epoch 141
2022-03-07 00:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:07:04 | INFO | train_inner | epoch 141:     11 / 97 loss=1.665, nll_loss=1.081, ppl=2.12, wps=21767.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13500, lr=0.000272166, gnorm=0.969, loss_scale=16, train_wall=270, gb_free=8.1, wall=40536
2022-03-07 00:09:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:11:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:11:19 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.001 | nll_loss 12.685 | ppl 6584.4 | wps 40193.1 | wpb 510.9 | bsz 1 | num_updates 13585 | best_loss 7.706
2022-03-07 00:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 13585 updates
2022-03-07 00:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:11:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 141 @ 13585 updates, score 13.001) (writing took 2.5667728651314974 seconds)
2022-03-07 00:11:21 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 00:11:21 | INFO | train | epoch 141 | loss 1.661 | nll_loss 1.077 | ppl 2.11 | wps 21703 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13585 | lr 0.000271313 | gnorm 0.999 | loss_scale 8 | train_wall 259 | gb_free 8.1 | wall 40794
2022-03-07 00:11:21 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 00:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:12:05 | INFO | train_inner | epoch 142:     15 / 97 loss=1.657, nll_loss=1.073, ppl=2.1, wps=21736.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13600, lr=0.000271163, gnorm=0.995, loss_scale=8, train_wall=270, gb_free=8.1, wall=40837
2022-03-07 00:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:16:08 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.042 | nll_loss 12.729 | ppl 6790.95 | wps 40913.6 | wpb 510.9 | bsz 1 | num_updates 13682 | best_loss 7.706
2022-03-07 00:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 13682 updates
2022-03-07 00:16:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 142 @ 13682 updates, score 13.042) (writing took 2.307090412825346 seconds)
2022-03-07 00:16:11 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 00:16:11 | INFO | train | epoch 142 | loss 1.654 | nll_loss 1.07 | ppl 2.1 | wps 21969.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13682 | lr 0.000270349 | gnorm 0.986 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 41083
2022-03-07 00:16:11 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 00:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:17:03 | INFO | train_inner | epoch 143:     18 / 97 loss=1.651, nll_loss=1.067, ppl=2.09, wps=21994.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13700, lr=0.000270172, gnorm=0.987, loss_scale=16, train_wall=267, gb_free=8.1, wall=41135
2022-03-07 00:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:20:58 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.099 | nll_loss 12.789 | ppl 7078.75 | wps 40513.7 | wpb 510.9 | bsz 1 | num_updates 13779 | best_loss 7.706
2022-03-07 00:20:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 13779 updates
2022-03-07 00:20:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 143 @ 13779 updates, score 13.099) (writing took 2.285360792186111 seconds)
2022-03-07 00:21:00 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 00:21:00 | INFO | train | epoch 143 | loss 1.645 | nll_loss 1.06 | ppl 2.09 | wps 21952.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13779 | lr 0.000269396 | gnorm 0.975 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 41372
2022-03-07 00:21:00 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 00:21:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:22:01 | INFO | train_inner | epoch 144:     21 / 97 loss=1.642, nll_loss=1.057, ppl=2.08, wps=21957.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13800, lr=0.000269191, gnorm=0.97, loss_scale=16, train_wall=267, gb_free=8.1, wall=41433
2022-03-07 00:23:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:25:47 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.082 | nll_loss 12.771 | ppl 6988.58 | wps 40220.9 | wpb 510.9 | bsz 1 | num_updates 13875 | best_loss 7.706
2022-03-07 00:25:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 13875 updates
2022-03-07 00:25:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:25:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 144 @ 13875 updates, score 13.082) (writing took 2.2262790729291737 seconds)
2022-03-07 00:25:49 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 00:25:49 | INFO | train | epoch 144 | loss 1.638 | nll_loss 1.053 | ppl 2.08 | wps 21718.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13875 | lr 0.000268462 | gnorm 0.983 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 41662
2022-03-07 00:25:50 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 00:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:27:02 | INFO | train_inner | epoch 145:     25 / 97 loss=1.635, nll_loss=1.05, ppl=2.07, wps=21751.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13900, lr=0.000268221, gnorm=0.977, loss_scale=16, train_wall=270, gb_free=8.1, wall=41734
2022-03-07 00:30:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:37 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.085 | nll_loss 12.775 | ppl 7009.41 | wps 40932.4 | wpb 510.9 | bsz 1 | num_updates 13971 | best_loss 7.706
2022-03-07 00:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 13971 updates
2022-03-07 00:30:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 145 @ 13971 updates, score 13.085) (writing took 2.2244720929302275 seconds)
2022-03-07 00:30:39 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 00:30:39 | INFO | train | epoch 145 | loss 1.631 | nll_loss 1.046 | ppl 2.07 | wps 21735.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 13971 | lr 0.000267538 | gnorm 0.965 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 41951
2022-03-07 00:30:39 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 00:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:32:03 | INFO | train_inner | epoch 146:     29 / 97 loss=1.631, nll_loss=1.046, ppl=2.06, wps=21772.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=14000, lr=0.000267261, gnorm=0.974, loss_scale=16, train_wall=270, gb_free=8.1, wall=42035
2022-03-07 00:34:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:35:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:35:26 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.101 | nll_loss 12.793 | ppl 7099.24 | wps 40536.9 | wpb 510.9 | bsz 1 | num_updates 14067 | best_loss 7.706
2022-03-07 00:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 14067 updates
2022-03-07 00:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 146 @ 14067 updates, score 13.101) (writing took 2.2542446716688573 seconds)
2022-03-07 00:35:28 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 00:35:28 | INFO | train | epoch 146 | loss 1.625 | nll_loss 1.039 | ppl 2.06 | wps 21736.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 14067 | lr 0.000266624 | gnorm 0.976 | loss_scale 8 | train_wall 259 | gb_free 8.1 | wall 42240
2022-03-07 00:35:28 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 00:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:37:04 | INFO | train_inner | epoch 147:     33 / 97 loss=1.621, nll_loss=1.035, ppl=2.05, wps=21759.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=14100, lr=0.000266312, gnorm=0.967, loss_scale=8, train_wall=270, gb_free=8.1, wall=42336
2022-03-07 00:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:40:15 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.158 | nll_loss 12.849 | ppl 7377.99 | wps 40302.3 | wpb 510.9 | bsz 1 | num_updates 14164 | best_loss 7.706
2022-03-07 00:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 14164 updates
2022-03-07 00:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 147 @ 14164 updates, score 13.158) (writing took 2.2748046540655196 seconds)
2022-03-07 00:40:17 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 00:40:17 | INFO | train | epoch 147 | loss 1.618 | nll_loss 1.032 | ppl 2.05 | wps 21947.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14164 | lr 0.000265709 | gnorm 0.971 | loss_scale 8 | train_wall 259 | gb_free 8.1 | wall 42529
2022-03-07 00:40:17 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 00:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:42:02 | INFO | train_inner | epoch 148:     36 / 97 loss=1.616, nll_loss=1.03, ppl=2.04, wps=21983.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14200, lr=0.000265372, gnorm=0.98, loss_scale=16, train_wall=267, gb_free=8.1, wall=42634
2022-03-07 00:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:45:04 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.155 | nll_loss 12.847 | ppl 7367.34 | wps 40888.8 | wpb 510.9 | bsz 1 | num_updates 14261 | best_loss 7.706
2022-03-07 00:45:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 14261 updates
2022-03-07 00:45:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:45:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 148 @ 14261 updates, score 13.155) (writing took 2.3183709857985377 seconds)
2022-03-07 00:45:07 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 00:45:07 | INFO | train | epoch 148 | loss 1.613 | nll_loss 1.027 | ppl 2.04 | wps 21958.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14261 | lr 0.000264804 | gnorm 0.976 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 42819
2022-03-07 00:45:07 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 00:45:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:47:00 | INFO | train_inner | epoch 149:     39 / 97 loss=1.61, nll_loss=1.024, ppl=2.03, wps=21959.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14300, lr=0.000264443, gnorm=0.965, loss_scale=16, train_wall=267, gb_free=8.1, wall=42932
2022-03-07 00:47:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:47:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-07 00:49:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:49:54 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.133 | nll_loss 12.825 | ppl 7255.82 | wps 40380.6 | wpb 510.9 | bsz 1 | num_updates 14356 | best_loss 7.706
2022-03-07 00:49:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 14356 updates
2022-03-07 00:49:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:49:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:49:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 149 @ 14356 updates, score 13.133) (writing took 2.2517272597178817 seconds)
2022-03-07 00:49:56 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 00:49:56 | INFO | train | epoch 149 | loss 1.603 | nll_loss 1.018 | ppl 2.02 | wps 21494.3 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 14356 | lr 0.000263927 | gnorm 0.956 | loss_scale 8 | train_wall 259 | gb_free 8.1 | wall 43108
2022-03-07 00:49:56 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 00:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:52:04 | INFO | train_inner | epoch 150:     44 / 97 loss=1.602, nll_loss=1.016, ppl=2.02, wps=21546.2, ups=0.33, wpb=65495, bsz=127.9, num_updates=14400, lr=0.000263523, gnorm=0.967, loss_scale=8, train_wall=272, gb_free=8.1, wall=43236
2022-03-07 00:54:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:54:44 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.15 | nll_loss 12.839 | ppl 7327.45 | wps 40400.6 | wpb 510.9 | bsz 1 | num_updates 14453 | best_loss 7.706
2022-03-07 00:54:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 14453 updates
2022-03-07 00:54:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 150 @ 14453 updates, score 13.15) (writing took 2.2943717688322067 seconds)
2022-03-07 00:54:46 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 00:54:46 | INFO | train | epoch 150 | loss 1.601 | nll_loss 1.015 | ppl 2.02 | wps 21931.2 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 14453 | lr 0.00026304 | gnorm 0.977 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 43398
2022-03-07 00:54:46 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 00:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:57:02 | INFO | train_inner | epoch 151:     47 / 97 loss=1.596, nll_loss=1.01, ppl=2.01, wps=21954.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14500, lr=0.000262613, gnorm=0.963, loss_scale=16, train_wall=267, gb_free=8.1, wall=43535
2022-03-07 00:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:59:33 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.161 | nll_loss 12.85 | ppl 7384.64 | wps 40997 | wpb 510.9 | bsz 1 | num_updates 14550 | best_loss 7.706
2022-03-07 00:59:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 14550 updates
2022-03-07 00:59:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:59:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 00:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 151 @ 14550 updates, score 13.161) (writing took 2.2257865802384913 seconds)
2022-03-07 00:59:35 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 00:59:35 | INFO | train | epoch 151 | loss 1.593 | nll_loss 1.006 | ppl 2.01 | wps 21955 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14550 | lr 0.000262161 | gnorm 0.959 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 43687
2022-03-07 00:59:35 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 00:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:00:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:02:03 | INFO | train_inner | epoch 152:     51 / 97 loss=1.59, nll_loss=1.003, ppl=2, wps=21764.7, ups=0.33, wpb=65495, bsz=127.9, num_updates=14600, lr=0.000261712, gnorm=0.963, loss_scale=16, train_wall=270, gb_free=8.1, wall=43835
2022-03-07 01:04:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:04:22 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.203 | nll_loss 12.898 | ppl 7634.54 | wps 40726.2 | wpb 510.9 | bsz 1 | num_updates 14646 | best_loss 7.706
2022-03-07 01:04:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 14646 updates
2022-03-07 01:04:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:04:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:04:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 152 @ 14646 updates, score 13.203) (writing took 2.259027022868395 seconds)
2022-03-07 01:04:24 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 01:04:24 | INFO | train | epoch 152 | loss 1.586 | nll_loss 1 | ppl 2 | wps 21743.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 14646 | lr 0.000261301 | gnorm 0.964 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 43976
2022-03-07 01:04:24 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 01:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:07:01 | INFO | train_inner | epoch 153:     54 / 97 loss=1.584, nll_loss=0.997, ppl=2, wps=21986.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14700, lr=0.00026082, gnorm=0.963, loss_scale=32, train_wall=267, gb_free=8.1, wall=44133
2022-03-07 01:07:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:09:11 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.184 | nll_loss 12.875 | ppl 7513.19 | wps 40392.9 | wpb 510.9 | bsz 1 | num_updates 14742 | best_loss 7.706
2022-03-07 01:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 14742 updates
2022-03-07 01:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:09:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:09:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 153 @ 14742 updates, score 13.184) (writing took 2.2485350440256298 seconds)
2022-03-07 01:09:14 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 01:09:14 | INFO | train | epoch 153 | loss 1.581 | nll_loss 0.994 | ppl 1.99 | wps 21730.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 14742 | lr 0.000260448 | gnorm 0.96 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 44266
2022-03-07 01:09:14 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 01:09:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:02 | INFO | train_inner | epoch 154:     58 / 97 loss=1.577, nll_loss=0.991, ppl=1.99, wps=21770.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=14800, lr=0.000259938, gnorm=0.959, loss_scale=16, train_wall=270, gb_free=8.1, wall=44434
2022-03-07 01:13:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:14:01 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.231 | nll_loss 12.926 | ppl 7780.51 | wps 41045.4 | wpb 510.9 | bsz 1 | num_updates 14839 | best_loss 7.706
2022-03-07 01:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 14839 updates
2022-03-07 01:14:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 154 @ 14839 updates, score 13.231) (writing took 2.2471443759277463 seconds)
2022-03-07 01:14:03 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 01:14:03 | INFO | train | epoch 154 | loss 1.576 | nll_loss 0.989 | ppl 1.99 | wps 21973.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14839 | lr 0.000259596 | gnorm 0.957 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 44555
2022-03-07 01:14:03 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 01:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:14:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:17:03 | INFO | train_inner | epoch 155:     62 / 97 loss=1.574, nll_loss=0.987, ppl=1.98, wps=21769, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=14900, lr=0.000259064, gnorm=0.971, loss_scale=16, train_wall=270, gb_free=8.1, wall=44735
2022-03-07 01:18:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:18:50 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.232 | nll_loss 12.926 | ppl 7779.73 | wps 40648.3 | wpb 510.9 | bsz 1 | num_updates 14935 | best_loss 7.706
2022-03-07 01:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 14935 updates
2022-03-07 01:18:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 155 @ 14935 updates, score 13.232) (writing took 2.2569210371002555 seconds)
2022-03-07 01:18:52 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 01:18:52 | INFO | train | epoch 155 | loss 1.569 | nll_loss 0.983 | ppl 1.98 | wps 21740.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 14935 | lr 0.00025876 | gnorm 0.978 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 44844
2022-03-07 01:18:52 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 01:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:22:04 | INFO | train_inner | epoch 156:     66 / 97 loss=1.565, nll_loss=0.978, ppl=1.97, wps=21778.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15000, lr=0.000258199, gnorm=0.962, loss_scale=16, train_wall=270, gb_free=8.1, wall=45036
2022-03-07 01:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:23:39 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.214 | nll_loss 12.906 | ppl 7677.33 | wps 40483.7 | wpb 510.9 | bsz 1 | num_updates 15031 | best_loss 7.706
2022-03-07 01:23:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 15031 updates
2022-03-07 01:23:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:23:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:23:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 156 @ 15031 updates, score 13.214) (writing took 2.266505992040038 seconds)
2022-03-07 01:23:41 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 01:23:41 | INFO | train | epoch 156 | loss 1.563 | nll_loss 0.976 | ppl 1.97 | wps 21729.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15031 | lr 0.000257932 | gnorm 0.955 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 45133
2022-03-07 01:23:41 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 01:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:02 | INFO | train_inner | epoch 157:     69 / 97 loss=1.561, nll_loss=0.974, ppl=1.96, wps=21968.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=15100, lr=0.000257343, gnorm=0.957, loss_scale=16, train_wall=267, gb_free=8.1, wall=45334
2022-03-07 01:27:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:28:28 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.217 | nll_loss 12.908 | ppl 7684.11 | wps 40932.8 | wpb 510.9 | bsz 1 | num_updates 15127 | best_loss 7.706
2022-03-07 01:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 15127 updates
2022-03-07 01:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 157 @ 15127 updates, score 13.217) (writing took 2.319237883668393 seconds)
2022-03-07 01:28:31 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 01:28:31 | INFO | train | epoch 157 | loss 1.558 | nll_loss 0.971 | ppl 1.96 | wps 21736.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15127 | lr 0.000257113 | gnorm 0.961 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 45423
2022-03-07 01:28:31 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 01:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:03 | INFO | train_inner | epoch 158:     73 / 97 loss=1.556, nll_loss=0.969, ppl=1.96, wps=21765.7, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=15200, lr=0.000256495, gnorm=0.96, loss_scale=16, train_wall=270, gb_free=8.1, wall=45635
2022-03-07 01:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:33:18 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.298 | nll_loss 12.993 | ppl 8154.63 | wps 40825.8 | wpb 510.9 | bsz 1 | num_updates 15224 | best_loss 7.706
2022-03-07 01:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 15224 updates
2022-03-07 01:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 158 @ 15224 updates, score 13.298) (writing took 2.334753136150539 seconds)
2022-03-07 01:33:20 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 01:33:20 | INFO | train | epoch 158 | loss 1.553 | nll_loss 0.966 | ppl 1.95 | wps 21960.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15224 | lr 0.000256292 | gnorm 0.953 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 45712
2022-03-07 01:33:20 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 01:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:35:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:37:04 | INFO | train_inner | epoch 159:     77 / 97 loss=1.55, nll_loss=0.963, ppl=1.95, wps=21773.5, ups=0.33, wpb=65495, bsz=127.9, num_updates=15300, lr=0.000255655, gnorm=0.95, loss_scale=16, train_wall=270, gb_free=8.1, wall=45936
2022-03-07 01:38:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:38:07 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.292 | nll_loss 12.987 | ppl 8121.24 | wps 40509.9 | wpb 510.9 | bsz 1 | num_updates 15320 | best_loss 7.706
2022-03-07 01:38:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 15320 updates
2022-03-07 01:38:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:38:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 159 @ 15320 updates, score 13.292) (writing took 2.3298814459703863 seconds)
2022-03-07 01:38:09 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 01:38:09 | INFO | train | epoch 159 | loss 1.547 | nll_loss 0.96 | ppl 1.95 | wps 21731.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15320 | lr 0.000255488 | gnorm 0.949 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 46001
2022-03-07 01:38:09 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 01:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:42:02 | INFO | train_inner | epoch 160:     80 / 97 loss=1.542, nll_loss=0.955, ppl=1.94, wps=21959.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15400, lr=0.000254824, gnorm=0.948, loss_scale=32, train_wall=267, gb_free=8.1, wall=46234
2022-03-07 01:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:42:56 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.295 | nll_loss 12.99 | ppl 8135.33 | wps 41075.2 | wpb 510.9 | bsz 1 | num_updates 15417 | best_loss 7.706
2022-03-07 01:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 15417 updates
2022-03-07 01:42:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:42:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 160 @ 15417 updates, score 13.295) (writing took 2.2378501100465655 seconds)
2022-03-07 01:42:59 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 01:42:59 | INFO | train | epoch 160 | loss 1.542 | nll_loss 0.954 | ppl 1.94 | wps 21956.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15417 | lr 0.000254683 | gnorm 0.944 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 46291
2022-03-07 01:42:59 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 01:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:47:03 | INFO | train_inner | epoch 161:     84 / 97 loss=1.539, nll_loss=0.952, ppl=1.93, wps=21765.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15500, lr=0.000254, gnorm=0.939, loss_scale=16, train_wall=270, gb_free=8.1, wall=46535
2022-03-07 01:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:47:46 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.278 | nll_loss 12.971 | ppl 8030.76 | wps 40465 | wpb 510.9 | bsz 1 | num_updates 15513 | best_loss 7.706
2022-03-07 01:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 15513 updates
2022-03-07 01:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:47:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 161 @ 15513 updates, score 13.278) (writing took 2.31695605115965 seconds)
2022-03-07 01:47:48 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 01:47:48 | INFO | train | epoch 161 | loss 1.537 | nll_loss 0.949 | ppl 1.93 | wps 21726.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15513 | lr 0.000253894 | gnorm 0.94 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 46580
2022-03-07 01:47:48 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 01:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:52:04 | INFO | train_inner | epoch 162:     88 / 97 loss=1.534, nll_loss=0.946, ppl=1.93, wps=21762.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15600, lr=0.000253185, gnorm=0.941, loss_scale=16, train_wall=270, gb_free=8.1, wall=46836
2022-03-07 01:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:52:35 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.32 | nll_loss 13.017 | ppl 8289.08 | wps 41239.4 | wpb 510.9 | bsz 1 | num_updates 15609 | best_loss 7.706
2022-03-07 01:52:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 15609 updates
2022-03-07 01:52:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:52:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 162 @ 15609 updates, score 13.32) (writing took 2.3746562930755317 seconds)
2022-03-07 01:52:37 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 01:52:37 | INFO | train | epoch 162 | loss 1.531 | nll_loss 0.943 | ppl 1.92 | wps 21725.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15609 | lr 0.000253112 | gnorm 0.941 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 46869
2022-03-07 01:52:37 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 01:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:56:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:57:05 | INFO | train_inner | epoch 163:     92 / 97 loss=1.529, nll_loss=0.941, ppl=1.92, wps=21738.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=15700, lr=0.000252377, gnorm=0.962, loss_scale=16, train_wall=270, gb_free=8.1, wall=47137
2022-03-07 01:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:57:25 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.352 | nll_loss 13.05 | ppl 8479.17 | wps 40997 | wpb 510.9 | bsz 1 | num_updates 15705 | best_loss 7.706
2022-03-07 01:57:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 15705 updates
2022-03-07 01:57:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:57:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 01:57:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 163 @ 15705 updates, score 13.352) (writing took 2.325755164027214 seconds)
2022-03-07 01:57:27 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 01:57:27 | INFO | train | epoch 163 | loss 1.527 | nll_loss 0.939 | ppl 1.92 | wps 21708.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15705 | lr 0.000252337 | gnorm 0.96 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 47159
2022-03-07 01:57:27 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 01:57:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:02:03 | INFO | train_inner | epoch 164:     95 / 97 loss=1.52, nll_loss=0.932, ppl=1.91, wps=21990, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15800, lr=0.000251577, gnorm=0.938, loss_scale=16, train_wall=267, gb_free=8.1, wall=47435
2022-03-07 02:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:02:14 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.325 | nll_loss 13.023 | ppl 8321.89 | wps 40489.9 | wpb 510.9 | bsz 1 | num_updates 15802 | best_loss 7.706
2022-03-07 02:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 15802 updates
2022-03-07 02:02:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:02:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 164 @ 15802 updates, score 13.325) (writing took 2.2680838201195 seconds)
2022-03-07 02:02:16 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 02:02:16 | INFO | train | epoch 164 | loss 1.52 | nll_loss 0.932 | ppl 1.91 | wps 21969.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15802 | lr 0.000251561 | gnorm 0.937 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 47448
2022-03-07 02:02:16 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 02:02:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:03:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:06:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:07:03 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.388 | nll_loss 13.087 | ppl 8698.9 | wps 41179.8 | wpb 510.9 | bsz 1 | num_updates 15898 | best_loss 7.706
2022-03-07 02:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 15898 updates
2022-03-07 02:07:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:07:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:07:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 165 @ 15898 updates, score 13.388) (writing took 2.3256946611218154 seconds)
2022-03-07 02:07:05 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 02:07:05 | INFO | train | epoch 165 | loss 1.516 | nll_loss 0.927 | ppl 1.9 | wps 21738.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15898 | lr 0.000250801 | gnorm 0.944 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 47737
2022-03-07 02:07:05 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 02:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:07:11 | INFO | train_inner | epoch 166:      2 / 97 loss=1.516, nll_loss=0.927, ppl=1.9, wps=21220.1, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=15900, lr=0.000250785, gnorm=0.944, loss_scale=16, train_wall=269, gb_free=8.1, wall=47743
2022-03-07 02:09:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:11:52 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.401 | nll_loss 13.1 | ppl 8777.48 | wps 41066.6 | wpb 510.9 | bsz 1 | num_updates 15994 | best_loss 7.706
2022-03-07 02:11:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 15994 updates
2022-03-07 02:11:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:11:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 166 @ 15994 updates, score 13.401) (writing took 2.265649721957743 seconds)
2022-03-07 02:11:54 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 02:11:54 | INFO | train | epoch 166 | loss 1.51 | nll_loss 0.921 | ppl 1.89 | wps 21740.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 15994 | lr 0.000250047 | gnorm 0.938 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 48026
2022-03-07 02:11:54 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 02:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:12:12 | INFO | train_inner | epoch 167:      6 / 97 loss=1.509, nll_loss=0.92, ppl=1.89, wps=21772.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16000, lr=0.00025, gnorm=0.938, loss_scale=16, train_wall=270, gb_free=8.1, wall=48044
2022-03-07 02:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:16:41 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.392 | nll_loss 13.091 | ppl 8728 | wps 40421.4 | wpb 510.9 | bsz 1 | num_updates 16091 | best_loss 7.706
2022-03-07 02:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 16091 updates
2022-03-07 02:16:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 167 @ 16091 updates, score 13.392) (writing took 2.3064058390446007 seconds)
2022-03-07 02:16:44 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 02:16:44 | INFO | train | epoch 167 | loss 1.506 | nll_loss 0.917 | ppl 1.89 | wps 21962.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16091 | lr 0.000249292 | gnorm 0.942 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 48316
2022-03-07 02:16:44 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 02:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:10 | INFO | train_inner | epoch 168:      9 / 97 loss=1.504, nll_loss=0.915, ppl=1.89, wps=21977.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16100, lr=0.000249222, gnorm=0.94, loss_scale=32, train_wall=267, gb_free=8.1, wall=48342
2022-03-07 02:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:21:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:21:31 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.4 | nll_loss 13.102 | ppl 8794.95 | wps 40673.7 | wpb 510.9 | bsz 1 | num_updates 16187 | best_loss 7.706
2022-03-07 02:21:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 16187 updates
2022-03-07 02:21:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:21:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 168 @ 16187 updates, score 13.4) (writing took 2.3286229078657925 seconds)
2022-03-07 02:21:33 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 02:21:33 | INFO | train | epoch 168 | loss 1.502 | nll_loss 0.913 | ppl 1.88 | wps 21716.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16187 | lr 0.000248552 | gnorm 0.941 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 48605
2022-03-07 02:21:33 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 02:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:22:11 | INFO | train_inner | epoch 169:     13 / 97 loss=1.499, nll_loss=0.91, ppl=1.88, wps=21746.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16200, lr=0.000248452, gnorm=0.941, loss_scale=16, train_wall=270, gb_free=8.1, wall=48643
2022-03-07 02:25:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:21 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.367 | nll_loss 13.064 | ppl 8562.45 | wps 40976.3 | wpb 510.9 | bsz 1 | num_updates 16283 | best_loss 7.706
2022-03-07 02:26:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 16283 updates
2022-03-07 02:26:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:26:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:26:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 169 @ 16283 updates, score 13.367) (writing took 2.2656807843595743 seconds)
2022-03-07 02:26:23 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 02:26:23 | INFO | train | epoch 169 | loss 1.497 | nll_loss 0.908 | ppl 1.88 | wps 21705.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16283 | lr 0.000247818 | gnorm 0.946 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 48895
2022-03-07 02:26:23 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 02:26:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:27:12 | INFO | train_inner | epoch 170:     17 / 97 loss=1.494, nll_loss=0.906, ppl=1.87, wps=21744.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=16300, lr=0.000247689, gnorm=0.946, loss_scale=16, train_wall=270, gb_free=8.1, wall=48944
2022-03-07 02:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:31:10 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.443 | nll_loss 13.144 | ppl 9054.54 | wps 43425.1 | wpb 510.9 | bsz 1 | num_updates 16380 | best_loss 7.706
2022-03-07 02:31:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 16380 updates
2022-03-07 02:31:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 170 @ 16380 updates, score 13.443) (writing took 2.281121333129704 seconds)
2022-03-07 02:31:12 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 02:31:12 | INFO | train | epoch 170 | loss 1.493 | nll_loss 0.904 | ppl 1.87 | wps 21976 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16380 | lr 0.000247083 | gnorm 0.936 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 49184
2022-03-07 02:31:12 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 02:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:32:10 | INFO | train_inner | epoch 171:     20 / 97 loss=1.493, nll_loss=0.905, ppl=1.87, wps=21982.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=16400, lr=0.000246932, gnorm=0.932, loss_scale=32, train_wall=267, gb_free=8.1, wall=49242
2022-03-07 02:34:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:35:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:35:59 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.428 | nll_loss 13.125 | ppl 8934.92 | wps 40668.5 | wpb 510.9 | bsz 1 | num_updates 16476 | best_loss 7.706
2022-03-07 02:35:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 16476 updates
2022-03-07 02:35:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:36:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 171 @ 16476 updates, score 13.428) (writing took 2.3020384022966027 seconds)
2022-03-07 02:36:01 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 02:36:01 | INFO | train | epoch 171 | loss 1.489 | nll_loss 0.901 | ppl 1.87 | wps 21726.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16476 | lr 0.000246362 | gnorm 0.936 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 49473
2022-03-07 02:36:01 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 02:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:37:11 | INFO | train_inner | epoch 172:     24 / 97 loss=1.486, nll_loss=0.897, ppl=1.86, wps=21764.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16500, lr=0.000246183, gnorm=0.937, loss_scale=16, train_wall=270, gb_free=8.1, wall=49543
2022-03-07 02:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:40:48 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.429 | nll_loss 13.13 | ppl 8965.27 | wps 40509.7 | wpb 510.9 | bsz 1 | num_updates 16573 | best_loss 7.706
2022-03-07 02:40:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 16573 updates
2022-03-07 02:40:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:40:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 172 @ 16573 updates, score 13.429) (writing took 2.2422046046704054 seconds)
2022-03-07 02:40:51 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 02:40:51 | INFO | train | epoch 172 | loss 1.484 | nll_loss 0.895 | ppl 1.86 | wps 21958.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16573 | lr 0.00024564 | gnorm 0.932 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 49763
2022-03-07 02:40:51 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 02:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:42:09 | INFO | train_inner | epoch 173:     27 / 97 loss=1.482, nll_loss=0.893, ppl=1.86, wps=21986.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16600, lr=0.00024544, gnorm=0.929, loss_scale=32, train_wall=267, gb_free=8.1, wall=49841
2022-03-07 02:44:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:45:38 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.495 | nll_loss 13.199 | ppl 9404.19 | wps 40765.1 | wpb 510.9 | bsz 1 | num_updates 16669 | best_loss 7.706
2022-03-07 02:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 16669 updates
2022-03-07 02:45:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:45:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:45:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 173 @ 16669 updates, score 13.495) (writing took 2.267048907931894 seconds)
2022-03-07 02:45:40 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 02:45:40 | INFO | train | epoch 173 | loss 1.479 | nll_loss 0.89 | ppl 1.85 | wps 21728.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16669 | lr 0.000244932 | gnorm 0.934 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 50052
2022-03-07 02:45:40 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 02:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:47:10 | INFO | train_inner | epoch 174:     31 / 97 loss=1.477, nll_loss=0.888, ppl=1.85, wps=21750.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=16700, lr=0.000244704, gnorm=0.943, loss_scale=16, train_wall=270, gb_free=8.1, wall=50142
2022-03-07 02:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:50:27 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.468 | nll_loss 13.169 | ppl 9213.05 | wps 40408.2 | wpb 510.9 | bsz 1 | num_updates 16766 | best_loss 7.706
2022-03-07 02:50:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 16766 updates
2022-03-07 02:50:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:50:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 174 @ 16766 updates, score 13.468) (writing took 2.2797089777886868 seconds)
2022-03-07 02:50:29 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 02:50:29 | INFO | train | epoch 174 | loss 1.474 | nll_loss 0.885 | ppl 1.85 | wps 21952.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16766 | lr 0.000244222 | gnorm 0.947 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 50341
2022-03-07 02:50:29 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 02:50:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:51:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:52:11 | INFO | train_inner | epoch 175:     35 / 97 loss=1.469, nll_loss=0.88, ppl=1.84, wps=21751.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=16800, lr=0.000243975, gnorm=0.933, loss_scale=16, train_wall=270, gb_free=8.1, wall=50443
2022-03-07 02:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:55:17 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.491 | nll_loss 13.192 | ppl 9354.9 | wps 40490.1 | wpb 510.9 | bsz 1 | num_updates 16862 | best_loss 7.706
2022-03-07 02:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 16862 updates
2022-03-07 02:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:55:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 02:55:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 175 @ 16862 updates, score 13.491) (writing took 2.2376643349416554 seconds)
2022-03-07 02:55:19 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 02:55:19 | INFO | train | epoch 175 | loss 1.469 | nll_loss 0.879 | ppl 1.84 | wps 21720.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16862 | lr 0.000243526 | gnorm 0.93 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 50631
2022-03-07 02:55:19 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 02:55:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:57:09 | INFO | train_inner | epoch 176:     38 / 97 loss=1.468, nll_loss=0.879, ppl=1.84, wps=21989.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=16900, lr=0.000243252, gnorm=0.935, loss_scale=16, train_wall=267, gb_free=8.1, wall=50741
2022-03-07 02:58:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:06 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.437 | nll_loss 13.138 | ppl 9016.04 | wps 41044.5 | wpb 510.9 | bsz 1 | num_updates 16958 | best_loss 7.706
2022-03-07 03:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 16958 updates
2022-03-07 03:00:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:00:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:00:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 176 @ 16958 updates, score 13.437) (writing took 2.2950307559221983 seconds)
2022-03-07 03:00:08 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 03:00:08 | INFO | train | epoch 176 | loss 1.464 | nll_loss 0.875 | ppl 1.83 | wps 21741.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 16958 | lr 0.000242836 | gnorm 0.93 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 50920
2022-03-07 03:00:08 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 03:00:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:10 | INFO | train_inner | epoch 177:     42 / 97 loss=1.465, nll_loss=0.875, ppl=1.83, wps=21771.6, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=17000, lr=0.000242536, gnorm=0.922, loss_scale=16, train_wall=270, gb_free=8.1, wall=51042
2022-03-07 03:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:04:55 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.515 | nll_loss 13.217 | ppl 9524.73 | wps 40585.6 | wpb 510.9 | bsz 1 | num_updates 17055 | best_loss 7.706
2022-03-07 03:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 17055 updates
2022-03-07 03:04:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 177 @ 17055 updates, score 13.515) (writing took 2.3315349961631 seconds)
2022-03-07 03:04:57 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 03:04:57 | INFO | train | epoch 177 | loss 1.461 | nll_loss 0.871 | ppl 1.83 | wps 21978.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17055 | lr 0.000242144 | gnorm 0.919 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 51209
2022-03-07 03:04:57 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 03:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:06:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:07:11 | INFO | train_inner | epoch 178:     46 / 97 loss=1.458, nll_loss=0.868, ppl=1.83, wps=21763.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17100, lr=0.000241825, gnorm=0.92, loss_scale=16, train_wall=270, gb_free=8.1, wall=51343
2022-03-07 03:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:09:44 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.472 | nll_loss 13.174 | ppl 9241.55 | wps 40257.9 | wpb 510.9 | bsz 1 | num_updates 17151 | best_loss 7.706
2022-03-07 03:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 17151 updates
2022-03-07 03:09:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 178 @ 17151 updates, score 13.472) (writing took 2.439890859182924 seconds)
2022-03-07 03:09:47 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 03:09:47 | INFO | train | epoch 178 | loss 1.457 | nll_loss 0.867 | ppl 1.82 | wps 21707.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17151 | lr 0.000241466 | gnorm 0.92 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 51499
2022-03-07 03:09:47 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 03:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:12:09 | INFO | train_inner | epoch 179:     49 / 97 loss=1.456, nll_loss=0.867, ppl=1.82, wps=21960.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17200, lr=0.000241121, gnorm=0.922, loss_scale=16, train_wall=267, gb_free=8.1, wall=51641
2022-03-07 03:12:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:34 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.506 | nll_loss 13.21 | ppl 9472.9 | wps 40823.3 | wpb 510.9 | bsz 1 | num_updates 17247 | best_loss 7.706
2022-03-07 03:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 17247 updates
2022-03-07 03:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 179 @ 17247 updates, score 13.506) (writing took 2.26010943390429 seconds)
2022-03-07 03:14:36 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:14:36 | INFO | train | epoch 179 | loss 1.453 | nll_loss 0.863 | ppl 1.82 | wps 21721.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17247 | lr 0.000240793 | gnorm 0.921 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 51788
2022-03-07 03:14:36 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:10 | INFO | train_inner | epoch 180:     53 / 97 loss=1.449, nll_loss=0.859, ppl=1.81, wps=21746.8, ups=0.33, wpb=65495, bsz=127.9, num_updates=17300, lr=0.000240424, gnorm=0.913, loss_scale=16, train_wall=270, gb_free=8.1, wall=51942
2022-03-07 03:19:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:23 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.489 | nll_loss 13.189 | ppl 9338.74 | wps 40484.1 | wpb 510.9 | bsz 1 | num_updates 17343 | best_loss 7.706
2022-03-07 03:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 17343 updates
2022-03-07 03:19:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:19:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:19:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 180 @ 17343 updates, score 13.489) (writing took 2.276659666094929 seconds)
2022-03-07 03:19:25 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:19:25 | INFO | train | epoch 180 | loss 1.448 | nll_loss 0.858 | ppl 1.81 | wps 21727.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17343 | lr 0.000240125 | gnorm 0.919 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 52078
2022-03-07 03:19:25 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:22:11 | INFO | train_inner | epoch 181:     57 / 97 loss=1.445, nll_loss=0.856, ppl=1.81, wps=21751.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=17400, lr=0.000239732, gnorm=0.927, loss_scale=16, train_wall=270, gb_free=8.1, wall=52243
2022-03-07 03:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:24:13 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.531 | nll_loss 13.235 | ppl 9643.49 | wps 41372 | wpb 510.9 | bsz 1 | num_updates 17440 | best_loss 7.706
2022-03-07 03:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 17440 updates
2022-03-07 03:24:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:24:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 181 @ 17440 updates, score 13.531) (writing took 2.3280314090661705 seconds)
2022-03-07 03:24:15 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:24:15 | INFO | train | epoch 181 | loss 1.445 | nll_loss 0.855 | ppl 1.81 | wps 21948 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17440 | lr 0.000239457 | gnorm 0.923 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 52367
2022-03-07 03:24:15 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:25:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:27:12 | INFO | train_inner | epoch 182:     61 / 97 loss=1.446, nll_loss=0.857, ppl=1.81, wps=21776.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17500, lr=0.000239046, gnorm=0.931, loss_scale=16, train_wall=270, gb_free=8.1, wall=52544
2022-03-07 03:28:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:29:02 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.51 | nll_loss 13.214 | ppl 9499.27 | wps 41124.3 | wpb 510.9 | bsz 1 | num_updates 17536 | best_loss 7.706
2022-03-07 03:29:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 17536 updates
2022-03-07 03:29:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:29:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 182 @ 17536 updates, score 13.51) (writing took 2.3062910973094404 seconds)
2022-03-07 03:29:04 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 03:29:04 | INFO | train | epoch 182 | loss 1.44 | nll_loss 0.85 | ppl 1.8 | wps 21735.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17536 | lr 0.0002388 | gnorm 0.919 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 52656
2022-03-07 03:29:04 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 03:29:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:10 | INFO | train_inner | epoch 183:     64 / 97 loss=1.436, nll_loss=0.846, ppl=1.8, wps=21981, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17600, lr=0.000238366, gnorm=0.905, loss_scale=16, train_wall=267, gb_free=8.1, wall=52842
2022-03-07 03:32:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:33:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:33:51 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.527 | nll_loss 13.232 | ppl 9618.42 | wps 40595.3 | wpb 510.9 | bsz 1 | num_updates 17632 | best_loss 7.706
2022-03-07 03:33:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 17632 updates
2022-03-07 03:33:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:33:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:33:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 183 @ 17632 updates, score 13.527) (writing took 2.2850916711613536 seconds)
2022-03-07 03:33:53 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 03:33:53 | INFO | train | epoch 183 | loss 1.436 | nll_loss 0.846 | ppl 1.8 | wps 21756.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17632 | lr 0.000238149 | gnorm 0.912 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 52945
2022-03-07 03:33:53 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 03:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:37:11 | INFO | train_inner | epoch 184:     68 / 97 loss=1.435, nll_loss=0.845, ppl=1.8, wps=21774.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17700, lr=0.000237691, gnorm=0.912, loss_scale=16, train_wall=270, gb_free=8.1, wall=53143
2022-03-07 03:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:40 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.476 | nll_loss 13.179 | ppl 9273.78 | wps 40438.3 | wpb 510.9 | bsz 1 | num_updates 17729 | best_loss 7.706
2022-03-07 03:38:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 17729 updates
2022-03-07 03:38:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:38:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 184 @ 17729 updates, score 13.476) (writing took 2.306750976946205 seconds)
2022-03-07 03:38:43 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 03:38:43 | INFO | train | epoch 184 | loss 1.434 | nll_loss 0.844 | ppl 1.79 | wps 21947.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17729 | lr 0.000237497 | gnorm 0.914 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 53235
2022-03-07 03:38:43 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 03:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:41:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:42:12 | INFO | train_inner | epoch 185:     72 / 97 loss=1.432, nll_loss=0.842, ppl=1.79, wps=21755.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=17800, lr=0.000237023, gnorm=0.922, loss_scale=16, train_wall=270, gb_free=8.1, wall=53444
2022-03-07 03:43:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:30 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.496 | nll_loss 13.2 | ppl 9407.1 | wps 40729.5 | wpb 510.9 | bsz 1 | num_updates 17825 | best_loss 7.706
2022-03-07 03:43:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 17825 updates
2022-03-07 03:43:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:43:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:43:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 185 @ 17825 updates, score 13.496) (writing took 2.258553417865187 seconds)
2022-03-07 03:43:32 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 03:43:32 | INFO | train | epoch 185 | loss 1.43 | nll_loss 0.84 | ppl 1.79 | wps 21722.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17825 | lr 0.000236856 | gnorm 0.925 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 53524
2022-03-07 03:43:32 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 03:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:47:10 | INFO | train_inner | epoch 186:     75 / 97 loss=1.429, nll_loss=0.839, ppl=1.79, wps=21967.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=17900, lr=0.00023636, gnorm=0.919, loss_scale=16, train_wall=267, gb_free=8.1, wall=53742
2022-03-07 03:47:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:19 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.507 | nll_loss 13.213 | ppl 9493.45 | wps 43563.5 | wpb 510.9 | bsz 1 | num_updates 17921 | best_loss 7.706
2022-03-07 03:48:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 17921 updates
2022-03-07 03:48:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 186 @ 17921 updates, score 13.507) (writing took 2.216807283926755 seconds)
2022-03-07 03:48:21 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 03:48:21 | INFO | train | epoch 186 | loss 1.426 | nll_loss 0.836 | ppl 1.79 | wps 21759.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 17921 | lr 0.000236221 | gnorm 0.912 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 53813
2022-03-07 03:48:21 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 03:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:52:11 | INFO | train_inner | epoch 187:     79 / 97 loss=1.422, nll_loss=0.832, ppl=1.78, wps=21795.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18000, lr=0.000235702, gnorm=0.909, loss_scale=16, train_wall=270, gb_free=8.1, wall=54043
2022-03-07 03:53:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:53:08 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.577 | nll_loss 13.282 | ppl 9961.09 | wps 40676.6 | wpb 510.9 | bsz 1 | num_updates 18018 | best_loss 7.706
2022-03-07 03:53:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 18018 updates
2022-03-07 03:53:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:53:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:53:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 187 @ 18018 updates, score 13.577) (writing took 2.2552602137438953 seconds)
2022-03-07 03:53:10 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 03:53:10 | INFO | train | epoch 187 | loss 1.422 | nll_loss 0.832 | ppl 1.78 | wps 21956.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18018 | lr 0.000235584 | gnorm 0.91 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 54102
2022-03-07 03:53:10 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 03:53:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:54:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:57:11 | INFO | train_inner | epoch 188:     83 / 97 loss=1.421, nll_loss=0.831, ppl=1.78, wps=21768.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18100, lr=0.00023505, gnorm=0.914, loss_scale=16, train_wall=270, gb_free=8.1, wall=54343
2022-03-07 03:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:57 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.568 | nll_loss 13.276 | ppl 9921.84 | wps 41818.7 | wpb 510.9 | bsz 1 | num_updates 18114 | best_loss 7.706
2022-03-07 03:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 18114 updates
2022-03-07 03:57:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 03:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 188 @ 18114 updates, score 13.568) (writing took 2.329427285119891 seconds)
2022-03-07 03:57:59 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 03:57:59 | INFO | train | epoch 188 | loss 1.418 | nll_loss 0.828 | ppl 1.77 | wps 21741.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18114 | lr 0.000234959 | gnorm 0.914 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 54392
2022-03-07 03:57:59 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 03:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:00:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:02:12 | INFO | train_inner | epoch 189:     87 / 97 loss=1.415, nll_loss=0.825, ppl=1.77, wps=21767.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=18200, lr=0.000234404, gnorm=0.913, loss_scale=16, train_wall=270, gb_free=8.1, wall=54644
2022-03-07 04:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:46 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.547 | nll_loss 13.256 | ppl 9780.75 | wps 41296.6 | wpb 510.9 | bsz 1 | num_updates 18210 | best_loss 7.706
2022-03-07 04:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 18210 updates
2022-03-07 04:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 189 @ 18210 updates, score 13.547) (writing took 2.3616587189026177 seconds)
2022-03-07 04:02:49 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 04:02:49 | INFO | train | epoch 189 | loss 1.415 | nll_loss 0.825 | ppl 1.77 | wps 21734.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18210 | lr 0.000234339 | gnorm 0.91 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 54681
2022-03-07 04:02:49 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 04:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:06:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:07:13 | INFO | train_inner | epoch 190:     91 / 97 loss=1.414, nll_loss=0.823, ppl=1.77, wps=21783.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18300, lr=0.000233762, gnorm=0.923, loss_scale=16, train_wall=270, gb_free=8.1, wall=54945
2022-03-07 04:07:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:07:36 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.529 | nll_loss 13.233 | ppl 9626.94 | wps 40423.2 | wpb 510.9 | bsz 1 | num_updates 18306 | best_loss 7.706
2022-03-07 04:07:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 18306 updates
2022-03-07 04:07:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:07:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:07:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 190 @ 18306 updates, score 13.529) (writing took 2.2615550672635436 seconds)
2022-03-07 04:07:38 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 04:07:38 | INFO | train | epoch 190 | loss 1.411 | nll_loss 0.821 | ppl 1.77 | wps 21744 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18306 | lr 0.000233724 | gnorm 0.925 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 54970
2022-03-07 04:07:38 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 04:07:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:12:11 | INFO | train_inner | epoch 191:     94 / 97 loss=1.408, nll_loss=0.818, ppl=1.76, wps=21959.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18400, lr=0.000233126, gnorm=0.901, loss_scale=16, train_wall=267, gb_free=8.1, wall=55243
2022-03-07 04:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:12:25 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.586 | nll_loss 13.296 | ppl 10060 | wps 40115.6 | wpb 510.9 | bsz 1 | num_updates 18403 | best_loss 7.706
2022-03-07 04:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 18403 updates
2022-03-07 04:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:12:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 191 @ 18403 updates, score 13.586) (writing took 2.381411709357053 seconds)
2022-03-07 04:12:28 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 04:12:28 | INFO | train | epoch 191 | loss 1.407 | nll_loss 0.816 | ppl 1.76 | wps 21933 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 18403 | lr 0.000233107 | gnorm 0.898 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 55260
2022-03-07 04:12:28 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 04:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:15:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:17:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:17:15 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.611 | nll_loss 13.319 | ppl 10219.4 | wps 40848.4 | wpb 510.9 | bsz 1 | num_updates 18499 | best_loss 7.706
2022-03-07 04:17:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 18499 updates
2022-03-07 04:17:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:17:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:17:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 192 @ 18499 updates, score 13.611) (writing took 2.2310544489882886 seconds)
2022-03-07 04:17:17 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:17:17 | INFO | train | epoch 192 | loss 1.404 | nll_loss 0.814 | ppl 1.76 | wps 21725.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18499 | lr 0.000232502 | gnorm 0.9 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 55549
2022-03-07 04:17:17 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:20 | INFO | train_inner | epoch 193:      1 / 97 loss=1.405, nll_loss=0.814, ppl=1.76, wps=21196.3, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=18500, lr=0.000232495, gnorm=0.9, loss_scale=16, train_wall=270, gb_free=8.1, wall=55552
2022-03-07 04:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:22:04 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.572 | nll_loss 13.279 | ppl 9940.63 | wps 40647.4 | wpb 510.9 | bsz 1 | num_updates 18596 | best_loss 7.706
2022-03-07 04:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 18596 updates
2022-03-07 04:22:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:22:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 193 @ 18596 updates, score 13.572) (writing took 2.235543703660369 seconds)
2022-03-07 04:22:06 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:22:06 | INFO | train | epoch 193 | loss 1.401 | nll_loss 0.811 | ppl 1.75 | wps 21962.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18596 | lr 0.000231894 | gnorm 0.918 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 55838
2022-03-07 04:22:06 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:22:18 | INFO | train_inner | epoch 194:      4 / 97 loss=1.4, nll_loss=0.81, ppl=1.75, wps=21979, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18600, lr=0.000231869, gnorm=0.917, loss_scale=32, train_wall=267, gb_free=8.1, wall=55850
2022-03-07 04:23:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:53 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.616 | nll_loss 13.324 | ppl 10258.2 | wps 41114.5 | wpb 510.9 | bsz 1 | num_updates 18692 | best_loss 7.706
2022-03-07 04:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 18692 updates
2022-03-07 04:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:26:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 194 @ 18692 updates, score 13.616) (writing took 2.273989603854716 seconds)
2022-03-07 04:26:55 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:26:55 | INFO | train | epoch 194 | loss 1.395 | nll_loss 0.805 | ppl 1.75 | wps 21740.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18692 | lr 0.000231298 | gnorm 0.897 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 56127
2022-03-07 04:26:55 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:19 | INFO | train_inner | epoch 195:      8 / 97 loss=1.394, nll_loss=0.803, ppl=1.75, wps=21770.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18700, lr=0.000231249, gnorm=0.895, loss_scale=16, train_wall=270, gb_free=8.1, wall=56151
2022-03-07 04:31:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:31:42 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.574 | nll_loss 13.282 | ppl 9962.48 | wps 40925 | wpb 510.9 | bsz 1 | num_updates 18788 | best_loss 7.706
2022-03-07 04:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 18788 updates
2022-03-07 04:31:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:31:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:31:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 195 @ 18788 updates, score 13.574) (writing took 2.275934707839042 seconds)
2022-03-07 04:31:45 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:31:45 | INFO | train | epoch 195 | loss 1.393 | nll_loss 0.803 | ppl 1.74 | wps 21739.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18788 | lr 0.000230706 | gnorm 0.904 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 56417
2022-03-07 04:31:45 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:32:19 | INFO | train_inner | epoch 196:     12 / 97 loss=1.391, nll_loss=0.801, ppl=1.74, wps=21778.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=18800, lr=0.000230633, gnorm=0.903, loss_scale=16, train_wall=270, gb_free=8.1, wall=56452
2022-03-07 04:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:36:31 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.609 | nll_loss 13.317 | ppl 10208 | wps 40562.5 | wpb 510.9 | bsz 1 | num_updates 18885 | best_loss 7.706
2022-03-07 04:36:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 18885 updates
2022-03-07 04:36:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:36:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:36:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 196 @ 18885 updates, score 13.609) (writing took 2.269112735055387 seconds)
2022-03-07 04:36:34 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:36:34 | INFO | train | epoch 196 | loss 1.39 | nll_loss 0.799 | ppl 1.74 | wps 21980.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18885 | lr 0.000230113 | gnorm 0.902 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 56706
2022-03-07 04:36:34 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:37:17 | INFO | train_inner | epoch 197:     15 / 97 loss=1.388, nll_loss=0.798, ppl=1.74, wps=21987.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18900, lr=0.000230022, gnorm=0.901, loss_scale=16, train_wall=267, gb_free=8.1, wall=56749
2022-03-07 04:38:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:41:21 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.669 | nll_loss 13.38 | ppl 10663.9 | wps 41977.6 | wpb 510.9 | bsz 1 | num_updates 18981 | best_loss 7.706
2022-03-07 04:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 18981 updates
2022-03-07 04:41:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:41:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:41:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 197 @ 18981 updates, score 13.669) (writing took 2.395646672230214 seconds)
2022-03-07 04:41:23 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:41:23 | INFO | train | epoch 197 | loss 1.387 | nll_loss 0.796 | ppl 1.74 | wps 21717 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 18981 | lr 0.000229531 | gnorm 0.897 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 56995
2022-03-07 04:41:23 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:42:18 | INFO | train_inner | epoch 198:     19 / 97 loss=1.385, nll_loss=0.794, ppl=1.73, wps=21750.4, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=19000, lr=0.000229416, gnorm=0.896, loss_scale=16, train_wall=270, gb_free=8.1, wall=57050
2022-03-07 04:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:46:10 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.637 | nll_loss 13.346 | ppl 10409.2 | wps 40693.9 | wpb 510.9 | bsz 1 | num_updates 19078 | best_loss 7.706
2022-03-07 04:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 19078 updates
2022-03-07 04:46:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 198 @ 19078 updates, score 13.637) (writing took 2.2617118791677058 seconds)
2022-03-07 04:46:13 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:46:13 | INFO | train | epoch 198 | loss 1.383 | nll_loss 0.793 | ppl 1.73 | wps 21947 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19078 | lr 0.000228946 | gnorm 0.891 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 57285
2022-03-07 04:46:13 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:17 | INFO | train_inner | epoch 199:     22 / 97 loss=1.383, nll_loss=0.793, ppl=1.73, wps=21970.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=19100, lr=0.000228814, gnorm=0.892, loss_scale=32, train_wall=267, gb_free=8.1, wall=57349
2022-03-07 04:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:50:59 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.64 | nll_loss 13.35 | ppl 10438.2 | wps 41387.3 | wpb 510.9 | bsz 1 | num_updates 19175 | best_loss 7.706
2022-03-07 04:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 19175 updates
2022-03-07 04:50:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:51:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 199 @ 19175 updates, score 13.64) (writing took 2.2628405592404306 seconds)
2022-03-07 04:51:02 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:51:02 | INFO | train | epoch 199 | loss 1.381 | nll_loss 0.79 | ppl 1.73 | wps 21969.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19175 | lr 0.000228366 | gnorm 0.902 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 57574
2022-03-07 04:51:02 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:51:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:52:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:52:20 | INFO | train_inner | epoch 200:     27 / 97 loss=1.379, nll_loss=0.789, ppl=1.73, wps=21570, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=19200, lr=0.000228218, gnorm=0.905, loss_scale=16, train_wall=272, gb_free=8.1, wall=57652
2022-03-07 04:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:55:49 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.637 | nll_loss 13.348 | ppl 10427.1 | wps 40548.7 | wpb 510.9 | bsz 1 | num_updates 19270 | best_loss 7.706
2022-03-07 04:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 19270 updates
2022-03-07 04:55:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:55:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 04:55:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 200 @ 19270 updates, score 13.637) (writing took 2.246356847230345 seconds)
2022-03-07 04:55:51 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:55:51 | INFO | train | epoch 200 | loss 1.378 | nll_loss 0.787 | ppl 1.73 | wps 21522.8 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 19270 | lr 0.000227803 | gnorm 0.905 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 57863
2022-03-07 04:55:51 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:57:18 | INFO | train_inner | epoch 201:     30 / 97 loss=1.376, nll_loss=0.786, ppl=1.72, wps=21984.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=19300, lr=0.000227626, gnorm=0.898, loss_scale=16, train_wall=267, gb_free=8.1, wall=57950
2022-03-07 05:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:38 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.633 | nll_loss 13.34 | ppl 10368.9 | wps 40768.9 | wpb 510.9 | bsz 1 | num_updates 19367 | best_loss 7.706
2022-03-07 05:00:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 19367 updates
2022-03-07 05:00:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:00:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 201 @ 19367 updates, score 13.633) (writing took 2.2349660568870604 seconds)
2022-03-07 05:00:40 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 05:00:40 | INFO | train | epoch 201 | loss 1.374 | nll_loss 0.784 | ppl 1.72 | wps 21966.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19367 | lr 0.000227232 | gnorm 0.892 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 58152
2022-03-07 05:00:40 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 05:00:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:01:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:02:19 | INFO | train_inner | epoch 202:     34 / 97 loss=1.372, nll_loss=0.781, ppl=1.72, wps=21786.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=19400, lr=0.000227038, gnorm=0.893, loss_scale=16, train_wall=270, gb_free=8.1, wall=58251
2022-03-07 05:05:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:05:27 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.706 | nll_loss 13.418 | ppl 10944.7 | wps 40896.4 | wpb 510.9 | bsz 1 | num_updates 19463 | best_loss 7.706
2022-03-07 05:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 19463 updates
2022-03-07 05:05:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:05:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:05:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 202 @ 19463 updates, score 13.706) (writing took 2.3344308109954 seconds)
2022-03-07 05:05:29 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 05:05:29 | INFO | train | epoch 202 | loss 1.37 | nll_loss 0.779 | ppl 1.72 | wps 21722 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19463 | lr 0.000226671 | gnorm 0.892 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 58441
2022-03-07 05:05:29 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 05:05:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:07:17 | INFO | train_inner | epoch 203:     37 / 97 loss=1.368, nll_loss=0.778, ppl=1.71, wps=21960.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19500, lr=0.000226455, gnorm=0.891, loss_scale=16, train_wall=267, gb_free=8.1, wall=58549
2022-03-07 05:09:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:10:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:10:16 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.694 | nll_loss 13.405 | ppl 10848.9 | wps 40429.8 | wpb 510.9 | bsz 1 | num_updates 19559 | best_loss 7.706
2022-03-07 05:10:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 19559 updates
2022-03-07 05:10:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:10:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:10:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 203 @ 19559 updates, score 13.694) (writing took 2.2634394420310855 seconds)
2022-03-07 05:10:19 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 05:10:19 | INFO | train | epoch 203 | loss 1.368 | nll_loss 0.777 | ppl 1.71 | wps 21736.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19559 | lr 0.000226114 | gnorm 0.886 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 58731
2022-03-07 05:10:19 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 05:10:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:12:18 | INFO | train_inner | epoch 204:     41 / 97 loss=1.367, nll_loss=0.777, ppl=1.71, wps=21748.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=19600, lr=0.000225877, gnorm=0.886, loss_scale=16, train_wall=270, gb_free=8.1, wall=58850
2022-03-07 05:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:15:06 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.647 | nll_loss 13.358 | ppl 10502.6 | wps 40374.4 | wpb 510.9 | bsz 1 | num_updates 19656 | best_loss 7.706
2022-03-07 05:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 19656 updates
2022-03-07 05:15:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 204 @ 19656 updates, score 13.647) (writing took 2.3411157024092972 seconds)
2022-03-07 05:15:08 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 05:15:08 | INFO | train | epoch 204 | loss 1.365 | nll_loss 0.775 | ppl 1.71 | wps 21932.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 19656 | lr 0.000225555 | gnorm 0.893 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 59020
2022-03-07 05:15:08 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 05:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:17:19 | INFO | train_inner | epoch 205:     45 / 97 loss=1.363, nll_loss=0.772, ppl=1.71, wps=21755.3, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=19700, lr=0.000225303, gnorm=0.889, loss_scale=16, train_wall=270, gb_free=8.1, wall=59151
2022-03-07 05:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:19:55 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.664 | nll_loss 13.375 | ppl 10624.4 | wps 41041.1 | wpb 510.9 | bsz 1 | num_updates 19752 | best_loss 7.706
2022-03-07 05:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 19752 updates
2022-03-07 05:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 205 @ 19752 updates, score 13.664) (writing took 2.212097241077572 seconds)
2022-03-07 05:19:58 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 05:19:58 | INFO | train | epoch 205 | loss 1.362 | nll_loss 0.771 | ppl 1.71 | wps 21729.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19752 | lr 0.000225006 | gnorm 0.883 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 59310
2022-03-07 05:19:58 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 05:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:22:17 | INFO | train_inner | epoch 206:     48 / 97 loss=1.361, nll_loss=0.77, ppl=1.71, wps=21981.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=19800, lr=0.000224733, gnorm=0.883, loss_scale=16, train_wall=267, gb_free=8.1, wall=59449
2022-03-07 05:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:24:45 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.74 | nll_loss 13.454 | ppl 11219.1 | wps 40463.3 | wpb 510.9 | bsz 1 | num_updates 19849 | best_loss 7.706
2022-03-07 05:24:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 19849 updates
2022-03-07 05:24:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:24:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:24:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 206 @ 19849 updates, score 13.74) (writing took 2.2320238649845123 seconds)
2022-03-07 05:24:47 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 05:24:47 | INFO | train | epoch 206 | loss 1.359 | nll_loss 0.768 | ppl 1.7 | wps 21973.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19849 | lr 0.000224456 | gnorm 0.894 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 59599
2022-03-07 05:24:47 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 05:24:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:27:15 | INFO | train_inner | epoch 207:     51 / 97 loss=1.357, nll_loss=0.766, ppl=1.7, wps=21973.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19900, lr=0.000224168, gnorm=0.889, loss_scale=32, train_wall=267, gb_free=8.1, wall=59747
2022-03-07 05:29:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:29:34 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.697 | nll_loss 13.412 | ppl 10900.3 | wps 40508.6 | wpb 510.9 | bsz 1 | num_updates 19945 | best_loss 7.706
2022-03-07 05:29:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 19945 updates
2022-03-07 05:29:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:29:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 207 @ 19945 updates, score 13.697) (writing took 2.2712972024455667 seconds)
2022-03-07 05:29:36 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 05:29:36 | INFO | train | epoch 207 | loss 1.354 | nll_loss 0.764 | ppl 1.7 | wps 21731.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 19945 | lr 0.000223915 | gnorm 0.878 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 59888
2022-03-07 05:29:36 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 05:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:32:16 | INFO | train_inner | epoch 208:     55 / 97 loss=1.354, nll_loss=0.763, ppl=1.7, wps=21779.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=20000, lr=0.000223607, gnorm=0.882, loss_scale=32, train_wall=269, gb_free=8.1, wall=60048
2022-03-07 05:34:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:34:23 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.681 | nll_loss 13.394 | ppl 10768.2 | wps 40825.7 | wpb 510.9 | bsz 1 | num_updates 20041 | best_loss 7.706
2022-03-07 05:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 20041 updates
2022-03-07 05:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:34:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 208 @ 20041 updates, score 13.681) (writing took 2.275765439029783 seconds)
2022-03-07 05:34:25 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 05:34:25 | INFO | train | epoch 208 | loss 1.353 | nll_loss 0.762 | ppl 1.7 | wps 21733.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20041 | lr 0.000223378 | gnorm 0.886 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 60177
2022-03-07 05:34:25 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 05:34:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:17 | INFO | train_inner | epoch 209:     59 / 97 loss=1.353, nll_loss=0.762, ppl=1.7, wps=21762.1, ups=0.33, wpb=65495, bsz=127.9, num_updates=20100, lr=0.00022305, gnorm=0.888, loss_scale=16, train_wall=270, gb_free=8.1, wall=60349
2022-03-07 05:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:39:12 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.698 | nll_loss 13.412 | ppl 10900 | wps 42965.4 | wpb 510.9 | bsz 1 | num_updates 20138 | best_loss 7.706
2022-03-07 05:39:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 20138 updates
2022-03-07 05:39:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 209 @ 20138 updates, score 13.698) (writing took 2.235931346192956 seconds)
2022-03-07 05:39:14 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:39:14 | INFO | train | epoch 209 | loss 1.35 | nll_loss 0.759 | ppl 1.69 | wps 21984.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20138 | lr 0.000222839 | gnorm 0.887 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 60466
2022-03-07 05:39:14 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:42:15 | INFO | train_inner | epoch 210:     62 / 97 loss=1.347, nll_loss=0.757, ppl=1.69, wps=21983.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20200, lr=0.000222497, gnorm=0.885, loss_scale=32, train_wall=267, gb_free=8.1, wall=60647
2022-03-07 05:43:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:44:01 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.654 | nll_loss 13.365 | ppl 10550.3 | wps 40568 | wpb 510.9 | bsz 1 | num_updates 20234 | best_loss 7.706
2022-03-07 05:44:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 20234 updates
2022-03-07 05:44:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:44:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:44:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 210 @ 20234 updates, score 13.654) (writing took 2.2356803780421615 seconds)
2022-03-07 05:44:04 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:44:04 | INFO | train | epoch 210 | loss 1.347 | nll_loss 0.757 | ppl 1.69 | wps 21730.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20234 | lr 0.00022231 | gnorm 0.884 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 60756
2022-03-07 05:44:04 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:44:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:47:16 | INFO | train_inner | epoch 211:     66 / 97 loss=1.346, nll_loss=0.755, ppl=1.69, wps=21770.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=20300, lr=0.000221948, gnorm=0.884, loss_scale=16, train_wall=270, gb_free=8.1, wall=60948
2022-03-07 05:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:48:51 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.714 | nll_loss 13.427 | ppl 11013.5 | wps 40608.6 | wpb 510.9 | bsz 1 | num_updates 20331 | best_loss 7.706
2022-03-07 05:48:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 20331 updates
2022-03-07 05:48:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:48:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:48:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 211 @ 20331 updates, score 13.714) (writing took 2.286700609140098 seconds)
2022-03-07 05:48:53 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:48:53 | INFO | train | epoch 211 | loss 1.344 | nll_loss 0.753 | ppl 1.69 | wps 21941.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20331 | lr 0.000221779 | gnorm 0.88 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 61045
2022-03-07 05:48:53 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:51:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:52:16 | INFO | train_inner | epoch 212:     70 / 97 loss=1.343, nll_loss=0.752, ppl=1.68, wps=21759.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=20400, lr=0.000221404, gnorm=0.878, loss_scale=16, train_wall=270, gb_free=8.1, wall=61249
2022-03-07 05:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:53:40 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.768 | nll_loss 13.485 | ppl 11468.5 | wps 41316.2 | wpb 510.9 | bsz 1 | num_updates 20427 | best_loss 7.706
2022-03-07 05:53:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 20427 updates
2022-03-07 05:53:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 212 @ 20427 updates, score 13.768) (writing took 2.2904034620150924 seconds)
2022-03-07 05:53:42 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:53:42 | INFO | train | epoch 212 | loss 1.341 | nll_loss 0.75 | ppl 1.68 | wps 21742 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20427 | lr 0.000221257 | gnorm 0.877 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 61334
2022-03-07 05:53:42 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:14 | INFO | train_inner | epoch 213:     73 / 97 loss=1.339, nll_loss=0.748, ppl=1.68, wps=21983.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20500, lr=0.000220863, gnorm=0.873, loss_scale=16, train_wall=267, gb_free=8.1, wall=61546
2022-03-07 05:58:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:58:29 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.737 | nll_loss 13.453 | ppl 11216.4 | wps 40618.7 | wpb 510.9 | bsz 1 | num_updates 20523 | best_loss 7.706
2022-03-07 05:58:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 20523 updates
2022-03-07 05:58:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 05:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 213 @ 20523 updates, score 13.737) (writing took 2.2582972636446357 seconds)
2022-03-07 05:58:32 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:58:32 | INFO | train | epoch 213 | loss 1.338 | nll_loss 0.747 | ppl 1.68 | wps 21744.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20523 | lr 0.000220739 | gnorm 0.877 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 61624
2022-03-07 05:58:32 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:02:15 | INFO | train_inner | epoch 214:     77 / 97 loss=1.339, nll_loss=0.748, ppl=1.68, wps=21789.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=20600, lr=0.000220326, gnorm=0.888, loss_scale=16, train_wall=269, gb_free=8.1, wall=61847
2022-03-07 06:03:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:03:18 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.699 | nll_loss 13.412 | ppl 10897.8 | wps 40444.6 | wpb 510.9 | bsz 1 | num_updates 20620 | best_loss 7.706
2022-03-07 06:03:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 20620 updates
2022-03-07 06:03:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:03:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:03:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 214 @ 20620 updates, score 13.699) (writing took 2.3336321702226996 seconds)
2022-03-07 06:03:21 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 06:03:21 | INFO | train | epoch 214 | loss 1.337 | nll_loss 0.747 | ppl 1.68 | wps 21967.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20620 | lr 0.000220219 | gnorm 0.886 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 61913
2022-03-07 06:03:21 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 06:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:04:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:07:16 | INFO | train_inner | epoch 215:     81 / 97 loss=1.334, nll_loss=0.744, ppl=1.67, wps=21750.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=20700, lr=0.000219793, gnorm=0.875, loss_scale=16, train_wall=270, gb_free=8.1, wall=62148
2022-03-07 06:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:08:08 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.754 | nll_loss 13.467 | ppl 11322.2 | wps 41135.2 | wpb 510.9 | bsz 1 | num_updates 20716 | best_loss 7.706
2022-03-07 06:08:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 20716 updates
2022-03-07 06:08:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:08:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:08:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 215 @ 20716 updates, score 13.754) (writing took 2.248373436741531 seconds)
2022-03-07 06:08:10 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 06:08:10 | INFO | train | epoch 215 | loss 1.332 | nll_loss 0.742 | ppl 1.67 | wps 21731.5 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20716 | lr 0.000219709 | gnorm 0.871 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 62202
2022-03-07 06:08:10 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 06:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:12:14 | INFO | train_inner | epoch 216:     84 / 97 loss=1.331, nll_loss=0.74, ppl=1.67, wps=21974.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20800, lr=0.000219265, gnorm=0.877, loss_scale=32, train_wall=267, gb_free=8.1, wall=62446
2022-03-07 06:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:12:57 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.717 | nll_loss 13.431 | ppl 11040.9 | wps 43278 | wpb 510.9 | bsz 1 | num_updates 20813 | best_loss 7.706
2022-03-07 06:12:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 20813 updates
2022-03-07 06:12:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 216 @ 20813 updates, score 13.717) (writing took 2.2942089601419866 seconds)
2022-03-07 06:12:59 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 06:12:59 | INFO | train | epoch 216 | loss 1.331 | nll_loss 0.74 | ppl 1.67 | wps 21981.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20813 | lr 0.000219196 | gnorm 0.879 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 62491
2022-03-07 06:12:59 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 06:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:14:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:17:15 | INFO | train_inner | epoch 217:     88 / 97 loss=1.328, nll_loss=0.737, ppl=1.67, wps=21773, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=20900, lr=0.000218739, gnorm=0.865, loss_scale=16, train_wall=270, gb_free=8.1, wall=62747
2022-03-07 06:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:17:46 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.81 | nll_loss 13.529 | ppl 11817.3 | wps 40588.9 | wpb 510.9 | bsz 1 | num_updates 20909 | best_loss 7.706
2022-03-07 06:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 20909 updates
2022-03-07 06:17:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 217 @ 20909 updates, score 13.81) (writing took 2.2575544929131866 seconds)
2022-03-07 06:17:49 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 06:17:49 | INFO | train | epoch 217 | loss 1.326 | nll_loss 0.735 | ppl 1.66 | wps 21711.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 20909 | lr 0.000218692 | gnorm 0.862 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 62781
2022-03-07 06:17:49 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 06:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:21:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:22:16 | INFO | train_inner | epoch 218:     92 / 97 loss=1.326, nll_loss=0.736, ppl=1.67, wps=21770.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=21000, lr=0.000218218, gnorm=0.871, loss_scale=16, train_wall=270, gb_free=8.1, wall=63048
2022-03-07 06:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:22:36 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.799 | nll_loss 13.517 | ppl 11726 | wps 40990.1 | wpb 510.9 | bsz 1 | num_updates 21005 | best_loss 7.706
2022-03-07 06:22:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 21005 updates
2022-03-07 06:22:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:22:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:22:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 218 @ 21005 updates, score 13.799) (writing took 2.236591204069555 seconds)
2022-03-07 06:22:38 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 06:22:38 | INFO | train | epoch 218 | loss 1.325 | nll_loss 0.735 | ppl 1.66 | wps 21743.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 21005 | lr 0.000218192 | gnorm 0.873 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 63070
2022-03-07 06:22:38 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 06:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:27:14 | INFO | train_inner | epoch 219:     95 / 97 loss=1.323, nll_loss=0.733, ppl=1.66, wps=21984.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21100, lr=0.0002177, gnorm=0.882, loss_scale=16, train_wall=267, gb_free=8.1, wall=63346
2022-03-07 06:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:27:25 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.748 | nll_loss 13.463 | ppl 11289.8 | wps 41117.2 | wpb 510.9 | bsz 1 | num_updates 21102 | best_loss 7.706
2022-03-07 06:27:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 21102 updates
2022-03-07 06:27:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:27:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:27:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 219 @ 21102 updates, score 13.748) (writing took 2.275634143035859 seconds)
2022-03-07 06:27:27 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 06:27:27 | INFO | train | epoch 219 | loss 1.322 | nll_loss 0.732 | ppl 1.66 | wps 21968.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21102 | lr 0.00021769 | gnorm 0.88 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 63359
2022-03-07 06:27:27 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 06:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:32:14 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.786 | nll_loss 13.502 | ppl 11603 | wps 40428.8 | wpb 510.9 | bsz 1 | num_updates 21198 | best_loss 7.706
2022-03-07 06:32:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 21198 updates
2022-03-07 06:32:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 220 @ 21198 updates, score 13.786) (writing took 2.300045303069055 seconds)
2022-03-07 06:32:16 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 06:32:16 | INFO | train | epoch 220 | loss 1.319 | nll_loss 0.729 | ppl 1.66 | wps 21734.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 21198 | lr 0.000217196 | gnorm 0.876 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 63648
2022-03-07 06:32:16 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 06:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:32:22 | INFO | train_inner | epoch 221:      2 / 97 loss=1.32, nll_loss=0.729, ppl=1.66, wps=21222.2, ups=0.32, wpb=65451.9, bsz=127.8, num_updates=21200, lr=0.000217186, gnorm=0.876, loss_scale=16, train_wall=269, gb_free=8.1, wall=63654
2022-03-07 06:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:37:03 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.801 | nll_loss 13.522 | ppl 11761.5 | wps 40902.8 | wpb 510.9 | bsz 1 | num_updates 21295 | best_loss 7.706
2022-03-07 06:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 21295 updates
2022-03-07 06:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 221 @ 21295 updates, score 13.801) (writing took 2.408998076338321 seconds)
2022-03-07 06:37:06 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 06:37:06 | INFO | train | epoch 221 | loss 1.317 | nll_loss 0.726 | ppl 1.65 | wps 21936.9 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 21295 | lr 0.000216701 | gnorm 0.87 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 63938
2022-03-07 06:37:06 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 06:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:20 | INFO | train_inner | epoch 222:      5 / 97 loss=1.315, nll_loss=0.725, ppl=1.65, wps=21953.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21300, lr=0.000216676, gnorm=0.869, loss_scale=32, train_wall=267, gb_free=8.1, wall=63952
2022-03-07 06:39:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:41:53 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.772 | nll_loss 13.489 | ppl 11495.3 | wps 41176.6 | wpb 510.9 | bsz 1 | num_updates 21391 | best_loss 7.706
2022-03-07 06:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 21391 updates
2022-03-07 06:41:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 222 @ 21391 updates, score 13.772) (writing took 2.1958452919498086 seconds)
2022-03-07 06:41:55 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 06:41:55 | INFO | train | epoch 222 | loss 1.314 | nll_loss 0.724 | ppl 1.65 | wps 21731.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 21391 | lr 0.000216214 | gnorm 0.879 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 64227
2022-03-07 06:41:55 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 06:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:21 | INFO | train_inner | epoch 223:      9 / 97 loss=1.313, nll_loss=0.722, ppl=1.65, wps=21766.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=21400, lr=0.000216169, gnorm=0.878, loss_scale=16, train_wall=270, gb_free=8.1, wall=64253
2022-03-07 06:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:46:42 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.757 | nll_loss 13.477 | ppl 11399.9 | wps 40694 | wpb 510.9 | bsz 1 | num_updates 21488 | best_loss 7.706
2022-03-07 06:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 21488 updates
2022-03-07 06:46:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:46:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:46:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 223 @ 21488 updates, score 13.757) (writing took 2.2873707311227918 seconds)
2022-03-07 06:46:44 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 06:46:44 | INFO | train | epoch 223 | loss 1.311 | nll_loss 0.721 | ppl 1.65 | wps 21966.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21488 | lr 0.000215726 | gnorm 0.868 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 64516
2022-03-07 06:46:44 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 06:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:47:19 | INFO | train_inner | epoch 224:     12 / 97 loss=1.31, nll_loss=0.719, ppl=1.65, wps=21978.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21500, lr=0.000215666, gnorm=0.866, loss_scale=32, train_wall=267, gb_free=8.1, wall=64551
2022-03-07 06:49:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:51:31 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.761 | nll_loss 13.477 | ppl 11403.6 | wps 40409.2 | wpb 510.9 | bsz 1 | num_updates 21584 | best_loss 7.706
2022-03-07 06:51:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 21584 updates
2022-03-07 06:51:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:51:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 224 @ 21584 updates, score 13.761) (writing took 2.220044023822993 seconds)
2022-03-07 06:51:34 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 06:51:34 | INFO | train | epoch 224 | loss 1.309 | nll_loss 0.718 | ppl 1.65 | wps 21729.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 21584 | lr 0.000215245 | gnorm 0.87 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 64806
2022-03-07 06:51:34 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 06:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:52:20 | INFO | train_inner | epoch 225:     16 / 97 loss=1.306, nll_loss=0.715, ppl=1.64, wps=21764.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=21600, lr=0.000215166, gnorm=0.867, loss_scale=16, train_wall=270, gb_free=8.1, wall=64852
2022-03-07 06:56:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:56:21 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.767 | nll_loss 13.482 | ppl 11444.3 | wps 41948.9 | wpb 510.9 | bsz 1 | num_updates 21681 | best_loss 7.706
2022-03-07 06:56:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 21681 updates
2022-03-07 06:56:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:56:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 06:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 225 @ 21681 updates, score 13.767) (writing took 2.414533331990242 seconds)
2022-03-07 06:56:23 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 06:56:23 | INFO | train | epoch 225 | loss 1.307 | nll_loss 0.716 | ppl 1.64 | wps 21954.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21681 | lr 0.000214763 | gnorm 0.873 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 65095
2022-03-07 06:56:23 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 06:56:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:57:18 | INFO | train_inner | epoch 226:     19 / 97 loss=1.307, nll_loss=0.717, ppl=1.64, wps=21978.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21700, lr=0.000214669, gnorm=0.878, loss_scale=32, train_wall=267, gb_free=8.1, wall=65150
2022-03-07 06:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:01:10 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.799 | nll_loss 13.518 | ppl 11730 | wps 41104.4 | wpb 510.9 | bsz 1 | num_updates 21777 | best_loss 7.706
2022-03-07 07:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 21777 updates
2022-03-07 07:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:01:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:01:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 226 @ 21777 updates, score 13.799) (writing took 2.3036133302375674 seconds)
2022-03-07 07:01:12 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 07:01:12 | INFO | train | epoch 226 | loss 1.304 | nll_loss 0.713 | ppl 1.64 | wps 21734.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 21777 | lr 0.00021429 | gnorm 0.871 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 65384
2022-03-07 07:01:12 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 07:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:02:18 | INFO | train_inner | epoch 227:     23 / 97 loss=1.302, nll_loss=0.712, ppl=1.64, wps=21830.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=21800, lr=0.000214176, gnorm=0.868, loss_scale=16, train_wall=269, gb_free=8.1, wall=65450
2022-03-07 07:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:05:56 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.785 | nll_loss 13.502 | ppl 11605.1 | wps 40627.5 | wpb 510.9 | bsz 1 | num_updates 21874 | best_loss 7.706
2022-03-07 07:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 21874 updates
2022-03-07 07:05:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 227 @ 21874 updates, score 13.785) (writing took 2.2803783528506756 seconds)
2022-03-07 07:05:59 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 07:05:59 | INFO | train | epoch 227 | loss 1.302 | nll_loss 0.711 | ppl 1.64 | wps 22183.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21874 | lr 0.000213814 | gnorm 0.864 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 65671
2022-03-07 07:05:59 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 07:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:07:14 | INFO | train_inner | epoch 228:     26 / 97 loss=1.299, nll_loss=0.709, ppl=1.63, wps=22120.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21900, lr=0.000213687, gnorm=0.862, loss_scale=32, train_wall=265, gb_free=8.1, wall=65746
2022-03-07 07:08:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:10:46 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.797 | nll_loss 13.517 | ppl 11722.5 | wps 41133.4 | wpb 510.9 | bsz 1 | num_updates 21970 | best_loss 7.706
2022-03-07 07:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 21970 updates
2022-03-07 07:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:10:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:10:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 228 @ 21970 updates, score 13.797) (writing took 2.194576034322381 seconds)
2022-03-07 07:10:48 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 07:10:48 | INFO | train | epoch 228 | loss 1.299 | nll_loss 0.708 | ppl 1.63 | wps 21732.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 21970 | lr 0.000213346 | gnorm 0.868 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 65960
2022-03-07 07:10:48 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 07:10:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:12:15 | INFO | train_inner | epoch 229:     30 / 97 loss=1.299, nll_loss=0.708, ppl=1.63, wps=21773.1, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=22000, lr=0.000213201, gnorm=0.866, loss_scale=16, train_wall=270, gb_free=8.1, wall=66047
2022-03-07 07:14:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:15:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:15:35 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.818 | nll_loss 13.536 | ppl 11878.1 | wps 40629.2 | wpb 510.9 | bsz 1 | num_updates 22066 | best_loss 7.706
2022-03-07 07:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 22066 updates
2022-03-07 07:15:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:15:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:15:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 229 @ 22066 updates, score 13.818) (writing took 2.2882342990487814 seconds)
2022-03-07 07:15:37 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 07:15:37 | INFO | train | epoch 229 | loss 1.297 | nll_loss 0.707 | ppl 1.63 | wps 21729.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 22066 | lr 0.000212882 | gnorm 0.864 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 66249
2022-03-07 07:15:37 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 07:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:17:16 | INFO | train_inner | epoch 230:     34 / 97 loss=1.296, nll_loss=0.706, ppl=1.63, wps=21747.4, ups=0.33, wpb=65495, bsz=127.9, num_updates=22100, lr=0.000212718, gnorm=0.864, loss_scale=16, train_wall=270, gb_free=8.1, wall=66348
2022-03-07 07:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:20:24 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.761 | nll_loss 13.479 | ppl 11419.7 | wps 40474.5 | wpb 510.9 | bsz 1 | num_updates 22163 | best_loss 7.706
2022-03-07 07:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 22163 updates
2022-03-07 07:20:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 230 @ 22163 updates, score 13.761) (writing took 2.3528736531734467 seconds)
2022-03-07 07:20:27 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 07:20:27 | INFO | train | epoch 230 | loss 1.295 | nll_loss 0.704 | ppl 1.63 | wps 21943.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22163 | lr 0.000212415 | gnorm 0.859 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 66539
2022-03-07 07:20:27 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 07:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:21:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:22:17 | INFO | train_inner | epoch 231:     38 / 97 loss=1.295, nll_loss=0.705, ppl=1.63, wps=21757.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=22200, lr=0.000212238, gnorm=0.867, loss_scale=16, train_wall=270, gb_free=8.1, wall=66649
2022-03-07 07:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:25:14 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.814 | nll_loss 13.534 | ppl 11859.9 | wps 40834.1 | wpb 510.9 | bsz 1 | num_updates 22259 | best_loss 7.706
2022-03-07 07:25:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 22259 updates
2022-03-07 07:25:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:25:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 231 @ 22259 updates, score 13.814) (writing took 2.326203419826925 seconds)
2022-03-07 07:25:16 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 07:25:16 | INFO | train | epoch 231 | loss 1.292 | nll_loss 0.702 | ppl 1.63 | wps 21717.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 22259 | lr 0.000211957 | gnorm 0.866 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 66828
2022-03-07 07:25:16 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 07:25:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:27:15 | INFO | train_inner | epoch 232:     41 / 97 loss=1.289, nll_loss=0.699, ppl=1.62, wps=21977.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22300, lr=0.000211762, gnorm=0.862, loss_scale=16, train_wall=267, gb_free=8.1, wall=66947
2022-03-07 07:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:03 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.781 | nll_loss 13.5 | ppl 11582.7 | wps 40877.9 | wpb 510.9 | bsz 1 | num_updates 22356 | best_loss 7.706
2022-03-07 07:30:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 22356 updates
2022-03-07 07:30:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 232 @ 22356 updates, score 13.781) (writing took 2.2472178982570767 seconds)
2022-03-07 07:30:05 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 07:30:05 | INFO | train | epoch 232 | loss 1.29 | nll_loss 0.699 | ppl 1.62 | wps 21968.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22356 | lr 0.000211496 | gnorm 0.856 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 67117
2022-03-07 07:30:05 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 07:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:32:16 | INFO | train_inner | epoch 233:     45 / 97 loss=1.289, nll_loss=0.699, ppl=1.62, wps=21752.1, ups=0.33, wpb=65495, bsz=127.9, num_updates=22400, lr=0.000211289, gnorm=0.85, loss_scale=16, train_wall=270, gb_free=8.1, wall=67248
2022-03-07 07:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:34:53 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.835 | nll_loss 13.556 | ppl 12045.7 | wps 40556.1 | wpb 510.9 | bsz 1 | num_updates 22452 | best_loss 7.706
2022-03-07 07:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 22452 updates
2022-03-07 07:34:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 233 @ 22452 updates, score 13.835) (writing took 2.304878030437976 seconds)
2022-03-07 07:34:55 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 07:34:55 | INFO | train | epoch 233 | loss 1.288 | nll_loss 0.697 | ppl 1.62 | wps 21722.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 22452 | lr 0.000211044 | gnorm 0.857 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 67407
2022-03-07 07:34:55 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 07:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:37:15 | INFO | train_inner | epoch 234:     48 / 97 loss=1.288, nll_loss=0.698, ppl=1.62, wps=21964.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22500, lr=0.000210819, gnorm=0.859, loss_scale=32, train_wall=267, gb_free=8.1, wall=67547
2022-03-07 07:38:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:39:42 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.825 | nll_loss 13.542 | ppl 11929.6 | wps 40270.7 | wpb 510.9 | bsz 1 | num_updates 22548 | best_loss 7.706
2022-03-07 07:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 22548 updates
2022-03-07 07:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 234 @ 22548 updates, score 13.825) (writing took 2.274201439227909 seconds)
2022-03-07 07:39:44 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 07:39:44 | INFO | train | epoch 234 | loss 1.287 | nll_loss 0.696 | ppl 1.62 | wps 21713.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 22548 | lr 0.000210594 | gnorm 0.86 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 67696
2022-03-07 07:39:44 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 07:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:42:15 | INFO | train_inner | epoch 235:     52 / 97 loss=1.286, nll_loss=0.695, ppl=1.62, wps=21762.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=22600, lr=0.000210352, gnorm=0.86, loss_scale=16, train_wall=270, gb_free=8.1, wall=67848
2022-03-07 07:44:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:44:31 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.805 | nll_loss 13.525 | ppl 11786.6 | wps 40997 | wpb 510.9 | bsz 1 | num_updates 22645 | best_loss 7.706
2022-03-07 07:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 22645 updates
2022-03-07 07:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:44:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:44:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 235 @ 22645 updates, score 13.805) (writing took 2.2243744879961014 seconds)
2022-03-07 07:44:34 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 07:44:34 | INFO | train | epoch 235 | loss 1.284 | nll_loss 0.694 | ppl 1.62 | wps 21962.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22645 | lr 0.000210142 | gnorm 0.86 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 67986
2022-03-07 07:44:34 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 07:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:13 | INFO | train_inner | epoch 236:     55 / 97 loss=1.283, nll_loss=0.693, ppl=1.62, wps=21978.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22700, lr=0.000209888, gnorm=0.863, loss_scale=32, train_wall=267, gb_free=8.1, wall=68145
2022-03-07 07:47:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:20 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.839 | nll_loss 13.559 | ppl 12071.8 | wps 40312.8 | wpb 510.9 | bsz 1 | num_updates 22741 | best_loss 7.706
2022-03-07 07:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 22741 updates
2022-03-07 07:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 236 @ 22741 updates, score 13.839) (writing took 2.390070960856974 seconds)
2022-03-07 07:49:23 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 07:49:23 | INFO | train | epoch 236 | loss 1.282 | nll_loss 0.691 | ppl 1.61 | wps 21739.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 22741 | lr 0.000209698 | gnorm 0.862 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 68275
2022-03-07 07:49:23 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 07:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:52:15 | INFO | train_inner | epoch 237:     59 / 97 loss=1.281, nll_loss=0.69, ppl=1.61, wps=21754.8, ups=0.33, wpb=65495, bsz=127.9, num_updates=22800, lr=0.000209427, gnorm=0.856, loss_scale=16, train_wall=270, gb_free=8.1, wall=68447
2022-03-07 07:54:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:54:10 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.784 | nll_loss 13.501 | ppl 11595.4 | wps 41050.5 | wpb 510.9 | bsz 1 | num_updates 22838 | best_loss 7.706
2022-03-07 07:54:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 22838 updates
2022-03-07 07:54:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:54:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:54:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 237 @ 22838 updates, score 13.784) (writing took 2.2573232972063124 seconds)
2022-03-07 07:54:12 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 07:54:12 | INFO | train | epoch 237 | loss 1.279 | nll_loss 0.689 | ppl 1.61 | wps 21949.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22838 | lr 0.000209253 | gnorm 0.855 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 68564
2022-03-07 07:54:12 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 07:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:57:12 | INFO | train_inner | epoch 238:     62 / 97 loss=1.277, nll_loss=0.687, ppl=1.61, wps=21989.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22900, lr=0.000208969, gnorm=0.85, loss_scale=32, train_wall=267, gb_free=8.1, wall=68744
2022-03-07 07:57:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:59 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.826 | nll_loss 13.548 | ppl 11974.7 | wps 40818.4 | wpb 510.9 | bsz 1 | num_updates 22934 | best_loss 7.706
2022-03-07 07:58:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 22934 updates
2022-03-07 07:58:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:59:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 07:59:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 238 @ 22934 updates, score 13.826) (writing took 2.2383939870633185 seconds)
2022-03-07 07:59:02 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 07:59:02 | INFO | train | epoch 238 | loss 1.276 | nll_loss 0.686 | ppl 1.61 | wps 21731.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 22934 | lr 0.000208814 | gnorm 0.851 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 68854
2022-03-07 07:59:02 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 07:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:02:13 | INFO | train_inner | epoch 239:     66 / 97 loss=1.276, nll_loss=0.686, ppl=1.61, wps=21753.5, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=23000, lr=0.000208514, gnorm=0.863, loss_scale=16, train_wall=270, gb_free=8.1, wall=69045
2022-03-07 08:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:49 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.805 | nll_loss 13.526 | ppl 11795.8 | wps 41076.2 | wpb 510.9 | bsz 1 | num_updates 23031 | best_loss 7.706
2022-03-07 08:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 23031 updates
2022-03-07 08:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 239 @ 23031 updates, score 13.805) (writing took 2.2714588860981166 seconds)
2022-03-07 08:03:51 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 08:03:51 | INFO | train | epoch 239 | loss 1.275 | nll_loss 0.684 | ppl 1.61 | wps 21956.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23031 | lr 0.000208374 | gnorm 0.856 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 69143
2022-03-07 08:03:51 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 08:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:07:12 | INFO | train_inner | epoch 240:     69 / 97 loss=1.273, nll_loss=0.682, ppl=1.6, wps=21962.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23100, lr=0.000208063, gnorm=0.845, loss_scale=32, train_wall=267, gb_free=8.1, wall=69344
2022-03-07 08:07:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:08:38 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.887 | nll_loss 13.609 | ppl 12497.4 | wps 40652.1 | wpb 510.9 | bsz 1 | num_updates 23127 | best_loss 7.706
2022-03-07 08:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 23127 updates
2022-03-07 08:08:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 240 @ 23127 updates, score 13.887) (writing took 2.3300046417862177 seconds)
2022-03-07 08:08:40 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 08:08:40 | INFO | train | epoch 240 | loss 1.272 | nll_loss 0.682 | ppl 1.6 | wps 21719.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23127 | lr 0.000207941 | gnorm 0.849 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 69432
2022-03-07 08:08:40 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 08:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:12:13 | INFO | train_inner | epoch 241:     73 / 97 loss=1.272, nll_loss=0.682, ppl=1.6, wps=21747.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23200, lr=0.000207614, gnorm=0.857, loss_scale=16, train_wall=270, gb_free=8.1, wall=69645
2022-03-07 08:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:28 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.824 | nll_loss 13.545 | ppl 11952.8 | wps 40722 | wpb 510.9 | bsz 1 | num_updates 23224 | best_loss 7.706
2022-03-07 08:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 23224 updates
2022-03-07 08:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:13:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 241 @ 23224 updates, score 13.824) (writing took 2.2575441296212375 seconds)
2022-03-07 08:13:30 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 08:13:30 | INFO | train | epoch 241 | loss 1.271 | nll_loss 0.681 | ppl 1.6 | wps 21931.4 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 23224 | lr 0.000207506 | gnorm 0.855 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 69722
2022-03-07 08:13:30 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 08:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:17:14 | INFO | train_inner | epoch 242:     77 / 97 loss=1.269, nll_loss=0.679, ppl=1.6, wps=21760, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23300, lr=0.000207168, gnorm=0.854, loss_scale=16, train_wall=270, gb_free=8.1, wall=69946
2022-03-07 08:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:18:17 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.832 | nll_loss 13.552 | ppl 12009.2 | wps 40696.4 | wpb 510.9 | bsz 1 | num_updates 23320 | best_loss 7.706
2022-03-07 08:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 23320 updates
2022-03-07 08:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 242 @ 23320 updates, score 13.832) (writing took 2.297729756683111 seconds)
2022-03-07 08:18:19 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 08:18:19 | INFO | train | epoch 242 | loss 1.267 | nll_loss 0.677 | ppl 1.6 | wps 21726.2 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23320 | lr 0.000207079 | gnorm 0.853 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 70011
2022-03-07 08:18:19 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 08:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:22:12 | INFO | train_inner | epoch 243:     80 / 97 loss=1.266, nll_loss=0.676, ppl=1.6, wps=21961.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23400, lr=0.000206725, gnorm=0.85, loss_scale=16, train_wall=267, gb_free=8.1, wall=70244
2022-03-07 08:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:23:06 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.867 | nll_loss 13.588 | ppl 12314.1 | wps 41846.1 | wpb 510.9 | bsz 1 | num_updates 23417 | best_loss 7.706
2022-03-07 08:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 23417 updates
2022-03-07 08:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 243 @ 23417 updates, score 13.867) (writing took 2.2021092479117215 seconds)
2022-03-07 08:23:09 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 08:23:09 | INFO | train | epoch 243 | loss 1.266 | nll_loss 0.675 | ppl 1.6 | wps 21970.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23417 | lr 0.00020665 | gnorm 0.85 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 70301
2022-03-07 08:23:09 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 08:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:23:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:27:12 | INFO | train_inner | epoch 244:     84 / 97 loss=1.265, nll_loss=0.675, ppl=1.6, wps=21793.9, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23500, lr=0.000206284, gnorm=0.863, loss_scale=16, train_wall=270, gb_free=8.1, wall=70545
2022-03-07 08:27:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:27:56 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.854 | nll_loss 13.577 | ppl 12216.4 | wps 40279.4 | wpb 510.9 | bsz 1 | num_updates 23513 | best_loss 7.706
2022-03-07 08:27:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 23513 updates
2022-03-07 08:27:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:27:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:27:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 244 @ 23513 updates, score 13.854) (writing took 2.2423725239932537 seconds)
2022-03-07 08:27:58 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 08:27:58 | INFO | train | epoch 244 | loss 1.263 | nll_loss 0.673 | ppl 1.59 | wps 21735.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23513 | lr 0.000206227 | gnorm 0.861 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 70590
2022-03-07 08:27:58 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 08:27:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:31:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:32:14 | INFO | train_inner | epoch 245:     88 / 97 loss=1.261, nll_loss=0.671, ppl=1.59, wps=21744.7, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23600, lr=0.000205847, gnorm=0.849, loss_scale=16, train_wall=270, gb_free=8.1, wall=70846
2022-03-07 08:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:32:45 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.917 | nll_loss 13.64 | ppl 12766.7 | wps 40490.8 | wpb 510.9 | bsz 1 | num_updates 23609 | best_loss 7.706
2022-03-07 08:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 23609 updates
2022-03-07 08:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 245 @ 23609 updates, score 13.917) (writing took 2.294789131730795 seconds)
2022-03-07 08:32:47 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 08:32:47 | INFO | train | epoch 245 | loss 1.26 | nll_loss 0.67 | ppl 1.59 | wps 21715 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23609 | lr 0.000205808 | gnorm 0.847 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 70879
2022-03-07 08:32:47 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 08:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:37:12 | INFO | train_inner | epoch 246:     91 / 97 loss=1.262, nll_loss=0.672, ppl=1.59, wps=21948.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23700, lr=0.000205412, gnorm=0.848, loss_scale=16, train_wall=267, gb_free=8.1, wall=71144
2022-03-07 08:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:35 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.876 | nll_loss 13.599 | ppl 12410.2 | wps 41103.6 | wpb 510.9 | bsz 1 | num_updates 23706 | best_loss 7.706
2022-03-07 08:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 23706 updates
2022-03-07 08:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:37:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:37:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 246 @ 23706 updates, score 13.876) (writing took 2.233075311873108 seconds)
2022-03-07 08:37:37 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 08:37:37 | INFO | train | epoch 246 | loss 1.261 | nll_loss 0.67 | ppl 1.59 | wps 21943.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23706 | lr 0.000205386 | gnorm 0.848 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 71169
2022-03-07 08:37:37 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 08:37:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:39:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:42:13 | INFO | train_inner | epoch 247:     95 / 97 loss=1.259, nll_loss=0.669, ppl=1.59, wps=21782.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23800, lr=0.00020498, gnorm=0.842, loss_scale=16, train_wall=269, gb_free=8.1, wall=71445
2022-03-07 08:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:42:24 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.853 | nll_loss 13.573 | ppl 12190.2 | wps 40675.9 | wpb 510.9 | bsz 1 | num_updates 23802 | best_loss 7.706
2022-03-07 08:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 23802 updates
2022-03-07 08:42:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 247 @ 23802 updates, score 13.853) (writing took 2.3724483270198107 seconds)
2022-03-07 08:42:26 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 08:42:26 | INFO | train | epoch 247 | loss 1.258 | nll_loss 0.668 | ppl 1.59 | wps 21733.6 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23802 | lr 0.000204971 | gnorm 0.842 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 71458
2022-03-07 08:42:26 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 08:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:47:13 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.865 | nll_loss 13.587 | ppl 12302.9 | wps 41981.7 | wpb 510.9 | bsz 1 | num_updates 23899 | best_loss 7.706
2022-03-07 08:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 23899 updates
2022-03-07 08:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 248 @ 23899 updates, score 13.865) (writing took 2.4170408230274916 seconds)
2022-03-07 08:47:15 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 08:47:15 | INFO | train | epoch 248 | loss 1.256 | nll_loss 0.666 | ppl 1.59 | wps 21958.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23899 | lr 0.000204555 | gnorm 0.845 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 71747
2022-03-07 08:47:15 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 08:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:47:18 | INFO | train_inner | epoch 249:      1 / 97 loss=1.256, nll_loss=0.666, ppl=1.59, wps=21408.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=23900, lr=0.000204551, gnorm=0.845, loss_scale=32, train_wall=267, gb_free=8.1, wall=71750
2022-03-07 08:50:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:02 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.834 | nll_loss 13.554 | ppl 12030.2 | wps 41390 | wpb 510.9 | bsz 1 | num_updates 23995 | best_loss 7.706
2022-03-07 08:52:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 23995 updates
2022-03-07 08:52:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:52:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:52:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 249 @ 23995 updates, score 13.834) (writing took 2.2777420170605183 seconds)
2022-03-07 08:52:05 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 08:52:05 | INFO | train | epoch 249 | loss 1.254 | nll_loss 0.664 | ppl 1.58 | wps 21730.4 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 23995 | lr 0.000204145 | gnorm 0.843 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 72037
2022-03-07 08:52:05 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 08:52:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:52:19 | INFO | train_inner | epoch 250:      5 / 97 loss=1.253, nll_loss=0.663, ppl=1.58, wps=21761.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=24000, lr=0.000204124, gnorm=0.842, loss_scale=16, train_wall=270, gb_free=8.1, wall=72051
2022-03-07 08:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:52 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.857 | nll_loss 13.578 | ppl 12226.2 | wps 40858.9 | wpb 510.9 | bsz 1 | num_updates 24092 | best_loss 7.706
2022-03-07 08:56:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 24092 updates
2022-03-07 08:56:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:56:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 08:56:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 250 @ 24092 updates, score 13.857) (writing took 2.239187535829842 seconds)
2022-03-07 08:56:54 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 08:56:54 | INFO | train | epoch 250 | loss 1.251 | nll_loss 0.661 | ppl 1.58 | wps 21951.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24092 | lr 0.000203734 | gnorm 0.842 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 72326
2022-03-07 08:56:54 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 08:56:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:57:17 | INFO | train_inner | epoch 251:      8 / 97 loss=1.25, nll_loss=0.66, ppl=1.58, wps=21977.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24100, lr=0.0002037, gnorm=0.841, loss_scale=32, train_wall=267, gb_free=8.1, wall=72349
2022-03-07 08:57:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:01:41 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.86 | nll_loss 13.582 | ppl 12259 | wps 40619.1 | wpb 510.9 | bsz 1 | num_updates 24188 | best_loss 7.706
2022-03-07 09:01:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 24188 updates
2022-03-07 09:01:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 251 @ 24188 updates, score 13.86) (writing took 2.3344852668233216 seconds)
2022-03-07 09:01:44 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 09:01:44 | INFO | train | epoch 251 | loss 1.25 | nll_loss 0.66 | ppl 1.58 | wps 21719.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24188 | lr 0.000203329 | gnorm 0.84 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 72616
2022-03-07 09:01:44 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 09:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:02:19 | INFO | train_inner | epoch 252:     12 / 97 loss=1.249, nll_loss=0.659, ppl=1.58, wps=21739.6, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=24200, lr=0.000203279, gnorm=0.839, loss_scale=16, train_wall=270, gb_free=8.1, wall=72651
2022-03-07 09:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:06:31 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.886 | nll_loss 13.609 | ppl 12491.6 | wps 40496.3 | wpb 510.9 | bsz 1 | num_updates 24284 | best_loss 7.706
2022-03-07 09:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 24284 updates
2022-03-07 09:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 252 @ 24284 updates, score 13.886) (writing took 2.2716795220039785 seconds)
2022-03-07 09:06:33 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 09:06:33 | INFO | train | epoch 252 | loss 1.248 | nll_loss 0.658 | ppl 1.58 | wps 21717.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24284 | lr 0.000202927 | gnorm 0.839 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 72905
2022-03-07 09:06:33 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 09:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:07:20 | INFO | train_inner | epoch 253:     16 / 97 loss=1.247, nll_loss=0.657, ppl=1.58, wps=21751.9, ups=0.33, wpb=65495, bsz=127.9, num_updates=24300, lr=0.00020286, gnorm=0.837, loss_scale=16, train_wall=270, gb_free=8.1, wall=72952
2022-03-07 09:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:11:20 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.837 | nll_loss 13.558 | ppl 12063.1 | wps 41019.3 | wpb 510.9 | bsz 1 | num_updates 24381 | best_loss 7.706
2022-03-07 09:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 24381 updates
2022-03-07 09:11:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:11:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:11:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 253 @ 24381 updates, score 13.837) (writing took 2.18703828798607 seconds)
2022-03-07 09:11:23 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 09:11:23 | INFO | train | epoch 253 | loss 1.246 | nll_loss 0.656 | ppl 1.58 | wps 21952 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24381 | lr 0.000202523 | gnorm 0.836 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 73195
2022-03-07 09:11:23 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 09:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:12:18 | INFO | train_inner | epoch 254:     19 / 97 loss=1.246, nll_loss=0.656, ppl=1.58, wps=21978.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24400, lr=0.000202444, gnorm=0.836, loss_scale=32, train_wall=267, gb_free=8.1, wall=73250
2022-03-07 09:12:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:16:09 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.881 | nll_loss 13.604 | ppl 12452.9 | wps 40852.6 | wpb 510.9 | bsz 1 | num_updates 24477 | best_loss 7.706
2022-03-07 09:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 24477 updates
2022-03-07 09:16:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:16:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:16:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 254 @ 24477 updates, score 13.881) (writing took 2.2198727265931666 seconds)
2022-03-07 09:16:12 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 09:16:12 | INFO | train | epoch 254 | loss 1.244 | nll_loss 0.654 | ppl 1.57 | wps 21742.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24477 | lr 0.000202125 | gnorm 0.842 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 73484
2022-03-07 09:16:12 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 09:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:17:19 | INFO | train_inner | epoch 255:     23 / 97 loss=1.242, nll_loss=0.653, ppl=1.57, wps=21775, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=24500, lr=0.000202031, gnorm=0.841, loss_scale=16, train_wall=270, gb_free=8.1, wall=73551
2022-03-07 09:19:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:20:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:59 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.867 | nll_loss 13.592 | ppl 12352 | wps 40358.6 | wpb 510.9 | bsz 1 | num_updates 24573 | best_loss 7.706
2022-03-07 09:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 24573 updates
2022-03-07 09:20:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:21:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:21:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 255 @ 24573 updates, score 13.867) (writing took 2.2372577572241426 seconds)
2022-03-07 09:21:01 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 09:21:01 | INFO | train | epoch 255 | loss 1.241 | nll_loss 0.651 | ppl 1.57 | wps 21741.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24573 | lr 0.00020173 | gnorm 0.829 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 73773
2022-03-07 09:21:01 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 09:21:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:19 | INFO | train_inner | epoch 256:     27 / 97 loss=1.239, nll_loss=0.649, ppl=1.57, wps=21762, ups=0.33, wpb=65495, bsz=127.9, num_updates=24600, lr=0.000201619, gnorm=0.834, loss_scale=16, train_wall=270, gb_free=8.1, wall=73852
2022-03-07 09:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:25:48 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.927 | nll_loss 13.654 | ppl 12888.4 | wps 40718.7 | wpb 510.9 | bsz 1 | num_updates 24670 | best_loss 7.706
2022-03-07 09:25:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 24670 updates
2022-03-07 09:25:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:25:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 256 @ 24670 updates, score 13.927) (writing took 2.262013425119221 seconds)
2022-03-07 09:25:50 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 09:25:50 | INFO | train | epoch 256 | loss 1.24 | nll_loss 0.651 | ppl 1.57 | wps 21952.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24670 | lr 0.000201333 | gnorm 0.841 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 74062
2022-03-07 09:25:50 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 09:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:27:18 | INFO | train_inner | epoch 257:     30 / 97 loss=1.241, nll_loss=0.652, ppl=1.57, wps=21972.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24700, lr=0.000201211, gnorm=0.837, loss_scale=32, train_wall=267, gb_free=8.1, wall=74150
2022-03-07 09:28:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:30:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:30:37 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.947 | nll_loss 13.673 | ppl 13063 | wps 41210.5 | wpb 510.9 | bsz 1 | num_updates 24766 | best_loss 7.706
2022-03-07 09:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 24766 updates
2022-03-07 09:30:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 257 @ 24766 updates, score 13.947) (writing took 2.2875101980753243 seconds)
2022-03-07 09:30:39 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 09:30:39 | INFO | train | epoch 257 | loss 1.239 | nll_loss 0.649 | ppl 1.57 | wps 21736.1 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24766 | lr 0.000200943 | gnorm 0.84 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 74352
2022-03-07 09:30:40 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 09:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:32:18 | INFO | train_inner | epoch 258:     34 / 97 loss=1.238, nll_loss=0.648, ppl=1.57, wps=21783.3, ups=0.33, wpb=65495, bsz=127.9, num_updates=24800, lr=0.000200805, gnorm=0.838, loss_scale=16, train_wall=270, gb_free=8.1, wall=74450
2022-03-07 09:34:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:35:26 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.921 | nll_loss 13.645 | ppl 12813.5 | wps 43669.3 | wpb 510.9 | bsz 1 | num_updates 24862 | best_loss 7.706
2022-03-07 09:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 24862 updates
2022-03-07 09:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 258 @ 24862 updates, score 13.921) (writing took 2.3926872690208256 seconds)
2022-03-07 09:35:28 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 09:35:28 | INFO | train | epoch 258 | loss 1.237 | nll_loss 0.647 | ppl 1.57 | wps 21762 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 24862 | lr 0.000200554 | gnorm 0.83 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 74640
2022-03-07 09:35:28 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 09:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:37:19 | INFO | train_inner | epoch 259:     38 / 97 loss=1.234, nll_loss=0.644, ppl=1.56, wps=21770.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=24900, lr=0.000200401, gnorm=0.828, loss_scale=16, train_wall=270, gb_free=8.1, wall=74751
2022-03-07 09:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:40:15 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.897 | nll_loss 13.622 | ppl 12608.6 | wps 40889.6 | wpb 510.9 | bsz 1 | num_updates 24959 | best_loss 7.706
2022-03-07 09:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 24959 updates
2022-03-07 09:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:40:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 259 @ 24959 updates, score 13.897) (writing took 2.3617385760881007 seconds)
2022-03-07 09:40:18 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 09:40:18 | INFO | train | epoch 259 | loss 1.235 | nll_loss 0.645 | ppl 1.56 | wps 21948.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24959 | lr 0.000200164 | gnorm 0.832 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 74930
2022-03-07 09:40:18 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 09:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:41:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:42:20 | INFO | train_inner | epoch 260:     42 / 97 loss=1.234, nll_loss=0.644, ppl=1.56, wps=21771.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=25000, lr=0.0002, gnorm=0.834, loss_scale=16, train_wall=270, gb_free=8.1, wall=75052
2022-03-07 09:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:45:05 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.937 | nll_loss 13.666 | ppl 12995.1 | wps 40512.6 | wpb 510.9 | bsz 1 | num_updates 25055 | best_loss 7.706
2022-03-07 09:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 25055 updates
2022-03-07 09:45:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:45:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 260 @ 25055 updates, score 13.937) (writing took 2.219792543910444 seconds)
2022-03-07 09:45:07 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 09:45:07 | INFO | train | epoch 260 | loss 1.232 | nll_loss 0.642 | ppl 1.56 | wps 21744.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25055 | lr 0.00019978 | gnorm 0.832 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 75219
2022-03-07 09:45:07 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 09:45:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:47:18 | INFO | train_inner | epoch 261:     45 / 97 loss=1.233, nll_loss=0.643, ppl=1.56, wps=21998.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25100, lr=0.000199601, gnorm=0.838, loss_scale=16, train_wall=267, gb_free=8.1, wall=75350
2022-03-07 09:47:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:49:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:49:54 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.943 | nll_loss 13.669 | ppl 13022.2 | wps 41123.8 | wpb 510.9 | bsz 1 | num_updates 25151 | best_loss 7.706
2022-03-07 09:49:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 25151 updates
2022-03-07 09:49:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:49:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:49:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 261 @ 25151 updates, score 13.943) (writing took 2.2348283329047263 seconds)
2022-03-07 09:49:56 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 09:49:56 | INFO | train | epoch 261 | loss 1.231 | nll_loss 0.642 | ppl 1.56 | wps 21756.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25151 | lr 0.000199399 | gnorm 0.844 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 75508
2022-03-07 09:49:56 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 09:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:18 | INFO | train_inner | epoch 262:     49 / 97 loss=1.229, nll_loss=0.639, ppl=1.56, wps=21789.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25200, lr=0.000199205, gnorm=0.837, loss_scale=16, train_wall=270, gb_free=8.1, wall=75650
2022-03-07 09:54:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:54:43 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.894 | nll_loss 13.618 | ppl 12568.8 | wps 40391.3 | wpb 510.9 | bsz 1 | num_updates 25248 | best_loss 7.706
2022-03-07 09:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 25248 updates
2022-03-07 09:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:54:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 262 @ 25248 updates, score 13.894) (writing took 2.1935337353497744 seconds)
2022-03-07 09:54:45 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 09:54:45 | INFO | train | epoch 262 | loss 1.229 | nll_loss 0.639 | ppl 1.56 | wps 21992.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25248 | lr 0.000199015 | gnorm 0.829 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 75797
2022-03-07 09:54:45 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 09:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:57:19 | INFO | train_inner | epoch 263:     53 / 97 loss=1.229, nll_loss=0.64, ppl=1.56, wps=21773.7, ups=0.33, wpb=65495, bsz=127.9, num_updates=25300, lr=0.000198811, gnorm=0.832, loss_scale=16, train_wall=270, gb_free=8.1, wall=75951
2022-03-07 09:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:59:32 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.92 | nll_loss 13.646 | ppl 12820.6 | wps 40369.8 | wpb 510.9 | bsz 1 | num_updates 25344 | best_loss 7.706
2022-03-07 09:59:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 25344 updates
2022-03-07 09:59:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:59:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 09:59:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 263 @ 25344 updates, score 13.92) (writing took 2.2553717787377536 seconds)
2022-03-07 09:59:34 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 09:59:34 | INFO | train | epoch 263 | loss 1.227 | nll_loss 0.637 | ppl 1.56 | wps 21735.7 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25344 | lr 0.000198638 | gnorm 0.827 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 76086
2022-03-07 09:59:34 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 09:59:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:02:17 | INFO | train_inner | epoch 264:     56 / 97 loss=1.226, nll_loss=0.636, ppl=1.55, wps=21990.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25400, lr=0.000198419, gnorm=0.828, loss_scale=16, train_wall=267, gb_free=8.1, wall=76249
2022-03-07 10:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:04:21 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.909 | nll_loss 13.638 | ppl 12745.9 | wps 40615.5 | wpb 510.9 | bsz 1 | num_updates 25441 | best_loss 7.706
2022-03-07 10:04:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 25441 updates
2022-03-07 10:04:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:04:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:04:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 264 @ 25441 updates, score 13.909) (writing took 2.315262721851468 seconds)
2022-03-07 10:04:24 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 10:04:24 | INFO | train | epoch 264 | loss 1.226 | nll_loss 0.637 | ppl 1.55 | wps 21946.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25441 | lr 0.000198259 | gnorm 0.832 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 76376
2022-03-07 10:04:24 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 10:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:06:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:07:18 | INFO | train_inner | epoch 265:     60 / 97 loss=1.224, nll_loss=0.635, ppl=1.55, wps=21757.1, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=25500, lr=0.00019803, gnorm=0.832, loss_scale=16, train_wall=270, gb_free=8.1, wall=76550
2022-03-07 10:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:09:10 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.912 | nll_loss 13.636 | ppl 12733.1 | wps 41201.2 | wpb 510.9 | bsz 1 | num_updates 25537 | best_loss 7.706
2022-03-07 10:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 25537 updates
2022-03-07 10:09:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:09:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 265 @ 25537 updates, score 13.912) (writing took 2.195072223432362 seconds)
2022-03-07 10:09:13 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 10:09:13 | INFO | train | epoch 265 | loss 1.224 | nll_loss 0.634 | ppl 1.55 | wps 21753.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25537 | lr 0.000197886 | gnorm 0.834 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 76665
2022-03-07 10:09:13 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 10:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:12:15 | INFO | train_inner | epoch 266:     63 / 97 loss=1.224, nll_loss=0.634, ppl=1.55, wps=22005.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=25600, lr=0.000197642, gnorm=0.828, loss_scale=16, train_wall=267, gb_free=8.1, wall=76847
2022-03-07 10:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:13:59 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.961 | nll_loss 13.689 | ppl 13203.1 | wps 40821.5 | wpb 510.9 | bsz 1 | num_updates 25634 | best_loss 7.706
2022-03-07 10:13:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 25634 updates
2022-03-07 10:13:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 266 @ 25634 updates, score 13.961) (writing took 2.2220452539622784 seconds)
2022-03-07 10:14:01 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 10:14:01 | INFO | train | epoch 266 | loss 1.222 | nll_loss 0.632 | ppl 1.55 | wps 21994.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25634 | lr 0.000197511 | gnorm 0.823 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 76953
2022-03-07 10:14:01 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 10:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:17:13 | INFO | train_inner | epoch 267:     66 / 97 loss=1.221, nll_loss=0.632, ppl=1.55, wps=21994.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25700, lr=0.000197257, gnorm=0.824, loss_scale=32, train_wall=267, gb_free=8.1, wall=77145
2022-03-07 10:18:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:18:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:18:48 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.943 | nll_loss 13.669 | ppl 13021.5 | wps 42538 | wpb 510.9 | bsz 1 | num_updates 25730 | best_loss 7.706
2022-03-07 10:18:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 25730 updates
2022-03-07 10:18:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:18:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:18:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 267 @ 25730 updates, score 13.943) (writing took 2.346026036888361 seconds)
2022-03-07 10:18:50 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 10:18:50 | INFO | train | epoch 267 | loss 1.221 | nll_loss 0.632 | ppl 1.55 | wps 21745.9 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 25730 | lr 0.000197142 | gnorm 0.827 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 77243
2022-03-07 10:18:51 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 10:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:22:14 | INFO | train_inner | epoch 268:     70 / 97 loss=1.218, nll_loss=0.629, ppl=1.55, wps=21792.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=25800, lr=0.000196875, gnorm=0.824, loss_scale=16, train_wall=270, gb_free=8.1, wall=77446
2022-03-07 10:23:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:23:37 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.879 | nll_loss 13.604 | ppl 12455 | wps 41183.4 | wpb 510.9 | bsz 1 | num_updates 25827 | best_loss 7.706
2022-03-07 10:23:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 25827 updates
2022-03-07 10:23:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:23:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:23:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 268 @ 25827 updates, score 13.879) (writing took 2.2362336460500956 seconds)
2022-03-07 10:23:40 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 10:23:40 | INFO | train | epoch 268 | loss 1.218 | nll_loss 0.629 | ppl 1.55 | wps 21980.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25827 | lr 0.000196772 | gnorm 0.828 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 77532
2022-03-07 10:23:40 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 10:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:12 | INFO | train_inner | epoch 269:     73 / 97 loss=1.219, nll_loss=0.63, ppl=1.55, wps=21980.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25900, lr=0.000196494, gnorm=0.828, loss_scale=32, train_wall=267, gb_free=8.1, wall=77744
2022-03-07 10:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:28:27 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.886 | nll_loss 13.613 | ppl 12529.5 | wps 40835.4 | wpb 510.9 | bsz 1 | num_updates 25924 | best_loss 7.706
2022-03-07 10:28:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 25924 updates
2022-03-07 10:28:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:28:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:28:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 269 @ 25924 updates, score 13.886) (writing took 2.2759948349557817 seconds)
2022-03-07 10:28:29 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 10:28:29 | INFO | train | epoch 269 | loss 1.217 | nll_loss 0.628 | ppl 1.55 | wps 21957.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25924 | lr 0.000196403 | gnorm 0.824 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 77821
2022-03-07 10:28:29 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 10:28:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:28:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:32:13 | INFO | train_inner | epoch 270:     77 / 97 loss=1.217, nll_loss=0.627, ppl=1.54, wps=21764.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26000, lr=0.000196116, gnorm=0.827, loss_scale=16, train_wall=270, gb_free=8.1, wall=78045
2022-03-07 10:33:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:33:16 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.996 | nll_loss 13.726 | ppl 13551.6 | wps 40640.7 | wpb 510.9 | bsz 1 | num_updates 26020 | best_loss 7.706
2022-03-07 10:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 26020 updates
2022-03-07 10:33:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:33:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 270 @ 26020 updates, score 13.996) (writing took 2.3010373087599874 seconds)
2022-03-07 10:33:18 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 10:33:18 | INFO | train | epoch 270 | loss 1.215 | nll_loss 0.625 | ppl 1.54 | wps 21731.8 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26020 | lr 0.000196041 | gnorm 0.822 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 78110
2022-03-07 10:33:18 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 10:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:37:13 | INFO | train_inner | epoch 271:     81 / 97 loss=1.213, nll_loss=0.623, ppl=1.54, wps=21769.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=26100, lr=0.00019574, gnorm=0.817, loss_scale=16, train_wall=270, gb_free=8.1, wall=78345
2022-03-07 10:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:38:05 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.972 | nll_loss 13.696 | ppl 13272.2 | wps 41016.6 | wpb 510.9 | bsz 1 | num_updates 26116 | best_loss 7.706
2022-03-07 10:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 26116 updates
2022-03-07 10:38:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:38:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:38:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 271 @ 26116 updates, score 13.972) (writing took 2.3164228522218764 seconds)
2022-03-07 10:38:07 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 10:38:07 | INFO | train | epoch 271 | loss 1.213 | nll_loss 0.624 | ppl 1.54 | wps 21730.3 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 26116 | lr 0.00019568 | gnorm 0.817 | loss_scale 16 | train_wall 259 | gb_free 8.1 | wall 78400
2022-03-07 10:38:07 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 10:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:42:11 | INFO | train_inner | epoch 272:     84 / 97 loss=1.214, nll_loss=0.625, ppl=1.54, wps=21983.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26200, lr=0.000195366, gnorm=0.819, loss_scale=32, train_wall=267, gb_free=8.1, wall=78643
2022-03-07 10:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:42:54 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.951 | nll_loss 13.679 | ppl 13111.3 | wps 41645.7 | wpb 510.9 | bsz 1 | num_updates 26213 | best_loss 7.706
2022-03-07 10:42:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 26213 updates
2022-03-07 10:42:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:42:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 272 @ 26213 updates, score 13.951) (writing took 2.360471159219742 seconds)
2022-03-07 10:42:57 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 10:42:57 | INFO | train | epoch 272 | loss 1.213 | nll_loss 0.623 | ppl 1.54 | wps 21973.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26213 | lr 0.000195318 | gnorm 0.816 | loss_scale 32 | train_wall 259 | gb_free 8.1 | wall 78689
2022-03-07 10:42:57 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 10:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:47:04 | INFO | train_inner | epoch 273:     87 / 97 loss=1.212, nll_loss=0.623, ppl=1.54, wps=22385.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=26300, lr=0.000194994, gnorm=0.827, loss_scale=32, train_wall=262, gb_free=8.1, wall=78936
2022-03-07 10:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:47:37 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.945 | nll_loss 13.672 | ppl 13056.6 | wps 44597.5 | wpb 510.9 | bsz 1 | num_updates 26310 | best_loss 7.706
2022-03-07 10:47:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 26310 updates
2022-03-07 10:47:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:47:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 273 @ 26310 updates, score 13.945) (writing took 2.2951215747743845 seconds)
2022-03-07 10:47:39 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 10:47:39 | INFO | train | epoch 273 | loss 1.212 | nll_loss 0.622 | ppl 1.54 | wps 22462.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26310 | lr 0.000194957 | gnorm 0.83 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 78971
2022-03-07 10:47:39 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 10:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:48:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:49:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:52:02 | INFO | train_inner | epoch 274:     92 / 97 loss=1.21, nll_loss=0.62, ppl=1.54, wps=22001.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=26400, lr=0.000194625, gnorm=0.822, loss_scale=16, train_wall=267, gb_free=8.1, wall=79234
2022-03-07 10:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:52:21 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.951 | nll_loss 13.679 | ppl 13117 | wps 43962 | wpb 510.9 | bsz 1 | num_updates 26405 | best_loss 7.706
2022-03-07 10:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 26405 updates
2022-03-07 10:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:52:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 274 @ 26405 updates, score 13.951) (writing took 2.2217021700926125 seconds)
2022-03-07 10:52:23 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 10:52:23 | INFO | train | epoch 274 | loss 1.208 | nll_loss 0.618 | ppl 1.53 | wps 21933.5 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 26405 | lr 0.000194606 | gnorm 0.82 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 79255
2022-03-07 10:52:23 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 10:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:56:54 | INFO | train_inner | epoch 275:     95 / 97 loss=1.208, nll_loss=0.618, ppl=1.54, wps=22376.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26500, lr=0.000194257, gnorm=0.815, loss_scale=32, train_wall=263, gb_free=8.1, wall=79526
2022-03-07 10:57:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:57:05 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.997 | nll_loss 13.724 | ppl 13529.9 | wps 43609.7 | wpb 510.9 | bsz 1 | num_updates 26502 | best_loss 7.706
2022-03-07 10:57:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 26502 updates
2022-03-07 10:57:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 10:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 275 @ 26502 updates, score 13.997) (writing took 2.29154228977859 seconds)
2022-03-07 10:57:07 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 10:57:07 | INFO | train | epoch 275 | loss 1.207 | nll_loss 0.618 | ppl 1.53 | wps 22359.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26502 | lr 0.00019425 | gnorm 0.814 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 79539
2022-03-07 10:57:07 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 10:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:01:49 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.974 | nll_loss 13.702 | ppl 13330.8 | wps 43862.8 | wpb 510.9 | bsz 1 | num_updates 26598 | best_loss 7.706
2022-03-07 11:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 26598 updates
2022-03-07 11:01:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:01:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:01:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 276 @ 26598 updates, score 13.974) (writing took 2.25087702088058 seconds)
2022-03-07 11:01:51 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 11:01:51 | INFO | train | epoch 276 | loss 1.207 | nll_loss 0.617 | ppl 1.53 | wps 22145.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26598 | lr 0.000193899 | gnorm 0.833 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 79823
2022-03-07 11:01:51 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 11:01:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:01:57 | INFO | train_inner | epoch 277:      2 / 97 loss=1.206, nll_loss=0.617, ppl=1.53, wps=21630.8, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=26600, lr=0.000193892, gnorm=0.833, loss_scale=16, train_wall=265, gb_free=8.1, wall=79829
2022-03-07 11:05:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:06:32 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.956 | nll_loss 13.685 | ppl 13174.7 | wps 44155.2 | wpb 510.9 | bsz 1 | num_updates 26694 | best_loss 7.706
2022-03-07 11:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 26694 updates
2022-03-07 11:06:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 277 @ 26694 updates, score 13.956) (writing took 2.2215321413241327 seconds)
2022-03-07 11:06:34 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 11:06:34 | INFO | train | epoch 277 | loss 1.203 | nll_loss 0.614 | ppl 1.53 | wps 22198.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26694 | lr 0.00019355 | gnorm 0.823 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80106
2022-03-07 11:06:34 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 11:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:06:51 | INFO | train_inner | epoch 278:      6 / 97 loss=1.203, nll_loss=0.613, ppl=1.53, wps=22235.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26700, lr=0.000193528, gnorm=0.823, loss_scale=16, train_wall=265, gb_free=8.1, wall=80123
2022-03-07 11:11:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:11:16 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.95 | nll_loss 13.676 | ppl 13091.5 | wps 43804.5 | wpb 510.9 | bsz 1 | num_updates 26791 | best_loss 7.706
2022-03-07 11:11:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 26791 updates
2022-03-07 11:11:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 278 @ 26791 updates, score 13.95) (writing took 2.213040249887854 seconds)
2022-03-07 11:11:18 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 11:11:18 | INFO | train | epoch 278 | loss 1.203 | nll_loss 0.614 | ppl 1.53 | wps 22394.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26791 | lr 0.000193199 | gnorm 0.829 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80390
2022-03-07 11:11:18 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 11:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:11:44 | INFO | train_inner | epoch 279:      9 / 97 loss=1.202, nll_loss=0.613, ppl=1.53, wps=22403, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26800, lr=0.000193167, gnorm=0.825, loss_scale=32, train_wall=262, gb_free=8.1, wall=80416
2022-03-07 11:15:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:15:58 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.965 | nll_loss 13.693 | ppl 13246.9 | wps 44117.1 | wpb 510.9 | bsz 1 | num_updates 26887 | best_loss 7.706
2022-03-07 11:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 26887 updates
2022-03-07 11:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:16:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 279 @ 26887 updates, score 13.965) (writing took 2.263357006944716 seconds)
2022-03-07 11:16:01 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 11:16:01 | INFO | train | epoch 279 | loss 1.201 | nll_loss 0.612 | ppl 1.53 | wps 22231.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26887 | lr 0.000192854 | gnorm 0.813 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80673
2022-03-07 11:16:01 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 11:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:16:38 | INFO | train_inner | epoch 280:     13 / 97 loss=1.2, nll_loss=0.611, ppl=1.53, wps=22276.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26900, lr=0.000192807, gnorm=0.815, loss_scale=16, train_wall=264, gb_free=8.1, wall=80710
2022-03-07 11:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:20:41 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.97 | nll_loss 13.699 | ppl 13302 | wps 43950.7 | wpb 510.9 | bsz 1 | num_updates 26984 | best_loss 7.706
2022-03-07 11:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 26984 updates
2022-03-07 11:20:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:20:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 280 @ 26984 updates, score 13.97) (writing took 2.217090557795018 seconds)
2022-03-07 11:20:43 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 11:20:43 | INFO | train | epoch 280 | loss 1.199 | nll_loss 0.61 | ppl 1.53 | wps 22480.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26984 | lr 0.000192507 | gnorm 0.821 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80955
2022-03-07 11:20:43 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 11:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:29 | INFO | train_inner | epoch 281:     16 / 97 loss=1.198, nll_loss=0.609, ppl=1.53, wps=22496, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27000, lr=0.00019245, gnorm=0.819, loss_scale=32, train_wall=262, gb_free=8.1, wall=81001
2022-03-07 11:21:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:25:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:25:23 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.951 | nll_loss 13.678 | ppl 13105.9 | wps 44443.5 | wpb 510.9 | bsz 1 | num_updates 27080 | best_loss 7.706
2022-03-07 11:25:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 27080 updates
2022-03-07 11:25:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:25:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 281 @ 27080 updates, score 13.951) (writing took 2.2407220569439232 seconds)
2022-03-07 11:25:25 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 11:25:25 | INFO | train | epoch 281 | loss 1.198 | nll_loss 0.609 | ppl 1.53 | wps 22290.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27080 | lr 0.000192166 | gnorm 0.816 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 81237
2022-03-07 11:25:25 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 11:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:26:22 | INFO | train_inner | epoch 282:     20 / 97 loss=1.197, nll_loss=0.608, ppl=1.52, wps=22335.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=27100, lr=0.000192095, gnorm=0.815, loss_scale=16, train_wall=264, gb_free=8.1, wall=81294
2022-03-07 11:29:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:30:05 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.931 | nll_loss 13.661 | ppl 12951.4 | wps 44412.1 | wpb 510.9 | bsz 1 | num_updates 27176 | best_loss 7.706
2022-03-07 11:30:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 27176 updates
2022-03-07 11:30:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:30:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:30:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 282 @ 27176 updates, score 13.931) (writing took 2.225286500994116 seconds)
2022-03-07 11:30:07 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 11:30:07 | INFO | train | epoch 282 | loss 1.195 | nll_loss 0.606 | ppl 1.52 | wps 22322.1 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 27176 | lr 0.000191826 | gnorm 0.809 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 81519
2022-03-07 11:30:07 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 11:30:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:31:15 | INFO | train_inner | epoch 283:     24 / 97 loss=1.196, nll_loss=0.606, ppl=1.52, wps=22353.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=27200, lr=0.000191741, gnorm=0.808, loss_scale=16, train_wall=263, gb_free=8.1, wall=81587
2022-03-07 11:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:47 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.986 | nll_loss 13.716 | ppl 13454.4 | wps 44616.8 | wpb 510.9 | bsz 1 | num_updates 27273 | best_loss 7.706
2022-03-07 11:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 27273 updates
2022-03-07 11:34:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:34:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:34:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 283 @ 27273 updates, score 13.986) (writing took 2.2079783868975937 seconds)
2022-03-07 11:34:49 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 11:34:49 | INFO | train | epoch 283 | loss 1.195 | nll_loss 0.606 | ppl 1.52 | wps 22554.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27273 | lr 0.000191484 | gnorm 0.814 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 81801
2022-03-07 11:34:49 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 11:34:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:05 | INFO | train_inner | epoch 284:     27 / 97 loss=1.194, nll_loss=0.605, ppl=1.52, wps=22574.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27300, lr=0.00019139, gnorm=0.811, loss_scale=32, train_wall=261, gb_free=8.1, wall=81877
2022-03-07 11:37:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:39:28 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.968 | nll_loss 13.696 | ppl 13272.4 | wps 44645.1 | wpb 510.9 | bsz 1 | num_updates 27369 | best_loss 7.706
2022-03-07 11:39:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 27369 updates
2022-03-07 11:39:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:39:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:39:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 284 @ 27369 updates, score 13.968) (writing took 2.209462934639305 seconds)
2022-03-07 11:39:30 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 11:39:30 | INFO | train | epoch 284 | loss 1.193 | nll_loss 0.604 | ppl 1.52 | wps 22329.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27369 | lr 0.000191148 | gnorm 0.814 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 82082
2022-03-07 11:39:30 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 11:39:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:40:58 | INFO | train_inner | epoch 285:     31 / 97 loss=1.192, nll_loss=0.603, ppl=1.52, wps=22361.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27400, lr=0.00019104, gnorm=0.815, loss_scale=16, train_wall=263, gb_free=8.1, wall=82170
2022-03-07 11:43:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:44:10 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.944 | nll_loss 13.675 | ppl 13082.9 | wps 44675.8 | wpb 510.9 | bsz 1 | num_updates 27465 | best_loss 7.706
2022-03-07 11:44:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 27465 updates
2022-03-07 11:44:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:44:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 285 @ 27465 updates, score 13.944) (writing took 2.157043426297605 seconds)
2022-03-07 11:44:12 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 11:44:12 | INFO | train | epoch 285 | loss 1.191 | nll_loss 0.602 | ppl 1.52 | wps 22332.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27465 | lr 0.000190814 | gnorm 0.812 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 82364
2022-03-07 11:44:12 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 11:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:45:51 | INFO | train_inner | epoch 286:     35 / 97 loss=1.191, nll_loss=0.602, ppl=1.52, wps=22363.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27500, lr=0.000190693, gnorm=0.81, loss_scale=16, train_wall=263, gb_free=8.1, wall=82463
2022-03-07 11:48:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:48:51 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.94 | nll_loss 13.669 | ppl 13029.3 | wps 44648.5 | wpb 510.9 | bsz 1 | num_updates 27562 | best_loss 7.706
2022-03-07 11:48:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 27562 updates
2022-03-07 11:48:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:48:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:48:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 286 @ 27562 updates, score 13.94) (writing took 2.168225470930338 seconds)
2022-03-07 11:48:53 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 11:48:53 | INFO | train | epoch 286 | loss 1.189 | nll_loss 0.6 | ppl 1.52 | wps 22563.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27562 | lr 0.000190478 | gnorm 0.801 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 82645
2022-03-07 11:48:53 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 11:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:50:41 | INFO | train_inner | epoch 287:     38 / 97 loss=1.187, nll_loss=0.598, ppl=1.51, wps=22582.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27600, lr=0.000190347, gnorm=0.804, loss_scale=32, train_wall=261, gb_free=8.1, wall=82753
2022-03-07 11:51:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:33 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.97 | nll_loss 13.7 | ppl 13305.8 | wps 44423.4 | wpb 510.9 | bsz 1 | num_updates 27658 | best_loss 7.706
2022-03-07 11:53:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 27658 updates
2022-03-07 11:53:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 287 @ 27658 updates, score 13.97) (writing took 2.193461894057691 seconds)
2022-03-07 11:53:35 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 11:53:35 | INFO | train | epoch 287 | loss 1.189 | nll_loss 0.6 | ppl 1.52 | wps 22326.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27658 | lr 0.000190147 | gnorm 0.815 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 82927
2022-03-07 11:53:35 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 11:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:55:34 | INFO | train_inner | epoch 288:     42 / 97 loss=1.189, nll_loss=0.6, ppl=1.52, wps=22353.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=27700, lr=0.000190003, gnorm=0.812, loss_scale=16, train_wall=263, gb_free=8.1, wall=83046
2022-03-07 11:58:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:58:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:58:14 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.956 | nll_loss 13.686 | ppl 13176.2 | wps 44750.8 | wpb 510.9 | bsz 1 | num_updates 27754 | best_loss 7.706
2022-03-07 11:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 27754 updates
2022-03-07 11:58:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 11:58:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 288 @ 27754 updates, score 13.956) (writing took 2.181726865004748 seconds)
2022-03-07 11:58:17 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 11:58:17 | INFO | train | epoch 288 | loss 1.187 | nll_loss 0.599 | ppl 1.51 | wps 22329.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27754 | lr 0.000189818 | gnorm 0.813 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 83209
2022-03-07 11:58:17 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 11:58:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:00:27 | INFO | train_inner | epoch 289:     46 / 97 loss=1.187, nll_loss=0.598, ppl=1.51, wps=22362.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27800, lr=0.000189661, gnorm=0.815, loss_scale=16, train_wall=263, gb_free=8.1, wall=83339
2022-03-07 12:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:56 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.974 | nll_loss 13.704 | ppl 13344.4 | wps 44586.3 | wpb 510.9 | bsz 1 | num_updates 27851 | best_loss 7.706
2022-03-07 12:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 27851 updates
2022-03-07 12:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 289 @ 27851 updates, score 13.974) (writing took 2.2485927608795464 seconds)
2022-03-07 12:02:58 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 12:02:58 | INFO | train | epoch 289 | loss 1.185 | nll_loss 0.596 | ppl 1.51 | wps 22547.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27851 | lr 0.000189487 | gnorm 0.81 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 83490
2022-03-07 12:02:58 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 12:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:17 | INFO | train_inner | epoch 290:     49 / 97 loss=1.185, nll_loss=0.596, ppl=1.51, wps=22568.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=27900, lr=0.000189321, gnorm=0.805, loss_scale=32, train_wall=261, gb_free=8.1, wall=83629
2022-03-07 12:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:38 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.978 | nll_loss 13.71 | ppl 13400.2 | wps 44576.8 | wpb 510.9 | bsz 1 | num_updates 27948 | best_loss 7.706
2022-03-07 12:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 27948 updates
2022-03-07 12:07:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:07:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:07:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 290 @ 27948 updates, score 13.978) (writing took 2.1827111709862947 seconds)
2022-03-07 12:07:40 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 12:07:40 | INFO | train | epoch 290 | loss 1.185 | nll_loss 0.596 | ppl 1.51 | wps 22560.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27948 | lr 0.000189158 | gnorm 0.803 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 83772
2022-03-07 12:07:40 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 12:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:07:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:10:10 | INFO | train_inner | epoch 291:     53 / 97 loss=1.184, nll_loss=0.595, ppl=1.51, wps=22358.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28000, lr=0.000188982, gnorm=0.809, loss_scale=16, train_wall=263, gb_free=8.1, wall=83922
2022-03-07 12:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:12:19 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.92 | nll_loss 13.651 | ppl 12859.2 | wps 44352.9 | wpb 510.9 | bsz 1 | num_updates 28044 | best_loss 7.706
2022-03-07 12:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 28044 updates
2022-03-07 12:12:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:12:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 291 @ 28044 updates, score 13.92) (writing took 2.1807936928234994 seconds)
2022-03-07 12:12:22 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 12:12:22 | INFO | train | epoch 291 | loss 1.184 | nll_loss 0.595 | ppl 1.51 | wps 22321.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28044 | lr 0.000188834 | gnorm 0.806 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 84054
2022-03-07 12:12:22 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 12:12:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:15:00 | INFO | train_inner | epoch 292:     56 / 97 loss=1.184, nll_loss=0.595, ppl=1.51, wps=22570.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28100, lr=0.000188646, gnorm=0.805, loss_scale=32, train_wall=261, gb_free=8.1, wall=84212
2022-03-07 12:16:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:17:01 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.998 | nll_loss 13.726 | ppl 13552.4 | wps 44502.2 | wpb 510.9 | bsz 1 | num_updates 28141 | best_loss 7.706
2022-03-07 12:17:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 28141 updates
2022-03-07 12:17:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:17:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:17:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 292 @ 28141 updates, score 13.998) (writing took 2.222566820681095 seconds)
2022-03-07 12:17:03 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 12:17:03 | INFO | train | epoch 292 | loss 1.182 | nll_loss 0.593 | ppl 1.51 | wps 22549.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28141 | lr 0.000188508 | gnorm 0.808 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 84335
2022-03-07 12:17:03 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 12:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:19:53 | INFO | train_inner | epoch 293:     60 / 97 loss=1.179, nll_loss=0.591, ppl=1.51, wps=22348.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=28200, lr=0.000188311, gnorm=0.806, loss_scale=16, train_wall=263, gb_free=8.1, wall=84505
2022-03-07 12:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:43 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 14.027 | nll_loss 13.759 | ppl 13867.2 | wps 44376.8 | wpb 510.9 | bsz 1 | num_updates 28237 | best_loss 7.706
2022-03-07 12:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 28237 updates
2022-03-07 12:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:21:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:21:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 293 @ 28237 updates, score 14.027) (writing took 2.235489204991609 seconds)
2022-03-07 12:21:45 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 12:21:45 | INFO | train | epoch 293 | loss 1.181 | nll_loss 0.592 | ppl 1.51 | wps 22318.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28237 | lr 0.000188187 | gnorm 0.808 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 84617
2022-03-07 12:21:45 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 12:21:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:24:43 | INFO | train_inner | epoch 294:     63 / 97 loss=1.181, nll_loss=0.592, ppl=1.51, wps=22574.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28300, lr=0.000187978, gnorm=0.812, loss_scale=16, train_wall=261, gb_free=8.1, wall=84795
2022-03-07 12:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:26:24 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.984 | nll_loss 13.715 | ppl 13448.2 | wps 44401.4 | wpb 510.9 | bsz 1 | num_updates 28334 | best_loss 7.706
2022-03-07 12:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 28334 updates
2022-03-07 12:26:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 294 @ 28334 updates, score 13.984) (writing took 2.1631893417797983 seconds)
2022-03-07 12:26:26 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 12:26:26 | INFO | train | epoch 294 | loss 1.179 | nll_loss 0.59 | ppl 1.51 | wps 22563.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28334 | lr 0.000187865 | gnorm 0.807 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 84899
2022-03-07 12:26:26 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 12:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:29:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:29:36 | INFO | train_inner | epoch 295:     67 / 97 loss=1.177, nll_loss=0.588, ppl=1.5, wps=22360, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28400, lr=0.000187647, gnorm=0.802, loss_scale=16, train_wall=263, gb_free=8.1, wall=85088
2022-03-07 12:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:31:06 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.972 | nll_loss 13.701 | ppl 13315.5 | wps 44380.4 | wpb 510.9 | bsz 1 | num_updates 28430 | best_loss 7.706
2022-03-07 12:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 28430 updates
2022-03-07 12:31:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:31:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:31:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 295 @ 28430 updates, score 13.972) (writing took 2.309822225011885 seconds)
2022-03-07 12:31:08 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 12:31:08 | INFO | train | epoch 295 | loss 1.177 | nll_loss 0.588 | ppl 1.5 | wps 22320.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28430 | lr 0.000187548 | gnorm 0.808 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 85180
2022-03-07 12:31:08 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 12:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:34:26 | INFO | train_inner | epoch 296:     70 / 97 loss=1.177, nll_loss=0.589, ppl=1.5, wps=22565.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28500, lr=0.000187317, gnorm=0.806, loss_scale=16, train_wall=261, gb_free=8.1, wall=85378
2022-03-07 12:35:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:35:48 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 14.011 | nll_loss 13.74 | ppl 13686.8 | wps 44630.7 | wpb 510.9 | bsz 1 | num_updates 28526 | best_loss 7.706
2022-03-07 12:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 28526 updates
2022-03-07 12:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 296 @ 28526 updates, score 14.011) (writing took 2.320931968744844 seconds)
2022-03-07 12:35:50 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 12:35:50 | INFO | train | epoch 296 | loss 1.175 | nll_loss 0.587 | ppl 1.5 | wps 22315.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28526 | lr 0.000187232 | gnorm 0.801 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 85462
2022-03-07 12:35:50 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 12:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:39:19 | INFO | train_inner | epoch 297:     74 / 97 loss=1.175, nll_loss=0.586, ppl=1.5, wps=22351.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28600, lr=0.000186989, gnorm=0.798, loss_scale=16, train_wall=263, gb_free=8.1, wall=85671
2022-03-07 12:40:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:40:29 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 14.016 | nll_loss 13.748 | ppl 13760.7 | wps 44611.8 | wpb 510.9 | bsz 1 | num_updates 28623 | best_loss 7.706
2022-03-07 12:40:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 28623 updates
2022-03-07 12:40:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:40:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 297 @ 28623 updates, score 14.016) (writing took 2.224941296968609 seconds)
2022-03-07 12:40:32 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 12:40:32 | INFO | train | epoch 297 | loss 1.175 | nll_loss 0.586 | ppl 1.5 | wps 22557.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28623 | lr 0.000186914 | gnorm 0.803 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 85744
2022-03-07 12:40:32 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 12:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:42:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:44:12 | INFO | train_inner | epoch 298:     78 / 97 loss=1.175, nll_loss=0.586, ppl=1.5, wps=22358.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28700, lr=0.000186663, gnorm=0.806, loss_scale=16, train_wall=263, gb_free=8.1, wall=85964
2022-03-07 12:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:45:11 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.925 | nll_loss 13.655 | ppl 12901.4 | wps 44467.1 | wpb 510.9 | bsz 1 | num_updates 28719 | best_loss 7.706
2022-03-07 12:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 28719 updates
2022-03-07 12:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:45:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:45:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 298 @ 28719 updates, score 13.925) (writing took 2.2746581020765007 seconds)
2022-03-07 12:45:13 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 12:45:13 | INFO | train | epoch 298 | loss 1.173 | nll_loss 0.585 | ppl 1.5 | wps 22322 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28719 | lr 0.000186602 | gnorm 0.802 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 86025
2022-03-07 12:45:13 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 12:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:49:02 | INFO | train_inner | epoch 299:     81 / 97 loss=1.173, nll_loss=0.584, ppl=1.5, wps=22574.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28800, lr=0.000186339, gnorm=0.802, loss_scale=32, train_wall=261, gb_free=8.1, wall=86255
2022-03-07 12:49:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:49:53 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.961 | nll_loss 13.692 | ppl 13233.5 | wps 44493.2 | wpb 510.9 | bsz 1 | num_updates 28816 | best_loss 7.706
2022-03-07 12:49:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 28816 updates
2022-03-07 12:49:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:49:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 299 @ 28816 updates, score 13.961) (writing took 2.25069790892303 seconds)
2022-03-07 12:49:55 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 12:49:55 | INFO | train | epoch 299 | loss 1.172 | nll_loss 0.584 | ppl 1.5 | wps 22555.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28816 | lr 0.000186287 | gnorm 0.805 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 86307
2022-03-07 12:49:55 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 12:49:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:53:56 | INFO | train_inner | epoch 300:     85 / 97 loss=1.171, nll_loss=0.583, ppl=1.5, wps=22345.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28900, lr=0.000186016, gnorm=0.807, loss_scale=16, train_wall=263, gb_free=8.1, wall=86548
2022-03-07 12:54:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:34 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 14.063 | nll_loss 13.797 | ppl 14231.5 | wps 44689.3 | wpb 510.9 | bsz 1 | num_updates 28912 | best_loss 7.706
2022-03-07 12:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 28912 updates
2022-03-07 12:54:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:54:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 300 @ 28912 updates, score 14.063) (writing took 2.2605278003029525 seconds)
2022-03-07 12:54:37 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 12:54:37 | INFO | train | epoch 300 | loss 1.17 | nll_loss 0.582 | ppl 1.5 | wps 22316.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28912 | lr 0.000185978 | gnorm 0.806 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 86589
2022-03-07 12:54:37 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 12:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:57:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:58:49 | INFO | train_inner | epoch 301:     89 / 97 loss=1.17, nll_loss=0.582, ppl=1.5, wps=22351.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29000, lr=0.000185695, gnorm=0.81, loss_scale=16, train_wall=263, gb_free=8.1, wall=86841
2022-03-07 12:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:16 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.996 | nll_loss 13.728 | ppl 13567.8 | wps 44596.7 | wpb 510.9 | bsz 1 | num_updates 29008 | best_loss 7.706
2022-03-07 12:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 29008 updates
2022-03-07 12:59:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 12:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 301 @ 29008 updates, score 13.996) (writing took 2.2106960900127888 seconds)
2022-03-07 12:59:18 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 12:59:18 | INFO | train | epoch 301 | loss 1.17 | nll_loss 0.581 | ppl 1.5 | wps 22322.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29008 | lr 0.00018567 | gnorm 0.809 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 86870
2022-03-07 12:59:18 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 12:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:03:39 | INFO | train_inner | epoch 302:     92 / 97 loss=1.168, nll_loss=0.579, ppl=1.49, wps=22577.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29100, lr=0.000185376, gnorm=0.8, loss_scale=32, train_wall=261, gb_free=8.1, wall=87131
2022-03-07 13:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:03:58 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.978 | nll_loss 13.709 | ppl 13395.7 | wps 44558.4 | wpb 510.9 | bsz 1 | num_updates 29105 | best_loss 7.706
2022-03-07 13:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 29105 updates
2022-03-07 13:03:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:04:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 302 @ 29105 updates, score 13.978) (writing took 2.197219701949507 seconds)
2022-03-07 13:04:00 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 13:04:00 | INFO | train | epoch 302 | loss 1.167 | nll_loss 0.579 | ppl 1.49 | wps 22562.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29105 | lr 0.00018536 | gnorm 0.797 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 87152
2022-03-07 13:04:00 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 13:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:05:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:08:31 | INFO | train_inner | epoch 303:     96 / 97 loss=1.168, nll_loss=0.58, ppl=1.49, wps=22365.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29200, lr=0.000185058, gnorm=0.799, loss_scale=16, train_wall=263, gb_free=8.1, wall=87424
2022-03-07 13:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:39 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.941 | nll_loss 13.671 | ppl 13042.9 | wps 44510.1 | wpb 510.9 | bsz 1 | num_updates 29201 | best_loss 7.706
2022-03-07 13:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 29201 updates
2022-03-07 13:08:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:08:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 303 @ 29201 updates, score 13.941) (writing took 2.2130878241732717 seconds)
2022-03-07 13:08:41 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 13:08:41 | INFO | train | epoch 303 | loss 1.167 | nll_loss 0.578 | ppl 1.49 | wps 22331.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29201 | lr 0.000185055 | gnorm 0.799 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 87433
2022-03-07 13:08:41 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 13:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:13:21 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 14.023 | nll_loss 13.757 | ppl 13847.7 | wps 44781.4 | wpb 510.9 | bsz 1 | num_updates 29297 | best_loss 7.706
2022-03-07 13:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 29297 updates
2022-03-07 13:13:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:13:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:13:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 304 @ 29297 updates, score 14.023) (writing took 2.253826532047242 seconds)
2022-03-07 13:13:23 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 13:13:23 | INFO | train | epoch 304 | loss 1.166 | nll_loss 0.577 | ppl 1.49 | wps 22333.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29297 | lr 0.000184752 | gnorm 0.805 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 87715
2022-03-07 13:13:23 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 13:13:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:13:31 | INFO | train_inner | epoch 305:      3 / 97 loss=1.165, nll_loss=0.577, ppl=1.49, wps=21823.8, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=29300, lr=0.000184742, gnorm=0.804, loss_scale=16, train_wall=263, gb_free=8.1, wall=87723
2022-03-07 13:17:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:02 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.974 | nll_loss 13.706 | ppl 13362.3 | wps 44528.5 | wpb 510.9 | bsz 1 | num_updates 29394 | best_loss 7.706
2022-03-07 13:18:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 29394 updates
2022-03-07 13:18:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:18:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:18:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 305 @ 29394 updates, score 13.974) (writing took 2.2268595597706735 seconds)
2022-03-07 13:18:04 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 13:18:04 | INFO | train | epoch 305 | loss 1.163 | nll_loss 0.575 | ppl 1.49 | wps 22558.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29394 | lr 0.000184447 | gnorm 0.797 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 87996
2022-03-07 13:18:04 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 13:18:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:18:22 | INFO | train_inner | epoch 306:      6 / 97 loss=1.163, nll_loss=0.574, ppl=1.49, wps=22574.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29400, lr=0.000184428, gnorm=0.796, loss_scale=16, train_wall=261, gb_free=8.1, wall=88014
2022-03-07 13:19:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:22:44 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 14.021 | nll_loss 13.755 | ppl 13820.6 | wps 44426.8 | wpb 510.9 | bsz 1 | num_updates 29490 | best_loss 7.706
2022-03-07 13:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 29490 updates
2022-03-07 13:22:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:22:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 306 @ 29490 updates, score 14.021) (writing took 2.254587505944073 seconds)
2022-03-07 13:22:46 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 13:22:46 | INFO | train | epoch 306 | loss 1.162 | nll_loss 0.574 | ppl 1.49 | wps 22326.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29490 | lr 0.000184146 | gnorm 0.8 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 88278
2022-03-07 13:22:46 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 13:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:23:14 | INFO | train_inner | epoch 307:     10 / 97 loss=1.162, nll_loss=0.573, ppl=1.49, wps=22358.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29500, lr=0.000184115, gnorm=0.801, loss_scale=16, train_wall=263, gb_free=8.1, wall=88306
2022-03-07 13:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:27:26 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 14.028 | nll_loss 13.762 | ppl 13893.6 | wps 44592.6 | wpb 510.9 | bsz 1 | num_updates 29587 | best_loss 7.706
2022-03-07 13:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 29587 updates
2022-03-07 13:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 307 @ 29587 updates, score 14.028) (writing took 2.2102333130314946 seconds)
2022-03-07 13:27:28 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 13:27:28 | INFO | train | epoch 307 | loss 1.161 | nll_loss 0.573 | ppl 1.49 | wps 22551.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29587 | lr 0.000183844 | gnorm 0.786 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 88560
2022-03-07 13:27:28 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 13:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:28:05 | INFO | train_inner | epoch 308:     13 / 97 loss=1.16, nll_loss=0.572, ppl=1.49, wps=22567.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=29600, lr=0.000183804, gnorm=0.788, loss_scale=32, train_wall=261, gb_free=8.1, wall=88597
2022-03-07 13:28:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:32:07 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 14.055 | nll_loss 13.79 | ppl 14161.5 | wps 44476.3 | wpb 510.9 | bsz 1 | num_updates 29683 | best_loss 7.706
2022-03-07 13:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 29683 updates
2022-03-07 13:32:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 308 @ 29683 updates, score 14.055) (writing took 2.2408522102050483 seconds)
2022-03-07 13:32:09 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 13:32:09 | INFO | train | epoch 308 | loss 1.16 | nll_loss 0.571 | ppl 1.49 | wps 22332.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29683 | lr 0.000183546 | gnorm 0.8 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 88841
2022-03-07 13:32:09 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 13:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:32:57 | INFO | train_inner | epoch 309:     17 / 97 loss=1.158, nll_loss=0.57, ppl=1.48, wps=22370.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=29700, lr=0.000183494, gnorm=0.797, loss_scale=16, train_wall=263, gb_free=8.1, wall=88889
2022-03-07 13:36:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:36:49 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 14.035 | nll_loss 13.768 | ppl 13948.4 | wps 44572.8 | wpb 510.9 | bsz 1 | num_updates 29779 | best_loss 7.706
2022-03-07 13:36:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 29779 updates
2022-03-07 13:36:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:36:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:36:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 309 @ 29779 updates, score 14.035) (writing took 2.208516708575189 seconds)
2022-03-07 13:36:51 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 13:36:51 | INFO | train | epoch 309 | loss 1.158 | nll_loss 0.57 | ppl 1.48 | wps 22331.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29779 | lr 0.00018325 | gnorm 0.791 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 89123
2022-03-07 13:36:51 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 13:36:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:37:50 | INFO | train_inner | epoch 310:     21 / 97 loss=1.158, nll_loss=0.569, ppl=1.48, wps=22356.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29800, lr=0.000183186, gnorm=0.797, loss_scale=16, train_wall=263, gb_free=8.1, wall=89182
2022-03-07 13:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:30 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.962 | nll_loss 13.694 | ppl 13255.2 | wps 44637.4 | wpb 510.9 | bsz 1 | num_updates 29876 | best_loss 7.706
2022-03-07 13:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 29876 updates
2022-03-07 13:41:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 310 @ 29876 updates, score 13.962) (writing took 2.2617131709121168 seconds)
2022-03-07 13:41:32 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 13:41:32 | INFO | train | epoch 310 | loss 1.157 | nll_loss 0.569 | ppl 1.48 | wps 22556.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29876 | lr 0.000182953 | gnorm 0.794 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 89404
2022-03-07 13:41:32 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 13:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:42:40 | INFO | train_inner | epoch 311:     24 / 97 loss=1.156, nll_loss=0.568, ppl=1.48, wps=22578.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29900, lr=0.000182879, gnorm=0.79, loss_scale=16, train_wall=261, gb_free=8.1, wall=89472
2022-03-07 13:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:12 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.975 | nll_loss 13.708 | ppl 13379.1 | wps 44521.1 | wpb 510.9 | bsz 1 | num_updates 29973 | best_loss 7.706
2022-03-07 13:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 29973 updates
2022-03-07 13:46:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 311 @ 29973 updates, score 13.975) (writing took 2.2214985168538988 seconds)
2022-03-07 13:46:14 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 13:46:14 | INFO | train | epoch 311 | loss 1.156 | nll_loss 0.568 | ppl 1.48 | wps 22554.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29973 | lr 0.000182656 | gnorm 0.795 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 89686
2022-03-07 13:46:14 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 13:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:47:31 | INFO | train_inner | epoch 312:     27 / 97 loss=1.156, nll_loss=0.568, ppl=1.48, wps=22568.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30000, lr=0.000182574, gnorm=0.793, loss_scale=32, train_wall=261, gb_free=8.1, wall=89763
2022-03-07 13:48:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:49:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:50:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:53 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 14.027 | nll_loss 13.763 | ppl 13897.5 | wps 44597.6 | wpb 510.9 | bsz 1 | num_updates 30068 | best_loss 7.706
2022-03-07 13:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 30068 updates
2022-03-07 13:50:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:50:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 312 @ 30068 updates, score 14.027) (writing took 2.2382920989766717 seconds)
2022-03-07 13:50:56 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 13:50:56 | INFO | train | epoch 312 | loss 1.154 | nll_loss 0.566 | ppl 1.48 | wps 22091.4 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 30068 | lr 0.000182368 | gnorm 0.79 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 89968
2022-03-07 13:50:56 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 13:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:26 | INFO | train_inner | epoch 313:     32 / 97 loss=1.153, nll_loss=0.565, ppl=1.48, wps=22146.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30100, lr=0.000182271, gnorm=0.789, loss_scale=16, train_wall=266, gb_free=8.1, wall=90058
2022-03-07 13:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:55:35 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 14.034 | nll_loss 13.768 | ppl 13951.5 | wps 44446 | wpb 510.9 | bsz 1 | num_updates 30165 | best_loss 7.706
2022-03-07 13:55:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 30165 updates
2022-03-07 13:55:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 13:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 313 @ 30165 updates, score 14.034) (writing took 2.192378255072981 seconds)
2022-03-07 13:55:37 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 13:55:37 | INFO | train | epoch 313 | loss 1.154 | nll_loss 0.566 | ppl 1.48 | wps 22555.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30165 | lr 0.000182074 | gnorm 0.788 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 90249
2022-03-07 13:55:37 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 13:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:16 | INFO | train_inner | epoch 314:     35 / 97 loss=1.153, nll_loss=0.565, ppl=1.48, wps=22571.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=30200, lr=0.000181969, gnorm=0.789, loss_scale=32, train_wall=261, gb_free=8.1, wall=90349
2022-03-07 14:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:00:17 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 14.042 | nll_loss 13.776 | ppl 14029 | wps 44759.3 | wpb 510.9 | bsz 1 | num_updates 30262 | best_loss 7.706
2022-03-07 14:00:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 30262 updates
2022-03-07 14:00:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:00:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:00:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 314 @ 30262 updates, score 14.042) (writing took 2.2194090941920877 seconds)
2022-03-07 14:00:19 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 14:00:19 | INFO | train | epoch 314 | loss 1.152 | nll_loss 0.564 | ppl 1.48 | wps 22561 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30262 | lr 0.000181782 | gnorm 0.791 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 90531
2022-03-07 14:00:19 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 14:00:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:02:07 | INFO | train_inner | epoch 315:     38 / 97 loss=1.152, nll_loss=0.564, ppl=1.48, wps=22580.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30300, lr=0.000181668, gnorm=0.791, loss_scale=32, train_wall=261, gb_free=8.1, wall=90639
2022-03-07 14:02:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:02:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:04:58 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 14.019 | nll_loss 13.752 | ppl 13794.1 | wps 44554.4 | wpb 510.9 | bsz 1 | num_updates 30357 | best_loss 7.706
2022-03-07 14:04:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 30357 updates
2022-03-07 14:04:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:05:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:05:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 315 @ 30357 updates, score 14.019) (writing took 2.243679964914918 seconds)
2022-03-07 14:05:01 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 14:05:01 | INFO | train | epoch 315 | loss 1.152 | nll_loss 0.564 | ppl 1.48 | wps 22095.1 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 30357 | lr 0.000181497 | gnorm 0.799 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 90813
2022-03-07 14:05:01 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 14:05:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:07:02 | INFO | train_inner | epoch 316:     43 / 97 loss=1.151, nll_loss=0.563, ppl=1.48, wps=22142, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30400, lr=0.000181369, gnorm=0.794, loss_scale=16, train_wall=266, gb_free=8.1, wall=90934
2022-03-07 14:08:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:09:40 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 14.01 | nll_loss 13.744 | ppl 13716.8 | wps 44713.7 | wpb 510.9 | bsz 1 | num_updates 30453 | best_loss 7.706
2022-03-07 14:09:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 30453 updates
2022-03-07 14:09:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:09:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 316 @ 30453 updates, score 14.01) (writing took 2.2180800368078053 seconds)
2022-03-07 14:09:42 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 14:09:42 | INFO | train | epoch 316 | loss 1.15 | nll_loss 0.562 | ppl 1.48 | wps 22326.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30453 | lr 0.000181211 | gnorm 0.789 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 91094
2022-03-07 14:09:42 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 14:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:11:55 | INFO | train_inner | epoch 317:     47 / 97 loss=1.148, nll_loss=0.56, ppl=1.47, wps=22359.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=30500, lr=0.000181071, gnorm=0.789, loss_scale=16, train_wall=263, gb_free=8.1, wall=91227
2022-03-07 14:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:14:22 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 14.055 | nll_loss 13.79 | ppl 14164.5 | wps 44469.3 | wpb 510.9 | bsz 1 | num_updates 30550 | best_loss 7.706
2022-03-07 14:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 30550 updates
2022-03-07 14:14:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:14:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:14:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 317 @ 30550 updates, score 14.055) (writing took 2.2318919729441404 seconds)
2022-03-07 14:14:24 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 14:14:24 | INFO | train | epoch 317 | loss 1.148 | nll_loss 0.561 | ppl 1.47 | wps 22555 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30550 | lr 0.000180923 | gnorm 0.782 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 91376
2022-03-07 14:14:24 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 14:14:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:16:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:16:48 | INFO | train_inner | epoch 318:     51 / 97 loss=1.148, nll_loss=0.561, ppl=1.47, wps=22359.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.784, loss_scale=16, train_wall=263, gb_free=8.1, wall=91520
2022-03-07 14:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:19:03 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 14.011 | nll_loss 13.744 | ppl 13720.8 | wps 44594.4 | wpb 510.9 | bsz 1 | num_updates 30646 | best_loss 7.706
2022-03-07 14:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 30646 updates
2022-03-07 14:19:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:19:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:19:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 318 @ 30646 updates, score 14.011) (writing took 2.1732531203888357 seconds)
2022-03-07 14:19:05 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 14:19:05 | INFO | train | epoch 318 | loss 1.148 | nll_loss 0.56 | ppl 1.47 | wps 22335.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30646 | lr 0.00018064 | gnorm 0.795 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 91657
2022-03-07 14:19:05 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 14:19:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:21:38 | INFO | train_inner | epoch 319:     54 / 97 loss=1.147, nll_loss=0.559, ppl=1.47, wps=22584.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=30700, lr=0.000180481, gnorm=0.794, loss_scale=16, train_wall=261, gb_free=8.1, wall=91810
2022-03-07 14:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:23:45 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 14.041 | nll_loss 13.776 | ppl 14026.4 | wps 44583.9 | wpb 510.9 | bsz 1 | num_updates 30743 | best_loss 7.706
2022-03-07 14:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 30743 updates
2022-03-07 14:23:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 319 @ 30743 updates, score 14.041) (writing took 2.214843959081918 seconds)
2022-03-07 14:23:47 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 14:23:47 | INFO | train | epoch 319 | loss 1.146 | nll_loss 0.558 | ppl 1.47 | wps 22559.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30743 | lr 0.000180354 | gnorm 0.791 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 91939
2022-03-07 14:23:47 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 14:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:26:28 | INFO | train_inner | epoch 320:     57 / 97 loss=1.146, nll_loss=0.558, ppl=1.47, wps=22580.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30800, lr=0.000180187, gnorm=0.783, loss_scale=32, train_wall=261, gb_free=8.1, wall=92100
2022-03-07 14:27:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:28:26 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 14.036 | nll_loss 13.771 | ppl 13983 | wps 44711.5 | wpb 510.9 | bsz 1 | num_updates 30839 | best_loss 7.706
2022-03-07 14:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 30839 updates
2022-03-07 14:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 320 @ 30839 updates, score 14.036) (writing took 2.246964812744409 seconds)
2022-03-07 14:28:28 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 14:28:28 | INFO | train | epoch 320 | loss 1.145 | nll_loss 0.557 | ppl 1.47 | wps 22332.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30839 | lr 0.000180074 | gnorm 0.779 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 92220
2022-03-07 14:28:28 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 14:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:21 | INFO | train_inner | epoch 321:     61 / 97 loss=1.145, nll_loss=0.558, ppl=1.47, wps=22359, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30900, lr=0.000179896, gnorm=0.789, loss_scale=16, train_wall=263, gb_free=8.1, wall=92393
2022-03-07 14:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:33:08 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 14.045 | nll_loss 13.781 | ppl 14079.4 | wps 44524.2 | wpb 510.9 | bsz 1 | num_updates 30936 | best_loss 7.706
2022-03-07 14:33:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 30936 updates
2022-03-07 14:33:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:33:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 321 @ 30936 updates, score 14.045) (writing took 2.199763576965779 seconds)
2022-03-07 14:33:10 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 14:33:10 | INFO | train | epoch 321 | loss 1.145 | nll_loss 0.557 | ppl 1.47 | wps 22560.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30936 | lr 0.000179791 | gnorm 0.787 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 92502
2022-03-07 14:33:10 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 14:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:11 | INFO | train_inner | epoch 322:     64 / 97 loss=1.142, nll_loss=0.555, ppl=1.47, wps=22575.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=31000, lr=0.000179605, gnorm=0.773, loss_scale=32, train_wall=261, gb_free=8.1, wall=92683
2022-03-07 14:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:37:49 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 14.034 | nll_loss 13.767 | ppl 13944.8 | wps 44356.2 | wpb 510.9 | bsz 1 | num_updates 31033 | best_loss 7.706
2022-03-07 14:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 31033 updates
2022-03-07 14:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:37:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:37:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 322 @ 31033 updates, score 14.034) (writing took 2.2527243993245065 seconds)
2022-03-07 14:37:52 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 14:37:52 | INFO | train | epoch 322 | loss 1.142 | nll_loss 0.555 | ppl 1.47 | wps 22545.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31033 | lr 0.00017951 | gnorm 0.776 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 92784
2022-03-07 14:37:52 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 14:37:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:38:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:41:04 | INFO | train_inner | epoch 323:     68 / 97 loss=1.143, nll_loss=0.556, ppl=1.47, wps=22347.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=31100, lr=0.000179316, gnorm=0.787, loss_scale=16, train_wall=263, gb_free=8.1, wall=92976
2022-03-07 14:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:42:31 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 14.08 | nll_loss 13.816 | ppl 14425 | wps 44793.6 | wpb 510.9 | bsz 1 | num_updates 31129 | best_loss 7.706
2022-03-07 14:42:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 31129 updates
2022-03-07 14:42:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 323 @ 31129 updates, score 14.08) (writing took 2.285546474158764 seconds)
2022-03-07 14:42:33 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 14:42:33 | INFO | train | epoch 323 | loss 1.141 | nll_loss 0.554 | ppl 1.47 | wps 22324 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31129 | lr 0.000179233 | gnorm 0.788 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 93065
2022-03-07 14:42:33 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 14:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:45:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:45:57 | INFO | train_inner | epoch 324:     72 / 97 loss=1.141, nll_loss=0.553, ppl=1.47, wps=22361.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31200, lr=0.000179029, gnorm=0.788, loss_scale=16, train_wall=263, gb_free=8.1, wall=93269
2022-03-07 14:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:47:13 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.992 | nll_loss 13.727 | ppl 13556.2 | wps 44491.5 | wpb 510.9 | bsz 1 | num_updates 31225 | best_loss 7.706
2022-03-07 14:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 31225 updates
2022-03-07 14:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 324 @ 31225 updates, score 13.992) (writing took 2.3127610897645354 seconds)
2022-03-07 14:47:15 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 14:47:15 | INFO | train | epoch 324 | loss 1.14 | nll_loss 0.553 | ppl 1.47 | wps 22320.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31225 | lr 0.000178957 | gnorm 0.792 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 93347
2022-03-07 14:47:15 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 14:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:50:47 | INFO | train_inner | epoch 325:     75 / 97 loss=1.14, nll_loss=0.553, ppl=1.47, wps=22564.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31300, lr=0.000178743, gnorm=0.795, loss_scale=16, train_wall=261, gb_free=8.1, wall=93559
2022-03-07 14:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:51:54 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.987 | nll_loss 13.723 | ppl 13521.1 | wps 44682.8 | wpb 510.9 | bsz 1 | num_updates 31322 | best_loss 7.706
2022-03-07 14:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 31322 updates
2022-03-07 14:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:51:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:51:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 325 @ 31322 updates, score 13.987) (writing took 2.2918928512372077 seconds)
2022-03-07 14:51:57 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 14:51:57 | INFO | train | epoch 325 | loss 1.139 | nll_loss 0.552 | ppl 1.47 | wps 22553.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31322 | lr 0.00017868 | gnorm 0.789 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 93629
2022-03-07 14:51:57 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 14:51:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:55:40 | INFO | train_inner | epoch 326:     79 / 97 loss=1.138, nll_loss=0.551, ppl=1.47, wps=22345.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31400, lr=0.000178458, gnorm=0.785, loss_scale=16, train_wall=263, gb_free=8.1, wall=93853
2022-03-07 14:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:56:36 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 14.026 | nll_loss 13.76 | ppl 13876.1 | wps 44604.4 | wpb 510.9 | bsz 1 | num_updates 31418 | best_loss 7.706
2022-03-07 14:56:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 31418 updates
2022-03-07 14:56:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:56:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 14:56:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 326 @ 31418 updates, score 14.026) (writing took 2.2961928281001747 seconds)
2022-03-07 14:56:38 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 14:56:38 | INFO | train | epoch 326 | loss 1.138 | nll_loss 0.551 | ppl 1.47 | wps 22312.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31418 | lr 0.000178407 | gnorm 0.784 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 93911
2022-03-07 14:56:39 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 14:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:00:31 | INFO | train_inner | epoch 327:     82 / 97 loss=1.138, nll_loss=0.551, ppl=1.47, wps=22569.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31500, lr=0.000178174, gnorm=0.784, loss_scale=16, train_wall=261, gb_free=8.1, wall=94143
2022-03-07 15:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:01:18 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 14.024 | nll_loss 13.758 | ppl 13858.2 | wps 44527.5 | wpb 510.9 | bsz 1 | num_updates 31515 | best_loss 7.706
2022-03-07 15:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 31515 updates
2022-03-07 15:01:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:01:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:01:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 327 @ 31515 updates, score 14.024) (writing took 2.3100137198343873 seconds)
2022-03-07 15:01:20 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 15:01:20 | INFO | train | epoch 327 | loss 1.137 | nll_loss 0.549 | ppl 1.46 | wps 22552.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31515 | lr 0.000178132 | gnorm 0.784 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 94192
2022-03-07 15:01:20 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 15:01:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:04:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:05:24 | INFO | train_inner | epoch 328:     86 / 97 loss=1.136, nll_loss=0.549, ppl=1.46, wps=22348.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31600, lr=0.000177892, gnorm=0.791, loss_scale=16, train_wall=263, gb_free=8.1, wall=94436
2022-03-07 15:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:06:00 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 14.034 | nll_loss 13.771 | ppl 13976.2 | wps 44605.1 | wpb 510.9 | bsz 1 | num_updates 31611 | best_loss 7.706
2022-03-07 15:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 31611 updates
2022-03-07 15:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:06:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 328 @ 31611 updates, score 14.034) (writing took 2.273858340922743 seconds)
2022-03-07 15:06:02 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 15:06:02 | INFO | train | epoch 328 | loss 1.136 | nll_loss 0.549 | ppl 1.46 | wps 22318 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31611 | lr 0.000177861 | gnorm 0.795 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 94474
2022-03-07 15:06:02 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 15:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:10:14 | INFO | train_inner | epoch 329:     89 / 97 loss=1.136, nll_loss=0.549, ppl=1.46, wps=22562, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31700, lr=0.000177611, gnorm=0.786, loss_scale=16, train_wall=261, gb_free=8.1, wall=94726
2022-03-07 15:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:10:41 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 14.032 | nll_loss 13.767 | ppl 13944.3 | wps 44643.9 | wpb 510.9 | bsz 1 | num_updates 31708 | best_loss 7.706
2022-03-07 15:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 31708 updates
2022-03-07 15:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 329 @ 31708 updates, score 14.032) (writing took 2.3211974459700286 seconds)
2022-03-07 15:10:44 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 15:10:44 | INFO | train | epoch 329 | loss 1.135 | nll_loss 0.548 | ppl 1.46 | wps 22540.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31708 | lr 0.000177589 | gnorm 0.781 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 94756
2022-03-07 15:10:44 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 15:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:15:07 | INFO | train_inner | epoch 330:     93 / 97 loss=1.134, nll_loss=0.547, ppl=1.46, wps=22358.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31800, lr=0.000177332, gnorm=0.78, loss_scale=16, train_wall=263, gb_free=8.1, wall=95019
2022-03-07 15:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:15:23 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 14.037 | nll_loss 13.774 | ppl 14005.5 | wps 44504.2 | wpb 510.9 | bsz 1 | num_updates 31804 | best_loss 7.706
2022-03-07 15:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 31804 updates
2022-03-07 15:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 330 @ 31804 updates, score 14.037) (writing took 2.2186815538443625 seconds)
2022-03-07 15:15:25 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 15:15:25 | INFO | train | epoch 330 | loss 1.133 | nll_loss 0.546 | ppl 1.46 | wps 22333.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31804 | lr 0.000177321 | gnorm 0.781 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 95037
2022-03-07 15:15:25 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 15:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:19:57 | INFO | train_inner | epoch 331:     96 / 97 loss=1.134, nll_loss=0.547, ppl=1.46, wps=22579.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31900, lr=0.000177054, gnorm=0.783, loss_scale=32, train_wall=261, gb_free=8.1, wall=95309
2022-03-07 15:20:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:20:05 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 14.071 | nll_loss 13.809 | ppl 14353.6 | wps 44273.6 | wpb 510.9 | bsz 1 | num_updates 31901 | best_loss 7.706
2022-03-07 15:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 31901 updates
2022-03-07 15:20:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 331 @ 31901 updates, score 14.071) (writing took 2.2334307180717587 seconds)
2022-03-07 15:20:07 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 15:20:07 | INFO | train | epoch 331 | loss 1.133 | nll_loss 0.546 | ppl 1.46 | wps 22558.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31901 | lr 0.000177051 | gnorm 0.781 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 95319
2022-03-07 15:20:07 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 15:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:22:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:46 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 14.049 | nll_loss 13.788 | ppl 14149.3 | wps 44459.4 | wpb 510.9 | bsz 1 | num_updates 31997 | best_loss 7.706
2022-03-07 15:24:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 31997 updates
2022-03-07 15:24:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 332 @ 31997 updates, score 14.049) (writing took 2.252402016893029 seconds)
2022-03-07 15:24:48 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 15:24:48 | INFO | train | epoch 332 | loss 1.131 | nll_loss 0.544 | ppl 1.46 | wps 22324.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31997 | lr 0.000176785 | gnorm 0.785 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 95601
2022-03-07 15:24:48 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 15:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:57 | INFO | train_inner | epoch 333:      3 / 97 loss=1.13, nll_loss=0.543, ppl=1.46, wps=21812.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=32000, lr=0.000176777, gnorm=0.784, loss_scale=16, train_wall=263, gb_free=8.1, wall=95609
2022-03-07 15:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:29:28 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 14.066 | nll_loss 13.803 | ppl 14292.3 | wps 44676.6 | wpb 510.9 | bsz 1 | num_updates 32094 | best_loss 7.706
2022-03-07 15:29:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 32094 updates
2022-03-07 15:29:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:29:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:29:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 333 @ 32094 updates, score 14.066) (writing took 2.2140827332623303 seconds)
2022-03-07 15:29:30 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 15:29:30 | INFO | train | epoch 333 | loss 1.13 | nll_loss 0.543 | ppl 1.46 | wps 22566.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32094 | lr 0.000176518 | gnorm 0.779 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 95882
2022-03-07 15:29:30 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 15:29:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:29:47 | INFO | train_inner | epoch 334:      6 / 97 loss=1.129, nll_loss=0.542, ppl=1.46, wps=22581.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32100, lr=0.000176501, gnorm=0.778, loss_scale=32, train_wall=261, gb_free=8.1, wall=95899
2022-03-07 15:31:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:34:09 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 14.012 | nll_loss 13.747 | ppl 13753.2 | wps 44338.1 | wpb 510.9 | bsz 1 | num_updates 32190 | best_loss 7.706
2022-03-07 15:34:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 32190 updates
2022-03-07 15:34:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:34:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:34:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 334 @ 32190 updates, score 14.012) (writing took 2.270793274976313 seconds)
2022-03-07 15:34:12 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 15:34:12 | INFO | train | epoch 334 | loss 1.129 | nll_loss 0.542 | ppl 1.46 | wps 22322.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32190 | lr 0.000176254 | gnorm 0.776 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 96164
2022-03-07 15:34:12 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 15:34:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:34:40 | INFO | train_inner | epoch 335:     10 / 97 loss=1.129, nll_loss=0.542, ppl=1.46, wps=22359, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32200, lr=0.000176227, gnorm=0.776, loss_scale=16, train_wall=263, gb_free=8.1, wall=96192
2022-03-07 15:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:38:51 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 14.04 | nll_loss 13.774 | ppl 14010.7 | wps 44530.6 | wpb 510.9 | bsz 1 | num_updates 32287 | best_loss 7.706
2022-03-07 15:38:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 32287 updates
2022-03-07 15:38:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:38:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:38:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 335 @ 32287 updates, score 14.04) (writing took 2.289818800985813 seconds)
2022-03-07 15:38:53 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 15:38:53 | INFO | train | epoch 335 | loss 1.128 | nll_loss 0.541 | ppl 1.45 | wps 22557.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32287 | lr 0.000175989 | gnorm 0.776 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 96445
2022-03-07 15:38:53 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 15:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:39:30 | INFO | train_inner | epoch 336:     13 / 97 loss=1.127, nll_loss=0.54, ppl=1.45, wps=22574.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32300, lr=0.000175954, gnorm=0.776, loss_scale=32, train_wall=261, gb_free=8.1, wall=96482
2022-03-07 15:40:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:43:33 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 14.053 | nll_loss 13.789 | ppl 14155.3 | wps 44544 | wpb 510.9 | bsz 1 | num_updates 32383 | best_loss 7.706
2022-03-07 15:43:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 32383 updates
2022-03-07 15:43:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 336 @ 32383 updates, score 14.053) (writing took 2.2227077926509082 seconds)
2022-03-07 15:43:35 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 15:43:35 | INFO | train | epoch 336 | loss 1.127 | nll_loss 0.54 | ppl 1.45 | wps 22321.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32383 | lr 0.000175728 | gnorm 0.783 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 96727
2022-03-07 15:43:35 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 15:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:44:23 | INFO | train_inner | epoch 337:     17 / 97 loss=1.127, nll_loss=0.54, ppl=1.45, wps=22352.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32400, lr=0.000175682, gnorm=0.785, loss_scale=16, train_wall=263, gb_free=8.1, wall=96775
2022-03-07 15:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:48:14 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 14.018 | nll_loss 13.755 | ppl 13822.9 | wps 44578.2 | wpb 510.9 | bsz 1 | num_updates 32480 | best_loss 7.706
2022-03-07 15:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 32480 updates
2022-03-07 15:48:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:48:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:48:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 337 @ 32480 updates, score 14.018) (writing took 2.22548327408731 seconds)
2022-03-07 15:48:17 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 15:48:17 | INFO | train | epoch 337 | loss 1.126 | nll_loss 0.539 | ppl 1.45 | wps 22551.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32480 | lr 0.000175466 | gnorm 0.786 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 97009
2022-03-07 15:48:17 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 15:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:49:13 | INFO | train_inner | epoch 338:     20 / 97 loss=1.125, nll_loss=0.538, ppl=1.45, wps=22568.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32500, lr=0.000175412, gnorm=0.78, loss_scale=32, train_wall=261, gb_free=8.1, wall=97065
2022-03-07 15:50:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:52:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:52:56 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 14.061 | nll_loss 13.798 | ppl 14243.5 | wps 44466.8 | wpb 510.9 | bsz 1 | num_updates 32576 | best_loss 7.706
2022-03-07 15:52:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 32576 updates
2022-03-07 15:52:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 338 @ 32576 updates, score 14.061) (writing took 2.241801771800965 seconds)
2022-03-07 15:52:58 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 15:52:58 | INFO | train | epoch 338 | loss 1.124 | nll_loss 0.537 | ppl 1.45 | wps 22322.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32576 | lr 0.000175207 | gnorm 0.771 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 97290
2022-03-07 15:52:58 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 15:52:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:06 | INFO | train_inner | epoch 339:     24 / 97 loss=1.124, nll_loss=0.537, ppl=1.45, wps=22356.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32600, lr=0.000175142, gnorm=0.775, loss_scale=16, train_wall=263, gb_free=8.1, wall=97358
2022-03-07 15:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:57:38 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 14.036 | nll_loss 13.774 | ppl 14004.9 | wps 44627.4 | wpb 510.9 | bsz 1 | num_updates 32673 | best_loss 7.706
2022-03-07 15:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 32673 updates
2022-03-07 15:57:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 15:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 339 @ 32673 updates, score 14.036) (writing took 2.236781974323094 seconds)
2022-03-07 15:57:40 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 15:57:40 | INFO | train | epoch 339 | loss 1.123 | nll_loss 0.537 | ppl 1.45 | wps 22561 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32673 | lr 0.000174947 | gnorm 0.775 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 97572
2022-03-07 15:57:40 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 15:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:58:59 | INFO | train_inner | epoch 340:     28 / 97 loss=1.122, nll_loss=0.535, ppl=1.45, wps=22359.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=32700, lr=0.000174874, gnorm=0.773, loss_scale=16, train_wall=263, gb_free=8.1, wall=97651
2022-03-07 16:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:02:19 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 14.079 | nll_loss 13.817 | ppl 14437.1 | wps 44618.4 | wpb 510.9 | bsz 1 | num_updates 32769 | best_loss 7.706
2022-03-07 16:02:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 32769 updates
2022-03-07 16:02:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 340 @ 32769 updates, score 14.079) (writing took 2.2351275393739343 seconds)
2022-03-07 16:02:21 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 16:02:21 | INFO | train | epoch 340 | loss 1.123 | nll_loss 0.536 | ppl 1.45 | wps 22326.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32769 | lr 0.00017469 | gnorm 0.777 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 97853
2022-03-07 16:02:21 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 16:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:49 | INFO | train_inner | epoch 341:     31 / 97 loss=1.124, nll_loss=0.537, ppl=1.45, wps=22575.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32800, lr=0.000174608, gnorm=0.776, loss_scale=16, train_wall=261, gb_free=8.1, wall=97941
2022-03-07 16:05:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:07:01 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 14.093 | nll_loss 13.832 | ppl 14581.9 | wps 43974.8 | wpb 510.9 | bsz 1 | num_updates 32865 | best_loss 7.706
2022-03-07 16:07:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 32865 updates
2022-03-07 16:07:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:07:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:07:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 341 @ 32865 updates, score 14.093) (writing took 2.2561493832618 seconds)
2022-03-07 16:07:03 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 16:07:03 | INFO | train | epoch 341 | loss 1.122 | nll_loss 0.536 | ppl 1.45 | wps 22312.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32865 | lr 0.000174435 | gnorm 0.778 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 98135
2022-03-07 16:07:03 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 16:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:42 | INFO | train_inner | epoch 342:     35 / 97 loss=1.12, nll_loss=0.533, ppl=1.45, wps=22346.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32900, lr=0.000174342, gnorm=0.775, loss_scale=16, train_wall=263, gb_free=8.1, wall=98234
2022-03-07 16:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:11:43 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 14.036 | nll_loss 13.771 | ppl 13982.4 | wps 44369.2 | wpb 510.9 | bsz 1 | num_updates 32962 | best_loss 7.706
2022-03-07 16:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 32962 updates
2022-03-07 16:11:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:11:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 342 @ 32962 updates, score 14.036) (writing took 2.2195039368234575 seconds)
2022-03-07 16:11:45 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 16:11:45 | INFO | train | epoch 342 | loss 1.12 | nll_loss 0.533 | ppl 1.45 | wps 22556.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32962 | lr 0.000174178 | gnorm 0.771 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 98417
2022-03-07 16:11:45 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 16:11:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:13:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:13:35 | INFO | train_inner | epoch 343:     39 / 97 loss=1.12, nll_loss=0.533, ppl=1.45, wps=22358.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=33000, lr=0.000174078, gnorm=0.773, loss_scale=16, train_wall=263, gb_free=8.1, wall=98527
2022-03-07 16:16:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:16:24 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 14.08 | nll_loss 13.819 | ppl 14454.1 | wps 44744 | wpb 510.9 | bsz 1 | num_updates 33058 | best_loss 7.706
2022-03-07 16:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 33058 updates
2022-03-07 16:16:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:16:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:16:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 343 @ 33058 updates, score 14.08) (writing took 2.2017888762056828 seconds)
2022-03-07 16:16:26 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 16:16:26 | INFO | train | epoch 343 | loss 1.118 | nll_loss 0.532 | ppl 1.45 | wps 22334.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33058 | lr 0.000173925 | gnorm 0.772 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 98698
2022-03-07 16:16:26 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 16:16:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:18:25 | INFO | train_inner | epoch 344:     42 / 97 loss=1.118, nll_loss=0.532, ppl=1.45, wps=22581.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33100, lr=0.000173814, gnorm=0.767, loss_scale=16, train_wall=261, gb_free=8.1, wall=98817
2022-03-07 16:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:21:06 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 14.045 | nll_loss 13.784 | ppl 14106.3 | wps 44593.9 | wpb 510.9 | bsz 1 | num_updates 33155 | best_loss 7.706
2022-03-07 16:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 33155 updates
2022-03-07 16:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:21:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:21:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 344 @ 33155 updates, score 14.045) (writing took 2.240131687372923 seconds)
2022-03-07 16:21:08 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 16:21:08 | INFO | train | epoch 344 | loss 1.118 | nll_loss 0.532 | ppl 1.45 | wps 22558.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33155 | lr 0.00017367 | gnorm 0.762 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 98980
2022-03-07 16:21:08 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 16:21:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:23:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:23:18 | INFO | train_inner | epoch 345:     46 / 97 loss=1.118, nll_loss=0.532, ppl=1.45, wps=22365, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33200, lr=0.000173553, gnorm=0.771, loss_scale=16, train_wall=263, gb_free=8.1, wall=99110
2022-03-07 16:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:47 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 14.076 | nll_loss 13.817 | ppl 14434.4 | wps 44877.5 | wpb 510.9 | bsz 1 | num_updates 33251 | best_loss 7.706
2022-03-07 16:25:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 33251 updates
2022-03-07 16:25:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:25:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 345 @ 33251 updates, score 14.076) (writing took 2.269036591053009 seconds)
2022-03-07 16:25:49 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 16:25:49 | INFO | train | epoch 345 | loss 1.117 | nll_loss 0.531 | ppl 1.44 | wps 22335.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33251 | lr 0.000173419 | gnorm 0.778 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 99262
2022-03-07 16:25:49 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 16:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:28:08 | INFO | train_inner | epoch 346:     49 / 97 loss=1.117, nll_loss=0.53, ppl=1.44, wps=22579.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=33300, lr=0.000173292, gnorm=0.774, loss_scale=16, train_wall=261, gb_free=8.1, wall=99400
2022-03-07 16:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:30:29 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 14.055 | nll_loss 13.792 | ppl 14180.8 | wps 44704.7 | wpb 510.9 | bsz 1 | num_updates 33348 | best_loss 7.706
2022-03-07 16:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 33348 updates
2022-03-07 16:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:30:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:30:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 346 @ 33348 updates, score 14.055) (writing took 2.322305880021304 seconds)
2022-03-07 16:30:31 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 16:30:31 | INFO | train | epoch 346 | loss 1.117 | nll_loss 0.531 | ppl 1.45 | wps 22560.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33348 | lr 0.000173167 | gnorm 0.773 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 99543
2022-03-07 16:30:31 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 16:30:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:32:58 | INFO | train_inner | epoch 347:     52 / 97 loss=1.116, nll_loss=0.53, ppl=1.44, wps=22571.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33400, lr=0.000173032, gnorm=0.772, loss_scale=32, train_wall=261, gb_free=8.1, wall=99690
2022-03-07 16:33:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:35:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:35:10 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 14.117 | nll_loss 13.856 | ppl 14828.8 | wps 44440.3 | wpb 510.9 | bsz 1 | num_updates 33444 | best_loss 7.706
2022-03-07 16:35:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 33444 updates
2022-03-07 16:35:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:35:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:35:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 347 @ 33444 updates, score 14.117) (writing took 2.2173266070894897 seconds)
2022-03-07 16:35:13 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 16:35:13 | INFO | train | epoch 347 | loss 1.116 | nll_loss 0.529 | ppl 1.44 | wps 22322.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33444 | lr 0.000172918 | gnorm 0.771 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 99825
2022-03-07 16:35:13 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 16:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:51 | INFO | train_inner | epoch 348:     56 / 97 loss=1.115, nll_loss=0.529, ppl=1.44, wps=22363.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=33500, lr=0.000172774, gnorm=0.776, loss_scale=16, train_wall=263, gb_free=8.1, wall=99983
2022-03-07 16:39:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:52 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 14.094 | nll_loss 13.832 | ppl 14587.4 | wps 44395.6 | wpb 510.9 | bsz 1 | num_updates 33541 | best_loss 7.706
2022-03-07 16:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 33541 updates
2022-03-07 16:39:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 348 @ 33541 updates, score 14.094) (writing took 2.2528307819738984 seconds)
2022-03-07 16:39:54 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 16:39:54 | INFO | train | epoch 348 | loss 1.115 | nll_loss 0.529 | ppl 1.44 | wps 22560.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33541 | lr 0.000172668 | gnorm 0.779 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 100106
2022-03-07 16:39:54 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 16:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:42:41 | INFO | train_inner | epoch 349:     59 / 97 loss=1.114, nll_loss=0.528, ppl=1.44, wps=22575.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33600, lr=0.000172516, gnorm=0.767, loss_scale=32, train_wall=261, gb_free=8.1, wall=100273
2022-03-07 16:43:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:44:34 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 14.058 | nll_loss 13.798 | ppl 14246.9 | wps 44502.5 | wpb 510.9 | bsz 1 | num_updates 33637 | best_loss 7.706
2022-03-07 16:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 33637 updates
2022-03-07 16:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:44:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:44:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 349 @ 33637 updates, score 14.058) (writing took 2.212046854197979 seconds)
2022-03-07 16:44:36 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 16:44:36 | INFO | train | epoch 349 | loss 1.113 | nll_loss 0.526 | ppl 1.44 | wps 22333 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33637 | lr 0.000172421 | gnorm 0.764 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 100388
2022-03-07 16:44:36 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 16:44:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:34 | INFO | train_inner | epoch 350:     63 / 97 loss=1.112, nll_loss=0.526, ppl=1.44, wps=22362.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33700, lr=0.00017226, gnorm=0.775, loss_scale=16, train_wall=263, gb_free=8.1, wall=100566
2022-03-07 16:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:15 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 14.069 | nll_loss 13.808 | ppl 14342 | wps 44593.5 | wpb 510.9 | bsz 1 | num_updates 33734 | best_loss 7.706
2022-03-07 16:49:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 33734 updates
2022-03-07 16:49:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:49:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 350 @ 33734 updates, score 14.069) (writing took 2.2403324763290584 seconds)
2022-03-07 16:49:17 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 16:49:17 | INFO | train | epoch 350 | loss 1.112 | nll_loss 0.526 | ppl 1.44 | wps 22559.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33734 | lr 0.000172173 | gnorm 0.777 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 100669
2022-03-07 16:49:17 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 16:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:51:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:52:27 | INFO | train_inner | epoch 351:     67 / 97 loss=1.113, nll_loss=0.527, ppl=1.44, wps=22360.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=33800, lr=0.000172005, gnorm=0.774, loss_scale=16, train_wall=263, gb_free=8.1, wall=100859
2022-03-07 16:53:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:53:57 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 14.101 | nll_loss 13.841 | ppl 14676.4 | wps 44549.1 | wpb 510.9 | bsz 1 | num_updates 33830 | best_loss 7.706
2022-03-07 16:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 33830 updates
2022-03-07 16:53:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:53:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:53:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 351 @ 33830 updates, score 14.101) (writing took 2.2277114931493998 seconds)
2022-03-07 16:53:59 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 16:53:59 | INFO | train | epoch 351 | loss 1.111 | nll_loss 0.525 | ppl 1.44 | wps 22324.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33830 | lr 0.000171929 | gnorm 0.767 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 100951
2022-03-07 16:53:59 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 16:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:57:17 | INFO | train_inner | epoch 352:     70 / 97 loss=1.11, nll_loss=0.524, ppl=1.44, wps=22572.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33900, lr=0.000171751, gnorm=0.759, loss_scale=16, train_wall=261, gb_free=8.1, wall=101149
2022-03-07 16:58:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:38 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 14.089 | nll_loss 13.829 | ppl 14557.6 | wps 44572.6 | wpb 510.9 | bsz 1 | num_updates 33927 | best_loss 7.706
2022-03-07 16:58:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 33927 updates
2022-03-07 16:58:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:58:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 16:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 352 @ 33927 updates, score 14.089) (writing took 2.1675975117832422 seconds)
2022-03-07 16:58:41 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 16:58:41 | INFO | train | epoch 352 | loss 1.11 | nll_loss 0.524 | ppl 1.44 | wps 22563.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33927 | lr 0.000171683 | gnorm 0.762 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 101233
2022-03-07 16:58:41 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 16:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:01:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:02:10 | INFO | train_inner | epoch 353:     74 / 97 loss=1.109, nll_loss=0.523, ppl=1.44, wps=22361.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34000, lr=0.000171499, gnorm=0.766, loss_scale=16, train_wall=263, gb_free=8.1, wall=101442
2022-03-07 17:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:03:20 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 14.108 | nll_loss 13.848 | ppl 14750.4 | wps 44319.9 | wpb 510.9 | bsz 1 | num_updates 34023 | best_loss 7.706
2022-03-07 17:03:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 34023 updates
2022-03-07 17:03:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:03:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:03:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 353 @ 34023 updates, score 14.108) (writing took 2.219203757122159 seconds)
2022-03-07 17:03:22 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 17:03:22 | INFO | train | epoch 353 | loss 1.108 | nll_loss 0.522 | ppl 1.44 | wps 22325 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34023 | lr 0.000171441 | gnorm 0.764 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 101514
2022-03-07 17:03:22 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 17:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:07:00 | INFO | train_inner | epoch 354:     77 / 97 loss=1.11, nll_loss=0.524, ppl=1.44, wps=22572.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34100, lr=0.000171247, gnorm=0.762, loss_scale=16, train_wall=261, gb_free=8.1, wall=101732
2022-03-07 17:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:08:02 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 14.087 | nll_loss 13.827 | ppl 14528.6 | wps 44248.8 | wpb 510.9 | bsz 1 | num_updates 34120 | best_loss 7.706
2022-03-07 17:08:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 34120 updates
2022-03-07 17:08:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:08:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:08:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 354 @ 34120 updates, score 14.087) (writing took 2.125452206004411 seconds)
2022-03-07 17:08:04 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 17:08:04 | INFO | train | epoch 354 | loss 1.109 | nll_loss 0.523 | ppl 1.44 | wps 22561 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34120 | lr 0.000171197 | gnorm 0.763 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 101796
2022-03-07 17:08:04 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 17:08:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:11:53 | INFO | train_inner | epoch 355:     81 / 97 loss=1.107, nll_loss=0.521, ppl=1.43, wps=22361.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34200, lr=0.000170996, gnorm=0.76, loss_scale=16, train_wall=263, gb_free=8.1, wall=102025
2022-03-07 17:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:12:43 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 14.113 | nll_loss 13.853 | ppl 14798.1 | wps 44399.6 | wpb 510.9 | bsz 1 | num_updates 34216 | best_loss 7.706
2022-03-07 17:12:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 34216 updates
2022-03-07 17:12:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 355 @ 34216 updates, score 14.113) (writing took 2.387214371934533 seconds)
2022-03-07 17:12:46 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 17:12:46 | INFO | train | epoch 355 | loss 1.106 | nll_loss 0.52 | ppl 1.43 | wps 22309.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34216 | lr 0.000170956 | gnorm 0.761 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102078
2022-03-07 17:12:46 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 17:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:15:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:16:46 | INFO | train_inner | epoch 356:     85 / 97 loss=1.107, nll_loss=0.521, ppl=1.43, wps=22329, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34300, lr=0.000170747, gnorm=0.772, loss_scale=16, train_wall=264, gb_free=8.1, wall=102318
2022-03-07 17:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:17:25 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 14.08 | nll_loss 13.82 | ppl 14459 | wps 44265.2 | wpb 510.9 | bsz 1 | num_updates 34312 | best_loss 7.706
2022-03-07 17:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 34312 updates
2022-03-07 17:17:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 356 @ 34312 updates, score 14.08) (writing took 2.345082206185907 seconds)
2022-03-07 17:17:28 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 17:17:28 | INFO | train | epoch 356 | loss 1.107 | nll_loss 0.521 | ppl 1.43 | wps 22278 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34312 | lr 0.000170717 | gnorm 0.771 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102360
2022-03-07 17:17:28 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 17:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:21:37 | INFO | train_inner | epoch 357:     88 / 97 loss=1.107, nll_loss=0.521, ppl=1.44, wps=22525.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34400, lr=0.000170499, gnorm=0.762, loss_scale=16, train_wall=261, gb_free=8.1, wall=102609
2022-03-07 17:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:22:07 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 14.052 | nll_loss 13.791 | ppl 14173.4 | wps 44413.1 | wpb 510.9 | bsz 1 | num_updates 34409 | best_loss 7.706
2022-03-07 17:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 34409 updates
2022-03-07 17:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 357 @ 34409 updates, score 14.052) (writing took 2.248021185863763 seconds)
2022-03-07 17:22:10 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 17:22:10 | INFO | train | epoch 357 | loss 1.105 | nll_loss 0.519 | ppl 1.43 | wps 22535.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34409 | lr 0.000170476 | gnorm 0.759 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102642
2022-03-07 17:22:10 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 17:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:22:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:26:30 | INFO | train_inner | epoch 358:     92 / 97 loss=1.105, nll_loss=0.519, ppl=1.43, wps=22348.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=34500, lr=0.000170251, gnorm=0.765, loss_scale=16, train_wall=263, gb_free=8.1, wall=102902
2022-03-07 17:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:26:49 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 14.07 | nll_loss 13.811 | ppl 14373 | wps 44363.8 | wpb 510.9 | bsz 1 | num_updates 34505 | best_loss 7.706
2022-03-07 17:26:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 34505 updates
2022-03-07 17:26:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:26:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:26:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 358 @ 34505 updates, score 14.07) (writing took 2.2012385758571327 seconds)
2022-03-07 17:26:51 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 17:26:51 | INFO | train | epoch 358 | loss 1.105 | nll_loss 0.519 | ppl 1.43 | wps 22319.1 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 34505 | lr 0.000170239 | gnorm 0.766 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102923
2022-03-07 17:26:51 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 17:26:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:31:23 | INFO | train_inner | epoch 359:     96 / 97 loss=1.104, nll_loss=0.519, ppl=1.43, wps=22360.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34600, lr=0.000170005, gnorm=0.764, loss_scale=16, train_wall=263, gb_free=8.1, wall=103195
2022-03-07 17:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:31 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 14.116 | nll_loss 13.857 | ppl 14837.2 | wps 44542.2 | wpb 510.9 | bsz 1 | num_updates 34601 | best_loss 7.706
2022-03-07 17:31:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 34601 updates
2022-03-07 17:31:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:31:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:31:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 359 @ 34601 updates, score 14.116) (writing took 2.2245767461135983 seconds)
2022-03-07 17:31:33 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 17:31:33 | INFO | train | epoch 359 | loss 1.103 | nll_loss 0.518 | ppl 1.43 | wps 22328.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34601 | lr 0.000170003 | gnorm 0.763 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 103205
2022-03-07 17:31:33 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 17:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:36:12 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 14.076 | nll_loss 13.818 | ppl 14441.5 | wps 44540.9 | wpb 510.9 | bsz 1 | num_updates 34698 | best_loss 7.706
2022-03-07 17:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 34698 updates
2022-03-07 17:36:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:36:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:36:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 360 @ 34698 updates, score 14.076) (writing took 2.1956017720513046 seconds)
2022-03-07 17:36:15 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 17:36:15 | INFO | train | epoch 360 | loss 1.103 | nll_loss 0.517 | ppl 1.43 | wps 22560.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34698 | lr 0.000169765 | gnorm 0.77 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 103487
2022-03-07 17:36:15 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 17:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:36:20 | INFO | train_inner | epoch 361:      2 / 97 loss=1.103, nll_loss=0.517, ppl=1.43, wps=22027.1, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=34700, lr=0.00016976, gnorm=0.769, loss_scale=16, train_wall=261, gb_free=8.1, wall=103492
2022-03-07 17:37:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:40:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:40:54 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 14.117 | nll_loss 13.857 | ppl 14841.4 | wps 44750 | wpb 510.9 | bsz 1 | num_updates 34794 | best_loss 7.706
2022-03-07 17:40:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 34794 updates
2022-03-07 17:40:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:40:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:40:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 361 @ 34794 updates, score 14.117) (writing took 2.2028176430612803 seconds)
2022-03-07 17:40:56 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 17:40:56 | INFO | train | epoch 361 | loss 1.101 | nll_loss 0.515 | ppl 1.43 | wps 22325.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34794 | lr 0.00016953 | gnorm 0.76 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 103768
2022-03-07 17:40:56 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 17:40:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:41:13 | INFO | train_inner | epoch 362:      6 / 97 loss=1.1, nll_loss=0.514, ppl=1.43, wps=22357.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34800, lr=0.000169516, gnorm=0.76, loss_scale=16, train_wall=263, gb_free=8.1, wall=103785
2022-03-07 17:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:36 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 14.124 | nll_loss 13.866 | ppl 14935.9 | wps 44642.6 | wpb 510.9 | bsz 1 | num_updates 34891 | best_loss 7.706
2022-03-07 17:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 34891 updates
2022-03-07 17:45:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 362 @ 34891 updates, score 14.124) (writing took 2.19264211691916 seconds)
2022-03-07 17:45:38 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 17:45:38 | INFO | train | epoch 362 | loss 1.1 | nll_loss 0.514 | ppl 1.43 | wps 22559 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34891 | lr 0.000169295 | gnorm 0.76 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 104050
2022-03-07 17:45:38 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 17:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:46:03 | INFO | train_inner | epoch 363:      9 / 97 loss=1.099, nll_loss=0.514, ppl=1.43, wps=22573.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34900, lr=0.000169273, gnorm=0.761, loss_scale=32, train_wall=261, gb_free=8.1, wall=104075
2022-03-07 17:46:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:50:17 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 14.125 | nll_loss 13.867 | ppl 14943.3 | wps 44523.1 | wpb 510.9 | bsz 1 | num_updates 34987 | best_loss 7.706
2022-03-07 17:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 34987 updates
2022-03-07 17:50:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 363 @ 34987 updates, score 14.125) (writing took 2.1899043950252235 seconds)
2022-03-07 17:50:19 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 17:50:19 | INFO | train | epoch 363 | loss 1.1 | nll_loss 0.514 | ppl 1.43 | wps 22331.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34987 | lr 0.000169062 | gnorm 0.759 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 104331
2022-03-07 17:50:19 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 17:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:50:56 | INFO | train_inner | epoch 364:     13 / 97 loss=1.099, nll_loss=0.514, ppl=1.43, wps=22365.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35000, lr=0.000169031, gnorm=0.759, loss_scale=16, train_wall=263, gb_free=8.1, wall=104368
2022-03-07 17:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:54:59 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 14.082 | nll_loss 13.821 | ppl 14471 | wps 44634.4 | wpb 510.9 | bsz 1 | num_updates 35084 | best_loss 7.706
2022-03-07 17:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 35084 updates
2022-03-07 17:54:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:55:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:55:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 364 @ 35084 updates, score 14.082) (writing took 2.220853777602315 seconds)
2022-03-07 17:55:01 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 17:55:01 | INFO | train | epoch 364 | loss 1.099 | nll_loss 0.513 | ppl 1.43 | wps 22553.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35084 | lr 0.000168828 | gnorm 0.759 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 104613
2022-03-07 17:55:01 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 17:55:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:55:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:55:49 | INFO | train_inner | epoch 365:     17 / 97 loss=1.098, nll_loss=0.513, ppl=1.43, wps=22353.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35100, lr=0.00016879, gnorm=0.761, loss_scale=16, train_wall=263, gb_free=8.1, wall=104661
2022-03-07 17:59:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:41 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 14.142 | nll_loss 13.885 | ppl 15127.3 | wps 44678.7 | wpb 510.9 | bsz 1 | num_updates 35180 | best_loss 7.706
2022-03-07 17:59:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 35180 updates
2022-03-07 17:59:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:59:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 17:59:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 365 @ 35180 updates, score 14.142) (writing took 2.2073419322259724 seconds)
2022-03-07 17:59:43 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 17:59:43 | INFO | train | epoch 365 | loss 1.098 | nll_loss 0.512 | ppl 1.43 | wps 22263.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35180 | lr 0.000168598 | gnorm 0.762 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 104895
2022-03-07 17:59:43 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 17:59:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:00:40 | INFO | train_inner | epoch 366:     20 / 97 loss=1.097, nll_loss=0.511, ppl=1.43, wps=22513, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35200, lr=0.00016855, gnorm=0.759, loss_scale=16, train_wall=262, gb_free=8.1, wall=104952
2022-03-07 18:01:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:23 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 14.032 | nll_loss 13.772 | ppl 13986.1 | wps 44563.2 | wpb 510.9 | bsz 1 | num_updates 35276 | best_loss 7.706
2022-03-07 18:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 35276 updates
2022-03-07 18:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 366 @ 35276 updates, score 14.032) (writing took 2.235599397215992 seconds)
2022-03-07 18:04:25 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 18:04:25 | INFO | train | epoch 366 | loss 1.098 | nll_loss 0.512 | ppl 1.43 | wps 22314.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35276 | lr 0.000168368 | gnorm 0.76 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 105177
2022-03-07 18:04:25 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 18:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:05:33 | INFO | train_inner | epoch 367:     24 / 97 loss=1.097, nll_loss=0.511, ppl=1.43, wps=22343.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35300, lr=0.000168311, gnorm=0.76, loss_scale=16, train_wall=264, gb_free=8.1, wall=105245
2022-03-07 18:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:09:05 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 14.081 | nll_loss 13.821 | ppl 14469.1 | wps 44607.5 | wpb 510.9 | bsz 1 | num_updates 35373 | best_loss 7.706
2022-03-07 18:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 35373 updates
2022-03-07 18:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 367 @ 35373 updates, score 14.081) (writing took 2.198271226603538 seconds)
2022-03-07 18:09:07 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 18:09:07 | INFO | train | epoch 367 | loss 1.096 | nll_loss 0.511 | ppl 1.42 | wps 22540.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35373 | lr 0.000168137 | gnorm 0.755 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 105459
2022-03-07 18:09:07 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 18:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:24 | INFO | train_inner | epoch 368:     27 / 97 loss=1.096, nll_loss=0.511, ppl=1.42, wps=22558.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35400, lr=0.000168073, gnorm=0.753, loss_scale=32, train_wall=261, gb_free=8.1, wall=105536
2022-03-07 18:13:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:13:47 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 14.095 | nll_loss 13.838 | ppl 14643.7 | wps 44501.2 | wpb 510.9 | bsz 1 | num_updates 35469 | best_loss 7.706
2022-03-07 18:13:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 35469 updates
2022-03-07 18:13:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:13:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:13:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 368 @ 35469 updates, score 14.095) (writing took 2.171975065022707 seconds)
2022-03-07 18:13:49 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 18:13:49 | INFO | train | epoch 368 | loss 1.095 | nll_loss 0.509 | ppl 1.42 | wps 22316.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35469 | lr 0.00016791 | gnorm 0.758 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 105741
2022-03-07 18:13:49 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 18:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:15:17 | INFO | train_inner | epoch 369:     31 / 97 loss=1.094, nll_loss=0.509, ppl=1.42, wps=22351.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35500, lr=0.000167836, gnorm=0.757, loss_scale=16, train_wall=263, gb_free=8.1, wall=105829
2022-03-07 18:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:18:29 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 14.104 | nll_loss 13.846 | ppl 14724.4 | wps 42303.9 | wpb 510.9 | bsz 1 | num_updates 35566 | best_loss 7.706
2022-03-07 18:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 35566 updates
2022-03-07 18:18:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:18:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 369 @ 35566 updates, score 14.104) (writing took 2.307248879224062 seconds)
2022-03-07 18:18:31 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 18:18:31 | INFO | train | epoch 369 | loss 1.094 | nll_loss 0.508 | ppl 1.42 | wps 22516.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35566 | lr 0.00016768 | gnorm 0.758 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 106023
2022-03-07 18:18:31 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 18:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:20:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:20:11 | INFO | train_inner | epoch 370:     35 / 97 loss=1.094, nll_loss=0.509, ppl=1.42, wps=22240.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35600, lr=0.0001676, gnorm=0.76, loss_scale=16, train_wall=264, gb_free=8.1, wall=106123
2022-03-07 18:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:12 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 14.11 | nll_loss 13.852 | ppl 14789.2 | wps 44726.1 | wpb 510.9 | bsz 1 | num_updates 35662 | best_loss 7.706
2022-03-07 18:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 35662 updates
2022-03-07 18:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 370 @ 35662 updates, score 14.11) (writing took 2.2211301787756383 seconds)
2022-03-07 18:23:14 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 18:23:14 | INFO | train | epoch 370 | loss 1.093 | nll_loss 0.508 | ppl 1.42 | wps 22206.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35662 | lr 0.000167455 | gnorm 0.753 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 106306
2022-03-07 18:23:14 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 18:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:02 | INFO | train_inner | epoch 371:     38 / 97 loss=1.093, nll_loss=0.508, ppl=1.42, wps=22538.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35700, lr=0.000167365, gnorm=0.754, loss_scale=16, train_wall=261, gb_free=8.1, wall=106414
2022-03-07 18:26:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:27:53 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 14.072 | nll_loss 13.816 | ppl 14423.5 | wps 44497.8 | wpb 510.9 | bsz 1 | num_updates 35758 | best_loss 7.706
2022-03-07 18:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 35758 updates
2022-03-07 18:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:27:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 371 @ 35758 updates, score 14.072) (writing took 2.240896177943796 seconds)
2022-03-07 18:27:56 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 18:27:56 | INFO | train | epoch 371 | loss 1.094 | nll_loss 0.508 | ppl 1.42 | wps 22311.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35758 | lr 0.00016723 | gnorm 0.764 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 106588
2022-03-07 18:27:56 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 18:27:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:29:55 | INFO | train_inner | epoch 372:     42 / 97 loss=1.092, nll_loss=0.506, ppl=1.42, wps=22340.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=35800, lr=0.000167132, gnorm=0.764, loss_scale=16, train_wall=264, gb_free=8.1, wall=106707
2022-03-07 18:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:32:35 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 14.031 | nll_loss 13.771 | ppl 13975.2 | wps 44228.8 | wpb 510.9 | bsz 1 | num_updates 35855 | best_loss 7.706
2022-03-07 18:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 35855 updates
2022-03-07 18:32:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 372 @ 35855 updates, score 14.031) (writing took 2.214459836948663 seconds)
2022-03-07 18:32:38 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 18:32:38 | INFO | train | epoch 372 | loss 1.092 | nll_loss 0.506 | ppl 1.42 | wps 22545.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35855 | lr 0.000167003 | gnorm 0.761 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 106870
2022-03-07 18:32:38 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 18:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:34:45 | INFO | train_inner | epoch 373:     45 / 97 loss=1.092, nll_loss=0.507, ppl=1.42, wps=22563.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35900, lr=0.000166899, gnorm=0.755, loss_scale=32, train_wall=261, gb_free=8.1, wall=106997
2022-03-07 18:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:37:18 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 14.044 | nll_loss 13.784 | ppl 14101.8 | wps 40801.8 | wpb 510.9 | bsz 1 | num_updates 35952 | best_loss 7.706
2022-03-07 18:37:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 35952 updates
2022-03-07 18:37:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 373 @ 35952 updates, score 14.044) (writing took 2.1679729158058763 seconds)
2022-03-07 18:37:20 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 18:37:20 | INFO | train | epoch 373 | loss 1.091 | nll_loss 0.506 | ppl 1.42 | wps 22461.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35952 | lr 0.000166778 | gnorm 0.754 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 107152
2022-03-07 18:37:20 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 18:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:39:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:39:40 | INFO | train_inner | epoch 374:     49 / 97 loss=1.091, nll_loss=0.506, ppl=1.42, wps=22228.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=36000, lr=0.000166667, gnorm=0.758, loss_scale=32, train_wall=264, gb_free=8.1, wall=107292
2022-03-07 18:39:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:42:01 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 14.065 | nll_loss 13.805 | ppl 14314.2 | wps 44261 | wpb 510.9 | bsz 1 | num_updates 36047 | best_loss 7.706
2022-03-07 18:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 36047 updates
2022-03-07 18:42:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:42:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 374 @ 36047 updates, score 14.065) (writing took 2.2397857108153403 seconds)
2022-03-07 18:42:03 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 18:42:03 | INFO | train | epoch 374 | loss 1.09 | nll_loss 0.505 | ppl 1.42 | wps 22005 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 36047 | lr 0.000166558 | gnorm 0.759 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 107435
2022-03-07 18:42:03 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 18:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:44:33 | INFO | train_inner | epoch 375:     53 / 97 loss=1.09, nll_loss=0.504, ppl=1.42, wps=22314.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36100, lr=0.000166436, gnorm=0.76, loss_scale=16, train_wall=264, gb_free=8.1, wall=107585
2022-03-07 18:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:46:43 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 14.097 | nll_loss 13.839 | ppl 14655.2 | wps 44479.7 | wpb 510.9 | bsz 1 | num_updates 36144 | best_loss 7.706
2022-03-07 18:46:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 36144 updates
2022-03-07 18:46:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:46:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 375 @ 36144 updates, score 14.097) (writing took 2.4872089750133455 seconds)
2022-03-07 18:46:45 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 18:46:45 | INFO | train | epoch 375 | loss 1.09 | nll_loss 0.505 | ppl 1.42 | wps 22527.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36144 | lr 0.000166334 | gnorm 0.758 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 107717
2022-03-07 18:46:45 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 18:46:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:24 | INFO | train_inner | epoch 376:     56 / 97 loss=1.09, nll_loss=0.505, ppl=1.42, wps=22536.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36200, lr=0.000166206, gnorm=0.754, loss_scale=32, train_wall=261, gb_free=8.1, wall=107876
2022-03-07 18:49:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:51:25 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 14.07 | nll_loss 13.809 | ppl 14355.1 | wps 44416.1 | wpb 510.9 | bsz 1 | num_updates 36240 | best_loss 7.706
2022-03-07 18:51:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 36240 updates
2022-03-07 18:51:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 376 @ 36240 updates, score 14.07) (writing took 2.2109445007517934 seconds)
2022-03-07 18:51:27 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 18:51:27 | INFO | train | epoch 376 | loss 1.089 | nll_loss 0.503 | ppl 1.42 | wps 22302.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36240 | lr 0.000166114 | gnorm 0.759 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 107999
2022-03-07 18:51:27 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 18:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:54:17 | INFO | train_inner | epoch 377:     60 / 97 loss=1.089, nll_loss=0.503, ppl=1.42, wps=22336.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=36300, lr=0.000165977, gnorm=0.763, loss_scale=16, train_wall=264, gb_free=8.1, wall=108169
2022-03-07 18:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:56:07 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 14.085 | nll_loss 13.828 | ppl 14539.6 | wps 44498.7 | wpb 510.9 | bsz 1 | num_updates 36337 | best_loss 7.706
2022-03-07 18:56:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 36337 updates
2022-03-07 18:56:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:56:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 18:56:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 377 @ 36337 updates, score 14.085) (writing took 2.228993414901197 seconds)
2022-03-07 18:56:09 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 18:56:09 | INFO | train | epoch 377 | loss 1.088 | nll_loss 0.503 | ppl 1.42 | wps 22542.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36337 | lr 0.000165892 | gnorm 0.756 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 108281
2022-03-07 18:56:09 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 18:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:07 | INFO | train_inner | epoch 378:     63 / 97 loss=1.086, nll_loss=0.501, ppl=1.42, wps=22562.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36400, lr=0.000165748, gnorm=0.748, loss_scale=32, train_wall=261, gb_free=8.1, wall=108459
2022-03-07 19:00:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:00:54 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 14.097 | nll_loss 13.837 | ppl 14637.6 | wps 37859.1 | wpb 510.9 | bsz 1 | num_updates 36433 | best_loss 7.706
2022-03-07 19:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 36433 updates
2022-03-07 19:00:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 378 @ 36433 updates, score 14.097) (writing took 2.1389034800231457 seconds)
2022-03-07 19:00:56 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 19:00:56 | INFO | train | epoch 378 | loss 1.086 | nll_loss 0.501 | ppl 1.42 | wps 21877 | ups 0.33 | wpb 65491.1 | bsz 127.9 | num_updates 36433 | lr 0.000165673 | gnorm 0.748 | loss_scale 16 | train_wall 257 | gb_free 8.1 | wall 108568
2022-03-07 19:00:56 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 19:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:04:16 | INFO | train_inner | epoch 379:     67 / 97 loss=1.086, nll_loss=0.501, ppl=1.41, wps=21186.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36500, lr=0.000165521, gnorm=0.748, loss_scale=16, train_wall=275, gb_free=8.1, wall=108768
2022-03-07 19:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:05:52 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 14.062 | nll_loss 13.805 | ppl 14314.4 | wps 37279.6 | wpb 510.9 | bsz 1 | num_updates 36530 | best_loss 7.706
2022-03-07 19:05:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 36530 updates
2022-03-07 19:05:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:05:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 379 @ 36530 updates, score 14.062) (writing took 2.236767817288637 seconds)
2022-03-07 19:05:54 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 19:05:54 | INFO | train | epoch 379 | loss 1.085 | nll_loss 0.5 | ppl 1.41 | wps 21346.4 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 36530 | lr 0.000165453 | gnorm 0.751 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 108866
2022-03-07 19:05:54 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 19:05:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:08:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:09:26 | INFO | train_inner | epoch 380:     71 / 97 loss=1.085, nll_loss=0.5, ppl=1.41, wps=21154.2, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36600, lr=0.000165295, gnorm=0.754, loss_scale=16, train_wall=276, gb_free=8.1, wall=109078
2022-03-07 19:10:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:10:50 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 14.072 | nll_loss 13.815 | ppl 14408.7 | wps 36357.6 | wpb 510.9 | bsz 1 | num_updates 36626 | best_loss 7.706
2022-03-07 19:10:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 36626 updates
2022-03-07 19:10:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:10:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:10:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 380 @ 36626 updates, score 14.072) (writing took 2.3045861613936722 seconds)
2022-03-07 19:10:52 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 19:10:52 | INFO | train | epoch 380 | loss 1.085 | nll_loss 0.5 | ppl 1.41 | wps 21085.5 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36626 | lr 0.000165236 | gnorm 0.753 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 109164
2022-03-07 19:10:52 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 19:10:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:14:33 | INFO | train_inner | epoch 381:     74 / 97 loss=1.087, nll_loss=0.502, ppl=1.42, wps=21338.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=36700, lr=0.00016507, gnorm=0.761, loss_scale=16, train_wall=273, gb_free=8.1, wall=109385
2022-03-07 19:15:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:15:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:15:47 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 14.037 | nll_loss 13.777 | ppl 14038.1 | wps 38981.3 | wpb 510.9 | bsz 1 | num_updates 36722 | best_loss 7.706
2022-03-07 19:15:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 36722 updates
2022-03-07 19:15:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:15:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:15:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 381 @ 36722 updates, score 14.037) (writing took 2.281525115016848 seconds)
2022-03-07 19:15:49 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 19:15:49 | INFO | train | epoch 381 | loss 1.085 | nll_loss 0.5 | ppl 1.41 | wps 21146 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 36722 | lr 0.00016502 | gnorm 0.763 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 109461
2022-03-07 19:15:49 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 19:15:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:19:42 | INFO | train_inner | epoch 382:     78 / 97 loss=1.083, nll_loss=0.498, ppl=1.41, wps=21159.1, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=36800, lr=0.000164845, gnorm=0.756, loss_scale=16, train_wall=276, gb_free=8.1, wall=109694
2022-03-07 19:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:45 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 14.114 | nll_loss 13.855 | ppl 14815.1 | wps 37314.2 | wpb 510.9 | bsz 1 | num_updates 36819 | best_loss 7.706
2022-03-07 19:20:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 36819 updates
2022-03-07 19:20:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:20:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:20:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 382 @ 36819 updates, score 14.114) (writing took 2.266585416160524 seconds)
2022-03-07 19:20:47 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 19:20:47 | INFO | train | epoch 382 | loss 1.083 | nll_loss 0.498 | ppl 1.41 | wps 21319.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 36819 | lr 0.000164803 | gnorm 0.756 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 109759
2022-03-07 19:20:47 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 19:20:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:24:50 | INFO | train_inner | epoch 383:     81 / 97 loss=1.082, nll_loss=0.497, ppl=1.41, wps=21308.5, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=36900, lr=0.000164622, gnorm=0.751, loss_scale=32, train_wall=273, gb_free=8.1, wall=110002
2022-03-07 19:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:25:43 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 14.049 | nll_loss 13.792 | ppl 14181.5 | wps 37875.2 | wpb 510.9 | bsz 1 | num_updates 36916 | best_loss 7.706
2022-03-07 19:25:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 36916 updates
2022-03-07 19:25:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:25:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:25:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 383 @ 36916 updates, score 14.049) (writing took 2.1951598157174885 seconds)
2022-03-07 19:25:45 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 19:25:45 | INFO | train | epoch 383 | loss 1.082 | nll_loss 0.497 | ppl 1.41 | wps 21299.6 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 36916 | lr 0.000164586 | gnorm 0.75 | loss_scale 32 | train_wall 265 | gb_free 8.1 | wall 110058
2022-03-07 19:25:45 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 19:25:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:27:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:30:00 | INFO | train_inner | epoch 384:     85 / 97 loss=1.083, nll_loss=0.498, ppl=1.41, wps=21127.9, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=37000, lr=0.000164399, gnorm=0.755, loss_scale=16, train_wall=276, gb_free=8.1, wall=110312
2022-03-07 19:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:30:41 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 14.057 | nll_loss 13.8 | ppl 14258.5 | wps 36760.2 | wpb 510.9 | bsz 1 | num_updates 37012 | best_loss 7.706
2022-03-07 19:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 37012 updates
2022-03-07 19:30:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:30:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 384 @ 37012 updates, score 14.057) (writing took 2.3327085631899536 seconds)
2022-03-07 19:30:44 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 19:30:44 | INFO | train | epoch 384 | loss 1.082 | nll_loss 0.497 | ppl 1.41 | wps 21072.3 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37012 | lr 0.000164372 | gnorm 0.752 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 110356
2022-03-07 19:30:44 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 19:30:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:07 | INFO | train_inner | epoch 385:     88 / 97 loss=1.082, nll_loss=0.497, ppl=1.41, wps=21330.3, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=37100, lr=0.000164177, gnorm=0.745, loss_scale=32, train_wall=273, gb_free=8.1, wall=110619
2022-03-07 19:35:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:35:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:35:40 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 14.082 | nll_loss 13.825 | ppl 14516.5 | wps 36264.5 | wpb 510.9 | bsz 1 | num_updates 37108 | best_loss 7.706
2022-03-07 19:35:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 37108 updates
2022-03-07 19:35:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:35:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:35:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 385 @ 37108 updates, score 14.082) (writing took 2.402074017096311 seconds)
2022-03-07 19:35:42 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 19:35:42 | INFO | train | epoch 385 | loss 1.081 | nll_loss 0.497 | ppl 1.41 | wps 21085 | ups 0.32 | wpb 65491.1 | bsz 127.9 | num_updates 37108 | lr 0.00016416 | gnorm 0.746 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 110654
2022-03-07 19:35:42 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 19:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:17 | INFO | train_inner | epoch 386:     92 / 97 loss=1.081, nll_loss=0.496, ppl=1.41, wps=21108.3, ups=0.32, wpb=65492.9, bsz=127.9, num_updates=37200, lr=0.000163956, gnorm=0.752, loss_scale=16, train_wall=276, gb_free=8.1, wall=110929
2022-03-07 19:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:40:38 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 14.104 | nll_loss 13.846 | ppl 14722.9 | wps 36953.2 | wpb 510.9 | bsz 1 | num_updates 37205 | best_loss 7.706
2022-03-07 19:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 37205 updates
2022-03-07 19:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 386 @ 37205 updates, score 14.104) (writing took 2.237229773774743 seconds)
2022-03-07 19:40:40 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 19:40:40 | INFO | train | epoch 386 | loss 1.08 | nll_loss 0.495 | ppl 1.41 | wps 21316.8 | ups 0.33 | wpb 65491.6 | bsz 127.9 | num_updates 37205 | lr 0.000163945 | gnorm 0.753 | loss_scale 16 | train_wall 265 | gb_free 8.1 | wall 110952
2022-03-07 19:40:40 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 19:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:42:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:45:15 | INFO | train_inner | epoch 387:     96 / 97 loss=1.079, nll_loss=0.495, ppl=1.41, wps=22001, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37300, lr=0.000163737, gnorm=0.748, loss_scale=16, train_wall=266, gb_free=8.1, wall=111227
2022-03-07 19:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:45:22 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 14.086 | nll_loss 13.83 | ppl 14565.1 | wps 44485.7 | wpb 510.9 | bsz 1 | num_updates 37301 | best_loss 7.706
2022-03-07 19:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 37301 updates
2022-03-07 19:45:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 387 @ 37301 updates, score 14.086) (writing took 2.22891778498888 seconds)
2022-03-07 19:45:25 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 19:45:25 | INFO | train | epoch 387 | loss 1.079 | nll_loss 0.494 | ppl 1.41 | wps 22093.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37301 | lr 0.000163734 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 111237
2022-03-07 19:45:25 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 19:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:49:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:50:04 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 14.11 | nll_loss 13.855 | ppl 14816.5 | wps 44529.2 | wpb 510.9 | bsz 1 | num_updates 37397 | best_loss 7.706
2022-03-07 19:50:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 37397 updates
2022-03-07 19:50:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:50:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:50:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 388 @ 37397 updates, score 14.11) (writing took 2.279165107756853 seconds)
2022-03-07 19:50:06 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 19:50:06 | INFO | train | epoch 388 | loss 1.078 | nll_loss 0.494 | ppl 1.41 | wps 22318.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37397 | lr 0.000163524 | gnorm 0.742 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 111518
2022-03-07 19:50:06 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 19:50:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:15 | INFO | train_inner | epoch 389:      3 / 97 loss=1.078, nll_loss=0.493, ppl=1.41, wps=21809.1, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=37400, lr=0.000163517, gnorm=0.742, loss_scale=16, train_wall=263, gb_free=8.1, wall=111527
2022-03-07 19:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:54:46 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 14.121 | nll_loss 13.865 | ppl 14915.8 | wps 44240.9 | wpb 510.9 | bsz 1 | num_updates 37494 | best_loss 7.706
2022-03-07 19:54:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 37494 updates
2022-03-07 19:54:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:54:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:54:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 389 @ 37494 updates, score 14.121) (writing took 2.227682749275118 seconds)
2022-03-07 19:54:48 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 19:54:48 | INFO | train | epoch 389 | loss 1.077 | nll_loss 0.493 | ppl 1.41 | wps 22543.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37494 | lr 0.000163312 | gnorm 0.745 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 111800
2022-03-07 19:54:48 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 19:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:55:05 | INFO | train_inner | epoch 390:      6 / 97 loss=1.077, nll_loss=0.493, ppl=1.41, wps=22560.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37500, lr=0.000163299, gnorm=0.746, loss_scale=16, train_wall=261, gb_free=8.1, wall=111817
2022-03-07 19:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:59:28 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 14.063 | nll_loss 13.805 | ppl 14310.7 | wps 44436.1 | wpb 510.9 | bsz 1 | num_updates 37591 | best_loss 7.706
2022-03-07 19:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 37591 updates
2022-03-07 19:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 19:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 390 @ 37591 updates, score 14.063) (writing took 2.2767121526412666 seconds)
2022-03-07 19:59:30 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 19:59:30 | INFO | train | epoch 390 | loss 1.077 | nll_loss 0.493 | ppl 1.41 | wps 22549.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37591 | lr 0.000163102 | gnorm 0.742 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 112082
2022-03-07 19:59:30 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 19:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:55 | INFO | train_inner | epoch 391:      9 / 97 loss=1.076, nll_loss=0.492, ppl=1.41, wps=22566.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37600, lr=0.000163082, gnorm=0.741, loss_scale=32, train_wall=261, gb_free=8.1, wall=112107
2022-03-07 20:02:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:04:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:10 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 14.095 | nll_loss 13.837 | ppl 14634.6 | wps 44557.5 | wpb 510.9 | bsz 1 | num_updates 37686 | best_loss 7.706
2022-03-07 20:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 37686 updates
2022-03-07 20:04:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:04:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:04:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 391 @ 37686 updates, score 14.095) (writing took 2.1289050970226526 seconds)
2022-03-07 20:04:12 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 20:04:12 | INFO | train | epoch 391 | loss 1.076 | nll_loss 0.491 | ppl 1.41 | wps 22054.6 | ups 0.34 | wpb 65490.6 | bsz 127.9 | num_updates 37686 | lr 0.000162896 | gnorm 0.748 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 112364
2022-03-07 20:04:12 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 20:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:05:11 | INFO | train_inner | epoch 392:     14 / 97 loss=1.075, nll_loss=0.49, ppl=1.4, wps=20779.4, ups=0.32, wpb=65495, bsz=127.9, num_updates=37700, lr=0.000162866, gnorm=0.747, loss_scale=16, train_wall=268, gb_free=8.1, wall=112423
2022-03-07 20:09:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:09:13 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 14.13 | nll_loss 13.876 | ppl 15029.9 | wps 44297 | wpb 510.9 | bsz 1 | num_updates 37783 | best_loss 7.706
2022-03-07 20:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 37783 updates
2022-03-07 20:09:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:09:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:09:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 392 @ 37783 updates, score 14.13) (writing took 2.2838243287988007 seconds)
2022-03-07 20:09:15 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 20:09:15 | INFO | train | epoch 392 | loss 1.075 | nll_loss 0.491 | ppl 1.41 | wps 20952.5 | ups 0.32 | wpb 65491.6 | bsz 127.9 | num_updates 37783 | lr 0.000162687 | gnorm 0.744 | loss_scale 16 | train_wall 256 | gb_free 8.1 | wall 112667
2022-03-07 20:09:15 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 20:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:10:03 | INFO | train_inner | epoch 393:     17 / 97 loss=1.075, nll_loss=0.491, ppl=1.41, wps=22363.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37800, lr=0.00016265, gnorm=0.745, loss_scale=16, train_wall=263, gb_free=8.1, wall=112715
2022-03-07 20:12:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:13:57 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 14.067 | nll_loss 13.81 | ppl 14361.1 | wps 40299.2 | wpb 510.9 | bsz 1 | num_updates 37879 | best_loss 7.706
2022-03-07 20:13:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 37879 updates
2022-03-07 20:13:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:13:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:13:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 393 @ 37879 updates, score 14.067) (writing took 2.3396502030082047 seconds)
2022-03-07 20:13:59 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 20:13:59 | INFO | train | epoch 393 | loss 1.074 | nll_loss 0.49 | ppl 1.4 | wps 22143.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37879 | lr 0.00016248 | gnorm 0.745 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 112951
2022-03-07 20:13:59 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 20:13:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:59 | INFO | train_inner | epoch 394:     21 / 97 loss=1.073, nll_loss=0.489, ppl=1.4, wps=22140.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37900, lr=0.000162435, gnorm=0.746, loss_scale=16, train_wall=265, gb_free=8.1, wall=113011
2022-03-07 20:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:18:41 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 14.092 | nll_loss 13.834 | ppl 14598.9 | wps 44170.4 | wpb 510.9 | bsz 1 | num_updates 37976 | best_loss 7.706
2022-03-07 20:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 37976 updates
2022-03-07 20:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 394 @ 37976 updates, score 14.092) (writing took 2.269449819345027 seconds)
2022-03-07 20:18:43 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 20:18:43 | INFO | train | epoch 394 | loss 1.074 | nll_loss 0.49 | ppl 1.4 | wps 22382.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37976 | lr 0.000162273 | gnorm 0.747 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 113235
2022-03-07 20:18:43 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 20:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:19:52 | INFO | train_inner | epoch 395:     24 / 97 loss=1.073, nll_loss=0.488, ppl=1.4, wps=22370.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38000, lr=0.000162221, gnorm=0.744, loss_scale=32, train_wall=263, gb_free=8.1, wall=113304
2022-03-07 20:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:23:25 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 14.137 | nll_loss 13.879 | ppl 15069.7 | wps 44251.5 | wpb 510.9 | bsz 1 | num_updates 38073 | best_loss 7.706
2022-03-07 20:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 38073 updates
2022-03-07 20:23:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:23:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:23:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 395 @ 38073 updates, score 14.137) (writing took 2.2329347082413733 seconds)
2022-03-07 20:23:27 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 20:23:27 | INFO | train | epoch 395 | loss 1.072 | nll_loss 0.487 | ppl 1.4 | wps 22352.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38073 | lr 0.000162066 | gnorm 0.737 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 113519
2022-03-07 20:23:27 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 20:23:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:24:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:24:47 | INFO | train_inner | epoch 396:     28 / 97 loss=1.072, nll_loss=0.487, ppl=1.4, wps=22233.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38100, lr=0.000162008, gnorm=0.744, loss_scale=16, train_wall=265, gb_free=8.1, wall=113599
2022-03-07 20:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:28:09 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 14.076 | nll_loss 13.819 | ppl 14450 | wps 40250.4 | wpb 510.9 | bsz 1 | num_updates 38169 | best_loss 7.706
2022-03-07 20:28:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 38169 updates
2022-03-07 20:28:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:28:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 396 @ 38169 updates, score 14.076) (writing took 2.3937924369238317 seconds)
2022-03-07 20:28:11 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 20:28:11 | INFO | train | epoch 396 | loss 1.072 | nll_loss 0.488 | ppl 1.4 | wps 22108.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38169 | lr 0.000161862 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113803
2022-03-07 20:28:11 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 20:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:40 | INFO | train_inner | epoch 397:     31 / 97 loss=1.073, nll_loss=0.489, ppl=1.4, wps=22344.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=38200, lr=0.000161796, gnorm=0.75, loss_scale=16, train_wall=263, gb_free=8.1, wall=113892
2022-03-07 20:32:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:32:53 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 14.078 | nll_loss 13.822 | ppl 14479 | wps 44182.6 | wpb 510.9 | bsz 1 | num_updates 38265 | best_loss 7.706
2022-03-07 20:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 38265 updates
2022-03-07 20:32:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:32:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 397 @ 38265 updates, score 14.078) (writing took 2.307270480785519 seconds)
2022-03-07 20:32:55 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 20:32:55 | INFO | train | epoch 397 | loss 1.071 | nll_loss 0.487 | ppl 1.4 | wps 22180.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38265 | lr 0.000161659 | gnorm 0.74 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 114087
2022-03-07 20:32:55 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 20:32:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:34:35 | INFO | train_inner | epoch 398:     35 / 97 loss=1.069, nll_loss=0.485, ppl=1.4, wps=22159.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38300, lr=0.000161585, gnorm=0.746, loss_scale=16, train_wall=265, gb_free=8.1, wall=114187
2022-03-07 20:37:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:37:37 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 14.115 | nll_loss 13.858 | ppl 14851.2 | wps 44182.6 | wpb 510.9 | bsz 1 | num_updates 38362 | best_loss 7.706
2022-03-07 20:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 38362 updates
2022-03-07 20:37:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:37:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:37:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 398 @ 38362 updates, score 14.115) (writing took 2.256481188349426 seconds)
2022-03-07 20:37:39 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 20:37:39 | INFO | train | epoch 398 | loss 1.071 | nll_loss 0.486 | ppl 1.4 | wps 22352 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38362 | lr 0.000161454 | gnorm 0.752 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114371
2022-03-07 20:37:39 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 20:37:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:39:28 | INFO | train_inner | epoch 399:     38 / 97 loss=1.07, nll_loss=0.486, ppl=1.4, wps=22369.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38400, lr=0.000161374, gnorm=0.749, loss_scale=32, train_wall=263, gb_free=8.1, wall=114480
2022-03-07 20:39:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:42:21 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 14.134 | nll_loss 13.877 | ppl 15046.8 | wps 44249.1 | wpb 510.9 | bsz 1 | num_updates 38458 | best_loss 7.706
2022-03-07 20:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 38458 updates
2022-03-07 20:42:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 399 @ 38458 updates, score 14.134) (writing took 2.2917552879080176 seconds)
2022-03-07 20:42:23 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 20:42:23 | INFO | train | epoch 399 | loss 1.069 | nll_loss 0.485 | ppl 1.4 | wps 22125.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38458 | lr 0.000161253 | gnorm 0.748 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114655
2022-03-07 20:42:23 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 20:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:44:22 | INFO | train_inner | epoch 400:     42 / 97 loss=1.069, nll_loss=0.485, ppl=1.4, wps=22238.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38500, lr=0.000161165, gnorm=0.747, loss_scale=16, train_wall=265, gb_free=8.1, wall=114775
2022-03-07 20:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:47:04 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 14.097 | nll_loss 13.842 | ppl 14682.6 | wps 44332.7 | wpb 510.9 | bsz 1 | num_updates 38555 | best_loss 7.706
2022-03-07 20:47:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 38555 updates
2022-03-07 20:47:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:47:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:47:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 400 @ 38555 updates, score 14.097) (writing took 2.276883117854595 seconds)
2022-03-07 20:47:07 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 20:47:07 | INFO | train | epoch 400 | loss 1.069 | nll_loss 0.485 | ppl 1.4 | wps 22416 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38555 | lr 0.00016105 | gnorm 0.74 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 114939
2022-03-07 20:47:07 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 20:47:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:47:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:49:18 | INFO | train_inner | epoch 401:     46 / 97 loss=1.069, nll_loss=0.484, ppl=1.4, wps=22150, ups=0.34, wpb=65495, bsz=127.9, num_updates=38600, lr=0.000160956, gnorm=0.738, loss_scale=16, train_wall=265, gb_free=8.1, wall=115070
2022-03-07 20:51:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:51:49 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 14.08 | nll_loss 13.824 | ppl 14501.9 | wps 44169.4 | wpb 510.9 | bsz 1 | num_updates 38651 | best_loss 7.706
2022-03-07 20:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 38651 updates
2022-03-07 20:51:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:51:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:51:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 401 @ 38651 updates, score 14.08) (writing took 2.2941028219647706 seconds)
2022-03-07 20:51:51 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 20:51:51 | INFO | train | epoch 401 | loss 1.068 | nll_loss 0.484 | ppl 1.4 | wps 22125.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38651 | lr 0.000160849 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115223
2022-03-07 20:51:51 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 20:51:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:54:11 | INFO | train_inner | epoch 402:     49 / 97 loss=1.067, nll_loss=0.483, ppl=1.4, wps=22378.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38700, lr=0.000160748, gnorm=0.742, loss_scale=32, train_wall=263, gb_free=8.1, wall=115363
2022-03-07 20:54:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:56:33 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 14.105 | nll_loss 13.848 | ppl 14746.7 | wps 44075.4 | wpb 510.9 | bsz 1 | num_updates 38747 | best_loss 7.706
2022-03-07 20:56:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 38747 updates
2022-03-07 20:56:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 20:56:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 402 @ 38747 updates, score 14.105) (writing took 2.3429989786818624 seconds)
2022-03-07 20:56:35 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 20:56:35 | INFO | train | epoch 402 | loss 1.067 | nll_loss 0.483 | ppl 1.4 | wps 22114.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38747 | lr 0.00016065 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115507
2022-03-07 20:56:35 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 20:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:59:06 | INFO | train_inner | epoch 403:     53 / 97 loss=1.068, nll_loss=0.484, ppl=1.4, wps=22154.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38800, lr=0.00016054, gnorm=0.743, loss_scale=16, train_wall=265, gb_free=8.1, wall=115658
2022-03-07 21:01:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:01:16 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 14.11 | nll_loss 13.854 | ppl 14803.7 | wps 44219.3 | wpb 510.9 | bsz 1 | num_updates 38844 | best_loss 7.706
2022-03-07 21:01:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 38844 updates
2022-03-07 21:01:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:01:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:01:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 403 @ 38844 updates, score 14.11) (writing took 2.2237589731812477 seconds)
2022-03-07 21:01:18 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 21:01:18 | INFO | train | epoch 403 | loss 1.066 | nll_loss 0.482 | ppl 1.4 | wps 22433.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38844 | lr 0.000160449 | gnorm 0.745 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 115790
2022-03-07 21:01:18 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 21:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:01:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:04:01 | INFO | train_inner | epoch 404:     57 / 97 loss=1.065, nll_loss=0.481, ppl=1.4, wps=22233.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=38900, lr=0.000160334, gnorm=0.745, loss_scale=16, train_wall=264, gb_free=8.1, wall=115953
2022-03-07 21:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:06:00 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 14.063 | nll_loss 13.803 | ppl 14294.4 | wps 44002.1 | wpb 510.9 | bsz 1 | num_updates 38940 | best_loss 7.706
2022-03-07 21:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 38940 updates
2022-03-07 21:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:06:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:06:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 404 @ 38940 updates, score 14.063) (writing took 2.2782299336977303 seconds)
2022-03-07 21:06:03 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 21:06:03 | INFO | train | epoch 404 | loss 1.064 | nll_loss 0.48 | ppl 1.39 | wps 22119.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38940 | lr 0.000160251 | gnorm 0.739 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 116075
2022-03-07 21:06:03 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 21:06:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:08:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:08:57 | INFO | train_inner | epoch 405:     61 / 97 loss=1.066, nll_loss=0.482, ppl=1.4, wps=22155.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39000, lr=0.000160128, gnorm=0.745, loss_scale=16, train_wall=265, gb_free=8.1, wall=116249
2022-03-07 21:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:10:44 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 14.106 | nll_loss 13.849 | ppl 14752.7 | wps 44521.8 | wpb 510.9 | bsz 1 | num_updates 39036 | best_loss 7.706
2022-03-07 21:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 39036 updates
2022-03-07 21:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 405 @ 39036 updates, score 14.106) (writing took 2.2878938750363886 seconds)
2022-03-07 21:10:47 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 21:10:47 | INFO | train | epoch 405 | loss 1.066 | nll_loss 0.482 | ppl 1.4 | wps 22117.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39036 | lr 0.000160054 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 116359
2022-03-07 21:10:47 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 21:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:13:49 | INFO | train_inner | epoch 406:     64 / 97 loss=1.065, nll_loss=0.481, ppl=1.4, wps=22374.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39100, lr=0.000159923, gnorm=0.74, loss_scale=16, train_wall=263, gb_free=8.1, wall=116541
2022-03-07 21:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:15:28 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 14.117 | nll_loss 13.862 | ppl 14891.5 | wps 44085.2 | wpb 510.9 | bsz 1 | num_updates 39133 | best_loss 7.706
2022-03-07 21:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 39133 updates
2022-03-07 21:15:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 406 @ 39133 updates, score 14.117) (writing took 2.2760372175835073 seconds)
2022-03-07 21:15:30 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 21:15:30 | INFO | train | epoch 406 | loss 1.064 | nll_loss 0.48 | ppl 1.4 | wps 22426.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39133 | lr 0.000159856 | gnorm 0.742 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 116642
2022-03-07 21:15:30 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 21:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:18:42 | INFO | train_inner | epoch 407:     67 / 97 loss=1.064, nll_loss=0.48, ppl=1.39, wps=22370.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39200, lr=0.000159719, gnorm=0.745, loss_scale=32, train_wall=263, gb_free=8.1, wall=116834
2022-03-07 21:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:12 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 14.087 | nll_loss 13.831 | ppl 14568.9 | wps 44151.1 | wpb 510.9 | bsz 1 | num_updates 39230 | best_loss 7.706
2022-03-07 21:20:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 39230 updates
2022-03-07 21:20:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:20:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 407 @ 39230 updates, score 14.087) (writing took 2.3303668363951147 seconds)
2022-03-07 21:20:14 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 21:20:14 | INFO | train | epoch 407 | loss 1.063 | nll_loss 0.48 | ppl 1.39 | wps 22337.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39230 | lr 0.000159658 | gnorm 0.74 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 116926
2022-03-07 21:20:14 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 21:20:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:21:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:22:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:23:40 | INFO | train_inner | epoch 408:     72 / 97 loss=1.063, nll_loss=0.479, ppl=1.39, wps=22005, ups=0.34, wpb=65495, bsz=127.9, num_updates=39300, lr=0.000159516, gnorm=0.738, loss_scale=16, train_wall=267, gb_free=8.1, wall=117132
2022-03-07 21:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:24:56 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 14.112 | nll_loss 13.857 | ppl 14834.1 | wps 44238.5 | wpb 510.9 | bsz 1 | num_updates 39325 | best_loss 7.706
2022-03-07 21:24:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 39325 updates
2022-03-07 21:24:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 408 @ 39325 updates, score 14.112) (writing took 2.2547145229764283 seconds)
2022-03-07 21:24:59 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 21:24:59 | INFO | train | epoch 408 | loss 1.062 | nll_loss 0.478 | ppl 1.39 | wps 21885.7 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 39325 | lr 0.000159465 | gnorm 0.739 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117211
2022-03-07 21:24:59 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 21:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:32 | INFO | train_inner | epoch 409:     75 / 97 loss=1.063, nll_loss=0.48, ppl=1.39, wps=22373.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39400, lr=0.000159313, gnorm=0.742, loss_scale=32, train_wall=263, gb_free=8.1, wall=117425
2022-03-07 21:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:29:40 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 14.076 | nll_loss 13.82 | ppl 14463.7 | wps 40614.1 | wpb 510.9 | bsz 1 | num_updates 39422 | best_loss 7.706
2022-03-07 21:29:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 39422 updates
2022-03-07 21:29:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:29:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 409 @ 39422 updates, score 14.076) (writing took 2.384668425656855 seconds)
2022-03-07 21:29:43 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 21:29:43 | INFO | train | epoch 409 | loss 1.062 | nll_loss 0.479 | ppl 1.39 | wps 22377.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39422 | lr 0.000159269 | gnorm 0.739 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 117495
2022-03-07 21:29:43 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 21:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:33:25 | INFO | train_inner | epoch 410:     78 / 97 loss=1.062, nll_loss=0.479, ppl=1.39, wps=22359.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39500, lr=0.000159111, gnorm=0.737, loss_scale=32, train_wall=262, gb_free=8.1, wall=117717
2022-03-07 21:34:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:34:24 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 14.097 | nll_loss 13.841 | ppl 14670.4 | wps 44350.8 | wpb 510.9 | bsz 1 | num_updates 39519 | best_loss 7.706
2022-03-07 21:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 39519 updates
2022-03-07 21:34:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 410 @ 39519 updates, score 14.097) (writing took 2.329223508015275 seconds)
2022-03-07 21:34:26 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 21:34:26 | INFO | train | epoch 410 | loss 1.062 | nll_loss 0.478 | ppl 1.39 | wps 22389.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39519 | lr 0.000159073 | gnorm 0.74 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 117778
2022-03-07 21:34:26 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 21:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:34:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:37:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:38:24 | INFO | train_inner | epoch 411:     83 / 97 loss=1.061, nll_loss=0.477, ppl=1.39, wps=21952.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39600, lr=0.00015891, gnorm=0.745, loss_scale=16, train_wall=268, gb_free=8.1, wall=118016
2022-03-07 21:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:08 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 14.092 | nll_loss 13.836 | ppl 14619.5 | wps 44231.2 | wpb 510.9 | bsz 1 | num_updates 39614 | best_loss 7.706
2022-03-07 21:39:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 39614 updates
2022-03-07 21:39:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:39:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 411 @ 39614 updates, score 14.092) (writing took 2.2822442087344825 seconds)
2022-03-07 21:39:11 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 21:39:11 | INFO | train | epoch 411 | loss 1.06 | nll_loss 0.477 | ppl 1.39 | wps 21895 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 39614 | lr 0.000158882 | gnorm 0.748 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 118063
2022-03-07 21:39:11 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 21:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:15 | INFO | train_inner | epoch 412:     86 / 97 loss=1.06, nll_loss=0.477, ppl=1.39, wps=22451.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39700, lr=0.00015871, gnorm=0.741, loss_scale=16, train_wall=262, gb_free=8.1, wall=118307
2022-03-07 21:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:43:52 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 14.029 | nll_loss 13.769 | ppl 13962.1 | wps 40458 | wpb 510.9 | bsz 1 | num_updates 39711 | best_loss 7.706
2022-03-07 21:43:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 39711 updates
2022-03-07 21:43:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 412 @ 39711 updates, score 14.029) (writing took 2.42418522387743 seconds)
2022-03-07 21:43:55 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 21:43:55 | INFO | train | epoch 412 | loss 1.059 | nll_loss 0.476 | ppl 1.39 | wps 22338.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39711 | lr 0.000158688 | gnorm 0.738 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 118347
2022-03-07 21:43:55 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 21:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:08 | INFO | train_inner | epoch 413:     89 / 97 loss=1.06, nll_loss=0.476, ppl=1.39, wps=22358.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39800, lr=0.000158511, gnorm=0.736, loss_scale=32, train_wall=262, gb_free=8.1, wall=118600
2022-03-07 21:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:48:36 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 14.097 | nll_loss 13.841 | ppl 14675.5 | wps 44516.2 | wpb 510.9 | bsz 1 | num_updates 39808 | best_loss 7.706
2022-03-07 21:48:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 39808 updates
2022-03-07 21:48:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 413 @ 39808 updates, score 14.097) (writing took 2.284818616230041 seconds)
2022-03-07 21:48:38 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 21:48:38 | INFO | train | epoch 413 | loss 1.06 | nll_loss 0.476 | ppl 1.39 | wps 22434 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39808 | lr 0.000158495 | gnorm 0.735 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 118630
2022-03-07 21:48:38 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 21:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:50:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:53:04 | INFO | train_inner | epoch 414:     93 / 97 loss=1.059, nll_loss=0.476, ppl=1.39, wps=22166.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39900, lr=0.000158312, gnorm=0.738, loss_scale=32, train_wall=265, gb_free=8.1, wall=118896
2022-03-07 21:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:53:20 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 14.156 | nll_loss 13.902 | ppl 15313.1 | wps 44563.5 | wpb 510.9 | bsz 1 | num_updates 39904 | best_loss 7.706
2022-03-07 21:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 39904 updates
2022-03-07 21:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 414 @ 39904 updates, score 14.156) (writing took 2.2386712739244103 seconds)
2022-03-07 21:53:22 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 21:53:22 | INFO | train | epoch 414 | loss 1.058 | nll_loss 0.474 | ppl 1.39 | wps 22129.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39904 | lr 0.000158304 | gnorm 0.737 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 118914
2022-03-07 21:53:22 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 21:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:56:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:57:59 | INFO | train_inner | epoch 415:     97 / 97 loss=1.058, nll_loss=0.475, ppl=1.39, wps=22173.5, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=40000, lr=0.000158114, gnorm=0.733, loss_scale=32, train_wall=265, gb_free=8.1, wall=119191
2022-03-07 21:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:58:04 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 14.1 | nll_loss 13.845 | ppl 14712.5 | wps 43070.6 | wpb 510.9 | bsz 1 | num_updates 40000 | best_loss 7.706
2022-03-07 21:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 40000 updates
2022-03-07 21:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:58:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 21:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 415 @ 40000 updates, score 14.1) (writing took 2.245633570011705 seconds)
2022-03-07 21:58:06 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 21:58:06 | INFO | train | epoch 415 | loss 1.058 | nll_loss 0.474 | ppl 1.39 | wps 22124.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40000 | lr 0.000158114 | gnorm 0.732 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 119198
2022-03-07 21:58:06 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 21:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:59:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:02:47 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 14.121 | nll_loss 13.864 | ppl 14909.9 | wps 44455.9 | wpb 510.9 | bsz 1 | num_updates 40096 | best_loss 7.706
2022-03-07 22:02:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 40096 updates
2022-03-07 22:02:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:02:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 416 @ 40096 updates, score 14.121) (writing took 2.30880139535293 seconds)
2022-03-07 22:02:50 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 22:02:50 | INFO | train | epoch 416 | loss 1.057 | nll_loss 0.473 | ppl 1.39 | wps 22195.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40096 | lr 0.000157924 | gnorm 0.73 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 119482
2022-03-07 22:02:50 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 22:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:01 | INFO | train_inner | epoch 417:      4 / 97 loss=1.056, nll_loss=0.473, ppl=1.39, wps=21682.4, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=40100, lr=0.000157917, gnorm=0.729, loss_scale=16, train_wall=265, gb_free=8.1, wall=119493
2022-03-07 22:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:07:32 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 14.12 | nll_loss 13.866 | ppl 14930.9 | wps 44254.2 | wpb 510.9 | bsz 1 | num_updates 40193 | best_loss 7.706
2022-03-07 22:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 40193 updates
2022-03-07 22:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 417 @ 40193 updates, score 14.12) (writing took 2.2960424008779228 seconds)
2022-03-07 22:07:34 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 22:07:34 | INFO | train | epoch 417 | loss 1.057 | nll_loss 0.473 | ppl 1.39 | wps 22344.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40193 | lr 0.000157734 | gnorm 0.729 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 119766
2022-03-07 22:07:34 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 22:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:07:54 | INFO | train_inner | epoch 418:      7 / 97 loss=1.056, nll_loss=0.473, ppl=1.39, wps=22368, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40200, lr=0.00015772, gnorm=0.729, loss_scale=32, train_wall=263, gb_free=8.1, wall=119786
2022-03-07 22:08:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:12:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:12:16 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 14.055 | nll_loss 13.8 | ppl 14264.8 | wps 44275 | wpb 510.9 | bsz 1 | num_updates 40289 | best_loss 7.706
2022-03-07 22:12:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 40289 updates
2022-03-07 22:12:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:12:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 418 @ 40289 updates, score 14.055) (writing took 2.2947606216184795 seconds)
2022-03-07 22:12:18 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 22:12:18 | INFO | train | epoch 418 | loss 1.056 | nll_loss 0.472 | ppl 1.39 | wps 22129.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40289 | lr 0.000157546 | gnorm 0.732 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120050
2022-03-07 22:12:18 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 22:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:12:49 | INFO | train_inner | epoch 419:     11 / 97 loss=1.055, nll_loss=0.472, ppl=1.39, wps=22167.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40300, lr=0.000157524, gnorm=0.732, loss_scale=16, train_wall=265, gb_free=8.1, wall=120081
2022-03-07 22:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:16:59 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 14.129 | nll_loss 13.875 | ppl 15025.6 | wps 44274 | wpb 510.9 | bsz 1 | num_updates 40386 | best_loss 7.706
2022-03-07 22:16:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 40386 updates
2022-03-07 22:16:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:17:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:17:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 419 @ 40386 updates, score 14.129) (writing took 2.2550192000344396 seconds)
2022-03-07 22:17:01 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 22:17:01 | INFO | train | epoch 419 | loss 1.055 | nll_loss 0.471 | ppl 1.39 | wps 22437.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40386 | lr 0.000157356 | gnorm 0.729 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 120333
2022-03-07 22:17:01 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 22:17:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:17:42 | INFO | train_inner | epoch 420:     14 / 97 loss=1.054, nll_loss=0.471, ppl=1.39, wps=22369.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40400, lr=0.000157329, gnorm=0.728, loss_scale=32, train_wall=263, gb_free=8.1, wall=120374
2022-03-07 22:20:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:21:43 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 14.068 | nll_loss 13.809 | ppl 14351.6 | wps 44341.1 | wpb 510.9 | bsz 1 | num_updates 40482 | best_loss 7.706
2022-03-07 22:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 40482 updates
2022-03-07 22:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:21:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:21:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 420 @ 40482 updates, score 14.068) (writing took 2.247061910107732 seconds)
2022-03-07 22:21:45 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 22:21:45 | INFO | train | epoch 420 | loss 1.055 | nll_loss 0.471 | ppl 1.39 | wps 22118.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40482 | lr 0.00015717 | gnorm 0.733 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 120617
2022-03-07 22:21:45 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 22:21:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:22:37 | INFO | train_inner | epoch 421:     18 / 97 loss=1.054, nll_loss=0.47, ppl=1.39, wps=22240.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40500, lr=0.000157135, gnorm=0.736, loss_scale=32, train_wall=265, gb_free=8.1, wall=120669
2022-03-07 22:22:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:26:27 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 14.057 | nll_loss 13.801 | ppl 14275.1 | wps 44377.1 | wpb 510.9 | bsz 1 | num_updates 40578 | best_loss 7.706
2022-03-07 22:26:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 40578 updates
2022-03-07 22:26:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:26:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:26:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 421 @ 40578 updates, score 14.057) (writing took 2.2948552262969315 seconds)
2022-03-07 22:26:30 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 22:26:30 | INFO | train | epoch 421 | loss 1.054 | nll_loss 0.47 | ppl 1.39 | wps 22120.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40578 | lr 0.000156984 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120902
2022-03-07 22:26:30 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 22:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:27:32 | INFO | train_inner | epoch 422:     22 / 97 loss=1.053, nll_loss=0.47, ppl=1.39, wps=22152.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=40600, lr=0.000156941, gnorm=0.742, loss_scale=16, train_wall=265, gb_free=8.1, wall=120964
2022-03-07 22:31:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:31:11 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 14.065 | nll_loss 13.809 | ppl 14357.1 | wps 44280.2 | wpb 510.9 | bsz 1 | num_updates 40675 | best_loss 7.706
2022-03-07 22:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 40675 updates
2022-03-07 22:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:31:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 422 @ 40675 updates, score 14.065) (writing took 2.3156178942881525 seconds)
2022-03-07 22:31:13 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 22:31:13 | INFO | train | epoch 422 | loss 1.053 | nll_loss 0.47 | ppl 1.38 | wps 22410.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40675 | lr 0.000156796 | gnorm 0.728 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 121185
2022-03-07 22:31:13 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 22:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:32:25 | INFO | train_inner | epoch 423:     25 / 97 loss=1.053, nll_loss=0.47, ppl=1.38, wps=22369, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40700, lr=0.000156748, gnorm=0.731, loss_scale=32, train_wall=263, gb_free=8.1, wall=121257
2022-03-07 22:35:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:35:55 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 14.074 | nll_loss 13.819 | ppl 14455.7 | wps 44250.9 | wpb 510.9 | bsz 1 | num_updates 40771 | best_loss 7.706
2022-03-07 22:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 40771 updates
2022-03-07 22:35:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:35:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:35:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 423 @ 40771 updates, score 14.074) (writing took 2.321693000383675 seconds)
2022-03-07 22:35:57 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 22:35:57 | INFO | train | epoch 423 | loss 1.052 | nll_loss 0.469 | ppl 1.38 | wps 22140.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40771 | lr 0.000156612 | gnorm 0.737 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 121469
2022-03-07 22:35:57 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 22:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:37:20 | INFO | train_inner | epoch 424:     29 / 97 loss=1.051, nll_loss=0.468, ppl=1.38, wps=22173.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40800, lr=0.000156556, gnorm=0.733, loss_scale=32, train_wall=265, gb_free=8.1, wall=121552
2022-03-07 22:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:40:39 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 14.134 | nll_loss 13.881 | ppl 15084.5 | wps 44221.7 | wpb 510.9 | bsz 1 | num_updates 40868 | best_loss 7.706
2022-03-07 22:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 40868 updates
2022-03-07 22:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 424 @ 40868 updates, score 14.134) (writing took 2.3000035821460187 seconds)
2022-03-07 22:40:41 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 22:40:41 | INFO | train | epoch 424 | loss 1.051 | nll_loss 0.468 | ppl 1.38 | wps 22365 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40868 | lr 0.000156426 | gnorm 0.732 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 121753
2022-03-07 22:40:41 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 22:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:41:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:42:15 | INFO | train_inner | epoch 425:     33 / 97 loss=1.051, nll_loss=0.468, ppl=1.38, wps=22248.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40900, lr=0.000156365, gnorm=0.731, loss_scale=32, train_wall=264, gb_free=8.1, wall=121847
2022-03-07 22:42:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:45:23 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 14.133 | nll_loss 13.88 | ppl 15074 | wps 41005.1 | wpb 510.9 | bsz 1 | num_updates 40963 | best_loss 7.706
2022-03-07 22:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 40963 updates
2022-03-07 22:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 425 @ 40963 updates, score 14.133) (writing took 2.4485367448069155 seconds)
2022-03-07 22:45:25 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 22:45:25 | INFO | train | epoch 425 | loss 1.05 | nll_loss 0.466 | ppl 1.38 | wps 21912.8 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 40963 | lr 0.000156244 | gnorm 0.735 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 122037
2022-03-07 22:45:25 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 22:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:47:10 | INFO | train_inner | epoch 426:     37 / 97 loss=1.049, nll_loss=0.466, ppl=1.38, wps=22142.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41000, lr=0.000156174, gnorm=0.737, loss_scale=16, train_wall=265, gb_free=8.1, wall=122143
2022-03-07 22:49:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:50:06 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 14.097 | nll_loss 13.842 | ppl 14680.2 | wps 44184.7 | wpb 510.9 | bsz 1 | num_updates 41059 | best_loss 7.706
2022-03-07 22:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 41059 updates
2022-03-07 22:50:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:50:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 426 @ 41059 updates, score 14.097) (writing took 2.2396049932576716 seconds)
2022-03-07 22:50:09 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 22:50:09 | INFO | train | epoch 426 | loss 1.05 | nll_loss 0.467 | ppl 1.38 | wps 22161.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41059 | lr 0.000156062 | gnorm 0.732 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 122321
2022-03-07 22:50:09 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 22:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:52:06 | INFO | train_inner | epoch 427:     41 / 97 loss=1.049, nll_loss=0.466, ppl=1.38, wps=22146.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41100, lr=0.000155984, gnorm=0.724, loss_scale=16, train_wall=265, gb_free=8.1, wall=122438
2022-03-07 22:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:54:51 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 14.068 | nll_loss 13.813 | ppl 14390.5 | wps 44311.7 | wpb 510.9 | bsz 1 | num_updates 41156 | best_loss 7.706
2022-03-07 22:54:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 41156 updates
2022-03-07 22:54:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:54:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 427 @ 41156 updates, score 14.068) (writing took 2.2596350060775876 seconds)
2022-03-07 22:54:53 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 22:54:53 | INFO | train | epoch 427 | loss 1.049 | nll_loss 0.466 | ppl 1.38 | wps 22330.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41156 | lr 0.000155877 | gnorm 0.73 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 122605
2022-03-07 22:54:53 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 22:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:56:59 | INFO | train_inner | epoch 428:     44 / 97 loss=1.05, nll_loss=0.467, ppl=1.38, wps=22363.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=41200, lr=0.000155794, gnorm=0.736, loss_scale=32, train_wall=263, gb_free=8.1, wall=122731
2022-03-07 22:59:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:59:35 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 14.117 | nll_loss 13.862 | ppl 14886.2 | wps 40495.7 | wpb 510.9 | bsz 1 | num_updates 41253 | best_loss 7.706
2022-03-07 22:59:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 41253 updates
2022-03-07 22:59:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 22:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 428 @ 41253 updates, score 14.117) (writing took 2.452380118891597 seconds)
2022-03-07 22:59:38 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 22:59:38 | INFO | train | epoch 428 | loss 1.049 | nll_loss 0.466 | ppl 1.38 | wps 22321.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41253 | lr 0.000155694 | gnorm 0.73 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 122890
2022-03-07 22:59:38 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 22:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:00:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:01:54 | INFO | train_inner | epoch 429:     48 / 97 loss=1.048, nll_loss=0.465, ppl=1.38, wps=22199.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41300, lr=0.000155606, gnorm=0.729, loss_scale=16, train_wall=264, gb_free=8.1, wall=123026
2022-03-07 23:04:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:04:19 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 14.045 | nll_loss 13.788 | ppl 14142.8 | wps 44400.5 | wpb 510.9 | bsz 1 | num_updates 41349 | best_loss 7.706
2022-03-07 23:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 41349 updates
2022-03-07 23:04:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:04:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:04:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 429 @ 41349 updates, score 14.045) (writing took 2.220344416797161 seconds)
2022-03-07 23:04:21 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 23:04:21 | INFO | train | epoch 429 | loss 1.048 | nll_loss 0.465 | ppl 1.38 | wps 22191.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41349 | lr 0.000155513 | gnorm 0.735 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 123173
2022-03-07 23:04:21 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 23:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:06:47 | INFO | train_inner | epoch 430:     51 / 97 loss=1.048, nll_loss=0.465, ppl=1.38, wps=22375.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41400, lr=0.000155417, gnorm=0.741, loss_scale=16, train_wall=263, gb_free=8.1, wall=123319
2022-03-07 23:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:09:03 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 14.112 | nll_loss 13.856 | ppl 14829.3 | wps 44156.7 | wpb 510.9 | bsz 1 | num_updates 41446 | best_loss 7.706
2022-03-07 23:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 41446 updates
2022-03-07 23:09:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 430 @ 41446 updates, score 14.112) (writing took 2.223442040849477 seconds)
2022-03-07 23:09:05 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 23:09:05 | INFO | train | epoch 430 | loss 1.047 | nll_loss 0.464 | ppl 1.38 | wps 22357.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41446 | lr 0.000155331 | gnorm 0.735 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 123457
2022-03-07 23:09:05 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 23:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:11:40 | INFO | train_inner | epoch 431:     54 / 97 loss=1.046, nll_loss=0.463, ppl=1.38, wps=22360.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41500, lr=0.00015523, gnorm=0.725, loss_scale=32, train_wall=263, gb_free=8.1, wall=123612
2022-03-07 23:12:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:13:47 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 14.08 | nll_loss 13.825 | ppl 14513.1 | wps 44286.7 | wpb 510.9 | bsz 1 | num_updates 41542 | best_loss 7.706
2022-03-07 23:13:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 41542 updates
2022-03-07 23:13:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:13:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:13:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 431 @ 41542 updates, score 14.08) (writing took 2.2216056217439473 seconds)
2022-03-07 23:13:50 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 23:13:50 | INFO | train | epoch 431 | loss 1.046 | nll_loss 0.463 | ppl 1.38 | wps 22108.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41542 | lr 0.000155152 | gnorm 0.725 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 123742
2022-03-07 23:13:50 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 23:13:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:16:35 | INFO | train_inner | epoch 432:     58 / 97 loss=1.046, nll_loss=0.464, ppl=1.38, wps=22151.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=41600, lr=0.000155043, gnorm=0.729, loss_scale=16, train_wall=265, gb_free=8.1, wall=123907
2022-03-07 23:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:18:31 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 14.083 | nll_loss 13.83 | ppl 14558.8 | wps 44684.8 | wpb 510.9 | bsz 1 | num_updates 41639 | best_loss 7.706
2022-03-07 23:18:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 41639 updates
2022-03-07 23:18:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:18:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 432 @ 41639 updates, score 14.083) (writing took 2.2697193562053144 seconds)
2022-03-07 23:18:33 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 23:18:33 | INFO | train | epoch 432 | loss 1.046 | nll_loss 0.463 | ppl 1.38 | wps 22422 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41639 | lr 0.000154971 | gnorm 0.731 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 124025
2022-03-07 23:18:33 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 23:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:21:27 | INFO | train_inner | epoch 433:     61 / 97 loss=1.045, nll_loss=0.462, ppl=1.38, wps=22452.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41700, lr=0.000154857, gnorm=0.728, loss_scale=32, train_wall=262, gb_free=8.1, wall=124199
2022-03-07 23:21:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:23:15 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 14.041 | nll_loss 13.786 | ppl 14122.5 | wps 44267 | wpb 510.9 | bsz 1 | num_updates 41735 | best_loss 7.706
2022-03-07 23:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 41735 updates
2022-03-07 23:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 433 @ 41735 updates, score 14.041) (writing took 2.2270953496918082 seconds)
2022-03-07 23:23:17 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 23:23:17 | INFO | train | epoch 433 | loss 1.045 | nll_loss 0.462 | ppl 1.38 | wps 22125.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41735 | lr 0.000154792 | gnorm 0.732 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 124309
2022-03-07 23:23:17 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 23:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:26:23 | INFO | train_inner | epoch 434:     65 / 97 loss=1.045, nll_loss=0.462, ppl=1.38, wps=22158.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41800, lr=0.000154672, gnorm=0.731, loss_scale=16, train_wall=265, gb_free=8.1, wall=124495
2022-03-07 23:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:27:59 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 14.065 | nll_loss 13.81 | ppl 14364.3 | wps 44382.7 | wpb 510.9 | bsz 1 | num_updates 41832 | best_loss 7.706
2022-03-07 23:27:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 41832 updates
2022-03-07 23:27:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:28:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 434 @ 41832 updates, score 14.065) (writing took 2.2521732840687037 seconds)
2022-03-07 23:28:01 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 23:28:01 | INFO | train | epoch 434 | loss 1.044 | nll_loss 0.461 | ppl 1.38 | wps 22346.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41832 | lr 0.000154613 | gnorm 0.725 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 124593
2022-03-07 23:28:01 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 23:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:31:15 | INFO | train_inner | epoch 435:     68 / 97 loss=1.045, nll_loss=0.462, ppl=1.38, wps=22371.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41900, lr=0.000154487, gnorm=0.727, loss_scale=32, train_wall=263, gb_free=8.1, wall=124787
2022-03-07 23:32:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:32:42 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 14.091 | nll_loss 13.837 | ppl 14635.6 | wps 44213.1 | wpb 510.9 | bsz 1 | num_updates 41929 | best_loss 7.706
2022-03-07 23:32:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 41929 updates
2022-03-07 23:32:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:32:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:32:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 435 @ 41929 updates, score 14.091) (writing took 2.269081291742623 seconds)
2022-03-07 23:32:45 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 23:32:45 | INFO | train | epoch 435 | loss 1.044 | nll_loss 0.462 | ppl 1.38 | wps 22421.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41929 | lr 0.000154434 | gnorm 0.728 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 124877
2022-03-07 23:32:45 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 23:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:34:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:36:11 | INFO | train_inner | epoch 436:     72 / 97 loss=1.044, nll_loss=0.461, ppl=1.38, wps=22165, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42000, lr=0.000154303, gnorm=0.725, loss_scale=32, train_wall=265, gb_free=8.1, wall=125083
2022-03-07 23:37:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:37:26 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 14.044 | nll_loss 13.79 | ppl 14162.8 | wps 44315.8 | wpb 510.9 | bsz 1 | num_updates 42025 | best_loss 7.706
2022-03-07 23:37:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 42025 updates
2022-03-07 23:37:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:37:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 436 @ 42025 updates, score 14.044) (writing took 2.2211271040141582 seconds)
2022-03-07 23:37:29 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 23:37:29 | INFO | train | epoch 436 | loss 1.043 | nll_loss 0.46 | ppl 1.38 | wps 22138.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42025 | lr 0.000154257 | gnorm 0.725 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 125161
2022-03-07 23:37:29 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 23:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:38:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:41:05 | INFO | train_inner | epoch 437:     76 / 97 loss=1.042, nll_loss=0.459, ppl=1.37, wps=22239, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42100, lr=0.00015412, gnorm=0.727, loss_scale=16, train_wall=264, gb_free=8.1, wall=125377
2022-03-07 23:42:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:42:11 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 14.215 | nll_loss 13.962 | ppl 15961.4 | wps 44235.7 | wpb 510.9 | bsz 1 | num_updates 42121 | best_loss 7.706
2022-03-07 23:42:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 42121 updates
2022-03-07 23:42:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:42:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:42:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 437 @ 42121 updates, score 14.215) (writing took 2.1967296260409057 seconds)
2022-03-07 23:42:13 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 23:42:13 | INFO | train | epoch 437 | loss 1.042 | nll_loss 0.459 | ppl 1.37 | wps 22131.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42121 | lr 0.000154082 | gnorm 0.73 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 125445
2022-03-07 23:42:13 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 23:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:45:58 | INFO | train_inner | epoch 438:     79 / 97 loss=1.043, nll_loss=0.46, ppl=1.38, wps=22392.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42200, lr=0.000153937, gnorm=0.731, loss_scale=32, train_wall=263, gb_free=8.1, wall=125670
2022-03-07 23:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:54 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 14.089 | nll_loss 13.836 | ppl 14619.8 | wps 39952.9 | wpb 510.9 | bsz 1 | num_updates 42218 | best_loss 7.706
2022-03-07 23:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 42218 updates
2022-03-07 23:46:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 438 @ 42218 updates, score 14.089) (writing took 2.3701436948031187 seconds)
2022-03-07 23:46:57 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 23:46:57 | INFO | train | epoch 438 | loss 1.042 | nll_loss 0.459 | ppl 1.37 | wps 22383.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42218 | lr 0.000153904 | gnorm 0.727 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 125729
2022-03-07 23:46:57 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 23:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:51 | INFO | train_inner | epoch 439:     82 / 97 loss=1.042, nll_loss=0.46, ppl=1.38, wps=22353.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42300, lr=0.000153755, gnorm=0.727, loss_scale=32, train_wall=262, gb_free=8.1, wall=125963
2022-03-07 23:51:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:51:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:51:38 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 14.131 | nll_loss 13.876 | ppl 15038 | wps 44314.8 | wpb 510.9 | bsz 1 | num_updates 42314 | best_loss 7.706
2022-03-07 23:51:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 42314 updates
2022-03-07 23:51:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:51:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:51:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 439 @ 42314 updates, score 14.131) (writing took 2.2614304861053824 seconds)
2022-03-07 23:51:40 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 23:51:40 | INFO | train | epoch 439 | loss 1.041 | nll_loss 0.459 | ppl 1.37 | wps 22157.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42314 | lr 0.00015373 | gnorm 0.728 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126012
2022-03-07 23:51:40 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 23:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:55:46 | INFO | train_inner | epoch 440:     86 / 97 loss=1.041, nll_loss=0.459, ppl=1.37, wps=22152.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42400, lr=0.000153574, gnorm=0.731, loss_scale=16, train_wall=265, gb_free=8.1, wall=126258
2022-03-07 23:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:56:22 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 14.098 | nll_loss 13.843 | ppl 14695 | wps 44127 | wpb 510.9 | bsz 1 | num_updates 42411 | best_loss 7.706
2022-03-07 23:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 42411 updates
2022-03-07 23:56:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-07 23:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 440 @ 42411 updates, score 14.098) (writing took 2.2368039838038385 seconds)
2022-03-07 23:56:25 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 23:56:25 | INFO | train | epoch 440 | loss 1.041 | nll_loss 0.458 | ppl 1.37 | wps 22338 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42411 | lr 0.000153554 | gnorm 0.726 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126297
2022-03-07 23:56:25 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 23:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:00:38 | INFO | train_inner | epoch 441:     89 / 97 loss=1.04, nll_loss=0.457, ppl=1.37, wps=22450.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42500, lr=0.000153393, gnorm=0.719, loss_scale=32, train_wall=262, gb_free=8.1, wall=126550
2022-03-08 00:00:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:01:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:01:07 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 14.142 | nll_loss 13.888 | ppl 15157.5 | wps 40551.2 | wpb 510.9 | bsz 1 | num_updates 42507 | best_loss 7.706
2022-03-08 00:01:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 42507 updates
2022-03-08 00:01:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 441 @ 42507 updates, score 14.142) (writing took 2.274369254242629 seconds)
2022-03-08 00:01:09 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-08 00:01:09 | INFO | train | epoch 441 | loss 1.039 | nll_loss 0.457 | ppl 1.37 | wps 22124.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42507 | lr 0.00015338 | gnorm 0.72 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126581
2022-03-08 00:01:09 | INFO | fairseq.trainer | begin training epoch 442
2022-03-08 00:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:05:34 | INFO | train_inner | epoch 442:     93 / 97 loss=1.04, nll_loss=0.457, ppl=1.37, wps=22137.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42600, lr=0.000153213, gnorm=0.72, loss_scale=16, train_wall=265, gb_free=8.1, wall=126846
2022-03-08 00:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:05:50 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 14.132 | nll_loss 13.879 | ppl 15066.9 | wps 44412.7 | wpb 510.9 | bsz 1 | num_updates 42604 | best_loss 7.706
2022-03-08 00:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 42604 updates
2022-03-08 00:05:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 442 @ 42604 updates, score 14.132) (writing took 2.2352804713882506 seconds)
2022-03-08 00:05:52 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-08 00:05:52 | INFO | train | epoch 442 | loss 1.039 | nll_loss 0.457 | ppl 1.37 | wps 22410.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42604 | lr 0.000153206 | gnorm 0.72 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 126864
2022-03-08 00:05:52 | INFO | fairseq.trainer | begin training epoch 443
2022-03-08 00:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:10:27 | INFO | train_inner | epoch 443:     96 / 97 loss=1.041, nll_loss=0.458, ppl=1.37, wps=22362.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42700, lr=0.000153033, gnorm=0.722, loss_scale=32, train_wall=263, gb_free=8.1, wall=127139
2022-03-08 00:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:10:34 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 14.109 | nll_loss 13.855 | ppl 14818.9 | wps 44297.6 | wpb 510.9 | bsz 1 | num_updates 42701 | best_loss 7.706
2022-03-08 00:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 42701 updates
2022-03-08 00:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:10:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:10:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 443 @ 42701 updates, score 14.109) (writing took 2.217772220261395 seconds)
2022-03-08 00:10:37 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-08 00:10:37 | INFO | train | epoch 443 | loss 1.04 | nll_loss 0.458 | ppl 1.37 | wps 22341.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42701 | lr 0.000153032 | gnorm 0.722 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 127149
2022-03-08 00:10:37 | INFO | fairseq.trainer | begin training epoch 444
2022-03-08 00:10:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:13:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:15:19 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 14.108 | nll_loss 13.857 | ppl 14834.7 | wps 43938.8 | wpb 510.9 | bsz 1 | num_updates 42797 | best_loss 7.706
2022-03-08 00:15:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 42797 updates
2022-03-08 00:15:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:15:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:15:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 444 @ 42797 updates, score 14.108) (writing took 2.2449007858522236 seconds)
2022-03-08 00:15:21 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-08 00:15:21 | INFO | train | epoch 444 | loss 1.038 | nll_loss 0.456 | ppl 1.37 | wps 22119.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42797 | lr 0.00015286 | gnorm 0.727 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 127433
2022-03-08 00:15:21 | INFO | fairseq.trainer | begin training epoch 445
2022-03-08 00:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:15:30 | INFO | train_inner | epoch 445:      3 / 97 loss=1.038, nll_loss=0.456, ppl=1.37, wps=21624, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=42800, lr=0.000152854, gnorm=0.726, loss_scale=16, train_wall=265, gb_free=8.1, wall=127442
2022-03-08 00:19:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:20:02 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 14.081 | nll_loss 13.827 | ppl 14537.5 | wps 44198.7 | wpb 510.9 | bsz 1 | num_updates 42894 | best_loss 7.706
2022-03-08 00:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 42894 updates
2022-03-08 00:20:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 445 @ 42894 updates, score 14.081) (writing took 2.2191011351533234 seconds)
2022-03-08 00:20:04 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-08 00:20:04 | INFO | train | epoch 445 | loss 1.039 | nll_loss 0.456 | ppl 1.37 | wps 22421.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42894 | lr 0.000152687 | gnorm 0.724 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 127716
2022-03-08 00:20:04 | INFO | fairseq.trainer | begin training epoch 446
2022-03-08 00:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:20:21 | INFO | train_inner | epoch 446:      6 / 97 loss=1.038, nll_loss=0.456, ppl=1.37, wps=22441.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42900, lr=0.000152676, gnorm=0.723, loss_scale=32, train_wall=262, gb_free=8.1, wall=127733
2022-03-08 00:24:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:24:47 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 14.083 | nll_loss 13.829 | ppl 14550.5 | wps 44271.1 | wpb 510.9 | bsz 1 | num_updates 42991 | best_loss 7.706
2022-03-08 00:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 42991 updates
2022-03-08 00:24:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:24:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 446 @ 42991 updates, score 14.083) (writing took 2.215850709937513 seconds)
2022-03-08 00:24:49 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-08 00:24:49 | INFO | train | epoch 446 | loss 1.038 | nll_loss 0.456 | ppl 1.37 | wps 22325.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42991 | lr 0.000152515 | gnorm 0.718 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 128001
2022-03-08 00:24:49 | INFO | fairseq.trainer | begin training epoch 447
2022-03-08 00:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:25:14 | INFO | train_inner | epoch 447:      9 / 97 loss=1.038, nll_loss=0.455, ppl=1.37, wps=22347.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43000, lr=0.000152499, gnorm=0.72, loss_scale=32, train_wall=263, gb_free=8.1, wall=128026
2022-03-08 00:25:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:27:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:29:31 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 14.132 | nll_loss 13.879 | ppl 15063.1 | wps 44030.8 | wpb 510.9 | bsz 1 | num_updates 43086 | best_loss 7.706
2022-03-08 00:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 43086 updates
2022-03-08 00:29:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 447 @ 43086 updates, score 14.132) (writing took 2.260768303181976 seconds)
2022-03-08 00:29:33 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-08 00:29:33 | INFO | train | epoch 447 | loss 1.036 | nll_loss 0.454 | ppl 1.37 | wps 21872.6 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 43086 | lr 0.000152346 | gnorm 0.728 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 128285
2022-03-08 00:29:33 | INFO | fairseq.trainer | begin training epoch 448
2022-03-08 00:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:30:13 | INFO | train_inner | epoch 448:     14 / 97 loss=1.035, nll_loss=0.453, ppl=1.37, wps=21929.9, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=43100, lr=0.000152322, gnorm=0.725, loss_scale=16, train_wall=268, gb_free=8.1, wall=128325
2022-03-08 00:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:34:15 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 14.12 | nll_loss 13.868 | ppl 14954.2 | wps 44086.8 | wpb 510.9 | bsz 1 | num_updates 43183 | best_loss 7.706
2022-03-08 00:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 43183 updates
2022-03-08 00:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:34:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:34:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 448 @ 43183 updates, score 14.12) (writing took 2.211889375001192 seconds)
2022-03-08 00:34:17 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-08 00:34:17 | INFO | train | epoch 448 | loss 1.036 | nll_loss 0.453 | ppl 1.37 | wps 22407.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43183 | lr 0.000152175 | gnorm 0.724 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 128569
2022-03-08 00:34:17 | INFO | fairseq.trainer | begin training epoch 449
2022-03-08 00:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:06 | INFO | train_inner | epoch 449:     17 / 97 loss=1.035, nll_loss=0.453, ppl=1.37, wps=22351.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=43200, lr=0.000152145, gnorm=0.725, loss_scale=32, train_wall=263, gb_free=8.1, wall=128618
2022-03-08 00:35:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:38:59 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 14.106 | nll_loss 13.852 | ppl 14783.3 | wps 44083.2 | wpb 510.9 | bsz 1 | num_updates 43279 | best_loss 7.706
2022-03-08 00:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 43279 updates
2022-03-08 00:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:39:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 449 @ 43279 updates, score 14.106) (writing took 2.297856651712209 seconds)
2022-03-08 00:39:01 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-08 00:39:01 | INFO | train | epoch 449 | loss 1.035 | nll_loss 0.452 | ppl 1.37 | wps 22104.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43279 | lr 0.000152006 | gnorm 0.723 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 128853
2022-03-08 00:39:01 | INFO | fairseq.trainer | begin training epoch 450
2022-03-08 00:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:40:01 | INFO | train_inner | epoch 450:     21 / 97 loss=1.035, nll_loss=0.453, ppl=1.37, wps=22204.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43300, lr=0.000151969, gnorm=0.723, loss_scale=16, train_wall=265, gb_free=8.1, wall=128913
2022-03-08 00:43:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:43:43 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 14.098 | nll_loss 13.845 | ppl 14719.9 | wps 44124.9 | wpb 510.9 | bsz 1 | num_updates 43376 | best_loss 7.706
2022-03-08 00:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 43376 updates
2022-03-08 00:43:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 450 @ 43376 updates, score 14.098) (writing took 2.268447006121278 seconds)
2022-03-08 00:43:45 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-08 00:43:45 | INFO | train | epoch 450 | loss 1.035 | nll_loss 0.452 | ppl 1.37 | wps 22353.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43376 | lr 0.000151836 | gnorm 0.716 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 129137
2022-03-08 00:43:45 | INFO | fairseq.trainer | begin training epoch 451
2022-03-08 00:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:44:54 | INFO | train_inner | epoch 451:     24 / 97 loss=1.034, nll_loss=0.452, ppl=1.37, wps=22393, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43400, lr=0.000151794, gnorm=0.714, loss_scale=32, train_wall=263, gb_free=8.1, wall=129206
2022-03-08 00:47:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:48:27 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 14.092 | nll_loss 13.84 | ppl 14662.3 | wps 39337.9 | wpb 510.9 | bsz 1 | num_updates 43472 | best_loss 7.706
2022-03-08 00:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 43472 updates
2022-03-08 00:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:48:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:48:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 451 @ 43472 updates, score 14.092) (writing took 2.365016421303153 seconds)
2022-03-08 00:48:29 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-08 00:48:29 | INFO | train | epoch 451 | loss 1.033 | nll_loss 0.451 | ppl 1.37 | wps 22141.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43472 | lr 0.000151668 | gnorm 0.716 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 129421
2022-03-08 00:48:29 | INFO | fairseq.trainer | begin training epoch 452
2022-03-08 00:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:49:49 | INFO | train_inner | epoch 452:     28 / 97 loss=1.032, nll_loss=0.45, ppl=1.37, wps=22134.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43500, lr=0.00015162, gnorm=0.711, loss_scale=32, train_wall=265, gb_free=8.1, wall=129501
2022-03-08 00:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:53:11 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 14.213 | nll_loss 13.961 | ppl 15951.6 | wps 43859.3 | wpb 510.9 | bsz 1 | num_updates 43569 | best_loss 7.706
2022-03-08 00:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 43569 updates
2022-03-08 00:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 452 @ 43569 updates, score 14.213) (writing took 2.2648889697156847 seconds)
2022-03-08 00:53:13 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-08 00:53:13 | INFO | train | epoch 452 | loss 1.033 | nll_loss 0.451 | ppl 1.37 | wps 22381.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43569 | lr 0.0001515 | gnorm 0.715 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 129705
2022-03-08 00:53:13 | INFO | fairseq.trainer | begin training epoch 453
2022-03-08 00:53:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:54:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:54:45 | INFO | train_inner | epoch 453:     32 / 97 loss=1.032, nll_loss=0.45, ppl=1.37, wps=22159.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43600, lr=0.000151446, gnorm=0.718, loss_scale=32, train_wall=265, gb_free=8.1, wall=129797
2022-03-08 00:56:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:57:55 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 14.163 | nll_loss 13.91 | ppl 15395.2 | wps 44178.2 | wpb 510.9 | bsz 1 | num_updates 43664 | best_loss 7.706
2022-03-08 00:57:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 43664 updates
2022-03-08 00:57:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 00:57:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 453 @ 43664 updates, score 14.163) (writing took 2.3509254888631403 seconds)
2022-03-08 00:57:58 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-08 00:57:58 | INFO | train | epoch 453 | loss 1.033 | nll_loss 0.451 | ppl 1.37 | wps 21881.7 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 43664 | lr 0.000151335 | gnorm 0.724 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129990
2022-03-08 00:57:58 | INFO | fairseq.trainer | begin training epoch 454
2022-03-08 00:57:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:59:40 | INFO | train_inner | epoch 454:     36 / 97 loss=1.033, nll_loss=0.451, ppl=1.37, wps=22188.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=43700, lr=0.000151272, gnorm=0.724, loss_scale=16, train_wall=265, gb_free=8.1, wall=130092
2022-03-08 01:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:02:40 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 14.131 | nll_loss 13.88 | ppl 15073.9 | wps 40521.4 | wpb 510.9 | bsz 1 | num_updates 43761 | best_loss 7.706
2022-03-08 01:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 43761 updates
2022-03-08 01:02:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 454 @ 43761 updates, score 14.131) (writing took 2.402836489956826 seconds)
2022-03-08 01:02:42 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-08 01:02:42 | INFO | train | epoch 454 | loss 1.031 | nll_loss 0.449 | ppl 1.37 | wps 22325.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43761 | lr 0.000151167 | gnorm 0.717 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 130274
2022-03-08 01:02:42 | INFO | fairseq.trainer | begin training epoch 455
2022-03-08 01:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:04:33 | INFO | train_inner | epoch 455:     39 / 97 loss=1.031, nll_loss=0.448, ppl=1.36, wps=22369.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43800, lr=0.000151099, gnorm=0.717, loss_scale=32, train_wall=262, gb_free=8.1, wall=130385
2022-03-08 01:05:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:23 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 14.114 | nll_loss 13.861 | ppl 14875.8 | wps 44345.1 | wpb 510.9 | bsz 1 | num_updates 43857 | best_loss 7.706
2022-03-08 01:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 43857 updates
2022-03-08 01:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:07:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:07:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 455 @ 43857 updates, score 14.114) (writing took 2.3193130306899548 seconds)
2022-03-08 01:07:26 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-08 01:07:26 | INFO | train | epoch 455 | loss 1.031 | nll_loss 0.449 | ppl 1.36 | wps 22182.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43857 | lr 0.000151001 | gnorm 0.717 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 130558
2022-03-08 01:07:26 | INFO | fairseq.trainer | begin training epoch 456
2022-03-08 01:07:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:09:28 | INFO | train_inner | epoch 456:     43 / 97 loss=1.031, nll_loss=0.449, ppl=1.37, wps=22158.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=43900, lr=0.000150927, gnorm=0.716, loss_scale=16, train_wall=265, gb_free=8.1, wall=130681
2022-03-08 01:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:12:08 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 14.146 | nll_loss 13.893 | ppl 15210.4 | wps 44090.9 | wpb 510.9 | bsz 1 | num_updates 43954 | best_loss 7.706
2022-03-08 01:12:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 43954 updates
2022-03-08 01:12:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:12:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 456 @ 43954 updates, score 14.146) (writing took 2.2640612577088177 seconds)
2022-03-08 01:12:10 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-08 01:12:10 | INFO | train | epoch 456 | loss 1.031 | nll_loss 0.449 | ppl 1.36 | wps 22338.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43954 | lr 0.000150835 | gnorm 0.721 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 130842
2022-03-08 01:12:10 | INFO | fairseq.trainer | begin training epoch 457
2022-03-08 01:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:14:21 | INFO | train_inner | epoch 457:     46 / 97 loss=1.031, nll_loss=0.449, ppl=1.36, wps=22361, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44000, lr=0.000150756, gnorm=0.721, loss_scale=32, train_wall=263, gb_free=8.1, wall=130973
2022-03-08 01:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:16:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:16:52 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 14.134 | nll_loss 13.883 | ppl 15109.9 | wps 44242 | wpb 510.9 | bsz 1 | num_updates 44050 | best_loss 7.706
2022-03-08 01:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 44050 updates
2022-03-08 01:16:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:16:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:16:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 457 @ 44050 updates, score 14.134) (writing took 2.2793739163316786 seconds)
2022-03-08 01:16:54 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-08 01:16:54 | INFO | train | epoch 457 | loss 1.03 | nll_loss 0.448 | ppl 1.36 | wps 22134.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44050 | lr 0.00015067 | gnorm 0.715 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131126
2022-03-08 01:16:54 | INFO | fairseq.trainer | begin training epoch 458
2022-03-08 01:16:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:19:16 | INFO | train_inner | epoch 458:     50 / 97 loss=1.029, nll_loss=0.447, ppl=1.36, wps=22204.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44100, lr=0.000150585, gnorm=0.712, loss_scale=16, train_wall=265, gb_free=8.1, wall=131268
2022-03-08 01:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:21:35 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 14.1 | nll_loss 13.848 | ppl 14747.8 | wps 44220.4 | wpb 510.9 | bsz 1 | num_updates 44147 | best_loss 7.706
2022-03-08 01:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 44147 updates
2022-03-08 01:21:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 458 @ 44147 updates, score 14.1) (writing took 2.3206625329330564 seconds)
2022-03-08 01:21:37 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-08 01:21:37 | INFO | train | epoch 458 | loss 1.03 | nll_loss 0.448 | ppl 1.36 | wps 22411.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44147 | lr 0.000150504 | gnorm 0.716 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 131409
2022-03-08 01:21:37 | INFO | fairseq.trainer | begin training epoch 459
2022-03-08 01:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:23:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:24:12 | INFO | train_inner | epoch 459:     54 / 97 loss=1.03, nll_loss=0.448, ppl=1.36, wps=22175.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44200, lr=0.000150414, gnorm=0.719, loss_scale=16, train_wall=265, gb_free=8.1, wall=131564
2022-03-08 01:26:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:26:19 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 14.132 | nll_loss 13.881 | ppl 15088.7 | wps 44167.9 | wpb 510.9 | bsz 1 | num_updates 44243 | best_loss 7.706
2022-03-08 01:26:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 44243 updates
2022-03-08 01:26:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 459 @ 44243 updates, score 14.132) (writing took 2.308241978753358 seconds)
2022-03-08 01:26:22 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-08 01:26:22 | INFO | train | epoch 459 | loss 1.03 | nll_loss 0.448 | ppl 1.36 | wps 22111.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44243 | lr 0.000150341 | gnorm 0.718 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131694
2022-03-08 01:26:22 | INFO | fairseq.trainer | begin training epoch 460
2022-03-08 01:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:29:04 | INFO | train_inner | epoch 460:     57 / 97 loss=1.03, nll_loss=0.449, ppl=1.36, wps=22364.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44300, lr=0.000150244, gnorm=0.722, loss_scale=16, train_wall=263, gb_free=8.1, wall=131857
2022-03-08 01:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:31:04 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 14.114 | nll_loss 13.861 | ppl 14878.2 | wps 44305.9 | wpb 510.9 | bsz 1 | num_updates 44340 | best_loss 7.706
2022-03-08 01:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 44340 updates
2022-03-08 01:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 460 @ 44340 updates, score 14.114) (writing took 2.275562698021531 seconds)
2022-03-08 01:31:06 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-08 01:31:06 | INFO | train | epoch 460 | loss 1.03 | nll_loss 0.448 | ppl 1.36 | wps 22342.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44340 | lr 0.000150177 | gnorm 0.722 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 131978
2022-03-08 01:31:06 | INFO | fairseq.trainer | begin training epoch 461
2022-03-08 01:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:31:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:34:00 | INFO | train_inner | epoch 461:     61 / 97 loss=1.028, nll_loss=0.446, ppl=1.36, wps=22162.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44400, lr=0.000150075, gnorm=0.721, loss_scale=16, train_wall=265, gb_free=8.1, wall=132152
2022-03-08 01:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:35:47 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 14.155 | nll_loss 13.905 | ppl 15338.5 | wps 44113.6 | wpb 510.9 | bsz 1 | num_updates 44436 | best_loss 7.706
2022-03-08 01:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 44436 updates
2022-03-08 01:35:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:35:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 461 @ 44436 updates, score 14.155) (writing took 2.3150712461210787 seconds)
2022-03-08 01:35:49 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-08 01:35:49 | INFO | train | epoch 461 | loss 1.028 | nll_loss 0.447 | ppl 1.36 | wps 22203.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44436 | lr 0.000150014 | gnorm 0.722 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 132261
2022-03-08 01:35:49 | INFO | fairseq.trainer | begin training epoch 462
2022-03-08 01:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:38:52 | INFO | train_inner | epoch 462:     64 / 97 loss=1.028, nll_loss=0.446, ppl=1.36, wps=22448, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44500, lr=0.000149906, gnorm=0.716, loss_scale=32, train_wall=262, gb_free=8.1, wall=132444
2022-03-08 01:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:40:31 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 14.13 | nll_loss 13.878 | ppl 15057.9 | wps 44322.7 | wpb 510.9 | bsz 1 | num_updates 44533 | best_loss 7.706
2022-03-08 01:40:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 44533 updates
2022-03-08 01:40:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:40:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:40:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 462 @ 44533 updates, score 14.13) (writing took 2.266928542871028 seconds)
2022-03-08 01:40:33 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-08 01:40:33 | INFO | train | epoch 462 | loss 1.028 | nll_loss 0.446 | ppl 1.36 | wps 22359.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44533 | lr 0.000149851 | gnorm 0.715 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 132545
2022-03-08 01:40:33 | INFO | fairseq.trainer | begin training epoch 463
2022-03-08 01:40:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:43:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:43:47 | INFO | train_inner | epoch 463:     68 / 97 loss=1.028, nll_loss=0.447, ppl=1.36, wps=22158.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44600, lr=0.000149738, gnorm=0.715, loss_scale=32, train_wall=265, gb_free=8.1, wall=132739
2022-03-08 01:44:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:45:15 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 14.095 | nll_loss 13.844 | ppl 14701.7 | wps 44117.5 | wpb 510.9 | bsz 1 | num_updates 44628 | best_loss 7.706
2022-03-08 01:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 44628 updates
2022-03-08 01:45:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:45:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 463 @ 44628 updates, score 14.095) (writing took 2.3332539829425514 seconds)
2022-03-08 01:45:18 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-08 01:45:18 | INFO | train | epoch 463 | loss 1.027 | nll_loss 0.445 | ppl 1.36 | wps 21876.3 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 44628 | lr 0.000149691 | gnorm 0.711 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132830
2022-03-08 01:45:18 | INFO | fairseq.trainer | begin training epoch 464
2022-03-08 01:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:48:43 | INFO | train_inner | epoch 464:     72 / 97 loss=1.026, nll_loss=0.444, ppl=1.36, wps=22138.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=44700, lr=0.000149571, gnorm=0.713, loss_scale=16, train_wall=265, gb_free=8.1, wall=133035
2022-03-08 01:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:49:59 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 14.112 | nll_loss 13.86 | ppl 14866 | wps 43590.2 | wpb 510.9 | bsz 1 | num_updates 44725 | best_loss 7.706
2022-03-08 01:49:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 44725 updates
2022-03-08 01:49:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 464 @ 44725 updates, score 14.112) (writing took 2.2671931590884924 seconds)
2022-03-08 01:50:01 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-08 01:50:01 | INFO | train | epoch 464 | loss 1.026 | nll_loss 0.444 | ppl 1.36 | wps 22407.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44725 | lr 0.000149529 | gnorm 0.715 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 133113
2022-03-08 01:50:01 | INFO | fairseq.trainer | begin training epoch 465
2022-03-08 01:50:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:53:36 | INFO | train_inner | epoch 465:     75 / 97 loss=1.026, nll_loss=0.445, ppl=1.36, wps=22363.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44800, lr=0.000149404, gnorm=0.712, loss_scale=32, train_wall=263, gb_free=8.1, wall=133328
2022-03-08 01:54:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:54:43 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 14.203 | nll_loss 13.954 | ppl 15870.3 | wps 44100.2 | wpb 510.9 | bsz 1 | num_updates 44822 | best_loss 7.706
2022-03-08 01:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 44822 updates
2022-03-08 01:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:54:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 465 @ 44822 updates, score 14.203) (writing took 2.2558623836375773 seconds)
2022-03-08 01:54:45 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-08 01:54:45 | INFO | train | epoch 465 | loss 1.026 | nll_loss 0.444 | ppl 1.36 | wps 22351.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44822 | lr 0.000149367 | gnorm 0.71 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 133398
2022-03-08 01:54:45 | INFO | fairseq.trainer | begin training epoch 466
2022-03-08 01:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:55:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:58:31 | INFO | train_inner | epoch 466:     79 / 97 loss=1.026, nll_loss=0.444, ppl=1.36, wps=22232.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44900, lr=0.000149237, gnorm=0.715, loss_scale=16, train_wall=265, gb_free=8.1, wall=133623
2022-03-08 01:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:59:28 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 14.129 | nll_loss 13.876 | ppl 15037.3 | wps 44079.3 | wpb 510.9 | bsz 1 | num_updates 44918 | best_loss 7.706
2022-03-08 01:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 44918 updates
2022-03-08 01:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 01:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 466 @ 44918 updates, score 14.129) (writing took 2.3033034969121218 seconds)
2022-03-08 01:59:30 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-08 01:59:30 | INFO | train | epoch 466 | loss 1.026 | nll_loss 0.444 | ppl 1.36 | wps 22109.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44918 | lr 0.000149207 | gnorm 0.715 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133682
2022-03-08 01:59:30 | INFO | fairseq.trainer | begin training epoch 467
2022-03-08 01:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:03:24 | INFO | train_inner | epoch 467:     82 / 97 loss=1.026, nll_loss=0.444, ppl=1.36, wps=22358, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45000, lr=0.000149071, gnorm=0.716, loss_scale=32, train_wall=263, gb_free=8.1, wall=133916
2022-03-08 02:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:04:11 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 14.146 | nll_loss 13.895 | ppl 15231.5 | wps 44294.2 | wpb 510.9 | bsz 1 | num_updates 45015 | best_loss 7.706
2022-03-08 02:04:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 45015 updates
2022-03-08 02:04:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:04:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:04:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 467 @ 45015 updates, score 14.146) (writing took 2.2742893109098077 seconds)
2022-03-08 02:04:13 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-08 02:04:13 | INFO | train | epoch 467 | loss 1.025 | nll_loss 0.443 | ppl 1.36 | wps 22417.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45015 | lr 0.000149046 | gnorm 0.715 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 133965
2022-03-08 02:04:13 | INFO | fairseq.trainer | begin training epoch 468
2022-03-08 02:04:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:08:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:08:19 | INFO | train_inner | epoch 468:     86 / 97 loss=1.025, nll_loss=0.444, ppl=1.36, wps=22162.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45100, lr=0.000148906, gnorm=0.713, loss_scale=32, train_wall=265, gb_free=8.1, wall=134211
2022-03-08 02:08:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:55 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 14.135 | nll_loss 13.883 | ppl 15111.6 | wps 44323.7 | wpb 510.9 | bsz 1 | num_updates 45111 | best_loss 7.706
2022-03-08 02:08:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 45111 updates
2022-03-08 02:08:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:08:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 468 @ 45111 updates, score 14.135) (writing took 2.286669463850558 seconds)
2022-03-08 02:08:57 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-08 02:08:57 | INFO | train | epoch 468 | loss 1.025 | nll_loss 0.443 | ppl 1.36 | wps 22128 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45111 | lr 0.000148888 | gnorm 0.712 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 134249
2022-03-08 02:08:57 | INFO | fairseq.trainer | begin training epoch 469
2022-03-08 02:08:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:13:12 | INFO | train_inner | epoch 469:     89 / 97 loss=1.023, nll_loss=0.442, ppl=1.36, wps=22369.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45200, lr=0.000148741, gnorm=0.708, loss_scale=32, train_wall=263, gb_free=8.1, wall=134504
2022-03-08 02:13:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:13:39 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 14.136 | nll_loss 13.885 | ppl 15129.5 | wps 44025.9 | wpb 510.9 | bsz 1 | num_updates 45207 | best_loss 7.706
2022-03-08 02:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 45207 updates
2022-03-08 02:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:13:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:13:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 469 @ 45207 updates, score 14.136) (writing took 2.2683240096084774 seconds)
2022-03-08 02:13:42 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-08 02:13:42 | INFO | train | epoch 469 | loss 1.023 | nll_loss 0.441 | ppl 1.36 | wps 22117.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45207 | lr 0.00014873 | gnorm 0.71 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134534
2022-03-08 02:13:42 | INFO | fairseq.trainer | begin training epoch 470
2022-03-08 02:13:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:18:07 | INFO | train_inner | epoch 470:     93 / 97 loss=1.023, nll_loss=0.442, ppl=1.36, wps=22209.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45300, lr=0.000148577, gnorm=0.711, loss_scale=16, train_wall=265, gb_free=8.1, wall=134799
2022-03-08 02:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:18:23 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 14.108 | nll_loss 13.856 | ppl 14832.8 | wps 39752.6 | wpb 510.9 | bsz 1 | num_updates 45304 | best_loss 7.706
2022-03-08 02:18:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 45304 updates
2022-03-08 02:18:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:18:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:18:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 470 @ 45304 updates, score 14.108) (writing took 2.467120344284922 seconds)
2022-03-08 02:18:26 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-08 02:18:26 | INFO | train | epoch 470 | loss 1.022 | nll_loss 0.441 | ppl 1.36 | wps 22346.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45304 | lr 0.00014857 | gnorm 0.71 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 134818
2022-03-08 02:18:26 | INFO | fairseq.trainer | begin training epoch 471
2022-03-08 02:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:23:00 | INFO | train_inner | epoch 471:     96 / 97 loss=1.023, nll_loss=0.442, ppl=1.36, wps=22329.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45400, lr=0.000148413, gnorm=0.709, loss_scale=32, train_wall=263, gb_free=8.1, wall=135092
2022-03-08 02:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:23:08 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 14.135 | nll_loss 13.883 | ppl 15106.8 | wps 44209.4 | wpb 510.9 | bsz 1 | num_updates 45401 | best_loss 7.706
2022-03-08 02:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 45401 updates
2022-03-08 02:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:23:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 471 @ 45401 updates, score 14.135) (writing took 2.3261764110065997 seconds)
2022-03-08 02:23:10 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-08 02:23:10 | INFO | train | epoch 471 | loss 1.023 | nll_loss 0.442 | ppl 1.36 | wps 22360.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45401 | lr 0.000148411 | gnorm 0.708 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 135102
2022-03-08 02:23:10 | INFO | fairseq.trainer | begin training epoch 472
2022-03-08 02:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:26:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:27:52 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 14.151 | nll_loss 13.9 | ppl 15289.9 | wps 44178 | wpb 510.9 | bsz 1 | num_updates 45497 | best_loss 7.706
2022-03-08 02:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 45497 updates
2022-03-08 02:27:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 472 @ 45497 updates, score 14.151) (writing took 2.307014892809093 seconds)
2022-03-08 02:27:54 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-08 02:27:54 | INFO | train | epoch 472 | loss 1.02 | nll_loss 0.439 | ppl 1.36 | wps 22109.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45497 | lr 0.000148255 | gnorm 0.706 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 135386
2022-03-08 02:27:54 | INFO | fairseq.trainer | begin training epoch 473
2022-03-08 02:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:28:03 | INFO | train_inner | epoch 473:      3 / 97 loss=1.02, nll_loss=0.439, ppl=1.36, wps=21605.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=45500, lr=0.00014825, gnorm=0.706, loss_scale=32, train_wall=265, gb_free=8.1, wall=135395
2022-03-08 02:31:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:32:36 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 14.143 | nll_loss 13.892 | ppl 15201.7 | wps 40355.9 | wpb 510.9 | bsz 1 | num_updates 45593 | best_loss 7.706
2022-03-08 02:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 45593 updates
2022-03-08 02:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 473 @ 45593 updates, score 14.143) (writing took 2.3816406819969416 seconds)
2022-03-08 02:32:39 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-08 02:32:39 | INFO | train | epoch 473 | loss 1.021 | nll_loss 0.44 | ppl 1.36 | wps 22106.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45593 | lr 0.000148099 | gnorm 0.711 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135671
2022-03-08 02:32:39 | INFO | fairseq.trainer | begin training epoch 474
2022-03-08 02:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:32:59 | INFO | train_inner | epoch 474:      7 / 97 loss=1.021, nll_loss=0.439, ppl=1.36, wps=22116.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45600, lr=0.000148087, gnorm=0.71, loss_scale=16, train_wall=265, gb_free=8.1, wall=135691
2022-03-08 02:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:20 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 14.115 | nll_loss 13.864 | ppl 14907.7 | wps 44360.5 | wpb 510.9 | bsz 1 | num_updates 45690 | best_loss 7.706
2022-03-08 02:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 45690 updates
2022-03-08 02:37:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 474 @ 45690 updates, score 14.115) (writing took 2.332394810859114 seconds)
2022-03-08 02:37:23 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-08 02:37:23 | INFO | train | epoch 474 | loss 1.021 | nll_loss 0.44 | ppl 1.36 | wps 22384.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45690 | lr 0.000147941 | gnorm 0.71 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135955
2022-03-08 02:37:23 | INFO | fairseq.trainer | begin training epoch 475
2022-03-08 02:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:37:51 | INFO | train_inner | epoch 475:     10 / 97 loss=1.021, nll_loss=0.439, ppl=1.36, wps=22436, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45700, lr=0.000147925, gnorm=0.71, loss_scale=32, train_wall=262, gb_free=8.1, wall=135983
2022-03-08 02:41:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:42:05 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 14.096 | nll_loss 13.843 | ppl 14696.8 | wps 44183.8 | wpb 510.9 | bsz 1 | num_updates 45786 | best_loss 7.706
2022-03-08 02:42:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 45786 updates
2022-03-08 02:42:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:42:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:42:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 475 @ 45786 updates, score 14.096) (writing took 2.2766925836913288 seconds)
2022-03-08 02:42:07 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-08 02:42:07 | INFO | train | epoch 475 | loss 1.02 | nll_loss 0.439 | ppl 1.36 | wps 22099.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45786 | lr 0.000147786 | gnorm 0.712 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136239
2022-03-08 02:42:07 | INFO | fairseq.trainer | begin training epoch 476
2022-03-08 02:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:42:47 | INFO | train_inner | epoch 476:     14 / 97 loss=1.019, nll_loss=0.438, ppl=1.35, wps=22137.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45800, lr=0.000147764, gnorm=0.712, loss_scale=16, train_wall=265, gb_free=8.1, wall=136279
2022-03-08 02:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:46:49 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 14.105 | nll_loss 13.854 | ppl 14804.5 | wps 40651.8 | wpb 510.9 | bsz 1 | num_updates 45883 | best_loss 7.706
2022-03-08 02:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 45883 updates
2022-03-08 02:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 476 @ 45883 updates, score 14.105) (writing took 2.499858417082578 seconds)
2022-03-08 02:46:52 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-08 02:46:52 | INFO | train | epoch 476 | loss 1.02 | nll_loss 0.439 | ppl 1.36 | wps 22325.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45883 | lr 0.00014763 | gnorm 0.716 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136524
2022-03-08 02:46:52 | INFO | fairseq.trainer | begin training epoch 477
2022-03-08 02:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:47:40 | INFO | train_inner | epoch 477:     17 / 97 loss=1.02, nll_loss=0.439, ppl=1.36, wps=22342.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45900, lr=0.000147602, gnorm=0.718, loss_scale=32, train_wall=263, gb_free=8.1, wall=136572
2022-03-08 02:48:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:51:33 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 14.111 | nll_loss 13.86 | ppl 14866.2 | wps 44397.5 | wpb 510.9 | bsz 1 | num_updates 45979 | best_loss 7.706
2022-03-08 02:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 45979 updates
2022-03-08 02:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 477 @ 45979 updates, score 14.111) (writing took 2.2627280498854816 seconds)
2022-03-08 02:51:35 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-08 02:51:35 | INFO | train | epoch 477 | loss 1.019 | nll_loss 0.438 | ppl 1.35 | wps 22181.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45979 | lr 0.000147476 | gnorm 0.712 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 136807
2022-03-08 02:51:35 | INFO | fairseq.trainer | begin training epoch 478
2022-03-08 02:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:52:36 | INFO | train_inner | epoch 478:     21 / 97 loss=1.018, nll_loss=0.437, ppl=1.35, wps=22151.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46000, lr=0.000147442, gnorm=0.71, loss_scale=16, train_wall=266, gb_free=8.1, wall=136868
2022-03-08 02:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:56:17 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 14.133 | nll_loss 13.882 | ppl 15092.4 | wps 44528.5 | wpb 510.9 | bsz 1 | num_updates 46076 | best_loss 7.706
2022-03-08 02:56:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 46076 updates
2022-03-08 02:56:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 02:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 478 @ 46076 updates, score 14.133) (writing took 2.2866958999074996 seconds)
2022-03-08 02:56:19 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-08 02:56:19 | INFO | train | epoch 478 | loss 1.018 | nll_loss 0.437 | ppl 1.35 | wps 22348.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46076 | lr 0.00014732 | gnorm 0.712 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 137091
2022-03-08 02:56:19 | INFO | fairseq.trainer | begin training epoch 479
2022-03-08 02:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:57:27 | INFO | train_inner | epoch 479:     24 / 97 loss=1.018, nll_loss=0.437, ppl=1.35, wps=22442.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46100, lr=0.000147282, gnorm=0.709, loss_scale=32, train_wall=262, gb_free=8.1, wall=137159
2022-03-08 03:00:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:01:01 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 14.14 | nll_loss 13.886 | ppl 15140.6 | wps 41410.4 | wpb 510.9 | bsz 1 | num_updates 46172 | best_loss 7.706
2022-03-08 03:01:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 46172 updates
2022-03-08 03:01:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:01:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:01:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 479 @ 46172 updates, score 14.14) (writing took 2.2560131601057947 seconds)
2022-03-08 03:01:04 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-08 03:01:04 | INFO | train | epoch 479 | loss 1.017 | nll_loss 0.436 | ppl 1.35 | wps 22108 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46172 | lr 0.000147167 | gnorm 0.711 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 137376
2022-03-08 03:01:04 | INFO | fairseq.trainer | begin training epoch 480
2022-03-08 03:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:02:23 | INFO | train_inner | epoch 480:     28 / 97 loss=1.018, nll_loss=0.436, ppl=1.35, wps=22145, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46200, lr=0.000147122, gnorm=0.71, loss_scale=32, train_wall=265, gb_free=8.1, wall=137455
2022-03-08 03:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:05:45 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 14.106 | nll_loss 13.855 | ppl 14820.6 | wps 44330.4 | wpb 510.9 | bsz 1 | num_updates 46269 | best_loss 7.706
2022-03-08 03:05:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 46269 updates
2022-03-08 03:05:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 480 @ 46269 updates, score 14.106) (writing took 2.2755405777134 seconds)
2022-03-08 03:05:47 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-08 03:05:47 | INFO | train | epoch 480 | loss 1.018 | nll_loss 0.437 | ppl 1.35 | wps 22428.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46269 | lr 0.000147013 | gnorm 0.707 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 137659
2022-03-08 03:05:47 | INFO | fairseq.trainer | begin training epoch 481
2022-03-08 03:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:07:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 03:07:19 | INFO | train_inner | epoch 481:     32 / 97 loss=1.016, nll_loss=0.435, ppl=1.35, wps=22169.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46300, lr=0.000146964, gnorm=0.705, loss_scale=32, train_wall=265, gb_free=8.1, wall=137751
2022-03-08 03:09:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:10:29 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 14.099 | nll_loss 13.847 | ppl 14734.3 | wps 44354.2 | wpb 510.9 | bsz 1 | num_updates 46364 | best_loss 7.706
2022-03-08 03:10:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 46364 updates
2022-03-08 03:10:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 481 @ 46364 updates, score 14.099) (writing took 2.4693762687966228 seconds)
2022-03-08 03:10:31 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-08 03:10:31 | INFO | train | epoch 481 | loss 1.016 | nll_loss 0.435 | ppl 1.35 | wps 21887.6 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 46364 | lr 0.000146862 | gnorm 0.713 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137943
2022-03-08 03:10:31 | INFO | fairseq.trainer | begin training epoch 482
2022-03-08 03:10:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:12:14 | INFO | train_inner | epoch 482:     36 / 97 loss=1.016, nll_loss=0.435, ppl=1.35, wps=22148.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46400, lr=0.000146805, gnorm=0.716, loss_scale=16, train_wall=265, gb_free=8.1, wall=138046
2022-03-08 03:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:15:13 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 14.168 | nll_loss 13.915 | ppl 15448.6 | wps 44242.8 | wpb 510.9 | bsz 1 | num_updates 46461 | best_loss 7.706
2022-03-08 03:15:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 46461 updates
2022-03-08 03:15:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:15:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:15:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 482 @ 46461 updates, score 14.168) (writing took 2.2802191269584 seconds)
2022-03-08 03:15:15 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-08 03:15:15 | INFO | train | epoch 482 | loss 1.017 | nll_loss 0.436 | ppl 1.35 | wps 22343.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46461 | lr 0.000146709 | gnorm 0.714 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 138228
2022-03-08 03:15:15 | INFO | fairseq.trainer | begin training epoch 483
2022-03-08 03:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:17:06 | INFO | train_inner | epoch 483:     39 / 97 loss=1.016, nll_loss=0.435, ppl=1.35, wps=22441, ups=0.34, wpb=65495, bsz=127.9, num_updates=46500, lr=0.000146647, gnorm=0.71, loss_scale=32, train_wall=262, gb_free=8.1, wall=138338
2022-03-08 03:18:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:19:56 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 14.111 | nll_loss 13.858 | ppl 14849.4 | wps 44317.6 | wpb 510.9 | bsz 1 | num_updates 46557 | best_loss 7.706
2022-03-08 03:19:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 46557 updates
2022-03-08 03:19:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:19:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 483 @ 46557 updates, score 14.111) (writing took 2.2798479138873518 seconds)
2022-03-08 03:19:59 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-08 03:19:59 | INFO | train | epoch 483 | loss 1.016 | nll_loss 0.435 | ppl 1.35 | wps 22204.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46557 | lr 0.000146557 | gnorm 0.707 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 138511
2022-03-08 03:19:59 | INFO | fairseq.trainer | begin training epoch 484
2022-03-08 03:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:22:02 | INFO | train_inner | epoch 484:     43 / 97 loss=1.016, nll_loss=0.435, ppl=1.35, wps=22155.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46600, lr=0.00014649, gnorm=0.713, loss_scale=16, train_wall=265, gb_free=8.1, wall=138634
2022-03-08 03:24:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:24:41 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 14.137 | nll_loss 13.886 | ppl 15142.8 | wps 44019 | wpb 510.9 | bsz 1 | num_updates 46654 | best_loss 7.706
2022-03-08 03:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 46654 updates
2022-03-08 03:24:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:24:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:24:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 484 @ 46654 updates, score 14.137) (writing took 2.296437615994364 seconds)
2022-03-08 03:24:43 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-08 03:24:43 | INFO | train | epoch 484 | loss 1.015 | nll_loss 0.434 | ppl 1.35 | wps 22335.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46654 | lr 0.000146405 | gnorm 0.711 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 138795
2022-03-08 03:24:43 | INFO | fairseq.trainer | begin training epoch 485
2022-03-08 03:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:25:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:26:57 | INFO | train_inner | epoch 485:     47 / 97 loss=1.013, nll_loss=0.433, ppl=1.35, wps=22148.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46700, lr=0.000146333, gnorm=0.706, loss_scale=16, train_wall=265, gb_free=8.1, wall=138930
2022-03-08 03:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:29:25 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 14.134 | nll_loss 13.882 | ppl 15098.3 | wps 44363.3 | wpb 510.9 | bsz 1 | num_updates 46750 | best_loss 7.706
2022-03-08 03:29:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 46750 updates
2022-03-08 03:29:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:29:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 485 @ 46750 updates, score 14.134) (writing took 2.2755376659333706 seconds)
2022-03-08 03:29:27 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-08 03:29:27 | INFO | train | epoch 485 | loss 1.015 | nll_loss 0.434 | ppl 1.35 | wps 22123.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46750 | lr 0.000146254 | gnorm 0.708 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139079
2022-03-08 03:29:27 | INFO | fairseq.trainer | begin training epoch 486
2022-03-08 03:29:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:31:50 | INFO | train_inner | epoch 486:     50 / 97 loss=1.015, nll_loss=0.434, ppl=1.35, wps=22386.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46800, lr=0.000146176, gnorm=0.71, loss_scale=16, train_wall=262, gb_free=8.1, wall=139222
2022-03-08 03:33:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:34:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:34:08 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 14.106 | nll_loss 13.852 | ppl 14791.1 | wps 44178.2 | wpb 510.9 | bsz 1 | num_updates 46846 | best_loss 7.706
2022-03-08 03:34:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 46846 updates
2022-03-08 03:34:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:34:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 486 @ 46846 updates, score 14.106) (writing took 2.3534662406891584 seconds)
2022-03-08 03:34:11 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-08 03:34:11 | INFO | train | epoch 486 | loss 1.014 | nll_loss 0.434 | ppl 1.35 | wps 22176.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46846 | lr 0.000146105 | gnorm 0.711 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 139363
2022-03-08 03:34:11 | INFO | fairseq.trainer | begin training epoch 487
2022-03-08 03:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:36:45 | INFO | train_inner | epoch 487:     54 / 97 loss=1.014, nll_loss=0.434, ppl=1.35, wps=22210.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46900, lr=0.00014602, gnorm=0.705, loss_scale=16, train_wall=265, gb_free=8.1, wall=139517
2022-03-08 03:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:38:52 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 14.114 | nll_loss 13.862 | ppl 14890 | wps 44324.1 | wpb 510.9 | bsz 1 | num_updates 46943 | best_loss 7.706
2022-03-08 03:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 46943 updates
2022-03-08 03:38:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:38:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 487 @ 46943 updates, score 14.114) (writing took 2.299762195907533 seconds)
2022-03-08 03:38:55 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-08 03:38:55 | INFO | train | epoch 487 | loss 1.014 | nll_loss 0.433 | ppl 1.35 | wps 22375.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46943 | lr 0.000145954 | gnorm 0.699 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139647
2022-03-08 03:38:55 | INFO | fairseq.trainer | begin training epoch 488
2022-03-08 03:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:39:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:41:39 | INFO | train_inner | epoch 488:     58 / 97 loss=1.013, nll_loss=0.433, ppl=1.35, wps=22276.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=47000, lr=0.000145865, gnorm=0.705, loss_scale=16, train_wall=264, gb_free=8.1, wall=139811
2022-03-08 03:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:43:35 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 14.123 | nll_loss 13.871 | ppl 14987 | wps 44490.4 | wpb 510.9 | bsz 1 | num_updates 47039 | best_loss 7.706
2022-03-08 03:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 47039 updates
2022-03-08 03:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:43:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 488 @ 47039 updates, score 14.123) (writing took 2.291800673119724 seconds)
2022-03-08 03:43:37 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-08 03:43:37 | INFO | train | epoch 488 | loss 1.013 | nll_loss 0.432 | ppl 1.35 | wps 22234.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47039 | lr 0.000145805 | gnorm 0.708 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 139929
2022-03-08 03:43:37 | INFO | fairseq.trainer | begin training epoch 489
2022-03-08 03:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:46:31 | INFO | train_inner | epoch 489:     61 / 97 loss=1.013, nll_loss=0.432, ppl=1.35, wps=22403.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47100, lr=0.00014571, gnorm=0.705, loss_scale=32, train_wall=262, gb_free=8.1, wall=140103
2022-03-08 03:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:48:18 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 14.145 | nll_loss 13.896 | ppl 15247.2 | wps 44426.8 | wpb 510.9 | bsz 1 | num_updates 47136 | best_loss 7.706
2022-03-08 03:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 47136 updates
2022-03-08 03:48:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 489 @ 47136 updates, score 14.145) (writing took 2.2674883268773556 seconds)
2022-03-08 03:48:20 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-08 03:48:20 | INFO | train | epoch 489 | loss 1.014 | nll_loss 0.433 | ppl 1.35 | wps 22467.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47136 | lr 0.000145654 | gnorm 0.709 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 140212
2022-03-08 03:48:20 | INFO | fairseq.trainer | begin training epoch 490
2022-03-08 03:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:50:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:51:25 | INFO | train_inner | epoch 490:     65 / 97 loss=1.013, nll_loss=0.432, ppl=1.35, wps=22273.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=47200, lr=0.000145556, gnorm=0.707, loss_scale=16, train_wall=264, gb_free=8.1, wall=140397
2022-03-08 03:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:53:02 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 14.163 | nll_loss 13.913 | ppl 15420.7 | wps 44376.2 | wpb 510.9 | bsz 1 | num_updates 47232 | best_loss 7.706
2022-03-08 03:53:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 47232 updates
2022-03-08 03:53:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:53:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:53:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 490 @ 47232 updates, score 14.163) (writing took 2.309152050409466 seconds)
2022-03-08 03:53:04 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-08 03:53:04 | INFO | train | epoch 490 | loss 1.012 | nll_loss 0.431 | ppl 1.35 | wps 22149.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47232 | lr 0.000145506 | gnorm 0.706 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140496
2022-03-08 03:53:04 | INFO | fairseq.trainer | begin training epoch 491
2022-03-08 03:53:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:56:17 | INFO | train_inner | epoch 491:     68 / 97 loss=1.012, nll_loss=0.431, ppl=1.35, wps=22415.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47300, lr=0.000145402, gnorm=0.708, loss_scale=32, train_wall=262, gb_free=8.1, wall=140689
2022-03-08 03:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:57:44 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 14.151 | nll_loss 13.901 | ppl 15294.8 | wps 44402.5 | wpb 510.9 | bsz 1 | num_updates 47329 | best_loss 7.706
2022-03-08 03:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 47329 updates
2022-03-08 03:57:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:57:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 03:57:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 491 @ 47329 updates, score 14.151) (writing took 2.3657400608062744 seconds)
2022-03-08 03:57:47 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-08 03:57:47 | INFO | train | epoch 491 | loss 1.011 | nll_loss 0.431 | ppl 1.35 | wps 22471.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47329 | lr 0.000145357 | gnorm 0.705 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 140779
2022-03-08 03:57:47 | INFO | fairseq.trainer | begin training epoch 492
2022-03-08 03:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:58:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:01:12 | INFO | train_inner | epoch 492:     72 / 97 loss=1.011, nll_loss=0.43, ppl=1.35, wps=22267.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47400, lr=0.000145248, gnorm=0.702, loss_scale=16, train_wall=264, gb_free=8.1, wall=140984
2022-03-08 04:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:02:28 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 14.151 | nll_loss 13.902 | ppl 15308.7 | wps 44325.1 | wpb 510.9 | bsz 1 | num_updates 47425 | best_loss 7.706
2022-03-08 04:02:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 47425 updates
2022-03-08 04:02:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:02:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:02:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 492 @ 47425 updates, score 14.151) (writing took 2.334777045994997 seconds)
2022-03-08 04:02:30 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-08 04:02:30 | INFO | train | epoch 492 | loss 1.01 | nll_loss 0.43 | ppl 1.35 | wps 22162 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47425 | lr 0.00014521 | gnorm 0.703 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 141062
2022-03-08 04:02:30 | INFO | fairseq.trainer | begin training epoch 493
2022-03-08 04:02:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:05:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:06:06 | INFO | train_inner | epoch 493:     76 / 97 loss=1.011, nll_loss=0.43, ppl=1.35, wps=22206.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=47500, lr=0.000145095, gnorm=0.709, loss_scale=16, train_wall=265, gb_free=8.1, wall=141279
2022-03-08 04:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:07:11 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 14.052 | nll_loss 13.8 | ppl 14264.2 | wps 44502.2 | wpb 510.9 | bsz 1 | num_updates 47521 | best_loss 7.706
2022-03-08 04:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 47521 updates
2022-03-08 04:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 493 @ 47521 updates, score 14.052) (writing took 2.317553940229118 seconds)
2022-03-08 04:07:13 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-08 04:07:13 | INFO | train | epoch 493 | loss 1.011 | nll_loss 0.43 | ppl 1.35 | wps 22247.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47521 | lr 0.000145063 | gnorm 0.71 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 141345
2022-03-08 04:07:13 | INFO | fairseq.trainer | begin training epoch 494
2022-03-08 04:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:10:58 | INFO | train_inner | epoch 494:     79 / 97 loss=1.01, nll_loss=0.43, ppl=1.35, wps=22479.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47600, lr=0.000144943, gnorm=0.707, loss_scale=16, train_wall=262, gb_free=8.1, wall=141570
2022-03-08 04:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:11:53 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 14.168 | nll_loss 13.919 | ppl 15484.1 | wps 44483.3 | wpb 510.9 | bsz 1 | num_updates 47618 | best_loss 7.706
2022-03-08 04:11:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 47618 updates
2022-03-08 04:11:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:11:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:11:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 494 @ 47618 updates, score 14.168) (writing took 2.41040863096714 seconds)
2022-03-08 04:11:56 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-08 04:11:56 | INFO | train | epoch 494 | loss 1.01 | nll_loss 0.429 | ppl 1.35 | wps 22454.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47618 | lr 0.000144915 | gnorm 0.706 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 141628
2022-03-08 04:11:56 | INFO | fairseq.trainer | begin training epoch 495
2022-03-08 04:11:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:15:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:15:53 | INFO | train_inner | epoch 495:     83 / 97 loss=1.009, nll_loss=0.429, ppl=1.35, wps=22198.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47700, lr=0.000144791, gnorm=0.702, loss_scale=16, train_wall=265, gb_free=8.1, wall=141865
2022-03-08 04:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:16:37 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 14.109 | nll_loss 13.857 | ppl 14834.6 | wps 44395.3 | wpb 510.9 | bsz 1 | num_updates 47714 | best_loss 7.706
2022-03-08 04:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 47714 updates
2022-03-08 04:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 495 @ 47714 updates, score 14.109) (writing took 2.346928209066391 seconds)
2022-03-08 04:16:40 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-08 04:16:40 | INFO | train | epoch 495 | loss 1.009 | nll_loss 0.429 | ppl 1.35 | wps 22147.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47714 | lr 0.00014477 | gnorm 0.7 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 141912
2022-03-08 04:16:40 | INFO | fairseq.trainer | begin training epoch 496
2022-03-08 04:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:20:44 | INFO | train_inner | epoch 496:     86 / 97 loss=1.01, nll_loss=0.429, ppl=1.35, wps=22470.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=47800, lr=0.000144639, gnorm=0.703, loss_scale=16, train_wall=262, gb_free=8.1, wall=142156
2022-03-08 04:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:21:20 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 14.101 | nll_loss 13.851 | ppl 14781 | wps 44360.3 | wpb 510.9 | bsz 1 | num_updates 47811 | best_loss 7.706
2022-03-08 04:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 47811 updates
2022-03-08 04:21:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 496 @ 47811 updates, score 14.101) (writing took 2.328414331190288 seconds)
2022-03-08 04:21:23 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-08 04:21:23 | INFO | train | epoch 496 | loss 1.009 | nll_loss 0.429 | ppl 1.35 | wps 22464.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47811 | lr 0.000144623 | gnorm 0.702 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142195
2022-03-08 04:21:23 | INFO | fairseq.trainer | begin training epoch 497
2022-03-08 04:21:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:25:37 | INFO | train_inner | epoch 497:     89 / 97 loss=1.008, nll_loss=0.428, ppl=1.34, wps=22403.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47900, lr=0.000144488, gnorm=0.704, loss_scale=32, train_wall=262, gb_free=8.1, wall=142449
2022-03-08 04:25:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:26:04 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 14.151 | nll_loss 13.901 | ppl 15295.6 | wps 44431.4 | wpb 510.9 | bsz 1 | num_updates 47908 | best_loss 7.706
2022-03-08 04:26:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 47908 updates
2022-03-08 04:26:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:26:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:26:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 497 @ 47908 updates, score 14.151) (writing took 2.3492996441200376 seconds)
2022-03-08 04:26:06 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-08 04:26:06 | INFO | train | epoch 497 | loss 1.008 | nll_loss 0.427 | ppl 1.34 | wps 22379.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47908 | lr 0.000144476 | gnorm 0.706 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 142478
2022-03-08 04:26:06 | INFO | fairseq.trainer | begin training epoch 498
2022-03-08 04:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:27:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:30:31 | INFO | train_inner | epoch 498:     93 / 97 loss=1.008, nll_loss=0.428, ppl=1.35, wps=22269, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48000, lr=0.000144338, gnorm=0.707, loss_scale=32, train_wall=264, gb_free=8.1, wall=142743
2022-03-08 04:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:30:47 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 14.165 | nll_loss 13.916 | ppl 15457.9 | wps 44679.7 | wpb 510.9 | bsz 1 | num_updates 48004 | best_loss 7.706
2022-03-08 04:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 48004 updates
2022-03-08 04:30:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 498 @ 48004 updates, score 14.165) (writing took 2.37403069389984 seconds)
2022-03-08 04:30:49 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-08 04:30:49 | INFO | train | epoch 498 | loss 1.007 | nll_loss 0.427 | ppl 1.34 | wps 22234.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48004 | lr 0.000144332 | gnorm 0.706 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 142761
2022-03-08 04:30:49 | INFO | fairseq.trainer | begin training epoch 499
2022-03-08 04:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:34:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:35:26 | INFO | train_inner | epoch 499:     97 / 97 loss=1.008, nll_loss=0.428, ppl=1.34, wps=22195.1, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=48100, lr=0.000144187, gnorm=0.7, loss_scale=32, train_wall=265, gb_free=8.1, wall=143038
2022-03-08 04:35:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:35:31 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 14.114 | nll_loss 13.864 | ppl 14910.9 | wps 44258.4 | wpb 510.9 | bsz 1 | num_updates 48100 | best_loss 7.706
2022-03-08 04:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 48100 updates
2022-03-08 04:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:35:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 499 @ 48100 updates, score 14.114) (writing took 2.4700976251624525 seconds)
2022-03-08 04:35:33 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-08 04:35:33 | INFO | train | epoch 499 | loss 1.007 | nll_loss 0.427 | ppl 1.34 | wps 22145.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48100 | lr 0.000144187 | gnorm 0.699 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 143045
2022-03-08 04:35:33 | INFO | fairseq.trainer | begin training epoch 500
2022-03-08 04:35:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:40:14 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 14.112 | nll_loss 13.861 | ppl 14882 | wps 44518.2 | wpb 510.9 | bsz 1 | num_updates 48197 | best_loss 7.706
2022-03-08 04:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 48197 updates
2022-03-08 04:40:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 500 @ 48197 updates, score 14.112) (writing took 2.3390000900253654 seconds)
2022-03-08 04:40:16 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-08 04:40:16 | INFO | train | epoch 500 | loss 1.007 | nll_loss 0.427 | ppl 1.34 | wps 22467.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48197 | lr 0.000144042 | gnorm 0.7 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 143328
2022-03-08 04:40:16 | INFO | fairseq.trainer | begin training epoch 501
2022-03-08 04:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:40:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 04:40:27 | INFO | train_inner | epoch 501:      4 / 97 loss=1.006, nll_loss=0.426, ppl=1.34, wps=21717.1, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=48200, lr=0.000144038, gnorm=0.699, loss_scale=32, train_wall=264, gb_free=8.1, wall=143339
2022-03-08 04:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:44:57 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 14.13 | nll_loss 13.878 | ppl 15055.4 | wps 40789.6 | wpb 510.9 | bsz 1 | num_updates 48293 | best_loss 7.706
2022-03-08 04:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 48293 updates
2022-03-08 04:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:45:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 501 @ 48293 updates, score 14.13) (writing took 2.5154576473869383 seconds)
2022-03-08 04:45:00 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-08 04:45:00 | INFO | train | epoch 501 | loss 1.006 | nll_loss 0.426 | ppl 1.34 | wps 22128.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48293 | lr 0.000143899 | gnorm 0.695 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 143612
2022-03-08 04:45:00 | INFO | fairseq.trainer | begin training epoch 502
2022-03-08 04:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:45:20 | INFO | train_inner | epoch 502:      7 / 97 loss=1.006, nll_loss=0.425, ppl=1.34, wps=22358.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48300, lr=0.000143889, gnorm=0.695, loss_scale=32, train_wall=262, gb_free=8.1, wall=143632
2022-03-08 04:46:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:49:41 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 14.159 | nll_loss 13.909 | ppl 15384.9 | wps 44160.5 | wpb 510.9 | bsz 1 | num_updates 48389 | best_loss 7.706
2022-03-08 04:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 48389 updates
2022-03-08 04:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:49:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 502 @ 48389 updates, score 14.159) (writing took 2.3398828064091504 seconds)
2022-03-08 04:49:43 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-08 04:49:43 | INFO | train | epoch 502 | loss 1.006 | nll_loss 0.426 | ppl 1.34 | wps 22217.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48389 | lr 0.000143756 | gnorm 0.7 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143895
2022-03-08 04:49:43 | INFO | fairseq.trainer | begin training epoch 503
2022-03-08 04:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:50:14 | INFO | train_inner | epoch 503:     11 / 97 loss=1.005, nll_loss=0.425, ppl=1.34, wps=22278.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48400, lr=0.00014374, gnorm=0.7, loss_scale=16, train_wall=264, gb_free=8.1, wall=143926
2022-03-08 04:54:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:54:23 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 14.14 | nll_loss 13.888 | ppl 15163.8 | wps 44647.9 | wpb 510.9 | bsz 1 | num_updates 48486 | best_loss 7.706
2022-03-08 04:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 48486 updates
2022-03-08 04:54:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:54:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 503 @ 48486 updates, score 14.14) (writing took 2.2939799269661307 seconds)
2022-03-08 04:54:26 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-08 04:54:26 | INFO | train | epoch 503 | loss 1.006 | nll_loss 0.426 | ppl 1.34 | wps 22477.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48486 | lr 0.000143612 | gnorm 0.703 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 144178
2022-03-08 04:54:26 | INFO | fairseq.trainer | begin training epoch 504
2022-03-08 04:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:54:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:55:09 | INFO | train_inner | epoch 504:     15 / 97 loss=1.006, nll_loss=0.426, ppl=1.34, wps=22195.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48500, lr=0.000143592, gnorm=0.703, loss_scale=16, train_wall=265, gb_free=8.1, wall=144221
2022-03-08 04:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:59:07 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 14.166 | nll_loss 13.917 | ppl 15469.4 | wps 44417.2 | wpb 510.9 | bsz 1 | num_updates 48582 | best_loss 7.706
2022-03-08 04:59:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 48582 updates
2022-03-08 04:59:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:59:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 04:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 504 @ 48582 updates, score 14.166) (writing took 2.3637165860272944 seconds)
2022-03-08 04:59:09 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-08 04:59:09 | INFO | train | epoch 504 | loss 1.005 | nll_loss 0.425 | ppl 1.34 | wps 22147.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48582 | lr 0.00014347 | gnorm 0.703 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144462
2022-03-08 04:59:09 | INFO | fairseq.trainer | begin training epoch 505
2022-03-08 04:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:00:00 | INFO | train_inner | epoch 505:     18 / 97 loss=1.004, nll_loss=0.424, ppl=1.34, wps=22488.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48600, lr=0.000143444, gnorm=0.702, loss_scale=16, train_wall=261, gb_free=8.1, wall=144512
2022-03-08 05:03:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:03:50 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 14.139 | nll_loss 13.89 | ppl 15182.8 | wps 44387.9 | wpb 510.9 | bsz 1 | num_updates 48679 | best_loss 7.706
2022-03-08 05:03:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 48679 updates
2022-03-08 05:03:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:03:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 505 @ 48679 updates, score 14.139) (writing took 2.3149164761416614 seconds)
2022-03-08 05:03:52 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-08 05:03:52 | INFO | train | epoch 505 | loss 1.004 | nll_loss 0.424 | ppl 1.34 | wps 22478.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48679 | lr 0.000143327 | gnorm 0.698 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 144744
2022-03-08 05:03:52 | INFO | fairseq.trainer | begin training epoch 506
2022-03-08 05:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:04:52 | INFO | train_inner | epoch 506:     21 / 97 loss=1.004, nll_loss=0.424, ppl=1.34, wps=22438.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=48700, lr=0.000143296, gnorm=0.695, loss_scale=32, train_wall=262, gb_free=8.1, wall=144804
2022-03-08 05:06:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:08:33 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 14.128 | nll_loss 13.876 | ppl 15034.1 | wps 44586.1 | wpb 510.9 | bsz 1 | num_updates 48775 | best_loss 7.706
2022-03-08 05:08:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 48775 updates
2022-03-08 05:08:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 506 @ 48775 updates, score 14.128) (writing took 2.3734470028430223 seconds)
2022-03-08 05:08:36 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-08 05:08:36 | INFO | train | epoch 506 | loss 1.003 | nll_loss 0.423 | ppl 1.34 | wps 22167.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48775 | lr 0.000143186 | gnorm 0.697 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 145028
2022-03-08 05:08:36 | INFO | fairseq.trainer | begin training epoch 507
2022-03-08 05:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:09:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:09:49 | INFO | train_inner | epoch 507:     26 / 97 loss=1.004, nll_loss=0.424, ppl=1.34, wps=22045.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48800, lr=0.00014315, gnorm=0.703, loss_scale=16, train_wall=267, gb_free=8.1, wall=145101
2022-03-08 05:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:13:17 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 14.138 | nll_loss 13.889 | ppl 15170.2 | wps 44694.9 | wpb 510.9 | bsz 1 | num_updates 48871 | best_loss 7.706
2022-03-08 05:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 48871 updates
2022-03-08 05:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:13:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:13:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 507 @ 48871 updates, score 14.138) (writing took 2.2251417730003595 seconds)
2022-03-08 05:13:19 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-08 05:13:19 | INFO | train | epoch 507 | loss 1.003 | nll_loss 0.423 | ppl 1.34 | wps 22213.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48871 | lr 0.000143046 | gnorm 0.704 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145311
2022-03-08 05:13:19 | INFO | fairseq.trainer | begin training epoch 508
2022-03-08 05:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:14:42 | INFO | train_inner | epoch 508:     29 / 97 loss=1.002, nll_loss=0.422, ppl=1.34, wps=22401, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48900, lr=0.000143003, gnorm=0.703, loss_scale=16, train_wall=263, gb_free=8.1, wall=145394
2022-03-08 05:15:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:18:00 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 14.121 | nll_loss 13.872 | ppl 14997.4 | wps 40590.5 | wpb 510.9 | bsz 1 | num_updates 48967 | best_loss 7.706
2022-03-08 05:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 48967 updates
2022-03-08 05:18:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:18:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 508 @ 48967 updates, score 14.121) (writing took 2.2678244370035827 seconds)
2022-03-08 05:18:03 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-08 05:18:03 | INFO | train | epoch 508 | loss 1.003 | nll_loss 0.423 | ppl 1.34 | wps 22153.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48967 | lr 0.000142905 | gnorm 0.704 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145595
2022-03-08 05:18:03 | INFO | fairseq.trainer | begin training epoch 509
2022-03-08 05:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:19:36 | INFO | train_inner | epoch 509:     33 / 97 loss=1.002, nll_loss=0.422, ppl=1.34, wps=22253.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=49000, lr=0.000142857, gnorm=0.699, loss_scale=16, train_wall=264, gb_free=8.1, wall=145688
2022-03-08 05:22:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:22:43 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 14.129 | nll_loss 13.879 | ppl 15069.8 | wps 44505.7 | wpb 510.9 | bsz 1 | num_updates 49064 | best_loss 7.706
2022-03-08 05:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 49064 updates
2022-03-08 05:22:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:22:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 509 @ 49064 updates, score 14.129) (writing took 2.203794516157359 seconds)
2022-03-08 05:22:46 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-08 05:22:46 | INFO | train | epoch 509 | loss 1.002 | nll_loss 0.422 | ppl 1.34 | wps 22437.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49064 | lr 0.000142764 | gnorm 0.693 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 145878
2022-03-08 05:22:46 | INFO | fairseq.trainer | begin training epoch 510
2022-03-08 05:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:24:28 | INFO | train_inner | epoch 510:     36 / 97 loss=1.002, nll_loss=0.422, ppl=1.34, wps=22440.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49100, lr=0.000142712, gnorm=0.689, loss_scale=32, train_wall=262, gb_free=8.1, wall=145980
2022-03-08 05:26:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:27:26 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 14.148 | nll_loss 13.899 | ppl 15272.5 | wps 44577.7 | wpb 510.9 | bsz 1 | num_updates 49160 | best_loss 7.706
2022-03-08 05:27:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 49160 updates
2022-03-08 05:27:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 510 @ 49160 updates, score 14.148) (writing took 2.282825442031026 seconds)
2022-03-08 05:27:28 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-08 05:27:28 | INFO | train | epoch 510 | loss 1.002 | nll_loss 0.422 | ppl 1.34 | wps 22255 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49160 | lr 0.000142624 | gnorm 0.693 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 146160
2022-03-08 05:27:28 | INFO | fairseq.trainer | begin training epoch 511
2022-03-08 05:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:29:23 | INFO | train_inner | epoch 511:     40 / 97 loss=1.002, nll_loss=0.423, ppl=1.34, wps=22228.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=49200, lr=0.000142566, gnorm=0.7, loss_scale=16, train_wall=265, gb_free=8.1, wall=146275
2022-03-08 05:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:32:10 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 14.186 | nll_loss 13.936 | ppl 15673 | wps 44087.4 | wpb 510.9 | bsz 1 | num_updates 49257 | best_loss 7.706
2022-03-08 05:32:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 49257 updates
2022-03-08 05:32:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:32:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 511 @ 49257 updates, score 14.186) (writing took 2.226175944786519 seconds)
2022-03-08 05:32:12 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-08 05:32:12 | INFO | train | epoch 511 | loss 1.002 | nll_loss 0.422 | ppl 1.34 | wps 22388.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49257 | lr 0.000142484 | gnorm 0.704 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 146444
2022-03-08 05:32:12 | INFO | fairseq.trainer | begin training epoch 512
2022-03-08 05:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:34:14 | INFO | train_inner | epoch 512:     43 / 97 loss=1, nll_loss=0.421, ppl=1.34, wps=22467.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49300, lr=0.000142422, gnorm=0.698, loss_scale=32, train_wall=262, gb_free=8.1, wall=146566
2022-03-08 05:36:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:36:52 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 14.107 | nll_loss 13.858 | ppl 14845.9 | wps 44720.3 | wpb 510.9 | bsz 1 | num_updates 49353 | best_loss 7.706
2022-03-08 05:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 49353 updates
2022-03-08 05:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 512 @ 49353 updates, score 14.107) (writing took 2.2539165490306914 seconds)
2022-03-08 05:36:55 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-08 05:36:55 | INFO | train | epoch 512 | loss 1.001 | nll_loss 0.421 | ppl 1.34 | wps 22238.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49353 | lr 0.000142345 | gnorm 0.693 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 146727
2022-03-08 05:36:55 | INFO | fairseq.trainer | begin training epoch 513
2022-03-08 05:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:39:09 | INFO | train_inner | epoch 513:     47 / 97 loss=1, nll_loss=0.42, ppl=1.34, wps=22203.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49400, lr=0.000142278, gnorm=0.692, loss_scale=16, train_wall=265, gb_free=8.1, wall=146861
2022-03-08 05:41:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:41:36 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 14.159 | nll_loss 13.911 | ppl 15409 | wps 44323.1 | wpb 510.9 | bsz 1 | num_updates 49450 | best_loss 7.706
2022-03-08 05:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 49450 updates
2022-03-08 05:41:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:41:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 513 @ 49450 updates, score 14.159) (writing took 2.2595449411310256 seconds)
2022-03-08 05:41:39 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-08 05:41:39 | INFO | train | epoch 513 | loss 1 | nll_loss 0.42 | ppl 1.34 | wps 22365.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49450 | lr 0.000142206 | gnorm 0.695 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 147011
2022-03-08 05:41:39 | INFO | fairseq.trainer | begin training epoch 514
2022-03-08 05:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:44:01 | INFO | train_inner | epoch 514:     50 / 97 loss=1.002, nll_loss=0.422, ppl=1.34, wps=22451, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49500, lr=0.000142134, gnorm=0.703, loss_scale=32, train_wall=262, gb_free=8.1, wall=147153
2022-03-08 05:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:46:19 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 14.172 | nll_loss 13.922 | ppl 15525.3 | wps 44542.7 | wpb 510.9 | bsz 1 | num_updates 49547 | best_loss 7.706
2022-03-08 05:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 49547 updates
2022-03-08 05:46:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:46:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:46:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 514 @ 49547 updates, score 14.172) (writing took 2.213702836073935 seconds)
2022-03-08 05:46:21 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-08 05:46:21 | INFO | train | epoch 514 | loss 1.001 | nll_loss 0.421 | ppl 1.34 | wps 22475.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49547 | lr 0.000142066 | gnorm 0.7 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 147293
2022-03-08 05:46:21 | INFO | fairseq.trainer | begin training epoch 515
2022-03-08 05:46:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:48:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 05:48:55 | INFO | train_inner | epoch 515:     54 / 97 loss=1, nll_loss=0.42, ppl=1.34, wps=22229.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=49600, lr=0.00014199, gnorm=0.696, loss_scale=32, train_wall=265, gb_free=8.1, wall=147447
2022-03-08 05:50:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:51:03 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 14.183 | nll_loss 13.937 | ppl 15679.6 | wps 43455.6 | wpb 510.9 | bsz 1 | num_updates 49642 | best_loss 7.706
2022-03-08 05:51:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 49642 updates
2022-03-08 05:51:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:51:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:51:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 515 @ 49642 updates, score 14.183) (writing took 2.252547840587795 seconds)
2022-03-08 05:51:05 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-08 05:51:05 | INFO | train | epoch 515 | loss 1 | nll_loss 0.42 | ppl 1.34 | wps 21921.9 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 49642 | lr 0.00014193 | gnorm 0.702 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 147577
2022-03-08 05:51:05 | INFO | fairseq.trainer | begin training epoch 516
2022-03-08 05:51:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:53:49 | INFO | train_inner | epoch 516:     58 / 97 loss=0.999, nll_loss=0.419, ppl=1.34, wps=22272.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49700, lr=0.000141848, gnorm=0.699, loss_scale=16, train_wall=264, gb_free=8.1, wall=147741
2022-03-08 05:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:55:46 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 14.157 | nll_loss 13.908 | ppl 15370.7 | wps 44572.7 | wpb 510.9 | bsz 1 | num_updates 49739 | best_loss 7.706
2022-03-08 05:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 49739 updates
2022-03-08 05:55:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:55:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 05:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 516 @ 49739 updates, score 14.157) (writing took 2.2617177460342646 seconds)
2022-03-08 05:55:48 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-08 05:55:48 | INFO | train | epoch 516 | loss 0.999 | nll_loss 0.419 | ppl 1.34 | wps 22466.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49739 | lr 0.000141792 | gnorm 0.696 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 147860
2022-03-08 05:55:48 | INFO | fairseq.trainer | begin training epoch 517
2022-03-08 05:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:58:42 | INFO | train_inner | epoch 517:     61 / 97 loss=0.999, nll_loss=0.42, ppl=1.34, wps=22404.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49800, lr=0.000141705, gnorm=0.7, loss_scale=32, train_wall=263, gb_free=8.1, wall=148034
2022-03-08 06:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:00:29 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 14.126 | nll_loss 13.876 | ppl 15037.2 | wps 39231.7 | wpb 510.9 | bsz 1 | num_updates 49836 | best_loss 7.706
2022-03-08 06:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 49836 updates
2022-03-08 06:00:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 06:00:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 06:00:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 517 @ 49836 updates, score 14.126) (writing took 2.4150494998320937 seconds)
2022-03-08 06:00:32 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-08 06:00:32 | INFO | train | epoch 517 | loss 0.998 | nll_loss 0.418 | ppl 1.34 | wps 22395.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49836 | lr 0.000141654 | gnorm 0.692 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 148144
2022-03-08 06:00:32 | INFO | fairseq.trainer | begin training epoch 518
2022-03-08 06:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:01:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 06:03:36 | INFO | train_inner | epoch 518:     65 / 97 loss=0.998, nll_loss=0.418, ppl=1.34, wps=22227.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49900, lr=0.000141563, gnorm=0.69, loss_scale=16, train_wall=264, gb_free=8.1, wall=148328
2022-03-08 06:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:05:13 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 14.124 | nll_loss 13.872 | ppl 14998.2 | wps 44447.7 | wpb 510.9 | bsz 1 | num_updates 49932 | best_loss 7.706
2022-03-08 06:05:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 49932 updates
2022-03-08 06:05:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 06:05:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 06:05:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 518 @ 49932 updates, score 14.124) (writing took 2.2864737450145185 seconds)
2022-03-08 06:05:15 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-08 06:05:15 | INFO | train | epoch 518 | loss 0.998 | nll_loss 0.419 | ppl 1.34 | wps 22170.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49932 | lr 0.000141518 | gnorm 0.694 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 148427
2022-03-08 06:05:15 | INFO | fairseq.trainer | begin training epoch 519
2022-03-08 06:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 06:08:29 | INFO | train_inner | epoch 519:     68 / 97 loss=0.999, nll_loss=0.419, ppl=1.34, wps=22394, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=50000, lr=0.000141421, gnorm=0.696, loss_scale=32, train_wall=263, gb_free=8.1, wall=148621
2022-03-08 06:08:29 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 06:08:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 06:08:34 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 14.095 | nll_loss 13.844 | ppl 14700.8 | wps 44417.7 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 7.706
2022-03-08 06:08:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 50000 updates
2022-03-08 06:08:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 06:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt
2022-03-08 06:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.02_#2/checkpoint_last.pt (epoch 519 @ 50000 updates, score 14.095) (writing took 2.266656124033034 seconds)
2022-03-08 06:08:36 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-08 06:08:36 | INFO | train | epoch 519 | loss 0.994 | nll_loss 0.414 | ppl 1.33 | wps 22175.1 | ups 0.34 | wpb 65532.9 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.693 | loss_scale 32 | train_wall 178 | gb_free 8.1 | wall 148628
2022-03-08 06:08:36 | INFO | fairseq_cli.train | done training in 148627.8 seconds
