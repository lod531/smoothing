Sender: LSF System <lsfadmin@eu-g3-059>
Subject: Job 210581186: <iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:24:03 2022
Job was executed on host(s) <eu-g3-059>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:24:24 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:24:24 2022
Terminated at Wed Mar 23 10:27:24 2022
Results reported at Wed Mar 23 10:27:24 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3764.32 sec.
    Max Memory :                                 5272 MB
    Average Memory :                             4099.28 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14728.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3780 sec.
    Turnaround time :                            3801 sec.

The output (if any) follows:

2022-03-23 09:24:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:24:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:24:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:24:37 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:24:37 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:24:37 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:24:37 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:24:37 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:24:37 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:24:37 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:24:37 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:24:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:24:42 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:24:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:24:42 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:24:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:24:42 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:24:42 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:24:42 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:24:42 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:24:42 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:24:42 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:24:42 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:24:42 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:24:42 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:24:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:24:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:24:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:25:20 | INFO | train_inner | epoch 001:    104 / 157 loss=12.18, nll_loss=11.855, ppl=3704.04, wps=78738.3, ups=3.13, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=2.984, loss_scale=8, train_wall=36, gb_free=13.6, wall=38
2022-03-23 09:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:25:39 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:25:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:25:42 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 09:25:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:25:45 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:25:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:25:49 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 09:25:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:25:54 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:54 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:25:59 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:26:04 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:26:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:17 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:26:19 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:26:19 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.752 | nll_loss 10.056 | ppl 1064.85 | bleu 0.01 | wps 4056.5 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:26:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:26:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:26:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:26:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6281958129256964 seconds)
2022-03-23 09:26:21 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:26:21 | INFO | train | epoch 001 | loss 11.823 | nll_loss 11.408 | ppl 2717.62 | wps 41072.1 | ups 1.64 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.302 | loss_scale 8 | train_wall 52 | gb_free 13.9 | wall 99
2022-03-23 09:26:21 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:26:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:36 | INFO | train_inner | epoch 002:     47 / 157 loss=10.95, nll_loss=10.314, ppl=1272.64, wps=32753.3, ups=1.31, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=1.039, loss_scale=8, train_wall=30, gb_free=22.4, wall=114
2022-03-23 09:27:07 | INFO | train_inner | epoch 002:    147 / 157 loss=10.289, nll_loss=9.438, ppl=693.74, wps=80071, ups=3.2, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=1.15, loss_scale=8, train_wall=31, gb_free=13.9, wall=145
2022-03-23 09:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:13 | INFO | fairseq.tasks.translation | example hypothesis: you you.
2022-03-23 09:27:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:27:17 | INFO | fairseq.tasks.translation | example hypothesis: the the the.
2022-03-23 09:27:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:27:20 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i.
2022-03-23 09:27:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:27:23 | INFO | fairseq.tasks.translation | example hypothesis: so,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 09:27:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:27:28 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 09:27:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:27:33 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we we we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:27:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:27:39 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:27:45 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:27:52 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:55 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.985 | nll_loss 8.944 | ppl 492.34 | bleu 0.02 | wps 3971.4 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 09:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:27:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:27:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.7598824882879853 seconds)
2022-03-23 09:27:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:27:56 | INFO | train | epoch 002 | loss 10.404 | nll_loss 9.593 | ppl 772.26 | wps 41318.5 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.117 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 195
2022-03-23 09:27:57 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:25 | INFO | train_inner | epoch 003:     90 / 157 loss=10.043, nll_loss=9.07, ppl=537.29, wps=32040.9, ups=1.29, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=1.093, loss_scale=8, train_wall=30, gb_free=13.9, wall=223
2022-03-23 09:28:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:49 | INFO | fairseq.tasks.translation | example hypothesis: it's's.
2022-03-23 09:28:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:28:53 | INFO | fairseq.tasks.translation | example hypothesis: he he he.
2022-03-23 09:28:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:28:57 | INFO | fairseq.tasks.translation | example hypothesis: and i i to to to a a a a a a.
2022-03-23 09:28:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:29:02 | INFO | fairseq.tasks.translation | example hypothesis: and he was was was, he was was was was was was, he was was was was was was was was was was was was was was was was was was.
2022-03-23 09:29:02 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:29:07 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we we, we we, we, we we, we we, we, we, we, we we, we, we, we, we, we, we, we, we, we
2022-03-23 09:29:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:29:13 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we to we to we we to we to we to we to to to to to to to to to to to to to to to to to to to we we we we we we to to to to to to to to to to to to to to to to to to
2022-03-23 09:29:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:29:19 | INFO | fairseq.tasks.translation | example hypothesis: and it's, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but but but but the, but the, but the, but the, but the, but the, but the, but the, but the, but but but but but but but but
2022-03-23 09:29:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:25 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we the, we we the, and we we the, and we the, we the, and we we the, and we, we, and we we we, we, and we, we, we, and we we, we, we, and we we the, and we we we we we we we we we we we we, we, and we the, and we, we, and we we we we
2022-03-23 09:29:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example hypothesis: and and and we, and the, "" the, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:35 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, the, the, the, the, and the, the, and the, the, and the, we we the, and the, and the, and the, and the, and the, and the, and the, we we the, and the, and the, we we we we the, we we we we we we the, we we we, we we the, the, the, and the, and the, and the, the, and the, and the, and the, and the, the, and the, and the, and the, and the, and the, and the, and the, we we we we we we we, and the, and the, and the, and the, we we we we we we we we the, and the, we we we the, and the, we we the, the, the, we we we we we we we we we the, and the, and the, and the, the, the, the, the, we, we
2022-03-23 09:29:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:35 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.771 | nll_loss 8.622 | ppl 394.01 | bleu 0.15 | wps 3577.4 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.15
2022-03-23 09:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 09:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:29:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.15) (writing took 1.7793524749577045 seconds)
2022-03-23 09:29:37 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:29:37 | INFO | train | epoch 003 | loss 9.961 | nll_loss 8.958 | ppl 497.26 | wps 39027.2 | ups 1.55 | wpb 25122.4 | bsz 1014.9 | num_updates 466 | lr 5.825e-05 | gnorm 1.141 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 295
2022-03-23 09:29:37 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:29:48 | INFO | train_inner | epoch 004:     34 / 157 loss=9.842, nll_loss=8.798, ppl=445.15, wps=30743.9, ups=1.21, wpb=25511.1, bsz=1058.2, num_updates=500, lr=6.25e-05, gnorm=1.132, loss_scale=4, train_wall=31, gb_free=14.7, wall=306
2022-03-23 09:30:19 | INFO | train_inner | epoch 004:    134 / 157 loss=9.581, nll_loss=8.455, ppl=350.99, wps=80794, ups=3.2, wpb=25228.8, bsz=1092.2, num_updates=600, lr=7.5e-05, gnorm=1.347, loss_scale=4, train_wall=31, gb_free=14, wall=337
2022-03-23 09:30:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can can can can can can can can can can can can can can can can see
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:30:36 | INFO | fairseq.tasks.translation | example hypothesis: he's a years of the world of the world of the world of the world of the world, he can can can can can can can see the
2022-03-23 09:30:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:30:42 | INFO | fairseq.tasks.translation | example hypothesis: so i'm to be a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of the
2022-03-23 09:30:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:30:48 | INFO | fairseq.tasks.translation | example hypothesis: and he was was he was he was was he was was was was was was was was was was was was was was was was was was was was was was was was was was he was he was was a
2022-03-23 09:30:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:30:53 | INFO | fairseq.tasks.translation | example hypothesis: so, we know, what we're're're're're're're're're a lot, and what we're're're're're going to know, and what what we can can can can can can can can can can can can can know
2022-03-23 09:30:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:30:59 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can can see or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 09:30:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example hypothesis: but it's the other, but they're're not not not not not not not not not not not not not not the world, but they have the world, but they're the world, but but but they have the world, but but they're not not not not not not not not not not not have the world, but but they're have the
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:11 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the world of the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can see the
2022-03-23 09:31:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example hypothesis: and so, we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can the the the the the the the the the way, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" it, "" "" "" it, "" it, "" it, "" "it's a a a a a a
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example hypothesis: so we're to to be the world, and we can can can can can can see the world of the world of the world of the world of the world of the world, and it's the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the world of the world of the world of the world of the world of the world of the world of the world of the world, and the world of the world of the world of the world of the world of the world of the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.377 | nll_loss 8.11 | ppl 276.27 | bleu 0.73 | wps 3223.5 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.73
2022-03-23 09:31:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 09:31:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.73) (writing took 1.7378448811359704 seconds)
2022-03-23 09:31:23 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:31:23 | INFO | train | epoch 004 | loss 9.633 | nll_loss 8.523 | ppl 367.98 | wps 37082.3 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.25 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 401
2022-03-23 09:31:24 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:48 | INFO | train_inner | epoch 005:     77 / 157 loss=9.365, nll_loss=8.164, ppl=286.92, wps=28311, ups=1.13, wpb=25101.8, bsz=1058.5, num_updates=700, lr=8.75e-05, gnorm=1.454, loss_scale=4, train_wall=30, gb_free=14, wall=426
2022-03-23 09:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:17 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can can can can can can can can can't be.
2022-03-23 09:32:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:32:22 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the time, he can can be a lot.
2022-03-23 09:32:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:32:27 | INFO | fairseq.tasks.translation | example hypothesis: and i can be a lot of a lot of a lot of a lot, i can be a lot of a lot of a lot of a lot of a lot of a lot
2022-03-23 09:32:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example hypothesis: he was he was me, he was me, he was he was me, he was he was me, he was he was he was he was me, he was he was me, he was he was
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:32:38 | INFO | fairseq.tasks.translation | example hypothesis: and so what we have a lot of what we have a lot of a lot of what we have a lot of what we have a lot of a lot of a lot of a lot of what we have to do, and we have a lot
2022-03-23 09:32:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:32:44 | INFO | fairseq.tasks.translation | example hypothesis: and we have to be about about the world, and we're going to do we're going to do or the world, and we're going to do we're going to do or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 09:32:44 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example hypothesis: but if if you're a lot of the world, but they're not not not not not not not not a lot of the world, but they're a lot of the world, but they're not not not not not not not not not not not not not not not not not not not not not not not not the world, but they're the world
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:32:56 | INFO | fairseq.tasks.translation | example hypothesis: and if we have a lot of the world, and we can see a lot of the world, and we can see the world, and we can see the world of the world of the world, and we can see the world, and we can see the world, and we can see the world of the world of the world of the world, and we can see the world, and we can see the world, and we can see the world, and we have
2022-03-23 09:32:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:04 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" i said, "" "" we said, "" "i said," i said, "we said," "" "" "" "" we said, "" "we said, and i said," "" we said, "" "" "" "" "" "" "" "we said, and i said, and i said, and i said, and i said," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "the first first first first first first first said, and i said, and i said, and i said, and i said, and i said, and i said, and i said," "" "" "we said, and i said," "" i said, "" "
2022-03-23 09:33:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:06 | INFO | fairseq.tasks.translation | example hypothesis: and so, we have to be the world, and the world, and i think, and the first first first first first way, and we've've have to be a lot of the world of the world of the world, and we have to be the world, and the world, and the world of the world of the world, and the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first of the world, and that we have to be to be to be, and the first first first first first first first first first first first first first first first first first first first first first first first first first first, and we have to be to be, and that we have to be be be be, and the first first first first of the world, and that we've have to be the world, and we have to be, and we think, and we think, and we have to be the
2022-03-23 09:33:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:06 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.034 | nll_loss 7.641 | ppl 199.6 | bleu 1.19 | wps 3309.3 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.19
2022-03-23 09:33:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 09:33:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:33:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.19) (writing took 1.8033434781245887 seconds)
2022-03-23 09:33:08 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:33:08 | INFO | train | epoch 005 | loss 9.29 | nll_loss 8.063 | ppl 267.41 | wps 37750.7 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.329 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 506
2022-03-23 09:33:08 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:33:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:15 | INFO | train_inner | epoch 006:     20 / 157 loss=9.238, nll_loss=7.992, ppl=254.53, wps=28854.9, ups=1.15, wpb=25109.9, bsz=964.5, num_updates=800, lr=0.0001, gnorm=1.257, loss_scale=4, train_wall=30, gb_free=14, wall=513
2022-03-23 09:33:46 | INFO | train_inner | epoch 006:    120 / 157 loss=9.068, nll_loss=7.757, ppl=216.31, wps=80743.7, ups=3.22, wpb=25050.4, bsz=929.7, num_updates=900, lr=0.0001125, gnorm=1.24, loss_scale=4, train_wall=31, gb_free=14, wall=544
2022-03-23 09:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:01 | INFO | fairseq.tasks.translation | example hypothesis: it can be not be a lot of these way.
2022-03-23 09:34:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:34:05 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the time in the world.
2022-03-23 09:34:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:34:10 | INFO | fairseq.tasks.translation | example hypothesis: now, i can see this is a lot of the way that i can can be a lot of the way.
2022-03-23 09:34:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was he was he was he was he was been been been been been been been been been been been been been been been been been been been been been been been been been been been been
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:34:21 | INFO | fairseq.tasks.translation | example hypothesis: and so what we have a lot of what we have a lot of what we have a lot of what we have a lot of what we have a lot of what we're going to do, and we have a lot of what we're going
2022-03-23 09:34:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:34:26 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do the world of our world, or we're going to talk about the world, and we're going to do the world, and we're going to do the world, or that we're going to have to have to do the world.
2022-03-23 09:34:26 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to have a lot of the way, you're going to see the way of the way, you're going to see the way of the way, but they're going to make the way, but they're going to make the way, but they're going to make the way, but they're going to have to be the way
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we can
2022-03-23 09:34:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" we said, "" "" i said, "" "" we said, "" we're going to go to say, "" you're going to go to go to say, "we're going to say," "" we're going to do the first first first first first first first first first first first first, "you're going to go to say," you're going to say, "you're going to go to go to go to go to say," that we're going to go to go to go to do, and i said, "" it, "" that's going to say, and i said, and i said, and i said, and i said, "we're going to go to say," you're going to do the first first first first first first first first first first first first, "" ""
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:48 | INFO | fairseq.tasks.translation | example hypothesis: so, if we have a lot of the world, we're going to be a lot of the world, which is that we're going to be a lot of the world, which is going to be a lot of the world, and we're going to be a lot of the world, and we're going to see that we're going to be a lot of the world, and we're going to be a lot of the world, which is that we're going to be a lot of the world, which is going to be a lot of the world, which is that we're going to be a lot of the world, which is going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to make the world, and we're going to be a lot of the world of the world of the world,
2022-03-23 09:34:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:48 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.741 | nll_loss 7.255 | ppl 152.77 | bleu 1.65 | wps 3458.5 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.65
2022-03-23 09:34:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:34:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:34:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:34:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.65) (writing took 1.7519738478586078 seconds)
2022-03-23 09:34:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:34:50 | INFO | train | epoch 006 | loss 9 | nll_loss 7.669 | ppl 203.46 | wps 38573.5 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.285 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 608
2022-03-23 09:34:51 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:34:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:11 | INFO | train_inner | epoch 007:     63 / 157 loss=8.822, nll_loss=7.431, ppl=172.55, wps=29471, ups=1.18, wpb=24987.9, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=1.143, loss_scale=4, train_wall=31, gb_free=13.8, wall=629
2022-03-23 09:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:43 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:35:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:35:47 | INFO | fairseq.tasks.translation | example hypothesis: in fact, he can be a year.
2022-03-23 09:35:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:35:52 | INFO | fairseq.tasks.translation | example hypothesis: so, i can't have a lot of course.
2022-03-23 09:35:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:35:56 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was his father, because he was his father, because he was never never never never never never never never never never never never never never never never never never never never never never never never got
2022-03-23 09:35:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:36:01 | INFO | fairseq.tasks.translation | example hypothesis: so, what's a little bit of what we're going to do, and we're going to do, and we're going to do, and what we're going to do? "
2022-03-23 09:36:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to talk about our time, or our time, or we're going to do our time, or our time or or or or our time, or our time.
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:36:11 | INFO | fairseq.tasks.translation | example hypothesis: now, there are not a lot of course, but if you're not not a lot of the way, but they're not not not the same way, but they're not not not not the same way, but they're going to get the way, but they're going to get the way, but they're going to get the way.
2022-03-23 09:36:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, and we can see the world, and then we can see the world, and we can see the world, and we can see the world, and then we can see the world, and we can see the world, and then we can see the world, and we can see the world, and then we can see, and then we can see the world, and we can see the world, and we can see
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "and" "" "" "" "" "" and "and" and "" "" and "" "" "" "and" "" "" "" "" "" "" "" "" "" "" "" "and" "" "" "" and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to have a lot of the way, and if we're going to have a lot of the way, and then we're going to get it, and then we're going to get to make the same, and we're going to make the way, and then we're going to make the way, and then we're going to get it, and then we're going to get it, and then we're going to get it, and then we're going to get it, and then we're going to get to make the same, and we're going to make the same way, and we're going to get a little bit of the world, and we're going to make the same, and we're going to make the same, and we're going to make the way, and then we're going to get to get a little bit of the world, and we're going to make the way, and we're going to make the way, and we're going to get a little bit of the world, and then the
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:28 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 8.511 | nll_loss 6.91 | ppl 120.22 | bleu 2.41 | wps 3700.4 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.41
2022-03-23 09:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.41) (writing took 1.8072850131429732 seconds)
2022-03-23 09:36:29 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:36:29 | INFO | train | epoch 007 | loss 8.741 | nll_loss 7.322 | ppl 159.98 | wps 39827.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.112 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 708
2022-03-23 09:36:30 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:32 | INFO | train_inner | epoch 008:      6 / 157 loss=8.668, nll_loss=7.224, ppl=149.46, wps=31193.4, ups=1.23, wpb=25346.2, bsz=1050.7, num_updates=1100, lr=0.0001375, gnorm=1.108, loss_scale=4, train_wall=30, gb_free=15.3, wall=710
2022-03-23 09:37:03 | INFO | train_inner | epoch 008:    106 / 157 loss=8.528, nll_loss=7.036, ppl=131.26, wps=80147.3, ups=3.2, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=1.131, loss_scale=4, train_wall=31, gb_free=22.4, wall=741
2022-03-23 09:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able to be able.
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example hypothesis: the last year is about the last year.
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:37:32 | INFO | fairseq.tasks.translation | example hypothesis: so this is a lot of course, i can make a lot of course.
2022-03-23 09:37:32 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example hypothesis: he had he had his father, because he had his father was his father.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a little bit of what we're going to do, and what we're going to do with what we're going to do? "
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example hypothesis: so, our time we're going to talk about our time, or not about the world.
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example hypothesis: some of them are some of them, but if you're not going to go out, but they don't know, but they don't get it.
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:37:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the way that we can see the way that we can see the way that we can see the world, and then we can see the kind of the world.
2022-03-23 09:37:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the one of the one of the one of the first thing, "if you're going to say," you're going to say, "if you're going to say," if you're going to say, "you're going to say," you're going to say, you're going to say, "you're going to say, you're going to say," well, "well, you're going to say, you're going to say," well, "well," well, "well," well, "well," well, "well," if you're going to say, you're going to say, "if you're going to say," if you're going to say, you're going to say, you're going to say, you're going to say, "you're going to say," you're going to go
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:01 | INFO | fairseq.tasks.translation | example hypothesis: so, the second thing is, if you're going to see the first time, if you're going to get a little little bit of the way that we're going to get a little bit of the way that we're going to get a little bit of the way that we're going to get a little bit of the way that we're going to get it.
2022-03-23 09:38:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:01 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 8.256 | nll_loss 6.572 | ppl 95.13 | bleu 4.41 | wps 4358.9 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 4.41
2022-03-23 09:38:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:38:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:38:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:38:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 4.41) (writing took 1.7758051841519773 seconds)
2022-03-23 09:38:02 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:38:02 | INFO | train | epoch 008 | loss 8.516 | nll_loss 7.018 | ppl 129.65 | wps 42436.6 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.137 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 801
2022-03-23 09:38:03 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:18 | INFO | train_inner | epoch 009:     49 / 157 loss=8.428, nll_loss=6.9, ppl=119.41, wps=33588.4, ups=1.33, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=1.141, loss_scale=4, train_wall=30, gb_free=13.6, wall=816
2022-03-23 09:38:49 | INFO | train_inner | epoch 009:    149 / 157 loss=8.272, nll_loss=6.692, ppl=103.4, wps=81159.9, ups=3.2, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=1.032, loss_scale=4, train_wall=31, gb_free=14, wall=847
2022-03-23 09:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:38:55 | INFO | fairseq.tasks.translation | example hypothesis: these can't use these energy.
2022-03-23 09:38:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:38:59 | INFO | fairseq.tasks.translation | example hypothesis: and the last year can be about about about the last year.
2022-03-23 09:38:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:39:03 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of course, i can use of course, of course, i can use a lot of course.
2022-03-23 09:39:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:39:07 | INFO | fairseq.tasks.translation | example hypothesis: he had his father.
2022-03-23 09:39:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:39:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i've got a few years, and what we're going to do?
2022-03-23 09:39:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:39:17 | INFO | fairseq.tasks.translation | example hypothesis: and so, so we have our time to talk about things about things like things like things like the other things, or not about the other other things or the other other other other other or or or other other other other, or or other other other other other other other other other other other or
2022-03-23 09:39:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:39:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the way of the way of the way, but if you don't have the way, but if you don't have the way, if you don't have the way, you don't have to use the way, it, but if you don't have the way, they don't need to use it, you don't have the
2022-03-23 09:39:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the information of these kinds of these kinds of these information that we can see this information, and then we can see that we can see the kind of the kind of the kind of information, and then we can see that we can see the kind of the kind of the kind of information, and then we can see that we can see, which we can see, which we can see the kind of the kind of the kind of the kind of
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:36 | INFO | fairseq.tasks.translation | example hypothesis: "one of the question, and it's the way, and it's going to say," and then it's going to say, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:39:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:38 | INFO | fairseq.tasks.translation | example hypothesis: and so, it's always always always always always always been a lot of the mother, and when we've got a lot of course, and if we're going to get a lot of course, if you're going to see that we're going to see that if we're going to get a lot of the way to get the way to see that if we're going to get a lot of the way to get a lot of the way to see that if we're going to get a lot of the way to get a lot of the way to get a lot of the planet, and then we're going to see that if we're going to make it, if we're going to see that if we're going to see that we're going to see that if we're going to get a lot of the way to get a lot of the other other other other other other other other other people are going to see that if we're going to get a lot of the way to get a lot of the way to see that we're going to see that,
2022-03-23 09:39:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:38 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.053 | nll_loss 6.259 | ppl 76.57 | bleu 4.93 | wps 3837.6 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.93
2022-03-23 09:39:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:39:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:39:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.93) (writing took 1.749073205050081 seconds)
2022-03-23 09:39:40 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:39:40 | INFO | train | epoch 009 | loss 8.292 | nll_loss 6.719 | ppl 105.37 | wps 40641.4 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.074 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 898
2022-03-23 09:39:40 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:09 | INFO | train_inner | epoch 010:     92 / 157 loss=8.091, nll_loss=6.449, ppl=87.37, wps=31923.9, ups=1.25, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=1.252, loss_scale=4, train_wall=31, gb_free=12.6, wall=927
2022-03-23 09:40:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:33 | INFO | fairseq.tasks.translation | example hypothesis: these can't have no form.
2022-03-23 09:40:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:40:37 | INFO | fairseq.tasks.translation | example hypothesis: and he can be about about about 30,000 miles.
2022-03-23 09:40:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:40:41 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, of course, i can make a lot of course.
2022-03-23 09:40:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:40:45 | INFO | fairseq.tasks.translation | example hypothesis: he had his father because his father had his father had his father, she had his father.
2022-03-23 09:40:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:40:49 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a few years, and a child has been going to do what we're doing?
2022-03-23 09:40:49 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:40:53 | INFO | fairseq.tasks.translation | example hypothesis: and so we started our time about things like things like things like to talk about how to talk about other, or or every time.
2022-03-23 09:40:53 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:40:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are in the brain, but if they don't need to be able to do it, and if they don't need it, they don't need it.
2022-03-23 09:40:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can see this information, we can see a little bit of the energy, and then we can get a little bit of it.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:07 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons that it's interesting interesting, and it's interesting for me for me for me, "" "" "if you have to say," "" "" "you have to say," you know, "you know," you know, "you know," you know, "if you've got to say," "you've got to say," if you've said, "you've got to say," you've got to say, "well," well, "well," well, "if you know," "you've said," well, "you've said," you've got to say, "you've got to say," "" "" "" "" "you know," for this is, "you know," you've got to say, "you've said," you know, "
2022-03-23 09:41:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's still still always always always always always the mother, and a lot of work that we've got a lot of work, or if we had to get a lot of the way that we had to do it.
2022-03-23 09:41:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:09 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.797 | nll_loss 5.908 | ppl 60.03 | bleu 8.33 | wps 4567.5 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 8.33
2022-03-23 09:41:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:41:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:41:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 8.33) (writing took 1.7781385709531605 seconds)
2022-03-23 09:41:10 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:41:10 | INFO | train | epoch 010 | loss 8.105 | nll_loss 6.467 | ppl 88.46 | wps 43533.1 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.175 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 989
2022-03-23 09:41:11 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:22 | INFO | train_inner | epoch 011:     35 / 157 loss=8.075, nll_loss=6.427, ppl=86.01, wps=34178, ups=1.37, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=1.071, loss_scale=4, train_wall=30, gb_free=22.4, wall=1000
2022-03-23 09:41:53 | INFO | train_inner | epoch 011:    135 / 157 loss=7.876, nll_loss=6.161, ppl=71.56, wps=81252, ups=3.22, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=1.069, loss_scale=4, train_wall=31, gb_free=14.4, wall=1031
2022-03-23 09:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:03 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these materials.
2022-03-23 09:42:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:42:08 | INFO | fairseq.tasks.translation | example hypothesis: and then, he can be about about about 88,000 miles in the house.
2022-03-23 09:42:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:42:12 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, of course, i can also also have a lot of course to get a lot of course.
2022-03-23 09:42:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:42:16 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father because his father had his mother, she had his mother when she had his mother.
2022-03-23 09:42:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:42:21 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a lot of aids, and a child has been a child, so we asked us a child, so what do we do?
2022-03-23 09:42:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:42:25 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to our time about things like the same time, as we don't talk about the time, or each other people don't talk about each other.
2022-03-23 09:42:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:42:29 | INFO | fairseq.tasks.translation | example hypothesis: first, first, some of you are some of the maddddding in the way, but it doesn't need to be so if you need to change the energy.
2022-03-23 09:42:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the information of this information, we can start with a little bit of a little bit of the information, and we can use the information that's going to create the information, and all of the information.
2022-03-23 09:42:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons that it's interesting interesting to do, and it's interesting for me for me for me for me, "that we've got to say," and then we've got to say, "well," if we've got a lot of the best people who said, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "if we've got the best."
2022-03-23 09:42:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:39 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still always always always always always the mother, and the work of the work that we have a lot of work on our work that we've had to see that we had a lot of a lot of the way that we've had to see that we had to see that we had to see that we had to see that we've had to see a lot of a lot of a lot of a lot of the problems that we had to see that we had to see that we've had to see that we've been able to make a lot of a lot of a lot of a lot of a lot of a lot of the planet.
2022-03-23 09:42:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:39 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 7.592 | nll_loss 5.58 | ppl 47.84 | bleu 10.16 | wps 4537.7 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 10.16
2022-03-23 09:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:42:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:42:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:42:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 10.16) (writing took 1.7915923078544438 seconds)
2022-03-23 09:42:41 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:42:41 | INFO | train | epoch 011 | loss 7.861 | nll_loss 6.143 | ppl 70.69 | wps 43414.4 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.043 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1079
2022-03-23 09:42:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:06 | INFO | train_inner | epoch 012:     78 / 157 loss=7.586, nll_loss=5.78, ppl=54.93, wps=34814.4, ups=1.36, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=1.001, loss_scale=4, train_wall=30, gb_free=14.8, wall=1105
2022-03-23 09:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:35 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use these materials.
2022-03-23 09:43:35 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:43:39 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about 88,000 miles.
2022-03-23 09:43:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:43:43 | INFO | fairseq.tasks.translation | example hypothesis: so, i can also find that of course, of course, of course, of course.
2022-03-23 09:43:43 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:43:47 | INFO | fairseq.tasks.translation | example hypothesis: he had never been his father, because his father had his father, she had his mother when she had his father with him.
2022-03-23 09:43:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:43:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my grandgrandgrandfather is a child, and a child, so we asked us, so we said, what do?
2022-03-23 09:43:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:43:55 | INFO | fairseq.tasks.translation | example hypothesis: so we spend time time to talk about time, like time, and how to talk about time, or not about poverty, or each other, or each other, or each of the end of poverty.
2022-03-23 09:43:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:44:00 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of you're looking at the field, but it doesn't like the alalalalalalalalalalalalalalalaly, but if you need to use your own energy, you need to use your own energy, and so you need to use your own energy.
2022-03-23 09:44:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information to use the information, we can start from this map, we can start with one of the traditional, and we can start to start with one of the structure, and the structure of the structure of the structure, and the structure, which is all the structure of the structure, and the structure, and the information is all the information that's all the information.
2022-03-23 09:44:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example hypothesis: 19th: one of the reasons it's interesting, and it's interesting for me for me to be here for me, "yes," yes, "yes," well, "if you say," well, "well," if you're going to tell you're going to say, "the best."
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:12 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and the great part of the work that we're working on our work on our work, we had to use the bottom of our body, or if we had to use it to use it, we had to use it with a huge system, we had to use it with a huge system, and we had to use that it, we had to use it, and we had to use it to use it with a huge system, we had to use it with a huge system, we had to see that it, and we had to see that it, and we had to use it, if we had to see that it is to use it is that it, we had to use it, we had to use it, we had to use it's a huge huge source that it, we had to use it, we had to see that it, we had to be a huge huge huge huge huge amount of a huge amount of a huge system that it, we had to see that it, or to see that
2022-03-23 09:44:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:12 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 7.295 | nll_loss 5.182 | ppl 36.31 | bleu 11.88 | wps 4425.9 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.88
2022-03-23 09:44:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:44:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.88) (writing took 1.8003881168551743 seconds)
2022-03-23 09:44:13 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:44:13 | INFO | train | epoch 012 | loss 7.638 | nll_loss 5.845 | ppl 57.48 | wps 42893.7 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.027 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1172
2022-03-23 09:44:14 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:20 | INFO | train_inner | epoch 013:     21 / 157 loss=7.642, nll_loss=5.848, ppl=57.62, wps=33334.4, ups=1.35, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=1.01, loss_scale=4, train_wall=30, gb_free=14.1, wall=1179
2022-03-23 09:44:52 | INFO | train_inner | epoch 013:    121 / 157 loss=7.432, nll_loss=5.567, ppl=47.42, wps=80428.3, ups=3.2, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=1.059, loss_scale=4, train_wall=31, gb_free=13.9, wall=1210
2022-03-23 09:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:07 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical amount of plastic.
2022-03-23 09:45:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:45:10 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 miles.
2022-03-23 09:45:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:45:14 | INFO | fairseq.tasks.translation | example hypothesis: these rres i can also have a lot of course.
2022-03-23 09:45:14 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:45:18 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because she had his father.
2022-03-23 09:45:18 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:45:21 | INFO | fairseq.tasks.translation | example hypothesis: so one of my couoled is a child and a child, so we asked us what do we do?
2022-03-23 09:45:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:45:25 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about how to talk about time, and not about the number of poverty.
2022-03-23 09:45:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of these are in the field, but it doesn't like it, if you don't need your energy, it doesn't need your energy, and if you need your energy.
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information from this reflection that we can start with one of the traditional traditional work, and we can start able to start with the kind of form of information, and the structure of information is a whole structure of information.
2022-03-23 09:45:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting for me to be here for me to be here.
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother, and the big design of our work that we've had to see that we had to get a little bit that if we had to be able to be able to be able to be able to be able to make it.
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:39 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 7.221 | nll_loss 5.08 | ppl 33.83 | bleu 11.24 | wps 5109.7 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.88
2022-03-23 09:45:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:45:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:45:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:45:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 13 @ 2036 updates, score 11.24) (writing took 0.7624005861580372 seconds)
2022-03-23 09:45:39 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:45:39 | INFO | train | epoch 013 | loss 7.42 | nll_loss 5.552 | ppl 46.92 | wps 45854 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.025 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1258
2022-03-23 09:45:40 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:00 | INFO | train_inner | epoch 014:     64 / 157 loss=7.259, nll_loss=5.338, ppl=40.45, wps=37281.5, ups=1.46, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=0.991, loss_scale=4, train_wall=30, gb_free=13.9, wall=1278
2022-03-23 09:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:33 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use any chemical chemical chemical chemical chemical rays.
2022-03-23 09:46:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:46:37 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about about 8,000 miles in the restaurant.
2022-03-23 09:46:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example hypothesis: this rrum can also, of course, of course, of course, i can also have a lot of course, of course, of course, of course.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:46:46 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother, because she had his mother.
2022-03-23 09:46:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:46:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is died in aids, and a child has died, so we asked us, so what do we do?
2022-03-23 09:46:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to talk about how things like things, and we don't talk about things, or not talk about the amount of poverty.
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magile, but in the field, you know, if you don't like it, you don't need to move, you need to move the energy, and you need to move your energy.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the reflection of this reflection, we can start with a traditional traditional, and we can begin to start with a huge form of information, which is the whole structure of information, and the whole structure of information, and the whole information, and so if we're all going to use the information.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:10 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting, and it's interesting for me to be interesting for tedson, for me, "well, you know, you know," you know, "the best revolution, you've got to tell you, and you know, you know, you know, you know, you know," you know, you know, you know, you've got to have a long time, you know, you've got to have a long time, and you know, you've got to have a lot of course, and you know, you know, you know, "you've got to have a lot of course, and you've got to have a lot of course, you've got to have a long time, you know, you've got to have a lot of course, and you've got to have a lot of course, and you know,"
2022-03-23 09:47:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:13 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, it's still still the mother, and the invention of the invention that we have to use a big work on our plane, and we have to see that, if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we're all the water, or the water, or the water, and the water, and that we're still able to use of the water, if you're still able to see that we're still able to use of a whole whole whole whole whole whole whole source of the water, and the water, and that we're still able to see that we're still able to see that we're still able to see that we're still able to use of the water, and you're still able to use of the bottom of the water
2022-03-23 09:47:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:13 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 7.036 | nll_loss 4.806 | ppl 27.98 | bleu 12.36 | wps 4087.6 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 12.36
2022-03-23 09:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:47:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 12.36) (writing took 1.7364637986756861 seconds)
2022-03-23 09:47:14 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:47:14 | INFO | train | epoch 014 | loss 7.241 | nll_loss 5.309 | ppl 39.65 | wps 41568.3 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.02 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1353
2022-03-23 09:47:15 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:17 | INFO | train_inner | epoch 015:      7 / 157 loss=7.245, nll_loss=5.311, ppl=39.71, wps=32133, ups=1.3, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=1.017, loss_scale=4, train_wall=30, gb_free=14, wall=1355
2022-03-23 09:47:48 | INFO | train_inner | epoch 015:    107 / 157 loss=7.071, nll_loss=5.079, ppl=33.8, wps=80380.3, ups=3.22, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=0.935, loss_scale=4, train_wall=31, gb_free=13.8, wall=1387
2022-03-23 09:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:08 | INFO | fairseq.tasks.translation | example hypothesis: it can't use these chemical rays.
2022-03-23 09:48:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:48:12 | INFO | fairseq.tasks.translation | example hypothesis: it can be about about 8,000 places in the restaurant.
2022-03-23 09:48:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:48:16 | INFO | fairseq.tasks.translation | example hypothesis: this is of course, i can also be able to be able to make a very popular bible of forms.
2022-03-23 09:48:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his mother, because his mother had been pregnant when she was pregnant with him.
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:48:25 | INFO | fairseq.tasks.translation | example hypothesis: so one of my coup is died in aids and died in aids, so we asked us, so what do we do?
2022-03-23 09:48:25 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about how things like the equation and not talk about the nuclear weapons of poverty or other weapons.
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example hypothesis: first, first, some of the magic of magnetic lines in the field, but if you don't want to move it, if you don't need your movements, it doesn't need to move your energy, and if you need your movements.
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional view of traditional factors, and you can start able to start to start with a huge form of the form of the form of the shape, and the information that's what's going to do.
2022-03-23 09:48:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedson, for me, "yes, it's the best time to be in the best time," well, "if you're going to say," if you're going to have a man, "and then you're going to have a long time," and you're going to do it, "you're going to have a long time to do it," and you're going to do it, "and you're going to do it," and you're going to do it, "if you're going to do it's a long time to do it's a long time to do it," you're going to do it, "you're going to do it's a long time to do it's a long time," you're going to do it, "the
2022-03-23 09:48:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a big design part of design that we had to solve our plane on our plane, and we had to solve a unique plane that was a unique way to solve it, if we had to solve it with a unique source of the bottom of the ground, and if we had to solve it, it was to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:48:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.76 | nll_loss 4.417 | ppl 21.36 | bleu 16.05 | wps 4420.8 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.05
2022-03-23 09:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.05) (writing took 1.8295342731289566 seconds)
2022-03-23 09:48:47 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:48:47 | INFO | train | epoch 015 | loss 7.038 | nll_loss 5.035 | ppl 32.78 | wps 42771.5 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.894 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1445
2022-03-23 09:48:47 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:03 | INFO | train_inner | epoch 016:     50 / 157 loss=6.976, nll_loss=4.949, ppl=30.88, wps=33790.3, ups=1.34, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=0.819, loss_scale=4, train_wall=31, gb_free=14.4, wall=1461
2022-03-23 09:49:34 | INFO | train_inner | epoch 016:    150 / 157 loss=6.765, nll_loss=4.669, ppl=25.44, wps=81428.7, ups=3.25, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=0.853, loss_scale=4, train_wall=30, gb_free=13.7, wall=1492
2022-03-23 09:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:40 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical chemical rocket.
2022-03-23 09:49:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:49:48 | INFO | fairseq.tasks.translation | example hypothesis: and of course, of course, i can also make a popular bible to forms of course.
2022-03-23 09:49:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:49:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his mother had his mother, when she was pregpregnant.
2022-03-23 09:49:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:49:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is died in aids, and a wawaisa child asked us what do we do with?
2022-03-23 09:49:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or nuclear weapons.
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:50:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic lines in the field, but the sususususus don't move their movements, if they need the energy and so forth.
2022-03-23 09:50:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional face of traditional face, and the real face of the face of the face of the information, the whole structure of the information, and the information that we can use all the information, and the information of this reflection of this reflection of this reflection of this reflection of this reflection, which is a reflect of this reflection of this reflection
2022-03-23 09:50:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here for tedson, "well, when we were going to help them, it was a long time to help you, and then it's a long time to help you that the truth, and then when we're going to do it's interesting interesting, and then we're going to take it interesting interesting, you're going to take it up for me to take a long time for me to take it up for me, and then we have a long time for me, and then we have a long time for me, you're going to help you're going to help you're going to help you're going to help you're going to help you're going to help you're going to help you're going to help you're going to help you're going to help you're going to help you're going to take it up with this
2022-03-23 09:50:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:16 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother's invention of invention, and a big part of the design design, we had to use the aircraft of our aircraft, and if we had a unique problems that we had to solve it, it was a unique source of the bottom of the air, and it's all the aircraft, and it's going to use a huge amount of a huge amount of design, and a huge amount of design system, and a great part of a huge amount of design, and a big design, and a big design, and a big design of design of design, and a big design, and a great design of the aircraft, and a great design of the aircraft, and a great design, and a great design of the aircraft, and a great design, and a great design of design design design design design design of a great design, and a great design, and a great design, and a great design, and a great design, and a great design, and a great design, and a great design of design of the
2022-03-23 09:50:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:16 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.672 | nll_loss 4.294 | ppl 19.62 | bleu 17.23 | wps 4553.7 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 17.23
2022-03-23 09:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 17.23) (writing took 1.801940186880529 seconds)
2022-03-23 09:50:18 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:50:18 | INFO | train | epoch 016 | loss 6.825 | nll_loss 4.749 | ppl 26.89 | wps 43400.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.851 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 1536
2022-03-23 09:50:18 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:48 | INFO | train_inner | epoch 017:     93 / 157 loss=6.656, nll_loss=4.522, ppl=22.98, wps=35141.9, ups=1.36, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.785, loss_scale=4, train_wall=31, gb_free=13.9, wall=1566
2022-03-23 09:51:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:11 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:51:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:51:15 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:51:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:51:19 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also make sure of course, of course, of course, of course, i can also get a popular bible.
2022-03-23 09:51:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:51:23 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned, because his mother had learned his mother, when she was pregnant with him.
2022-03-23 09:51:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:51:27 | INFO | fairseq.tasks.translation | example hypothesis: so one of my coup has died in aids, and one of aids has died in aids, so we said, what do we do with her?
2022-03-23 09:51:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:51:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talk about the nuclear weapons of poverty or any other topic.
2022-03-23 09:51:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:51:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bold field of magnetic field in the field, but it doesn't like if you need your movements, and so you need your energy.
2022-03-23 09:51:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start to start with a traditional face of the face, and the real shape of the information, and the information, and the information of the information, which is the whole structure.
2022-03-23 09:51:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting to measure it interesting and measure it for me to be here in tedwomen, "well, that it was the best one of the men who said," and then when we've got them to say, "in a table," and then, "and then when we've got it's a long time."
2022-03-23 09:51:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big part of design, and a great design of design that we've had to solve is a result that we had to solve all the problems of the problems that it was connected to the ground -- all the way that it was connected to us to the ground, to the soil, and it's all of us to the air, to the air, to the air, to the air, or to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, to the air, or to the air, to the air, to the air,
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:47 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.511 | nll_loss 4.07 | ppl 16.8 | bleu 19.49 | wps 4526.5 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.49
2022-03-23 09:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:51:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:51:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.49) (writing took 1.8078953730873764 seconds)
2022-03-23 09:51:49 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:51:49 | INFO | train | epoch 017 | loss 6.621 | nll_loss 4.476 | ppl 22.25 | wps 43395.2 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.795 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1627
2022-03-23 09:51:49 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:00 | INFO | train_inner | epoch 018:     36 / 157 loss=6.558, nll_loss=4.392, ppl=20.99, wps=33555.7, ups=1.37, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=0.865, loss_scale=4, train_wall=30, gb_free=14, wall=1639
2022-03-23 09:52:32 | INFO | train_inner | epoch 018:    136 / 157 loss=6.494, nll_loss=4.303, ppl=19.75, wps=81233.2, ups=3.18, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.767, loss_scale=4, train_wall=31, gb_free=13.6, wall=1670
2022-03-23 09:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:42 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:52:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:52:46 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:52:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:52:50 | INFO | fairseq.tasks.translation | example hypothesis: i can also be able to make that rrors, of course, of course, to form a popular bible.
2022-03-23 09:52:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother, when she was pregnant.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, and has a wake child, so we said, well, what do we do with her?
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about things like gender times, and not talking about it or the nuclear weapons of poverty, or any other topic of poverty.
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic lines are coming in the inside of the inside, but the superconductor doesn't like it, if you move your movements, you don't need your energy, and so you need it.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that can start with a traditional face, which is the big constructions of the face, and then the information of information, which is all the structure of the structure, and all the structure.
2022-03-23 09:53:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it, for me to be here in tedsters, "is that... yes, when we're going to help you, you know," if you're going to help you, you know, you're going to help you, you know, you know, you know, "you know, you know, you're going to love the truth for your truth, you know," you know, you know, you know, "you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you've already, you know, you know, you know, you know, you know, you know, you're
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, we need to get the mother, and a great part of the design work that we're going to see in our plane, if you're going to see it, it's a result that we had to solve all the problems that it was connected to the ground -- everything that you're going to the air system of a system, if you're either going to be refrigeration, you're going to be able to refrigeration, you're going to be in the air system, you're going to be able to be refrigeration, you're going to be able to be able to be able to be able to be able to be able to be able to be able to be refrigeration, you're either in the air, you're either in the air.
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:18 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.312 | nll_loss 3.802 | ppl 13.95 | bleu 21.4 | wps 4574.2 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.4
2022-03-23 09:53:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:53:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:53:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.4) (writing took 1.8114060056395829 seconds)
2022-03-23 09:53:19 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:53:19 | INFO | train | epoch 018 | loss 6.495 | nll_loss 4.306 | ppl 19.79 | wps 43553.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.818 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 1718
2022-03-23 09:53:20 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:53:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:45 | INFO | train_inner | epoch 019:     79 / 157 loss=6.379, nll_loss=4.152, ppl=17.78, wps=33677.6, ups=1.38, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=0.768, loss_scale=4, train_wall=30, gb_free=13.6, wall=1743
2022-03-23 09:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:54:16 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:54:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:54:20 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also extend to form a popular bias.
2022-03-23 09:54:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:54:24 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had his mother when she was pregnant with him.
2022-03-23 09:54:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:54:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died to aids, so we asked, well, what do we do with?
2022-03-23 09:54:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:54:32 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:54:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:54:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some bold field of magnetic lines in the inside of the inside, but the superconductor doesn't like it, if you're moving, you need your movements, you need your movements.
2022-03-23 09:54:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face of the face, and the real shape of the face of the face, and the real shape of the information, and then then then then the information of the information, and then then the whole structure of the structure.
2022-03-23 09:54:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measures for me to be here at tedwomen, is that -- yes, at the best time, it was the best, when someone said, "and then you're going to be able to help you," you know, "you know," you know, when you're going to have a lot of women, "and then you're going to help you know," and then you know, "and then you're going to help you know," the truth, "and then you're going to be in the truth."
2022-03-23 09:54:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of invention, and a big part of design that we're in the aircraft, was a result of the aircraft, and we had to solve the unique problems that we had to solve the unique problems that were connected to the ground, and it's all the way to a refrigergergergergered to a refrigered to the bottom of the air system, or to a frigerman that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get rid of a frifrigergergergered to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:47 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.241 | nll_loss 3.712 | ppl 13.11 | bleu 21 | wps 4741.1 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.4
2022-03-23 09:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:54:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:54:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:54:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 19 @ 2978 updates, score 21.0) (writing took 0.7775949058122933 seconds)
2022-03-23 09:54:48 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:54:48 | INFO | train | epoch 019 | loss 6.343 | nll_loss 4.103 | ppl 17.19 | wps 44668.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.752 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1806
2022-03-23 09:54:48 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:55 | INFO | train_inner | epoch 020:     22 / 157 loss=6.335, nll_loss=4.093, ppl=17.07, wps=35616.3, ups=1.42, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.73, loss_scale=4, train_wall=30, gb_free=14.6, wall=1813
2022-03-23 09:55:27 | INFO | train_inner | epoch 020:    122 / 157 loss=6.122, nll_loss=3.815, ppl=14.08, wps=82453.2, ups=3.18, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.648, loss_scale=4, train_wall=31, gb_free=22.4, wall=1845
2022-03-23 09:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:41 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:55:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:55:45 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:55:45 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:55:49 | INFO | fairseq.tasks.translation | example hypothesis: i can also extend to form a bible.
2022-03-23 09:55:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:55:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 09:55:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:55:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, so we asked us, what do we do with?
2022-03-23 09:55:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:56:01 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend time to talk about things like gender times and not talking about anxd or the spread of nuclear weapons or poverty or poverty, or every other time we spend time.
2022-03-23 09:56:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:56:06 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some bold field in the inside, but the supermagnetic field doesn't like the superconductor, if you're moving, if you're moving on, because your movements, your movements, your movements, and so the superpower of magnetic field.
2022-03-23 09:56:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:10 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big facial level of face, and the real shape of face, and the real shape of the face, and the real information that we can fold.
2022-03-23 09:56:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it starts to be interesting and measured for me to be here at tedwomen, is that... yes, in the top of the best time, is that -- when it was decreased by someone said, "you know, it starts to help you."
2022-03-23 09:56:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we had to solve the mother of invention, and a big part of design work that allows us to see on our airplane on the plane, is a result that we had to solve a result of it, that we had to solve the unique problems that we had to solve all the unique problems that we had to refrigeration, and to be able to be able to be able to be able to be able to create a refrigeration with a refrigeration with a refrigeration system, and to be refrigeration, and to be able to be able to create a refrigeration, and to be able to be able to use it, and to be able to be able to be able to be able to be able to create a refrigeration system that it's a refrigeration, if we're used to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a refrigeration,
2022-03-23 09:56:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:17 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.182 | nll_loss 3.645 | ppl 12.51 | bleu 22.9 | wps 4517 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.9
2022-03-23 09:56:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:56:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:56:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.9) (writing took 1.7714464059099555 seconds)
2022-03-23 09:56:19 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:56:19 | INFO | train | epoch 020 | loss 6.185 | nll_loss 3.898 | ppl 14.91 | wps 43385.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.68 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1897
2022-03-23 09:56:19 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:40 | INFO | train_inner | epoch 021:     65 / 157 loss=6.196, nll_loss=3.911, ppl=15.04, wps=33661.7, ups=1.37, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.717, loss_scale=4, train_wall=30, gb_free=14.7, wall=1918
2022-03-23 09:57:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:12 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rocket.
2022-03-23 09:57:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can protect about 8,000 places in the restaurant.
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand to form a popular bias.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father left his mother when she was pregnant.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died in aids, and we asked us what do we do?
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:57:31 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend time talking about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:57:31 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:57:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some bble of magnetic field in the inner lines, but the superconductor doesn't like it, if you move your movements, and so the superconductor disorders.
2022-03-23 09:57:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big configuration of the face and the basic shape, and through that information, the whole ports and fold all the structure.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here in tedwomen, is that... yes, it was the best, when someone said, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [" '"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we were on our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuing to refrigerate and refrigerate it from a continuation to refrigerate and refrigerate that we're going to refrigerate it.
2022-03-23 09:57:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:45 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.007 | nll_loss 3.375 | ppl 10.38 | bleu 24.53 | wps 4986.9 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.53
2022-03-23 09:57:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:57:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 09:57:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.53) (writing took 1.7571026049554348 seconds)
2022-03-23 09:57:47 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:57:47 | INFO | train | epoch 021 | loss 6.078 | nll_loss 3.757 | ppl 13.52 | wps 44961.8 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.647 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1985
2022-03-23 09:57:47 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:50 | INFO | train_inner | epoch 022:      8 / 157 loss=6.015, nll_loss=3.676, ppl=12.78, wps=36248.1, ups=1.43, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.614, loss_scale=4, train_wall=30, gb_free=14.3, wall=1988
2022-03-23 09:58:21 | INFO | train_inner | epoch 022:    108 / 157 loss=6.004, nll_loss=3.661, ppl=12.65, wps=80894.4, ups=3.2, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.668, loss_scale=4, train_wall=31, gb_free=13.9, wall=2019
2022-03-23 09:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:40 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical rockets.
2022-03-23 09:58:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example hypothesis: it can protect about 8,000 places in the restaurant.
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this round magnets.
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father left his mother when she was pregnant.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids and has an orphanage child, so we asked what do we do with her?
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:58:58 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend time talking about things like gender times and not talking about nuclear weapons or poverty or any other promising topic.
2022-03-23 09:58:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:59:02 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bold field of magnetic field are coming inside, but the superconductor doesn't like when you move your movements, you need your movements, and so the superconductor.
2022-03-23 09:59:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional factors of face and the basic form, and recovery, and then recoat it through the information that consequence the whole structure.
2022-03-23 09:59:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was interesting and measured to me here at tedwomen, is that... well, when it was stripped out, when someone said, "she said," take you to the men and say, "well, when the revolution begins.
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big piece of design work that we were on the plane was a result that we had to solve the unique problems that we were connected to the ground -- all sorts of refrigeration in a refrigeration system, and we're going to use it from a refrigeration system, and we're either going to be able to see it.
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:11 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.068 | nll_loss 3.469 | ppl 11.07 | bleu 20.68 | wps 5264.5 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.53
2022-03-23 09:59:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:59:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:59:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 09:59:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 20.68) (writing took 0.7948457482270896 seconds)
2022-03-23 09:59:12 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:59:12 | INFO | train | epoch 022 | loss 5.983 | nll_loss 3.634 | ppl 12.42 | wps 46517.4 | ups 1.85 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.656 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2070
2022-03-23 09:59:12 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:28 | INFO | train_inner | epoch 023:     51 / 157 loss=5.884, nll_loss=3.506, ppl=11.36, wps=37549.6, ups=1.49, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.636, loss_scale=4, train_wall=30, gb_free=14.7, wall=2086
2022-03-23 09:59:59 | INFO | train_inner | epoch 023:    151 / 157 loss=5.9, nll_loss=3.526, ppl=11.52, wps=80034.4, ups=3.23, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.585, loss_scale=4, train_wall=31, gb_free=13.9, wall=2117
2022-03-23 10:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example hypothesis: this sonde can't use chemical rockets.
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:00:08 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 10:00:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:00:13 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand that rough magnets, of course, to shape a popular equation.
2022-03-23 10:00:13 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:00:16 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 10:00:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:00:20 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died of aids, and we asked us, well, what do we do with her?
2022-03-23 10:00:20 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:00:24 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about the spread of nuclear weapons, or poverty or any other promising topic.
2022-03-23 10:00:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:00:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble of magnet field lines are caught in the inside, but the superconductor doesn't like it if you move, because your movements need, and so the superconductor disorders.
2022-03-23 10:00:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face, which is the big configuration of facial and the basic shape, and by the theft, the whole portion structure and all fold a fold.
2022-03-23 10:00:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measuring it to be here at tedwomen, is that... well, when you were the best dinner, when somebody said, "take you to the men on a table and say," if the revolution begins to be here, "if we're going to support you," and then you're going to support you, "the truth for me here," women, "you know," you know, "you know," you know, you know, "you know, you know, you know, you know, you know, you know, you know, you know, you know, you know," you know, you know, you're already, you know, you know, you know, you know, you know, you're going to have a sandra ra ra ra ra ra ra chief, "and then
2022-03-23 10:00:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane on the tooth, was a result of that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation of a system, and a refrigeration system that allows us to use it to refrigerate it to a refrigeration to a refrigeration to the ridge it to a ridge it to a ridge it to the operation of a system, to the operative, or to the wheat the wheel it, to the wheat the wheel, if we're also a refrigeration of a refrigeration of a system, it, to the wheat the wheat the wheat the wheat the wheat, it, it, it, it, it, it, it, it, it was a refrigeration of a refrigeration of a refrigeration
2022-03-23 10:00:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:40 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.799 | nll_loss 3.114 | ppl 8.66 | bleu 27.59 | wps 4683.9 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.59
2022-03-23 10:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:00:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:00:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.59) (writing took 1.8181137018837035 seconds)
2022-03-23 10:00:41 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:00:41 | INFO | train | epoch 023 | loss 5.87 | nll_loss 3.487 | ppl 11.21 | wps 43999.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.587 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2160
2022-03-23 10:00:42 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:12 | INFO | train_inner | epoch 024:     94 / 157 loss=5.767, nll_loss=3.355, ppl=10.23, wps=34613.6, ups=1.38, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.557, loss_scale=4, train_wall=30, gb_free=14, wall=2190
2022-03-23 10:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:35 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:01:35 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:01:39 | INFO | fairseq.tasks.translation | example hypothesis: it can protect about 8,000 places in the restaurant.
2022-03-23 10:01:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:01:43 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that smoke magnets, of course, to form a popular bias.
2022-03-23 10:01:43 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:01:47 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:01:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died to aids, and has a waisena child backwards, so we asked us, well, what do we do with her?
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, and not about the prevalence of nuclear weapons or poverty or any other talk.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught inside the inner lines, but the superconductor doesn't like when you move, because your movements use, and so the superconducting disorder.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection, we can start with a traditional facial can start with the big constructions of the face and the basic shape, which is all the porting structure and fold a fold.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it starts to be interesting and measured for me to be here at tedwomen, is that... well, when destrict dinner, it was best summarized as someone said, "turn you to the men of a table, and then we have love you for this long time."
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to the ground -- all of us to use it from a refrigeration system that allows us to use a ridge or a ridge.
2022-03-23 10:02:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:08 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.796 | nll_loss 3.124 | ppl 8.72 | bleu 27.14 | wps 5058.2 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.59
2022-03-23 10:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 24 @ 3763 updates, score 27.14) (writing took 0.8504420141689479 seconds)
2022-03-23 10:02:09 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:02:09 | INFO | train | epoch 024 | loss 5.797 | nll_loss 3.394 | ppl 10.51 | wps 45290.5 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.587 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2247
2022-03-23 10:02:09 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:20 | INFO | train_inner | epoch 025:     37 / 157 loss=5.81, nll_loss=3.411, ppl=10.64, wps=36083.9, ups=1.45, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.621, loss_scale=4, train_wall=30, gb_free=14.7, wall=2259
2022-03-23 10:02:52 | INFO | train_inner | epoch 025:    137 / 157 loss=5.737, nll_loss=3.317, ppl=9.97, wps=81058, ups=3.19, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.594, loss_scale=4, train_wall=31, gb_free=13.8, wall=2290
2022-03-23 10:02:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:02 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:03:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can expand to form a popular equality.
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:03:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 10:03:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:03:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well, what do we do with her?
2022-03-23 10:03:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example hypothesis: and that's why we spend our time talking about things like equality and not about genocide or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field are caught inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which is the big configuration of the facial and the basic form, which is the whole portion structure, which is the whole porture structure and all the fold.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured to me here at tedwomen, is that... well, at the dedicated dinner, it was the best summarized when someone said, "wade you to the men on your table and say," if the revolution begins to me, "when the revolution begins to be here at tedwomen," and then we support you. "
2022-03-23 10:03:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on the plane on the stest tower, was a result of that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation to the earth -- all of us to a continuous variation and a refrigeration system that allows us to use the wheel when you see the wheel in the ground, when you can see the wheel on the wheel on the wheel to the wheel in the wheel, when you can see the wheel, the wheel on the wheel, the wheel to the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the wheel, the
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:36 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.723 | nll_loss 3.015 | ppl 8.08 | bleu 28.61 | wps 4703.1 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.61
2022-03-23 10:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:03:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.61) (writing took 1.847883454989642 seconds)
2022-03-23 10:03:38 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:03:38 | INFO | train | epoch 025 | loss 5.735 | nll_loss 3.314 | ppl 9.94 | wps 44033.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.59 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2336
2022-03-23 10:03:39 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:03:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:04 | INFO | train_inner | epoch 026:     80 / 157 loss=5.66, nll_loss=3.217, ppl=9.3, wps=35304.2, ups=1.39, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.551, loss_scale=4, train_wall=30, gb_free=14, wall=2362
2022-03-23 10:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:32 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rockets.
2022-03-23 10:04:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:04:36 | INFO | fairseq.tasks.translation | example hypothesis: he can overcome about 8,000 places in the restaurant.
2022-03-23 10:04:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:04:40 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand this rotating magnet, of course, to form a popular equation.
2022-03-23 10:04:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:04:44 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:04:44 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:04:48 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well, what do we do with her?
2022-03-23 10:04:48 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:04:52 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equals, and not talking about angry or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:04:52 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:04:56 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, your movements use, and so the superconductor disorder.
2022-03-23 10:04:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, the big constructions of facial and the basic form, which is all the ports.
2022-03-23 10:05:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured for me to be here at tedwomen, is that... tyes, it was the best summarized when somebody said to men at ddesk and they say, "if the revolution starts to support you."
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're on our airplane are the stest towers, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use a refrigerator, it allows us to use it in the aircraft, if you can use it, you can use it in the gogods, you can use it to use it to use the wheels, you can use it to use it to use it to make a distorm.
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:07 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.703 | nll_loss 3.002 | ppl 8.01 | bleu 28.4 | wps 4772 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.61
2022-03-23 10:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:05:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:05:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 26 @ 4077 updates, score 28.4) (writing took 0.7746029761619866 seconds)
2022-03-23 10:05:07 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:05:07 | INFO | train | epoch 026 | loss 5.658 | nll_loss 3.218 | ppl 9.3 | wps 44341.7 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.546 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2426
2022-03-23 10:05:08 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:15 | INFO | train_inner | epoch 027:     23 / 157 loss=5.673, nll_loss=3.238, ppl=9.43, wps=35282.9, ups=1.4, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.583, loss_scale=4, train_wall=30, gb_free=13.7, wall=2433
2022-03-23 10:05:46 | INFO | train_inner | epoch 027:    123 / 157 loss=5.592, nll_loss=3.132, ppl=8.77, wps=80062.1, ups=3.21, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.486, loss_scale=4, train_wall=31, gb_free=14.1, wall=2464
2022-03-23 10:05:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:01 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:06:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:06:05 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:06:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:06:09 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can expand to form any kind of same same thing.
2022-03-23 10:06:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:06:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:06:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well what do we do with her?
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equals and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are caught in the inside, but the superconductor doesn't like it, if you move, because you use your movements, and so the superconducting disorders.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which is the big constructions of the face and the basic shape, and by the thief information, which is the whole porter structure and all folding a fold.
2022-03-23 10:06:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen, is that... well, in the strict dinner, it became the best, when someone said, "take you to the men at your table and say," if the revolution starts to support you, "women have already been supporting you for this long time."
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we are on our plane is the stest, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft in a particular, to make it happen to a specific machine.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:36 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.64 | nll_loss 2.921 | ppl 7.57 | bleu 29.62 | wps 4678.7 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.62
2022-03-23 10:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:06:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:06:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:06:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.62) (writing took 1.7803091839887202 seconds)
2022-03-23 10:06:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:06:38 | INFO | train | epoch 027 | loss 5.588 | nll_loss 3.127 | ppl 8.74 | wps 43784.7 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.525 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2516
2022-03-23 10:06:38 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:06:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:59 | INFO | train_inner | epoch 028:     66 / 157 loss=5.555, nll_loss=3.086, ppl=8.49, wps=35088, ups=1.38, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.539, loss_scale=4, train_wall=31, gb_free=13.9, wall=2537
2022-03-23 10:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:31 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:07:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:07:35 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:07:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:07:39 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this rough magnet to shape an unpopular equation.
2022-03-23 10:07:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:07:42 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:07:42 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:07:46 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a waisena child, so we asked ourselves, well, what do we do with them?
2022-03-23 10:07:46 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:07:50 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:07:50 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big constructions of the face and the basic shape of it, and by the one of the things that the whole ports structure and all fold a fold.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it was the best together when someone said, "turn you to the men at your table and tell them," if the revolution starts to support you. "
2022-03-23 10:08:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation and refrigeration system that allows us to use a machine in the aircraft, or when you get rid of the propelled, if you're going to be able to get rid of a mechanism, if you're going to see the wheel, if you're going to get rid of a mechanism, you're going to be able to get rid of a mechanism, if you're going to be able to get rid of a mechanism, you're going to get rid of the wheel out of the wheel, you're going to get rid of the wheel, or a mechanism, if you're getting rid of the wheel, if you're getting rid of the wheel, you're going to be able to get rid of the wheel, you're
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:05 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.559 | nll_loss 2.84 | ppl 7.16 | bleu 29.87 | wps 4763.6 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.87
2022-03-23 10:08:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:08:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:08:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:08:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.87) (writing took 1.8170028920285404 seconds)
2022-03-23 10:08:07 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:08:07 | INFO | train | epoch 028 | loss 5.555 | nll_loss 3.086 | ppl 8.49 | wps 44024.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.54 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2605
2022-03-23 10:08:08 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:11 | INFO | train_inner | epoch 029:      9 / 157 loss=5.524, nll_loss=3.046, ppl=8.26, wps=34918.9, ups=1.39, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.508, loss_scale=4, train_wall=31, gb_free=14.1, wall=2609
2022-03-23 10:08:42 | INFO | train_inner | epoch 029:    109 / 157 loss=5.483, nll_loss=2.995, ppl=7.97, wps=81043.1, ups=3.21, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.514, loss_scale=4, train_wall=31, gb_free=14.6, wall=2640
2022-03-23 10:08:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:00 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:09:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:09:04 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:09:04 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:09:08 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this roundant magnet, and i can expand, of course, to form any same glimpse.
2022-03-23 10:09:08 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:09:12 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father because his father left his mother when she was pregnant with him.
2022-03-23 10:09:12 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we left a waisena child, so we asked us, well, what do we do with her?
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:09:20 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide, or the spread of nuclear weapons or poverty, or any other talk about it.
2022-03-23 10:09:20 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:09:24 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:09:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:28 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can start, which is the big constructions of the face, and the baseline is repeated, and all the ports.
2022-03-23 10:09:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and appropriate for me to be here at tedwomen, is that... well, at the striking dinner, it was best summarized when somebody said, "take you to the men at your table and say," if the revolution begins, women love you for this issue, we have already been supporting you for this theme for a long time. "
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we've been on on on our airplane is a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variation and refrigeration system, that allows us to use a fluid system that allows us to use it in the aircraft.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:34 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.545 | nll_loss 2.821 | ppl 7.07 | bleu 29.56 | wps 4821.8 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.87
2022-03-23 10:09:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:09:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 29 @ 4548 updates, score 29.56) (writing took 0.7776605067774653 seconds)
2022-03-23 10:09:35 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:09:35 | INFO | train | epoch 029 | loss 5.469 | nll_loss 2.977 | ppl 7.87 | wps 44956.9 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.503 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2693
2022-03-23 10:09:35 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:09:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:09:52 | INFO | train_inner | epoch 030:     52 / 157 loss=5.421, nll_loss=2.916, ppl=7.55, wps=35569.8, ups=1.43, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.505, loss_scale=4, train_wall=30, gb_free=14.4, wall=2710
2022-03-23 10:10:23 | INFO | train_inner | epoch 030:    152 / 157 loss=5.429, nll_loss=2.927, ppl=7.6, wps=81253.7, ups=3.23, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.455, loss_scale=4, train_wall=31, gb_free=13.9, wall=2741
2022-03-23 10:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:28 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:10:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:10:32 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:10:32 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:10:37 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can expand, to form any same kind of thing.
2022-03-23 10:10:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:10:41 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:10:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:10:45 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a waisena child, so we asked ourselves, well, what do we do with her?
2022-03-23 10:10:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equals and not talking about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:10:49 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:10:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are caught inside, but the superconductor doesn't like when you move, because your movements use energy, and the superconducting disorders.
2022-03-23 10:10:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, the big constructions of the face and the basic shape, and recover it through the thief information that refers the whole porter structure and all the fine folds.
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and it's appropriate for me to be here at tedwomen, is that... well, when he was striking dinner, it was the best summit, when someone said, "turn you to the men on your table and say," if the revolution begins, the truth is that we have a long time for carchson's time. "
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on on our airplane are the stallest tower, was a result of that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigeration system that allows us to use a machine in the garbage of the propeller, or if you're either going to have to see the ground, it's a mechanism.
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:03 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 5.465 | nll_loss 2.729 | ppl 6.63 | bleu 31.41 | wps 4716.6 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.41
2022-03-23 10:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.41) (writing took 1.8025980899110436 seconds)
2022-03-23 10:11:05 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:11:05 | INFO | train | epoch 030 | loss 5.416 | nll_loss 2.91 | ppl 7.52 | wps 43960.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.472 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2783
2022-03-23 10:11:05 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:35 | INFO | train_inner | epoch 031:     95 / 157 loss=5.362, nll_loss=2.841, ppl=7.17, wps=34650.7, ups=1.38, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.48, loss_scale=4, train_wall=31, gb_free=14.5, wall=2814
2022-03-23 10:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:11:58 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:11:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:12:03 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:12:03 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:12:06 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, can expand, to form any equality.
2022-03-23 10:12:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and did we leave a waisena child, so we asked ourselves, well, what do we do with her?
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:12:23 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use, and so the superconductor disturbs.
2022-03-23 10:12:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial sscan, which gives the big constructions of the face and the basic shape, and then decrease it through the theft information that refits the entire portion structure and all the fits folds.
2022-03-23 10:12:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's highly interesting and appropriate for me to be here at tedwomen is that... well, when you dinner dinner, it was the best summarized when someone said, "turn you to the men on your table and say to them," if the revolution begins, then we support you. "
2022-03-23 10:12:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane are the stumber, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation of design and a cooling system that allows us to use an aircraft to the air system, that allows us to use a steady machine in the air, to a steady system, to the edge of the propeller when you get rid of the earth, or if you can see it, if you get rid of the earth, if you can see it, if you get rid of the forces, if you get rid of the earth, if you get rid of the earth, if you get rid of the earth, if you get rid of the trustops to the earth, if you get rid of the earth, or if you get rid of the earth, if you get rid of the earth, if you get rid of the air, you get rid
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:34 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 5.495 | nll_loss 2.762 | ppl 6.79 | bleu 31.33 | wps 4617.1 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.41
2022-03-23 10:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:12:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:12:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 31 @ 4862 updates, score 31.33) (writing took 0.8087203628383577 seconds)
2022-03-23 10:12:35 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:12:35 | INFO | train | epoch 031 | loss 5.372 | nll_loss 2.856 | ppl 7.24 | wps 44067 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.488 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2873
2022-03-23 10:12:35 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:12:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:47 | INFO | train_inner | epoch 032:     38 / 157 loss=5.385, nll_loss=2.872, ppl=7.32, wps=35326.9, ups=1.4, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.514, loss_scale=4, train_wall=30, gb_free=14.9, wall=2885
2022-03-23 10:13:18 | INFO | train_inner | epoch 032:    138 / 157 loss=5.296, nll_loss=2.758, ppl=6.76, wps=81172.7, ups=3.21, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.412, loss_scale=4, train_wall=31, gb_free=14.1, wall=2916
2022-03-23 10:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:28 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:13:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:13:32 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:13:32 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:13:36 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets to shape any equation.
2022-03-23 10:13:36 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:13:40 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:13:40 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:13:44 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:13:44 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:13:48 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:13:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:13:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:13:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that gives the big constructions of the face and the basic shape, and then recover it through the theft information that pulls the whole portion structure and all the folds.
2022-03-23 10:13:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and appropriate for me to be here at tedwomen is that... tyes, dinner was the best summarized when someone said, "turn you to the men on your table and say to them," if the revolution begins, then we support you, "the truth is that we've already been supporting you for this issue for a long time."
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:01 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the go-go-go-to-specialized traffic to a particular device that's either a mechanism.
2022-03-23 10:14:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:01 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 5.423 | nll_loss 2.679 | ppl 6.4 | bleu 31.33 | wps 4946.4 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.41
2022-03-23 10:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:14:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:14:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.33) (writing took 1.124884441960603 seconds)
2022-03-23 10:14:02 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:14:02 | INFO | train | epoch 032 | loss 5.316 | nll_loss 2.783 | ppl 6.88 | wps 44939 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.447 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2961
2022-03-23 10:14:03 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:28 | INFO | train_inner | epoch 033:     81 / 157 loss=5.287, nll_loss=2.745, ppl=6.71, wps=35633.8, ups=1.42, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.437, loss_scale=4, train_wall=31, gb_free=13.5, wall=2987
2022-03-23 10:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:14:55 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:14:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:14:59 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:14:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:15:03 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these roundmagnetic magnets to form any sort of any glimpse.
2022-03-23 10:15:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:15:07 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:15:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:15:11 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:15:11 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic shape of the face, and through the theft information that refers the entire porch structure and all the fine wrints.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and appropriate for me to be here at tedwomen, is that -- well, when contested dinner, it became best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, we support you. "'"
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a big part of the design work that we're on on our airplane are the staggering tower, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied variable drivers and a cooling system that allows us to use an aircraft at the most proud of a steady machine, and a divance system that allows us to be a diarrhea, and a mechanism, if you're going to be a steady, if you're going to be a mechanism, if you're going to be a mechanism, if you're going to operate in the basement.
2022-03-23 10:15:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:31 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 5.421 | nll_loss 2.679 | ppl 6.41 | bleu 31.84 | wps 4623.3 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.84
2022-03-23 10:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.84) (writing took 1.8039571540430188 seconds)
2022-03-23 10:15:33 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:15:33 | INFO | train | epoch 033 | loss 5.278 | nll_loss 2.736 | ppl 6.66 | wps 43700.5 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.453 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3051
2022-03-23 10:15:33 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:41 | INFO | train_inner | epoch 034:     24 / 157 loss=5.247, nll_loss=2.699, ppl=6.49, wps=34795.1, ups=1.38, wpb=25158.1, bsz=1109.5, num_updates=5200, lr=0.000438529, gnorm=0.464, loss_scale=4, train_wall=30, gb_free=14, wall=3059
2022-03-23 10:16:12 | INFO | train_inner | epoch 034:    124 / 157 loss=5.243, nll_loss=2.689, ppl=6.45, wps=80379.2, ups=3.2, wpb=25147.3, bsz=995.5, num_updates=5300, lr=0.000434372, gnorm=0.438, loss_scale=4, train_wall=31, gb_free=14, wall=3090
2022-03-23 10:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:26 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:16:26 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:16:34 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these roundmagnetic magnets to shape any kind of thing.
2022-03-23 10:16:34 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:16:42 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:16:42 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:16:46 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:16:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:16:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and the superconductor disorder.
2022-03-23 10:16:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial ugly, which gives the big constructions of the face and the basic shape, and recover it through the theft information that refers all the portion structure and all the fits it folds.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen, is that -- well, at the strict dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution starts, we support you. '"the truth, women's love is that we're already supporting you about this issue for a long time.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're on our plane is the most proud result that we had to solve the unique problems that were connected to operating on the ground -- all, from a continuous variation and cooling system with fluid that allows us to use an aircraft at the same time, that allows us to use an aircraft in the stop and use it to use it in the most specific traffic, or if you get rid of a particular, if you get rid of the propelled, if you get rid of a mechanism in the ground, if you get rid of a mechanism, if you get rid of a mechanically, you get rid of a mechanically, you get rid of the same, you get rid of the same, you get rid of a mechanism in the same thing you get rid of the same thing you get rid of the same, and you get rid of the air, you get rid of the same stuff you get rid of the safety
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:01 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.386 | nll_loss 2.633 | ppl 6.2 | bleu 32.29 | wps 4675.8 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.29
2022-03-23 10:17:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:17:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:17:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:17:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.29) (writing took 1.7447444763965905 seconds)
2022-03-23 10:17:03 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:17:03 | INFO | train | epoch 034 | loss 5.247 | nll_loss 2.695 | ppl 6.48 | wps 43841.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.442 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3141
2022-03-23 10:17:03 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:24 | INFO | train_inner | epoch 035:     67 / 157 loss=5.248, nll_loss=2.698, ppl=6.49, wps=34227.5, ups=1.38, wpb=24737.3, bsz=977.8, num_updates=5400, lr=0.000430331, gnorm=0.436, loss_scale=4, train_wall=31, gb_free=14.7, wall=3162
2022-03-23 10:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:17:56 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:17:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:18:00 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:18:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:18:03 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these roundmagnets to form any same glimpse.
2022-03-23 10:18:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:18:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:18:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:18:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:18:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or nuclear weapons or poverty or any other promising topic.
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:23 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial configurations that repeat the big constructions of facial and the basic form, and recover it through the information that refers the whole portion structure and all the fine folds.
2022-03-23 10:18:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen, is that -- well, when constrict dinner, it was best summarized when someone said, "turn you to the men at your table and tell you," if the revolution begins, then we support you. 'love, women is that we've already been supported for a long time. "
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we have at our airplane the staggering tower was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation of design and refrigeration system that allows us to use an aircraft to stop traffic, to a vibrant traffic, to a particular bite, to a particular bicycle cycle, to a particular drive drive the propeller, either if you can see the propellant, or a mechanism, if you can't see the propelled way down to a mechanism, if you see the earth's current current current current current current current current current current current current current current transport, to the prophecy, to a particular fly.
2022-03-23 10:18:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:30 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.376 | nll_loss 2.618 | ppl 6.14 | bleu 31.92 | wps 4825.9 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.29
2022-03-23 10:18:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:18:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:18:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.92) (writing took 0.8274331707507372 seconds)
2022-03-23 10:18:31 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:18:31 | INFO | train | epoch 035 | loss 5.213 | nll_loss 2.653 | ppl 6.29 | wps 44973 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.439 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3229
2022-03-23 10:18:31 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:18:34 | INFO | train_inner | epoch 036:     10 / 157 loss=5.2, nll_loss=2.636, ppl=6.22, wps=36466.6, ups=1.43, wpb=25566.1, bsz=1051.8, num_updates=5500, lr=0.000426401, gnorm=0.437, loss_scale=4, train_wall=30, gb_free=14.2, wall=3233
2022-03-23 10:19:06 | INFO | train_inner | epoch 036:    110 / 157 loss=5.162, nll_loss=2.589, ppl=6.02, wps=82007.8, ups=3.19, wpb=25691.2, bsz=1093.6, num_updates=5600, lr=0.000422577, gnorm=0.448, loss_scale=4, train_wall=31, gb_free=13.5, wall=3264
2022-03-23 10:19:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:24 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:19:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:19:27 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:19:27 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:19:32 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this round magnets to shape a popular glimpse.
2022-03-23 10:19:32 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:19:36 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:19:36 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:19:40 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:19:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:19:44 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty, or any other talk about it.
2022-03-23 10:19:44 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:19:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:19:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:52 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constructions of the face and the basic form, and recover it through the same information that pulls the entire porch structure and all the fine wrinkles.
2022-03-23 10:19:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:19:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, in the strictly dinner, it was best summarized when someone said, "well, you turn it to the men in your table and say," if the revolution begins, then we support you. "the truth, women love you, that we've already started this issue for a long time." in fact, carchel borne, "and then we've been supporting the future," in the future of sand, "and then we've got to downstream."
2022-03-23 10:19:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we have at our aircraft is the most staggering tower, a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variable and cooling system that allows us to use an aircraft at the same time, to be able to use the trusting traffic, or to a particular passenger system, that either you can see the propellment of a mechanism.
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:19:58 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 5.352 | nll_loss 2.591 | ppl 6.02 | bleu 32.93 | wps 4700.5 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.93
2022-03-23 10:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:19:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.93) (writing took 1.866066835820675 seconds)
2022-03-23 10:20:00 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:20:00 | INFO | train | epoch 036 | loss 5.182 | nll_loss 2.613 | ppl 6.12 | wps 44035.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.441 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3319
2022-03-23 10:20:01 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:20:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:17 | INFO | train_inner | epoch 037:     53 / 157 loss=5.184, nll_loss=2.616, ppl=6.13, wps=34298.3, ups=1.39, wpb=24594.8, bsz=930.9, num_updates=5700, lr=0.000418854, gnorm=0.42, loss_scale=4, train_wall=30, gb_free=13.6, wall=3336
2022-03-23 10:20:48 | INFO | train_inner | epoch 037:    153 / 157 loss=5.153, nll_loss=2.577, ppl=5.97, wps=81330.9, ups=3.24, wpb=25108.7, bsz=1017.4, num_updates=5800, lr=0.000415227, gnorm=0.432, loss_scale=4, train_wall=30, gb_free=14.7, wall=3367
2022-03-23 10:20:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:20:53 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:20:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:20:57 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:20:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:21:01 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circular magnet to shape any kind of thing.
2022-03-23 10:21:01 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:21:05 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:21:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:21:09 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:21:09 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:21:13 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or nuclear weapons or poverty or any other promising topic.
2022-03-23 10:21:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are caught inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:21 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information coming from this reflection, we can start with a traditional facial constructions of facial and the basic form, and then recover it through the thief information that refers the whole portion structure and all the ffits folds.
2022-03-23 10:21:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when constrict dinner, it became the best summarized when someone said, "turn you to the men on your table and say to them," when the revolution starts, we support you. '"
2022-03-23 10:21:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we have stumbled on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable operating and cooling system with fluid that allows us to use an aircraft on the surface to either be able to run the propelled when you're in the ground, or if you're either mechanical, you're going to get rid of the propelled, and you're either going to be able to be able to be able to be able to be able to use the aircraft, if you're going to get rid of the air, if you're going to get rid of the air, and you're going to run, if you're going to get rid of the wheels, if you're going to get rid of the dignity, and you're going to be able to be able to be able to be able to be able to get rid of the
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:27 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 5.355 | nll_loss 2.586 | ppl 6 | bleu 32.73 | wps 4847 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.93
2022-03-23 10:21:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:21:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:21:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:21:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.73) (writing took 0.7972273780032992 seconds)
2022-03-23 10:21:28 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:21:28 | INFO | train | epoch 037 | loss 5.142 | nll_loss 2.562 | ppl 5.91 | wps 45066.5 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.418 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3406
2022-03-23 10:21:28 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:21:58 | INFO | train_inner | epoch 038:     96 / 157 loss=5.135, nll_loss=2.553, ppl=5.87, wps=35615.1, ups=1.43, wpb=24888.9, bsz=988.9, num_updates=5900, lr=0.000411693, gnorm=0.457, loss_scale=4, train_wall=30, gb_free=13.7, wall=3436
2022-03-23 10:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:21 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 10:22:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:22:25 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over year.
2022-03-23 10:22:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:22:29 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circular magnets to form any sort of similar glimpse.
2022-03-23 10:22:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:22:33 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:22:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:22:37 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:22:37 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:22:41 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:22:41 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:22:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move because your movements use energy, and so the superconductor disorder.
2022-03-23 10:22:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial facial, that gives the big constructions of the facial and the basic shape, and defend it through the same information that refers the whole portion structure and all the fine wrinkles.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, when striking dinner, it was the best summarized when someone said, "turn you to the men on your table and say to them," if the revolution begins, then we support you. '"the truth, women, we've been supporting you for a long time."
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:22:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable, and a cooling system, that allows us to use an aircraft in the static traffic to a particular passenger, either mechanism, or a mechanical vehicle, when you see it's going to get rid of the ground, all the way away from a mechanism, all the way down to the road, when you can see it's going on, when you can see it's going on, if you're going to get rid of a mechanism, if you're going to get rid of a mechanism, you can see it's going to get rid of a mechanism, you can see it's going to get rid of a mechanism.
2022-03-23 10:22:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:22:56 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 5.3 | nll_loss 2.548 | ppl 5.85 | bleu 33.28 | wps 4692.8 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.28
2022-03-23 10:22:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:22:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:22:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt
2022-03-23 10:22:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_best.pt (epoch 38 @ 5961 updates, score 33.28) (writing took 1.840083695948124 seconds)
2022-03-23 10:22:58 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:22:58 | INFO | train | epoch 038 | loss 5.126 | nll_loss 2.543 | ppl 5.83 | wps 44002.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.434 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3496
2022-03-23 10:22:58 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:10 | INFO | train_inner | epoch 039:     39 / 157 loss=5.1, nll_loss=2.509, ppl=5.69, wps=35351.8, ups=1.39, wpb=25502.7, bsz=1028.5, num_updates=6000, lr=0.000408248, gnorm=0.398, loss_scale=4, train_wall=30, gb_free=13.1, wall=3509
2022-03-23 10:23:42 | INFO | train_inner | epoch 039:    139 / 157 loss=5.11, nll_loss=2.523, ppl=5.75, wps=80769.2, ups=3.21, wpb=25165.5, bsz=1001.3, num_updates=6100, lr=0.000404888, gnorm=0.422, loss_scale=4, train_wall=31, gb_free=13.9, wall=3540
2022-03-23 10:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:23:51 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:23:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:23:54 | INFO | fairseq.tasks.translation | example hypothesis: he can occupy about 8,000 places in the restaurant.
2022-03-23 10:23:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:23:59 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circular magnet to form any same.
2022-03-23 10:23:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:24:02 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 10:24:02 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can start the scales of the face and the basic form of it, and the whole porch structure and all the fine wrinkles.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it became best summarized when someone said, "turn you to the men on your table and tell them," when the revolution begins, we support you. '"the truth, women is that we've been supporting you for a long time.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our airplane the proud tower, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation of design and a cooling system that allows us to use an aircraft in the gunge to get rid of the truck, that either, if you move the prophecy, to the bottom of a mechanism, or if you get rid of a mechanism, to the wrong way down to the ground, to the edge of a mechanism, if you can see it, or if you can get rid of a mechanism, except for a mechanism, if you can't get rid of a mechanism, except for a mechanism, if you can't get rid of a mechanism.
2022-03-23 10:24:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:25 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.332 | nll_loss 2.558 | ppl 5.89 | bleu 32.5 | wps 4810.5 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.28
2022-03-23 10:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:24:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:24:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 39 @ 6118 updates, score 32.5) (writing took 0.7843568869866431 seconds)
2022-03-23 10:24:25 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:24:25 | INFO | train | epoch 039 | loss 5.092 | nll_loss 2.499 | ppl 5.65 | wps 45035 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.416 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 3584
2022-03-23 10:24:26 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:52 | INFO | train_inner | epoch 040:     82 / 157 loss=5.081, nll_loss=2.484, ppl=5.59, wps=35974.1, ups=1.43, wpb=25232.8, bsz=982.4, num_updates=6200, lr=0.00040161, gnorm=0.419, loss_scale=4, train_wall=30, gb_free=14.6, wall=3610
2022-03-23 10:25:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:18 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 10:25:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:25:22 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant over year.
2022-03-23 10:25:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:25:27 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can expand these roundmagnets to make any glider.
2022-03-23 10:25:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:25:34 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:25:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:25:38 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 10:25:38 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:25:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and the superconducting disorder.
2022-03-23 10:25:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:46 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can that gives the big contexts of the face and the basic form of it, and the whole portion structure and all the fine wrints.
2022-03-23 10:25:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:25:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, when constrict dinner, it was best summarized when someone said, "turn you to the men on your table and say to them, 'when the revolution begins to support you.'" the truth, women is that we've been supporting you for a long time. "
2022-03-23 10:25:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:25:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we've stumbled on on our airplane was a result that we've had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable and cooling system that allows us to use an aircraft on the stop and go-traffic to a specific passenger, either the propelled, or the bottom of a mechanism of a mechanism, all the way down to the ground when you see a continuously varied varied varied variables in a continuously varied variables in a continuously varied manner that allows us to run the stairs.
2022-03-23 10:25:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:25:53 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.303 | nll_loss 2.532 | ppl 5.78 | bleu 33.21 | wps 4742.6 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.28
2022-03-23 10:25:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:25:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.21) (writing took 0.8252437547780573 seconds)
2022-03-23 10:25:54 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:25:54 | INFO | train | epoch 040 | loss 5.07 | nll_loss 2.471 | ppl 5.55 | wps 44717.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.421 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3672
2022-03-23 10:25:54 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:02 | INFO | train_inner | epoch 041:     25 / 157 loss=5.046, nll_loss=2.442, ppl=5.43, wps=34793.5, ups=1.43, wpb=24410.6, bsz=1075.8, num_updates=6300, lr=0.00039841, gnorm=0.448, loss_scale=4, train_wall=30, gb_free=13.7, wall=3680
2022-03-23 10:26:33 | INFO | train_inner | epoch 041:    125 / 157 loss=5.036, nll_loss=2.427, ppl=5.38, wps=81610.1, ups=3.19, wpb=25606.7, bsz=1039.7, num_updates=6400, lr=0.000395285, gnorm=0.4, loss_scale=4, train_wall=31, gb_free=13.9, wall=3711
2022-03-23 10:26:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:47 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:26:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:26:51 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:26:51 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:26:55 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this round magnet to shape any equation.
2022-03-23 10:26:55 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:26:59 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:26:59 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:27:03 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousses died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:27:03 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocides, or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big configurations of the face and the basic form, and take it through the information that the whole portion structure and all the fine wrinkles.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and appropriate for me to be here at tedwomen is that -- well, when constricted dinner, it was best summarized when someone said, "turn you to the men on your table and say to you," when the revolution begins, we support you. '"the truth, women, we've been supporting you with this topic for a long time.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we've stumbled on on our airplane was a result that we had to solve the unique problems that were connected to operating on the floor -- everything from a continuously varied gear and a cooling system with liquid that allows us to use an aircraft in the gavage, or a specially passing drive the propeller, either the propeller, or the soil, when you see it's the wrong thing, all the way down to the ground, all the time you see it's going to the wrong way down to the same.
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:21 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.306 | nll_loss 2.528 | ppl 5.77 | bleu 33.04 | wps 4841.8 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.28
2022-03-23 10:27:21 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:27:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:27:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt
2022-03-23 10:27:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#4/checkpoint_last.pt (epoch 41 @ 6432 updates, score 33.04) (writing took 0.8485095012001693 seconds)
2022-03-23 10:27:21 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:27:21 | INFO | train | epoch 041 | loss 5.046 | nll_loss 2.44 | ppl 5.43 | wps 45053.7 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.419 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3760
2022-03-23 10:27:21 | INFO | fairseq_cli.train | done training in 3759.0 seconds
