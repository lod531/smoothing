Sender: LSF System <lsfadmin@eu-g2-09>
Subject: Job 202625113: <w2_jelinek_0.1_0.0_0.9_#4> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#4> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:50:12 2022
Job was executed on host(s) <eu-g2-09>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:50:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:50:45 2022
Terminated at Tue Feb  1 04:51:12 2022
Results reported at Tue Feb  1 04:51:12 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   70609.96 sec.
    Max Memory :                                 5500 MB
    Average Memory :                             3096.91 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14500.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72028 sec.
    Turnaround time :                            72060 sec.

The output (if any) follows:

2022-01-31 08:51:08 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:51:08 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:51:09 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1257/36718 [00:00<00:02, 12550.71it/s]  7%|▋         | 2513/36718 [00:00<00:03, 11330.27it/s] 10%|█         | 3794/36718 [00:00<00:02, 11963.43it/s] 14%|█▍        | 5176/36718 [00:00<00:02, 12666.47it/s] 18%|█▊        | 6450/36718 [00:00<00:02, 12328.22it/s] 21%|██        | 7689/36718 [00:00<00:02, 11934.55it/s] 24%|██▍       | 8888/36718 [00:00<00:02, 11700.65it/s] 27%|██▋       | 10086/36718 [00:00<00:02, 11785.23it/s] 31%|███       | 11268/36718 [00:00<00:02, 11595.52it/s] 34%|███▍      | 12503/36718 [00:01<00:02, 11814.22it/s] 37%|███▋      | 13755/36718 [00:01<00:01, 12021.64it/s] 41%|████      | 15018/36718 [00:01<00:01, 12199.69it/s] 44%|████▍     | 16240/36718 [00:01<00:01, 11752.40it/s] 48%|████▊     | 17445/36718 [00:01<00:01, 11835.12it/s] 51%|█████     | 18632/36718 [00:01<00:01, 11569.40it/s] 54%|█████▍    | 19955/36718 [00:01<00:01, 12051.78it/s] 58%|█████▊    | 21164/36718 [00:01<00:01, 11752.28it/s] 61%|██████    | 22343/36718 [00:01<00:01, 11565.60it/s] 64%|██████▍   | 23589/36718 [00:01<00:01, 11818.44it/s] 68%|██████▊   | 24961/36718 [00:02<00:00, 12373.48it/s] 71%|███████▏  | 26202/36718 [00:02<00:00, 12250.05it/s] 75%|███████▍  | 27430/36718 [00:02<00:00, 11573.65it/s] 78%|███████▊  | 28747/36718 [00:02<00:00, 12017.90it/s] 82%|████████▏ | 29958/36718 [00:02<00:00, 11923.94it/s] 85%|████████▍ | 31157/36718 [00:02<00:00, 11413.57it/s] 88%|████████▊ | 32306/36718 [00:02<00:00, 11280.65it/s] 91%|█████████ | 33442/36718 [00:02<00:00, 11294.46it/s] 94%|█████████▍| 34672/36718 [00:02<00:00, 11585.24it/s] 98%|█████████▊| 35835/36718 [00:03<00:00, 11413.83it/s]100%|██████████| 36718/36718 [00:03<00:00, 11784.71it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  6%|▋         | 2309/36718 [00:00<00:01, 23071.65it/s] 14%|█▎        | 5014/36718 [00:00<00:01, 25409.79it/s] 21%|██        | 7556/36718 [00:00<00:01, 25168.54it/s] 27%|██▋       | 10074/36718 [00:00<00:01, 24322.38it/s] 34%|███▍      | 12511/36718 [00:00<00:01, 23533.97it/s] 41%|████      | 14892/36718 [00:00<00:00, 23617.84it/s] 47%|████▋     | 17258/36718 [00:00<00:00, 23037.09it/s] 54%|█████▎    | 19721/36718 [00:00<00:00, 23522.89it/s] 60%|██████    | 22078/36718 [00:00<00:00, 23325.30it/s] 67%|██████▋   | 24568/36718 [00:01<00:00, 23793.76it/s] 73%|███████▎  | 26951/36718 [00:01<00:00, 23148.20it/s] 80%|███████▉  | 29271/36718 [00:01<00:00, 23059.32it/s] 86%|████████▌ | 31581/36718 [00:01<00:00, 22729.06it/s] 92%|█████████▏| 33857/36718 [00:01<00:00, 22652.57it/s] 99%|█████████▊| 36220/36718 [00:01<00:00, 22940.22it/s]100%|██████████| 36718/36718 [00:01<00:00, 23344.67it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 179.52it/s]2022-01-31 08:51:31 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:51:31 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:51:31 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:51:31 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:51:31 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:51:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:51:31 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:51:31 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:51:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:51:31 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:51:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:51:31 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:51:31 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:51:31 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint_last.pt
2022-01-31 08:51:31 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint_last.pt
2022-01-31 08:51:31 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:51:31 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:51:31 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:51:31 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:51:31 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:58:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.699 | ppl 26592.6 | wps 6901 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:58:13 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:58:13 | INFO | train | epoch 001 | loss 16.133 | ppl 71847.7 | wps 5223.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.237 | train_wall 368 | gb_free 6.1 | wall 401
KL Stats: Epoch 1 Divergences: Uniform: 0.517208394610612 Unigram: 3.6856011076604216
2022-01-31 08:58:13 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:01:33 | INFO | train_inner | epoch 002:     36 / 64 loss=15.593, ppl=49417.3, wps=5446.7, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.652, train_wall=568, gb_free=6.1, wall=602
2022-01-31 09:04:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:04:46 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.698 | ppl 13288.5 | wps 6877.9 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:04:46 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:04:46 | INFO | train | epoch 002 | loss 14.424 | ppl 21986.4 | wps 5310.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.494 | train_wall 361 | gb_free 6.1 | wall 795
KL Stats: Epoch 2 Divergences: Uniform: 0.5345499046738815 Unigram: 2.415997657361054
2022-01-31 09:04:46 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:04:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:10:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:11:27 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.877 | ppl 7520.44 | wps 6917.5 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:11:27 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:11:27 | INFO | train | epoch 003 | loss 13.522 | ppl 11762.5 | wps 5211.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.204 | train_wall 368 | gb_free 6.1 | wall 1195
KL Stats: Epoch 3 Divergences: Uniform: 0.5190752576416564 Unigram: 1.733469657351904
2022-01-31 09:11:27 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:12:13 | INFO | train_inner | epoch 004:      8 / 64 loss=13.655, ppl=12898.2, wps=5094.5, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.233, train_wall=575, gb_free=6.1, wall=1242
2022-01-31 09:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:18:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.032 | ppl 4186.81 | wps 6959.9 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:18:06 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:18:06 | INFO | train | epoch 004 | loss 12.574 | ppl 6099.57 | wps 5225.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.959 | train_wall 367 | gb_free 6.1 | wall 1595
KL Stats: Epoch 4 Divergences: Uniform: 0.6028876543785803 Unigram: 1.119898046115955
2022-01-31 09:18:06 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:22:14 | INFO | train_inner | epoch 005:     44 / 64 loss=12.226, ppl=4790.33, wps=5434, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.843, train_wall=568, gb_free=6.1, wall=1843
2022-01-31 09:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:24:38 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.513 | ppl 2922.68 | wps 6975.5 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:24:38 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:24:38 | INFO | train | epoch 005 | loss 11.78 | ppl 3516.08 | wps 5332.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.687 | train_wall 359 | gb_free 6.1 | wall 1987
KL Stats: Epoch 5 Divergences: Uniform: 0.8414502514768483 Unigram: 0.6666348311195255
2022-01-31 09:24:38 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:31:16 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.267 | ppl 2463.98 | wps 6930.1 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:31:16 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:31:16 | INFO | train | epoch 006 | loss 11.348 | ppl 2607.18 | wps 5244 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.584 | train_wall 366 | gb_free 6.1 | wall 2385
KL Stats: Epoch 6 Divergences: Uniform: 1.1381679960636897 Unigram: 0.466223778536306
2022-01-31 09:31:16 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:32:49 | INFO | train_inner | epoch 007:     16 / 64 loss=11.371, ppl=2648.07, wps=5139, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.582, train_wall=570, gb_free=6.1, wall=2477
2022-01-31 09:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:37:57 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.122 | ppl 2229.25 | wps 6926.5 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:37:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:37:57 | INFO | train | epoch 007 | loss 11.147 | ppl 2267.92 | wps 5213.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.524 | train_wall 368 | gb_free 6.1 | wall 2786
KL Stats: Epoch 7 Divergences: Uniform: 1.3621972641625302 Unigram: 0.4759570718658166
2022-01-31 09:37:57 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:42:58 | INFO | train_inner | epoch 008:     52 / 64 loss=11.086, ppl=2173.19, wps=5364.1, ups=0.16, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=576, gb_free=6.1, wall=3087
2022-01-31 09:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:44:30 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.017 | ppl 2072.77 | wps 6882 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:44:30 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:44:30 | INFO | train | epoch 008 | loss 11.034 | ppl 2096.41 | wps 5315.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 360 | gb_free 6.1 | wall 3179
KL Stats: Epoch 8 Divergences: Uniform: 1.477641246290245 Unigram: 0.55090545782554
2022-01-31 09:44:30 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:50:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:51:09 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.9 | ppl 1910.42 | wps 6912.2 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:51:09 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:51:09 | INFO | train | epoch 009 | loss 10.927 | ppl 1947.19 | wps 5232.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 367 | gb_free 6.1 | wall 3578
KL Stats: Epoch 9 Divergences: Uniform: 1.522980453171203 Unigram: 0.6545921842945029
2022-01-31 09:51:09 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:51:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:53:27 | INFO | train_inner | epoch 010:     24 / 64 loss=10.918, ppl=1934.73, wps=5182.4, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.488, train_wall=564, gb_free=6.1, wall=3716
2022-01-31 09:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:57:47 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.795 | ppl 1776.39 | wps 6962.6 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:57:47 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:57:47 | INFO | train | epoch 010 | loss 10.817 | ppl 1804.08 | wps 5249.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 365 | gb_free 6.1 | wall 3976
KL Stats: Epoch 10 Divergences: Uniform: 1.5479367586754715 Unigram: 0.768739755027727
2022-01-31 09:57:47 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:03:32 | INFO | train_inner | epoch 011:     60 / 64 loss=10.74, ppl=1710.71, wps=5403.1, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=572, gb_free=6.1, wall=4321
2022-01-31 10:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:04:23 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.686 | ppl 1647.97 | wps 7332 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 10:04:23 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 10:04:23 | INFO | train | epoch 011 | loss 10.7 | ppl 1663.77 | wps 5271.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 365 | gb_free 6.1 | wall 4372
KL Stats: Epoch 11 Divergences: Uniform: 1.5662919629482603 Unigram: 0.8823497823434991
2022-01-31 10:04:23 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 10:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:10:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:10:57 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.578 | ppl 1528.88 | wps 6871 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 10:10:57 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 10:10:57 | INFO | train | epoch 012 | loss 10.583 | ppl 1533.59 | wps 5299 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.479 | train_wall 361 | gb_free 6.1 | wall 4766
KL Stats: Epoch 12 Divergences: Uniform: 1.5772463506558076 Unigram: 0.9927787941083134
2022-01-31 10:10:57 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 10:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:14:03 | INFO | train_inner | epoch 013:     32 / 64 loss=10.559, ppl=1508.19, wps=5167.5, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.494, train_wall=568, gb_free=6.1, wall=4951
2022-01-31 10:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:17:38 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.488 | ppl 1435.97 | wps 6888.4 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:17:38 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:17:38 | INFO | train | epoch 013 | loss 10.468 | ppl 1416.33 | wps 5207.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 368 | gb_free 6.1 | wall 5167
KL Stats: Epoch 13 Divergences: Uniform: 1.6027387457321445 Unigram: 1.089840558810177
2022-01-31 10:17:38 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:17:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:24:19 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.393 | ppl 1344.23 | wps 6853.8 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:24:19 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:24:19 | INFO | train | epoch 014 | loss 10.357 | ppl 1311.24 | wps 5212 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.557 | train_wall 368 | gb_free 6.1 | wall 5568
KL Stats: Epoch 14 Divergences: Uniform: 1.6292497132864732 Unigram: 1.1795074918034127
2022-01-31 10:24:19 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:24:42 | INFO | train_inner | epoch 015:      4 / 64 loss=10.379, ppl=1332.01, wps=5096.3, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.537, train_wall=574, gb_free=6.1, wall=5591
2022-01-31 10:30:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:30:53 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.323 | ppl 1280.73 | wps 6920.9 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:30:53 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:30:53 | INFO | train | epoch 015 | loss 10.245 | ppl 1213.45 | wps 5307 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.537 | train_wall 361 | gb_free 6.1 | wall 5961
KL Stats: Epoch 15 Divergences: Uniform: 1.6525316768046014 Unigram: 1.2610839664592142
2022-01-31 10:30:53 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:30:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:34:43 | INFO | train_inner | epoch 016:     40 / 64 loss=10.204, ppl=1179.28, wps=5436.5, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.557, train_wall=568, gb_free=6.1, wall=6192
2022-01-31 10:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:37:31 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.243 | ppl 1211.72 | wps 6986.5 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:37:31 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:37:31 | INFO | train | epoch 016 | loss 10.138 | ppl 1127.16 | wps 5235 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.555 | train_wall 367 | gb_free 6.1 | wall 6360
KL Stats: Epoch 16 Divergences: Uniform: 1.6810889769489374 Unigram: 1.3394041445537825
2022-01-31 10:37:31 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:43:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:44:09 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.15 | ppl 1136.44 | wps 6986.3 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:44:09 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:44:09 | INFO | train | epoch 017 | loss 10.032 | ppl 1046.81 | wps 5250 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 366 | gb_free 6.1 | wall 6758
KL Stats: Epoch 17 Divergences: Uniform: 1.7144411620276798 Unigram: 1.40776968261585
2022-01-31 10:44:09 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:45:19 | INFO | train_inner | epoch 018:     12 / 64 loss=10.046, ppl=1057.12, wps=5132.8, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.55, train_wall=571, gb_free=6.1, wall=6827
2022-01-31 10:50:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:50:41 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.087 | ppl 1087.63 | wps 6929 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:50:41 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:50:41 | INFO | train | epoch 018 | loss 9.932 | ppl 976.59 | wps 5329.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.572 | train_wall 359 | gb_free 6.1 | wall 7150
KL Stats: Epoch 18 Divergences: Uniform: 1.7496488849904026 Unigram: 1.4746713423485551
2022-01-31 10:50:41 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:55:19 | INFO | train_inner | epoch 019:     48 / 64 loss=9.882, ppl=943.63, wps=5444.6, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.543, train_wall=567, gb_free=6.1, wall=7428
2022-01-31 10:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:57:22 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.013 | ppl 1033.27 | wps 6894 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:57:22 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:57:22 | INFO | train | epoch 019 | loss 9.828 | ppl 909.12 | wps 5217.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 368 | gb_free 6.1 | wall 7550
KL Stats: Epoch 19 Divergences: Uniform: 1.7792725108540752 Unigram: 1.5414256647434226
2022-01-31 10:57:22 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:04:02 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.928 | ppl 973.96 | wps 6894.9 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 11:04:02 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 11:04:02 | INFO | train | epoch 020 | loss 9.732 | ppl 850.39 | wps 5215.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.553 | train_wall 368 | gb_free 6.1 | wall 7951
KL Stats: Epoch 20 Divergences: Uniform: 1.810073113896505 Unigram: 1.6018857836352949
2022-01-31 11:04:02 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 11:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:05:57 | INFO | train_inner | epoch 021:     20 / 64 loss=9.727, ppl=847.46, wps=5105.8, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.547, train_wall=573, gb_free=6.1, wall=8066
2022-01-31 11:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:10:36 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.886 | ppl 945.96 | wps 6935.7 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 11:10:36 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 11:10:36 | INFO | train | epoch 021 | loss 9.638 | ppl 796.65 | wps 5307.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.528 | train_wall 361 | gb_free 6.1 | wall 8344
KL Stats: Epoch 21 Divergences: Uniform: 1.8398694904232575 Unigram: 1.6609174339600896
2022-01-31 11:10:36 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 11:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:16:00 | INFO | train_inner | epoch 022:     56 / 64 loss=9.585, ppl=768.17, wps=5422.8, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.536, train_wall=570, gb_free=6.1, wall=8669
2022-01-31 11:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:17:17 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.82 | ppl 903.64 | wps 6919.6 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 11:17:17 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 11:17:17 | INFO | train | epoch 022 | loss 9.549 | ppl 749.04 | wps 5209 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.547 | train_wall 368 | gb_free 6.1 | wall 8745
KL Stats: Epoch 22 Divergences: Uniform: 1.8648498854105915 Unigram: 1.7173722735310575
2022-01-31 11:17:17 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 11:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:23:58 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.761 | ppl 867.89 | wps 6858.2 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:23:58 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:23:58 | INFO | train | epoch 023 | loss 9.462 | ppl 705.38 | wps 5208.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.517 | train_wall 368 | gb_free 6.1 | wall 9146
KL Stats: Epoch 23 Divergences: Uniform: 1.8927516774288877 Unigram: 1.7692917245152893
2022-01-31 11:23:58 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:26:39 | INFO | train_inner | epoch 024:     28 / 64 loss=9.447, ppl=698.06, wps=5098.6, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.529, train_wall=574, gb_free=6.1, wall=9308
2022-01-31 11:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:30:30 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.702 | ppl 832.69 | wps 6935.2 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:30:30 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:30:30 | INFO | train | epoch 024 | loss 9.379 | ppl 665.78 | wps 5324 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.551 | train_wall 360 | gb_free 6.1 | wall 9539
KL Stats: Epoch 24 Divergences: Uniform: 1.9145869638355795 Unigram: 1.815088546175561
2022-01-31 11:30:30 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:36:38 | INFO | train_inner | epoch 025:     64 / 64 loss=9.325, ppl=641.36, wps=5448.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.531, train_wall=565, gb_free=6.1, wall=9906
2022-01-31 11:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:37:09 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.67 | ppl 814.62 | wps 6995 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:37:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:37:09 | INFO | train | epoch 025 | loss 9.297 | ppl 629.17 | wps 5233.7 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.52 | train_wall 367 | gb_free 6.1 | wall 9938
KL Stats: Epoch 25 Divergences: Uniform: 1.9436216731098985 Unigram: 1.8632243217175344
2022-01-31 11:37:09 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:43:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:43:46 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.619 | ppl 786.47 | wps 6979.7 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:43:46 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:43:46 | INFO | train | epoch 026 | loss 9.217 | ppl 595.05 | wps 5255 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.546 | train_wall 365 | gb_free 6.1 | wall 10335
KL Stats: Epoch 26 Divergences: Uniform: 1.9564830183824116 Unigram: 1.9069174388965078
2022-01-31 11:43:46 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:47:13 | INFO | train_inner | epoch 027:     36 / 64 loss=9.189, ppl=583.53, wps=5141.1, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.535, train_wall=571, gb_free=6.1, wall=10542
2022-01-31 11:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:50:21 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.589 | ppl 769.97 | wps 7607.5 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:50:21 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:50:21 | INFO | train | epoch 027 | loss 9.136 | ppl 562.48 | wps 5292.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.52 | train_wall 365 | gb_free 6.1 | wall 10730
KL Stats: Epoch 27 Divergences: Uniform: 1.9820231089738016 Unigram: 1.9459831047947016
2022-01-31 11:50:21 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:50:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:56:55 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.564 | ppl 756.84 | wps 6964 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:56:55 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:56:55 | INFO | train | epoch 028 | loss 9.058 | ppl 532.98 | wps 5302 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.525 | train_wall 362 | gb_free 6.1 | wall 11124
KL Stats: Epoch 28 Divergences: Uniform: 2.013568105456356 Unigram: 1.9871563517777484
2022-01-31 11:56:55 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:57:41 | INFO | train_inner | epoch 029:      8 / 64 loss=9.073, ppl=538.73, wps=5189.8, ups=0.16, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.527, train_wall=566, gb_free=6.1, wall=11170
2022-01-31 12:03:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:03:35 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.532 | ppl 740.08 | wps 6896.6 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 12:03:35 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 12:03:35 | INFO | train | epoch 029 | loss 8.979 | ppl 504.73 | wps 5225.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.527 | train_wall 367 | gb_free 6.1 | wall 11523
KL Stats: Epoch 29 Divergences: Uniform: 2.0329932599294147 Unigram: 2.024818367922089
2022-01-31 12:03:35 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 12:03:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:07:49 | INFO | train_inner | epoch 030:     44 / 64 loss=8.946, ppl=493.36, wps=5379.7, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.519, train_wall=574, gb_free=6.1, wall=11778
2022-01-31 12:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:10:15 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.503 | ppl 725.54 | wps 6880.4 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 12:10:15 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 12:10:15 | INFO | train | epoch 030 | loss 8.902 | ppl 478.35 | wps 5220.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.522 | train_wall 367 | gb_free 6.1 | wall 11924
KL Stats: Epoch 30 Divergences: Uniform: 2.052228590990245 Unigram: 2.0652157583080077
2022-01-31 12:10:15 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 12:10:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:16:48 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.455 | ppl 701.6 | wps 6890.5 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 12:16:48 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 12:16:48 | INFO | train | epoch 031 | loss 8.823 | ppl 452.88 | wps 5315 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.495 | train_wall 360 | gb_free 6.1 | wall 12316
KL Stats: Epoch 31 Divergences: Uniform: 2.0699090993621323 Unigram: 2.0991911459540558
2022-01-31 12:16:48 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 12:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:18:20 | INFO | train_inner | epoch 032:     16 / 64 loss=8.824, ppl=453.24, wps=5165.7, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.503, train_wall=566, gb_free=6.1, wall=12409
2022-01-31 12:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:23:28 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.419 | ppl 684.59 | wps 6888 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 12:23:28 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 12:23:28 | INFO | train | epoch 032 | loss 8.749 | ppl 430.28 | wps 5211.7 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.508 | train_wall 368 | gb_free 6.1 | wall 12717
KL Stats: Epoch 32 Divergences: Uniform: 2.0962749504270524 Unigram: 2.136079636775701
2022-01-31 12:23:28 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 12:23:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:28:29 | INFO | train_inner | epoch 033:     52 / 64 loss=8.712, ppl=419.42, wps=5371.3, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.512, train_wall=575, gb_free=6.1, wall=13017
2022-01-31 12:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:30:07 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.404 | ppl 677.58 | wps 7026.5 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:30:07 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:30:07 | INFO | train | epoch 033 | loss 8.675 | ppl 408.64 | wps 5240.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.51 | train_wall 366 | gb_free 6.1 | wall 13116
KL Stats: Epoch 33 Divergences: Uniform: 2.121835613589365 Unigram: 2.1758039922540684
2022-01-31 12:30:07 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:30:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:36:38 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.392 | ppl 672.03 | wps 7022.1 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:36:38 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:36:38 | INFO | train | epoch 034 | loss 8.599 | ppl 387.82 | wps 5337 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.512 | train_wall 359 | gb_free 6.1 | wall 13507
KL Stats: Epoch 34 Divergences: Uniform: 2.141329987124237 Unigram: 2.211969545667456
2022-01-31 12:36:38 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:38:57 | INFO | train_inner | epoch 035:     24 / 64 loss=8.586, ppl=384.4, wps=5188, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.514, train_wall=564, gb_free=6.1, wall=13646
2022-01-31 12:42:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:43:18 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.357 | ppl 655.6 | wps 6897.3 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:43:18 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:43:18 | INFO | train | epoch 035 | loss 8.527 | ppl 368.88 | wps 5226.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.507 | train_wall 367 | gb_free 6.1 | wall 13907
KL Stats: Epoch 35 Divergences: Uniform: 2.1630275068524356 Unigram: 2.2423064347854256
2022-01-31 12:43:18 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:43:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:49:05 | INFO | train_inner | epoch 036:     60 / 64 loss=8.483, ppl=357.73, wps=5370.3, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.499, train_wall=575, gb_free=6.1, wall=14254
2022-01-31 12:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:49:59 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.331 | ppl 643.93 | wps 6910.2 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:49:59 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:49:59 | INFO | train | epoch 036 | loss 8.453 | ppl 350.43 | wps 5211.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.497 | train_wall 368 | gb_free 6.1 | wall 14308
KL Stats: Epoch 36 Divergences: Uniform: 2.1848241602427367 Unigram: 2.2812232144715994
2022-01-31 12:49:59 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:56:32 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.349 | ppl 652.24 | wps 7014.6 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:56:32 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:56:32 | INFO | train | epoch 037 | loss 8.384 | ppl 334.07 | wps 5317.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.509 | train_wall 361 | gb_free 6.1 | wall 14700
KL Stats: Epoch 37 Divergences: Uniform: 2.203489617035752 Unigram: 2.316397890322906
2022-01-31 12:56:32 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:59:36 | INFO | train_inner | epoch 038:     32 / 64 loss=8.363, ppl=329.14, wps=5168.2, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.507, train_wall=566, gb_free=6.1, wall=14885
2022-01-31 13:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:03:10 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.329 | ppl 643.01 | wps 6982.6 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 13:03:10 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 13:03:10 | INFO | train | epoch 038 | loss 8.315 | ppl 318.58 | wps 5244.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.507 | train_wall 366 | gb_free 6.1 | wall 15099
KL Stats: Epoch 38 Divergences: Uniform: 2.234366494922494 Unigram: 2.3405972583210315
2022-01-31 13:03:10 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 13:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:09:47 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.312 | ppl 635.73 | wps 6995.3 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 13:09:47 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 13:09:47 | INFO | train | epoch 039 | loss 8.246 | ppl 303.68 | wps 5259.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.498 | train_wall 365 | gb_free 6.1 | wall 15496
KL Stats: Epoch 39 Divergences: Uniform: 2.24170071921029 Unigram: 2.3802682186199515
2022-01-31 13:09:47 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 13:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:10:10 | INFO | train_inner | epoch 040:      4 / 64 loss=8.268, ppl=308.33, wps=5143.4, ups=0.16, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.504, train_wall=570, gb_free=6.1, wall=15519
2022-01-31 13:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:16:17 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.29 | ppl 625.94 | wps 6871.5 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 13:16:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 13:16:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint40.pt
2022-01-31 13:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint40.pt
2022-01-31 13:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.29) (writing took 6.011344846338034 seconds)
2022-01-31 13:16:23 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 13:16:23 | INFO | train | epoch 040 | loss 8.178 | ppl 289.55 | wps 5270.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.501 | train_wall 357 | gb_free 6.1 | wall 15892
KL Stats: Epoch 40 Divergences: Uniform: 2.267977422467878 Unigram: 2.411234622630235
2022-01-31 13:16:23 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 13:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:20:13 | INFO | train_inner | epoch 041:     40 / 64 loss=8.154, ppl=284.87, wps=5419.6, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.499, train_wall=564, gb_free=6.1, wall=16122
2022-01-31 13:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:23:01 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.28 | ppl 621.58 | wps 7020.6 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.28
2022-01-31 13:23:01 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 13:23:01 | INFO | train | epoch 041 | loss 8.114 | ppl 277.01 | wps 5252 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.502 | train_wall 365 | gb_free 6.1 | wall 16290
KL Stats: Epoch 41 Divergences: Uniform: 2.2836917864710187 Unigram: 2.4385710476876574
2022-01-31 13:23:01 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 13:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:29:39 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.258 | ppl 612.46 | wps 6990.8 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.258
2022-01-31 13:29:39 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 13:29:39 | INFO | train | epoch 042 | loss 8.05 | ppl 264.98 | wps 5252.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.513 | train_wall 365 | gb_free 6.1 | wall 16687
KL Stats: Epoch 42 Divergences: Uniform: 2.300976599368634 Unigram: 2.474831047345943
2022-01-31 13:29:39 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 13:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:30:47 | INFO | train_inner | epoch 043:     12 / 64 loss=8.056, ppl=266.17, wps=5138.4, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.512, train_wall=570, gb_free=6.1, wall=16756
2022-01-31 13:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:36:12 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.288 | ppl 625.11 | wps 7859.8 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.288
2022-01-31 13:36:12 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 13:36:12 | INFO | train | epoch 043 | loss 7.984 | ppl 253.21 | wps 5311.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.497 | train_wall 364 | gb_free 6.1 | wall 17081
KL Stats: Epoch 43 Divergences: Uniform: 2.3226290864516934 Unigram: 2.503865702121564
2022-01-31 13:36:12 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 13:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:40:44 | INFO | train_inner | epoch 044:     48 / 64 loss=7.95, ppl=247.32, wps=5474.8, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.502, train_wall=568, gb_free=6.1, wall=17353
2022-01-31 13:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:42:47 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.295 | ppl 627.97 | wps 6920 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.29
2022-01-31 13:42:47 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:42:47 | INFO | train | epoch 044 | loss 7.925 | ppl 243.09 | wps 5283.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.509 | train_wall 363 | gb_free 6.1 | wall 17476
KL Stats: Epoch 44 Divergences: Uniform: 2.341551777314357 Unigram: 2.5316330457442717
2022-01-31 13:42:47 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:49:28 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.265 | ppl 615.16 | wps 6900.7 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.265
2022-01-31 13:49:28 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:49:28 | INFO | train | epoch 045 | loss 7.861 | ppl 232.52 | wps 5208.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.503 | train_wall 368 | gb_free 6.1 | wall 17877
KL Stats: Epoch 45 Divergences: Uniform: 2.3594785450936633 Unigram: 2.5660223371443935
2022-01-31 13:49:28 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:51:24 | INFO | train_inner | epoch 046:     20 / 64 loss=7.861, ppl=232.52, wps=5095.8, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.506, train_wall=575, gb_free=6.1, wall=17993
2022-01-31 13:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:56:09 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.274 | ppl 619.17 | wps 6911.4 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.274
2022-01-31 13:56:09 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:56:09 | INFO | train | epoch 046 | loss 7.803 | ppl 223.28 | wps 5212.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.513 | train_wall 368 | gb_free 6.1 | wall 18278
KL Stats: Epoch 46 Divergences: Uniform: 2.372532614273227 Unigram: 2.5855353878595224
2022-01-31 13:56:09 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:01:25 | INFO | train_inner | epoch 047:     56 / 64 loss=7.772, ppl=218.56, wps=5436.9, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.503, train_wall=568, gb_free=6.1, wall=18594
2022-01-31 14:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:02:42 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.261 | ppl 613.7 | wps 6869.7 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.261
2022-01-31 14:02:42 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 14:02:42 | INFO | train | epoch 047 | loss 7.744 | ppl 214.38 | wps 5314.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.498 | train_wall 360 | gb_free 6.1 | wall 18671
KL Stats: Epoch 47 Divergences: Uniform: 2.3953707973744356 Unigram: 2.6122049747759957
2022-01-31 14:02:42 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 14:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:09:21 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.253 | ppl 610.2 | wps 6930.6 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.253
2022-01-31 14:09:21 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 14:09:21 | INFO | train | epoch 048 | loss 7.687 | ppl 206.13 | wps 5235.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.511 | train_wall 366 | gb_free 6.1 | wall 19070
KL Stats: Epoch 48 Divergences: Uniform: 2.4143608979421143 Unigram: 2.642530954947643
2022-01-31 14:09:21 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 14:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:12:02 | INFO | train_inner | epoch 049:     28 / 64 loss=7.67, ppl=203.61, wps=5117.3, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.507, train_wall=572, gb_free=6.1, wall=19231
2022-01-31 14:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:16:00 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.282 | ppl 622.5 | wps 6870.2 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.282
2022-01-31 14:16:00 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 14:16:00 | INFO | train | epoch 049 | loss 7.63 | ppl 198.12 | wps 5224.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.507 | train_wall 367 | gb_free 6.1 | wall 19469
KL Stats: Epoch 49 Divergences: Uniform: 2.4188905508318213 Unigram: 2.6677853228301935
2022-01-31 14:16:00 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 14:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:22:02 | INFO | train_inner | epoch 050:     64 / 64 loss=7.606, ppl=194.86, wps=5433.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.525, train_wall=567, gb_free=6.1, wall=19831
2022-01-31 14:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:22:34 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.295 | ppl 628.08 | wps 6903.5 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.29
2022-01-31 14:22:34 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 14:22:34 | INFO | train | epoch 050 | loss 7.58 | ppl 191.31 | wps 5309.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.532 | train_wall 361 | gb_free 6.1 | wall 19863
KL Stats: Epoch 50 Divergences: Uniform: 2.4357930271031853 Unigram: 2.6851564620898873
2022-01-31 14:22:34 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 14:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:29:15 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.306 | ppl 632.87 | wps 6915.9 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.29
2022-01-31 14:29:15 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 14:29:15 | INFO | train | epoch 051 | loss 7.523 | ppl 183.98 | wps 5204.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.508 | train_wall 369 | gb_free 6.1 | wall 20264
KL Stats: Epoch 51 Divergences: Uniform: 2.4625107206030523 Unigram: 2.7080783075721224
2022-01-31 14:29:15 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 14:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:32:44 | INFO | train_inner | epoch 052:     36 / 64 loss=7.5, ppl=180.96, wps=5094, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.509, train_wall=577, gb_free=6.1, wall=20473
2022-01-31 14:35:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:35:55 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.291 | ppl 626.58 | wps 6938.2 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.29
2022-01-31 14:35:55 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 14:35:55 | INFO | train | epoch 052 | loss 7.471 | ppl 177.46 | wps 5229.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.52 | train_wall 367 | gb_free 6.1 | wall 20663
KL Stats: Epoch 52 Divergences: Uniform: 2.473241743594871 Unigram: 2.7419926173095432
2022-01-31 14:35:55 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 14:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:42:28 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.276 | ppl 620.04 | wps 6936.8 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.276
2022-01-31 14:42:28 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 14:42:28 | INFO | train | epoch 053 | loss 7.42 | ppl 171.21 | wps 5311.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.509 | train_wall 361 | gb_free 6.1 | wall 21057
KL Stats: Epoch 53 Divergences: Uniform: 2.4961905188418685 Unigram: 2.7590443627653363
2022-01-31 14:42:28 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 14:42:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:43:14 | INFO | train_inner | epoch 054:      8 / 64 loss=7.433, ppl=172.79, wps=5172.2, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.52, train_wall=566, gb_free=6.1, wall=21103
2022-01-31 14:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:49:09 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.33 | ppl 643.61 | wps 6903.7 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.29
2022-01-31 14:49:09 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:49:09 | INFO | train | epoch 054 | loss 7.37 | ppl 165.42 | wps 5207.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.525 | train_wall 368 | gb_free 6.1 | wall 21458
KL Stats: Epoch 54 Divergences: Uniform: 2.497436100146636 Unigram: 2.779324647748518
2022-01-31 14:49:09 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:49:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:53:23 | INFO | train_inner | epoch 055:     44 / 64 loss=7.342, ppl=162.23, wps=5365.1, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.518, train_wall=576, gb_free=6.1, wall=21712
2022-01-31 14:55:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:55:50 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.327 | ppl 642.36 | wps 6822 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.29
2022-01-31 14:55:50 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:55:50 | INFO | train | epoch 055 | loss 7.322 | ppl 160.05 | wps 5212.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.529 | train_wall 368 | gb_free 6.1 | wall 21858
KL Stats: Epoch 55 Divergences: Uniform: 2.512791394446619 Unigram: 2.808401310438587
2022-01-31 14:55:50 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:55:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:01:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:02:23 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.438 | ppl 693.63 | wps 6712 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.29
2022-01-31 15:02:23 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 15:02:23 | INFO | train | epoch 056 | loss 7.273 | ppl 154.69 | wps 5303.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.52 | train_wall 360 | gb_free 6.1 | wall 22252
KL Stats: Epoch 56 Divergences: Uniform: 2.51154919936294 Unigram: 2.825248114648947
2022-01-31 15:02:23 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 15:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:03:56 | INFO | train_inner | epoch 057:     16 / 64 loss=7.277, ppl=155.13, wps=5154.8, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.53, train_wall=566, gb_free=6.1, wall=22344
2022-01-31 15:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:09:03 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.416 | ppl 683.01 | wps 6945.2 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.29
2022-01-31 15:09:03 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 15:09:03 | INFO | train | epoch 057 | loss 7.226 | ppl 149.71 | wps 5229 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.531 | train_wall 367 | gb_free 6.1 | wall 22652
KL Stats: Epoch 57 Divergences: Uniform: 2.5433143425453415 Unigram: 2.8541784453698913
2022-01-31 15:09:03 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 15:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:14:02 | INFO | train_inner | epoch 058:     52 / 64 loss=7.202, ppl=147.19, wps=5385.8, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.527, train_wall=574, gb_free=6.1, wall=22951
2022-01-31 15:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:15:41 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.422 | ppl 685.83 | wps 6985.9 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.29
2022-01-31 15:15:41 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 15:15:41 | INFO | train | epoch 058 | loss 7.181 | ppl 145.13 | wps 5243.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.529 | train_wall 366 | gb_free 6.1 | wall 23050
KL Stats: Epoch 58 Divergences: Uniform: 2.5545396036536654 Unigram: 2.8690830763847734
2022-01-31 15:15:41 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 15:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:22:15 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.487 | ppl 717.77 | wps 8220.5 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.29
2022-01-31 15:22:15 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 15:22:15 | INFO | train | epoch 059 | loss 7.137 | ppl 140.7 | wps 5307.7 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.536 | train_wall 366 | gb_free 6.1 | wall 23443
KL Stats: Epoch 59 Divergences: Uniform: 2.56783731048286 Unigram: 2.8899126929068535
2022-01-31 15:22:15 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 15:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:24:30 | INFO | train_inner | epoch 060:     24 / 64 loss=7.13, ppl=140.11, wps=5192.9, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.536, train_wall=568, gb_free=6.1, wall=23579
2022-01-31 15:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:28:50 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.44 | ppl 694.49 | wps 6994.8 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.29
2022-01-31 15:28:50 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 15:28:50 | INFO | train | epoch 060 | loss 7.092 | ppl 136.47 | wps 5289.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.542 | train_wall 363 | gb_free 6.1 | wall 23838
KL Stats: Epoch 60 Divergences: Uniform: 2.582392889607815 Unigram: 2.9171904700626756
2022-01-31 15:28:50 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 15:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:34:36 | INFO | train_inner | epoch 061:     60 / 64 loss=7.073, ppl=134.67, wps=5393.1, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.547, train_wall=573, gb_free=6.1, wall=24185
2022-01-31 15:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:35:30 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.498 | ppl 722.85 | wps 6889.7 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.29
2022-01-31 15:35:30 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 15:35:30 | INFO | train | epoch 061 | loss 7.05 | ppl 132.51 | wps 5219.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.549 | train_wall 367 | gb_free 6.1 | wall 24239
KL Stats: Epoch 61 Divergences: Uniform: 2.6006211294791353 Unigram: 2.92704817183114
2022-01-31 15:35:30 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 15:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:42:10 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.468 | ppl 708.08 | wps 6924.7 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.29
2022-01-31 15:42:10 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 15:42:10 | INFO | train | epoch 062 | loss 7.008 | ppl 128.75 | wps 5218.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.551 | train_wall 368 | gb_free 6.1 | wall 24639
KL Stats: Epoch 62 Divergences: Uniform: 2.606305320687258 Unigram: 2.9574455860398685
2022-01-31 15:42:10 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 15:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:45:07 | INFO | train_inner | epoch 063:     32 / 64 loss=6.983, ppl=126.47, wps=5165.3, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.55, train_wall=566, gb_free=6.1, wall=24816
2022-01-31 15:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:48:42 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.48 | ppl 713.92 | wps 6882 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.29
2022-01-31 15:48:42 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 15:48:42 | INFO | train | epoch 063 | loss 6.965 | ppl 124.9 | wps 5327.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.547 | train_wall 359 | gb_free 6.1 | wall 25031
KL Stats: Epoch 63 Divergences: Uniform: 2.618785416238635 Unigram: 2.9738992967448974
2022-01-31 15:48:42 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 15:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:55:23 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.558 | ppl 753.82 | wps 6902.2 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.29
2022-01-31 15:55:23 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 15:55:23 | INFO | train | epoch 064 | loss 6.922 | ppl 121.26 | wps 5210.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.558 | train_wall 368 | gb_free 6.1 | wall 25432
KL Stats: Epoch 64 Divergences: Uniform: 2.628982474525611 Unigram: 2.992738841747211
2022-01-31 15:55:23 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 15:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:55:46 | INFO | train_inner | epoch 065:      4 / 64 loss=6.949, ppl=123.54, wps=5103.8, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.554, train_wall=574, gb_free=6.1, wall=25455
2022-01-31 16:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:02:03 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.565 | ppl 757.63 | wps 6913.4 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.29
2022-01-31 16:02:03 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 16:02:03 | INFO | train | epoch 065 | loss 6.879 | ppl 117.73 | wps 5217.7 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.555 | train_wall 368 | gb_free 6.1 | wall 25832
KL Stats: Epoch 65 Divergences: Uniform: 2.6387180847112095 Unigram: 3.0134925258143763
2022-01-31 16:02:03 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 16:02:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:05:48 | INFO | train_inner | epoch 066:     40 / 64 loss=6.855, ppl=115.79, wps=5430.8, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.561, train_wall=569, gb_free=6.1, wall=26057
2022-01-31 16:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:08:36 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.577 | ppl 763.57 | wps 6913.1 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.29
2022-01-31 16:08:36 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 16:08:36 | INFO | train | epoch 066 | loss 6.839 | ppl 114.52 | wps 5314.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.555 | train_wall 360 | gb_free 6.1 | wall 26225
KL Stats: Epoch 66 Divergences: Uniform: 2.651188497166606 Unigram: 3.0278592977426446
2022-01-31 16:08:36 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 16:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:15:17 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.553 | ppl 751.36 | wps 6919.2 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.29
2022-01-31 16:15:17 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 16:15:17 | INFO | train | epoch 067 | loss 6.798 | ppl 111.25 | wps 5214 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.554 | train_wall 368 | gb_free 6.1 | wall 26626
KL Stats: Epoch 67 Divergences: Uniform: 2.6699556343512065 Unigram: 3.0547058660614717
2022-01-31 16:15:17 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 16:15:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:16:26 | INFO | train_inner | epoch 068:     12 / 64 loss=6.806, ppl=111.93, wps=5105, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.551, train_wall=574, gb_free=6.1, wall=26695
2022-01-31 16:21:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:21:58 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.626 | ppl 789.97 | wps 6921.3 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.29
2022-01-31 16:21:58 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 16:21:58 | INFO | train | epoch 068 | loss 6.762 | ppl 108.5 | wps 5206.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.578 | train_wall 369 | gb_free 6.1 | wall 27027
KL Stats: Epoch 68 Divergences: Uniform: 2.6794011551594132 Unigram: 3.0733487497051186
2022-01-31 16:21:58 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 16:21:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:26:29 | INFO | train_inner | epoch 069:     48 / 64 loss=6.743, ppl=107.1, wps=5424.6, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.566, train_wall=569, gb_free=6.1, wall=27298
2022-01-31 16:28:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:28:31 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.635 | ppl 795.11 | wps 6944.1 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.29
2022-01-31 16:28:31 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 16:28:31 | INFO | train | epoch 069 | loss 6.722 | ppl 105.55 | wps 5307 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.555 | train_wall 361 | gb_free 6.1 | wall 27420
KL Stats: Epoch 69 Divergences: Uniform: 2.692300496289744 Unigram: 3.089894889250788
2022-01-31 16:28:31 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 16:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:35:12 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.703 | ppl 833.37 | wps 6939.7 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.29
2022-01-31 16:35:12 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 16:35:12 | INFO | train | epoch 070 | loss 6.687 | ppl 103.03 | wps 5210 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.559 | train_wall 368 | gb_free 6.1 | wall 27821
KL Stats: Epoch 70 Divergences: Uniform: 2.697833402813989 Unigram: 3.100456947016811
2022-01-31 16:35:12 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 16:35:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:37:08 | INFO | train_inner | epoch 071:     20 / 64 loss=6.681, ppl=102.63, wps=5098.8, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.563, train_wall=575, gb_free=6.1, wall=27937
2022-01-31 16:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:41:53 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.688 | ppl 824.87 | wps 6920.8 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.29
2022-01-31 16:41:53 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 16:41:53 | INFO | train | epoch 071 | loss 6.654 | ppl 100.68 | wps 5217 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.578 | train_wall 368 | gb_free 6.1 | wall 28221
KL Stats: Epoch 71 Divergences: Uniform: 2.708446192201698 Unigram: 3.123140413180172
2022-01-31 16:41:53 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 16:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:47:09 | INFO | train_inner | epoch 072:     56 / 64 loss=6.638, ppl=99.61, wps=5436.4, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.573, train_wall=568, gb_free=6.1, wall=28538
2022-01-31 16:47:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:48:27 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.641 | ppl 798.24 | wps 6916 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.29
2022-01-31 16:48:27 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 16:48:27 | INFO | train | epoch 072 | loss 6.618 | ppl 98.23 | wps 5292 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.57 | train_wall 362 | gb_free 6.1 | wall 28616
KL Stats: Epoch 72 Divergences: Uniform: 2.7257006899600444 Unigram: 3.1415577593031747
2022-01-31 16:48:27 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 16:48:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:55:07 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.73 | ppl 849.4 | wps 6894.7 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.29
2022-01-31 16:55:07 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 16:55:07 | INFO | train | epoch 073 | loss 6.586 | ppl 96.04 | wps 5232.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.571 | train_wall 366 | gb_free 6.1 | wall 29015
KL Stats: Epoch 73 Divergences: Uniform: 2.7247781095322745 Unigram: 3.157295048210391
2022-01-31 16:55:07 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 16:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:57:48 | INFO | train_inner | epoch 074:     28 / 64 loss=6.575, ppl=95.31, wps=5101, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.572, train_wall=574, gb_free=6.1, wall=29177
2022-01-31 17:01:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:01:46 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.626 | ppl 790.1 | wps 6900.5 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.29
2022-01-31 17:01:46 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 17:01:46 | INFO | train | epoch 074 | loss 6.554 | ppl 93.93 | wps 5223.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.586 | train_wall 367 | gb_free 6.1 | wall 29415
KL Stats: Epoch 74 Divergences: Uniform: 2.7385114359950893 Unigram: 3.184915355719623
2022-01-31 17:01:46 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 17:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:07:49 | INFO | train_inner | epoch 075:     64 / 64 loss=6.544, ppl=93.31, wps=5423.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.584, train_wall=568, gb_free=6.1, wall=29778
2022-01-31 17:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:08:19 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.766 | ppl 870.43 | wps 7279.5 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.29
2022-01-31 17:08:20 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 17:08:20 | INFO | train | epoch 075 | loss 6.523 | ppl 91.96 | wps 5313.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.578 | train_wall 362 | gb_free 6.1 | wall 29808
KL Stats: Epoch 75 Divergences: Uniform: 2.741120185949408 Unigram: 3.1948940729597544
2022-01-31 17:08:20 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 17:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:15:00 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.725 | ppl 846.13 | wps 6872.6 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.29
2022-01-31 17:15:00 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 17:15:00 | INFO | train | epoch 076 | loss 6.494 | ppl 90.12 | wps 5209 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.598 | train_wall 368 | gb_free 6.1 | wall 30209
KL Stats: Epoch 76 Divergences: Uniform: 2.7547274526891528 Unigram: 3.215229785341821
2022-01-31 17:15:00 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 17:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:18:28 | INFO | train_inner | epoch 077:     36 / 64 loss=6.468, ppl=88.54, wps=5116.6, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.592, train_wall=575, gb_free=6.1, wall=30417
2022-01-31 17:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:21:40 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.766 | ppl 870.59 | wps 6978.4 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.29
2022-01-31 17:21:40 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 17:21:40 | INFO | train | epoch 077 | loss 6.464 | ppl 88.27 | wps 5234 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.597 | train_wall 367 | gb_free 6.1 | wall 30608
KL Stats: Epoch 77 Divergences: Uniform: 2.755473268862782 Unigram: 3.2377440815124308
2022-01-31 17:21:40 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 17:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:28:17 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.73 | ppl 849.26 | wps 7164.3 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.29
2022-01-31 17:28:17 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 17:28:17 | INFO | train | epoch 078 | loss 6.437 | ppl 86.62 | wps 5251.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.601 | train_wall 366 | gb_free 6.1 | wall 31006
KL Stats: Epoch 78 Divergences: Uniform: 2.7689016539416627 Unigram: 3.249212446923897
2022-01-31 17:28:17 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 17:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:28:58 | INFO | train_inner | epoch 079:      8 / 64 loss=6.451, ppl=87.5, wps=5180.2, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.605, train_wall=566, gb_free=6.1, wall=31046
2022-01-31 17:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:34:50 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.827 | ppl 908.13 | wps 6953.5 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.29
2022-01-31 17:34:50 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 17:34:50 | INFO | train | epoch 079 | loss 6.405 | ppl 84.75 | wps 5323 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.588 | train_wall 360 | gb_free 6.1 | wall 31398
KL Stats: Epoch 79 Divergences: Uniform: 2.7718663429399095 Unigram: 3.2610553525788384
2022-01-31 17:34:50 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 17:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:39:03 | INFO | train_inner | epoch 080:     44 / 64 loss=6.389, ppl=83.81, wps=5398.7, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.591, train_wall=572, gb_free=6.1, wall=31652
2022-01-31 17:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:41:28 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.742 | ppl 856.06 | wps 7010.1 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.29
2022-01-31 17:41:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 17:41:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint80.pt
2022-01-31 17:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint80.pt
2022-01-31 17:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.742) (writing took 3.94170131534338 seconds)
2022-01-31 17:41:32 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 17:41:32 | INFO | train | epoch 080 | loss 6.381 | ppl 83.32 | wps 5191.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.603 | train_wall 366 | gb_free 6.1 | wall 31801
KL Stats: Epoch 80 Divergences: Uniform: 2.7778181665693977 Unigram: 3.2833505363608273
2022-01-31 17:41:32 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 17:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:48:10 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.814 | ppl 900.02 | wps 6926.2 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.29
2022-01-31 17:48:10 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 17:48:10 | INFO | train | epoch 081 | loss 6.355 | ppl 81.83 | wps 5242.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.615 | train_wall 366 | gb_free 6.1 | wall 32199
KL Stats: Epoch 81 Divergences: Uniform: 2.7978398000934734 Unigram: 3.299518783093557
2022-01-31 17:48:10 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 17:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:49:38 | INFO | train_inner | epoch 082:     16 / 64 loss=6.361, ppl=82.2, wps=5130.3, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.62, train_wall=567, gb_free=6.1, wall=32287
2022-01-31 17:54:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:54:43 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.772 | ppl 874.33 | wps 6966.5 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.29
2022-01-31 17:54:43 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 17:54:43 | INFO | train | epoch 082 | loss 6.328 | ppl 80.34 | wps 5323.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.61 | train_wall 360 | gb_free 6.1 | wall 32591
KL Stats: Epoch 82 Divergences: Uniform: 2.7992774490986303 Unigram: 3.322864494797816
2022-01-31 17:54:43 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 17:54:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:59:44 | INFO | train_inner | epoch 083:     52 / 64 loss=6.314, ppl=79.55, wps=5398.2, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.609, train_wall=572, gb_free=6.1, wall=32892
2022-01-31 18:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:01:23 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.693 | ppl 827.92 | wps 6884.2 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.29
2022-01-31 18:01:23 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 18:01:23 | INFO | train | epoch 083 | loss 6.304 | ppl 78.99 | wps 5216.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.618 | train_wall 368 | gb_free 6.1 | wall 32992
KL Stats: Epoch 83 Divergences: Uniform: 2.8133406032734958 Unigram: 3.33984726680632
2022-01-31 18:01:23 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 18:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:07:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:08:01 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.779 | ppl 878.48 | wps 6990.5 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.29
2022-01-31 18:08:01 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 18:08:01 | INFO | train | epoch 084 | loss 6.279 | ppl 77.63 | wps 5247.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.615 | train_wall 366 | gb_free 6.1 | wall 33390
KL Stats: Epoch 84 Divergences: Uniform: 2.8156578613819674 Unigram: 3.349408390783385
2022-01-31 18:08:01 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 18:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:10:20 | INFO | train_inner | epoch 085:     24 / 64 loss=6.268, ppl=77.06, wps=5127.4, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.615, train_wall=571, gb_free=6.1, wall=33528
2022-01-31 18:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:14:33 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.797 | ppl 889.54 | wps 6976.3 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.29
2022-01-31 18:14:33 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 18:14:33 | INFO | train | epoch 085 | loss 6.255 | ppl 76.35 | wps 5330 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.623 | train_wall 359 | gb_free 6.1 | wall 33782
KL Stats: Epoch 85 Divergences: Uniform: 2.8300923714889614 Unigram: 3.3609882021183126
2022-01-31 18:14:33 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 18:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:20:19 | INFO | train_inner | epoch 086:     60 / 64 loss=6.252, ppl=76.21, wps=5452.7, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.629, train_wall=566, gb_free=6.1, wall=34128
2022-01-31 18:20:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:21:12 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.815 | ppl 900.81 | wps 6937.3 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.29
2022-01-31 18:21:12 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 18:21:12 | INFO | train | epoch 086 | loss 6.231 | ppl 75.11 | wps 5236.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.632 | train_wall 366 | gb_free 6.1 | wall 34181
KL Stats: Epoch 86 Divergences: Uniform: 2.828308306320265 Unigram: 3.385656513217498
2022-01-31 18:21:12 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 18:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:27:50 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.851 | ppl 923.6 | wps 6899.7 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.29
2022-01-31 18:27:50 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 18:27:50 | INFO | train | epoch 087 | loss 6.209 | ppl 73.97 | wps 5241 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.651 | train_wall 366 | gb_free 6.1 | wall 34579
KL Stats: Epoch 87 Divergences: Uniform: 2.8336558541984913 Unigram: 3.393945844237983
2022-01-31 18:27:50 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 18:27:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:30:55 | INFO | train_inner | epoch 088:     32 / 64 loss=6.196, ppl=73.32, wps=5121.1, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.651, train_wall=572, gb_free=6.1, wall=34764
2022-01-31 18:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:34:22 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.815 | ppl 900.84 | wps 7086.2 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.29
2022-01-31 18:34:22 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 18:34:22 | INFO | train | epoch 088 | loss 6.186 | ppl 72.83 | wps 5331.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.648 | train_wall 360 | gb_free 6.1 | wall 34971
KL Stats: Epoch 88 Divergences: Uniform: 2.841669920757512 Unigram: 3.409556756483096
2022-01-31 18:34:22 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 18:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:41:01 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.82 | ppl 904.14 | wps 7034.8 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.29
2022-01-31 18:41:01 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 18:41:01 | INFO | train | epoch 089 | loss 6.168 | ppl 71.89 | wps 5240.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.661 | train_wall 366 | gb_free 6.1 | wall 35369
KL Stats: Epoch 89 Divergences: Uniform: 2.852255433916887 Unigram: 3.4218323981026466
2022-01-31 18:41:01 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 18:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:41:24 | INFO | train_inner | epoch 090:      4 / 64 loss=6.178, ppl=72.41, wps=5187.1, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.657, train_wall=565, gb_free=6.1, wall=35393
2022-01-31 18:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:47:40 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.893 | ppl 950.67 | wps 6879.3 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.29
2022-01-31 18:47:40 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 18:47:40 | INFO | train | epoch 090 | loss 6.144 | ppl 70.71 | wps 5231.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.637 | train_wall 366 | gb_free 6.1 | wall 35769
KL Stats: Epoch 90 Divergences: Uniform: 2.8513590447171446 Unigram: 3.431394040505197
2022-01-31 18:47:40 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 18:47:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:51:31 | INFO | train_inner | epoch 091:     40 / 64 loss=6.125, ppl=69.81, wps=5379.8, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.635, train_wall=574, gb_free=6.1, wall=36000
2022-01-31 18:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:54:12 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.885 | ppl 945.52 | wps 7194.8 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.29
2022-01-31 18:54:12 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 18:54:12 | INFO | train | epoch 091 | loss 6.122 | ppl 69.63 | wps 5326.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.645 | train_wall 361 | gb_free 6.1 | wall 36161
KL Stats: Epoch 91 Divergences: Uniform: 2.8609451318496184 Unigram: 3.457986270169708
2022-01-31 18:54:12 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 18:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:00:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:00:51 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.901 | ppl 956 | wps 6924.9 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.29
2022-01-31 19:00:51 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 19:00:51 | INFO | train | epoch 092 | loss 6.104 | ppl 68.77 | wps 5235 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.666 | train_wall 366 | gb_free 6.1 | wall 36560
KL Stats: Epoch 92 Divergences: Uniform: 2.865546964509086 Unigram: 3.466909888157885
2022-01-31 19:00:51 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 19:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:02:01 | INFO | train_inner | epoch 093:     12 / 64 loss=6.113, ppl=69.21, wps=5180.5, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.662, train_wall=566, gb_free=6.1, wall=36629
2022-01-31 19:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:07:32 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.848 | ppl 921.78 | wps 6885 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.29
2022-01-31 19:07:32 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 19:07:32 | INFO | train | epoch 093 | loss 6.086 | ppl 67.92 | wps 5205.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.664 | train_wall 368 | gb_free 6.1 | wall 36961
KL Stats: Epoch 93 Divergences: Uniform: 2.8747369600728625 Unigram: 3.4833577734282213
2022-01-31 19:07:32 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 19:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:12:11 | INFO | train_inner | epoch 094:     48 / 64 loss=6.071, ppl=67.24, wps=5350.2, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.666, train_wall=577, gb_free=6.1, wall=37240
2022-01-31 19:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:14:12 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.927 | ppl 973.76 | wps 7694.6 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.29
2022-01-31 19:14:12 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 19:14:12 | INFO | train | epoch 094 | loss 6.064 | ppl 66.9 | wps 5230 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.665 | train_wall 370 | gb_free 6.1 | wall 37360
KL Stats: Epoch 94 Divergences: Uniform: 2.877513395115581 Unigram: 3.49938328150797
2022-01-31 19:14:12 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 19:14:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:20:50 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.937 | ppl 980.42 | wps 6877.1 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.29
2022-01-31 19:20:50 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 19:20:50 | INFO | train | epoch 095 | loss 6.045 | ppl 66.01 | wps 5240.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.661 | train_wall 366 | gb_free 6.1 | wall 37759
KL Stats: Epoch 95 Divergences: Uniform: 2.8821069702168756 Unigram: 3.510813961333822
2022-01-31 19:20:50 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 19:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:22:47 | INFO | train_inner | epoch 096:     20 / 64 loss=6.044, ppl=65.97, wps=5127.7, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.663, train_wall=574, gb_free=6.1, wall=37876
2022-01-31 19:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:27:35 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.858 | ppl 927.75 | wps 6828.5 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.29
2022-01-31 19:27:35 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 19:27:35 | INFO | train | epoch 096 | loss 6.029 | ppl 65.28 | wps 5162.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.675 | train_wall 372 | gb_free 6.1 | wall 38164
KL Stats: Epoch 96 Divergences: Uniform: 2.89185744150977 Unigram: 3.5185268952801025
2022-01-31 19:27:35 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 19:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:33:01 | INFO | train_inner | epoch 097:     56 / 64 loss=6.023, ppl=65.03, wps=5324.5, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.686, train_wall=580, gb_free=6.1, wall=38490
2022-01-31 19:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:34:18 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.934 | ppl 977.99 | wps 6926.5 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.29
2022-01-31 19:34:18 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 19:34:18 | INFO | train | epoch 097 | loss 6.012 | ppl 64.52 | wps 5186.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.688 | train_wall 370 | gb_free 6.1 | wall 38566
KL Stats: Epoch 97 Divergences: Uniform: 2.9008521560663865 Unigram: 3.5440895684390825
2022-01-31 19:34:18 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 19:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:40:54 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.922 | ppl 969.96 | wps 6894.3 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.29
2022-01-31 19:40:54 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 19:40:54 | INFO | train | epoch 098 | loss 5.991 | ppl 63.61 | wps 5269.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.694 | train_wall 364 | gb_free 6.1 | wall 38963
KL Stats: Epoch 98 Divergences: Uniform: 2.898821637305587 Unigram: 3.5435061844200546
2022-01-31 19:40:54 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 19:40:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:43:37 | INFO | train_inner | epoch 099:     28 / 64 loss=5.982, ppl=63.22, wps=5128.8, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.693, train_wall=571, gb_free=6.1, wall=39125
2022-01-31 19:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:47:36 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.938 | ppl 980.89 | wps 6882.4 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.29
2022-01-31 19:47:36 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 19:47:36 | INFO | train | epoch 099 | loss 5.974 | ppl 62.84 | wps 5195.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.695 | train_wall 369 | gb_free 6.1 | wall 39365
KL Stats: Epoch 99 Divergences: Uniform: 2.9051198747705156 Unigram: 3.5648624337201005
2022-01-31 19:47:36 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 19:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:53:46 | INFO | train_inner | epoch 100:     64 / 64 loss=5.977, ppl=62.99, wps=5349.3, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.705, train_wall=576, gb_free=6.1, wall=39735
2022-01-31 19:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:54:17 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.881 | ppl 942.76 | wps 6954.3 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.29
2022-01-31 19:54:17 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 19:54:17 | INFO | train | epoch 100 | loss 5.96 | ppl 62.25 | wps 5201.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.711 | train_wall 369 | gb_free 6.1 | wall 39766
KL Stats: Epoch 100 Divergences: Uniform: 2.9088823478908683 Unigram: 3.573776732324972
2022-01-31 19:54:17 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 19:54:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:00:51 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.939 | ppl 981.4 | wps 6943 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.29
2022-01-31 20:00:51 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 20:00:51 | INFO | train | epoch 101 | loss 5.939 | ppl 61.35 | wps 5303.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.708 | train_wall 361 | gb_free 6.1 | wall 40160
KL Stats: Epoch 101 Divergences: Uniform: 2.918221504488258 Unigram: 3.5912306227262847
2022-01-31 20:00:51 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 20:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:04:20 | INFO | train_inner | epoch 102:     36 / 64 loss=5.926, ppl=60.78, wps=5157.1, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.717, train_wall=569, gb_free=6.1, wall=40369
2022-01-31 20:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:07:32 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.944 | ppl 985.34 | wps 6898.3 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.29
2022-01-31 20:07:32 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 20:07:32 | INFO | train | epoch 102 | loss 5.926 | ppl 60.79 | wps 5218.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.725 | train_wall 367 | gb_free 6.1 | wall 40560
KL Stats: Epoch 102 Divergences: Uniform: 2.9149174840514838 Unigram: 3.5996971195981176
2022-01-31 20:07:32 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 20:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:14:12 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.942 | ppl 983.48 | wps 6947.2 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.29
2022-01-31 20:14:12 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 20:14:12 | INFO | train | epoch 103 | loss 5.908 | ppl 60.05 | wps 5217 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.712 | train_wall 368 | gb_free 6.1 | wall 40961
KL Stats: Epoch 103 Divergences: Uniform: 2.929068771193835 Unigram: 3.6135491361842385
2022-01-31 20:14:12 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 20:14:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:14:58 | INFO | train_inner | epoch 104:      8 / 64 loss=5.915, ppl=60.35, wps=5104.5, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.716, train_wall=574, gb_free=6.1, wall=41007
2022-01-31 20:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:20:46 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.97 | ppl 1002.85 | wps 6973.5 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.29
2022-01-31 20:20:46 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 20:20:46 | INFO | train | epoch 104 | loss 5.895 | ppl 59.49 | wps 5302.6 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.723 | train_wall 362 | gb_free 6.1 | wall 41355
KL Stats: Epoch 104 Divergences: Uniform: 2.921846406913788 Unigram: 3.628791090228322
2022-01-31 20:20:46 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 20:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:25:01 | INFO | train_inner | epoch 105:     44 / 64 loss=5.882, ppl=58.97, wps=5424, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.724, train_wall=570, gb_free=6.1, wall=41610
2022-01-31 20:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:27:27 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.926 | ppl 972.58 | wps 6922.7 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.29
2022-01-31 20:27:27 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 20:27:27 | INFO | train | epoch 105 | loss 5.877 | ppl 58.79 | wps 5205.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.727 | train_wall 369 | gb_free 6.1 | wall 41756
KL Stats: Epoch 105 Divergences: Uniform: 2.927999191902184 Unigram: 3.6371713334382823
2022-01-31 20:27:27 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 20:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:34:09 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.952 | ppl 990.24 | wps 6910 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.29
2022-01-31 20:34:09 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 20:34:09 | INFO | train | epoch 106 | loss 5.861 | ppl 58.14 | wps 5202.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.717 | train_wall 369 | gb_free 6.1 | wall 42157
KL Stats: Epoch 106 Divergences: Uniform: 2.933958317510721 Unigram: 3.641976673868673
2022-01-31 20:34:09 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 20:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:35:42 | INFO | train_inner | epoch 107:     16 / 64 loss=5.865, ppl=58.27, wps=5088.3, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.721, train_wall=576, gb_free=6.1, wall=42250
2022-01-31 20:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:40:43 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.959 | ppl 995.17 | wps 6862.6 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.29
2022-01-31 20:40:43 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 20:40:43 | INFO | train | epoch 107 | loss 5.846 | ppl 57.53 | wps 5290.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.722 | train_wall 362 | gb_free 6.1 | wall 42552
KL Stats: Epoch 107 Divergences: Uniform: 2.944170568341739 Unigram: 3.662934894409383
2022-01-31 20:40:43 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 20:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:45:46 | INFO | train_inner | epoch 108:     52 / 64 loss=5.842, ppl=57.35, wps=5408.7, ups=0.17, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.726, train_wall=571, gb_free=6.1, wall=42855
2022-01-31 20:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:47:26 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.941 | ppl 983.21 | wps 6839.1 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.29
2022-01-31 20:47:26 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 20:47:26 | INFO | train | epoch 108 | loss 5.835 | ppl 57.09 | wps 5179.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.736 | train_wall 370 | gb_free 6.1 | wall 42955
KL Stats: Epoch 108 Divergences: Uniform: 2.9456544628261834 Unigram: 3.6713233821613227
2022-01-31 20:47:27 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 20:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:54:09 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.963 | ppl 998.24 | wps 6913.4 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.29
2022-01-31 20:54:09 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 20:54:09 | INFO | train | epoch 109 | loss 5.819 | ppl 56.47 | wps 5187.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.742 | train_wall 370 | gb_free 6.1 | wall 43358
KL Stats: Epoch 109 Divergences: Uniform: 2.9469948557816874 Unigram: 3.686066909625802
2022-01-31 20:54:09 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 20:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:56:28 | INFO | train_inner | epoch 110:     24 / 64 loss=5.813, ppl=56.23, wps=5073.3, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.747, train_wall=577, gb_free=6.1, wall=43497
2022-01-31 21:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:00:43 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.052 | ppl 1061.29 | wps 7196.5 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.29
2022-01-31 21:00:43 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 21:00:43 | INFO | train | epoch 110 | loss 5.806 | ppl 55.95 | wps 5308.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.748 | train_wall 362 | gb_free 6.1 | wall 43751
KL Stats: Epoch 110 Divergences: Uniform: 2.9529942547645347 Unigram: 3.688917320143949
2022-01-31 21:00:43 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 21:00:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:06:33 | INFO | train_inner | epoch 111:     60 / 64 loss=5.805, ppl=55.92, wps=5404.9, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.758, train_wall=573, gb_free=6.1, wall=44102
2022-01-31 21:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:07:27 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.997 | ppl 1021.8 | wps 6857.6 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.29
2022-01-31 21:07:27 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 21:07:27 | INFO | train | epoch 111 | loss 5.793 | ppl 55.43 | wps 5167.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.77 | train_wall 371 | gb_free 6.1 | wall 44156
KL Stats: Epoch 111 Divergences: Uniform: 2.958232169144957 Unigram: 3.712586618136471
2022-01-31 21:07:27 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 21:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:14:09 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.038 | ppl 1051.03 | wps 6860.1 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.29
2022-01-31 21:14:09 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 21:14:09 | INFO | train | epoch 112 | loss 5.778 | ppl 54.86 | wps 5191.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.748 | train_wall 369 | gb_free 6.1 | wall 44558
KL Stats: Epoch 112 Divergences: Uniform: 2.956651482749292 Unigram: 3.7232129993938203
2022-01-31 21:14:09 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 21:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:17:15 | INFO | train_inner | epoch 113:     32 / 64 loss=5.766, ppl=54.41, wps=5080.9, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.75, train_wall=576, gb_free=6.1, wall=44743
2022-01-31 21:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:20:48 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.065 | ppl 1071.18 | wps 7657.2 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.29
2022-01-31 21:20:48 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 21:20:48 | INFO | train | epoch 113 | loss 5.763 | ppl 54.3 | wps 5239.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.76 | train_wall 369 | gb_free 6.1 | wall 44957
KL Stats: Epoch 113 Divergences: Uniform: 2.970154316013673 Unigram: 3.7323132333785125
2022-01-31 21:20:48 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 21:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:27:25 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.032 | ppl 1046.72 | wps 6887.4 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.29
2022-01-31 21:27:25 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 21:27:25 | INFO | train | epoch 114 | loss 5.75 | ppl 53.83 | wps 5258 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.772 | train_wall 364 | gb_free 6.1 | wall 45354
KL Stats: Epoch 114 Divergences: Uniform: 2.9633227946014338 Unigram: 3.7364174323879875
2022-01-31 21:27:25 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 21:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:27:48 | INFO | train_inner | epoch 115:      4 / 64 loss=5.763, ppl=54.3, wps=5143.2, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.772, train_wall=572, gb_free=6.1, wall=45377
2022-01-31 21:33:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:34:07 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.052 | ppl 1061.8 | wps 6899.4 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.29
2022-01-31 21:34:07 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 21:34:07 | INFO | train | epoch 115 | loss 5.738 | ppl 53.38 | wps 5189.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.781 | train_wall 370 | gb_free 6.1 | wall 45756
KL Stats: Epoch 115 Divergences: Uniform: 2.9710936173829725 Unigram: 3.7451520825405944
2022-01-31 21:34:07 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 21:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:37:58 | INFO | train_inner | epoch 116:     40 / 64 loss=5.724, ppl=52.87, wps=5358.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.776, train_wall=577, gb_free=6.1, wall=45987
2022-01-31 21:40:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:40:47 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.013 | ppl 1033.54 | wps 6967.2 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.29
2022-01-31 21:40:47 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 21:40:47 | INFO | train | epoch 116 | loss 5.725 | ppl 52.89 | wps 5225.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.774 | train_wall 367 | gb_free 6.1 | wall 46156
KL Stats: Epoch 116 Divergences: Uniform: 2.9725005049944664 Unigram: 3.7522981510763427
2022-01-31 21:40:47 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 21:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:47:22 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.074 | ppl 1077.9 | wps 6897 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.29
2022-01-31 21:47:22 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 21:47:22 | INFO | train | epoch 117 | loss 5.715 | ppl 52.53 | wps 5290.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.789 | train_wall 362 | gb_free 6.1 | wall 46551
KL Stats: Epoch 117 Divergences: Uniform: 2.9722236854681903 Unigram: 3.771100226900496
2022-01-31 21:47:22 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 21:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:48:32 | INFO | train_inner | epoch 118:     12 / 64 loss=5.72, ppl=52.71, wps=5146.9, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.792, train_wall=569, gb_free=6.1, wall=46621
2022-01-31 21:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:54:04 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.103 | ppl 1099.98 | wps 6844.4 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.29
2022-01-31 21:54:04 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 21:54:04 | INFO | train | epoch 118 | loss 5.702 | ppl 52.07 | wps 5190 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.8 | train_wall 369 | gb_free 6.1 | wall 46953
KL Stats: Epoch 118 Divergences: Uniform: 2.984010811334602 Unigram: 3.7770286188409217
2022-01-31 21:54:04 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 21:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:58:44 | INFO | train_inner | epoch 119:     48 / 64 loss=5.691, ppl=51.68, wps=5339.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=578, gb_free=6.1, wall=47233
2022-01-31 22:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:00:47 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.057 | ppl 1065.31 | wps 6869.7 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.29
2022-01-31 22:00:47 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 22:00:47 | INFO | train | epoch 119 | loss 5.688 | ppl 51.56 | wps 5185.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.802 | train_wall 370 | gb_free 6.1 | wall 47356
KL Stats: Epoch 119 Divergences: Uniform: 2.9861449888426623 Unigram: 3.7924699652105027
2022-01-31 22:00:47 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 22:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:07:23 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.094 | ppl 1093.28 | wps 6878.5 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.29
2022-01-31 22:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 22:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint120.pt
2022-01-31 22:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint120.pt
2022-01-31 22:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.094) (writing took 4.148449286818504 seconds)
2022-01-31 22:07:28 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 22:07:28 | INFO | train | epoch 120 | loss 5.678 | ppl 51.2 | wps 5216.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.794 | train_wall 363 | gb_free 6.1 | wall 47756
KL Stats: Epoch 120 Divergences: Uniform: 2.989256713001981 Unigram: 3.7992169731096115
2022-01-31 22:07:28 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 22:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:09:24 | INFO | train_inner | epoch 121:     20 / 64 loss=5.679, ppl=51.23, wps=5093.7, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.8, train_wall=571, gb_free=6.1, wall=47873
2022-01-31 22:13:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:14:10 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.088 | ppl 1088.68 | wps 6838.6 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.29
2022-01-31 22:14:10 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 22:14:10 | INFO | train | epoch 121 | loss 5.667 | ppl 50.8 | wps 5187.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.802 | train_wall 370 | gb_free 6.1 | wall 48159
KL Stats: Epoch 121 Divergences: Uniform: 2.9903880911724228 Unigram: 3.807805982421252
2022-01-31 22:14:10 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 22:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:19:36 | INFO | train_inner | epoch 122:     56 / 64 loss=5.665, ppl=50.73, wps=5334.3, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.812, train_wall=579, gb_free=6.1, wall=48485
2022-01-31 22:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:20:53 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.039 | ppl 1052.15 | wps 6844.5 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.29
2022-01-31 22:20:53 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 22:20:53 | INFO | train | epoch 122 | loss 5.657 | ppl 50.44 | wps 5181.7 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.822 | train_wall 370 | gb_free 6.1 | wall 48562
KL Stats: Epoch 122 Divergences: Uniform: 2.996788647457382 Unigram: 3.8190911733675574
2022-01-31 22:20:53 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 22:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:27:28 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.127 | ppl 1118.49 | wps 6968.2 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.29
2022-01-31 22:27:28 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 22:27:28 | INFO | train | epoch 123 | loss 5.643 | ppl 49.99 | wps 5288 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.804 | train_wall 363 | gb_free 6.1 | wall 48957
KL Stats: Epoch 123 Divergences: Uniform: 2.996793557737226 Unigram: 3.8350295237419716
2022-01-31 22:27:28 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 22:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:30:10 | INFO | train_inner | epoch 124:     28 / 64 loss=5.637, ppl=49.76, wps=5143.2, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.806, train_wall=569, gb_free=6.1, wall=49119
2022-01-31 22:33:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:34:10 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.057 | ppl 1065.51 | wps 6880.2 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.29
2022-01-31 22:34:10 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 22:34:10 | INFO | train | epoch 124 | loss 5.634 | ppl 49.66 | wps 5205.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.828 | train_wall 368 | gb_free 6.1 | wall 49358
KL Stats: Epoch 124 Divergences: Uniform: 2.9909709621629235 Unigram: 3.8277534898841745
2022-01-31 22:34:10 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 22:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:40:19 | INFO | train_inner | epoch 125:     64 / 64 loss=5.637, ppl=49.76, wps=5355.6, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.833, train_wall=575, gb_free=6.1, wall=49728
2022-01-31 22:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:40:50 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.106 | ppl 1102.37 | wps 6953.5 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.29
2022-01-31 22:40:50 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 22:40:50 | INFO | train | epoch 125 | loss 5.622 | ppl 49.26 | wps 5210.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.827 | train_wall 368 | gb_free 6.1 | wall 49759
KL Stats: Epoch 125 Divergences: Uniform: 2.998012022288492 Unigram: 3.8434956307629187
2022-01-31 22:40:50 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 22:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:47:24 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.118 | ppl 1111.02 | wps 6816.6 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.29
2022-01-31 22:47:24 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 22:47:24 | INFO | train | epoch 126 | loss 5.611 | ppl 48.88 | wps 5303 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.814 | train_wall 361 | gb_free 6.1 | wall 50153
KL Stats: Epoch 126 Divergences: Uniform: 3.0052412037737253 Unigram: 3.854848321786839
2022-01-31 22:47:24 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 22:47:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:50:52 | INFO | train_inner | epoch 127:     36 / 64 loss=5.599, ppl=48.49, wps=5164.8, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.832, train_wall=568, gb_free=6.1, wall=50360
2022-01-31 22:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:54:04 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.102 | ppl 1098.67 | wps 6947.8 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.29
2022-01-31 22:54:04 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 22:54:04 | INFO | train | epoch 127 | loss 5.602 | ppl 48.57 | wps 5228.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.842 | train_wall 367 | gb_free 6.1 | wall 50552
KL Stats: Epoch 127 Divergences: Uniform: 3.0059959567815424 Unigram: 3.861290193059103
2022-01-31 22:54:04 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 22:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:00:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:00:44 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.125 | ppl 1116.66 | wps 6922.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.29
2022-01-31 23:00:44 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 23:00:44 | INFO | train | epoch 128 | loss 5.591 | ppl 48.2 | wps 5213.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.844 | train_wall 368 | gb_free 6.1 | wall 50953
KL Stats: Epoch 128 Divergences: Uniform: 3.0055516493145857 Unigram: 3.8689075788285434
2022-01-31 23:00:44 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 23:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:01:31 | INFO | train_inner | epoch 129:      8 / 64 loss=5.598, ppl=48.45, wps=5101.6, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.838, train_wall=574, gb_free=6.1, wall=50999
2022-01-31 23:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:07:18 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.124 | ppl 1115.58 | wps 7131.4 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.29
2022-01-31 23:07:18 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 23:07:18 | INFO | train | epoch 129 | loss 5.584 | ppl 47.98 | wps 5307.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.854 | train_wall 362 | gb_free 6.1 | wall 51347
KL Stats: Epoch 129 Divergences: Uniform: 3.002639358222511 Unigram: 3.877890855219435
2022-01-31 23:07:18 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 23:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:11:34 | INFO | train_inner | epoch 130:     44 / 64 loss=5.571, ppl=47.55, wps=5420.2, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.845, train_wall=571, gb_free=6.1, wall=51602
2022-01-31 23:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:14:00 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.128 | ppl 1118.85 | wps 6892.4 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.29
2022-01-31 23:14:00 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 23:14:00 | INFO | train | epoch 130 | loss 5.571 | ppl 47.53 | wps 5195.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.841 | train_wall 369 | gb_free 6.1 | wall 51749
KL Stats: Epoch 130 Divergences: Uniform: 3.008637856865691 Unigram: 3.888506879184281
2022-01-31 23:14:00 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 23:14:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:20:39 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.099 | ppl 1096.83 | wps 6919 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.29
2022-01-31 23:20:39 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 23:20:39 | INFO | train | epoch 131 | loss 5.563 | ppl 47.27 | wps 5227.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.86 | train_wall 367 | gb_free 6.1 | wall 52148
KL Stats: Epoch 131 Divergences: Uniform: 3.014075638398138 Unigram: 3.892896715503664
2022-01-31 23:20:39 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 23:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:22:12 | INFO | train_inner | epoch 132:     16 / 64 loss=5.566, ppl=47.37, wps=5103.4, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.859, train_wall=574, gb_free=6.1, wall=52241
2022-01-31 23:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:27:21 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.128 | ppl 1119.28 | wps 7097.6 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.29
2022-01-31 23:27:21 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 23:27:21 | INFO | train | epoch 132 | loss 5.553 | ppl 46.96 | wps 5199.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.872 | train_wall 370 | gb_free 6.1 | wall 52550
KL Stats: Epoch 132 Divergences: Uniform: 3.01276792201581 Unigram: 3.9087337620037164
2022-01-31 23:27:21 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 23:27:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:32:17 | INFO | train_inner | epoch 133:     52 / 64 loss=5.547, ppl=46.77, wps=5404.7, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.872, train_wall=572, gb_free=6.1, wall=52846
2022-01-31 23:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:33:57 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.095 | ppl 1093.75 | wps 6896.3 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.29
2022-01-31 23:33:57 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 23:33:57 | INFO | train | epoch 133 | loss 5.542 | ppl 46.6 | wps 5274.7 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.871 | train_wall 363 | gb_free 6.1 | wall 52946
KL Stats: Epoch 133 Divergences: Uniform: 3.0247023631560235 Unigram: 3.9125850140334126
2022-01-31 23:33:57 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 23:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:40:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:40:40 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.213 | ppl 1187.23 | wps 6877.7 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.29
2022-01-31 23:40:40 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 23:40:40 | INFO | train | epoch 134 | loss 5.534 | ppl 46.35 | wps 5182.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.901 | train_wall 370 | gb_free 6.1 | wall 53349
KL Stats: Epoch 134 Divergences: Uniform: 3.015347536859965 Unigram: 3.918390897978585
2022-01-31 23:40:40 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 23:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:42:59 | INFO | train_inner | epoch 135:     24 / 64 loss=5.533, ppl=46.3, wps=5078.1, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.892, train_wall=577, gb_free=6.1, wall=53488
2022-01-31 23:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:47:20 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.154 | ppl 1138.99 | wps 6923.7 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.29
2022-01-31 23:47:20 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 23:47:20 | INFO | train | epoch 135 | loss 5.524 | ppl 46.03 | wps 5222 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.879 | train_wall 367 | gb_free 6.1 | wall 53749
KL Stats: Epoch 135 Divergences: Uniform: 3.021054618791427 Unigram: 3.929158523143052
2022-01-31 23:47:20 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 23:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:53:00 | INFO | train_inner | epoch 136:     60 / 64 loss=5.525, ppl=46.05, wps=5437.3, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.886, train_wall=568, gb_free=6.1, wall=54089
2022-01-31 23:53:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:53:53 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.168 | ppl 1150.12 | wps 6953.7 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.29
2022-01-31 23:53:53 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 23:53:53 | INFO | train | epoch 136 | loss 5.516 | ppl 45.75 | wps 5313.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.889 | train_wall 361 | gb_free 6.1 | wall 54142
KL Stats: Epoch 136 Divergences: Uniform: 3.0212329563118856 Unigram: 3.933462528562313
2022-01-31 23:53:53 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 23:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:00:36 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.222 | ppl 1194.61 | wps 6839.1 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.29
2022-02-01 00:00:36 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-01 00:00:36 | INFO | train | epoch 137 | loss 5.509 | ppl 45.53 | wps 5178.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.921 | train_wall 370 | gb_free 6.1 | wall 54545
KL Stats: Epoch 137 Divergences: Uniform: 3.023289416453281 Unigram: 3.944449442310223
2022-02-01 00:00:36 | INFO | fairseq.trainer | begin training epoch 138
2022-02-01 00:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:03:42 | INFO | train_inner | epoch 138:     32 / 64 loss=5.499, ppl=45.23, wps=5075.5, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.903, train_wall=577, gb_free=6.1, wall=54731
2022-02-01 00:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:07:20 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.237 | ppl 1206.99 | wps 6884.6 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.29
2022-02-01 00:07:20 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-01 00:07:20 | INFO | train | epoch 138 | loss 5.497 | ppl 45.16 | wps 5182 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.891 | train_wall 370 | gb_free 6.1 | wall 54948
KL Stats: Epoch 138 Divergences: Uniform: 3.025632021112861 Unigram: 3.946643257903037
2022-02-01 00:07:20 | INFO | fairseq.trainer | begin training epoch 139
2022-02-01 00:07:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:13:55 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.211 | ppl 1185.54 | wps 6819.8 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.29
2022-02-01 00:13:55 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-01 00:13:55 | INFO | train | epoch 139 | loss 5.488 | ppl 44.88 | wps 5281 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.923 | train_wall 362 | gb_free 6.1 | wall 55344
KL Stats: Epoch 139 Divergences: Uniform: 3.028012962908518 Unigram: 3.9649852330664555
2022-02-01 00:13:55 | INFO | fairseq.trainer | begin training epoch 140
2022-02-01 00:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:14:18 | INFO | train_inner | epoch 140:      4 / 64 loss=5.496, ppl=45.12, wps=5126.8, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.921, train_wall=570, gb_free=6.1, wall=55367
2022-02-01 00:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:20:36 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.195 | ppl 1171.92 | wps 6928.6 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.29
2022-02-01 00:20:36 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-01 00:20:36 | INFO | train | epoch 140 | loss 5.48 | ppl 44.64 | wps 5212.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.922 | train_wall 368 | gb_free 6.1 | wall 55745
KL Stats: Epoch 140 Divergences: Uniform: 3.027051586497375 Unigram: 3.9706657729675863
2022-02-01 00:20:36 | INFO | fairseq.trainer | begin training epoch 141
2022-02-01 00:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:24:28 | INFO | train_inner | epoch 141:     40 / 64 loss=5.472, ppl=44.39, wps=5356.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.924, train_wall=577, gb_free=6.1, wall=55977
2022-02-01 00:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:27:18 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.251 | ppl 1218.6 | wps 6839.8 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.29
2022-02-01 00:27:18 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-01 00:27:18 | INFO | train | epoch 141 | loss 5.472 | ppl 44.39 | wps 5186.9 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.916 | train_wall 370 | gb_free 6.1 | wall 56147
KL Stats: Epoch 141 Divergences: Uniform: 3.033565383459058 Unigram: 3.9799895220949977
2022-02-01 00:27:18 | INFO | fairseq.trainer | begin training epoch 142
2022-02-01 00:27:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:33:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:33:53 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.203 | ppl 1178.51 | wps 6868.6 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.29
2022-02-01 00:33:53 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-01 00:33:53 | INFO | train | epoch 142 | loss 5.464 | ppl 44.14 | wps 5291.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.946 | train_wall 362 | gb_free 6.1 | wall 56542
KL Stats: Epoch 142 Divergences: Uniform: 3.0330811368059276 Unigram: 3.978078231566015
2022-02-01 00:33:53 | INFO | fairseq.trainer | begin training epoch 143
2022-02-01 00:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:35:03 | INFO | train_inner | epoch 143:     12 / 64 loss=5.465, ppl=44.17, wps=5137, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.931, train_wall=569, gb_free=6.1, wall=56612
2022-02-01 00:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:40:36 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.191 | ppl 1168.61 | wps 6967.7 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.29
2022-02-01 00:40:36 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-01 00:40:36 | INFO | train | epoch 143 | loss 5.455 | ppl 43.86 | wps 5187.5 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.918 | train_wall 370 | gb_free 6.1 | wall 56945
KL Stats: Epoch 143 Divergences: Uniform: 3.04291486221581 Unigram: 3.9888203822397097
2022-02-01 00:40:36 | INFO | fairseq.trainer | begin training epoch 144
2022-02-01 00:40:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:45:05 | INFO | train_inner | epoch 144:     48 / 64 loss=5.452, ppl=43.79, wps=5429.3, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.915, train_wall=569, gb_free=6.1, wall=57214
2022-02-01 00:46:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:46:49 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.278 | ppl 1241.81 | wps 8275.4 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.29
2022-02-01 00:46:49 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-01 00:46:49 | INFO | train | epoch 144 | loss 5.45 | ppl 43.7 | wps 5598.5 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.917 | train_wall 346 | gb_free 6.1 | wall 57318
KL Stats: Epoch 144 Divergences: Uniform: 3.0339599184814263 Unigram: 3.990451990949594
2022-02-01 00:46:49 | INFO | fairseq.trainer | begin training epoch 145
2022-02-01 00:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:52:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:52:30 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.215 | ppl 1188.73 | wps 8278.1 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.29
2022-02-01 00:52:30 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-01 00:52:30 | INFO | train | epoch 145 | loss 5.442 | ppl 43.48 | wps 6122.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.945 | train_wall 314 | gb_free 6.1 | wall 57659
KL Stats: Epoch 145 Divergences: Uniform: 3.042607400558072 Unigram: 4.001060286258201
2022-02-01 00:52:30 | INFO | fairseq.trainer | begin training epoch 146
2022-02-01 00:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:54:09 | INFO | train_inner | epoch 146:     20 / 64 loss=5.438, ppl=43.36, wps=5996, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.947, train_wall=490, gb_free=6.1, wall=57757
2022-02-01 00:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:58:11 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.231 | ppl 1201.56 | wps 8280 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.29
2022-02-01 00:58:11 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-01 00:58:11 | INFO | train | epoch 146 | loss 5.431 | ppl 43.16 | wps 6126.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.961 | train_wall 314 | gb_free 6.1 | wall 58000
KL Stats: Epoch 146 Divergences: Uniform: 3.03956439491912 Unigram: 4.0042693935602545
2022-02-01 00:58:11 | INFO | fairseq.trainer | begin training epoch 147
2022-02-01 00:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:02:48 | INFO | train_inner | epoch 147:     56 / 64 loss=5.433, ppl=43.21, wps=6293.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.969, train_wall=492, gb_free=6.1, wall=58277
2022-02-01 01:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:03:53 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.183 | ppl 1162.53 | wps 8254.4 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.29
2022-02-01 01:03:53 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-01 01:03:53 | INFO | train | epoch 147 | loss 5.424 | ppl 42.94 | wps 6112.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.98 | train_wall 314 | gb_free 6.1 | wall 58341
KL Stats: Epoch 147 Divergences: Uniform: 3.045200730132041 Unigram: 4.01579120177139
2022-02-01 01:03:53 | INFO | fairseq.trainer | begin training epoch 148
2022-02-01 01:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:09:34 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.208 | ppl 1182.65 | wps 8258.2 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.29
2022-02-01 01:09:34 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-01 01:09:34 | INFO | train | epoch 148 | loss 5.417 | ppl 42.71 | wps 6120.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.953 | train_wall 314 | gb_free 6.1 | wall 58683
KL Stats: Epoch 148 Divergences: Uniform: 3.0429937698763845 Unigram: 4.0224635293099595
2022-02-01 01:09:34 | INFO | fairseq.trainer | begin training epoch 149
2022-02-01 01:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:11:52 | INFO | train_inner | epoch 149:     28 / 64 loss=5.412, ppl=42.59, wps=5988.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.957, train_wall=490, gb_free=6.1, wall=58821
2022-02-01 01:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:15:15 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.287 | ppl 1249.06 | wps 8257.4 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.29
2022-02-01 01:15:15 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-01 01:15:15 | INFO | train | epoch 149 | loss 5.411 | ppl 42.55 | wps 6129.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.965 | train_wall 313 | gb_free 6.1 | wall 59023
KL Stats: Epoch 149 Divergences: Uniform: 3.0491225005148572 Unigram: 4.029804365612695
2022-02-01 01:15:15 | INFO | fairseq.trainer | begin training epoch 150
2022-02-01 01:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:20:29 | INFO | train_inner | epoch 150:     64 / 64 loss=5.413, ppl=42.61, wps=6310.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.972, train_wall=489, gb_free=6.1, wall=59338
2022-02-01 01:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:20:55 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.286 | ppl 1248.38 | wps 8271.6 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.29
2022-02-01 01:20:55 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-01 01:20:55 | INFO | train | epoch 150 | loss 5.402 | ppl 42.29 | wps 6132.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.97 | train_wall 313 | gb_free 6.1 | wall 59364
KL Stats: Epoch 150 Divergences: Uniform: 3.047466270880227 Unigram: 4.0299796912070125
2022-02-01 01:20:55 | INFO | fairseq.trainer | begin training epoch 151
2022-02-01 01:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:26:36 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.223 | ppl 1195.37 | wps 8262 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.29
2022-02-01 01:26:36 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-01 01:26:36 | INFO | train | epoch 151 | loss 5.394 | ppl 42.06 | wps 6120 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.997 | train_wall 314 | gb_free 6.1 | wall 59705
KL Stats: Epoch 151 Divergences: Uniform: 3.0434594882418198 Unigram: 4.039476807996849
2022-02-01 01:26:36 | INFO | fairseq.trainer | begin training epoch 152
2022-02-01 01:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:29:34 | INFO | train_inner | epoch 152:     36 / 64 loss=5.381, ppl=41.69, wps=5991.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.995, train_wall=491, gb_free=6.1, wall=59883
2022-02-01 01:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:32:18 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.213 | ppl 1186.53 | wps 8247.9 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.29
2022-02-01 01:32:18 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-01 01:32:18 | INFO | train | epoch 152 | loss 5.388 | ppl 41.86 | wps 6122.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.003 | train_wall 314 | gb_free 6.1 | wall 60046
KL Stats: Epoch 152 Divergences: Uniform: 3.0542965377641687 Unigram: 4.050538004423532
2022-02-01 01:32:18 | INFO | fairseq.trainer | begin training epoch 153
2022-02-01 01:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:37:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:37:58 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.263 | ppl 1228.88 | wps 8322.1 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.29
2022-02-01 01:37:58 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-01 01:37:58 | INFO | train | epoch 153 | loss 5.379 | ppl 41.62 | wps 6129.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.986 | train_wall 314 | gb_free 6.1 | wall 60387
KL Stats: Epoch 153 Divergences: Uniform: 3.0533656572374936 Unigram: 4.056986386332573
2022-02-01 01:37:58 | INFO | fairseq.trainer | begin training epoch 154
2022-02-01 01:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:38:38 | INFO | train_inner | epoch 154:      8 / 64 loss=5.388, ppl=41.86, wps=5996.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.997, train_wall=490, gb_free=6.1, wall=60427
2022-02-01 01:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:43:39 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.282 | ppl 1244.96 | wps 8250.6 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.29
2022-02-01 01:43:39 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-01 01:43:39 | INFO | train | epoch 154 | loss 5.373 | ppl 41.44 | wps 6123.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.011 | train_wall 314 | gb_free 6.1 | wall 60728
KL Stats: Epoch 154 Divergences: Uniform: 3.0596152090571267 Unigram: 4.058354967814046
2022-02-01 01:43:39 | INFO | fairseq.trainer | begin training epoch 155
2022-02-01 01:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:47:16 | INFO | train_inner | epoch 155:     44 / 64 loss=5.365, ppl=41.2, wps=6302.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.994, train_wall=491, gb_free=6.1, wall=60945
2022-02-01 01:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:49:20 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.261 | ppl 1226.66 | wps 8273.6 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.29
2022-02-01 01:49:20 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-01 01:49:20 | INFO | train | epoch 155 | loss 5.367 | ppl 41.28 | wps 6129.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.002 | train_wall 314 | gb_free 6.1 | wall 61069
KL Stats: Epoch 155 Divergences: Uniform: 3.0548763614837404 Unigram: 4.070180938448104
2022-02-01 01:49:20 | INFO | fairseq.trainer | begin training epoch 156
2022-02-01 01:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:55:02 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.271 | ppl 1235.58 | wps 8256.4 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.29
2022-02-01 01:55:02 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-01 01:55:02 | INFO | train | epoch 156 | loss 5.36 | ppl 41.06 | wps 6116.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.034 | train_wall 314 | gb_free 6.1 | wall 61411
KL Stats: Epoch 156 Divergences: Uniform: 3.056439922483455 Unigram: 4.069101174672444
2022-02-01 01:55:02 | INFO | fairseq.trainer | begin training epoch 157
2022-02-01 01:55:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:56:21 | INFO | train_inner | epoch 157:     16 / 64 loss=5.366, ppl=41.24, wps=5989.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.036, train_wall=490, gb_free=6.1, wall=61490
2022-02-01 02:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:00:43 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.232 | ppl 1202.85 | wps 8280.7 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.29
2022-02-01 02:00:43 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-01 02:00:43 | INFO | train | epoch 157 | loss 5.352 | ppl 40.85 | wps 6128.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.022 | train_wall 314 | gb_free 6.1 | wall 61751
KL Stats: Epoch 157 Divergences: Uniform: 3.0608715626910903 Unigram: 4.079767542947836
2022-02-01 02:00:43 | INFO | fairseq.trainer | begin training epoch 158
2022-02-01 02:00:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:04:59 | INFO | train_inner | epoch 158:     52 / 64 loss=5.346, ppl=40.67, wps=6309, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.014, train_wall=490, gb_free=6.1, wall=62008
2022-02-01 02:05:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:06:23 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.288 | ppl 1250.01 | wps 8258.6 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.29
2022-02-01 02:06:23 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 02:06:23 | INFO | train | epoch 158 | loss 5.346 | ppl 40.68 | wps 6133.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.016 | train_wall 313 | gb_free 6.1 | wall 62092
KL Stats: Epoch 158 Divergences: Uniform: 3.0558533945773583 Unigram: 4.086374289821213
2022-02-01 02:06:23 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 02:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:12:04 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.326 | ppl 1283.23 | wps 8268.8 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.29
2022-02-01 02:12:04 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 02:12:04 | INFO | train | epoch 159 | loss 5.34 | ppl 40.51 | wps 6130.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.054 | train_wall 313 | gb_free 6.1 | wall 62433
KL Stats: Epoch 159 Divergences: Uniform: 3.0549733275791513 Unigram: 4.093062282084784
2022-02-01 02:12:04 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 02:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:14:02 | INFO | train_inner | epoch 160:     24 / 64 loss=5.339, ppl=40.48, wps=5998.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.058, train_wall=489, gb_free=6.1, wall=62551
2022-02-01 02:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:17:45 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.269 | ppl 1234.01 | wps 8230.4 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.29
2022-02-01 02:17:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 02:17:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint160.pt
2022-02-01 02:17:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint160.pt
2022-02-01 02:17:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.269) (writing took 3.649901932105422 seconds)
2022-02-01 02:17:48 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 02:17:48 | INFO | train | epoch 160 | loss 5.333 | ppl 40.31 | wps 6063.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.046 | train_wall 313 | gb_free 6.1 | wall 62777
KL Stats: Epoch 160 Divergences: Uniform: 3.0616603969628158 Unigram: 4.100983607626151
2022-02-01 02:17:48 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 02:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:22:44 | INFO | train_inner | epoch 161:     60 / 64 loss=5.334, ppl=40.34, wps=6258.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.04, train_wall=491, gb_free=6.1, wall=63073
2022-02-01 02:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:23:29 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.24 | ppl 1209.22 | wps 8290 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.29
2022-02-01 02:23:29 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 02:23:29 | INFO | train | epoch 161 | loss 5.327 | ppl 40.14 | wps 6127.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.041 | train_wall 314 | gb_free 6.1 | wall 63118
KL Stats: Epoch 161 Divergences: Uniform: 3.0672003823918232 Unigram: 4.102704337899334
2022-02-01 02:23:29 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 02:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:29:10 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.242 | ppl 1211.15 | wps 8239.3 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.29
2022-02-01 02:29:10 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 02:29:10 | INFO | train | epoch 162 | loss 5.319 | ppl 39.92 | wps 6132.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.039 | train_wall 313 | gb_free 6.1 | wall 63458
KL Stats: Epoch 162 Divergences: Uniform: 3.068637760702473 Unigram: 4.110482323820518
2022-02-01 02:29:10 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 02:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:31:48 | INFO | train_inner | epoch 163:     32 / 64 loss=5.306, ppl=39.57, wps=6001, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.044, train_wall=489, gb_free=6.1, wall=63616
2022-02-01 02:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:34:50 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.387 | ppl 1338.81 | wps 8270 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.29
2022-02-01 02:34:50 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 02:34:50 | INFO | train | epoch 163 | loss 5.316 | ppl 39.83 | wps 6134.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.056 | train_wall 313 | gb_free 6.1 | wall 63799
KL Stats: Epoch 163 Divergences: Uniform: 3.0683272439429246 Unigram: 4.117609959309015
2022-02-01 02:34:50 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 02:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:40:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:40:31 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.279 | ppl 1242.12 | wps 8336 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.29
2022-02-01 02:40:31 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 02:40:31 | INFO | train | epoch 164 | loss 5.308 | ppl 39.61 | wps 6128.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.07 | train_wall 314 | gb_free 6.1 | wall 64140
KL Stats: Epoch 164 Divergences: Uniform: 3.0633462307138863 Unigram: 4.121737585562999
2022-02-01 02:40:31 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 02:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:40:51 | INFO | train_inner | epoch 165:      4 / 64 loss=5.323, ppl=40.02, wps=6000.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.065, train_wall=489, gb_free=6.1, wall=64160
2022-02-01 02:45:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:46:11 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.389 | ppl 1340.62 | wps 8266.1 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.29
2022-02-01 02:46:11 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 02:46:11 | INFO | train | epoch 165 | loss 5.3 | ppl 39.39 | wps 6137.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.058 | train_wall 313 | gb_free 6.1 | wall 64480
KL Stats: Epoch 165 Divergences: Uniform: 3.0696356733587122 Unigram: 4.132712199113341
2022-02-01 02:46:11 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 02:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:49:28 | INFO | train_inner | epoch 166:     40 / 64 loss=5.293, ppl=39.2, wps=6313.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.057, train_wall=490, gb_free=6.1, wall=64677
2022-02-01 02:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:51:52 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.191 | ppl 1168.97 | wps 8277.1 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.29
2022-02-01 02:51:52 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 02:51:52 | INFO | train | epoch 166 | loss 5.295 | ppl 39.27 | wps 6135.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.075 | train_wall 313 | gb_free 6.1 | wall 64820
KL Stats: Epoch 166 Divergences: Uniform: 3.0707235288683488 Unigram: 4.136854159265849
2022-02-01 02:51:52 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 02:51:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:57:33 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.205 | ppl 1180.29 | wps 8280.1 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.29
2022-02-01 02:57:33 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 02:57:33 | INFO | train | epoch 167 | loss 5.29 | ppl 39.13 | wps 6123.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.092 | train_wall 314 | gb_free 6.1 | wall 65161
KL Stats: Epoch 167 Divergences: Uniform: 3.0688495478310482 Unigram: 4.136527112892242
2022-02-01 02:57:33 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 02:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:58:32 | INFO | train_inner | epoch 168:     12 / 64 loss=5.292, ppl=39.18, wps=5998.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.097, train_wall=489, gb_free=6.1, wall=65221
2022-02-01 03:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:03:13 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.294 | ppl 1255.7 | wps 8308.8 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.29
2022-02-01 03:03:13 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 03:03:13 | INFO | train | epoch 168 | loss 5.284 | ppl 38.96 | wps 6130.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.11 | train_wall 314 | gb_free 6.1 | wall 65502
KL Stats: Epoch 168 Divergences: Uniform: 3.0764219447659538 Unigram: 4.141364380141867
2022-02-01 03:03:13 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 03:03:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:07:10 | INFO | train_inner | epoch 169:     48 / 64 loss=5.283, ppl=38.94, wps=6308.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.106, train_wall=490, gb_free=6.1, wall=65739
2022-02-01 03:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:08:54 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.264 | ppl 1229.46 | wps 8283 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.29
2022-02-01 03:08:54 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 03:08:54 | INFO | train | epoch 169 | loss 5.278 | ppl 38.8 | wps 6133.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.091 | train_wall 313 | gb_free 6.1 | wall 65843
KL Stats: Epoch 169 Divergences: Uniform: 3.0743679720933206 Unigram: 4.148062016241189
2022-02-01 03:08:54 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 03:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:14:35 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.318 | ppl 1276.73 | wps 8296.4 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.29
2022-02-01 03:14:35 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 03:14:35 | INFO | train | epoch 170 | loss 5.272 | ppl 38.64 | wps 6117.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.13 | train_wall 314 | gb_free 6.1 | wall 66184
KL Stats: Epoch 170 Divergences: Uniform: 3.076272813574346 Unigram: 4.152342232925544
2022-02-01 03:14:35 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 03:14:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:16:14 | INFO | train_inner | epoch 171:     20 / 64 loss=5.267, ppl=38.51, wps=5991.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.133, train_wall=490, gb_free=6.1, wall=66283
2022-02-01 03:19:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:20:16 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.268 | ppl 1233.32 | wps 8318.5 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.29
2022-02-01 03:20:16 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 03:20:16 | INFO | train | epoch 171 | loss 5.268 | ppl 38.52 | wps 6135.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.148 | train_wall 313 | gb_free 6.1 | wall 66524
KL Stats: Epoch 171 Divergences: Uniform: 3.07382952283342 Unigram: 4.158352140104088
2022-02-01 03:20:16 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 03:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:24:52 | INFO | train_inner | epoch 172:     56 / 64 loss=5.269, ppl=38.56, wps=6312.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.117, train_wall=490, gb_free=6.1, wall=66800
2022-02-01 03:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:25:56 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.295 | ppl 1256.31 | wps 8328.4 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.29
2022-02-01 03:25:56 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 03:25:56 | INFO | train | epoch 172 | loss 5.259 | ppl 38.3 | wps 6139 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.111 | train_wall 313 | gb_free 6.1 | wall 66865
KL Stats: Epoch 172 Divergences: Uniform: 3.0753096500291752 Unigram: 4.166689883747262
2022-02-01 03:25:56 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 03:25:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:31:37 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.232 | ppl 1202.99 | wps 8308.7 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.29
2022-02-01 03:31:37 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 03:31:37 | INFO | train | epoch 173 | loss 5.256 | ppl 38.22 | wps 6130.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.162 | train_wall 314 | gb_free 6.1 | wall 67205
KL Stats: Epoch 173 Divergences: Uniform: 3.07695695849138 Unigram: 4.16835253364607
2022-02-01 03:31:37 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 03:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:33:54 | INFO | train_inner | epoch 174:     28 / 64 loss=5.25, ppl=38.05, wps=6006, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.147, train_wall=489, gb_free=6.1, wall=67343
2022-02-01 03:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:37:17 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.342 | ppl 1297.96 | wps 8281.8 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.29
2022-02-01 03:37:17 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 03:37:17 | INFO | train | epoch 174 | loss 5.251 | ppl 38.08 | wps 6141.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.132 | train_wall 313 | gb_free 6.1 | wall 67546
KL Stats: Epoch 174 Divergences: Uniform: 3.0758240920302606 Unigram: 4.178547501511114
2022-02-01 03:37:17 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 03:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:42:31 | INFO | train_inner | epoch 175:     64 / 64 loss=5.254, ppl=38.17, wps=6314.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.139, train_wall=489, gb_free=6.1, wall=67859
2022-02-01 03:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:42:57 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.366 | ppl 1319.3 | wps 8278.5 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.29
2022-02-01 03:42:57 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 03:42:57 | INFO | train | epoch 175 | loss 5.244 | ppl 37.89 | wps 6137.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.132 | train_wall 313 | gb_free 6.1 | wall 67886
KL Stats: Epoch 175 Divergences: Uniform: 3.086779721408646 Unigram: 4.180490780977265
2022-02-01 03:42:57 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 03:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:48:38 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.31 | ppl 1269.41 | wps 8278.7 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.29
2022-02-01 03:48:38 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 03:48:38 | INFO | train | epoch 176 | loss 5.239 | ppl 37.77 | wps 6122.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.157 | train_wall 314 | gb_free 6.1 | wall 68227
KL Stats: Epoch 176 Divergences: Uniform: 3.08545310413684 Unigram: 4.189388365730729
2022-02-01 03:48:38 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 03:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:51:36 | INFO | train_inner | epoch 177:     36 / 64 loss=5.226, ppl=37.44, wps=5994.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.158, train_wall=491, gb_free=6.1, wall=68405
2022-02-01 03:53:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:54:19 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.29 | ppl 1252.21 | wps 8248 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.29
2022-02-01 03:54:19 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 03:54:19 | INFO | train | epoch 177 | loss 5.234 | ppl 37.63 | wps 6126 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.181 | train_wall 314 | gb_free 6.1 | wall 68568
KL Stats: Epoch 177 Divergences: Uniform: 3.0804037656246477 Unigram: 4.191443756110289
2022-02-01 03:54:19 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 03:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:59:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:00:00 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.292 | ppl 1253.46 | wps 8260.4 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.29
2022-02-01 04:00:00 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 04:00:00 | INFO | train | epoch 178 | loss 5.23 | ppl 37.53 | wps 6133.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.169 | train_wall 313 | gb_free 6.1 | wall 68908
KL Stats: Epoch 178 Divergences: Uniform: 3.0918264613382243 Unigram: 4.19606172038458
2022-02-01 04:00:00 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 04:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:00:39 | INFO | train_inner | epoch 179:      8 / 64 loss=5.237, ppl=37.72, wps=5997.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.177, train_wall=489, gb_free=6.1, wall=68948
2022-02-01 04:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:05:41 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.266 | ppl 1231.27 | wps 8209.5 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.29
2022-02-01 04:05:41 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 04:05:41 | INFO | train | epoch 179 | loss 5.223 | ppl 37.35 | wps 6116.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.194 | train_wall 314 | gb_free 6.1 | wall 69250
KL Stats: Epoch 179 Divergences: Uniform: 3.0924607379352893 Unigram: 4.201193349392108
2022-02-01 04:05:41 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 04:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:09:19 | INFO | train_inner | epoch 180:     44 / 64 loss=5.219, ppl=37.24, wps=6293.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.191, train_wall=491, gb_free=6.1, wall=69467
2022-02-01 04:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:11:23 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.245 | ppl 1213.84 | wps 8264.1 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.29
2022-02-01 04:11:23 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 04:11:23 | INFO | train | epoch 180 | loss 5.22 | ppl 37.26 | wps 6116.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.215 | train_wall 314 | gb_free 6.1 | wall 69591
KL Stats: Epoch 180 Divergences: Uniform: 3.087293082642333 Unigram: 4.205507170926503
2022-02-01 04:11:23 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 04:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:17:03 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.325 | ppl 1283 | wps 8266.6 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.29
2022-02-01 04:17:03 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 04:17:03 | INFO | train | epoch 181 | loss 5.213 | ppl 37.1 | wps 6131.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.216 | train_wall 313 | gb_free 6.1 | wall 69932
KL Stats: Epoch 181 Divergences: Uniform: 3.0915367225514907 Unigram: 4.212614743062987
2022-02-01 04:17:03 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 04:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:18:22 | INFO | train_inner | epoch 182:     16 / 64 loss=5.214, ppl=37.12, wps=5999, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.228, train_wall=489, gb_free=6.1, wall=70011
2022-02-01 04:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:22:44 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.265 | ppl 1230.47 | wps 8281.9 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.29
2022-02-01 04:22:44 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 04:22:44 | INFO | train | epoch 182 | loss 5.208 | ppl 36.98 | wps 6136 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.209 | train_wall 313 | gb_free 6.1 | wall 70272
KL Stats: Epoch 182 Divergences: Uniform: 3.0913826336714623 Unigram: 4.209573042218123
2022-02-01 04:22:44 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 04:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:27:00 | INFO | train_inner | epoch 183:     52 / 64 loss=5.206, ppl=36.92, wps=6303.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.211, train_wall=491, gb_free=6.1, wall=70529
2022-02-01 04:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:28:25 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.33 | ppl 1287.48 | wps 8264.3 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.29
2022-02-01 04:28:25 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 04:28:25 | INFO | train | epoch 183 | loss 5.203 | ppl 36.83 | wps 6122.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.213 | train_wall 314 | gb_free 6.1 | wall 70614
KL Stats: Epoch 183 Divergences: Uniform: 3.094593125240463 Unigram: 4.221917499291648
2022-02-01 04:28:25 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 04:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:34:06 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.254 | ppl 1220.84 | wps 8271.9 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.29
2022-02-01 04:34:06 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 04:34:06 | INFO | train | epoch 184 | loss 5.2 | ppl 36.75 | wps 6125.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.24 | train_wall 314 | gb_free 6.1 | wall 70955
KL Stats: Epoch 184 Divergences: Uniform: 3.0945662885996907 Unigram: 4.222409460844064
2022-02-01 04:34:06 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 04:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:36:04 | INFO | train_inner | epoch 185:     24 / 64 loss=5.2, ppl=36.75, wps=5992.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.239, train_wall=490, gb_free=6.1, wall=71073
2022-02-01 04:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:39:47 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.29 | ppl 1251.86 | wps 8228.8 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.29
2022-02-01 04:39:47 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 04:39:47 | INFO | train | epoch 185 | loss 5.195 | ppl 36.63 | wps 6116.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.245 | train_wall 314 | gb_free 6.1 | wall 71296
KL Stats: Epoch 185 Divergences: Uniform: 3.091036509366973 Unigram: 4.227940000643267
2022-02-01 04:39:47 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 04:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:44:43 | INFO | train_inner | epoch 186:     60 / 64 loss=5.195, ppl=36.62, wps=6299.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.227, train_wall=491, gb_free=6.1, wall=71592
2022-02-01 04:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:45:28 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.201 | ppl 1176.96 | wps 8244.5 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.29
2022-02-01 04:45:28 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 04:45:28 | INFO | train | epoch 186 | loss 5.19 | ppl 36.52 | wps 6127 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.217 | train_wall 314 | gb_free 6.1 | wall 71637
KL Stats: Epoch 186 Divergences: Uniform: 3.0946367632480287 Unigram: 4.230184487538818
2022-02-01 04:45:28 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 04:45:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:51:09 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.295 | ppl 1256.65 | wps 8269.4 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.29
2022-02-01 04:51:09 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 04:51:09 | INFO | train | epoch 187 | loss 5.184 | ppl 36.36 | wps 6119.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.233 | train_wall 314 | gb_free 6.1 | wall 71978
KL Stats: Epoch 187 Divergences: Uniform: 3.0938049467521087 Unigram: 4.234701700544971
2022-02-01 04:51:09 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 04:51:09 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g3-004>
Subject: Job 202993621: <w2_jelinek_0.1_0.0_0.9_#4> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#4> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:07:12 2022
Job was executed on host(s) <eu-g3-004>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:07:34 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:07:34 2022
Terminated at Thu Feb  3 02:07:36 2022
Results reported at Thu Feb  3 02:07:36 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 4002 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71957.00 sec.
    Max Memory :                                 5444 MB
    Average Memory :                             3219.13 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14556.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72001 sec.
    Turnaround time :                            72024 sec.

The output (if any) follows:

2022-02-02 06:07:43 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4002, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 4002, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:07:44 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:07:45 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1068/36718 [00:00<00:03, 10673.70it/s]  6%|▌         | 2136/36718 [00:00<00:03, 10186.65it/s]  9%|▉         | 3337/36718 [00:00<00:03, 10993.16it/s] 13%|█▎        | 4621/36718 [00:00<00:02, 11699.12it/s] 16%|█▌        | 5930/36718 [00:00<00:02, 12192.69it/s] 19%|█▉        | 7152/36718 [00:00<00:02, 11415.16it/s] 23%|██▎       | 8304/36718 [00:00<00:02, 11401.73it/s] 26%|██▌       | 9451/36718 [00:00<00:02, 11357.28it/s] 29%|██▉       | 10592/36718 [00:00<00:02, 11308.00it/s] 32%|███▏      | 11726/36718 [00:01<00:02, 11223.89it/s] 35%|███▌      | 12897/36718 [00:01<00:02, 11364.47it/s] 38%|███▊      | 14084/36718 [00:01<00:01, 11515.51it/s] 42%|████▏     | 15304/36718 [00:01<00:01, 11714.39it/s] 45%|████▍     | 16477/36718 [00:01<00:01, 11326.77it/s] 48%|████▊     | 17614/36718 [00:01<00:01, 11273.46it/s] 51%|█████     | 18792/36718 [00:01<00:01, 11417.70it/s] 55%|█████▍    | 20065/36718 [00:01<00:01, 11805.02it/s] 58%|█████▊    | 21248/36718 [00:01<00:01, 11480.35it/s] 61%|██████    | 22400/36718 [00:01<00:01, 11380.65it/s] 64%|██████▍   | 23641/36718 [00:02<00:01, 11675.61it/s] 68%|██████▊   | 24973/36718 [00:02<00:00, 12155.65it/s] 71%|███████▏  | 26192/36718 [00:02<00:00, 12018.30it/s] 75%|███████▍  | 27396/36718 [00:02<00:00, 11367.70it/s] 78%|███████▊  | 28639/36718 [00:02<00:00, 11666.01it/s] 81%|████████  | 29813/36718 [00:02<00:00, 11514.82it/s] 84%|████████▍ | 30970/36718 [00:02<00:00, 11065.54it/s] 87%|████████▋ | 32083/36718 [00:02<00:00, 10973.74it/s] 90%|█████████ | 33185/36718 [00:02<00:00, 10837.96it/s] 93%|█████████▎| 34296/36718 [00:03<00:00, 10912.71it/s] 97%|█████████▋| 35505/36718 [00:03<00:00, 11253.61it/s]100%|█████████▉| 36643/36718 [00:03<00:00, 11287.74it/s]100%|██████████| 36718/36718 [00:03<00:00, 11391.90it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  5%|▌         | 1934/36718 [00:00<00:01, 19317.45it/s] 11%|█▏        | 4176/36718 [00:00<00:01, 21076.09it/s] 18%|█▊        | 6451/36718 [00:00<00:01, 21814.82it/s] 24%|██▎       | 8633/36718 [00:00<00:01, 21209.32it/s] 29%|██▉       | 10785/36718 [00:00<00:01, 21309.54it/s] 35%|███▌      | 12918/36718 [00:00<00:01, 21240.30it/s] 41%|████▏     | 15194/36718 [00:00<00:00, 21723.52it/s] 47%|████▋     | 17368/36718 [00:00<00:00, 21230.42it/s] 54%|█████▎    | 19668/36718 [00:00<00:00, 21765.07it/s] 60%|█████▉    | 21848/36718 [00:01<00:00, 21443.69it/s] 66%|██████▌   | 24225/36718 [00:01<00:00, 22139.15it/s] 72%|███████▏  | 26465/36718 [00:01<00:00, 22215.67it/s] 78%|███████▊  | 28690/36718 [00:01<00:00, 22068.18it/s] 84%|████████▍ | 30899/36718 [00:01<00:00, 21529.57it/s] 90%|█████████ | 33056/36718 [00:01<00:00, 21147.59it/s] 96%|█████████▌| 35265/36718 [00:01<00:00, 21419.95it/s]100%|██████████| 36718/36718 [00:01<00:00, 21506.60it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 83.48it/s]2022-02-02 06:07:59 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:07:59 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:07:59 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:07:59 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:07:59 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:07:59 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:07:59 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:07:59 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:07:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:59 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:07:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:07:59 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:07:59 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint_last.pt
2022-02-02 06:07:59 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint_last.pt
2022-02-02 06:07:59 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:07:59 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:07:59 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:07:59 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:07:59 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:14:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.64 | ppl 25536.6 | wps 7867.4 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:14:01 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:14:01 | INFO | train | epoch 001 | loss 16.138 | ppl 72125.5 | wps 5812.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.267 | train_wall 330 | gb_free 6.1 | wall 362
KL Stats: Epoch 1 Divergences: Uniform: 0.5234875889603318 Unigram: 3.694472046677293
2022-02-02 06:14:01 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:17:08 | INFO | train_inner | epoch 002:     36 / 64 loss=15.578, ppl=48910.9, wps=5984.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.671, train_wall=516, gb_free=6.1, wall=549
2022-02-02 06:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:19:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.57 | ppl 12160.1 | wps 7886.8 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:19:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:19:59 | INFO | train | epoch 002 | loss 14.364 | ppl 21091.1 | wps 5830.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.492 | train_wall 329 | gb_free 6.1 | wall 721
KL Stats: Epoch 2 Divergences: Uniform: 0.5349303368087138 Unigram: 2.3713361978319236
2022-02-02 06:19:59 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:25:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.753 | ppl 6904.89 | wps 7831.9 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:25:58 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:25:58 | INFO | train | epoch 003 | loss 13.46 | ppl 11266.4 | wps 5819.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.182 | train_wall 329 | gb_free 6.1 | wall 1079
KL Stats: Epoch 3 Divergences: Uniform: 0.5208396130384894 Unigram: 1.685627439315193
2022-02-02 06:25:58 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:26:40 | INFO | train_inner | epoch 004:      8 / 64 loss=13.589, ppl=12325.6, wps=5700.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.216, train_wall=514, gb_free=6.1, wall=1121
2022-02-02 06:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:31:57 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.95 | ppl 3955.8 | wps 7842.6 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:31:57 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:31:57 | INFO | train | epoch 004 | loss 12.529 | ppl 5910.75 | wps 5819.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.924 | train_wall 329 | gb_free 6.1 | wall 1438
KL Stats: Epoch 4 Divergences: Uniform: 0.6063370884020383 Unigram: 1.0644478563515283
2022-02-02 06:31:57 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:35:45 | INFO | train_inner | epoch 005:     44 / 64 loss=12.197, ppl=4695.42, wps=5991.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.811, train_wall=515, gb_free=6.1, wall=1667
2022-02-02 06:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:37:55 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.472 | ppl 2841.14 | wps 7862.6 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:37:55 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:37:55 | INFO | train | epoch 005 | loss 11.763 | ppl 3474.56 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.679 | train_wall 329 | gb_free 6.1 | wall 1797
KL Stats: Epoch 5 Divergences: Uniform: 0.8504523938357221 Unigram: 0.6130831626008681
2022-02-02 06:37:56 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:43:54 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.27 | ppl 2469.16 | wps 7898 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:43:54 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:43:54 | INFO | train | epoch 006 | loss 11.362 | ppl 2631.22 | wps 5825.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.629 | train_wall 329 | gb_free 6.1 | wall 2155
KL Stats: Epoch 6 Divergences: Uniform: 1.152136946645145 Unigram: 0.4210829399608793
2022-02-02 06:43:54 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:45:17 | INFO | train_inner | epoch 007:     16 / 64 loss=11.378, ppl=2661.58, wps=5701.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.615, train_wall=514, gb_free=6.1, wall=2238
2022-02-02 06:49:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:49:52 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.13 | ppl 2240.51 | wps 7874.7 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:49:52 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:49:52 | INFO | train | epoch 007 | loss 11.162 | ppl 2291.12 | wps 5835.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.513 | train_wall 329 | gb_free 6.1 | wall 2513
KL Stats: Epoch 7 Divergences: Uniform: 1.3616047418228636 Unigram: 0.4557804301268675
2022-02-02 06:49:52 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:54:21 | INFO | train_inner | epoch 008:     52 / 64 loss=11.096, ppl=2188.65, wps=6006.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.513, train_wall=514, gb_free=6.1, wall=2782
2022-02-02 06:55:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:55:50 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.025 | ppl 2083.46 | wps 7865 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:55:50 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:55:50 | INFO | train | epoch 008 | loss 11.043 | ppl 2109.46 | wps 5838.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 328 | gb_free 6.1 | wall 2871
KL Stats: Epoch 8 Divergences: Uniform: 1.4776753989315752 Unigram: 0.5398541677543125
2022-02-02 06:55:50 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:55:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:01:48 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.937 | ppl 1960.65 | wps 7869.4 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 07:01:48 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 07:01:48 | INFO | train | epoch 009 | loss 10.937 | ppl 1960.9 | wps 5824.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.486 | train_wall 329 | gb_free 6.1 | wall 3229
KL Stats: Epoch 9 Divergences: Uniform: 1.5295236794831115 Unigram: 0.6431399847579647
2022-02-02 07:01:48 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 07:01:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:03:52 | INFO | train_inner | epoch 010:     24 / 64 loss=10.928, ppl=1948.1, wps=5705.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.484, train_wall=513, gb_free=6.1, wall=3354
2022-02-02 07:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:07:46 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.806 | ppl 1790.3 | wps 7881.6 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:07:46 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:07:46 | INFO | train | epoch 010 | loss 10.827 | ppl 1816.44 | wps 5829.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.492 | train_wall 329 | gb_free 6.1 | wall 3588
KL Stats: Epoch 10 Divergences: Uniform: 1.5460580880516008 Unigram: 0.756889783008015
2022-02-02 07:07:46 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:12:58 | INFO | train_inner | epoch 011:     60 / 64 loss=10.748, ppl=1720.02, wps=5996.1, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.491, train_wall=515, gb_free=6.1, wall=3899
2022-02-02 07:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:13:45 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.704 | ppl 1667.97 | wps 7796.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:13:45 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:13:45 | INFO | train | epoch 011 | loss 10.712 | ppl 1677.01 | wps 5824.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.48 | train_wall 329 | gb_free 6.1 | wall 3946
KL Stats: Epoch 11 Divergences: Uniform: 1.5638981259668132 Unigram: 0.8701910750896625
2022-02-02 07:13:45 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:19:44 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.604 | ppl 1555.93 | wps 7847.5 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:19:44 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:19:44 | INFO | train | epoch 012 | loss 10.594 | ppl 1546.01 | wps 5818.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.52 | train_wall 329 | gb_free 6.1 | wall 4305
KL Stats: Epoch 12 Divergences: Uniform: 1.579986524222112 Unigram: 0.9798989795442692
2022-02-02 07:19:44 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:22:30 | INFO | train_inner | epoch 013:     32 / 64 loss=10.571, ppl=1521.45, wps=5690, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.503, train_wall=514, gb_free=6.1, wall=4472
2022-02-02 07:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:25:43 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.51 | ppl 1458.42 | wps 7879.2 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:25:43 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:25:43 | INFO | train | epoch 013 | loss 10.477 | ppl 1425.37 | wps 5817.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.502 | train_wall 330 | gb_free 6.1 | wall 4664
KL Stats: Epoch 13 Divergences: Uniform: 1.599751137332603 Unigram: 1.0788878205083923
2022-02-02 07:25:43 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:25:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:31:42 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.404 | ppl 1355.01 | wps 7878.9 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:31:42 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:31:42 | INFO | train | epoch 014 | loss 10.363 | ppl 1317.28 | wps 5826.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.502 | train_wall 329 | gb_free 6.1 | wall 5023
KL Stats: Epoch 14 Divergences: Uniform: 1.6257054207857269 Unigram: 1.1676613747465097
2022-02-02 07:31:42 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:32:02 | INFO | train_inner | epoch 015:      4 / 64 loss=10.388, ppl=1339.6, wps=5700.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.51, train_wall=514, gb_free=6.1, wall=5044
2022-02-02 07:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:37:40 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.327 | ppl 1284.85 | wps 7861.5 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:37:40 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:37:40 | INFO | train | epoch 015 | loss 10.252 | ppl 1219.07 | wps 5828.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.528 | train_wall 329 | gb_free 6.1 | wall 5381
KL Stats: Epoch 15 Divergences: Uniform: 1.658927843616213 Unigram: 1.2466341810019028
2022-02-02 07:37:40 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:37:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:41:07 | INFO | train_inner | epoch 016:     40 / 64 loss=10.207, ppl=1182.14, wps=5995.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.512, train_wall=515, gb_free=6.1, wall=5589
2022-02-02 07:43:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:43:38 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.251 | ppl 1218.29 | wps 7862.9 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:43:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:43:38 | INFO | train | epoch 016 | loss 10.138 | ppl 1127.01 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.491 | train_wall 329 | gb_free 6.1 | wall 5740
KL Stats: Epoch 16 Divergences: Uniform: 1.6876163969450508 Unigram: 1.3305367185336137
2022-02-02 07:43:38 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:43:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:49:37 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.149 | ppl 1135.11 | wps 7874.6 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:49:37 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:49:37 | INFO | train | epoch 017 | loss 10.032 | ppl 1046.66 | wps 5817.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.545 | train_wall 330 | gb_free 6.1 | wall 6099
KL Stats: Epoch 17 Divergences: Uniform: 1.717703493023469 Unigram: 1.4021577500683224
2022-02-02 07:49:37 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:50:40 | INFO | train_inner | epoch 018:     12 / 64 loss=10.043, ppl=1054.91, wps=5696, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.539, train_wall=514, gb_free=6.1, wall=6161
2022-02-02 07:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:55:37 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.079 | ppl 1081.49 | wps 7852.8 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:55:37 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:55:37 | INFO | train | epoch 018 | loss 9.925 | ppl 972.33 | wps 5813.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.535 | train_wall 330 | gb_free 6.1 | wall 6458
KL Stats: Epoch 18 Divergences: Uniform: 1.7501451526807776 Unigram: 1.472507549136467
2022-02-02 07:55:37 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:59:46 | INFO | train_inner | epoch 019:     48 / 64 loss=9.88, ppl=942.07, wps=5977.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.517, train_wall=516, gb_free=6.1, wall=6708
2022-02-02 08:01:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:01:36 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.017 | ppl 1036.29 | wps 7867.6 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 08:01:36 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 08:01:36 | INFO | train | epoch 019 | loss 9.825 | ppl 906.99 | wps 5808.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.539 | train_wall 330 | gb_free 6.1 | wall 6817
KL Stats: Epoch 19 Divergences: Uniform: 1.7831323483336305 Unigram: 1.538639666819329
2022-02-02 08:01:36 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 08:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:07:36 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.942 | ppl 983.74 | wps 7833 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:07:36 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:07:36 | INFO | train | epoch 020 | loss 9.728 | ppl 847.78 | wps 5810.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.541 | train_wall 330 | gb_free 6.1 | wall 7177
KL Stats: Epoch 20 Divergences: Uniform: 1.810767223609589 Unigram: 1.6003022063217638
2022-02-02 08:07:36 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:09:20 | INFO | train_inner | epoch 021:     20 / 64 loss=9.721, ppl=844.19, wps=5686.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.561, train_wall=515, gb_free=6.1, wall=7281
2022-02-02 08:13:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:13:35 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.887 | ppl 946.79 | wps 7861.1 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:13:35 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:13:35 | INFO | train | epoch 021 | loss 9.638 | ppl 796.99 | wps 5816.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.577 | train_wall 330 | gb_free 6.1 | wall 7536
KL Stats: Epoch 21 Divergences: Uniform: 1.8392628628679555 Unigram: 1.6570216015715415
2022-02-02 08:13:35 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:18:25 | INFO | train_inner | epoch 022:     56 / 64 loss=9.588, ppl=769.75, wps=5988.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.557, train_wall=515, gb_free=6.1, wall=7827
2022-02-02 08:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:19:33 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.83 | ppl 909.97 | wps 7881.3 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:19:33 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:19:33 | INFO | train | epoch 022 | loss 9.549 | ppl 748.92 | wps 5822.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.54 | train_wall 329 | gb_free 6.1 | wall 7895
KL Stats: Epoch 22 Divergences: Uniform: 1.8692579975246695 Unigram: 1.7098254425177508
2022-02-02 08:19:33 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:25:32 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.753 | ppl 862.95 | wps 7853.2 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:25:32 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:25:32 | INFO | train | epoch 023 | loss 9.46 | ppl 704.31 | wps 5825.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.51 | train_wall 329 | gb_free 6.1 | wall 8253
KL Stats: Epoch 23 Divergences: Uniform: 1.8847960985558752 Unigram: 1.7639092869934272
2022-02-02 08:25:32 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:27:57 | INFO | train_inner | epoch 024:     28 / 64 loss=9.447, ppl=697.9, wps=5701.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.518, train_wall=514, gb_free=6.1, wall=8398
2022-02-02 08:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:31:30 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.729 | ppl 848.8 | wps 7845.8 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:31:30 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:31:30 | INFO | train | epoch 024 | loss 9.378 | ppl 665.26 | wps 5827.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.535 | train_wall 329 | gb_free 6.1 | wall 8612
KL Stats: Epoch 24 Divergences: Uniform: 1.9154612198968066 Unigram: 1.8146643333841417
2022-02-02 08:31:30 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:31:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:37:02 | INFO | train_inner | epoch 025:     64 / 64 loss=9.322, ppl=640.18, wps=5987.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.534, train_wall=514, gb_free=6.1, wall=8943
2022-02-02 08:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:37:29 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.706 | ppl 835.03 | wps 7843.4 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:37:29 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:37:29 | INFO | train | epoch 025 | loss 9.296 | ppl 628.76 | wps 5816.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.531 | train_wall 330 | gb_free 6.1 | wall 8971
KL Stats: Epoch 25 Divergences: Uniform: 1.9410459478854922 Unigram: 1.8618020901296914
2022-02-02 08:37:29 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:43:28 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.643 | ppl 799.71 | wps 7852.6 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:43:28 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:43:28 | INFO | train | epoch 026 | loss 9.214 | ppl 593.66 | wps 5818 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.53 | train_wall 330 | gb_free 6.1 | wall 9330
KL Stats: Epoch 26 Divergences: Uniform: 1.964514373092719 Unigram: 1.9033216901001166
2022-02-02 08:43:28 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:46:35 | INFO | train_inner | epoch 027:     36 / 64 loss=9.187, ppl=582.69, wps=5699, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.516, train_wall=515, gb_free=6.1, wall=9516
2022-02-02 08:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:49:27 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.609 | ppl 780.7 | wps 7835.4 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:49:27 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:49:27 | INFO | train | epoch 027 | loss 9.134 | ppl 561.65 | wps 5828.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.522 | train_wall 329 | gb_free 6.1 | wall 9688
KL Stats: Epoch 27 Divergences: Uniform: 1.985673853835687 Unigram: 1.949171240150902
2022-02-02 08:49:27 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:55:25 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.56 | ppl 754.58 | wps 7874.4 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:55:25 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:55:25 | INFO | train | epoch 028 | loss 9.057 | ppl 532.61 | wps 5824.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.53 | train_wall 329 | gb_free 6.1 | wall 10047
KL Stats: Epoch 28 Divergences: Uniform: 2.016281208989888 Unigram: 1.9875067384095917
2022-02-02 08:55:25 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:56:07 | INFO | train_inner | epoch 029:      8 / 64 loss=9.071, ppl=537.77, wps=5700.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.538, train_wall=514, gb_free=6.1, wall=10088
2022-02-02 09:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:01:24 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.547 | ppl 747.99 | wps 7813.4 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 09:01:24 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 09:01:24 | INFO | train | epoch 029 | loss 8.978 | ppl 504.32 | wps 5816.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.518 | train_wall 329 | gb_free 6.1 | wall 10406
KL Stats: Epoch 29 Divergences: Uniform: 2.0385744168501243 Unigram: 2.0268782427508834
2022-02-02 09:01:25 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 09:01:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:05:13 | INFO | train_inner | epoch 030:     44 / 64 loss=8.945, ppl=492.78, wps=5981.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.524, train_wall=516, gb_free=6.1, wall=10635
2022-02-02 09:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:07:24 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.497 | ppl 722.51 | wps 7867.7 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 09:07:24 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 09:07:24 | INFO | train | epoch 030 | loss 8.901 | ppl 478.04 | wps 5813.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.523 | train_wall 330 | gb_free 6.1 | wall 10765
KL Stats: Epoch 30 Divergences: Uniform: 2.0513958403972112 Unigram: 2.061674464293919
2022-02-02 09:07:24 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 09:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:13:22 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.454 | ppl 701.53 | wps 7857.4 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:13:22 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:13:22 | INFO | train | epoch 031 | loss 8.826 | ppl 453.78 | wps 5822.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.52 | train_wall 329 | gb_free 6.1 | wall 11124
KL Stats: Epoch 31 Divergences: Uniform: 2.0725912973714626 Unigram: 2.100885598224584
2022-02-02 09:13:22 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:14:46 | INFO | train_inner | epoch 032:     16 / 64 loss=8.829, ppl=454.65, wps=5694.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.514, train_wall=514, gb_free=6.1, wall=11207
2022-02-02 09:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:19:22 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.446 | ppl 697.28 | wps 7863.1 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:19:22 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:19:22 | INFO | train | epoch 032 | loss 8.75 | ppl 430.52 | wps 5812.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.514 | train_wall 330 | gb_free 6.1 | wall 11483
KL Stats: Epoch 32 Divergences: Uniform: 2.096563154255291 Unigram: 2.141343765030212
2022-02-02 09:19:22 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:23:52 | INFO | train_inner | epoch 033:     52 / 64 loss=8.708, ppl=418.13, wps=5983.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.508, train_wall=516, gb_free=6.1, wall=11753
2022-02-02 09:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:25:21 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.409 | ppl 679.83 | wps 7859.9 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:25:21 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:25:21 | INFO | train | epoch 033 | loss 8.676 | ppl 408.9 | wps 5821.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.499 | train_wall 329 | gb_free 6.1 | wall 11842
KL Stats: Epoch 33 Divergences: Uniform: 2.116781993278439 Unigram: 2.175125512450312
2022-02-02 09:25:21 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:31:19 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.4 | ppl 675.36 | wps 7885.6 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:31:19 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:31:19 | INFO | train | epoch 034 | loss 8.601 | ppl 388.41 | wps 5826.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.511 | train_wall 329 | gb_free 6.1 | wall 12200
KL Stats: Epoch 34 Divergences: Uniform: 2.1418780394781445 Unigram: 2.2128370067462675
2022-02-02 09:31:19 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:33:24 | INFO | train_inner | epoch 035:     24 / 64 loss=8.59, ppl=385.22, wps=5701.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.508, train_wall=514, gb_free=6.1, wall=12325
2022-02-02 09:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:37:18 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.354 | ppl 654.26 | wps 7875.9 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:37:18 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:37:18 | INFO | train | epoch 035 | loss 8.527 | ppl 368.99 | wps 5821.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.505 | train_wall 329 | gb_free 6.1 | wall 12559
KL Stats: Epoch 35 Divergences: Uniform: 2.16018672958777 Unigram: 2.2441587565583334
2022-02-02 09:37:18 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:42:30 | INFO | train_inner | epoch 036:     60 / 64 loss=8.49, ppl=359.65, wps=5987.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.5, train_wall=516, gb_free=6.1, wall=12871
2022-02-02 09:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:43:17 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.334 | ppl 645.34 | wps 7882.5 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:43:17 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:43:17 | INFO | train | epoch 036 | loss 8.457 | ppl 351.5 | wps 5822 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.494 | train_wall 329 | gb_free 6.1 | wall 12918
KL Stats: Epoch 36 Divergences: Uniform: 2.1841496013822526 Unigram: 2.282860183313694
2022-02-02 09:43:17 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:49:15 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.309 | ppl 634.44 | wps 7879.6 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:49:15 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:49:15 | INFO | train | epoch 037 | loss 8.387 | ppl 334.73 | wps 5830.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.5 | train_wall 329 | gb_free 6.1 | wall 13276
KL Stats: Epoch 37 Divergences: Uniform: 2.200581163181181 Unigram: 2.310812539330494
2022-02-02 09:49:15 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:52:01 | INFO | train_inner | epoch 038:     32 / 64 loss=8.364, ppl=329.44, wps=5706.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.498, train_wall=513, gb_free=6.1, wall=13442
2022-02-02 09:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:55:13 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.301 | ppl 630.69 | wps 7856.9 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:55:13 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:55:13 | INFO | train | epoch 038 | loss 8.319 | ppl 319.26 | wps 5824.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.513 | train_wall 329 | gb_free 6.1 | wall 13635
KL Stats: Epoch 38 Divergences: Uniform: 2.231137509881471 Unigram: 2.346402894006112
2022-02-02 09:55:13 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:01:11 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.288 | ppl 624.96 | wps 7865.4 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 10:01:11 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 10:01:11 | INFO | train | epoch 039 | loss 8.249 | ppl 304.3 | wps 5834.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.489 | train_wall 329 | gb_free 6.1 | wall 13993
KL Stats: Epoch 39 Divergences: Uniform: 2.248762086609232 Unigram: 2.3825014591005393
2022-02-02 10:01:11 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 10:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:01:32 | INFO | train_inner | epoch 040:      4 / 64 loss=8.272, ppl=309.03, wps=5704.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.502, train_wall=513, gb_free=6.1, wall=14013
2022-02-02 10:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:07:09 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.304 | ppl 631.89 | wps 7846.7 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 10:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 10:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint40.pt
2022-02-02 10:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint40.pt
2022-02-02 10:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.304) (writing took 4.768395206891 seconds)
2022-02-02 10:07:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 10:07:14 | INFO | train | epoch 040 | loss 8.181 | ppl 290.14 | wps 5757.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.486 | train_wall 328 | gb_free 6.1 | wall 14355
KL Stats: Epoch 40 Divergences: Uniform: 2.2700072996255507 Unigram: 2.41565082764234
2022-02-02 10:07:14 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 10:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:10:41 | INFO | train_inner | epoch 041:     40 / 64 loss=8.156, ppl=285.2, wps=5953.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.491, train_wall=514, gb_free=6.1, wall=14562
2022-02-02 10:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:13:12 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.264 | ppl 614.99 | wps 7865 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.264
2022-02-02 10:13:12 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:13:12 | INFO | train | epoch 041 | loss 8.117 | ppl 277.65 | wps 5839.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.508 | train_wall 328 | gb_free 6.1 | wall 14713
KL Stats: Epoch 41 Divergences: Uniform: 2.2860789841881766 Unigram: 2.441657578209692
2022-02-02 10:13:12 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:18:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:19:10 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.291 | ppl 626.57 | wps 7885.7 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.291
2022-02-02 10:19:10 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:19:10 | INFO | train | epoch 042 | loss 8.051 | ppl 265.21 | wps 5823.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.489 | train_wall 329 | gb_free 6.1 | wall 15072
KL Stats: Epoch 42 Divergences: Uniform: 2.3078399265389202 Unigram: 2.477612528439051
2022-02-02 10:19:11 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:20:13 | INFO | train_inner | epoch 043:     12 / 64 loss=8.057, ppl=266.28, wps=5703, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.495, train_wall=514, gb_free=6.1, wall=15134
2022-02-02 10:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:25:09 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.264 | ppl 614.99 | wps 7879.1 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.264
2022-02-02 10:25:09 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:25:09 | INFO | train | epoch 043 | loss 7.989 | ppl 254.04 | wps 5827.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.493 | train_wall 329 | gb_free 6.1 | wall 15430
KL Stats: Epoch 43 Divergences: Uniform: 2.32825190016708 Unigram: 2.5039405977255074
2022-02-02 10:25:09 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:29:18 | INFO | train_inner | epoch 044:     48 / 64 loss=7.957, ppl=248.54, wps=5994.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.497, train_wall=515, gb_free=6.1, wall=15679
2022-02-02 10:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:31:07 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.23 | ppl 600.57 | wps 7868 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.23
2022-02-02 10:31:07 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:31:07 | INFO | train | epoch 044 | loss 7.927 | ppl 243.42 | wps 5826.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.506 | train_wall 329 | gb_free 6.1 | wall 15789
KL Stats: Epoch 44 Divergences: Uniform: 2.3363716182209258 Unigram: 2.5324153605959334
2022-02-02 10:31:07 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:37:06 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.266 | ppl 615.53 | wps 7858.1 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.266
2022-02-02 10:37:06 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:37:06 | INFO | train | epoch 045 | loss 7.866 | ppl 233.27 | wps 5823.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.493 | train_wall 329 | gb_free 6.1 | wall 16147
KL Stats: Epoch 45 Divergences: Uniform: 2.360351909386863 Unigram: 2.5658330046437445
2022-02-02 10:37:06 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:38:50 | INFO | train_inner | epoch 046:     20 / 64 loss=7.862, ppl=232.65, wps=5700.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.501, train_wall=514, gb_free=6.1, wall=16251
2022-02-02 10:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:43:04 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.263 | ppl 614.44 | wps 7864.6 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.263
2022-02-02 10:43:04 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:43:04 | INFO | train | epoch 046 | loss 7.806 | ppl 223.81 | wps 5833.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.493 | train_wall 329 | gb_free 6.1 | wall 16505
KL Stats: Epoch 46 Divergences: Uniform: 2.3763885498046875 Unigram: 2.590250836866356
2022-02-02 10:43:04 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:47:55 | INFO | train_inner | epoch 047:     56 / 64 loss=7.777, ppl=219.37, wps=5999.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.498, train_wall=514, gb_free=6.1, wall=16796
2022-02-02 10:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:49:02 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.279 | ppl 621.33 | wps 7885.1 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.279
2022-02-02 10:49:02 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:49:02 | INFO | train | epoch 047 | loss 7.75 | ppl 215.25 | wps 5829.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.503 | train_wall 329 | gb_free 6.1 | wall 16864
KL Stats: Epoch 47 Divergences: Uniform: 2.3979670699839586 Unigram: 2.620979196275016
2022-02-02 10:49:02 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:55:00 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.286 | ppl 624.1 | wps 7897.7 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.286
2022-02-02 10:55:00 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:55:00 | INFO | train | epoch 048 | loss 7.693 | ppl 206.89 | wps 5840.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.508 | train_wall 328 | gb_free 6.1 | wall 17221
KL Stats: Epoch 48 Divergences: Uniform: 2.411298159223845 Unigram: 2.641004359198315
2022-02-02 10:55:00 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:57:25 | INFO | train_inner | epoch 049:     28 / 64 loss=7.677, ppl=204.67, wps=5710.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.511, train_wall=513, gb_free=6.1, wall=17367
2022-02-02 11:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:00:59 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.295 | ppl 628.03 | wps 7867.5 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.295
2022-02-02 11:00:59 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 11:00:59 | INFO | train | epoch 049 | loss 7.636 | ppl 198.86 | wps 5824.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.51 | train_wall 329 | gb_free 6.1 | wall 17580
KL Stats: Epoch 49 Divergences: Uniform: 2.431771819347072 Unigram: 2.662545152309467
2022-02-02 11:00:59 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 11:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:06:28 | INFO | train_inner | epoch 050:     64 / 64 loss=7.608, ppl=195.08, wps=6003.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.509, train_wall=513, gb_free=6.1, wall=17910
2022-02-02 11:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 11:06:56 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.327 | ppl 642.2 | wps 7887.7 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.304
2022-02-02 11:06:56 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 11:06:56 | INFO | train | epoch 050 | loss 7.582 | ppl 191.6 | wps 5841.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.511 | train_wall 328 | gb_free 6.1 | wall 17937
KL Stats: Epoch 50 Divergences: Uniform: 2.4455385400727225 Unigram: 2.6923034987976644
2022-02-02 11:06:56 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 11:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:12:55 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.305 | ppl 632.45 | wps 7874.5 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.304
2022-02-02 11:12:55 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 11:12:55 | INFO | train | epoch 051 | loss 7.527 | ppl 184.47 | wps 5824.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.511 | train_wall 329 | gb_free 6.1 | wall 18296
KL Stats: Epoch 51 Divergences: Uniform: 2.459396011819852 Unigram: 2.715996659706817
2022-02-02 11:12:55 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 11:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:16:01 | INFO | train_inner | epoch 052:     36 / 64 loss=7.499, ppl=180.95, wps=5705.6, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.513, train_wall=515, gb_free=6.1, wall=18482
2022-02-02 11:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:18:53 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.308 | ppl 634.01 | wps 7871.1 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.304
2022-02-02 11:18:53 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:18:53 | INFO | train | epoch 052 | loss 7.475 | ppl 177.91 | wps 5832 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.516 | train_wall 329 | gb_free 6.1 | wall 18654
KL Stats: Epoch 52 Divergences: Uniform: 2.46826181811753 Unigram: 2.737437270770219
2022-02-02 11:18:53 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:24:51 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.312 | ppl 635.74 | wps 7848.7 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.304
2022-02-02 11:24:51 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:24:51 | INFO | train | epoch 053 | loss 7.423 | ppl 171.66 | wps 5823.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.519 | train_wall 329 | gb_free 6.1 | wall 19013
KL Stats: Epoch 53 Divergences: Uniform: 2.4888423012988703 Unigram: 2.7627490405977118
2022-02-02 11:24:51 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:25:33 | INFO | train_inner | epoch 054:      8 / 64 loss=7.442, ppl=173.84, wps=5700.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.517, train_wall=514, gb_free=6.1, wall=19054
2022-02-02 11:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:30:49 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.418 | ppl 684.08 | wps 7874.8 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.304
2022-02-02 11:30:49 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:30:49 | INFO | train | epoch 054 | loss 7.375 | ppl 166.02 | wps 5836.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.518 | train_wall 328 | gb_free 6.1 | wall 19371
KL Stats: Epoch 54 Divergences: Uniform: 2.498979971454348 Unigram: 2.774807212726307
2022-02-02 11:30:49 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:34:37 | INFO | train_inner | epoch 055:     44 / 64 loss=7.351, ppl=163.26, wps=6003.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.513, train_wall=514, gb_free=6.1, wall=19599
2022-02-02 11:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:36:47 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.342 | ppl 648.81 | wps 7904.4 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.304
2022-02-02 11:36:47 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:36:47 | INFO | train | epoch 055 | loss 7.322 | ppl 160.05 | wps 5832 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.505 | train_wall 329 | gb_free 6.1 | wall 19729
KL Stats: Epoch 55 Divergences: Uniform: 2.5144890166366043 Unigram: 2.8124795331459707
2022-02-02 11:36:47 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:36:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:42:45 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.395 | ppl 673.17 | wps 7874.9 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.304
2022-02-02 11:42:45 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:42:45 | INFO | train | epoch 056 | loss 7.276 | ppl 154.93 | wps 5836.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.526 | train_wall 328 | gb_free 6.1 | wall 20087
KL Stats: Epoch 56 Divergences: Uniform: 2.5326092572303227 Unigram: 2.8311464874362393
2022-02-02 11:42:45 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:44:08 | INFO | train_inner | epoch 057:     16 / 64 loss=7.275, ppl=154.87, wps=5709.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.523, train_wall=513, gb_free=6.1, wall=20170
2022-02-02 11:48:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:48:44 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.418 | ppl 684.3 | wps 7874.6 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.304
2022-02-02 11:48:44 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:48:44 | INFO | train | epoch 057 | loss 7.229 | ppl 150.06 | wps 5824 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.524 | train_wall 329 | gb_free 6.1 | wall 20445
KL Stats: Epoch 57 Divergences: Uniform: 2.5391691669696073 Unigram: 2.858388738318967
2022-02-02 11:48:44 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:53:14 | INFO | train_inner | epoch 058:     52 / 64 loss=7.203, ppl=147.33, wps=5995, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.522, train_wall=515, gb_free=6.1, wall=20715
2022-02-02 11:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:54:42 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.432 | ppl 690.83 | wps 7882.1 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.304
2022-02-02 11:54:42 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:54:42 | INFO | train | epoch 058 | loss 7.181 | ppl 145.11 | wps 5830.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.521 | train_wall 329 | gb_free 6.1 | wall 20803
KL Stats: Epoch 58 Divergences: Uniform: 2.5526896687121163 Unigram: 2.872005787310577
2022-02-02 11:54:42 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:54:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:00:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:00:40 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.431 | ppl 690.16 | wps 7896.6 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.304
2022-02-02 12:00:40 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 12:00:40 | INFO | train | epoch 059 | loss 7.136 | ppl 140.7 | wps 5827.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.53 | train_wall 329 | gb_free 6.1 | wall 21162
KL Stats: Epoch 59 Divergences: Uniform: 2.5648641273068473 Unigram: 2.8994396553005686
2022-02-02 12:00:40 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 12:00:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:02:45 | INFO | train_inner | epoch 060:     24 / 64 loss=7.131, ppl=140.2, wps=5704.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.532, train_wall=513, gb_free=6.1, wall=21286
2022-02-02 12:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:06:39 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.369 | ppl 661.03 | wps 7874.5 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.304
2022-02-02 12:06:39 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 12:06:39 | INFO | train | epoch 060 | loss 7.096 | ppl 136.77 | wps 5833.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.541 | train_wall 329 | gb_free 6.1 | wall 21520
KL Stats: Epoch 60 Divergences: Uniform: 2.580182966739402 Unigram: 2.9201355463020335
2022-02-02 12:06:39 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 12:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:11:49 | INFO | train_inner | epoch 061:     60 / 64 loss=7.074, ppl=134.72, wps=6004, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.543, train_wall=514, gb_free=6.1, wall=21831
2022-02-02 12:12:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:12:36 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.447 | ppl 698.02 | wps 7898.5 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.304
2022-02-02 12:12:36 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 12:12:36 | INFO | train | epoch 061 | loss 7.052 | ppl 132.67 | wps 5838.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.547 | train_wall 328 | gb_free 6.1 | wall 21878
KL Stats: Epoch 61 Divergences: Uniform: 2.591511855483108 Unigram: 2.9391679291824633
2022-02-02 12:12:36 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 12:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:18:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:18:35 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.4 | ppl 675.74 | wps 7874.4 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.304
2022-02-02 12:18:35 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:18:35 | INFO | train | epoch 062 | loss 7.008 | ppl 128.69 | wps 5827.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.538 | train_wall 329 | gb_free 6.1 | wall 22236
KL Stats: Epoch 62 Divergences: Uniform: 2.609786451418454 Unigram: 2.9642937632068445
2022-02-02 12:18:35 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:21:20 | INFO | train_inner | epoch 063:     32 / 64 loss=6.983, ppl=126.46, wps=5707.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.542, train_wall=513, gb_free=6.1, wall=22402
2022-02-02 12:24:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:24:33 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.504 | ppl 726.09 | wps 7869.3 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.304
2022-02-02 12:24:33 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:24:33 | INFO | train | epoch 063 | loss 6.967 | ppl 125.13 | wps 5834.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.541 | train_wall 329 | gb_free 6.1 | wall 22594
KL Stats: Epoch 63 Divergences: Uniform: 2.6217560632674366 Unigram: 2.9695965034190253
2022-02-02 12:24:33 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:24:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:30:31 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.448 | ppl 698.29 | wps 7898.3 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.304
2022-02-02 12:30:31 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:30:31 | INFO | train | epoch 064 | loss 6.926 | ppl 121.61 | wps 5835.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.55 | train_wall 329 | gb_free 6.1 | wall 22952
KL Stats: Epoch 64 Divergences: Uniform: 2.6376702524109836 Unigram: 2.9975216678656635
2022-02-02 12:30:31 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:30:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:30:51 | INFO | train_inner | epoch 065:      4 / 64 loss=6.951, ppl=123.72, wps=5710.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.547, train_wall=513, gb_free=6.1, wall=22973
2022-02-02 12:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:36:28 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.479 | ppl 713.38 | wps 7888.1 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.304
2022-02-02 12:36:28 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:36:28 | INFO | train | epoch 065 | loss 6.879 | ppl 117.7 | wps 5842 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.545 | train_wall 328 | gb_free 6.1 | wall 23309
KL Stats: Epoch 65 Divergences: Uniform: 2.649416949766983 Unigram: 3.025070076141154
2022-02-02 12:36:28 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:39:55 | INFO | train_inner | epoch 066:     40 / 64 loss=6.857, ppl=115.96, wps=6007.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.546, train_wall=514, gb_free=6.1, wall=23517
2022-02-02 12:41:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 12:42:26 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.482 | ppl 715.03 | wps 7899.8 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.304
2022-02-02 12:42:26 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:42:26 | INFO | train | epoch 066 | loss 6.84 | ppl 114.6 | wps 5838.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.555 | train_wall 328 | gb_free 6.1 | wall 23667
KL Stats: Epoch 66 Divergences: Uniform: 2.6605794968416676 Unigram: 3.0463309566338643
2022-02-02 12:42:26 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:47:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:48:24 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.553 | ppl 751.22 | wps 7856.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.304
2022-02-02 12:48:24 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:48:24 | INFO | train | epoch 067 | loss 6.798 | ppl 111.26 | wps 5832.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.543 | train_wall 329 | gb_free 6.1 | wall 24025
KL Stats: Epoch 67 Divergences: Uniform: 2.6672881251697906 Unigram: 3.0655741836566475
2022-02-02 12:48:24 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:48:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:49:26 | INFO | train_inner | epoch 068:     12 / 64 loss=6.805, ppl=111.8, wps=5710.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.547, train_wall=513, gb_free=6.1, wall=24087
2022-02-02 12:53:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:54:22 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.523 | ppl 735.74 | wps 7892.8 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.304
2022-02-02 12:54:22 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:54:22 | INFO | train | epoch 068 | loss 6.759 | ppl 108.28 | wps 5836.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.551 | train_wall 329 | gb_free 6.1 | wall 24383
KL Stats: Epoch 68 Divergences: Uniform: 2.6870570773291047 Unigram: 3.085725453499948
2022-02-02 12:54:22 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:58:31 | INFO | train_inner | epoch 069:     48 / 64 loss=6.741, ppl=106.98, wps=6001.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.559, train_wall=514, gb_free=6.1, wall=24632
2022-02-02 12:59:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:00:20 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.56 | ppl 754.79 | wps 7889.6 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.304
2022-02-02 13:00:20 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 13:00:20 | INFO | train | epoch 069 | loss 6.723 | ppl 105.61 | wps 5835.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.563 | train_wall 329 | gb_free 6.1 | wall 24741
KL Stats: Epoch 69 Divergences: Uniform: 2.6951488110948234 Unigram: 3.106675782099968
2022-02-02 13:00:20 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 13:00:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:06:17 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.549 | ppl 749.11 | wps 7898.9 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.304
2022-02-02 13:06:17 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 13:06:17 | INFO | train | epoch 070 | loss 6.686 | ppl 102.99 | wps 5843.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.564 | train_wall 328 | gb_free 6.1 | wall 25098
KL Stats: Epoch 70 Divergences: Uniform: 2.7058103701510645 Unigram: 3.1301378247159035
2022-02-02 13:06:17 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 13:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:08:01 | INFO | train_inner | epoch 071:     20 / 64 loss=6.684, ppl=102.8, wps=5720.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.567, train_wall=512, gb_free=6.1, wall=25202
2022-02-02 13:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:12:15 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.604 | ppl 778.16 | wps 7870.8 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.304
2022-02-02 13:12:15 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 13:12:15 | INFO | train | epoch 071 | loss 6.652 | ppl 100.58 | wps 5840.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.58 | train_wall 328 | gb_free 6.1 | wall 25456
KL Stats: Epoch 71 Divergences: Uniform: 2.713609515959244 Unigram: 3.144595650741909
2022-02-02 13:12:15 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 13:12:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:17:05 | INFO | train_inner | epoch 072:     56 / 64 loss=6.634, ppl=99.33, wps=6003.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.57, train_wall=514, gb_free=6.1, wall=25746
2022-02-02 13:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:18:13 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.598 | ppl 775.02 | wps 7873.6 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.304
2022-02-02 13:18:13 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 13:18:13 | INFO | train | epoch 072 | loss 6.618 | ppl 98.19 | wps 5834.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.563 | train_wall 329 | gb_free 6.1 | wall 25814
KL Stats: Epoch 72 Divergences: Uniform: 2.7192866579987873 Unigram: 3.1617722476370007
2022-02-02 13:18:13 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 13:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:24:11 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.507 | ppl 727.5 | wps 7893.9 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.304
2022-02-02 13:24:11 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:24:11 | INFO | train | epoch 073 | loss 6.583 | ppl 95.88 | wps 5829.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.576 | train_wall 329 | gb_free 6.1 | wall 26172
KL Stats: Epoch 73 Divergences: Uniform: 2.73648612350027 Unigram: 3.1835649253736853
2022-02-02 13:24:11 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:26:36 | INFO | train_inner | epoch 074:     28 / 64 loss=6.573, ppl=95.2, wps=5705.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.572, train_wall=513, gb_free=6.1, wall=26318
2022-02-02 13:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:30:10 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.595 | ppl 773.56 | wps 7867.4 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.304
2022-02-02 13:30:10 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:30:10 | INFO | train | epoch 074 | loss 6.551 | ppl 93.78 | wps 5825 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.576 | train_wall 329 | gb_free 6.1 | wall 26531
KL Stats: Epoch 74 Divergences: Uniform: 2.750198658021672 Unigram: 3.199281904573606
2022-02-02 13:30:10 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:35:40 | INFO | train_inner | epoch 075:     64 / 64 loss=6.542, ppl=93.21, wps=5992.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.586, train_wall=514, gb_free=6.1, wall=26862
2022-02-02 13:35:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:36:08 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.632 | ppl 793.52 | wps 7870 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.304
2022-02-02 13:36:08 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:36:08 | INFO | train | epoch 075 | loss 6.521 | ppl 91.82 | wps 5827.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.587 | train_wall 329 | gb_free 6.1 | wall 26889
KL Stats: Epoch 75 Divergences: Uniform: 2.7449420933399633 Unigram: 3.2228583452493096
2022-02-02 13:36:08 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:42:07 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.626 | ppl 790.18 | wps 7831.5 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.304
2022-02-02 13:42:07 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:42:07 | INFO | train | epoch 076 | loss 6.488 | ppl 89.78 | wps 5818.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.575 | train_wall 329 | gb_free 6.1 | wall 27248
KL Stats: Epoch 76 Divergences: Uniform: 2.76735151888157 Unigram: 3.238489379578043
2022-02-02 13:42:07 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:45:14 | INFO | train_inner | epoch 077:     36 / 64 loss=6.468, ppl=88.52, wps=5699.3, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.576, train_wall=515, gb_free=6.1, wall=27435
2022-02-02 13:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:48:05 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.54 | ppl 744.37 | wps 7846.9 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.304
2022-02-02 13:48:05 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:48:05 | INFO | train | epoch 077 | loss 6.458 | ppl 87.94 | wps 5826.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.578 | train_wall 329 | gb_free 6.1 | wall 27607
KL Stats: Epoch 77 Divergences: Uniform: 2.78054758235713 Unigram: 3.2539509150170245
2022-02-02 13:48:05 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:48:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:54:04 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.631 | ppl 792.84 | wps 7851.2 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.304
2022-02-02 13:54:04 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:54:04 | INFO | train | epoch 078 | loss 6.431 | ppl 86.31 | wps 5821.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.602 | train_wall 329 | gb_free 6.1 | wall 27965
KL Stats: Epoch 78 Divergences: Uniform: 2.7820208933001034 Unigram: 3.274805732054865
2022-02-02 13:54:04 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:54:46 | INFO | train_inner | epoch 079:      8 / 64 loss=6.441, ppl=86.89, wps=5698, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.594, train_wall=514, gb_free=6.1, wall=28007
2022-02-02 13:59:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:00:03 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.675 | ppl 817.35 | wps 7879.6 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.304
2022-02-02 14:00:03 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 14:00:03 | INFO | train | epoch 079 | loss 6.401 | ppl 84.49 | wps 5818.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.579 | train_wall 330 | gb_free 6.1 | wall 28324
KL Stats: Epoch 79 Divergences: Uniform: 2.787524851702924 Unigram: 3.2890802423423837
2022-02-02 14:00:03 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 14:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:03:52 | INFO | train_inner | epoch 080:     44 / 64 loss=6.384, ppl=83.51, wps=5984.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.586, train_wall=516, gb_free=6.1, wall=28553
2022-02-02 14:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:06:02 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.655 | ppl 806.08 | wps 7846.9 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.304
2022-02-02 14:06:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 14:06:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint80.pt
2022-02-02 14:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint80.pt
2022-02-02 14:06:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.655) (writing took 3.0700171878561378 seconds)
2022-02-02 14:06:05 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 14:06:05 | INFO | train | epoch 080 | loss 6.377 | ppl 83.09 | wps 5768.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.605 | train_wall 330 | gb_free 6.1 | wall 28687
KL Stats: Epoch 80 Divergences: Uniform: 2.796997312963988 Unigram: 3.3074559229932463
2022-02-02 14:06:05 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 14:06:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:12:04 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.676 | ppl 818.19 | wps 7844.8 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.304
2022-02-02 14:12:04 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 14:12:04 | INFO | train | epoch 081 | loss 6.351 | ppl 81.62 | wps 5818.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.615 | train_wall 329 | gb_free 6.1 | wall 29045
KL Stats: Epoch 81 Divergences: Uniform: 2.802174795695109 Unigram: 3.3233481429176654
2022-02-02 14:12:04 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 14:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:13:27 | INFO | train_inner | epoch 082:     16 / 64 loss=6.356, ppl=81.89, wps=5664.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.612, train_wall=514, gb_free=6.1, wall=29129
2022-02-02 14:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:18:03 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.709 | ppl 837 | wps 7852.5 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.304
2022-02-02 14:18:03 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 14:18:03 | INFO | train | epoch 082 | loss 6.323 | ppl 80.07 | wps 5820.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.606 | train_wall 329 | gb_free 6.1 | wall 29404
KL Stats: Epoch 82 Divergences: Uniform: 2.8096434539866033 Unigram: 3.3420063166738987
2022-02-02 14:18:03 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 14:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:22:33 | INFO | train_inner | epoch 083:     52 / 64 loss=6.312, ppl=79.47, wps=5989.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.612, train_wall=515, gb_free=6.1, wall=29674
2022-02-02 14:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:24:02 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.748 | ppl 859.76 | wps 7876.9 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.304
2022-02-02 14:24:02 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:24:02 | INFO | train | epoch 083 | loss 6.298 | ppl 78.69 | wps 5821.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.616 | train_wall 329 | gb_free 6.1 | wall 29763
KL Stats: Epoch 83 Divergences: Uniform: 2.8177326537215652 Unigram: 3.352316919137148
2022-02-02 14:24:02 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:29:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:30:00 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.761 | ppl 867.85 | wps 7879.9 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.304
2022-02-02 14:30:00 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:30:00 | INFO | train | epoch 084 | loss 6.273 | ppl 77.34 | wps 5825 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.621 | train_wall 329 | gb_free 6.1 | wall 30122
KL Stats: Epoch 84 Divergences: Uniform: 2.8267242084118824 Unigram: 3.374661650913745
2022-02-02 14:30:00 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:32:05 | INFO | train_inner | epoch 085:     24 / 64 loss=6.267, ppl=77.03, wps=5700.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.625, train_wall=514, gb_free=6.1, wall=30246
2022-02-02 14:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:35:59 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.774 | ppl 875.67 | wps 7891.4 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.304
2022-02-02 14:35:59 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:35:59 | INFO | train | epoch 085 | loss 6.25 | ppl 76.12 | wps 5822.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.632 | train_wall 329 | gb_free 6.1 | wall 30480
KL Stats: Epoch 85 Divergences: Uniform: 2.8327165161087096 Unigram: 3.381797820580995
2022-02-02 14:35:59 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:41:11 | INFO | train_inner | epoch 086:     60 / 64 loss=6.242, ppl=75.7, wps=5989.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.628, train_wall=515, gb_free=6.1, wall=30792
2022-02-02 14:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:41:58 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.762 | ppl 868.4 | wps 7846.6 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.304
2022-02-02 14:41:58 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:41:58 | INFO | train | epoch 086 | loss 6.226 | ppl 74.86 | wps 5822 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.624 | train_wall 329 | gb_free 6.1 | wall 30839
KL Stats: Epoch 86 Divergences: Uniform: 2.8384303816995566 Unigram: 3.403482693859698
2022-02-02 14:41:58 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:47:56 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.796 | ppl 888.85 | wps 7884.5 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.304
2022-02-02 14:47:56 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:47:56 | INFO | train | epoch 087 | loss 6.204 | ppl 73.72 | wps 5830.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.643 | train_wall 329 | gb_free 6.1 | wall 31197
KL Stats: Epoch 87 Divergences: Uniform: 2.8406522827470138 Unigram: 3.4255483767428614
2022-02-02 14:47:56 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:50:42 | INFO | train_inner | epoch 088:     32 / 64 loss=6.19, ppl=73, wps=5703.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.644, train_wall=514, gb_free=6.1, wall=31363
2022-02-02 14:53:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:53:55 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.778 | ppl 877.78 | wps 7855.3 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.304
2022-02-02 14:53:55 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:53:55 | INFO | train | epoch 088 | loss 6.181 | ppl 72.57 | wps 5818.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.645 | train_wall 330 | gb_free 6.1 | wall 31556
KL Stats: Epoch 88 Divergences: Uniform: 2.8538170277781343 Unigram: 3.434439085136241
2022-02-02 14:53:55 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:59:54 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.795 | ppl 888.31 | wps 7900.8 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.304
2022-02-02 14:59:54 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:59:54 | INFO | train | epoch 089 | loss 6.158 | ppl 71.43 | wps 5821.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.652 | train_wall 330 | gb_free 6.1 | wall 31915
KL Stats: Epoch 89 Divergences: Uniform: 2.8585669559422886 Unigram: 3.4424375827398186
2022-02-02 14:59:54 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:59:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:00:15 | INFO | train_inner | epoch 090:      4 / 64 loss=6.171, ppl=72.07, wps=5693.5, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.649, train_wall=514, gb_free=6.1, wall=31936
2022-02-02 15:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:05:52 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.769 | ppl 872.42 | wps 7870.3 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.304
2022-02-02 15:05:52 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 15:05:52 | INFO | train | epoch 090 | loss 6.139 | ppl 70.46 | wps 5834 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.653 | train_wall 329 | gb_free 6.1 | wall 32273
KL Stats: Epoch 90 Divergences: Uniform: 2.86486539574025 Unigram: 3.458737384780904
2022-02-02 15:05:52 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 15:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:09:19 | INFO | train_inner | epoch 091:     40 / 64 loss=6.124, ppl=69.77, wps=6004.1, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.648, train_wall=514, gb_free=6.1, wall=32480
2022-02-02 15:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:11:50 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.824 | ppl 906.35 | wps 7854.5 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.304
2022-02-02 15:11:50 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 15:11:50 | INFO | train | epoch 091 | loss 6.118 | ppl 69.44 | wps 5831.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.659 | train_wall 329 | gb_free 6.1 | wall 32631
KL Stats: Epoch 91 Divergences: Uniform: 2.8688706526267387 Unigram: 3.4769193896493857
2022-02-02 15:11:50 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 15:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:17:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:17:48 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.882 | ppl 943.42 | wps 7890.9 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.304
2022-02-02 15:17:48 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 15:17:48 | INFO | train | epoch 092 | loss 6.098 | ppl 68.5 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.667 | train_wall 329 | gb_free 6.1 | wall 32990
KL Stats: Epoch 92 Divergences: Uniform: 2.8685173268747817 Unigram: 3.48748480178386
2022-02-02 15:17:48 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 15:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:18:51 | INFO | train_inner | epoch 093:     12 / 64 loss=6.104, ppl=68.79, wps=5702.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.672, train_wall=514, gb_free=6.1, wall=33052
2022-02-02 15:23:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:23:46 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.804 | ppl 894.17 | wps 7868.9 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.304
2022-02-02 15:23:46 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 15:23:46 | INFO | train | epoch 093 | loss 6.078 | ppl 67.54 | wps 5840.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.672 | train_wall 328 | gb_free 6.1 | wall 33347
KL Stats: Epoch 93 Divergences: Uniform: 2.877378008284148 Unigram: 3.5083059202127336
2022-02-02 15:23:46 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 15:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:27:55 | INFO | train_inner | epoch 094:     48 / 64 loss=6.065, ppl=66.94, wps=6001.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.668, train_wall=514, gb_free=6.1, wall=33596
2022-02-02 15:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:29:45 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.828 | ppl 909.2 | wps 7862.8 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.304
2022-02-02 15:29:45 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:29:45 | INFO | train | epoch 094 | loss 6.056 | ppl 66.52 | wps 5825.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.66 | train_wall 329 | gb_free 6.1 | wall 33706
KL Stats: Epoch 94 Divergences: Uniform: 2.8826772968768015 Unigram: 3.5214821368495572
2022-02-02 15:29:45 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:35:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:35:43 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.868 | ppl 934.52 | wps 7874 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.304
2022-02-02 15:35:43 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:35:43 | INFO | train | epoch 095 | loss 6.039 | ppl 65.77 | wps 5821.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.674 | train_wall 329 | gb_free 6.1 | wall 34065
KL Stats: Epoch 95 Divergences: Uniform: 2.892888383340476 Unigram: 3.5310214631461165
2022-02-02 15:35:43 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:37:27 | INFO | train_inner | epoch 096:     20 / 64 loss=6.035, ppl=65.56, wps=5698.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.672, train_wall=514, gb_free=6.1, wall=34169
2022-02-02 15:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:41:42 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.82 | ppl 904.1 | wps 7860.1 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.304
2022-02-02 15:41:42 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:41:42 | INFO | train | epoch 096 | loss 6.021 | ppl 64.93 | wps 5821.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.684 | train_wall 329 | gb_free 6.1 | wall 34423
KL Stats: Epoch 96 Divergences: Uniform: 2.8969141440131216 Unigram: 3.54396929150415
2022-02-02 15:41:42 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:46:33 | INFO | train_inner | epoch 097:     56 / 64 loss=6.015, ppl=64.65, wps=5983.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.684, train_wall=516, gb_free=6.1, wall=34715
2022-02-02 15:47:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:47:42 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.846 | ppl 920.09 | wps 7856 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.304
2022-02-02 15:47:42 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:47:42 | INFO | train | epoch 097 | loss 6.001 | ppl 64.05 | wps 5811.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.682 | train_wall 330 | gb_free 6.1 | wall 34783
KL Stats: Epoch 97 Divergences: Uniform: 2.9022350884838417 Unigram: 3.5535006068094646
2022-02-02 15:47:42 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:53:40 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.837 | ppl 914.67 | wps 7865.3 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.304
2022-02-02 15:53:40 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:53:40 | INFO | train | epoch 098 | loss 5.985 | ppl 63.32 | wps 5821.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.706 | train_wall 329 | gb_free 6.1 | wall 35142
KL Stats: Epoch 98 Divergences: Uniform: 2.900271684076857 Unigram: 3.569897131236246
2022-02-02 15:53:40 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:53:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:56:05 | INFO | train_inner | epoch 099:     28 / 64 loss=5.977, ppl=62.99, wps=5699.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.695, train_wall=514, gb_free=6.1, wall=35287
2022-02-02 15:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:59:38 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.911 | ppl 962.41 | wps 7875.8 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.304
2022-02-02 15:59:38 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:59:38 | INFO | train | epoch 099 | loss 5.966 | ppl 62.51 | wps 5834.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.687 | train_wall 329 | gb_free 6.1 | wall 35500
KL Stats: Epoch 99 Divergences: Uniform: 2.905682610872847 Unigram: 3.5855693544116063
2022-02-02 15:59:38 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:05:09 | INFO | train_inner | epoch 100:     64 / 64 loss=5.965, ppl=62.45, wps=6000.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.694, train_wall=513, gb_free=6.1, wall=35830
2022-02-02 16:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:05:36 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.872 | ppl 937.23 | wps 7881.7 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.304
2022-02-02 16:05:36 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 16:05:36 | INFO | train | epoch 100 | loss 5.949 | ppl 61.76 | wps 5832.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.694 | train_wall 329 | gb_free 6.1 | wall 35858
KL Stats: Epoch 100 Divergences: Uniform: 2.9159933996898992 Unigram: 3.6003643076947887
2022-02-02 16:05:36 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 16:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:11:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:11:35 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.939 | ppl 981.36 | wps 7863.3 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.304
2022-02-02 16:11:35 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 16:11:35 | INFO | train | epoch 101 | loss 5.932 | ppl 61.06 | wps 5824.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.694 | train_wall 329 | gb_free 6.1 | wall 36216
KL Stats: Epoch 101 Divergences: Uniform: 2.921184202855394 Unigram: 3.6035044960482514
2022-02-02 16:11:35 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 16:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:14:42 | INFO | train_inner | epoch 102:     36 / 64 loss=5.918, ppl=60.45, wps=5702.7, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.71, train_wall=515, gb_free=6.1, wall=36403
2022-02-02 16:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:17:33 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.835 | ppl 913.59 | wps 7862.9 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.304
2022-02-02 16:17:33 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 16:17:33 | INFO | train | epoch 102 | loss 5.917 | ppl 60.4 | wps 5827.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.718 | train_wall 329 | gb_free 6.1 | wall 36575
KL Stats: Epoch 102 Divergences: Uniform: 2.922020210354158 Unigram: 3.6188604726931066
2022-02-02 16:17:33 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 16:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:23:32 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.959 | ppl 995.52 | wps 7884.6 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.304
2022-02-02 16:23:32 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 16:23:32 | INFO | train | epoch 103 | loss 5.899 | ppl 59.68 | wps 5828.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.709 | train_wall 329 | gb_free 6.1 | wall 36933
KL Stats: Epoch 103 Divergences: Uniform: 2.9212446566216426 Unigram: 3.6348047137948285
2022-02-02 16:23:32 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 16:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:24:13 | INFO | train_inner | epoch 104:      8 / 64 loss=5.906, ppl=59.97, wps=5705.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.703, train_wall=513, gb_free=6.1, wall=36974
2022-02-02 16:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:29:30 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.934 | ppl 977.89 | wps 7862.7 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.304
2022-02-02 16:29:30 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:29:30 | INFO | train | epoch 104 | loss 5.881 | ppl 58.92 | wps 5830.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.702 | train_wall 329 | gb_free 6.1 | wall 37291
KL Stats: Epoch 104 Divergences: Uniform: 2.9411434782276245 Unigram: 3.6493364392097294
2022-02-02 16:29:30 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:29:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:33:18 | INFO | train_inner | epoch 105:     44 / 64 loss=5.868, ppl=58.41, wps=5999.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.709, train_wall=514, gb_free=6.1, wall=37519
2022-02-02 16:35:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:35:28 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.934 | ppl 978.34 | wps 7902.8 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.304
2022-02-02 16:35:28 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:35:28 | INFO | train | epoch 105 | loss 5.87 | ppl 58.49 | wps 5834.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.738 | train_wall 329 | gb_free 6.1 | wall 37649
KL Stats: Epoch 105 Divergences: Uniform: 2.9391169413639817 Unigram: 3.6604554101831375
2022-02-02 16:35:28 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:40:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:41:27 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.94 | ppl 982.61 | wps 7875.1 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.304
2022-02-02 16:41:27 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:41:27 | INFO | train | epoch 106 | loss 5.853 | ppl 57.79 | wps 5824.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.739 | train_wall 329 | gb_free 6.1 | wall 38008
KL Stats: Epoch 106 Divergences: Uniform: 2.949664945238387 Unigram: 3.6687713010121703
2022-02-02 16:41:27 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:42:50 | INFO | train_inner | epoch 107:     16 / 64 loss=5.858, ppl=58, wps=5702.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.741, train_wall=514, gb_free=6.1, wall=38091
2022-02-02 16:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:47:25 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.913 | ppl 963.91 | wps 7866.8 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.304
2022-02-02 16:47:25 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:47:25 | INFO | train | epoch 107 | loss 5.839 | ppl 57.25 | wps 5829.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.721 | train_wall 329 | gb_free 6.1 | wall 38366
KL Stats: Epoch 107 Divergences: Uniform: 2.9437388643602556 Unigram: 3.683698908149323
2022-02-02 16:47:25 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:51:54 | INFO | train_inner | epoch 108:     52 / 64 loss=5.837, ppl=57.14, wps=5998.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.746, train_wall=515, gb_free=6.1, wall=38636
2022-02-02 16:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:53:23 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.984 | ppl 1012.75 | wps 7874.6 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.304
2022-02-02 16:53:23 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:53:23 | INFO | train | epoch 108 | loss 5.826 | ppl 56.71 | wps 5829.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.76 | train_wall 329 | gb_free 6.1 | wall 38724
KL Stats: Epoch 108 Divergences: Uniform: 2.953197902327265 Unigram: 3.689594753255222
2022-02-02 16:53:23 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:58:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:59:21 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.977 | ppl 1007.7 | wps 7866.7 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.304
2022-02-02 16:59:21 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:59:21 | INFO | train | epoch 109 | loss 5.809 | ppl 56.07 | wps 5832.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.762 | train_wall 329 | gb_free 6.1 | wall 39082
KL Stats: Epoch 109 Divergences: Uniform: 2.952637636867884 Unigram: 3.6984086085360577
2022-02-02 16:59:21 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:01:26 | INFO | train_inner | epoch 110:     24 / 64 loss=5.802, ppl=55.8, wps=5704.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.757, train_wall=513, gb_free=6.1, wall=39207
2022-02-02 17:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:05:20 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.017 | ppl 1036.44 | wps 7870 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.304
2022-02-02 17:05:20 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 17:05:20 | INFO | train | epoch 110 | loss 5.795 | ppl 55.52 | wps 5826.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.752 | train_wall 329 | gb_free 6.1 | wall 39441
KL Stats: Epoch 110 Divergences: Uniform: 2.960878667226115 Unigram: 3.7167256616032818
2022-02-02 17:05:20 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 17:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:10:31 | INFO | train_inner | epoch 111:     60 / 64 loss=5.794, ppl=55.47, wps=5995.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.752, train_wall=515, gb_free=6.1, wall=39752
2022-02-02 17:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:11:18 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.021 | ppl 1039.02 | wps 7857.2 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.304
2022-02-02 17:11:18 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 17:11:18 | INFO | train | epoch 111 | loss 5.781 | ppl 54.97 | wps 5827.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.751 | train_wall 329 | gb_free 6.1 | wall 39799
KL Stats: Epoch 111 Divergences: Uniform: 2.95418852908951 Unigram: 3.7276337706561202
2022-02-02 17:11:18 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 17:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:17:16 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.895 | ppl 952.32 | wps 7875.5 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.304
2022-02-02 17:17:16 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 17:17:16 | INFO | train | epoch 112 | loss 5.769 | ppl 54.52 | wps 5839.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.76 | train_wall 328 | gb_free 6.1 | wall 40157
KL Stats: Epoch 112 Divergences: Uniform: 2.9632614921370033 Unigram: 3.735384091979601
2022-02-02 17:17:16 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 17:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:20:02 | INFO | train_inner | epoch 113:     32 / 64 loss=5.756, ppl=54.04, wps=5709.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.767, train_wall=513, gb_free=6.1, wall=40323
2022-02-02 17:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:23:14 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.034 | ppl 1048.39 | wps 7858.3 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.304
2022-02-02 17:23:14 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 17:23:14 | INFO | train | epoch 113 | loss 5.756 | ppl 54.04 | wps 5827.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.775 | train_wall 329 | gb_free 6.1 | wall 40515
KL Stats: Epoch 113 Divergences: Uniform: 2.9644320024895867 Unigram: 3.7453976888102107
2022-02-02 17:23:14 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 17:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:29:12 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.945 | ppl 985.54 | wps 7875.2 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.304
2022-02-02 17:29:12 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 17:29:12 | INFO | train | epoch 114 | loss 5.742 | ppl 53.54 | wps 5829.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.757 | train_wall 329 | gb_free 6.1 | wall 40874
KL Stats: Epoch 114 Divergences: Uniform: 2.977450928897578 Unigram: 3.76280327664446
2022-02-02 17:29:12 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 17:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:29:33 | INFO | train_inner | epoch 115:      4 / 64 loss=5.755, ppl=54.02, wps=5706.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.758, train_wall=513, gb_free=6.1, wall=40894
2022-02-02 17:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:35:10 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.976 | ppl 1007.33 | wps 7897.5 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.304
2022-02-02 17:35:10 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:35:10 | INFO | train | epoch 115 | loss 5.73 | ppl 53.07 | wps 5836.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.782 | train_wall 329 | gb_free 6.1 | wall 41232
KL Stats: Epoch 115 Divergences: Uniform: 2.968495457107842 Unigram: 3.769234990205862
2022-02-02 17:35:10 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:38:38 | INFO | train_inner | epoch 116:     40 / 64 loss=5.718, ppl=52.64, wps=6002.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.778, train_wall=514, gb_free=6.1, wall=41439
2022-02-02 17:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:41:09 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.018 | ppl 1037.04 | wps 7877.1 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.304
2022-02-02 17:41:09 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:41:09 | INFO | train | epoch 116 | loss 5.716 | ppl 52.58 | wps 5829.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.771 | train_wall 329 | gb_free 6.1 | wall 41590
KL Stats: Epoch 116 Divergences: Uniform: 2.968921384544728 Unigram: 3.7734669932142344
2022-02-02 17:41:09 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:46:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:47:06 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.968 | ppl 1001.55 | wps 7915.8 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.304
2022-02-02 17:47:06 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:47:06 | INFO | train | epoch 117 | loss 5.703 | ppl 52.09 | wps 5839.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.768 | train_wall 328 | gb_free 6.1 | wall 41948
KL Stats: Epoch 117 Divergences: Uniform: 2.9761354896792613 Unigram: 3.788915592672769
2022-02-02 17:47:06 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:47:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:48:09 | INFO | train_inner | epoch 118:     12 / 64 loss=5.708, ppl=52.29, wps=5709.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.774, train_wall=513, gb_free=6.1, wall=42010
2022-02-02 17:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:53:05 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.077 | ppl 1080.11 | wps 7883.6 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.304
2022-02-02 17:53:05 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:53:05 | INFO | train | epoch 118 | loss 5.694 | ppl 51.76 | wps 5823.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.792 | train_wall 329 | gb_free 6.1 | wall 42306
KL Stats: Epoch 118 Divergences: Uniform: 2.9755661293923774 Unigram: 3.790172009059603
2022-02-02 17:53:05 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:57:14 | INFO | train_inner | epoch 119:     48 / 64 loss=5.684, ppl=51.42, wps=5996.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.777, train_wall=515, gb_free=6.1, wall=42555
2022-02-02 17:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:59:03 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.982 | ppl 1011.59 | wps 7880.6 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.304
2022-02-02 17:59:03 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:59:03 | INFO | train | epoch 119 | loss 5.679 | ppl 51.23 | wps 5835.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.774 | train_wall 329 | gb_free 6.1 | wall 42664
KL Stats: Epoch 119 Divergences: Uniform: 2.9889382363635595 Unigram: 3.8101020801136136
2022-02-02 17:59:03 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:59:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:04:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:05:01 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.012 | ppl 1032.42 | wps 7891.1 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.304
2022-02-02 18:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 18:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint120.pt
2022-02-02 18:05:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint120.pt
2022-02-02 18:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.012) (writing took 3.2716741068288684 seconds)
2022-02-02 18:05:04 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 18:05:04 | INFO | train | epoch 120 | loss 5.669 | ppl 50.89 | wps 5779.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.795 | train_wall 329 | gb_free 6.1 | wall 43025
KL Stats: Epoch 120 Divergences: Uniform: 2.9879424200553233 Unigram: 3.819814276705834
2022-02-02 18:05:04 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 18:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:06:48 | INFO | train_inner | epoch 121:     20 / 64 loss=5.667, ppl=50.81, wps=5674.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.796, train_wall=513, gb_free=6.1, wall=43129
2022-02-02 18:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:11:03 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.031 | ppl 1046.1 | wps 7874 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.304
2022-02-02 18:11:03 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 18:11:03 | INFO | train | epoch 121 | loss 5.656 | ppl 50.43 | wps 5828.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.796 | train_wall 329 | gb_free 6.1 | wall 43384
KL Stats: Epoch 121 Divergences: Uniform: 2.985624502988799 Unigram: 3.829137260523363
2022-02-02 18:11:03 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 18:11:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:15:53 | INFO | train_inner | epoch 122:     56 / 64 loss=5.656, ppl=50.42, wps=5999.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.809, train_wall=514, gb_free=6.1, wall=43674
2022-02-02 18:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:17:01 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.988 | ppl 1015.76 | wps 7865.9 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.304
2022-02-02 18:17:01 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 18:17:01 | INFO | train | epoch 122 | loss 5.645 | ppl 50.04 | wps 5833.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.816 | train_wall 329 | gb_free 6.1 | wall 43742
KL Stats: Epoch 122 Divergences: Uniform: 2.993642047199735 Unigram: 3.838179517628297
2022-02-02 18:17:01 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 18:17:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:22:59 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.011 | ppl 1031.58 | wps 7856.5 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.304
2022-02-02 18:22:59 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 18:22:59 | INFO | train | epoch 123 | loss 5.634 | ppl 49.67 | wps 5829.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.81 | train_wall 329 | gb_free 6.1 | wall 44100
KL Stats: Epoch 123 Divergences: Uniform: 2.991715958633795 Unigram: 3.847840809684513
2022-02-02 18:22:59 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 18:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:25:24 | INFO | train_inner | epoch 124:     28 / 64 loss=5.628, ppl=49.46, wps=5703.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.809, train_wall=513, gb_free=6.1, wall=44246
2022-02-02 18:28:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:28:58 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.064 | ppl 1070.74 | wps 7862.8 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.304
2022-02-02 18:28:58 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 18:28:58 | INFO | train | epoch 124 | loss 5.624 | ppl 49.31 | wps 5820.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.826 | train_wall 329 | gb_free 6.1 | wall 44459
KL Stats: Epoch 124 Divergences: Uniform: 2.994975816393978 Unigram: 3.85364300168677
2022-02-02 18:28:58 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 18:28:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:34:28 | INFO | train_inner | epoch 125:     64 / 64 loss=5.624, ppl=49.33, wps=5996.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.82, train_wall=513, gb_free=6.1, wall=44789
2022-02-02 18:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:34:56 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.99 | ppl 1016.97 | wps 7861.2 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.304
2022-02-02 18:34:56 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:34:56 | INFO | train | epoch 125 | loss 5.612 | ppl 48.92 | wps 5833.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.811 | train_wall 329 | gb_free 6.1 | wall 44817
KL Stats: Epoch 125 Divergences: Uniform: 2.9996105008690397 Unigram: 3.8644583484515898
2022-02-02 18:34:56 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:40:54 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.027 | ppl 1043.32 | wps 7873.2 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.304
2022-02-02 18:40:54 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:40:54 | INFO | train | epoch 126 | loss 5.602 | ppl 48.58 | wps 5828.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.852 | train_wall 329 | gb_free 6.1 | wall 45175
KL Stats: Epoch 126 Divergences: Uniform: 2.9974795251330746 Unigram: 3.8664798844511434
2022-02-02 18:40:54 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:40:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:44:01 | INFO | train_inner | epoch 127:     36 / 64 loss=5.587, ppl=48.08, wps=5706.9, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.837, train_wall=514, gb_free=6.1, wall=45362
2022-02-02 18:46:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:46:52 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.044 | ppl 1055.55 | wps 7882 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.304
2022-02-02 18:46:52 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:46:52 | INFO | train | epoch 127 | loss 5.592 | ppl 48.25 | wps 5836.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.833 | train_wall 328 | gb_free 6.1 | wall 45533
KL Stats: Epoch 127 Divergences: Uniform: 3.0026904635042073 Unigram: 3.8752232713271817
2022-02-02 18:46:52 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:52:51 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.984 | ppl 1012.52 | wps 7858.3 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.304
2022-02-02 18:52:51 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:52:51 | INFO | train | epoch 128 | loss 5.581 | ppl 47.88 | wps 5819.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.837 | train_wall 329 | gb_free 6.1 | wall 45892
KL Stats: Epoch 128 Divergences: Uniform: 3.0046612787818145 Unigram: 3.889239700434211
2022-02-02 18:52:51 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:52:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:53:32 | INFO | train_inner | epoch 129:      8 / 64 loss=5.589, ppl=48.14, wps=5701.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.842, train_wall=514, gb_free=6.1, wall=45934
2022-02-02 18:58:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:58:49 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.054 | ppl 1063.21 | wps 7875.3 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.304
2022-02-02 18:58:49 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:58:49 | INFO | train | epoch 129 | loss 5.571 | ppl 47.53 | wps 5829.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.853 | train_wall 329 | gb_free 6.1 | wall 46250
KL Stats: Epoch 129 Divergences: Uniform: 3.0061000973396284 Unigram: 3.900382055053169
2022-02-02 18:58:49 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:02:37 | INFO | train_inner | epoch 130:     44 / 64 loss=5.563, ppl=47.26, wps=5997.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.856, train_wall=515, gb_free=6.1, wall=46479
2022-02-02 19:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:04:47 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.061 | ppl 1068.41 | wps 7886.9 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.304
2022-02-02 19:04:47 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 19:04:47 | INFO | train | epoch 130 | loss 5.562 | ppl 47.23 | wps 5830.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.846 | train_wall 329 | gb_free 6.1 | wall 46609
KL Stats: Epoch 130 Divergences: Uniform: 3.0048315732467454 Unigram: 3.9034762575104667
2022-02-02 19:04:47 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 19:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:10:46 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.049 | ppl 1059.27 | wps 7850.2 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.304
2022-02-02 19:10:46 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 19:10:46 | INFO | train | epoch 131 | loss 5.551 | ppl 46.88 | wps 5823.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.825 | train_wall 329 | gb_free 6.1 | wall 46967
KL Stats: Epoch 131 Divergences: Uniform: 3.0125252247068337 Unigram: 3.9138267716459842
2022-02-02 19:10:46 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 19:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:12:09 | INFO | train_inner | epoch 132:     16 / 64 loss=5.556, ppl=47.04, wps=5703.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.831, train_wall=513, gb_free=6.1, wall=47050
2022-02-02 19:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:16:45 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.016 | ppl 1035.55 | wps 7869.8 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.304
2022-02-02 19:16:45 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 19:16:45 | INFO | train | epoch 132 | loss 5.542 | ppl 46.59 | wps 5824.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.85 | train_wall 329 | gb_free 6.1 | wall 47326
KL Stats: Epoch 132 Divergences: Uniform: 3.018020539192745 Unigram: 3.9223441973930457
2022-02-02 19:16:45 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 19:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:21:15 | INFO | train_inner | epoch 133:     52 / 64 loss=5.539, ppl=46.49, wps=5989.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.854, train_wall=515, gb_free=6.1, wall=47596
2022-02-02 19:22:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:22:43 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.182 | ppl 1161.68 | wps 7875.6 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.304
2022-02-02 19:22:43 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 19:22:43 | INFO | train | epoch 133 | loss 5.533 | ppl 46.31 | wps 5823.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.873 | train_wall 329 | gb_free 6.1 | wall 47684
KL Stats: Epoch 133 Divergences: Uniform: 3.0192263356008584 Unigram: 3.9305979338847843
2022-02-02 19:22:43 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 19:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:28:42 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.075 | ppl 1078.32 | wps 7873.8 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.304
2022-02-02 19:28:42 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 19:28:42 | INFO | train | epoch 134 | loss 5.523 | ppl 45.99 | wps 5826.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.863 | train_wall 329 | gb_free 6.1 | wall 48043
KL Stats: Epoch 134 Divergences: Uniform: 3.025147232541602 Unigram: 3.9390424450291457
2022-02-02 19:28:42 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 19:28:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:30:46 | INFO | train_inner | epoch 135:     24 / 64 loss=5.518, ppl=45.83, wps=5701, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.877, train_wall=514, gb_free=6.1, wall=48167
2022-02-02 19:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:34:40 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.08 | ppl 1082.72 | wps 7854.1 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.304
2022-02-02 19:34:40 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 19:34:40 | INFO | train | epoch 135 | loss 5.514 | ppl 45.7 | wps 5826.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.897 | train_wall 329 | gb_free 6.1 | wall 48401
KL Stats: Epoch 135 Divergences: Uniform: 3.0242574616003397 Unigram: 3.9436931646087143
2022-02-02 19:34:40 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 19:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:39:51 | INFO | train_inner | epoch 136:     60 / 64 loss=5.515, ppl=45.73, wps=5994.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.881, train_wall=515, gb_free=6.1, wall=48713
2022-02-02 19:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:40:39 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.13 | ppl 1120.21 | wps 7864.5 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.304
2022-02-02 19:40:39 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:40:39 | INFO | train | epoch 136 | loss 5.506 | ppl 45.45 | wps 5826.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.875 | train_wall 329 | gb_free 6.1 | wall 48760
KL Stats: Epoch 136 Divergences: Uniform: 3.0166454285555186 Unigram: 3.955015755207656
2022-02-02 19:40:39 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:46:37 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.069 | ppl 1074.2 | wps 7886.4 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.304
2022-02-02 19:46:37 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:46:37 | INFO | train | epoch 137 | loss 5.498 | ppl 45.18 | wps 5833.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.896 | train_wall 329 | gb_free 6.1 | wall 49118
KL Stats: Epoch 137 Divergences: Uniform: 3.027727591848564 Unigram: 3.9591028926322793
2022-02-02 19:46:37 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:49:23 | INFO | train_inner | epoch 138:     32 / 64 loss=5.485, ppl=44.79, wps=5701.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.896, train_wall=514, gb_free=6.1, wall=49284
2022-02-02 19:52:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:52:36 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.108 | ppl 1103.72 | wps 7856.6 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.304
2022-02-02 19:52:36 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:52:36 | INFO | train | epoch 138 | loss 5.486 | ppl 44.83 | wps 5813.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.893 | train_wall 330 | gb_free 6.1 | wall 49477
KL Stats: Epoch 138 Divergences: Uniform: 3.029182763402323 Unigram: 3.96375552421668
2022-02-02 19:52:36 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:58:35 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.134 | ppl 1123.42 | wps 7853.5 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.304
2022-02-02 19:58:35 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 19:58:35 | INFO | train | epoch 139 | loss 5.478 | ppl 44.56 | wps 5821 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.892 | train_wall 329 | gb_free 6.1 | wall 49836
KL Stats: Epoch 139 Divergences: Uniform: 3.0268866797843827 Unigram: 3.9720389346678524
2022-02-02 19:58:35 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 19:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:56 | INFO | train_inner | epoch 140:      4 / 64 loss=5.49, ppl=44.94, wps=5694.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.894, train_wall=514, gb_free=6.1, wall=49857
2022-02-02 20:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:04:34 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.119 | ppl 1111.72 | wps 7875.6 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.304
2022-02-02 20:04:34 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 20:04:34 | INFO | train | epoch 140 | loss 5.471 | ppl 44.37 | wps 5815.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.904 | train_wall 330 | gb_free 6.1 | wall 50195
KL Stats: Epoch 140 Divergences: Uniform: 3.0321455022995596 Unigram: 3.9855012343398633
2022-02-02 20:04:34 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 20:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:08:02 | INFO | train_inner | epoch 141:     40 / 64 loss=5.459, ppl=43.98, wps=5983.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.915, train_wall=516, gb_free=6.1, wall=50403
2022-02-02 20:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:10:33 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.157 | ppl 1141.65 | wps 7894.5 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.304
2022-02-02 20:10:33 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 20:10:33 | INFO | train | epoch 141 | loss 5.462 | ppl 44.09 | wps 5817.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.928 | train_wall 330 | gb_free 6.1 | wall 50554
KL Stats: Epoch 141 Divergences: Uniform: 3.033109246282328 Unigram: 3.988623440450845
2022-02-02 20:10:33 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 20:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:16:32 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.085 | ppl 1085.92 | wps 7897.1 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.304
2022-02-02 20:16:32 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 20:16:32 | INFO | train | epoch 142 | loss 5.454 | ppl 43.83 | wps 5824.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.921 | train_wall 329 | gb_free 6.1 | wall 50913
KL Stats: Epoch 142 Divergences: Uniform: 3.0396976887888765 Unigram: 3.994787385079578
2022-02-02 20:16:32 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 20:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:17:34 | INFO | train_inner | epoch 143:     12 / 64 loss=5.462, ppl=44.07, wps=5698, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.93, train_wall=514, gb_free=6.1, wall=50975
2022-02-02 20:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:22:30 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.147 | ppl 1133.52 | wps 7862.4 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.304
2022-02-02 20:22:30 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 20:22:30 | INFO | train | epoch 143 | loss 5.445 | ppl 43.55 | wps 5821.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.945 | train_wall 329 | gb_free 6.1 | wall 51272
KL Stats: Epoch 143 Divergences: Uniform: 3.0318551611699265 Unigram: 4.000431925362605
2022-02-02 20:22:30 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 20:22:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:26:40 | INFO | train_inner | epoch 144:     48 / 64 loss=5.435, ppl=43.25, wps=5980, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.936, train_wall=516, gb_free=6.1, wall=51522
2022-02-02 20:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:28:30 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.136 | ppl 1125 | wps 7847 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.304
2022-02-02 20:28:30 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 20:28:30 | INFO | train | epoch 144 | loss 5.439 | ppl 43.37 | wps 5803.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.933 | train_wall 330 | gb_free 6.1 | wall 51632
KL Stats: Epoch 144 Divergences: Uniform: 3.040380516001451 Unigram: 4.010488517539426
2022-02-02 20:28:30 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 20:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:34:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:34:29 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.138 | ppl 1126.66 | wps 7871 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.304
2022-02-02 20:34:29 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 20:34:29 | INFO | train | epoch 145 | loss 5.43 | ppl 43.11 | wps 5822.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.923 | train_wall 329 | gb_free 6.1 | wall 51990
KL Stats: Epoch 145 Divergences: Uniform: 3.043281892750245 Unigram: 4.014447052850228
2022-02-02 20:34:29 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 20:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:36:13 | INFO | train_inner | epoch 146:     20 / 64 loss=5.433, ppl=43.19, wps=5694.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.924, train_wall=514, gb_free=6.1, wall=52094
2022-02-02 20:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:40:28 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.075 | ppl 1078.59 | wps 7863.4 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.304
2022-02-02 20:40:28 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:40:28 | INFO | train | epoch 146 | loss 5.424 | ppl 42.93 | wps 5818.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.952 | train_wall 330 | gb_free 6.1 | wall 52349
KL Stats: Epoch 146 Divergences: Uniform: 3.044374889021601 Unigram: 4.025803585873675
2022-02-02 20:40:28 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:45:19 | INFO | train_inner | epoch 147:     56 / 64 loss=5.423, ppl=42.91, wps=5985.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.946, train_wall=516, gb_free=6.1, wall=52640
2022-02-02 20:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:46:27 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.172 | ppl 1154.06 | wps 7841.2 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.304
2022-02-02 20:46:27 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:46:27 | INFO | train | epoch 147 | loss 5.414 | ppl 42.64 | wps 5817.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.938 | train_wall 330 | gb_free 6.1 | wall 52708
KL Stats: Epoch 147 Divergences: Uniform: 3.0361623619060967 Unigram: 4.032334025891368
2022-02-02 20:46:27 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:46:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:52:26 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.105 | ppl 1101.66 | wps 7839.4 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.304
2022-02-02 20:52:26 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 20:52:26 | INFO | train | epoch 148 | loss 5.408 | ppl 42.45 | wps 5816.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.957 | train_wall 330 | gb_free 6.1 | wall 53067
KL Stats: Epoch 148 Divergences: Uniform: 3.048385838958564 Unigram: 4.035005243947333
2022-02-02 20:52:26 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 20:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:54:51 | INFO | train_inner | epoch 149:     28 / 64 loss=5.4, ppl=42.23, wps=5694.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.946, train_wall=514, gb_free=6.1, wall=53213
2022-02-02 20:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:58:24 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.166 | ppl 1148.61 | wps 7879.7 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.304
2022-02-02 20:58:24 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 20:58:24 | INFO | train | epoch 149 | loss 5.4 | ppl 42.23 | wps 5829 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.941 | train_wall 329 | gb_free 6.1 | wall 53426
KL Stats: Epoch 149 Divergences: Uniform: 3.0448647182462905 Unigram: 4.043667611893791
2022-02-02 20:58:24 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 20:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:03:55 | INFO | train_inner | epoch 150:     64 / 64 loss=5.405, ppl=42.36, wps=5992.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.971, train_wall=514, gb_free=6.1, wall=53757
2022-02-02 21:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:04:23 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.161 | ppl 1144.95 | wps 7848 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.304
2022-02-02 21:04:23 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 21:04:23 | INFO | train | epoch 150 | loss 5.392 | ppl 41.99 | wps 5821.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.972 | train_wall 329 | gb_free 6.1 | wall 53784
KL Stats: Epoch 150 Divergences: Uniform: 3.0504761866024745 Unigram: 4.045907383964054
2022-02-02 21:04:23 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 21:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:09:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:10:22 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.142 | ppl 1129.86 | wps 7848.7 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.304
2022-02-02 21:10:22 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 21:10:22 | INFO | train | epoch 151 | loss 5.385 | ppl 41.79 | wps 5826.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.975 | train_wall 329 | gb_free 6.1 | wall 54143
KL Stats: Epoch 151 Divergences: Uniform: 3.051252288602481 Unigram: 4.058525298999459
2022-02-02 21:10:22 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 21:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:13:28 | INFO | train_inner | epoch 152:     36 / 64 loss=5.376, ppl=41.52, wps=5704.9, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.976, train_wall=515, gb_free=6.1, wall=54329
2022-02-02 21:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:16:20 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.186 | ppl 1164.74 | wps 7879.2 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.304
2022-02-02 21:16:20 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 21:16:20 | INFO | train | epoch 152 | loss 5.379 | ppl 41.61 | wps 5835.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.982 | train_wall 329 | gb_free 6.1 | wall 54501
KL Stats: Epoch 152 Divergences: Uniform: 3.0551568006760164 Unigram: 4.0655332284665775
2022-02-02 21:16:20 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 21:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:22:18 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.17 | ppl 1152.45 | wps 7886.9 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.304
2022-02-02 21:22:18 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 21:22:18 | INFO | train | epoch 153 | loss 5.37 | ppl 41.36 | wps 5826.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.984 | train_wall 329 | gb_free 6.1 | wall 54859
KL Stats: Epoch 153 Divergences: Uniform: 3.052037893059092 Unigram: 4.066981661441429
2022-02-02 21:22:18 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 21:22:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:23:00 | INFO | train_inner | epoch 154:      8 / 64 loss=5.375, ppl=41.5, wps=5705.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.988, train_wall=513, gb_free=6.1, wall=54901
2022-02-02 21:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:28:16 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.167 | ppl 1149.84 | wps 7886.8 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.304
2022-02-02 21:28:16 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 21:28:16 | INFO | train | epoch 154 | loss 5.362 | ppl 41.12 | wps 5833.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.986 | train_wall 329 | gb_free 6.1 | wall 55217
KL Stats: Epoch 154 Divergences: Uniform: 3.0559720015240095 Unigram: 4.074266110744891
2022-02-02 21:28:16 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 21:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:32:04 | INFO | train_inner | epoch 155:     44 / 64 loss=5.356, ppl=40.96, wps=5998.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.997, train_wall=515, gb_free=6.1, wall=55446
2022-02-02 21:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:34:15 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.177 | ppl 1157.63 | wps 7878.2 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.304
2022-02-02 21:34:15 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 21:34:15 | INFO | train | epoch 155 | loss 5.358 | ppl 41.02 | wps 5822.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.016 | train_wall 329 | gb_free 6.1 | wall 55576
KL Stats: Epoch 155 Divergences: Uniform: 3.0567466403133223 Unigram: 4.08486285592734
2022-02-02 21:34:15 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 21:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:39:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:40:13 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.188 | ppl 1166.48 | wps 7869.4 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.304
2022-02-02 21:40:13 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 21:40:13 | INFO | train | epoch 156 | loss 5.351 | ppl 40.81 | wps 5832 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.001 | train_wall 329 | gb_free 6.1 | wall 55934
KL Stats: Epoch 156 Divergences: Uniform: 3.0607162023511294 Unigram: 4.094184223620351
2022-02-02 21:40:13 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 21:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:41:36 | INFO | train_inner | epoch 157:     16 / 64 loss=5.355, ppl=40.92, wps=5703.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.01, train_wall=513, gb_free=6.1, wall=56017
2022-02-02 21:45:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:46:12 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.133 | ppl 1123.21 | wps 7884.6 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.304
2022-02-02 21:46:12 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:46:12 | INFO | train | epoch 157 | loss 5.343 | ppl 40.58 | wps 5824.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.023 | train_wall 329 | gb_free 6.1 | wall 56293
KL Stats: Epoch 157 Divergences: Uniform: 3.0596397988699935 Unigram: 4.092923651998751
2022-02-02 21:46:12 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:50:41 | INFO | train_inner | epoch 158:     52 / 64 loss=5.339, ppl=40.46, wps=5991.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.02, train_wall=515, gb_free=6.1, wall=56563
2022-02-02 21:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:52:10 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.114 | ppl 1108.02 | wps 7863.3 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.304
2022-02-02 21:52:10 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 21:52:10 | INFO | train | epoch 158 | loss 5.338 | ppl 40.46 | wps 5824.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.035 | train_wall 329 | gb_free 6.1 | wall 56651
KL Stats: Epoch 158 Divergences: Uniform: 3.060458135245061 Unigram: 4.099308233603974
2022-02-02 21:52:10 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 21:52:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:58:09 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.145 | ppl 1132.32 | wps 7847.7 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.304
2022-02-02 21:58:09 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 21:58:09 | INFO | train | epoch 159 | loss 5.33 | ppl 40.23 | wps 5819.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.016 | train_wall 329 | gb_free 6.1 | wall 57010
KL Stats: Epoch 159 Divergences: Uniform: 3.0529968405214354 Unigram: 4.1035138878142945
2022-02-02 21:58:09 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 21:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:00:14 | INFO | train_inner | epoch 160:     24 / 64 loss=5.324, ppl=40.05, wps=5694.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.02, train_wall=514, gb_free=6.1, wall=57135
2022-02-02 22:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:04:08 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.166 | ppl 1149.09 | wps 7896.6 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.304
2022-02-02 22:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 22:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint160.pt
2022-02-02 22:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint160.pt
2022-02-02 22:04:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.166) (writing took 10.412703297100961 seconds)
2022-02-02 22:04:19 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 22:04:19 | INFO | train | epoch 160 | loss 5.326 | ppl 40.12 | wps 5652.2 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.037 | train_wall 330 | gb_free 6.1 | wall 57380
KL Stats: Epoch 160 Divergences: Uniform: 3.0621791084872 Unigram: 4.1074095229493
2022-02-02 22:04:19 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 22:04:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:09:30 | INFO | train_inner | epoch 161:     60 / 64 loss=5.331, ppl=40.25, wps=5871.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.046, train_wall=516, gb_free=6.1, wall=57692
2022-02-02 22:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:10:18 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.193 | ppl 1170.92 | wps 7859.6 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.304
2022-02-02 22:10:18 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 22:10:18 | INFO | train | epoch 161 | loss 5.316 | ppl 39.84 | wps 5815.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.035 | train_wall 330 | gb_free 6.1 | wall 57739
KL Stats: Epoch 161 Divergences: Uniform: 3.0614363447698127 Unigram: 4.116219551892372
2022-02-02 22:10:18 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 22:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:15:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:16:16 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.149 | ppl 1135.49 | wps 7844.8 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.304
2022-02-02 22:16:16 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 22:16:16 | INFO | train | epoch 162 | loss 5.31 | ppl 39.66 | wps 5823.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.047 | train_wall 329 | gb_free 6.1 | wall 58098
KL Stats: Epoch 162 Divergences: Uniform: 3.0638178240390443 Unigram: 4.124812097587535
2022-02-02 22:16:16 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 22:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:19:02 | INFO | train_inner | epoch 163:     32 / 64 loss=5.3, ppl=39.39, wps=5702.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.049, train_wall=513, gb_free=6.1, wall=58263
2022-02-02 22:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:22:14 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.176 | ppl 1156.76 | wps 7861.5 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.304
2022-02-02 22:22:14 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 22:22:14 | INFO | train | epoch 163 | loss 5.305 | ppl 39.53 | wps 5834 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.057 | train_wall 329 | gb_free 6.1 | wall 58456
KL Stats: Epoch 163 Divergences: Uniform: 3.059178019649338 Unigram: 4.123769859816834
2022-02-02 22:22:14 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 22:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:28:12 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.189 | ppl 1167.52 | wps 7868.1 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.304
2022-02-02 22:28:12 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 22:28:12 | INFO | train | epoch 164 | loss 5.3 | ppl 39.39 | wps 5837.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.066 | train_wall 328 | gb_free 6.1 | wall 58813
KL Stats: Epoch 164 Divergences: Uniform: 3.065287289490342 Unigram: 4.127892506053804
2022-02-02 22:28:12 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 22:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:28:33 | INFO | train_inner | epoch 165:      4 / 64 loss=5.31, ppl=39.66, wps=5710.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.067, train_wall=513, gb_free=6.1, wall=58834
2022-02-02 22:33:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:34:11 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.204 | ppl 1179.22 | wps 7847.2 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.304
2022-02-02 22:34:11 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 22:34:11 | INFO | train | epoch 165 | loss 5.294 | ppl 39.23 | wps 5821.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.061 | train_wall 329 | gb_free 6.1 | wall 59172
KL Stats: Epoch 165 Divergences: Uniform: 3.0655678083671236 Unigram: 4.138398239044311
2022-02-02 22:34:11 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 22:34:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:37:39 | INFO | train_inner | epoch 166:     40 / 64 loss=5.283, ppl=38.94, wps=5986.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.053, train_wall=516, gb_free=6.1, wall=59380
2022-02-02 22:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:40:10 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.178 | ppl 1158.7 | wps 7841.4 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.304
2022-02-02 22:40:10 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 22:40:10 | INFO | train | epoch 166 | loss 5.286 | ppl 39.03 | wps 5814.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.055 | train_wall 330 | gb_free 6.1 | wall 59531
KL Stats: Epoch 166 Divergences: Uniform: 3.067030313646746 Unigram: 4.148093614904181
2022-02-02 22:40:10 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 22:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:46:08 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.17 | ppl 1152.34 | wps 7858.4 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.304
2022-02-02 22:46:08 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:46:08 | INFO | train | epoch 167 | loss 5.283 | ppl 38.93 | wps 5831.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.11 | train_wall 329 | gb_free 6.1 | wall 59890
KL Stats: Epoch 167 Divergences: Uniform: 3.072037058939047 Unigram: 4.145448589451939
2022-02-02 22:46:08 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:46:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:47:10 | INFO | train_inner | epoch 168:     12 / 64 loss=5.285, ppl=38.99, wps=5703, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.098, train_wall=513, gb_free=6.1, wall=59952
2022-02-02 22:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:52:06 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.249 | ppl 1217.04 | wps 7877 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.304
2022-02-02 22:52:06 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 22:52:06 | INFO | train | epoch 168 | loss 5.277 | ppl 38.76 | wps 5831.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.089 | train_wall 329 | gb_free 6.1 | wall 60248
KL Stats: Epoch 168 Divergences: Uniform: 3.0643872053846484 Unigram: 4.147160236961409
2022-02-02 22:52:06 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 22:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:56:15 | INFO | train_inner | epoch 169:     48 / 64 loss=5.273, ppl=38.66, wps=5999.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.093, train_wall=515, gb_free=6.1, wall=60496
2022-02-02 22:57:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:58:05 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.206 | ppl 1181.08 | wps 7844.3 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.304
2022-02-02 22:58:05 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 22:58:05 | INFO | train | epoch 169 | loss 5.271 | ppl 38.61 | wps 5829.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.1 | train_wall 329 | gb_free 6.1 | wall 60606
KL Stats: Epoch 169 Divergences: Uniform: 3.0761511481395574 Unigram: 4.152647045523232
2022-02-02 22:58:05 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 22:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:03:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:04:03 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.226 | ppl 1197.7 | wps 7887.5 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.304
2022-02-02 23:04:03 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 23:04:03 | INFO | train | epoch 170 | loss 5.265 | ppl 38.46 | wps 5832.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.098 | train_wall 329 | gb_free 6.1 | wall 60964
KL Stats: Epoch 170 Divergences: Uniform: 3.0708014077204786 Unigram: 4.163966660810692
2022-02-02 23:04:03 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 23:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:05:46 | INFO | train_inner | epoch 171:     20 / 64 loss=5.263, ppl=38.39, wps=5707.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.095, train_wall=513, gb_free=6.1, wall=61068
2022-02-02 23:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:10:01 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.196 | ppl 1172.75 | wps 7862.6 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.304
2022-02-02 23:10:01 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 23:10:01 | INFO | train | epoch 171 | loss 5.259 | ppl 38.28 | wps 5832.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.103 | train_wall 329 | gb_free 6.1 | wall 61322
KL Stats: Epoch 171 Divergences: Uniform: 3.0781772317645077 Unigram: 4.1684432567303515
2022-02-02 23:10:01 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 23:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:14:51 | INFO | train_inner | epoch 172:     56 / 64 loss=5.26, ppl=38.33, wps=5995.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.128, train_wall=515, gb_free=6.1, wall=61613
2022-02-02 23:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:15:59 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.169 | ppl 1151.12 | wps 7884.1 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.304
2022-02-02 23:15:59 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 23:15:59 | INFO | train | epoch 172 | loss 5.254 | ppl 38.15 | wps 5826.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.141 | train_wall 329 | gb_free 6.1 | wall 61681
KL Stats: Epoch 172 Divergences: Uniform: 3.0784771261456485 Unigram: 4.173492270578452
2022-02-02 23:15:59 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 23:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:21:57 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.189 | ppl 1167.46 | wps 7874.8 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.304
2022-02-02 23:21:57 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 23:21:57 | INFO | train | epoch 173 | loss 5.247 | ppl 37.99 | wps 5836.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.106 | train_wall 328 | gb_free 6.1 | wall 62038
KL Stats: Epoch 173 Divergences: Uniform: 3.0787577899995506 Unigram: 4.179081519762252
2022-02-02 23:21:57 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 23:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:24:22 | INFO | train_inner | epoch 174:     28 / 64 loss=5.24, ppl=37.78, wps=5711.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.103, train_wall=513, gb_free=6.1, wall=62184
2022-02-02 23:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:27:55 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.22 | ppl 1192.73 | wps 7890.7 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.304
2022-02-02 23:27:55 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 23:27:55 | INFO | train | epoch 174 | loss 5.242 | ppl 37.84 | wps 5836.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.129 | train_wall 329 | gb_free 6.1 | wall 62396
KL Stats: Epoch 174 Divergences: Uniform: 3.075450116668444 Unigram: 4.1842977205912275
2022-02-02 23:27:55 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 23:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:33:25 | INFO | train_inner | epoch 175:     64 / 64 loss=5.253, ppl=38.12, wps=6003.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.154, train_wall=513, gb_free=6.1, wall=62727
2022-02-02 23:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:33:53 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.231 | ppl 1202.08 | wps 7862.8 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.304
2022-02-02 23:33:53 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 23:33:53 | INFO | train | epoch 175 | loss 5.239 | ppl 37.77 | wps 5834.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.147 | train_wall 329 | gb_free 6.1 | wall 62754
KL Stats: Epoch 175 Divergences: Uniform: 3.073419401606506 Unigram: 4.1826846587938356
2022-02-02 23:33:53 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 23:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:39:51 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.208 | ppl 1183.2 | wps 7866.1 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.304
2022-02-02 23:39:51 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 23:39:51 | INFO | train | epoch 176 | loss 5.231 | ppl 37.55 | wps 5831.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.134 | train_wall 329 | gb_free 6.1 | wall 63112
KL Stats: Epoch 176 Divergences: Uniform: 3.0772516217382018 Unigram: 4.194553728057076
2022-02-02 23:39:51 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 23:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:42:58 | INFO | train_inner | epoch 177:     36 / 64 loss=5.219, ppl=37.24, wps=5709.7, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.118, train_wall=514, gb_free=6.1, wall=63299
2022-02-02 23:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:45:49 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.182 | ppl 1161.33 | wps 7905.4 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.304
2022-02-02 23:45:49 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 23:45:49 | INFO | train | epoch 177 | loss 5.228 | ppl 37.47 | wps 5842.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.135 | train_wall 328 | gb_free 6.1 | wall 63470
KL Stats: Epoch 177 Divergences: Uniform: 3.088501293607357 Unigram: 4.195704619301408
2022-02-02 23:45:49 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 23:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:51:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:51:47 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.263 | ppl 1229.17 | wps 7874 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.304
2022-02-02 23:51:47 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 23:51:47 | INFO | train | epoch 178 | loss 5.222 | ppl 37.33 | wps 5832.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.158 | train_wall 329 | gb_free 6.1 | wall 63828
KL Stats: Epoch 178 Divergences: Uniform: 3.0767814699300806 Unigram: 4.195856140710701
2022-02-02 23:51:47 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 23:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:52:28 | INFO | train_inner | epoch 179:      8 / 64 loss=5.229, ppl=37.51, wps=5710.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.168, train_wall=513, gb_free=6.1, wall=63870
2022-02-02 23:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:57:46 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.276 | ppl 1239.71 | wps 7860.5 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.304
2022-02-02 23:57:46 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 23:57:46 | INFO | train | epoch 179 | loss 5.216 | ppl 37.18 | wps 5819.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.149 | train_wall 329 | gb_free 6.1 | wall 64187
KL Stats: Epoch 179 Divergences: Uniform: 3.0803575890359487 Unigram: 4.204876021602341
2022-02-02 23:57:46 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 23:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:01:34 | INFO | train_inner | epoch 180:     44 / 64 loss=5.209, ppl=36.99, wps=5989.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.158, train_wall=515, gb_free=6.1, wall=64415
2022-02-03 00:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:03:44 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.266 | ppl 1231.48 | wps 7872.2 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.304
2022-02-03 00:03:44 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-03 00:03:44 | INFO | train | epoch 180 | loss 5.212 | ppl 37.06 | wps 5828 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.185 | train_wall 329 | gb_free 6.1 | wall 64545
KL Stats: Epoch 180 Divergences: Uniform: 3.0806331220754664 Unigram: 4.210976132487277
2022-02-03 00:03:44 | INFO | fairseq.trainer | begin training epoch 181
2022-02-03 00:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:09:43 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.262 | ppl 1227.73 | wps 7866.9 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.304
2022-02-03 00:09:43 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-03 00:09:43 | INFO | train | epoch 181 | loss 5.207 | ppl 36.94 | wps 5826.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.209 | train_wall 329 | gb_free 6.1 | wall 64904
KL Stats: Epoch 181 Divergences: Uniform: 3.0856464758905577 Unigram: 4.216141191314074
2022-02-03 00:09:43 | INFO | fairseq.trainer | begin training epoch 182
2022-02-03 00:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:11:06 | INFO | train_inner | epoch 182:     16 / 64 loss=5.211, ppl=37.05, wps=5705.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.207, train_wall=513, gb_free=6.1, wall=64987
2022-02-03 00:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:15:41 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.246 | ppl 1214.65 | wps 7868.6 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.304
2022-02-03 00:15:41 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-03 00:15:41 | INFO | train | epoch 182 | loss 5.202 | ppl 36.82 | wps 5825.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.194 | train_wall 329 | gb_free 6.1 | wall 65262
KL Stats: Epoch 182 Divergences: Uniform: 3.082027015609843 Unigram: 4.2126026678445125
2022-02-03 00:15:41 | INFO | fairseq.trainer | begin training epoch 183
2022-02-03 00:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:20:11 | INFO | train_inner | epoch 183:     52 / 64 loss=5.196, ppl=36.66, wps=5996.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.223, train_wall=515, gb_free=6.1, wall=65532
2022-02-03 00:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:21:39 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.264 | ppl 1229.21 | wps 7892.7 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.304
2022-02-03 00:21:39 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-03 00:21:39 | INFO | train | epoch 183 | loss 5.196 | ppl 36.65 | wps 5835.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.243 | train_wall 329 | gb_free 6.1 | wall 65620
KL Stats: Epoch 183 Divergences: Uniform: 3.08711712560387 Unigram: 4.22699345539159
2022-02-03 00:21:39 | INFO | fairseq.trainer | begin training epoch 184
2022-02-03 00:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:27:38 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.238 | ppl 1207.59 | wps 7859.5 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.304
2022-02-03 00:27:38 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-03 00:27:38 | INFO | train | epoch 184 | loss 5.193 | ppl 36.58 | wps 5821.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.233 | train_wall 329 | gb_free 6.1 | wall 65979
KL Stats: Epoch 184 Divergences: Uniform: 3.087554031935894 Unigram: 4.226675790625046
2022-02-03 00:27:38 | INFO | fairseq.trainer | begin training epoch 185
2022-02-03 00:27:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:29:42 | INFO | train_inner | epoch 185:     24 / 64 loss=5.191, ppl=36.52, wps=5701.2, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.225, train_wall=514, gb_free=6.1, wall=66104
2022-02-03 00:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:33:36 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.229 | ppl 1200.28 | wps 7888.2 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.304
2022-02-03 00:33:36 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-03 00:33:36 | INFO | train | epoch 185 | loss 5.184 | ppl 36.36 | wps 5833.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.208 | train_wall 329 | gb_free 6.1 | wall 66337
KL Stats: Epoch 185 Divergences: Uniform: 3.089405037803328 Unigram: 4.233588203027203
2022-02-03 00:33:36 | INFO | fairseq.trainer | begin training epoch 186
2022-02-03 00:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:38:47 | INFO | train_inner | epoch 186:     60 / 64 loss=5.189, ppl=36.49, wps=6001.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.213, train_wall=514, gb_free=6.1, wall=66648
2022-02-03 00:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:39:34 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.241 | ppl 1210.59 | wps 7889.9 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.304
2022-02-03 00:39:34 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-03 00:39:34 | INFO | train | epoch 186 | loss 5.182 | ppl 36.3 | wps 5830.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.219 | train_wall 329 | gb_free 6.1 | wall 66695
KL Stats: Epoch 186 Divergences: Uniform: 3.084695045968135 Unigram: 4.232192116105392
2022-02-03 00:39:34 | INFO | fairseq.trainer | begin training epoch 187
2022-02-03 00:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:45:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:45:33 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.299 | ppl 1259.72 | wps 7853.7 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.304
2022-02-03 00:45:33 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-03 00:45:33 | INFO | train | epoch 187 | loss 5.178 | ppl 36.2 | wps 5818.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.258 | train_wall 330 | gb_free 6.1 | wall 67054
KL Stats: Epoch 187 Divergences: Uniform: 3.092458897043322 Unigram: 4.24161821971509
2022-02-03 00:45:33 | INFO | fairseq.trainer | begin training epoch 188
2022-02-03 00:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:48:19 | INFO | train_inner | epoch 188:     32 / 64 loss=5.165, ppl=35.88, wps=5697, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.247, train_wall=514, gb_free=6.1, wall=67220
2022-02-03 00:51:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:51:32 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.234 | ppl 1204.63 | wps 7848.5 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.304
2022-02-03 00:51:32 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 00:51:32 | INFO | train | epoch 188 | loss 5.171 | ppl 36.04 | wps 5825.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.237 | train_wall 329 | gb_free 6.1 | wall 67413
KL Stats: Epoch 188 Divergences: Uniform: 3.0901041420311386 Unigram: 4.242007558842103
2022-02-03 00:51:32 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 00:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:57:30 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.264 | ppl 1230.02 | wps 7901.7 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.304
2022-02-03 00:57:30 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 00:57:30 | INFO | train | epoch 189 | loss 5.169 | ppl 35.99 | wps 5824.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.292 | train_wall 329 | gb_free 6.1 | wall 67771
KL Stats: Epoch 189 Divergences: Uniform: 3.0907630566962285 Unigram: 4.249945306587473
2022-02-03 00:57:30 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 00:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:57:51 | INFO | train_inner | epoch 190:      4 / 64 loss=5.181, ppl=36.27, wps=5701, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.28, train_wall=514, gb_free=6.1, wall=67792
2022-02-03 01:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:03:28 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.217 | ppl 1190.31 | wps 7876.6 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.304
2022-02-03 01:03:28 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 01:03:28 | INFO | train | epoch 190 | loss 5.164 | ppl 35.85 | wps 5830.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.255 | train_wall 329 | gb_free 6.1 | wall 68130
KL Stats: Epoch 190 Divergences: Uniform: 3.097877830068535 Unigram: 4.2528817639899055
2022-02-03 01:03:28 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 01:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:06:56 | INFO | train_inner | epoch 191:     40 / 64 loss=5.153, ppl=35.57, wps=5997.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.264, train_wall=515, gb_free=6.1, wall=68337
2022-02-03 01:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:09:27 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.27 | ppl 1234.33 | wps 7886.6 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.304
2022-02-03 01:09:27 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 01:09:27 | INFO | train | epoch 191 | loss 5.159 | ppl 35.73 | wps 5826.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.297 | train_wall 329 | gb_free 6.1 | wall 68488
KL Stats: Epoch 191 Divergences: Uniform: 3.0931137171100627 Unigram: 4.258582676033734
2022-02-03 01:09:27 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 01:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:15:25 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.289 | ppl 1251.35 | wps 7880.6 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.304
2022-02-03 01:15:25 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 01:15:25 | INFO | train | epoch 192 | loss 5.155 | ppl 35.62 | wps 5830.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.258 | train_wall 329 | gb_free 6.1 | wall 68846
KL Stats: Epoch 192 Divergences: Uniform: 3.0901313784701316 Unigram: 4.260013689108018
2022-02-03 01:15:25 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 01:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:16:27 | INFO | train_inner | epoch 193:     12 / 64 loss=5.159, ppl=35.73, wps=5705, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.278, train_wall=513, gb_free=6.1, wall=68908
2022-02-03 01:20:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:21:24 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.255 | ppl 1221.58 | wps 7846.3 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.304
2022-02-03 01:21:24 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 01:21:24 | INFO | train | epoch 193 | loss 5.151 | ppl 35.52 | wps 5823 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.32 | train_wall 329 | gb_free 6.1 | wall 69205
KL Stats: Epoch 193 Divergences: Uniform: 3.094056656452692 Unigram: 4.264697101980752
2022-02-03 01:21:24 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 01:21:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:25:33 | INFO | train_inner | epoch 194:     48 / 64 loss=5.149, ppl=35.49, wps=5992.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.309, train_wall=515, gb_free=6.1, wall=69454
2022-02-03 01:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:27:22 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.255 | ppl 1222.06 | wps 7895 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.304
2022-02-03 01:27:22 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 01:27:22 | INFO | train | epoch 194 | loss 5.146 | ppl 35.42 | wps 5829.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.284 | train_wall 329 | gb_free 6.1 | wall 69563
KL Stats: Epoch 194 Divergences: Uniform: 3.094694492714277 Unigram: 4.272237891786848
2022-02-03 01:27:22 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 01:27:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:33:21 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.263 | ppl 1228.81 | wps 7887.3 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.304
2022-02-03 01:33:21 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 01:33:21 | INFO | train | epoch 195 | loss 5.142 | ppl 35.31 | wps 5824.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.307 | train_wall 329 | gb_free 6.1 | wall 69922
KL Stats: Epoch 195 Divergences: Uniform: 3.0899205007819774 Unigram: 4.267864880856016
2022-02-03 01:33:21 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 01:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:35:04 | INFO | train_inner | epoch 196:     20 / 64 loss=5.143, ppl=35.33, wps=5701.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.304, train_wall=514, gb_free=6.1, wall=70026
2022-02-03 01:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:39:18 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.212 | ppl 1186.09 | wps 7865.5 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.304
2022-02-03 01:39:18 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 01:39:18 | INFO | train | epoch 196 | loss 5.139 | ppl 35.23 | wps 5835.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.31 | train_wall 328 | gb_free 6.1 | wall 70280
KL Stats: Epoch 196 Divergences: Uniform: 3.095455316559664 Unigram: 4.280415531586818
2022-02-03 01:39:18 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 01:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:44:09 | INFO | train_inner | epoch 197:     56 / 64 loss=5.139, ppl=35.24, wps=6003.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.315, train_wall=514, gb_free=6.1, wall=70570
2022-02-03 01:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:45:17 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.258 | ppl 1224.38 | wps 7871.6 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.304
2022-02-03 01:45:17 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 01:45:17 | INFO | train | epoch 197 | loss 5.136 | ppl 35.15 | wps 5832.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.32 | train_wall 329 | gb_free 6.1 | wall 70638
KL Stats: Epoch 197 Divergences: Uniform: 3.096715258747749 Unigram: 4.288931886831285
2022-02-03 01:45:17 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 01:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:51:16 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.264 | ppl 1229.26 | wps 7851.4 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.304
2022-02-03 01:51:16 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 01:51:16 | INFO | train | epoch 198 | loss 5.128 | ppl 34.98 | wps 5813 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.347 | train_wall 330 | gb_free 6.1 | wall 70997
KL Stats: Epoch 198 Divergences: Uniform: 3.095064219823161 Unigram: 4.281971837063657
2022-02-03 01:51:16 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 01:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:53:41 | INFO | train_inner | epoch 199:     28 / 64 loss=5.124, ppl=34.87, wps=5696.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.332, train_wall=514, gb_free=6.1, wall=71142
2022-02-03 01:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:57:15 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.309 | ppl 1268.81 | wps 7830.4 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.304
2022-02-03 01:57:15 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 01:57:15 | INFO | train | epoch 199 | loss 5.125 | ppl 34.89 | wps 5823.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.345 | train_wall 329 | gb_free 6.1 | wall 71356
KL Stats: Epoch 199 Divergences: Uniform: 3.0931649670514116 Unigram: 4.286984068205554
2022-02-03 01:57:15 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 01:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:02:45 | INFO | train_inner | epoch 200:     64 / 64 loss=5.13, ppl=35.01, wps=5988, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.369, train_wall=514, gb_free=6.1, wall=71687
2022-02-03 02:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:03:13 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.279 | ppl 1242.81 | wps 7855.8 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.304
2022-02-03 02:03:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 02:03:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint200.pt
2022-02-03 02:03:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint200.pt
2022-02-03 02:03:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#4/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.279) (writing took 3.1001058192923665 seconds)
2022-02-03 02:03:16 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 02:03:16 | INFO | train | epoch 200 | loss 5.12 | ppl 34.77 | wps 5772.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.364 | train_wall 329 | gb_free 6.1 | wall 71718
KL Stats: Epoch 200 Divergences: Uniform: 3.096177130871437 Unigram: 4.293671230184096
2022-02-03 02:03:16 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 02:03:16 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
