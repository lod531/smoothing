Sender: LSF System <lsfadmin@eu-g3-039>
Subject: Job 207345745: <w103_size_0.03125_fp16_label_smoothing_0.06_#2> in cluster <euler> Done

Job <w103_size_0.03125_fp16_label_smoothing_0.06_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:01:45 2022
Job was executed on host(s) <eu-g3-039>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 14:35:19 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 14:35:19 2022
Terminated at Tue Mar  8 02:44:57 2022
Results reported at Tue Mar  8 02:44:57 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.06 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575622 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   129854.77 sec.
    Max Memory :                                 8196 MB
    Average Memory :                             4612.87 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11804.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                20
    Run time :                                   130178 sec.
    Turnaround time :                            135792 sec.

The output (if any) follows:

2022-03-06 14:35:32 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.06, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 14:35:33 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 14:35:34 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 14:35:34 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 14:35:34 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 14:35:34 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 14:35:34 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 14:35:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 14:35:34 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 14:35:42 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 14:35:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 14:35:42 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 14:35:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 14:35:42 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 14:35:42 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 14:35:42 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 14:35:42 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 14:35:42 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 14:35:42 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 14:35:42 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 14:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:35:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 14:35:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:35:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:36:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 14:37:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 14:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:37:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.434 | nll_loss 15.312 | ppl 40671.8 | wps 47242.2 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 14:37:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 14:37:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:38:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.434) (writing took 3.445010071620345 seconds)
2022-03-06 14:38:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 14:38:00 | INFO | train | epoch 001 | loss 16.558 | nll_loss 16.507 | ppl 93123.6 | wps 24536.8 | ups 0.38 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.943 | loss_scale 4 | train_wall 119 | gb_free 8.8 | wall 139
2022-03-06 14:38:00 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 14:38:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:39:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:40:03 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.04 | nll_loss 13.826 | ppl 14526.3 | wps 47264.1 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 14.04
2022-03-06 14:40:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 14:40:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:40:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 14.04) (writing took 3.437631255015731 seconds)
2022-03-06 14:40:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 14:40:06 | INFO | train | epoch 002 | loss 14.759 | nll_loss 14.594 | ppl 24727.2 | wps 25289.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.115 | loss_scale 4 | train_wall 107 | gb_free 8.8 | wall 264
2022-03-06 14:40:06 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 14:40:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:23 | INFO | train_inner | epoch 003:      7 / 49 loss=15.504, nll_loss=15.386, ppl=42827.2, wps=25060.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.312, loss_scale=4, train_wall=241, gb_free=8.8, wall=281
2022-03-06 14:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:42:08 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.406 | nll_loss 13.155 | ppl 9122.46 | wps 47198.5 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.406
2022-03-06 14:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 14:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.406) (writing took 3.6705755023285747 seconds)
2022-03-06 14:42:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 14:42:12 | INFO | train | epoch 003 | loss 13.856 | nll_loss 13.634 | ppl 12717 | wps 25212.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.339 | loss_scale 4 | train_wall 107 | gb_free 8.8 | wall 390
2022-03-06 14:42:12 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 14:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:44:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:44:14 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.63 | nll_loss 12.325 | ppl 5131.65 | wps 47228.7 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.63
2022-03-06 14:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 14:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:44:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:44:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.63) (writing took 3.6035020081326365 seconds)
2022-03-06 14:44:18 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 14:44:18 | INFO | train | epoch 004 | loss 13.15 | nll_loss 12.884 | ppl 7558.98 | wps 25230.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.17 | loss_scale 8 | train_wall 107 | gb_free 8.8 | wall 516
2022-03-06 14:44:18 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 14:44:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:44:40 | INFO | train_inner | epoch 005:      9 / 49 loss=13.382, nll_loss=13.13, ppl=8963.21, wps=25258.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.221, loss_scale=8, train_wall=218, gb_free=8.8, wall=538
2022-03-06 14:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:46:20 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.88 | nll_loss 11.516 | ppl 2929.34 | wps 47045.3 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.88
2022-03-06 14:46:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 14:46:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:46:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.88) (writing took 3.479184136725962 seconds)
2022-03-06 14:46:24 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 14:46:24 | INFO | train | epoch 005 | loss 12.33 | nll_loss 12.004 | ppl 4107.75 | wps 25250.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.93 | loss_scale 8 | train_wall 107 | gb_free 8.8 | wall 642
2022-03-06 14:46:24 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 14:46:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:48:26 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.281 | nll_loss 10.86 | ppl 1858.42 | wps 47083.6 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.281
2022-03-06 14:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 14:48:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.281) (writing took 3.6650479454547167 seconds)
2022-03-06 14:48:30 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 14:48:30 | INFO | train | epoch 006 | loss 11.617 | nll_loss 11.231 | ppl 2403.53 | wps 25227.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.724 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 768
2022-03-06 14:48:30 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 14:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:48:57 | INFO | train_inner | epoch 007:     11 / 49 loss=11.831, nll_loss=11.463, ppl=2822.81, wps=25269.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.789, loss_scale=16, train_wall=218, gb_free=8.8, wall=795
2022-03-06 14:50:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:50:32 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.896 | nll_loss 10.425 | ppl 1374.69 | wps 47138 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.896
2022-03-06 14:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 14:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:50:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.896) (writing took 3.627281090244651 seconds)
2022-03-06 14:50:36 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 14:50:36 | INFO | train | epoch 007 | loss 11.084 | nll_loss 10.642 | ppl 1597.97 | wps 25218.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.568 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 894
2022-03-06 14:50:36 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 14:50:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:52:38 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.656 | nll_loss 10.146 | ppl 1132.87 | wps 46982.8 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.656
2022-03-06 14:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 14:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.656) (writing took 3.4753226349130273 seconds)
2022-03-06 14:52:42 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 14:52:42 | INFO | train | epoch 008 | loss 10.752 | nll_loss 10.264 | ppl 1229.22 | wps 25242.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.478 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 1020
2022-03-06 14:52:42 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 14:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:53:13 | INFO | train_inner | epoch 009:     13 / 49 loss=10.841, nll_loss=10.365, ppl=1318.45, wps=25265.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.495, loss_scale=16, train_wall=218, gb_free=8.8, wall=1052
2022-03-06 14:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:54:44 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.491 | nll_loss 9.951 | ppl 989.93 | wps 47000.3 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.491
2022-03-06 14:54:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 14:54:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:54:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.491) (writing took 3.6554053146392107 seconds)
2022-03-06 14:54:48 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 14:54:48 | INFO | train | epoch 009 | loss 10.537 | nll_loss 10.014 | ppl 1034.24 | wps 25205.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.47 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 1146
2022-03-06 14:54:48 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 14:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:56:50 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.346 | nll_loss 9.788 | ppl 884.21 | wps 46859.7 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.346
2022-03-06 14:56:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 14:56:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:56:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:56:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.346) (writing took 3.4768951293081045 seconds)
2022-03-06 14:56:54 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 14:56:54 | INFO | train | epoch 010 | loss 10.365 | nll_loss 9.818 | ppl 902.73 | wps 25242.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.493 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 1272
2022-03-06 14:56:54 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 14:56:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:57:30 | INFO | train_inner | epoch 011:     15 / 49 loss=10.4, nll_loss=9.859, ppl=928.38, wps=25260.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.496, loss_scale=32, train_wall=218, gb_free=8.8, wall=1308
2022-03-06 14:58:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:58:56 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.199 | nll_loss 9.626 | ppl 789.91 | wps 47204.3 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 10.199
2022-03-06 14:58:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 14:58:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:58:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:59:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 10.199) (writing took 3.589586009271443 seconds)
2022-03-06 14:59:00 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 14:59:00 | INFO | train | epoch 011 | loss 10.205 | nll_loss 9.64 | ppl 798.11 | wps 25230 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.554 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 1398
2022-03-06 14:59:00 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 14:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:59:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:01:02 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.078 | nll_loss 9.491 | ppl 719.79 | wps 47180.9 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 10.078
2022-03-06 15:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 15:01:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:01:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:01:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 10.078) (writing took 3.4919312139973044 seconds)
2022-03-06 15:01:06 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 15:01:06 | INFO | train | epoch 012 | loss 10.052 | nll_loss 9.472 | ppl 710.11 | wps 24742.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.636 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 1524
2022-03-06 15:01:06 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 15:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:01:49 | INFO | train_inner | epoch 013:     18 / 49 loss=10.077, nll_loss=9.5, ppl=724.05, wps=25046.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.619, loss_scale=32, train_wall=220, gb_free=8.8, wall=1568
2022-03-06 15:03:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:03:08 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.964 | nll_loss 9.369 | ppl 661.08 | wps 47306.2 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.964
2022-03-06 15:03:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 15:03:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:03:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:03:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.964) (writing took 3.6422067806124687 seconds)
2022-03-06 15:03:11 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 15:03:11 | INFO | train | epoch 013 | loss 9.91 | nll_loss 9.317 | ppl 637.93 | wps 25243.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.659 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 1650
2022-03-06 15:03:12 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 15:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:05:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:05:14 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.857 | nll_loss 9.252 | ppl 609.56 | wps 47161.2 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.857
2022-03-06 15:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 15:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:05:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.857) (writing took 3.65029055532068 seconds)
2022-03-06 15:05:17 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 15:05:17 | INFO | train | epoch 014 | loss 9.775 | nll_loss 9.169 | ppl 575.8 | wps 24706.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.702 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 1776
2022-03-06 15:05:17 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 15:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:06:08 | INFO | train_inner | epoch 015:     21 / 49 loss=9.789, nll_loss=9.185, ppl=582.03, wps=25030.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.71, loss_scale=32, train_wall=220, gb_free=8.8, wall=1827
2022-03-06 15:07:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:07:20 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.747 | nll_loss 9.129 | ppl 559.95 | wps 47079.6 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.747
2022-03-06 15:07:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 15:07:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:07:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.747) (writing took 3.5198313212022185 seconds)
2022-03-06 15:07:23 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 15:07:23 | INFO | train | epoch 015 | loss 9.645 | nll_loss 9.027 | ppl 521.51 | wps 25247.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.766 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 1902
2022-03-06 15:07:23 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 15:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:09:26 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.648 | nll_loss 9.015 | ppl 517.36 | wps 47094.8 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.648
2022-03-06 15:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 15:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.648) (writing took 3.626707869581878 seconds)
2022-03-06 15:09:29 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 15:09:29 | INFO | train | epoch 016 | loss 9.518 | nll_loss 8.887 | ppl 473.4 | wps 25226.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.801 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2028
2022-03-06 15:09:29 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 15:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:10:25 | INFO | train_inner | epoch 017:     23 / 49 loss=9.524, nll_loss=8.893, ppl=475.45, wps=25270.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.77, loss_scale=32, train_wall=218, gb_free=8.8, wall=2083
2022-03-06 15:10:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:11:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:11:32 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.555 | nll_loss 8.918 | ppl 483.78 | wps 47456.9 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.555
2022-03-06 15:11:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 15:11:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:11:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:11:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.555) (writing took 3.6459580808877945 seconds)
2022-03-06 15:11:35 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 15:11:35 | INFO | train | epoch 017 | loss 9.395 | nll_loss 8.752 | ppl 431.11 | wps 24711.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.821 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2154
2022-03-06 15:11:35 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 15:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:13:38 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.469 | nll_loss 8.818 | ppl 451.26 | wps 47021 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.469
2022-03-06 15:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 15:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:13:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.469) (writing took 3.4894919488579035 seconds)
2022-03-06 15:13:41 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 15:13:41 | INFO | train | epoch 018 | loss 9.277 | nll_loss 8.622 | ppl 394.03 | wps 25241.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.844 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2279
2022-03-06 15:13:41 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 15:13:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:14:44 | INFO | train_inner | epoch 019:     26 / 49 loss=9.276, nll_loss=8.621, ppl=393.73, wps=25036.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.867, loss_scale=32, train_wall=220, gb_free=8.8, wall=2342
2022-03-06 15:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:15:44 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.385 | nll_loss 8.722 | ppl 422.23 | wps 47200 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.385
2022-03-06 15:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 15:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.385) (writing took 3.5722633050754666 seconds)
2022-03-06 15:15:47 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 15:15:47 | INFO | train | epoch 019 | loss 9.165 | nll_loss 8.499 | ppl 361.72 | wps 25245.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.919 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2405
2022-03-06 15:15:47 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 15:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:16:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:17:49 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.332 | nll_loss 8.677 | ppl 409.3 | wps 46496.4 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.332
2022-03-06 15:17:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 15:17:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:17:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.332) (writing took 3.646265326999128 seconds)
2022-03-06 15:17:53 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 15:17:53 | INFO | train | epoch 020 | loss 9.054 | nll_loss 8.377 | ppl 332.44 | wps 24707.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.838 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2531
2022-03-06 15:17:53 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 15:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:19:03 | INFO | train_inner | epoch 021:     29 / 49 loss=9.048, nll_loss=8.371, ppl=330.97, wps=25028.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.878, loss_scale=32, train_wall=220, gb_free=8.8, wall=2602
2022-03-06 15:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:19:55 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.261 | nll_loss 8.584 | ppl 383.82 | wps 46983.1 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.261
2022-03-06 15:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 15:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:19:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.261) (writing took 3.45221552811563 seconds)
2022-03-06 15:19:59 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 15:19:59 | INFO | train | epoch 021 | loss 8.949 | nll_loss 8.262 | ppl 306.94 | wps 25244 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.878 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2657
2022-03-06 15:19:59 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 15:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:21:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:22:01 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.201 | nll_loss 8.521 | ppl 367.23 | wps 46931.8 | wpb 510.9 | bsz 1 | num_updates 1068 | best_loss 9.201
2022-03-06 15:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1068 updates
2022-03-06 15:22:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:22:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:22:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 22 @ 1068 updates, score 9.201) (writing took 3.5962841790169477 seconds)
2022-03-06 15:22:05 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 15:22:05 | INFO | train | epoch 022 | loss 8.847 | nll_loss 8.15 | ppl 283.99 | wps 24703.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 1068 | lr 0.000133573 | gnorm 0.91 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2783
2022-03-06 15:22:05 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 15:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:23:23 | INFO | train_inner | epoch 023:     32 / 49 loss=8.833, nll_loss=8.134, ppl=280.96, wps=25032.8, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.899, loss_scale=32, train_wall=220, gb_free=8.8, wall=2861
2022-03-06 15:24:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:24:07 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.165 | nll_loss 8.479 | ppl 356.71 | wps 46523.8 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 9.165
2022-03-06 15:24:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 15:24:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:24:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 9.165) (writing took 3.5853492682799697 seconds)
2022-03-06 15:24:11 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 15:24:11 | INFO | train | epoch 023 | loss 8.749 | nll_loss 8.042 | ppl 263.62 | wps 25217.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.947 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 2909
2022-03-06 15:24:11 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 15:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:26:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:26:13 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.1 | nll_loss 8.406 | ppl 339.09 | wps 47000.5 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 9.1
2022-03-06 15:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 15:26:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 9.1) (writing took 3.488852273672819 seconds)
2022-03-06 15:26:17 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 15:26:17 | INFO | train | epoch 024 | loss 8.649 | nll_loss 7.933 | ppl 244.33 | wps 25242.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.879 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 3035
2022-03-06 15:26:17 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 15:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:27:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:27:42 | INFO | train_inner | epoch 025:     35 / 49 loss=8.634, nll_loss=7.916, ppl=241.48, wps=25026.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.924, loss_scale=32, train_wall=220, gb_free=8.8, wall=3120
2022-03-06 15:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:28:19 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.046 | nll_loss 8.342 | ppl 324.49 | wps 47069.2 | wpb 510.9 | bsz 1 | num_updates 1214 | best_loss 9.046
2022-03-06 15:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1214 updates
2022-03-06 15:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:28:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 25 @ 1214 updates, score 9.046) (writing took 3.641578460112214 seconds)
2022-03-06 15:28:23 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 15:28:23 | INFO | train | epoch 025 | loss 8.555 | nll_loss 7.829 | ppl 227.41 | wps 24689.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 1214 | lr 0.00015182 | gnorm 0.902 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 3161
2022-03-06 15:28:23 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 15:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:30:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:30:25 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.009 | nll_loss 8.3 | ppl 315.19 | wps 47245.1 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 9.009
2022-03-06 15:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 15:30:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:30:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:30:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 9.009) (writing took 3.46875986084342 seconds)
2022-03-06 15:30:29 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 15:30:29 | INFO | train | epoch 026 | loss 8.462 | nll_loss 7.726 | ppl 211.77 | wps 25254 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 0.961 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 3287
2022-03-06 15:30:29 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 15:30:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:31:59 | INFO | train_inner | epoch 027:     37 / 49 loss=8.439, nll_loss=7.702, ppl=208.17, wps=25255.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.928, loss_scale=32, train_wall=218, gb_free=8.8, wall=3377
2022-03-06 15:32:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:32:31 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.956 | nll_loss 8.241 | ppl 302.57 | wps 47260.7 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.956
2022-03-06 15:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 15:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:32:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.956) (writing took 3.6122175762429833 seconds)
2022-03-06 15:32:35 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 15:32:35 | INFO | train | epoch 027 | loss 8.366 | nll_loss 7.621 | ppl 196.83 | wps 25204.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.929 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 3413
2022-03-06 15:32:35 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 15:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:33:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:34:37 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.918 | nll_loss 8.19 | ppl 292.12 | wps 47159.3 | wpb 510.9 | bsz 1 | num_updates 1360 | best_loss 8.918
2022-03-06 15:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1360 updates
2022-03-06 15:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:34:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 28 @ 1360 updates, score 8.918) (writing took 3.624974894337356 seconds)
2022-03-06 15:34:41 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:34:41 | INFO | train | epoch 028 | loss 8.273 | nll_loss 7.519 | ppl 183.37 | wps 24706 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 1360 | lr 0.000170066 | gnorm 0.951 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 3539
2022-03-06 15:34:41 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:36:18 | INFO | train_inner | epoch 029:     40 / 49 loss=8.244, nll_loss=7.487, ppl=179.39, wps=25025.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.939, loss_scale=32, train_wall=220, gb_free=8.8, wall=3636
2022-03-06 15:36:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:36:43 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.881 | nll_loss 8.141 | ppl 282.37 | wps 47102 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.881
2022-03-06 15:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 15:36:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:36:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:36:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.881) (writing took 3.4759846096858382 seconds)
2022-03-06 15:36:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:36:47 | INFO | train | epoch 029 | loss 8.177 | nll_loss 7.414 | ppl 170.5 | wps 25251.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.925 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 3665
2022-03-06 15:36:47 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:36:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:38:49 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.846 | nll_loss 8.104 | ppl 275.16 | wps 47131.8 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.846
2022-03-06 15:38:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 15:38:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:38:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.846) (writing took 3.6084955586120486 seconds)
2022-03-06 15:38:53 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:38:53 | INFO | train | epoch 030 | loss 8.083 | nll_loss 7.311 | ppl 158.76 | wps 25241.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.959 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 3791
2022-03-06 15:38:53 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:39:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:40:37 | INFO | train_inner | epoch 031:     43 / 49 loss=8.049, nll_loss=7.273, ppl=154.7, wps=25039.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.951, loss_scale=32, train_wall=220, gb_free=8.8, wall=3895
2022-03-06 15:40:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:40:55 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.822 | nll_loss 8.071 | ppl 268.91 | wps 47016.1 | wpb 510.9 | bsz 1 | num_updates 1506 | best_loss 8.822
2022-03-06 15:40:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1506 updates
2022-03-06 15:40:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:40:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 31 @ 1506 updates, score 8.822) (writing took 3.5179094346240163 seconds)
2022-03-06 15:40:59 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:40:59 | INFO | train | epoch 031 | loss 7.987 | nll_loss 7.205 | ppl 147.57 | wps 24718.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 1506 | lr 0.000188312 | gnorm 0.956 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 3917
2022-03-06 15:40:59 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:43:01 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.802 | nll_loss 8.055 | ppl 265.89 | wps 46985 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.802
2022-03-06 15:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 15:43:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:43:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 8.802) (writing took 3.5981980431824923 seconds)
2022-03-06 15:43:05 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:43:05 | INFO | train | epoch 032 | loss 7.896 | nll_loss 7.104 | ppl 137.6 | wps 25212.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 0.971 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 4043
2022-03-06 15:43:05 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:44:54 | INFO | train_inner | epoch 033:     45 / 49 loss=7.857, nll_loss=7.062, ppl=133.59, wps=25255.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.957, loss_scale=32, train_wall=218, gb_free=8.8, wall=4152
2022-03-06 15:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:45:07 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.771 | nll_loss 8.019 | ppl 259.4 | wps 47281.4 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.771
2022-03-06 15:45:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 15:45:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:45:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:45:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.771) (writing took 3.677893338724971 seconds)
2022-03-06 15:45:11 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:45:11 | INFO | train | epoch 033 | loss 7.798 | nll_loss 6.998 | ppl 127.8 | wps 25200.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.938 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 4169
2022-03-06 15:45:11 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:45:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:47:13 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.758 | nll_loss 8.006 | ppl 257.09 | wps 46944.9 | wpb 510.9 | bsz 1 | num_updates 1652 | best_loss 8.758
2022-03-06 15:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1652 updates
2022-03-06 15:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:47:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 34 @ 1652 updates, score 8.758) (writing took 3.5031223576515913 seconds)
2022-03-06 15:47:17 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:47:17 | INFO | train | epoch 034 | loss 7.708 | nll_loss 6.898 | ppl 119.26 | wps 24707.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 1652 | lr 0.000206559 | gnorm 1.005 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 4295
2022-03-06 15:47:17 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:47:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:49:13 | INFO | train_inner | epoch 035:     48 / 49 loss=7.667, nll_loss=6.852, ppl=115.55, wps=25021.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.987, loss_scale=32, train_wall=220, gb_free=8.8, wall=4411
2022-03-06 15:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:49:19 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.772 | nll_loss 8.008 | ppl 257.44 | wps 46976.9 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.758
2022-03-06 15:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 15:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 35 @ 1701 updates, score 8.772) (writing took 1.6086707403883338 seconds)
2022-03-06 15:49:21 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:49:21 | INFO | train | epoch 035 | loss 7.616 | nll_loss 6.797 | ppl 111.17 | wps 25638.8 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 0.965 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 4419
2022-03-06 15:49:21 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:51:23 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.743 | nll_loss 7.985 | ppl 253.29 | wps 47250.2 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.743
2022-03-06 15:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 15:51:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.743) (writing took 3.670691949315369 seconds)
2022-03-06 15:51:27 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:51:27 | INFO | train | epoch 036 | loss 7.524 | nll_loss 6.696 | ppl 103.66 | wps 25211.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 1.031 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 4545
2022-03-06 15:51:27 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:52:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:53:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:53:29 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.728 | nll_loss 7.957 | ppl 248.55 | wps 47225.6 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.728
2022-03-06 15:53:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 15:53:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:53:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 37 @ 1798 updates, score 8.728) (writing took 3.476460037752986 seconds)
2022-03-06 15:53:33 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:53:33 | INFO | train | epoch 037 | loss 7.433 | nll_loss 6.595 | ppl 96.68 | wps 24732 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 1.031 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 4671
2022-03-06 15:53:33 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:53:37 | INFO | train_inner | epoch 038:      2 / 49 loss=7.477, nll_loss=6.644, ppl=100.01, wps=24413.3, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.029, loss_scale=32, train_wall=219, gb_free=8.8, wall=4676
2022-03-06 15:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:55:35 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.746 | nll_loss 7.973 | ppl 251.24 | wps 47376.3 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.728
2022-03-06 15:55:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 15:55:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.746) (writing took 1.5766618996858597 seconds)
2022-03-06 15:55:37 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:55:37 | INFO | train | epoch 038 | loss 7.345 | nll_loss 6.498 | ppl 90.39 | wps 25628.3 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 1.022 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 4795
2022-03-06 15:55:37 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:57:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:57:39 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.725 | nll_loss 7.946 | ppl 246.56 | wps 46995.7 | wpb 510.9 | bsz 1 | num_updates 1895 | best_loss 8.725
2022-03-06 15:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1895 updates
2022-03-06 15:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 15:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 39 @ 1895 updates, score 8.725) (writing took 3.4626000793650746 seconds)
2022-03-06 15:57:42 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:57:42 | INFO | train | epoch 039 | loss 7.253 | nll_loss 6.397 | ppl 84.27 | wps 24754.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 1895 | lr 0.000236928 | gnorm 1.023 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 4921
2022-03-06 15:57:42 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:57:55 | INFO | train_inner | epoch 040:      5 / 49 loss=7.291, nll_loss=6.439, ppl=86.74, wps=25238.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.025, loss_scale=32, train_wall=220, gb_free=8.8, wall=4933
2022-03-06 15:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:59:45 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.749 | nll_loss 7.975 | ppl 251.57 | wps 47063.4 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.725
2022-03-06 15:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 15:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:59:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:59:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.749) (writing took 1.6147460592910647 seconds)
2022-03-06 15:59:46 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 15:59:46 | INFO | train | epoch 040 | loss 7.17 | nll_loss 6.305 | ppl 79.08 | wps 25613.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.061 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 5045
2022-03-06 15:59:46 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 15:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:01:49 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.753 | nll_loss 7.966 | ppl 249.97 | wps 47060.2 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.725
2022-03-06 16:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 16:01:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:01:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:01:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.753) (writing took 1.5884497482329607 seconds)
2022-03-06 16:01:50 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:01:50 | INFO | train | epoch 041 | loss 7.081 | nll_loss 6.207 | ppl 73.87 | wps 25617.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.039 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 5169
2022-03-06 16:01:50 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:01:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:02:08 | INFO | train_inner | epoch 042:      7 / 49 loss=7.116, nll_loss=6.245, ppl=75.84, wps=25644.6, ups=0.4, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.07, loss_scale=32, train_wall=218, gb_free=8.8, wall=5186
2022-03-06 16:03:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:03:53 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.817 | nll_loss 8.05 | ppl 265 | wps 46950 | wpb 510.9 | bsz 1 | num_updates 2041 | best_loss 8.725
2022-03-06 16:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2041 updates
2022-03-06 16:03:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 42 @ 2041 updates, score 8.817) (writing took 1.6379603957757354 seconds)
2022-03-06 16:03:55 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:03:55 | INFO | train | epoch 042 | loss 6.997 | nll_loss 6.113 | ppl 69.24 | wps 25074.2 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 2041 | lr 0.000255174 | gnorm 1.1 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 5293
2022-03-06 16:03:55 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:05:57 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.841 | nll_loss 8.076 | ppl 269.83 | wps 47124.4 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.725
2022-03-06 16:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-06 16:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 43 @ 2090 updates, score 8.841) (writing took 1.5859320936724544 seconds)
2022-03-06 16:05:59 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:05:59 | INFO | train | epoch 043 | loss 6.911 | nll_loss 6.019 | ppl 64.83 | wps 25635.6 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.076 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 5417
2022-03-06 16:05:59 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:06:23 | INFO | train_inner | epoch 044:     10 / 49 loss=6.936, nll_loss=6.046, ppl=66.09, wps=25403.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.066, loss_scale=32, train_wall=220, gb_free=8.8, wall=5441
2022-03-06 16:07:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:08:01 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.848 | nll_loss 8.076 | ppl 269.83 | wps 47034.2 | wpb 510.9 | bsz 1 | num_updates 2138 | best_loss 8.725
2022-03-06 16:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2138 updates
2022-03-06 16:08:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:08:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 44 @ 2138 updates, score 8.848) (writing took 1.6361716538667679 seconds)
2022-03-06 16:08:03 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:08:03 | INFO | train | epoch 044 | loss 6.825 | nll_loss 5.924 | ppl 60.72 | wps 25092.2 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 2138 | lr 0.000267297 | gnorm 1.12 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 5541
2022-03-06 16:08:03 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:10:05 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.863 | nll_loss 8.088 | ppl 272.1 | wps 47372.4 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.725
2022-03-06 16:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-06 16:10:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:10:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:10:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 45 @ 2187 updates, score 8.863) (writing took 1.6487347483634949 seconds)
2022-03-06 16:10:07 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:10:07 | INFO | train | epoch 045 | loss 6.739 | nll_loss 5.829 | ppl 56.83 | wps 25630.2 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.066 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 5665
2022-03-06 16:10:07 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:10:38 | INFO | train_inner | epoch 046:     13 / 49 loss=6.758, nll_loss=5.85, ppl=57.69, wps=25402.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.089, loss_scale=16, train_wall=220, gb_free=8.8, wall=5696
2022-03-06 16:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:12:09 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.909 | nll_loss 8.144 | ppl 282.95 | wps 46912.6 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.725
2022-03-06 16:12:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 16:12:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:12:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:12:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 46 @ 2236 updates, score 8.909) (writing took 1.5908541893586516 seconds)
2022-03-06 16:12:11 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:12:11 | INFO | train | epoch 046 | loss 6.657 | nll_loss 5.738 | ppl 53.36 | wps 25601.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.119 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 5789
2022-03-06 16:12:11 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:14:13 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.916 | nll_loss 8.139 | ppl 281.91 | wps 47221.1 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.725
2022-03-06 16:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 16:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:14:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 47 @ 2285 updates, score 8.916) (writing took 1.6077061435207725 seconds)
2022-03-06 16:14:15 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:14:15 | INFO | train | epoch 047 | loss 6.57 | nll_loss 5.642 | ppl 49.92 | wps 25620.2 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.149 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 5913
2022-03-06 16:14:15 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:14:51 | INFO | train_inner | epoch 048:     15 / 49 loss=6.589, nll_loss=5.662, ppl=50.65, wps=25640.8, ups=0.4, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.144, loss_scale=32, train_wall=218, gb_free=8.8, wall=5949
2022-03-06 16:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:16:17 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.958 | nll_loss 8.184 | ppl 290.91 | wps 46840.8 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 8.725
2022-03-06 16:16:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-06 16:16:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 48 @ 2334 updates, score 8.958) (writing took 1.5777845084667206 seconds)
2022-03-06 16:16:19 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:16:19 | INFO | train | epoch 048 | loss 6.486 | nll_loss 5.549 | ppl 46.81 | wps 25601.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.169 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 6037
2022-03-06 16:16:19 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:18:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:18:21 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.997 | nll_loss 8.222 | ppl 298.63 | wps 46809.8 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 8.725
2022-03-06 16:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-06 16:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 49 @ 2382 updates, score 8.997) (writing took 1.6068746000528336 seconds)
2022-03-06 16:18:23 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:18:23 | INFO | train | epoch 049 | loss 6.401 | nll_loss 5.454 | ppl 43.85 | wps 25080.1 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.177 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 6161
2022-03-06 16:18:23 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:19:07 | INFO | train_inner | epoch 050:     18 / 49 loss=6.414, nll_loss=5.469, ppl=44.31, wps=25382.8, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.168, loss_scale=32, train_wall=220, gb_free=8.8, wall=6205
2022-03-06 16:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:20:26 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.047 | nll_loss 8.278 | ppl 310.43 | wps 47019.3 | wpb 510.9 | bsz 1 | num_updates 2431 | best_loss 8.725
2022-03-06 16:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2431 updates
2022-03-06 16:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 50 @ 2431 updates, score 9.047) (writing took 1.5927709452807903 seconds)
2022-03-06 16:20:27 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:20:27 | INFO | train | epoch 050 | loss 6.319 | nll_loss 5.364 | ppl 41.18 | wps 25603.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2431 | lr 0.000303914 | gnorm 1.212 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 6285
2022-03-06 16:20:27 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:22:32 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.08 | nll_loss 8.293 | ppl 313.65 | wps 43865.9 | wpb 510.9 | bsz 1 | num_updates 2480 | best_loss 8.725
2022-03-06 16:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2480 updates
2022-03-06 16:22:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:22:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:22:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 51 @ 2480 updates, score 9.08) (writing took 1.9089079508557916 seconds)
2022-03-06 16:22:34 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:22:34 | INFO | train | epoch 051 | loss 6.237 | nll_loss 5.272 | ppl 38.64 | wps 25018.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2480 | lr 0.000310038 | gnorm 1.205 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 6412
2022-03-06 16:22:34 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:23:24 | INFO | train_inner | epoch 052:     20 / 49 loss=6.247, nll_loss=5.283, ppl=38.94, wps=25267.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.231, loss_scale=32, train_wall=221, gb_free=8.8, wall=6462
2022-03-06 16:23:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:24:39 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.103 | nll_loss 8.32 | ppl 319.6 | wps 44249.1 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.725
2022-03-06 16:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-06 16:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 52 @ 2528 updates, score 9.103) (writing took 1.9321593092754483 seconds)
2022-03-06 16:24:41 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:24:41 | INFO | train | epoch 052 | loss 6.152 | nll_loss 5.179 | ppl 36.22 | wps 24566.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.204 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 6539
2022-03-06 16:24:41 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:25:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:26:46 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.143 | nll_loss 8.372 | ppl 331.41 | wps 44303.5 | wpb 510.9 | bsz 1 | num_updates 2576 | best_loss 8.725
2022-03-06 16:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2576 updates
2022-03-06 16:26:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:26:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:26:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 53 @ 2576 updates, score 9.143) (writing took 1.7815614230930805 seconds)
2022-03-06 16:26:47 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 16:26:47 | INFO | train | epoch 053 | loss 6.074 | nll_loss 5.091 | ppl 34.09 | wps 24588.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2576 | lr 0.000322036 | gnorm 1.239 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 6666
2022-03-06 16:26:47 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 16:26:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:27:47 | INFO | train_inner | epoch 054:     24 / 49 loss=6.078, nll_loss=5.095, ppl=34.18, wps=24646.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.268, loss_scale=16, train_wall=226, gb_free=8.8, wall=6725
2022-03-06 16:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:28:52 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.193 | nll_loss 8.409 | ppl 340.02 | wps 44098.9 | wpb 510.9 | bsz 1 | num_updates 2625 | best_loss 8.725
2022-03-06 16:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2625 updates
2022-03-06 16:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 54 @ 2625 updates, score 9.193) (writing took 1.9520176639780402 seconds)
2022-03-06 16:28:54 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 16:28:54 | INFO | train | epoch 054 | loss 5.999 | nll_loss 5.008 | ppl 32.17 | wps 25069.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2625 | lr 0.000328159 | gnorm 1.296 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 6792
2022-03-06 16:28:54 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 16:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:30:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:30:59 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.281 | nll_loss 8.525 | ppl 368.39 | wps 44193.8 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.725
2022-03-06 16:30:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-06 16:30:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:31:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:31:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 55 @ 2674 updates, score 9.281) (writing took 1.7318554958328605 seconds)
2022-03-06 16:31:01 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 16:31:01 | INFO | train | epoch 055 | loss 5.913 | nll_loss 4.912 | ppl 30.11 | wps 25121.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.269 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 6919
2022-03-06 16:31:01 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 16:31:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:32:05 | INFO | train_inner | epoch 056:     26 / 49 loss=5.912, nll_loss=4.911, ppl=30.1, wps=25121.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.227, loss_scale=32, train_wall=221, gb_free=8.8, wall=6983
2022-03-06 16:32:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:33:05 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.29 | nll_loss 8.499 | ppl 361.79 | wps 44112.2 | wpb 510.9 | bsz 1 | num_updates 2722 | best_loss 8.725
2022-03-06 16:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2722 updates
2022-03-06 16:33:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 56 @ 2722 updates, score 9.29) (writing took 1.7415155693888664 seconds)
2022-03-06 16:33:07 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 16:33:07 | INFO | train | epoch 056 | loss 5.829 | nll_loss 4.819 | ppl 28.23 | wps 24603.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2722 | lr 0.000340282 | gnorm 1.218 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7045
2022-03-06 16:33:07 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 16:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:35:12 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.358 | nll_loss 8.557 | ppl 376.72 | wps 44147.7 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.725
2022-03-06 16:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-06 16:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 57 @ 2771 updates, score 9.358) (writing took 1.916920030489564 seconds)
2022-03-06 16:35:14 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 16:35:14 | INFO | train | epoch 057 | loss 5.755 | nll_loss 4.735 | ppl 26.64 | wps 25086.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.36 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7172
2022-03-06 16:35:14 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 16:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:36:26 | INFO | train_inner | epoch 058:     29 / 49 loss=5.744, nll_loss=4.724, ppl=26.43, wps=24901.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.306, loss_scale=16, train_wall=224, gb_free=8.8, wall=7244
2022-03-06 16:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:37:19 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.404 | nll_loss 8.616 | ppl 392.4 | wps 44115.4 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.725
2022-03-06 16:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-06 16:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 58 @ 2820 updates, score 9.404) (writing took 1.8874209430068731 seconds)
2022-03-06 16:37:21 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 16:37:21 | INFO | train | epoch 058 | loss 5.675 | nll_loss 4.646 | ppl 25.04 | wps 25088.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.313 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7299
2022-03-06 16:37:21 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 16:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:39:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:39:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:39:25 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.46 | nll_loss 8.657 | ppl 403.73 | wps 44296.9 | wpb 510.9 | bsz 1 | num_updates 2868 | best_loss 8.725
2022-03-06 16:39:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2868 updates
2022-03-06 16:39:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:39:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 59 @ 2868 updates, score 9.46) (writing took 1.8481027679517865 seconds)
2022-03-06 16:39:27 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 16:39:27 | INFO | train | epoch 059 | loss 5.59 | nll_loss 4.552 | ppl 23.46 | wps 24609.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2868 | lr 0.000358528 | gnorm 1.292 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7425
2022-03-06 16:39:27 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 16:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:40:46 | INFO | train_inner | epoch 060:     32 / 49 loss=5.584, nll_loss=4.545, ppl=23.34, wps=24890.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.328, loss_scale=16, train_wall=224, gb_free=8.8, wall=7504
2022-03-06 16:41:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:41:33 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.535 | nll_loss 8.753 | ppl 431.37 | wps 43952.6 | wpb 510.9 | bsz 1 | num_updates 2917 | best_loss 8.725
2022-03-06 16:41:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2917 updates
2022-03-06 16:41:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:41:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 60 @ 2917 updates, score 9.535) (writing took 1.8883290151134133 seconds)
2022-03-06 16:41:35 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 16:41:35 | INFO | train | epoch 060 | loss 5.514 | nll_loss 4.467 | ppl 22.11 | wps 24931 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2917 | lr 0.000364652 | gnorm 1.321 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7553
2022-03-06 16:41:35 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 16:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:43:39 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.589 | nll_loss 8.795 | ppl 444.26 | wps 43372.6 | wpb 510.9 | bsz 1 | num_updates 2966 | best_loss 8.725
2022-03-06 16:43:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2966 updates
2022-03-06 16:43:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:43:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:43:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 61 @ 2966 updates, score 9.589) (writing took 1.9876357931643724 seconds)
2022-03-06 16:43:41 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 16:43:41 | INFO | train | epoch 061 | loss 5.439 | nll_loss 4.383 | ppl 20.86 | wps 25045.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2966 | lr 0.000370776 | gnorm 1.386 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7680
2022-03-06 16:43:41 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 16:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:45:06 | INFO | train_inner | epoch 062:     34 / 49 loss=5.419, nll_loss=4.361, ppl=20.54, wps=25002.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.343, loss_scale=32, train_wall=222, gb_free=8.8, wall=7764
2022-03-06 16:45:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:45:46 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.652 | nll_loss 8.85 | ppl 461.54 | wps 43763.6 | wpb 510.9 | bsz 1 | num_updates 3014 | best_loss 8.725
2022-03-06 16:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3014 updates
2022-03-06 16:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:45:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:45:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 62 @ 3014 updates, score 9.652) (writing took 2.0043013487011194 seconds)
2022-03-06 16:45:48 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 16:45:48 | INFO | train | epoch 062 | loss 5.354 | nll_loss 4.287 | ppl 19.53 | wps 24499.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3014 | lr 0.000376775 | gnorm 1.347 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 7807
2022-03-06 16:45:48 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 16:45:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:47:53 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.694 | nll_loss 8.903 | ppl 478.83 | wps 43958.8 | wpb 510.9 | bsz 1 | num_updates 3063 | best_loss 8.725
2022-03-06 16:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3063 updates
2022-03-06 16:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 63 @ 3063 updates, score 9.694) (writing took 1.9444519504904747 seconds)
2022-03-06 16:47:55 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 16:47:55 | INFO | train | epoch 063 | loss 5.283 | nll_loss 4.207 | ppl 18.47 | wps 25065.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3063 | lr 0.000382898 | gnorm 1.397 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7933
2022-03-06 16:47:55 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 16:47:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:49:27 | INFO | train_inner | epoch 064:     37 / 49 loss=5.267, nll_loss=4.19, ppl=18.25, wps=24840.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.392, loss_scale=16, train_wall=224, gb_free=8.8, wall=8025
2022-03-06 16:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:50:00 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.748 | nll_loss 8.958 | ppl 497.43 | wps 43825 | wpb 510.9 | bsz 1 | num_updates 3112 | best_loss 8.725
2022-03-06 16:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3112 updates
2022-03-06 16:50:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:50:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:50:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 64 @ 3112 updates, score 9.748) (writing took 1.9538695877417922 seconds)
2022-03-06 16:50:02 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 16:50:02 | INFO | train | epoch 064 | loss 5.205 | nll_loss 4.12 | ppl 17.39 | wps 25035.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3112 | lr 0.000389022 | gnorm 1.373 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8060
2022-03-06 16:50:02 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 16:50:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:51:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:52:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:52:07 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.799 | nll_loss 9.023 | ppl 520.1 | wps 44092.3 | wpb 510.9 | bsz 1 | num_updates 3160 | best_loss 8.725
2022-03-06 16:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3160 updates
2022-03-06 16:52:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:52:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:52:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 65 @ 3160 updates, score 9.799) (writing took 1.9766836576163769 seconds)
2022-03-06 16:52:09 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 16:52:09 | INFO | train | epoch 065 | loss 5.125 | nll_loss 4.031 | ppl 16.35 | wps 24540.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3160 | lr 0.000395021 | gnorm 1.368 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8187
2022-03-06 16:52:09 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 16:52:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:53:48 | INFO | train_inner | epoch 066:     40 / 49 loss=5.112, nll_loss=4.016, ppl=16.18, wps=24840.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.44, loss_scale=16, train_wall=224, gb_free=8.8, wall=8286
2022-03-06 16:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:54:14 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.881 | nll_loss 9.091 | ppl 545.44 | wps 44193.3 | wpb 510.9 | bsz 1 | num_updates 3209 | best_loss 8.725
2022-03-06 16:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3209 updates
2022-03-06 16:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:54:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:54:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 66 @ 3209 updates, score 9.881) (writing took 2.05059075076133 seconds)
2022-03-06 16:54:16 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 16:54:16 | INFO | train | epoch 066 | loss 5.073 | nll_loss 3.971 | ppl 15.68 | wps 25037.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3209 | lr 0.000401145 | gnorm 1.515 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8314
2022-03-06 16:54:16 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 16:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:56:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:56:21 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.897 | nll_loss 9.102 | ppl 549.41 | wps 44257.7 | wpb 510.9 | bsz 1 | num_updates 3258 | best_loss 8.725
2022-03-06 16:56:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3258 updates
2022-03-06 16:56:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:56:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 67 @ 3258 updates, score 9.897) (writing took 2.1440100139006972 seconds)
2022-03-06 16:56:23 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 16:56:23 | INFO | train | epoch 067 | loss 4.979 | nll_loss 3.867 | ppl 14.59 | wps 25028.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3258 | lr 0.000407269 | gnorm 1.355 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 8441
2022-03-06 16:56:23 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 16:56:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:58:09 | INFO | train_inner | epoch 068:     43 / 49 loss=4.957, nll_loss=3.842, ppl=14.34, wps=24850.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.387, loss_scale=16, train_wall=224, gb_free=8.8, wall=8547
2022-03-06 16:58:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:58:27 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.941 | nll_loss 9.139 | ppl 563.59 | wps 44426 | wpb 510.9 | bsz 1 | num_updates 3306 | best_loss 8.725
2022-03-06 16:58:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3306 updates
2022-03-06 16:58:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:58:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:58:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 68 @ 3306 updates, score 9.941) (writing took 1.844309507869184 seconds)
2022-03-06 16:58:29 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 16:58:29 | INFO | train | epoch 068 | loss 4.904 | nll_loss 3.781 | ppl 13.75 | wps 24630.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3306 | lr 0.000413267 | gnorm 1.426 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8568
2022-03-06 16:58:29 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 16:58:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:00:34 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.049 | nll_loss 9.265 | ppl 615.2 | wps 44419.9 | wpb 510.9 | bsz 1 | num_updates 3355 | best_loss 8.725
2022-03-06 17:00:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3355 updates
2022-03-06 17:00:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:00:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:00:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 69 @ 3355 updates, score 10.049) (writing took 1.8871214427053928 seconds)
2022-03-06 17:00:36 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 17:00:36 | INFO | train | epoch 069 | loss 4.834 | nll_loss 3.703 | ppl 13.02 | wps 25152.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3355 | lr 0.000419391 | gnorm 1.398 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8694
2022-03-06 17:00:36 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 17:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:02:27 | INFO | train_inner | epoch 070:     45 / 49 loss=4.807, nll_loss=3.673, ppl=12.75, wps=25179.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.426, loss_scale=16, train_wall=221, gb_free=8.8, wall=8805
2022-03-06 17:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:02:40 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.155 | nll_loss 9.378 | ppl 665.31 | wps 44628.8 | wpb 510.9 | bsz 1 | num_updates 3404 | best_loss 8.725
2022-03-06 17:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3404 updates
2022-03-06 17:02:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 70 @ 3404 updates, score 10.155) (writing took 1.8896575327962637 seconds)
2022-03-06 17:02:42 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 17:02:42 | INFO | train | epoch 070 | loss 4.767 | nll_loss 3.627 | ppl 12.35 | wps 25146.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3404 | lr 0.000425515 | gnorm 1.449 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8820
2022-03-06 17:02:42 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 17:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:03:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:04:46 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.208 | nll_loss 9.426 | ppl 687.65 | wps 44423.6 | wpb 510.9 | bsz 1 | num_updates 3452 | best_loss 8.725
2022-03-06 17:04:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3452 updates
2022-03-06 17:04:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 71 @ 3452 updates, score 10.208) (writing took 1.9712994880974293 seconds)
2022-03-06 17:04:48 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 17:04:48 | INFO | train | epoch 071 | loss 4.698 | nll_loss 3.549 | ppl 11.71 | wps 24655.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3452 | lr 0.000431514 | gnorm 1.534 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8946
2022-03-06 17:04:48 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 17:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:06:47 | INFO | train_inner | epoch 072:     48 / 49 loss=4.662, nll_loss=3.509, ppl=11.38, wps=24956.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.454, loss_scale=16, train_wall=223, gb_free=8.8, wall=9065
2022-03-06 17:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:06:53 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.279 | nll_loss 9.489 | ppl 718.65 | wps 44638.3 | wpb 510.9 | bsz 1 | num_updates 3501 | best_loss 8.725
2022-03-06 17:06:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3501 updates
2022-03-06 17:06:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:06:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:06:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 72 @ 3501 updates, score 10.279) (writing took 1.7488886173814535 seconds)
2022-03-06 17:06:54 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 17:06:54 | INFO | train | epoch 072 | loss 4.616 | nll_loss 3.457 | ppl 10.98 | wps 25186.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3501 | lr 0.000437637 | gnorm 1.38 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9073
2022-03-06 17:06:54 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 17:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:08:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:08:59 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.389 | nll_loss 9.626 | ppl 790.13 | wps 44570.5 | wpb 510.9 | bsz 1 | num_updates 3550 | best_loss 8.725
2022-03-06 17:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3550 updates
2022-03-06 17:08:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:09:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 73 @ 3550 updates, score 10.389) (writing took 1.8982880478724837 seconds)
2022-03-06 17:09:01 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 17:09:01 | INFO | train | epoch 073 | loss 4.556 | nll_loss 3.388 | ppl 10.47 | wps 25170 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3550 | lr 0.000443761 | gnorm 1.458 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9199
2022-03-06 17:09:01 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 17:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:09:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:11:05 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.483 | nll_loss 9.725 | ppl 846.22 | wps 44368.8 | wpb 510.9 | bsz 1 | num_updates 3598 | best_loss 8.725
2022-03-06 17:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3598 updates
2022-03-06 17:11:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:11:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 74 @ 3598 updates, score 10.483) (writing took 1.8303775656968355 seconds)
2022-03-06 17:11:07 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 17:11:07 | INFO | train | epoch 074 | loss 4.492 | nll_loss 3.315 | ppl 9.95 | wps 24660.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3598 | lr 0.00044976 | gnorm 1.572 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9325
2022-03-06 17:11:07 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 17:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:11:12 | INFO | train_inner | epoch 075:      2 / 49 loss=4.523, nll_loss=3.35, ppl=10.2, wps=24317.1, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.518, loss_scale=16, train_wall=222, gb_free=8.8, wall=9330
2022-03-06 17:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:11 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.525 | nll_loss 9.766 | ppl 870.69 | wps 44786.3 | wpb 510.9 | bsz 1 | num_updates 3647 | best_loss 8.725
2022-03-06 17:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3647 updates
2022-03-06 17:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:13:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 75 @ 3647 updates, score 10.525) (writing took 1.8473263215273619 seconds)
2022-03-06 17:13:13 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 17:13:13 | INFO | train | epoch 075 | loss 4.417 | nll_loss 3.232 | ppl 9.39 | wps 25187.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3647 | lr 0.000455884 | gnorm 1.392 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9451
2022-03-06 17:13:13 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 17:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:15:18 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.615 | nll_loss 9.85 | ppl 922.84 | wps 44494 | wpb 510.9 | bsz 1 | num_updates 3696 | best_loss 8.725
2022-03-06 17:15:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3696 updates
2022-03-06 17:15:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:15:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:15:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 76 @ 3696 updates, score 10.615) (writing took 1.8704651547595859 seconds)
2022-03-06 17:15:20 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 17:15:20 | INFO | train | epoch 076 | loss 4.356 | nll_loss 3.162 | ppl 8.95 | wps 25135.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3696 | lr 0.000462008 | gnorm 1.459 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 9578
2022-03-06 17:15:20 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 17:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:15:29 | INFO | train_inner | epoch 077:      4 / 49 loss=4.38, nll_loss=3.19, ppl=9.12, wps=25188.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.416, loss_scale=32, train_wall=221, gb_free=8.8, wall=9588
2022-03-06 17:15:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:17:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:17:24 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.633 | nll_loss 9.866 | ppl 932.95 | wps 43663.8 | wpb 510.9 | bsz 1 | num_updates 3744 | best_loss 8.725
2022-03-06 17:17:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3744 updates
2022-03-06 17:17:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:17:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:17:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 77 @ 3744 updates, score 10.633) (writing took 1.9757821029052138 seconds)
2022-03-06 17:17:26 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 17:17:26 | INFO | train | epoch 077 | loss 4.288 | nll_loss 3.084 | ppl 8.48 | wps 24546.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3744 | lr 0.000468006 | gnorm 1.479 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 9705
2022-03-06 17:17:26 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 17:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:19:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:19:31 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.757 | nll_loss 10.005 | ppl 1027.39 | wps 43620.4 | wpb 510.9 | bsz 1 | num_updates 3793 | best_loss 8.725
2022-03-06 17:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3793 updates
2022-03-06 17:19:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 78 @ 3793 updates, score 10.757) (writing took 1.9230758305639029 seconds)
2022-03-06 17:19:33 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 17:19:33 | INFO | train | epoch 078 | loss 4.223 | nll_loss 3.01 | ppl 8.06 | wps 25057.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3793 | lr 0.00047413 | gnorm 1.489 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9831
2022-03-06 17:19:33 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 17:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:19:51 | INFO | train_inner | epoch 079:      7 / 49 loss=4.245, nll_loss=3.035, ppl=8.2, wps=24849.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.487, loss_scale=16, train_wall=224, gb_free=8.8, wall=9849
2022-03-06 17:21:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:21:38 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.92 | nll_loss 10.164 | ppl 1146.98 | wps 43906.5 | wpb 510.9 | bsz 1 | num_updates 3842 | best_loss 8.725
2022-03-06 17:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3842 updates
2022-03-06 17:21:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:21:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 79 @ 3842 updates, score 10.92) (writing took 2.0119143035262823 seconds)
2022-03-06 17:21:40 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 17:21:40 | INFO | train | epoch 079 | loss 4.162 | nll_loss 2.94 | ppl 7.67 | wps 25037 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3842 | lr 0.000480254 | gnorm 1.511 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 9958
2022-03-06 17:21:40 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 17:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:22:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:23:45 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.946 | nll_loss 10.192 | ppl 1169.56 | wps 44028.2 | wpb 510.9 | bsz 1 | num_updates 3890 | best_loss 8.725
2022-03-06 17:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3890 updates
2022-03-06 17:23:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 80 @ 3890 updates, score 10.946) (writing took 1.8764964044094086 seconds)
2022-03-06 17:23:47 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 17:23:47 | INFO | train | epoch 080 | loss 4.12 | nll_loss 2.891 | ppl 7.42 | wps 24563.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3890 | lr 0.000486253 | gnorm 1.592 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 10085
2022-03-06 17:23:47 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 17:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:24:12 | INFO | train_inner | epoch 081:     10 / 49 loss=4.128, nll_loss=2.901, ppl=7.47, wps=24850.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.525, loss_scale=16, train_wall=224, gb_free=8.8, wall=10110
2022-03-06 17:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:25:52 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.029 | nll_loss 10.285 | ppl 1247.59 | wps 44000.7 | wpb 510.9 | bsz 1 | num_updates 3939 | best_loss 8.725
2022-03-06 17:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3939 updates
2022-03-06 17:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 81 @ 3939 updates, score 11.029) (writing took 1.9870928786695004 seconds)
2022-03-06 17:25:54 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 17:25:54 | INFO | train | epoch 081 | loss 4.033 | nll_loss 2.794 | ppl 6.94 | wps 25066.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 3939 | lr 0.000492377 | gnorm 1.376 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 10212
2022-03-06 17:25:54 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 17:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:27:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:27:59 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.137 | nll_loss 10.392 | ppl 1344.11 | wps 43876.2 | wpb 510.9 | bsz 1 | num_updates 3987 | best_loss 8.725
2022-03-06 17:27:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3987 updates
2022-03-06 17:27:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 82 @ 3987 updates, score 11.137) (writing took 1.8635745448991656 seconds)
2022-03-06 17:28:00 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 17:28:00 | INFO | train | epoch 082 | loss 3.987 | nll_loss 2.741 | ppl 6.68 | wps 24555.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3987 | lr 0.000498375 | gnorm 1.536 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 10339
2022-03-06 17:28:00 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 17:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:28:33 | INFO | train_inner | epoch 083:     13 / 49 loss=3.995, nll_loss=2.75, ppl=6.73, wps=24858.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.479, loss_scale=16, train_wall=224, gb_free=8.8, wall=10371
2022-03-06 17:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:30:05 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.163 | nll_loss 10.41 | ppl 1360.36 | wps 43752.1 | wpb 510.9 | bsz 1 | num_updates 4036 | best_loss 8.725
2022-03-06 17:30:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4036 updates
2022-03-06 17:30:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:30:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:30:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 83 @ 4036 updates, score 11.163) (writing took 1.9418219635263085 seconds)
2022-03-06 17:30:07 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 17:30:07 | INFO | train | epoch 083 | loss 3.915 | nll_loss 2.659 | ppl 6.31 | wps 25045.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4036 | lr 0.000497765 | gnorm 1.366 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 10465
2022-03-06 17:30:07 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 17:30:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:32:12 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.283 | nll_loss 10.537 | ppl 1486.16 | wps 43814.5 | wpb 510.9 | bsz 1 | num_updates 4085 | best_loss 8.725
2022-03-06 17:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4085 updates
2022-03-06 17:32:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 84 @ 4085 updates, score 11.283) (writing took 1.8131215861067176 seconds)
2022-03-06 17:32:14 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 17:32:14 | INFO | train | epoch 084 | loss 3.862 | nll_loss 2.599 | ppl 6.06 | wps 25099.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4085 | lr 0.000494771 | gnorm 1.466 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 10592
2022-03-06 17:32:14 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 17:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:32:51 | INFO | train_inner | epoch 085:     15 / 49 loss=3.869, nll_loss=2.607, ppl=6.09, wps=25090.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.388, loss_scale=16, train_wall=222, gb_free=8.8, wall=10629
2022-03-06 17:33:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:33:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:34:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:34:19 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.375 | nll_loss 10.636 | ppl 1591.18 | wps 43960.1 | wpb 510.9 | bsz 1 | num_updates 4132 | best_loss 8.725
2022-03-06 17:34:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4132 updates
2022-03-06 17:34:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:34:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:34:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 85 @ 4132 updates, score 11.375) (writing took 1.7821017010137439 seconds)
2022-03-06 17:34:21 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 17:34:21 | INFO | train | epoch 085 | loss 3.804 | nll_loss 2.532 | ppl 5.78 | wps 24041.8 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 4132 | lr 0.000491949 | gnorm 1.466 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10719
2022-03-06 17:34:21 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 17:34:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:36:25 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.453 | nll_loss 10.712 | ppl 1677.23 | wps 44120.5 | wpb 510.9 | bsz 1 | num_updates 4181 | best_loss 8.725
2022-03-06 17:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4181 updates
2022-03-06 17:36:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:36:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 86 @ 4181 updates, score 11.453) (writing took 1.8056479450315237 seconds)
2022-03-06 17:36:27 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 17:36:27 | INFO | train | epoch 086 | loss 3.738 | nll_loss 2.457 | ppl 5.49 | wps 25085.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4181 | lr 0.000489057 | gnorm 1.393 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10846
2022-03-06 17:36:27 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 17:36:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:37:14 | INFO | train_inner | epoch 087:     19 / 49 loss=3.747, nll_loss=2.467, ppl=5.53, wps=24648.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.416, loss_scale=8, train_wall=226, gb_free=8.8, wall=10893
2022-03-06 17:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:38:32 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.486 | nll_loss 10.732 | ppl 1700.62 | wps 43872.8 | wpb 510.9 | bsz 1 | num_updates 4230 | best_loss 8.725
2022-03-06 17:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4230 updates
2022-03-06 17:38:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:38:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 87 @ 4230 updates, score 11.486) (writing took 1.8823148105293512 seconds)
2022-03-06 17:38:34 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 17:38:34 | INFO | train | epoch 087 | loss 3.677 | nll_loss 2.388 | ppl 5.24 | wps 25068.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4230 | lr 0.000486217 | gnorm 1.314 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10972
2022-03-06 17:38:34 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 17:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:40:39 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.596 | nll_loss 10.852 | ppl 1847.86 | wps 43615.9 | wpb 510.9 | bsz 1 | num_updates 4279 | best_loss 8.725
2022-03-06 17:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4279 updates
2022-03-06 17:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 88 @ 4279 updates, score 11.596) (writing took 1.9940386293455958 seconds)
2022-03-06 17:40:41 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 17:40:41 | INFO | train | epoch 088 | loss 3.623 | nll_loss 2.326 | ppl 5.01 | wps 25051.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4279 | lr 0.000483425 | gnorm 1.355 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11099
2022-03-06 17:40:41 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 17:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:41:33 | INFO | train_inner | epoch 089:     21 / 49 loss=3.63, nll_loss=2.334, ppl=5.04, wps=25082.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.365, loss_scale=16, train_wall=221, gb_free=8.8, wall=11151
2022-03-06 17:42:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:42:46 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.685 | nll_loss 10.937 | ppl 1959.91 | wps 44106.5 | wpb 510.9 | bsz 1 | num_updates 4328 | best_loss 8.725
2022-03-06 17:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4328 updates
2022-03-06 17:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:42:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 89 @ 4328 updates, score 11.685) (writing took 2.0771199045702815 seconds)
2022-03-06 17:42:48 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 17:42:48 | INFO | train | epoch 089 | loss 3.572 | nll_loss 2.267 | ppl 4.81 | wps 25002.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4328 | lr 0.00048068 | gnorm 1.377 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 11226
2022-03-06 17:42:48 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 17:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:44:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:44:53 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.81 | nll_loss 11.097 | ppl 2190.01 | wps 44133.2 | wpb 510.9 | bsz 1 | num_updates 4376 | best_loss 8.725
2022-03-06 17:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4376 updates
2022-03-06 17:44:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 90 @ 4376 updates, score 11.81) (writing took 1.8419126756489277 seconds)
2022-03-06 17:44:55 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 17:44:55 | INFO | train | epoch 090 | loss 3.517 | nll_loss 2.206 | ppl 4.61 | wps 24562.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 4376 | lr 0.000478037 | gnorm 1.345 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 11353
2022-03-06 17:44:55 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 17:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:45:54 | INFO | train_inner | epoch 091:     24 / 49 loss=3.52, nll_loss=2.209, ppl=4.62, wps=24837.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.336, loss_scale=16, train_wall=224, gb_free=8.8, wall=11412
2022-03-06 17:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:47:00 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.88 | nll_loss 11.168 | ppl 2301.57 | wps 44150.7 | wpb 510.9 | bsz 1 | num_updates 4425 | best_loss 8.725
2022-03-06 17:47:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4425 updates
2022-03-06 17:47:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 91 @ 4425 updates, score 11.88) (writing took 1.8298209635540843 seconds)
2022-03-06 17:47:01 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 17:47:01 | INFO | train | epoch 091 | loss 3.464 | nll_loss 2.145 | ppl 4.42 | wps 25083.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4425 | lr 0.000475383 | gnorm 1.313 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 11480
2022-03-06 17:47:01 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 17:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:49:06 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.989 | nll_loss 11.273 | ppl 2474.6 | wps 44271.4 | wpb 510.9 | bsz 1 | num_updates 4474 | best_loss 8.725
2022-03-06 17:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4474 updates
2022-03-06 17:49:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:49:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 92 @ 4474 updates, score 11.989) (writing took 1.963469948619604 seconds)
2022-03-06 17:49:08 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 17:49:08 | INFO | train | epoch 092 | loss 3.42 | nll_loss 2.095 | ppl 4.27 | wps 25052.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4474 | lr 0.000472772 | gnorm 1.321 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 11607
2022-03-06 17:49:08 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 17:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:50:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:50:15 | INFO | train_inner | epoch 093:     27 / 49 loss=3.417, nll_loss=2.092, ppl=4.26, wps=24865.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.33, loss_scale=16, train_wall=224, gb_free=8.8, wall=11673
2022-03-06 17:51:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:51:13 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 12.052 | nll_loss 11.344 | ppl 2599.83 | wps 44435 | wpb 510.9 | bsz 1 | num_updates 4522 | best_loss 8.725
2022-03-06 17:51:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4522 updates
2022-03-06 17:51:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 93 @ 4522 updates, score 12.052) (writing took 1.8406088994815946 seconds)
2022-03-06 17:51:15 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 17:51:15 | INFO | train | epoch 093 | loss 3.37 | nll_loss 2.038 | ppl 4.11 | wps 24589 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 4522 | lr 0.000470256 | gnorm 1.343 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11733
2022-03-06 17:51:15 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 17:51:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:53:20 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 12.163 | nll_loss 11.441 | ppl 2780.19 | wps 44597 | wpb 510.9 | bsz 1 | num_updates 4571 | best_loss 8.725
2022-03-06 17:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4571 updates
2022-03-06 17:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 94 @ 4571 updates, score 12.163) (writing took 1.9053392205387354 seconds)
2022-03-06 17:53:22 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 17:53:22 | INFO | train | epoch 094 | loss 3.321 | nll_loss 1.982 | ppl 3.95 | wps 25092.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4571 | lr 0.000467729 | gnorm 1.268 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11860
2022-03-06 17:53:22 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 17:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:54:33 | INFO | train_inner | epoch 095:     29 / 49 loss=3.32, nll_loss=1.981, ppl=3.95, wps=25137, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.284, loss_scale=16, train_wall=221, gb_free=8.8, wall=11931
2022-03-06 17:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:55:26 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.205 | nll_loss 11.494 | ppl 2884.41 | wps 44165.5 | wpb 510.9 | bsz 1 | num_updates 4620 | best_loss 8.725
2022-03-06 17:55:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4620 updates
2022-03-06 17:55:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:55:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 95 @ 4620 updates, score 12.205) (writing took 1.9674408296123147 seconds)
2022-03-06 17:55:28 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 17:55:28 | INFO | train | epoch 095 | loss 3.281 | nll_loss 1.936 | ppl 3.83 | wps 25126 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4620 | lr 0.000465242 | gnorm 1.277 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11986
2022-03-06 17:55:28 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 17:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:55:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:56:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:57:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:57:33 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.161 | nll_loss 11.446 | ppl 2789.87 | wps 44265.3 | wpb 510.9 | bsz 1 | num_updates 4667 | best_loss 8.725
2022-03-06 17:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4667 updates
2022-03-06 17:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:57:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 96 @ 4667 updates, score 12.161) (writing took 1.9680269323289394 seconds)
2022-03-06 17:57:34 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 17:57:34 | INFO | train | epoch 096 | loss 3.238 | nll_loss 1.886 | ppl 3.7 | wps 24101.7 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 4667 | lr 0.000462894 | gnorm 1.28 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 12113
2022-03-06 17:57:34 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 17:57:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:58:56 | INFO | train_inner | epoch 097:     33 / 49 loss=3.233, nll_loss=1.881, ppl=3.68, wps=24691, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.262, loss_scale=8, train_wall=225, gb_free=8.8, wall=12194
2022-03-06 17:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:59:39 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.24 | nll_loss 11.515 | ppl 2927.01 | wps 44496 | wpb 510.9 | bsz 1 | num_updates 4716 | best_loss 8.725
2022-03-06 17:59:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4716 updates
2022-03-06 17:59:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:59:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:59:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 97 @ 4716 updates, score 12.24) (writing took 1.9836703659966588 seconds)
2022-03-06 17:59:41 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 17:59:41 | INFO | train | epoch 097 | loss 3.199 | nll_loss 1.843 | ppl 3.59 | wps 25132.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4716 | lr 0.000460482 | gnorm 1.24 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 12239
2022-03-06 17:59:41 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 17:59:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:01:46 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.261 | nll_loss 11.552 | ppl 3001.64 | wps 44321.5 | wpb 510.9 | bsz 1 | num_updates 4765 | best_loss 8.725
2022-03-06 18:01:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4765 updates
2022-03-06 18:01:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:01:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 98 @ 4765 updates, score 12.261) (writing took 1.8673471957445145 seconds)
2022-03-06 18:01:47 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 18:01:47 | INFO | train | epoch 098 | loss 3.16 | nll_loss 1.798 | ppl 3.48 | wps 25132 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4765 | lr 0.000458109 | gnorm 1.261 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 12366
2022-03-06 18:01:47 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 18:01:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:03:14 | INFO | train_inner | epoch 099:     35 / 49 loss=3.154, nll_loss=1.791, ppl=3.46, wps=25153, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.24, loss_scale=16, train_wall=221, gb_free=8.8, wall=12452
2022-03-06 18:03:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:03:52 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.429 | nll_loss 11.74 | ppl 3420.86 | wps 44423.9 | wpb 510.9 | bsz 1 | num_updates 4814 | best_loss 8.725
2022-03-06 18:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4814 updates
2022-03-06 18:03:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:03:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 99 @ 4814 updates, score 12.429) (writing took 1.977910304442048 seconds)
2022-03-06 18:03:54 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 18:03:54 | INFO | train | epoch 099 | loss 3.12 | nll_loss 1.753 | ppl 3.37 | wps 25118.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4814 | lr 0.000455771 | gnorm 1.22 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 12492
2022-03-06 18:03:54 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 18:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:05:58 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.423 | nll_loss 11.729 | ppl 3394.49 | wps 44721.2 | wpb 510.9 | bsz 1 | num_updates 4863 | best_loss 8.725
2022-03-06 18:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4863 updates
2022-03-06 18:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 100 @ 4863 updates, score 12.423) (writing took 1.8638639403507113 seconds)
2022-03-06 18:06:00 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 18:06:00 | INFO | train | epoch 100 | loss 3.083 | nll_loss 1.711 | ppl 3.27 | wps 25148.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4863 | lr 0.000453469 | gnorm 1.211 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 12618
2022-03-06 18:06:00 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 18:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:07:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:07:34 | INFO | train_inner | epoch 101:     38 / 49 loss=3.077, nll_loss=1.704, ppl=3.26, wps=24923.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.237, loss_scale=16, train_wall=223, gb_free=8.8, wall=12712
2022-03-06 18:08:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:08:05 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.446 | nll_loss 11.757 | ppl 3461.35 | wps 44375.8 | wpb 510.9 | bsz 1 | num_updates 4911 | best_loss 8.725
2022-03-06 18:08:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4911 updates
2022-03-06 18:08:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:08:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:08:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 101 @ 4911 updates, score 12.446) (writing took 1.9723172262310982 seconds)
2022-03-06 18:08:07 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 18:08:07 | INFO | train | epoch 101 | loss 3.047 | nll_loss 1.67 | ppl 3.18 | wps 24600 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 4911 | lr 0.000451248 | gnorm 1.247 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 12745
2022-03-06 18:08:07 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 18:08:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:10:11 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.449 | nll_loss 11.754 | ppl 3454.91 | wps 44367.9 | wpb 510.9 | bsz 1 | num_updates 4960 | best_loss 8.725
2022-03-06 18:10:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4960 updates
2022-03-06 18:10:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:10:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:10:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 102 @ 4960 updates, score 12.449) (writing took 1.819800939410925 seconds)
2022-03-06 18:10:13 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 18:10:13 | INFO | train | epoch 102 | loss 3.016 | nll_loss 1.634 | ppl 3.1 | wps 25136.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 4960 | lr 0.000449013 | gnorm 1.217 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 12871
2022-03-06 18:10:13 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 18:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:11:52 | INFO | train_inner | epoch 103:     40 / 49 loss=3.003, nll_loss=1.62, ppl=3.07, wps=25128.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.185, loss_scale=16, train_wall=221, gb_free=8.8, wall=12970
2022-03-06 18:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:12:19 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.574 | nll_loss 11.888 | ppl 3790.81 | wps 41698.1 | wpb 510.9 | bsz 1 | num_updates 5009 | best_loss 8.725
2022-03-06 18:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5009 updates
2022-03-06 18:12:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 103 @ 5009 updates, score 12.574) (writing took 2.015396036207676 seconds)
2022-03-06 18:12:21 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 18:12:21 | INFO | train | epoch 103 | loss 2.977 | nll_loss 1.591 | ppl 3.01 | wps 24850.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 5009 | lr 0.000446812 | gnorm 1.148 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 12999
2022-03-06 18:12:21 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 18:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:12:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:14:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:14:26 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.64 | nll_loss 11.966 | ppl 4001.42 | wps 44009.9 | wpb 510.9 | bsz 1 | num_updates 5057 | best_loss 8.725
2022-03-06 18:14:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5057 updates
2022-03-06 18:14:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:14:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 104 @ 5057 updates, score 12.64) (writing took 1.9034720892086625 seconds)
2022-03-06 18:14:28 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 18:14:28 | INFO | train | epoch 104 | loss 2.947 | nll_loss 1.557 | ppl 2.94 | wps 24525.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 5057 | lr 0.000444686 | gnorm 1.178 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 13126
2022-03-06 18:14:28 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 18:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:16:14 | INFO | train_inner | epoch 105:     43 / 49 loss=2.939, nll_loss=1.548, ppl=2.92, wps=24729, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.182, loss_scale=16, train_wall=224, gb_free=8.8, wall=13233
2022-03-06 18:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:16:33 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.627 | nll_loss 11.951 | ppl 3959.82 | wps 43642.3 | wpb 510.9 | bsz 1 | num_updates 5106 | best_loss 8.725
2022-03-06 18:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5106 updates
2022-03-06 18:16:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:16:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:16:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 105 @ 5106 updates, score 12.627) (writing took 1.8339024214074016 seconds)
2022-03-06 18:16:35 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 18:16:35 | INFO | train | epoch 105 | loss 2.919 | nll_loss 1.525 | ppl 2.88 | wps 25028.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5106 | lr 0.000442547 | gnorm 1.175 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 13253
2022-03-06 18:16:35 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 18:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:17:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:18:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:18:40 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.605 | nll_loss 11.908 | ppl 3844.2 | wps 44163.9 | wpb 510.9 | bsz 1 | num_updates 5154 | best_loss 8.725
2022-03-06 18:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5154 updates
2022-03-06 18:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 106 @ 5154 updates, score 12.605) (writing took 1.8267710199579597 seconds)
2022-03-06 18:18:42 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 18:18:42 | INFO | train | epoch 106 | loss 2.888 | nll_loss 1.491 | ppl 2.81 | wps 24562.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 5154 | lr 0.000440482 | gnorm 1.152 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 13380
2022-03-06 18:18:42 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 18:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:20:35 | INFO | train_inner | epoch 107:     46 / 49 loss=2.879, nll_loss=1.48, ppl=2.79, wps=24859.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.152, loss_scale=8, train_wall=224, gb_free=8.8, wall=13494
2022-03-06 18:20:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:20:47 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.795 | nll_loss 12.133 | ppl 4490.41 | wps 43630.9 | wpb 510.9 | bsz 1 | num_updates 5203 | best_loss 8.725
2022-03-06 18:20:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5203 updates
2022-03-06 18:20:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:20:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:20:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 107 @ 5203 updates, score 12.795) (writing took 1.7396682212129235 seconds)
2022-03-06 18:20:48 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 18:20:48 | INFO | train | epoch 107 | loss 2.862 | nll_loss 1.461 | ppl 2.75 | wps 25080.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5203 | lr 0.000438403 | gnorm 1.155 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 13507
2022-03-06 18:20:48 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 18:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:22:53 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.784 | nll_loss 12.112 | ppl 4425.64 | wps 43917.3 | wpb 510.9 | bsz 1 | num_updates 5252 | best_loss 8.725
2022-03-06 18:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5252 updates
2022-03-06 18:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:22:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:22:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 108 @ 5252 updates, score 12.784) (writing took 2.0783824743703008 seconds)
2022-03-06 18:22:55 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 18:22:55 | INFO | train | epoch 108 | loss 2.836 | nll_loss 1.432 | ppl 2.7 | wps 25012.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5252 | lr 0.000436353 | gnorm 1.137 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 13634
2022-03-06 18:22:56 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 18:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:24:54 | INFO | train_inner | epoch 109:     48 / 49 loss=2.825, nll_loss=1.42, ppl=2.68, wps=25067.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.142, loss_scale=16, train_wall=222, gb_free=8.8, wall=13752
2022-03-06 18:24:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:25:01 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.8 | nll_loss 12.138 | ppl 4508.44 | wps 43921.7 | wpb 510.9 | bsz 1 | num_updates 5301 | best_loss 8.725
2022-03-06 18:25:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5301 updates
2022-03-06 18:25:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:25:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 109 @ 5301 updates, score 12.8) (writing took 2.1434138854965568 seconds)
2022-03-06 18:25:03 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 18:25:03 | INFO | train | epoch 109 | loss 2.81 | nll_loss 1.402 | ppl 2.64 | wps 24993.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5301 | lr 0.000434331 | gnorm 1.144 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 13761
2022-03-06 18:25:03 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 18:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:26:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:27:08 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.846 | nll_loss 12.186 | ppl 4659.18 | wps 44084.9 | wpb 510.9 | bsz 1 | num_updates 5349 | best_loss 8.725
2022-03-06 18:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5349 updates
2022-03-06 18:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:27:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:27:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 110 @ 5349 updates, score 12.846) (writing took 1.9659923994913697 seconds)
2022-03-06 18:27:09 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 18:27:09 | INFO | train | epoch 110 | loss 2.783 | nll_loss 1.372 | ppl 2.59 | wps 24538.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 5349 | lr 0.000432378 | gnorm 1.138 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 13888
2022-03-06 18:27:10 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 18:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:29:15 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.822 | nll_loss 12.153 | ppl 4554.84 | wps 43828.1 | wpb 510.9 | bsz 1 | num_updates 5398 | best_loss 8.725
2022-03-06 18:29:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5398 updates
2022-03-06 18:29:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:29:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:29:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 111 @ 5398 updates, score 12.822) (writing took 1.973159221932292 seconds)
2022-03-06 18:29:16 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 18:29:16 | INFO | train | epoch 111 | loss 2.755 | nll_loss 1.341 | ppl 2.53 | wps 25023.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5398 | lr 0.000430411 | gnorm 1.078 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 14015
2022-03-06 18:29:17 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 18:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:29:22 | INFO | train_inner | epoch 112:      2 / 49 loss=2.768, nll_loss=1.355, ppl=2.56, wps=24145.2, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.109, loss_scale=8, train_wall=223, gb_free=8.8, wall=14020
2022-03-06 18:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:31:22 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.913 | nll_loss 12.257 | ppl 4894.98 | wps 44069.4 | wpb 510.9 | bsz 1 | num_updates 5447 | best_loss 8.725
2022-03-06 18:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5447 updates
2022-03-06 18:31:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:31:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 112 @ 5447 updates, score 12.913) (writing took 1.8028928795829415 seconds)
2022-03-06 18:31:23 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 18:31:23 | INFO | train | epoch 112 | loss 2.733 | nll_loss 1.317 | ppl 2.49 | wps 25049.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5447 | lr 0.000428471 | gnorm 1.107 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 14142
2022-03-06 18:31:23 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 18:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:33:29 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.897 | nll_loss 12.228 | ppl 4797.24 | wps 43290.4 | wpb 510.9 | bsz 1 | num_updates 5496 | best_loss 8.725
2022-03-06 18:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5496 updates
2022-03-06 18:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:33:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 113 @ 5496 updates, score 12.897) (writing took 1.9905198896303773 seconds)
2022-03-06 18:33:31 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 18:33:31 | INFO | train | epoch 113 | loss 2.709 | nll_loss 1.289 | ppl 2.44 | wps 24996.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5496 | lr 0.000426557 | gnorm 1.083 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 14269
2022-03-06 18:33:31 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 18:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:33:40 | INFO | train_inner | epoch 114:      4 / 49 loss=2.719, nll_loss=1.301, ppl=2.46, wps=25054, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=1.095, loss_scale=16, train_wall=222, gb_free=8.8, wall=14279
2022-03-06 18:33:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:35:36 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.998 | nll_loss 12.336 | ppl 5169.01 | wps 43840.5 | wpb 510.9 | bsz 1 | num_updates 5544 | best_loss 8.725
2022-03-06 18:35:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5544 updates
2022-03-06 18:35:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:35:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 114 @ 5544 updates, score 12.998) (writing took 1.9243126772344112 seconds)
2022-03-06 18:35:37 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 18:35:37 | INFO | train | epoch 114 | loss 2.687 | nll_loss 1.265 | ppl 2.4 | wps 24515.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 5544 | lr 0.000424706 | gnorm 1.096 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 14396
2022-03-06 18:35:37 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 18:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:37:43 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.923 | nll_loss 12.255 | ppl 4887.87 | wps 43606.4 | wpb 510.9 | bsz 1 | num_updates 5593 | best_loss 8.725
2022-03-06 18:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5593 updates
2022-03-06 18:37:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 115 @ 5593 updates, score 12.923) (writing took 1.9347392497584224 seconds)
2022-03-06 18:37:44 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 18:37:44 | INFO | train | epoch 115 | loss 2.669 | nll_loss 1.245 | ppl 2.37 | wps 25019.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5593 | lr 0.000422841 | gnorm 1.092 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 14523
2022-03-06 18:37:44 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 18:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:38:02 | INFO | train_inner | epoch 116:      7 / 49 loss=2.675, nll_loss=1.251, ppl=2.38, wps=24814.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.092, loss_scale=8, train_wall=224, gb_free=8.8, wall=14540
2022-03-06 18:39:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:39:50 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.958 | nll_loss 12.307 | ppl 5068.23 | wps 43751.7 | wpb 510.9 | bsz 1 | num_updates 5642 | best_loss 8.725
2022-03-06 18:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5642 updates
2022-03-06 18:39:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:39:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:39:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 116 @ 5642 updates, score 12.958) (writing took 1.9022247679531574 seconds)
2022-03-06 18:39:52 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 18:39:52 | INFO | train | epoch 116 | loss 2.644 | nll_loss 1.217 | ppl 2.32 | wps 25020 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5642 | lr 0.000421001 | gnorm 1.052 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 14650
2022-03-06 18:39:52 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 18:39:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:40:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:41:57 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.041 | nll_loss 12.39 | ppl 5366.15 | wps 43980.9 | wpb 510.9 | bsz 1 | num_updates 5690 | best_loss 8.725
2022-03-06 18:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5690 updates
2022-03-06 18:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:41:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 117 @ 5690 updates, score 13.041) (writing took 1.9281507078558207 seconds)
2022-03-06 18:41:58 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 18:41:58 | INFO | train | epoch 117 | loss 2.622 | nll_loss 1.193 | ppl 2.29 | wps 24509.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 5690 | lr 0.000419222 | gnorm 1.025 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 14777
2022-03-06 18:41:59 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 18:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:42:23 | INFO | train_inner | epoch 118:     10 / 49 loss=2.629, nll_loss=1.201, ppl=2.3, wps=24816.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.04, loss_scale=8, train_wall=224, gb_free=8.8, wall=14802
2022-03-06 18:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:44:04 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.043 | nll_loss 12.382 | ppl 5337.24 | wps 43828.3 | wpb 510.9 | bsz 1 | num_updates 5739 | best_loss 8.725
2022-03-06 18:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5739 updates
2022-03-06 18:44:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 118 @ 5739 updates, score 13.043) (writing took 1.9581355666741729 seconds)
2022-03-06 18:44:06 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 18:44:06 | INFO | train | epoch 118 | loss 2.607 | nll_loss 1.177 | ppl 2.26 | wps 25022 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5739 | lr 0.000417428 | gnorm 1.052 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 14904
2022-03-06 18:44:06 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 18:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:46:11 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.039 | nll_loss 12.384 | ppl 5343.97 | wps 44014.3 | wpb 510.9 | bsz 1 | num_updates 5788 | best_loss 8.725
2022-03-06 18:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5788 updates
2022-03-06 18:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 119 @ 5788 updates, score 13.039) (writing took 1.8345598261803389 seconds)
2022-03-06 18:46:12 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 18:46:12 | INFO | train | epoch 119 | loss 2.59 | nll_loss 1.158 | ppl 2.23 | wps 25054.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5788 | lr 0.000415658 | gnorm 1.05 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 15031
2022-03-06 18:46:12 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 18:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:46:42 | INFO | train_inner | epoch 120:     12 / 49 loss=2.595, nll_loss=1.163, ppl=2.24, wps=25070.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.048, loss_scale=16, train_wall=222, gb_free=8.8, wall=15060
2022-03-06 18:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:48:17 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.07 | nll_loss 12.426 | ppl 5501.64 | wps 44764 | wpb 510.9 | bsz 1 | num_updates 5837 | best_loss 8.725
2022-03-06 18:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5837 updates
2022-03-06 18:48:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:48:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:48:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 120 @ 5837 updates, score 13.07) (writing took 1.8715250873938203 seconds)
2022-03-06 18:48:19 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 18:48:19 | INFO | train | epoch 120 | loss 2.572 | nll_loss 1.138 | ppl 2.2 | wps 25087.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5837 | lr 0.000413909 | gnorm 1.027 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 15157
2022-03-06 18:48:19 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 18:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:50:24 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.134 | nll_loss 12.489 | ppl 5750.17 | wps 44217.3 | wpb 510.9 | bsz 1 | num_updates 5886 | best_loss 8.725
2022-03-06 18:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5886 updates
2022-03-06 18:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:50:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 121 @ 5886 updates, score 13.134) (writing took 1.7140083936974406 seconds)
2022-03-06 18:50:25 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 18:50:25 | INFO | train | epoch 121 | loss 2.551 | nll_loss 1.115 | ppl 2.17 | wps 25147.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5886 | lr 0.000412183 | gnorm 0.998 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 15284
2022-03-06 18:50:25 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 18:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:51:00 | INFO | train_inner | epoch 122:     14 / 49 loss=2.556, nll_loss=1.12, ppl=2.17, wps=25153, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.007, loss_scale=16, train_wall=221, gb_free=8.8, wall=15318
2022-03-06 18:51:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:52:30 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.068 | nll_loss 12.424 | ppl 5496.06 | wps 44277 | wpb 510.9 | bsz 1 | num_updates 5934 | best_loss 8.725
2022-03-06 18:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5934 updates
2022-03-06 18:52:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:52:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:52:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 122 @ 5934 updates, score 13.068) (writing took 1.7491900511085987 seconds)
2022-03-06 18:52:32 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 18:52:32 | INFO | train | epoch 122 | loss 2.535 | nll_loss 1.098 | ppl 2.14 | wps 24627.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 5934 | lr 0.000410512 | gnorm 1.005 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 15410
2022-03-06 18:52:32 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 18:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:54:36 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.091 | nll_loss 12.445 | ppl 5577.03 | wps 44476 | wpb 510.9 | bsz 1 | num_updates 5983 | best_loss 8.725
2022-03-06 18:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5983 updates
2022-03-06 18:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:54:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 123 @ 5983 updates, score 13.091) (writing took 1.9289011219516397 seconds)
2022-03-06 18:54:38 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 18:54:38 | INFO | train | epoch 123 | loss 2.522 | nll_loss 1.084 | ppl 2.12 | wps 25106.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 5983 | lr 0.000408828 | gnorm 0.993 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 15537
2022-03-06 18:54:38 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 18:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:20 | INFO | train_inner | epoch 124:     17 / 49 loss=2.524, nll_loss=1.085, ppl=2.12, wps=24911.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=0.999, loss_scale=8, train_wall=223, gb_free=8.8, wall=15579
2022-03-06 18:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:56:43 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.186 | nll_loss 12.553 | ppl 6007.48 | wps 44338.8 | wpb 510.9 | bsz 1 | num_updates 6032 | best_loss 8.725
2022-03-06 18:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6032 updates
2022-03-06 18:56:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:56:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:56:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 124 @ 6032 updates, score 13.186) (writing took 1.7644848767668009 seconds)
2022-03-06 18:56:45 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 18:56:45 | INFO | train | epoch 124 | loss 2.505 | nll_loss 1.064 | ppl 2.09 | wps 25147.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6032 | lr 0.000407164 | gnorm 0.99 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 15663
2022-03-06 18:56:45 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 18:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:58:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:58:49 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.132 | nll_loss 12.496 | ppl 5774.97 | wps 44741.4 | wpb 510.9 | bsz 1 | num_updates 6081 | best_loss 8.725
2022-03-06 18:58:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6081 updates
2022-03-06 18:58:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:58:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 125 @ 6081 updates, score 13.132) (writing took 1.8953445302322507 seconds)
2022-03-06 18:58:51 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 18:58:51 | INFO | train | epoch 125 | loss 2.489 | nll_loss 1.047 | ppl 2.07 | wps 25126.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6081 | lr 0.00040552 | gnorm 0.964 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 15789
2022-03-06 18:58:51 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 18:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:59:38 | INFO | train_inner | epoch 126:     19 / 49 loss=2.492, nll_loss=1.05, ppl=2.07, wps=25170.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.974, loss_scale=16, train_wall=221, gb_free=8.8, wall=15836
2022-03-06 19:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:00:56 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.272 | nll_loss 12.647 | ppl 6411.87 | wps 44094.2 | wpb 510.9 | bsz 1 | num_updates 6130 | best_loss 8.725
2022-03-06 19:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6130 updates
2022-03-06 19:00:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 126 @ 6130 updates, score 13.272) (writing took 1.899128194898367 seconds)
2022-03-06 19:00:58 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 19:00:58 | INFO | train | epoch 126 | loss 2.473 | nll_loss 1.031 | ppl 2.04 | wps 25137.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6130 | lr 0.000403896 | gnorm 0.969 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 15916
2022-03-06 19:00:58 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 19:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:02:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:03:02 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.17 | nll_loss 12.537 | ppl 5944.6 | wps 44018.3 | wpb 510.9 | bsz 1 | num_updates 6178 | best_loss 8.725
2022-03-06 19:03:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6178 updates
2022-03-06 19:03:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:03:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:03:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 127 @ 6178 updates, score 13.17) (writing took 2.0220802016556263 seconds)
2022-03-06 19:03:04 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 19:03:04 | INFO | train | epoch 127 | loss 2.459 | nll_loss 1.015 | ppl 2.02 | wps 24574.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 6178 | lr 0.000402324 | gnorm 0.962 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 16043
2022-03-06 19:03:04 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 19:03:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:03:59 | INFO | train_inner | epoch 128:     22 / 49 loss=2.458, nll_loss=1.015, ppl=2.02, wps=24900.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.956, loss_scale=8, train_wall=223, gb_free=8.8, wall=16097
2022-03-06 19:05:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:05:09 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.218 | nll_loss 12.588 | ppl 6156.09 | wps 44431.8 | wpb 510.9 | bsz 1 | num_updates 6227 | best_loss 8.725
2022-03-06 19:05:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6227 updates
2022-03-06 19:05:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:05:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 128 @ 6227 updates, score 13.218) (writing took 1.9916858682408929 seconds)
2022-03-06 19:05:11 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 19:05:11 | INFO | train | epoch 128 | loss 2.445 | nll_loss 1.001 | ppl 2 | wps 25114.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6227 | lr 0.000400738 | gnorm 0.954 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 16169
2022-03-06 19:05:11 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 19:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:07:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:07:16 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.268 | nll_loss 12.643 | ppl 6397.11 | wps 44045.4 | wpb 510.9 | bsz 1 | num_updates 6276 | best_loss 8.725
2022-03-06 19:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6276 updates
2022-03-06 19:07:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 129 @ 6276 updates, score 13.268) (writing took 1.836466516368091 seconds)
2022-03-06 19:07:17 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 19:07:17 | INFO | train | epoch 129 | loss 2.43 | nll_loss 0.985 | ppl 1.98 | wps 25099.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6276 | lr 0.000399171 | gnorm 0.943 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 16296
2022-03-06 19:07:17 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 19:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:08:18 | INFO | train_inner | epoch 130:     24 / 49 loss=2.432, nll_loss=0.987, ppl=1.98, wps=25051.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.948, loss_scale=16, train_wall=222, gb_free=8.8, wall=16356
2022-03-06 19:08:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:09:23 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.21 | nll_loss 12.58 | ppl 6124.77 | wps 43721.7 | wpb 510.9 | bsz 1 | num_updates 6324 | best_loss 8.725
2022-03-06 19:09:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6324 updates
2022-03-06 19:09:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:09:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 130 @ 6324 updates, score 13.21) (writing took 1.8820149572566152 seconds)
2022-03-06 19:09:25 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 19:09:25 | INFO | train | epoch 130 | loss 2.418 | nll_loss 0.972 | ppl 1.96 | wps 24396.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 6324 | lr 0.000397653 | gnorm 0.966 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 16423
2022-03-06 19:09:25 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 19:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:11:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:11:30 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.227 | nll_loss 12.607 | ppl 6239.73 | wps 43782.9 | wpb 510.9 | bsz 1 | num_updates 6373 | best_loss 8.725
2022-03-06 19:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6373 updates
2022-03-06 19:11:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:11:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 131 @ 6373 updates, score 13.227) (writing took 1.7610180238261819 seconds)
2022-03-06 19:11:32 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 19:11:32 | INFO | train | epoch 131 | loss 2.405 | nll_loss 0.958 | ppl 1.94 | wps 25063.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6373 | lr 0.000396121 | gnorm 0.924 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 16550
2022-03-06 19:11:32 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 19:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:12:39 | INFO | train_inner | epoch 132:     27 / 49 loss=2.405, nll_loss=0.957, ppl=1.94, wps=24847.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.94, loss_scale=8, train_wall=224, gb_free=8.8, wall=16617
2022-03-06 19:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:13:37 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.293 | nll_loss 12.666 | ppl 6499.44 | wps 43897.8 | wpb 510.9 | bsz 1 | num_updates 6422 | best_loss 8.725
2022-03-06 19:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6422 updates
2022-03-06 19:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 132 @ 6422 updates, score 13.293) (writing took 1.9479323700070381 seconds)
2022-03-06 19:13:39 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 19:13:39 | INFO | train | epoch 132 | loss 2.393 | nll_loss 0.945 | ppl 1.93 | wps 25045.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6422 | lr 0.000394607 | gnorm 0.936 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 16677
2022-03-06 19:13:39 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 19:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:14:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:15:44 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.303 | nll_loss 12.688 | ppl 6600.52 | wps 43750.9 | wpb 510.9 | bsz 1 | num_updates 6470 | best_loss 8.725
2022-03-06 19:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6470 updates
2022-03-06 19:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 133 @ 6470 updates, score 13.303) (writing took 2.0624946700409055 seconds)
2022-03-06 19:15:46 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 19:15:46 | INFO | train | epoch 133 | loss 2.38 | nll_loss 0.931 | ppl 1.91 | wps 24488.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 6470 | lr 0.000393141 | gnorm 0.908 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 16804
2022-03-06 19:15:46 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 19:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:17:00 | INFO | train_inner | epoch 134:     30 / 49 loss=2.38, nll_loss=0.932, ppl=1.91, wps=24810.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.914, loss_scale=8, train_wall=224, gb_free=8.8, wall=16878
2022-03-06 19:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:51 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.334 | nll_loss 12.732 | ppl 6802.34 | wps 44175.6 | wpb 510.9 | bsz 1 | num_updates 6519 | best_loss 8.725
2022-03-06 19:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6519 updates
2022-03-06 19:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 134 @ 6519 updates, score 13.334) (writing took 1.7696805577725172 seconds)
2022-03-06 19:17:53 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 19:17:53 | INFO | train | epoch 134 | loss 2.368 | nll_loss 0.919 | ppl 1.89 | wps 25059.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6519 | lr 0.00039166 | gnorm 0.891 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 16931
2022-03-06 19:17:53 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 19:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:19:58 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.356 | nll_loss 12.74 | ppl 6842.15 | wps 43841.3 | wpb 510.9 | bsz 1 | num_updates 6568 | best_loss 8.725
2022-03-06 19:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6568 updates
2022-03-06 19:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 135 @ 6568 updates, score 13.356) (writing took 2.003794778138399 seconds)
2022-03-06 19:20:00 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 19:20:00 | INFO | train | epoch 135 | loss 2.359 | nll_loss 0.91 | ppl 1.88 | wps 25024.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6568 | lr 0.000390197 | gnorm 0.908 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 17058
2022-03-06 19:20:00 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 19:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:21:19 | INFO | train_inner | epoch 136:     32 / 49 loss=2.357, nll_loss=0.907, ppl=1.87, wps=25079.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.898, loss_scale=16, train_wall=222, gb_free=8.8, wall=17137
2022-03-06 19:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:05 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.302 | nll_loss 12.686 | ppl 6591.83 | wps 43956.1 | wpb 510.9 | bsz 1 | num_updates 6617 | best_loss 8.725
2022-03-06 19:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6617 updates
2022-03-06 19:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:22:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 136 @ 6617 updates, score 13.302) (writing took 1.7635713201016188 seconds)
2022-03-06 19:22:06 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 19:22:06 | INFO | train | epoch 136 | loss 2.349 | nll_loss 0.899 | ppl 1.86 | wps 25091.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6617 | lr 0.000388749 | gnorm 0.903 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 17185
2022-03-06 19:22:06 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 19:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:23:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:24:11 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.241 | nll_loss 12.614 | ppl 6270.43 | wps 43813.1 | wpb 510.9 | bsz 1 | num_updates 6665 | best_loss 8.725
2022-03-06 19:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6665 updates
2022-03-06 19:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 137 @ 6665 updates, score 13.241) (writing took 2.090733624994755 seconds)
2022-03-06 19:24:13 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 19:24:13 | INFO | train | epoch 137 | loss 2.337 | nll_loss 0.887 | ppl 1.85 | wps 24488.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 6665 | lr 0.000387347 | gnorm 0.899 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 17312
2022-03-06 19:24:13 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 19:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:25:40 | INFO | train_inner | epoch 138:     35 / 49 loss=2.336, nll_loss=0.885, ppl=1.85, wps=24826.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.893, loss_scale=8, train_wall=224, gb_free=8.8, wall=17398
2022-03-06 19:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:26:18 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.267 | nll_loss 12.649 | ppl 6421.71 | wps 43784.6 | wpb 510.9 | bsz 1 | num_updates 6714 | best_loss 8.725
2022-03-06 19:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6714 updates
2022-03-06 19:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:26:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:26:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 138 @ 6714 updates, score 13.267) (writing took 2.042834180407226 seconds)
2022-03-06 19:26:21 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 19:26:21 | INFO | train | epoch 138 | loss 2.325 | nll_loss 0.874 | ppl 1.83 | wps 25004.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6714 | lr 0.000385931 | gnorm 0.877 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 17439
2022-03-06 19:26:21 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 19:26:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:28:26 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.341 | nll_loss 12.734 | ppl 6811.1 | wps 43805.5 | wpb 510.9 | bsz 1 | num_updates 6763 | best_loss 8.725
2022-03-06 19:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6763 updates
2022-03-06 19:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:28:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 139 @ 6763 updates, score 13.341) (writing took 2.04760664422065 seconds)
2022-03-06 19:28:28 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 19:28:28 | INFO | train | epoch 139 | loss 2.316 | nll_loss 0.865 | ppl 1.82 | wps 25017.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6763 | lr 0.00038453 | gnorm 0.868 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 17566
2022-03-06 19:28:28 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 19:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:29:59 | INFO | train_inner | epoch 140:     37 / 49 loss=2.313, nll_loss=0.862, ppl=1.82, wps=25035.8, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.867, loss_scale=16, train_wall=222, gb_free=8.8, wall=17657
2022-03-06 19:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:30:33 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.481 | nll_loss 12.884 | ppl 7559.81 | wps 43538.6 | wpb 510.9 | bsz 1 | num_updates 6812 | best_loss 8.725
2022-03-06 19:30:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6812 updates
2022-03-06 19:30:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:30:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 140 @ 6812 updates, score 13.481) (writing took 1.782994233071804 seconds)
2022-03-06 19:30:35 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 19:30:35 | INFO | train | epoch 140 | loss 2.304 | nll_loss 0.852 | ppl 1.8 | wps 25022.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6812 | lr 0.000383145 | gnorm 0.859 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 17693
2022-03-06 19:30:35 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 19:30:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:32:40 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.252 | nll_loss 12.634 | ppl 6357.9 | wps 43783.1 | wpb 510.9 | bsz 1 | num_updates 6861 | best_loss 8.725
2022-03-06 19:32:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6861 updates
2022-03-06 19:32:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 141 @ 6861 updates, score 13.252) (writing took 1.8838682314381003 seconds)
2022-03-06 19:32:41 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-06 19:32:41 | INFO | train | epoch 141 | loss 2.297 | nll_loss 0.845 | ppl 1.8 | wps 25053.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6861 | lr 0.000381774 | gnorm 0.875 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 17820
2022-03-06 19:32:41 | INFO | fairseq.trainer | begin training epoch 142
2022-03-06 19:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:34:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:34:20 | INFO | train_inner | epoch 142:     40 / 49 loss=2.294, nll_loss=0.841, ppl=1.79, wps=24846.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.862, loss_scale=16, train_wall=224, gb_free=8.8, wall=17919
2022-03-06 19:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:34:46 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.354 | nll_loss 12.754 | ppl 6908.09 | wps 43714.6 | wpb 510.9 | bsz 1 | num_updates 6909 | best_loss 8.725
2022-03-06 19:34:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6909 updates
2022-03-06 19:34:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:34:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 142 @ 6909 updates, score 13.354) (writing took 1.8353996947407722 seconds)
2022-03-06 19:34:48 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-06 19:34:48 | INFO | train | epoch 142 | loss 2.283 | nll_loss 0.831 | ppl 1.78 | wps 24554.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 6909 | lr 0.000380445 | gnorm 0.847 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 17946
2022-03-06 19:34:48 | INFO | fairseq.trainer | begin training epoch 143
2022-03-06 19:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:36:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:36:53 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.353 | nll_loss 12.75 | ppl 6887.2 | wps 43792 | wpb 510.9 | bsz 1 | num_updates 6958 | best_loss 8.725
2022-03-06 19:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6958 updates
2022-03-06 19:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 143 @ 6958 updates, score 13.353) (writing took 1.940669278614223 seconds)
2022-03-06 19:36:55 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-06 19:36:55 | INFO | train | epoch 143 | loss 2.278 | nll_loss 0.825 | ppl 1.77 | wps 24992.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 6958 | lr 0.000379103 | gnorm 0.85 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 18074
2022-03-06 19:36:55 | INFO | fairseq.trainer | begin training epoch 144
2022-03-06 19:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:37:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:38:42 | INFO | train_inner | epoch 144:     43 / 49 loss=2.274, nll_loss=0.822, ppl=1.77, wps=24816.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.852, loss_scale=8, train_wall=224, gb_free=8.8, wall=18180
2022-03-06 19:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:39:00 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.337 | nll_loss 12.732 | ppl 6805.56 | wps 43858.3 | wpb 510.9 | bsz 1 | num_updates 7006 | best_loss 8.725
2022-03-06 19:39:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7006 updates
2022-03-06 19:39:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 144 @ 7006 updates, score 13.337) (writing took 1.825144212692976 seconds)
2022-03-06 19:39:02 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-06 19:39:02 | INFO | train | epoch 144 | loss 2.267 | nll_loss 0.815 | ppl 1.76 | wps 24541.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7006 | lr 0.000377803 | gnorm 0.854 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 18200
2022-03-06 19:39:02 | INFO | fairseq.trainer | begin training epoch 145
2022-03-06 19:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:41:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:41:07 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.428 | nll_loss 12.84 | ppl 7334.35 | wps 43834.5 | wpb 510.9 | bsz 1 | num_updates 7055 | best_loss 8.725
2022-03-06 19:41:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7055 updates
2022-03-06 19:41:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:41:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 145 @ 7055 updates, score 13.428) (writing took 2.064099791459739 seconds)
2022-03-06 19:41:09 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-06 19:41:09 | INFO | train | epoch 145 | loss 2.258 | nll_loss 0.806 | ppl 1.75 | wps 25009 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7055 | lr 0.000376488 | gnorm 0.825 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 18327
2022-03-06 19:41:09 | INFO | fairseq.trainer | begin training epoch 146
2022-03-06 19:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:43:00 | INFO | train_inner | epoch 146:     45 / 49 loss=2.257, nll_loss=0.804, ppl=1.75, wps=25067.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.834, loss_scale=8, train_wall=222, gb_free=8.8, wall=18439
2022-03-06 19:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:43:14 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.29 | nll_loss 12.685 | ppl 6584.81 | wps 44242.8 | wpb 510.9 | bsz 1 | num_updates 7104 | best_loss 8.725
2022-03-06 19:43:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7104 updates
2022-03-06 19:43:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:43:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 146 @ 7104 updates, score 13.29) (writing took 1.9976709922775626 seconds)
2022-03-06 19:43:16 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-06 19:43:16 | INFO | train | epoch 146 | loss 2.252 | nll_loss 0.799 | ppl 1.74 | wps 25050.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7104 | lr 0.000375188 | gnorm 0.836 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 18454
2022-03-06 19:43:16 | INFO | fairseq.trainer | begin training epoch 147
2022-03-06 19:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:45:21 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.467 | nll_loss 12.875 | ppl 7510.65 | wps 44019.1 | wpb 510.9 | bsz 1 | num_updates 7153 | best_loss 8.725
2022-03-06 19:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7153 updates
2022-03-06 19:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:45:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 147 @ 7153 updates, score 13.467) (writing took 1.7022523200139403 seconds)
2022-03-06 19:45:22 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-06 19:45:22 | INFO | train | epoch 147 | loss 2.242 | nll_loss 0.789 | ppl 1.73 | wps 25161.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7153 | lr 0.0003739 | gnorm 0.824 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 18581
2022-03-06 19:45:22 | INFO | fairseq.trainer | begin training epoch 148
2022-03-06 19:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:47:18 | INFO | train_inner | epoch 148:     47 / 49 loss=2.24, nll_loss=0.787, ppl=1.73, wps=25158.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.836, loss_scale=16, train_wall=221, gb_free=8.8, wall=18697
2022-03-06 19:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:47:27 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.425 | nll_loss 12.831 | ppl 7284.97 | wps 43037.8 | wpb 510.9 | bsz 1 | num_updates 7202 | best_loss 8.725
2022-03-06 19:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7202 updates
2022-03-06 19:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 148 @ 7202 updates, score 13.425) (writing took 1.9093534853309393 seconds)
2022-03-06 19:47:29 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-06 19:47:29 | INFO | train | epoch 148 | loss 2.237 | nll_loss 0.784 | ppl 1.72 | wps 25048.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7202 | lr 0.000372626 | gnorm 0.849 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 18708
2022-03-06 19:47:29 | INFO | fairseq.trainer | begin training epoch 149
2022-03-06 19:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:49:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:49:34 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.349 | nll_loss 12.748 | ppl 6879.64 | wps 43561.2 | wpb 510.9 | bsz 1 | num_updates 7250 | best_loss 8.725
2022-03-06 19:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7250 updates
2022-03-06 19:49:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:49:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:49:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 149 @ 7250 updates, score 13.349) (writing took 2.0093744257465005 seconds)
2022-03-06 19:49:36 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-06 19:49:36 | INFO | train | epoch 149 | loss 2.222 | nll_loss 0.769 | ppl 1.7 | wps 24535.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7250 | lr 0.000371391 | gnorm 0.794 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 18834
2022-03-06 19:49:36 | INFO | fairseq.trainer | begin training epoch 150
2022-03-06 19:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:51:41 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.333 | nll_loss 12.735 | ppl 6818.36 | wps 43995.4 | wpb 510.9 | bsz 1 | num_updates 7299 | best_loss 8.725
2022-03-06 19:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7299 updates
2022-03-06 19:51:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 150 @ 7299 updates, score 13.333) (writing took 1.929778004065156 seconds)
2022-03-06 19:51:43 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-06 19:51:43 | INFO | train | epoch 150 | loss 2.219 | nll_loss 0.766 | ppl 1.7 | wps 25036.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7299 | lr 0.000370142 | gnorm 0.809 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 18961
2022-03-06 19:51:43 | INFO | fairseq.trainer | begin training epoch 151
2022-03-06 19:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:46 | INFO | train_inner | epoch 151:      1 / 49 loss=2.22, nll_loss=0.767, ppl=1.7, wps=24146.4, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.805, loss_scale=16, train_wall=223, gb_free=8.8, wall=18964
2022-03-06 19:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:53:48 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.401 | nll_loss 12.808 | ppl 7171.23 | wps 44018.5 | wpb 510.9 | bsz 1 | num_updates 7348 | best_loss 8.725
2022-03-06 19:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7348 updates
2022-03-06 19:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 151 @ 7348 updates, score 13.401) (writing took 1.8060115715488791 seconds)
2022-03-06 19:53:50 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-06 19:53:50 | INFO | train | epoch 151 | loss 2.21 | nll_loss 0.758 | ppl 1.69 | wps 25054.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7348 | lr 0.000368906 | gnorm 0.798 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 19088
2022-03-06 19:53:50 | INFO | fairseq.trainer | begin training epoch 152
2022-03-06 19:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:54:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:55:55 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.412 | nll_loss 12.831 | ppl 7286.87 | wps 44223.3 | wpb 510.9 | bsz 1 | num_updates 7396 | best_loss 8.725
2022-03-06 19:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7396 updates
2022-03-06 19:55:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:55:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 152 @ 7396 updates, score 13.412) (writing took 1.7987246625125408 seconds)
2022-03-06 19:55:57 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-06 19:55:57 | INFO | train | epoch 152 | loss 2.203 | nll_loss 0.75 | ppl 1.68 | wps 24566.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7396 | lr 0.000367707 | gnorm 0.809 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 19215
2022-03-06 19:55:57 | INFO | fairseq.trainer | begin training epoch 153
2022-03-06 19:55:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:56:07 | INFO | train_inner | epoch 153:      4 / 49 loss=2.206, nll_loss=0.753, ppl=1.69, wps=24859.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.803, loss_scale=16, train_wall=224, gb_free=8.8, wall=19225
2022-03-06 19:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:58:02 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.391 | nll_loss 12.8 | ppl 7130.93 | wps 43784.8 | wpb 510.9 | bsz 1 | num_updates 7445 | best_loss 8.725
2022-03-06 19:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7445 updates
2022-03-06 19:58:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:58:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 153 @ 7445 updates, score 13.391) (writing took 1.8325671767815948 seconds)
2022-03-06 19:58:04 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-06 19:58:04 | INFO | train | epoch 153 | loss 2.198 | nll_loss 0.745 | ppl 1.68 | wps 25033.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7445 | lr 0.000366495 | gnorm 0.807 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 19342
2022-03-06 19:58:04 | INFO | fairseq.trainer | begin training epoch 154
2022-03-06 19:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:09 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.382 | nll_loss 12.786 | ppl 7062.96 | wps 43680.5 | wpb 510.9 | bsz 1 | num_updates 7494 | best_loss 8.725
2022-03-06 20:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7494 updates
2022-03-06 20:00:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 154 @ 7494 updates, score 13.382) (writing took 2.036820233799517 seconds)
2022-03-06 20:00:11 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-06 20:00:11 | INFO | train | epoch 154 | loss 2.187 | nll_loss 0.735 | ppl 1.66 | wps 25001.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7494 | lr 0.000365295 | gnorm 0.776 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 19469
2022-03-06 20:00:11 | INFO | fairseq.trainer | begin training epoch 155
2022-03-06 20:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:00:26 | INFO | train_inner | epoch 155:      6 / 49 loss=2.192, nll_loss=0.739, ppl=1.67, wps=25047.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.793, loss_scale=16, train_wall=222, gb_free=8.8, wall=19484
2022-03-06 20:00:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:02:16 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.397 | nll_loss 12.807 | ppl 7164.64 | wps 44037 | wpb 510.9 | bsz 1 | num_updates 7542 | best_loss 8.725
2022-03-06 20:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7542 updates
2022-03-06 20:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:02:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 155 @ 7542 updates, score 13.397) (writing took 1.8192922417074442 seconds)
2022-03-06 20:02:17 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-06 20:02:17 | INFO | train | epoch 155 | loss 2.183 | nll_loss 0.73 | ppl 1.66 | wps 24555.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7542 | lr 0.00036413 | gnorm 0.802 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 19596
2022-03-06 20:02:17 | INFO | fairseq.trainer | begin training epoch 156
2022-03-06 20:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:04:23 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.352 | nll_loss 12.76 | ppl 6938.74 | wps 43718.7 | wpb 510.9 | bsz 1 | num_updates 7591 | best_loss 8.725
2022-03-06 20:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7591 updates
2022-03-06 20:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:04:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:04:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 156 @ 7591 updates, score 13.352) (writing took 1.7700255196541548 seconds)
2022-03-06 20:04:24 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-06 20:04:24 | INFO | train | epoch 156 | loss 2.175 | nll_loss 0.722 | ppl 1.65 | wps 25048 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7591 | lr 0.000362953 | gnorm 0.797 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 19723
2022-03-06 20:04:24 | INFO | fairseq.trainer | begin training epoch 157
2022-03-06 20:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:04:47 | INFO | train_inner | epoch 157:      9 / 49 loss=2.177, nll_loss=0.724, ppl=1.65, wps=24848.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.795, loss_scale=16, train_wall=224, gb_free=8.8, wall=19745
2022-03-06 20:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:06:29 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.469 | nll_loss 12.89 | ppl 7589.03 | wps 43893.3 | wpb 510.9 | bsz 1 | num_updates 7640 | best_loss 8.725
2022-03-06 20:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7640 updates
2022-03-06 20:06:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:06:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 157 @ 7640 updates, score 13.469) (writing took 1.953739358112216 seconds)
2022-03-06 20:06:31 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-06 20:06:31 | INFO | train | epoch 157 | loss 2.168 | nll_loss 0.716 | ppl 1.64 | wps 25033 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7640 | lr 0.000361787 | gnorm 0.775 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 19850
2022-03-06 20:06:31 | INFO | fairseq.trainer | begin training epoch 158
2022-03-06 20:06:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:07:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:08:36 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.4 | nll_loss 12.821 | ppl 7235.11 | wps 43684.1 | wpb 510.9 | bsz 1 | num_updates 7688 | best_loss 8.725
2022-03-06 20:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7688 updates
2022-03-06 20:08:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:08:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:08:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 158 @ 7688 updates, score 13.4) (writing took 2.0974013255909085 seconds)
2022-03-06 20:08:38 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-06 20:08:38 | INFO | train | epoch 158 | loss 2.16 | nll_loss 0.708 | ppl 1.63 | wps 24495 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7688 | lr 0.000360656 | gnorm 0.771 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 19977
2022-03-06 20:08:38 | INFO | fairseq.trainer | begin training epoch 159
2022-03-06 20:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:09:08 | INFO | train_inner | epoch 159:     12 / 49 loss=2.163, nll_loss=0.71, ppl=1.64, wps=24805.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.77, loss_scale=16, train_wall=224, gb_free=8.8, wall=20006
2022-03-06 20:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:10:43 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.344 | nll_loss 12.753 | ppl 6903.05 | wps 43989.2 | wpb 510.9 | bsz 1 | num_updates 7737 | best_loss 8.725
2022-03-06 20:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7737 updates
2022-03-06 20:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 159 @ 7737 updates, score 13.344) (writing took 1.9036817904561758 seconds)
2022-03-06 20:10:45 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-06 20:10:45 | INFO | train | epoch 159 | loss 2.157 | nll_loss 0.705 | ppl 1.63 | wps 25031.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7737 | lr 0.000359512 | gnorm 0.757 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 20104
2022-03-06 20:10:45 | INFO | fairseq.trainer | begin training epoch 160
2022-03-06 20:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:12:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:12:50 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.457 | nll_loss 12.88 | ppl 7539.91 | wps 43778 | wpb 510.9 | bsz 1 | num_updates 7786 | best_loss 8.725
2022-03-06 20:12:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7786 updates
2022-03-06 20:12:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:12:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 160 @ 7786 updates, score 13.457) (writing took 1.9275977406650782 seconds)
2022-03-06 20:12:52 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-06 20:12:52 | INFO | train | epoch 160 | loss 2.15 | nll_loss 0.698 | ppl 1.62 | wps 25027.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7786 | lr 0.000358379 | gnorm 0.757 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 20231
2022-03-06 20:12:52 | INFO | fairseq.trainer | begin training epoch 161
2022-03-06 20:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:13:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:13:29 | INFO | train_inner | epoch 161:     15 / 49 loss=2.152, nll_loss=0.7, ppl=1.62, wps=24830.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.757, loss_scale=16, train_wall=224, gb_free=8.8, wall=20268
2022-03-06 20:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:14:57 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.351 | nll_loss 12.77 | ppl 6985.75 | wps 43975 | wpb 510.9 | bsz 1 | num_updates 7834 | best_loss 8.725
2022-03-06 20:14:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7834 updates
2022-03-06 20:14:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 161 @ 7834 updates, score 13.351) (writing took 1.887672738172114 seconds)
2022-03-06 20:14:59 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-06 20:14:59 | INFO | train | epoch 161 | loss 2.142 | nll_loss 0.69 | ppl 1.61 | wps 24530.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7834 | lr 0.00035728 | gnorm 0.75 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 20357
2022-03-06 20:14:59 | INFO | fairseq.trainer | begin training epoch 162
2022-03-06 20:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:17:04 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.298 | nll_loss 12.71 | ppl 6699 | wps 43879.5 | wpb 510.9 | bsz 1 | num_updates 7883 | best_loss 8.725
2022-03-06 20:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7883 updates
2022-03-06 20:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 162 @ 7883 updates, score 13.298) (writing took 1.8544476134702563 seconds)
2022-03-06 20:17:06 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-06 20:17:06 | INFO | train | epoch 162 | loss 2.139 | nll_loss 0.687 | ppl 1.61 | wps 25063.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7883 | lr 0.000356167 | gnorm 0.753 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 20484
2022-03-06 20:17:06 | INFO | fairseq.trainer | begin training epoch 163
2022-03-06 20:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:17:48 | INFO | train_inner | epoch 163:     17 / 49 loss=2.138, nll_loss=0.687, ppl=1.61, wps=25085.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.748, loss_scale=16, train_wall=222, gb_free=8.8, wall=20526
2022-03-06 20:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:19:11 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.356 | nll_loss 12.766 | ppl 6966.55 | wps 43946.7 | wpb 510.9 | bsz 1 | num_updates 7932 | best_loss 8.725
2022-03-06 20:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7932 updates
2022-03-06 20:19:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 163 @ 7932 updates, score 13.356) (writing took 2.0186729710549116 seconds)
2022-03-06 20:19:13 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-06 20:19:13 | INFO | train | epoch 163 | loss 2.131 | nll_loss 0.68 | ppl 1.6 | wps 25015.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 7932 | lr 0.000355066 | gnorm 0.741 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 20611
2022-03-06 20:19:13 | INFO | fairseq.trainer | begin training epoch 164
2022-03-06 20:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:19:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:21:18 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.429 | nll_loss 12.855 | ppl 7410.92 | wps 44086.4 | wpb 510.9 | bsz 1 | num_updates 7980 | best_loss 8.725
2022-03-06 20:21:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7980 updates
2022-03-06 20:21:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:21:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:21:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 164 @ 7980 updates, score 13.429) (writing took 1.8069851668551564 seconds)
2022-03-06 20:21:20 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-06 20:21:20 | INFO | train | epoch 164 | loss 2.126 | nll_loss 0.675 | ppl 1.6 | wps 24577.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 7980 | lr 0.000353996 | gnorm 0.748 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 20738
2022-03-06 20:21:20 | INFO | fairseq.trainer | begin training epoch 165
2022-03-06 20:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:22:09 | INFO | train_inner | epoch 165:     20 / 49 loss=2.127, nll_loss=0.676, ppl=1.6, wps=24840.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.748, loss_scale=16, train_wall=224, gb_free=8.8, wall=20787
2022-03-06 20:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:23:25 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.314 | nll_loss 12.729 | ppl 6788.66 | wps 44061.7 | wpb 510.9 | bsz 1 | num_updates 8029 | best_loss 8.725
2022-03-06 20:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8029 updates
2022-03-06 20:23:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:23:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:23:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 165 @ 8029 updates, score 13.314) (writing took 1.9906878229230642 seconds)
2022-03-06 20:23:27 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-06 20:23:27 | INFO | train | epoch 165 | loss 2.12 | nll_loss 0.67 | ppl 1.59 | wps 25027.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8029 | lr 0.000352914 | gnorm 0.737 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 20865
2022-03-06 20:23:27 | INFO | fairseq.trainer | begin training epoch 166
2022-03-06 20:23:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:25:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:25:31 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.375 | nll_loss 12.796 | ppl 7111.91 | wps 44113.6 | wpb 510.9 | bsz 1 | num_updates 8077 | best_loss 8.725
2022-03-06 20:25:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8077 updates
2022-03-06 20:25:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:25:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:25:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 166 @ 8077 updates, score 13.375) (writing took 1.8773832833394408 seconds)
2022-03-06 20:25:33 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-06 20:25:33 | INFO | train | epoch 166 | loss 2.115 | nll_loss 0.664 | ppl 1.58 | wps 24566.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8077 | lr 0.000351864 | gnorm 0.744 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 20992
2022-03-06 20:25:33 | INFO | fairseq.trainer | begin training epoch 167
2022-03-06 20:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:26:30 | INFO | train_inner | epoch 167:     23 / 49 loss=2.114, nll_loss=0.663, ppl=1.58, wps=24860, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.734, loss_scale=16, train_wall=224, gb_free=8.8, wall=21048
2022-03-06 20:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:27:38 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.342 | nll_loss 12.765 | ppl 6960.1 | wps 44005.2 | wpb 510.9 | bsz 1 | num_updates 8126 | best_loss 8.725
2022-03-06 20:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8126 updates
2022-03-06 20:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:27:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 167 @ 8126 updates, score 13.342) (writing took 1.749278805218637 seconds)
2022-03-06 20:27:40 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-06 20:27:40 | INFO | train | epoch 167 | loss 2.108 | nll_loss 0.658 | ppl 1.58 | wps 25123.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8126 | lr 0.000350802 | gnorm 0.729 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 21118
2022-03-06 20:27:40 | INFO | fairseq.trainer | begin training epoch 168
2022-03-06 20:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:29:44 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.374 | nll_loss 12.799 | ppl 7127.36 | wps 44335.7 | wpb 510.9 | bsz 1 | num_updates 8175 | best_loss 8.725
2022-03-06 20:29:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8175 updates
2022-03-06 20:29:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:29:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 168 @ 8175 updates, score 13.374) (writing took 1.7147540096193552 seconds)
2022-03-06 20:29:46 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-06 20:29:46 | INFO | train | epoch 168 | loss 2.105 | nll_loss 0.655 | ppl 1.57 | wps 25170 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8175 | lr 0.000349749 | gnorm 0.733 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 21244
2022-03-06 20:29:46 | INFO | fairseq.trainer | begin training epoch 169
2022-03-06 20:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:30:48 | INFO | train_inner | epoch 169:     25 / 49 loss=2.104, nll_loss=0.654, ppl=1.57, wps=25175.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.732, loss_scale=32, train_wall=221, gb_free=8.8, wall=21306
2022-03-06 20:30:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:31:51 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.394 | nll_loss 12.827 | ppl 7267.84 | wps 44546.3 | wpb 510.9 | bsz 1 | num_updates 8223 | best_loss 8.725
2022-03-06 20:31:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8223 updates
2022-03-06 20:31:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:31:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 169 @ 8223 updates, score 13.394) (writing took 1.8782256869599223 seconds)
2022-03-06 20:31:53 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-06 20:31:53 | INFO | train | epoch 169 | loss 2.099 | nll_loss 0.649 | ppl 1.57 | wps 24625 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8223 | lr 0.000348726 | gnorm 0.745 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 21371
2022-03-06 20:31:53 | INFO | fairseq.trainer | begin training epoch 170
2022-03-06 20:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:33:57 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.408 | nll_loss 12.834 | ppl 7301.16 | wps 44394.5 | wpb 510.9 | bsz 1 | num_updates 8272 | best_loss 8.725
2022-03-06 20:33:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8272 updates
2022-03-06 20:33:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:33:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 170 @ 8272 updates, score 13.408) (writing took 1.9573965389281511 seconds)
2022-03-06 20:33:59 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-06 20:33:59 | INFO | train | epoch 170 | loss 2.093 | nll_loss 0.644 | ppl 1.56 | wps 25129.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8272 | lr 0.000347692 | gnorm 0.72 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 21497
2022-03-06 20:33:59 | INFO | fairseq.trainer | begin training epoch 171
2022-03-06 20:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:35:08 | INFO | train_inner | epoch 171:     28 / 49 loss=2.093, nll_loss=0.644, ppl=1.56, wps=24939.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.734, loss_scale=16, train_wall=223, gb_free=8.8, wall=21566
2022-03-06 20:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:36:03 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.346 | nll_loss 12.772 | ppl 6995.56 | wps 44499.8 | wpb 510.9 | bsz 1 | num_updates 8321 | best_loss 8.725
2022-03-06 20:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8321 updates
2022-03-06 20:36:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:36:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:36:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 171 @ 8321 updates, score 13.346) (writing took 1.8218996496871114 seconds)
2022-03-06 20:36:05 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-06 20:36:05 | INFO | train | epoch 171 | loss 2.088 | nll_loss 0.639 | ppl 1.56 | wps 25170.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8321 | lr 0.000346667 | gnorm 0.729 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 21623
2022-03-06 20:36:05 | INFO | fairseq.trainer | begin training epoch 172
2022-03-06 20:36:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:38:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:38:10 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.354 | nll_loss 12.787 | ppl 7066.04 | wps 44164 | wpb 510.9 | bsz 1 | num_updates 8370 | best_loss 8.725
2022-03-06 20:38:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8370 updates
2022-03-06 20:38:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:38:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 172 @ 8370 updates, score 13.354) (writing took 1.8466713046655059 seconds)
2022-03-06 20:38:12 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-06 20:38:12 | INFO | train | epoch 172 | loss 2.084 | nll_loss 0.635 | ppl 1.55 | wps 25148.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8370 | lr 0.000345651 | gnorm 0.717 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 21750
2022-03-06 20:38:12 | INFO | fairseq.trainer | begin training epoch 173
2022-03-06 20:38:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:38:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:39:28 | INFO | train_inner | epoch 173:     31 / 49 loss=2.083, nll_loss=0.634, ppl=1.55, wps=24931.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.711, loss_scale=16, train_wall=223, gb_free=8.8, wall=21826
2022-03-06 20:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:40:16 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.434 | nll_loss 12.869 | ppl 7480.85 | wps 44157.7 | wpb 510.9 | bsz 1 | num_updates 8418 | best_loss 8.725
2022-03-06 20:40:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8418 updates
2022-03-06 20:40:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:40:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 173 @ 8418 updates, score 13.434) (writing took 1.9225494032725692 seconds)
2022-03-06 20:40:18 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-06 20:40:18 | INFO | train | epoch 173 | loss 2.078 | nll_loss 0.629 | ppl 1.55 | wps 24568.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8418 | lr 0.000344664 | gnorm 0.711 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 21877
2022-03-06 20:40:18 | INFO | fairseq.trainer | begin training epoch 174
2022-03-06 20:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:42:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:42:23 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.423 | nll_loss 12.857 | ppl 7421.04 | wps 43832.5 | wpb 510.9 | bsz 1 | num_updates 8467 | best_loss 8.725
2022-03-06 20:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8467 updates
2022-03-06 20:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 174 @ 8467 updates, score 13.423) (writing took 1.7506409669294953 seconds)
2022-03-06 20:42:25 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-06 20:42:25 | INFO | train | epoch 174 | loss 2.073 | nll_loss 0.625 | ppl 1.54 | wps 25092.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8467 | lr 0.000343665 | gnorm 0.707 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 22003
2022-03-06 20:42:25 | INFO | fairseq.trainer | begin training epoch 175
2022-03-06 20:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:43:47 | INFO | train_inner | epoch 175:     33 / 49 loss=2.073, nll_loss=0.624, ppl=1.54, wps=25089.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.706, loss_scale=16, train_wall=222, gb_free=8.8, wall=22085
2022-03-06 20:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:44:30 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.423 | nll_loss 12.857 | ppl 7417.99 | wps 43916.8 | wpb 510.9 | bsz 1 | num_updates 8516 | best_loss 8.725
2022-03-06 20:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8516 updates
2022-03-06 20:44:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 175 @ 8516 updates, score 13.423) (writing took 1.8284246595576406 seconds)
2022-03-06 20:44:32 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-06 20:44:32 | INFO | train | epoch 175 | loss 2.068 | nll_loss 0.62 | ppl 1.54 | wps 25039.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8516 | lr 0.000342675 | gnorm 0.695 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 22130
2022-03-06 20:44:32 | INFO | fairseq.trainer | begin training epoch 176
2022-03-06 20:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:46:37 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.477 | nll_loss 12.927 | ppl 7789.38 | wps 43925.4 | wpb 510.9 | bsz 1 | num_updates 8565 | best_loss 8.725
2022-03-06 20:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8565 updates
2022-03-06 20:46:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:46:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:46:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 176 @ 8565 updates, score 13.477) (writing took 1.840513183735311 seconds)
2022-03-06 20:46:39 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-06 20:46:39 | INFO | train | epoch 176 | loss 2.066 | nll_loss 0.618 | ppl 1.53 | wps 25051.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8565 | lr 0.000341693 | gnorm 0.708 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 22257
2022-03-06 20:46:39 | INFO | fairseq.trainer | begin training epoch 177
2022-03-06 20:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:48:05 | INFO | train_inner | epoch 177:     35 / 49 loss=2.064, nll_loss=0.616, ppl=1.53, wps=25086.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.699, loss_scale=32, train_wall=222, gb_free=8.8, wall=22344
2022-03-06 20:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:48:44 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.406 | nll_loss 12.85 | ppl 7381.58 | wps 43497.3 | wpb 510.9 | bsz 1 | num_updates 8614 | best_loss 8.725
2022-03-06 20:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8614 updates
2022-03-06 20:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 177 @ 8614 updates, score 13.406) (writing took 1.8061544802039862 seconds)
2022-03-06 20:48:46 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-06 20:48:46 | INFO | train | epoch 177 | loss 2.058 | nll_loss 0.611 | ppl 1.53 | wps 25060.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8614 | lr 0.00034072 | gnorm 0.684 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 22384
2022-03-06 20:48:46 | INFO | fairseq.trainer | begin training epoch 178
2022-03-06 20:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:50:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:50:51 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.396 | nll_loss 12.829 | ppl 7277.82 | wps 44028.9 | wpb 510.9 | bsz 1 | num_updates 8662 | best_loss 8.725
2022-03-06 20:50:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8662 updates
2022-03-06 20:50:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 178 @ 8662 updates, score 13.396) (writing took 1.8203723765909672 seconds)
2022-03-06 20:50:52 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-06 20:50:52 | INFO | train | epoch 178 | loss 2.055 | nll_loss 0.608 | ppl 1.52 | wps 24538.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8662 | lr 0.000339775 | gnorm 0.696 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 22511
2022-03-06 20:50:52 | INFO | fairseq.trainer | begin training epoch 179
2022-03-06 20:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:52:26 | INFO | train_inner | epoch 179:     38 / 49 loss=2.054, nll_loss=0.607, ppl=1.52, wps=24843.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.695, loss_scale=32, train_wall=224, gb_free=8.8, wall=22605
2022-03-06 20:52:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:52:57 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.445 | nll_loss 12.895 | ppl 7617.06 | wps 43763.2 | wpb 510.9 | bsz 1 | num_updates 8710 | best_loss 8.725
2022-03-06 20:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8710 updates
2022-03-06 20:52:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:52:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:52:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 179 @ 8710 updates, score 13.445) (writing took 1.9526188652962446 seconds)
2022-03-06 20:52:59 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-06 20:52:59 | INFO | train | epoch 179 | loss 2.051 | nll_loss 0.605 | ppl 1.52 | wps 24516.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8710 | lr 0.000338837 | gnorm 0.699 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 22638
2022-03-06 20:52:59 | INFO | fairseq.trainer | begin training epoch 180
2022-03-06 20:52:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:55:04 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.32 | nll_loss 12.752 | ppl 6896.46 | wps 43895.8 | wpb 510.9 | bsz 1 | num_updates 8759 | best_loss 8.725
2022-03-06 20:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8759 updates
2022-03-06 20:55:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 180 @ 8759 updates, score 13.32) (writing took 2.015444084070623 seconds)
2022-03-06 20:55:06 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-06 20:55:06 | INFO | train | epoch 180 | loss 2.047 | nll_loss 0.6 | ppl 1.52 | wps 25022.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8759 | lr 0.000337888 | gnorm 0.702 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 22765
2022-03-06 20:55:06 | INFO | fairseq.trainer | begin training epoch 181
2022-03-06 20:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:56:48 | INFO | train_inner | epoch 181:     41 / 49 loss=2.045, nll_loss=0.598, ppl=1.51, wps=24816, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.692, loss_scale=16, train_wall=224, gb_free=8.8, wall=22866
2022-03-06 20:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:57:11 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.361 | nll_loss 12.796 | ppl 7109.59 | wps 44015.7 | wpb 510.9 | bsz 1 | num_updates 8808 | best_loss 8.725
2022-03-06 20:57:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8808 updates
2022-03-06 20:57:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 181 @ 8808 updates, score 13.361) (writing took 2.013040089979768 seconds)
2022-03-06 20:57:13 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-06 20:57:13 | INFO | train | epoch 181 | loss 2.041 | nll_loss 0.594 | ppl 1.51 | wps 25013.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8808 | lr 0.000336947 | gnorm 0.678 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 22892
2022-03-06 20:57:13 | INFO | fairseq.trainer | begin training epoch 182
2022-03-06 20:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:59:18 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.388 | nll_loss 12.828 | ppl 7270.49 | wps 43832.2 | wpb 510.9 | bsz 1 | num_updates 8857 | best_loss 8.725
2022-03-06 20:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8857 updates
2022-03-06 20:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 182 @ 8857 updates, score 13.388) (writing took 1.9908277709037066 seconds)
2022-03-06 20:59:20 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-06 20:59:20 | INFO | train | epoch 182 | loss 2.036 | nll_loss 0.59 | ppl 1.51 | wps 25013.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8857 | lr 0.000336013 | gnorm 0.673 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 23019
2022-03-06 20:59:20 | INFO | fairseq.trainer | begin training epoch 183
2022-03-06 20:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:01:07 | INFO | train_inner | epoch 183:     43 / 49 loss=2.036, nll_loss=0.59, ppl=1.51, wps=25042.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.678, loss_scale=32, train_wall=222, gb_free=8.8, wall=23125
2022-03-06 21:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:01:25 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.46 | nll_loss 12.907 | ppl 7680.5 | wps 43969.1 | wpb 510.9 | bsz 1 | num_updates 8906 | best_loss 8.725
2022-03-06 21:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8906 updates
2022-03-06 21:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 183 @ 8906 updates, score 13.46) (writing took 1.8985784454271197 seconds)
2022-03-06 21:01:27 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-06 21:01:27 | INFO | train | epoch 183 | loss 2.033 | nll_loss 0.587 | ppl 1.5 | wps 25036 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 8906 | lr 0.000335088 | gnorm 0.68 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 23146
2022-03-06 21:01:27 | INFO | fairseq.trainer | begin training epoch 184
2022-03-06 21:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:02:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:03:32 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.29 | nll_loss 12.726 | ppl 6774.38 | wps 43755.3 | wpb 510.9 | bsz 1 | num_updates 8954 | best_loss 8.725
2022-03-06 21:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8954 updates
2022-03-06 21:03:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:03:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:03:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 184 @ 8954 updates, score 13.29) (writing took 1.898720882833004 seconds)
2022-03-06 21:03:34 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-06 21:03:34 | INFO | train | epoch 184 | loss 2.028 | nll_loss 0.582 | ppl 1.5 | wps 24527.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8954 | lr 0.000334188 | gnorm 0.671 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 23273
2022-03-06 21:03:34 | INFO | fairseq.trainer | begin training epoch 185
2022-03-06 21:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:05:28 | INFO | train_inner | epoch 185:     46 / 49 loss=2.028, nll_loss=0.582, ppl=1.5, wps=24828.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.674, loss_scale=16, train_wall=224, gb_free=8.8, wall=23386
2022-03-06 21:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:05:39 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.342 | nll_loss 12.774 | ppl 7003.41 | wps 43590.4 | wpb 510.9 | bsz 1 | num_updates 9003 | best_loss 8.725
2022-03-06 21:05:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9003 updates
2022-03-06 21:05:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:05:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 185 @ 9003 updates, score 13.342) (writing took 1.7878375267609954 seconds)
2022-03-06 21:05:41 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-06 21:05:41 | INFO | train | epoch 185 | loss 2.026 | nll_loss 0.581 | ppl 1.5 | wps 25044.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9003 | lr 0.000333278 | gnorm 0.678 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 23399
2022-03-06 21:05:41 | INFO | fairseq.trainer | begin training epoch 186
2022-03-06 21:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:07:46 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.372 | nll_loss 12.813 | ppl 7195.01 | wps 43762.3 | wpb 510.9 | bsz 1 | num_updates 9052 | best_loss 8.725
2022-03-06 21:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9052 updates
2022-03-06 21:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 186 @ 9052 updates, score 13.372) (writing took 1.7594187669456005 seconds)
2022-03-06 21:07:48 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-06 21:07:48 | INFO | train | epoch 186 | loss 2.023 | nll_loss 0.578 | ppl 1.49 | wps 25051.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9052 | lr 0.000332375 | gnorm 0.671 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 23526
2022-03-06 21:07:48 | INFO | fairseq.trainer | begin training epoch 187
2022-03-06 21:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:09:47 | INFO | train_inner | epoch 187:     48 / 49 loss=2.021, nll_loss=0.576, ppl=1.49, wps=25088.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.667, loss_scale=32, train_wall=222, gb_free=8.8, wall=23645
2022-03-06 21:09:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:09:53 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.386 | nll_loss 12.821 | ppl 7236.6 | wps 43939.8 | wpb 510.9 | bsz 1 | num_updates 9101 | best_loss 8.725
2022-03-06 21:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9101 updates
2022-03-06 21:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 187 @ 9101 updates, score 13.386) (writing took 1.9005260961130261 seconds)
2022-03-06 21:09:55 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-06 21:09:55 | INFO | train | epoch 187 | loss 2.017 | nll_loss 0.573 | ppl 1.49 | wps 25054.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9101 | lr 0.000331479 | gnorm 0.661 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 23653
2022-03-06 21:09:55 | INFO | fairseq.trainer | begin training epoch 188
2022-03-06 21:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:11:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:12:00 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.329 | nll_loss 12.761 | ppl 6940.95 | wps 43793.5 | wpb 510.9 | bsz 1 | num_updates 9150 | best_loss 8.725
2022-03-06 21:12:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9150 updates
2022-03-06 21:12:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:12:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:12:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 188 @ 9150 updates, score 13.329) (writing took 1.9803309924900532 seconds)
2022-03-06 21:12:02 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-06 21:12:02 | INFO | train | epoch 188 | loss 2.013 | nll_loss 0.569 | ppl 1.48 | wps 25004.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9150 | lr 0.00033059 | gnorm 0.657 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 23780
2022-03-06 21:12:02 | INFO | fairseq.trainer | begin training epoch 189
2022-03-06 21:12:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:14:07 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.4 | nll_loss 12.847 | ppl 7367.26 | wps 43605.9 | wpb 510.9 | bsz 1 | num_updates 9198 | best_loss 8.725
2022-03-06 21:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9198 updates
2022-03-06 21:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:14:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 189 @ 9198 updates, score 13.4) (writing took 2.0109606431797147 seconds)
2022-03-06 21:14:09 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-06 21:14:09 | INFO | train | epoch 189 | loss 2.01 | nll_loss 0.566 | ppl 1.48 | wps 24493.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 9198 | lr 0.000329726 | gnorm 0.666 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 23907
2022-03-06 21:14:09 | INFO | fairseq.trainer | begin training epoch 190
2022-03-06 21:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:14:14 | INFO | train_inner | epoch 190:      2 / 49 loss=2.011, nll_loss=0.567, ppl=1.48, wps=24139, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=9200, lr=0.00032969, gnorm=0.663, loss_scale=16, train_wall=223, gb_free=8.8, wall=23912
2022-03-06 21:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:16:14 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.445 | nll_loss 12.894 | ppl 7614.11 | wps 43973.3 | wpb 510.9 | bsz 1 | num_updates 9247 | best_loss 8.725
2022-03-06 21:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9247 updates
2022-03-06 21:16:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 190 @ 9247 updates, score 13.445) (writing took 1.9159789830446243 seconds)
2022-03-06 21:16:16 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-06 21:16:16 | INFO | train | epoch 190 | loss 2.006 | nll_loss 0.563 | ppl 1.48 | wps 25068.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9247 | lr 0.000328851 | gnorm 0.658 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 24034
2022-03-06 21:16:16 | INFO | fairseq.trainer | begin training epoch 191
2022-03-06 21:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:18:20 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.401 | nll_loss 12.843 | ppl 7345.95 | wps 44401.5 | wpb 510.9 | bsz 1 | num_updates 9296 | best_loss 8.725
2022-03-06 21:18:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9296 updates
2022-03-06 21:18:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:18:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:18:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 191 @ 9296 updates, score 13.401) (writing took 1.7712393011897802 seconds)
2022-03-06 21:18:22 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-06 21:18:22 | INFO | train | epoch 191 | loss 2.004 | nll_loss 0.561 | ppl 1.48 | wps 25148.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9296 | lr 0.000327983 | gnorm 0.653 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 24160
2022-03-06 21:18:22 | INFO | fairseq.trainer | begin training epoch 192
2022-03-06 21:18:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:18:32 | INFO | train_inner | epoch 192:      4 / 49 loss=2.004, nll_loss=0.561, ppl=1.48, wps=25140.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.656, loss_scale=16, train_wall=221, gb_free=8.8, wall=24170
2022-03-06 21:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:20:27 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.319 | nll_loss 12.758 | ppl 6928.05 | wps 44828 | wpb 510.9 | bsz 1 | num_updates 9345 | best_loss 8.725
2022-03-06 21:20:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9345 updates
2022-03-06 21:20:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:20:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 192 @ 9345 updates, score 13.319) (writing took 2.004983538761735 seconds)
2022-03-06 21:20:29 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-06 21:20:29 | INFO | train | epoch 192 | loss 1.998 | nll_loss 0.556 | ppl 1.47 | wps 25139.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9345 | lr 0.000327122 | gnorm 0.656 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 24287
2022-03-06 21:20:29 | INFO | fairseq.trainer | begin training epoch 193
2022-03-06 21:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:22:33 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.361 | nll_loss 12.806 | ppl 7159.35 | wps 44562.4 | wpb 510.9 | bsz 1 | num_updates 9394 | best_loss 8.725
2022-03-06 21:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9394 updates
2022-03-06 21:22:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:22:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:22:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 193 @ 9394 updates, score 13.361) (writing took 1.796482989564538 seconds)
2022-03-06 21:22:35 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-06 21:22:35 | INFO | train | epoch 193 | loss 1.996 | nll_loss 0.554 | ppl 1.47 | wps 25163.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9394 | lr 0.000326268 | gnorm 0.65 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 24413
2022-03-06 21:22:35 | INFO | fairseq.trainer | begin training epoch 194
2022-03-06 21:22:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:22:50 | INFO | train_inner | epoch 194:      6 / 49 loss=1.997, nll_loss=0.554, ppl=1.47, wps=25171.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.651, loss_scale=32, train_wall=221, gb_free=8.8, wall=24428
2022-03-06 21:24:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:24:39 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.412 | nll_loss 12.863 | ppl 7450.56 | wps 44487.2 | wpb 510.9 | bsz 1 | num_updates 9442 | best_loss 8.725
2022-03-06 21:24:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9442 updates
2022-03-06 21:24:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 194 @ 9442 updates, score 13.412) (writing took 1.972033373080194 seconds)
2022-03-06 21:24:41 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-06 21:24:41 | INFO | train | epoch 194 | loss 1.992 | nll_loss 0.55 | ppl 1.46 | wps 24596.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 9442 | lr 0.000325438 | gnorm 0.64 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 24540
2022-03-06 21:24:41 | INFO | fairseq.trainer | begin training epoch 195
2022-03-06 21:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:26:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:26:46 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.386 | nll_loss 12.837 | ppl 7316.17 | wps 44624.8 | wpb 510.9 | bsz 1 | num_updates 9490 | best_loss 8.725
2022-03-06 21:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9490 updates
2022-03-06 21:26:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:26:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:26:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 195 @ 9490 updates, score 13.386) (writing took 1.8462249441072345 seconds)
2022-03-06 21:26:48 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-06 21:26:48 | INFO | train | epoch 195 | loss 1.99 | nll_loss 0.548 | ppl 1.46 | wps 24623.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 9490 | lr 0.000324614 | gnorm 0.648 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 24666
2022-03-06 21:26:48 | INFO | fairseq.trainer | begin training epoch 196
2022-03-06 21:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:27:13 | INFO | train_inner | epoch 196:     10 / 49 loss=1.99, nll_loss=0.548, ppl=1.46, wps=24693.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.643, loss_scale=16, train_wall=226, gb_free=8.8, wall=24691
2022-03-06 21:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:28:52 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.443 | nll_loss 12.895 | ppl 7618.85 | wps 44258.2 | wpb 510.9 | bsz 1 | num_updates 9539 | best_loss 8.725
2022-03-06 21:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9539 updates
2022-03-06 21:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 196 @ 9539 updates, score 13.443) (writing took 1.992637386545539 seconds)
2022-03-06 21:28:54 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-06 21:28:54 | INFO | train | epoch 196 | loss 1.987 | nll_loss 0.546 | ppl 1.46 | wps 25115.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9539 | lr 0.000323779 | gnorm 0.643 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 24793
2022-03-06 21:28:54 | INFO | fairseq.trainer | begin training epoch 197
2022-03-06 21:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:30:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:30:59 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.396 | nll_loss 12.847 | ppl 7368.03 | wps 43973.9 | wpb 510.9 | bsz 1 | num_updates 9588 | best_loss 8.725
2022-03-06 21:30:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9588 updates
2022-03-06 21:30:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:31:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:31:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 197 @ 9588 updates, score 13.396) (writing took 1.816698889248073 seconds)
2022-03-06 21:31:01 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-06 21:31:01 | INFO | train | epoch 197 | loss 1.981 | nll_loss 0.54 | ppl 1.45 | wps 25155.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9588 | lr 0.000322951 | gnorm 0.631 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 24919
2022-03-06 21:31:01 | INFO | fairseq.trainer | begin training epoch 198
2022-03-06 21:31:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:31:30 | INFO | train_inner | epoch 198:     12 / 49 loss=1.983, nll_loss=0.542, ppl=1.46, wps=25166.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.64, loss_scale=16, train_wall=221, gb_free=8.8, wall=24949
2022-03-06 21:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:33:05 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.365 | nll_loss 12.812 | ppl 7192 | wps 44474.5 | wpb 510.9 | bsz 1 | num_updates 9637 | best_loss 8.725
2022-03-06 21:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9637 updates
2022-03-06 21:33:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 198 @ 9637 updates, score 13.365) (writing took 1.9790660478174686 seconds)
2022-03-06 21:33:07 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-06 21:33:07 | INFO | train | epoch 198 | loss 1.981 | nll_loss 0.54 | ppl 1.45 | wps 25128.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9637 | lr 0.000322128 | gnorm 0.667 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 25045
2022-03-06 21:33:07 | INFO | fairseq.trainer | begin training epoch 199
2022-03-06 21:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:35:12 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.333 | nll_loss 12.781 | ppl 7040.62 | wps 44106.3 | wpb 510.9 | bsz 1 | num_updates 9685 | best_loss 8.725
2022-03-06 21:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9685 updates
2022-03-06 21:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 199 @ 9685 updates, score 13.333) (writing took 1.963065984658897 seconds)
2022-03-06 21:35:14 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-06 21:35:14 | INFO | train | epoch 199 | loss 1.973 | nll_loss 0.533 | ppl 1.45 | wps 24574.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 9685 | lr 0.000321329 | gnorm 0.625 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 25172
2022-03-06 21:35:14 | INFO | fairseq.trainer | begin training epoch 200
2022-03-06 21:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:35:51 | INFO | train_inner | epoch 200:     15 / 49 loss=1.975, nll_loss=0.535, ppl=1.45, wps=24891.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.64, loss_scale=16, train_wall=223, gb_free=8.8, wall=25209
2022-03-06 21:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:37:19 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.475 | nll_loss 12.933 | ppl 7820.99 | wps 43808.1 | wpb 510.9 | bsz 1 | num_updates 9734 | best_loss 8.725
2022-03-06 21:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9734 updates
2022-03-06 21:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 200 @ 9734 updates, score 13.475) (writing took 2.112993160262704 seconds)
2022-03-06 21:37:21 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-06 21:37:21 | INFO | train | epoch 200 | loss 1.972 | nll_loss 0.532 | ppl 1.45 | wps 25029.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9734 | lr 0.000320519 | gnorm 0.636 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 25299
2022-03-06 21:37:21 | INFO | fairseq.trainer | begin training epoch 201
2022-03-06 21:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:39:26 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.417 | nll_loss 12.871 | ppl 7491.93 | wps 43672.7 | wpb 510.9 | bsz 1 | num_updates 9783 | best_loss 8.725
2022-03-06 21:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9783 updates
2022-03-06 21:39:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:39:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 201 @ 9783 updates, score 13.417) (writing took 2.16082794778049 seconds)
2022-03-06 21:39:28 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-06 21:39:28 | INFO | train | epoch 201 | loss 1.969 | nll_loss 0.529 | ppl 1.44 | wps 24955.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9783 | lr 0.000319716 | gnorm 0.628 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 25426
2022-03-06 21:39:28 | INFO | fairseq.trainer | begin training epoch 202
2022-03-06 21:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:40:10 | INFO | train_inner | epoch 202:     17 / 49 loss=1.969, nll_loss=0.53, ppl=1.44, wps=25014.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.634, loss_scale=32, train_wall=222, gb_free=8.8, wall=25469
2022-03-06 21:41:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:41:33 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.433 | nll_loss 12.89 | ppl 7592.03 | wps 43986.6 | wpb 510.9 | bsz 1 | num_updates 9832 | best_loss 8.725
2022-03-06 21:41:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9832 updates
2022-03-06 21:41:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:41:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 202 @ 9832 updates, score 13.433) (writing took 2.136033627204597 seconds)
2022-03-06 21:41:35 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-06 21:41:35 | INFO | train | epoch 202 | loss 1.966 | nll_loss 0.526 | ppl 1.44 | wps 24997.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9832 | lr 0.000318918 | gnorm 0.625 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 25554
2022-03-06 21:41:35 | INFO | fairseq.trainer | begin training epoch 203
2022-03-06 21:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:43:40 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.426 | nll_loss 12.885 | ppl 7565.71 | wps 43845 | wpb 510.9 | bsz 1 | num_updates 9880 | best_loss 8.725
2022-03-06 21:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9880 updates
2022-03-06 21:43:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:43:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 203 @ 9880 updates, score 13.426) (writing took 2.0337784346193075 seconds)
2022-03-06 21:43:42 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-06 21:43:42 | INFO | train | epoch 203 | loss 1.963 | nll_loss 0.524 | ppl 1.44 | wps 24524.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 9880 | lr 0.000318142 | gnorm 0.625 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 25680
2022-03-06 21:43:42 | INFO | fairseq.trainer | begin training epoch 204
2022-03-06 21:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:44:32 | INFO | train_inner | epoch 204:     20 / 49 loss=1.963, nll_loss=0.524, ppl=1.44, wps=24802.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.62, loss_scale=16, train_wall=224, gb_free=8.8, wall=25730
2022-03-06 21:45:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:47 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.403 | nll_loss 12.857 | ppl 7418.79 | wps 43777.3 | wpb 510.9 | bsz 1 | num_updates 9929 | best_loss 8.725
2022-03-06 21:45:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9929 updates
2022-03-06 21:45:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:45:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:45:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 204 @ 9929 updates, score 13.403) (writing took 1.9274394642561674 seconds)
2022-03-06 21:45:49 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-06 21:45:49 | INFO | train | epoch 204 | loss 1.96 | nll_loss 0.522 | ppl 1.44 | wps 25022.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9929 | lr 0.000317356 | gnorm 0.621 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 25807
2022-03-06 21:45:49 | INFO | fairseq.trainer | begin training epoch 205
2022-03-06 21:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:47:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:47:54 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.371 | nll_loss 12.824 | ppl 7252.12 | wps 43823 | wpb 510.9 | bsz 1 | num_updates 9978 | best_loss 8.725
2022-03-06 21:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9978 updates
2022-03-06 21:47:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:47:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:47:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 205 @ 9978 updates, score 13.371) (writing took 2.0135806892067194 seconds)
2022-03-06 21:47:56 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-06 21:47:56 | INFO | train | epoch 205 | loss 1.958 | nll_loss 0.519 | ppl 1.43 | wps 25031 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 9978 | lr 0.000316576 | gnorm 0.621 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 25934
2022-03-06 21:47:56 | INFO | fairseq.trainer | begin training epoch 206
2022-03-06 21:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:48:51 | INFO | train_inner | epoch 206:     22 / 49 loss=1.957, nll_loss=0.519, ppl=1.43, wps=25065.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.62, loss_scale=16, train_wall=222, gb_free=8.8, wall=25989
2022-03-06 21:49:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:01 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.371 | nll_loss 12.831 | ppl 7285.91 | wps 43968.9 | wpb 510.9 | bsz 1 | num_updates 10026 | best_loss 8.725
2022-03-06 21:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10026 updates
2022-03-06 21:50:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 206 @ 10026 updates, score 13.371) (writing took 1.9451748104766011 seconds)
2022-03-06 21:50:03 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-06 21:50:03 | INFO | train | epoch 206 | loss 1.953 | nll_loss 0.515 | ppl 1.43 | wps 24549.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 10026 | lr 0.000315817 | gnorm 0.622 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 26061
2022-03-06 21:50:03 | INFO | fairseq.trainer | begin training epoch 207
2022-03-06 21:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:08 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.306 | nll_loss 12.761 | ppl 6940.05 | wps 43723.6 | wpb 510.9 | bsz 1 | num_updates 10075 | best_loss 8.725
2022-03-06 21:52:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10075 updates
2022-03-06 21:52:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:52:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:52:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 207 @ 10075 updates, score 13.306) (writing took 2.079927245154977 seconds)
2022-03-06 21:52:10 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-06 21:52:10 | INFO | train | epoch 207 | loss 1.951 | nll_loss 0.513 | ppl 1.43 | wps 25013 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10075 | lr 0.000315049 | gnorm 0.611 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 26188
2022-03-06 21:52:10 | INFO | fairseq.trainer | begin training epoch 208
2022-03-06 21:52:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:53:12 | INFO | train_inner | epoch 208:     25 / 49 loss=1.951, nll_loss=0.513, ppl=1.43, wps=24824.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.614, loss_scale=16, train_wall=224, gb_free=8.8, wall=26250
2022-03-06 21:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:15 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.362 | nll_loss 12.82 | ppl 7230.75 | wps 43798.6 | wpb 510.9 | bsz 1 | num_updates 10124 | best_loss 8.725
2022-03-06 21:54:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10124 updates
2022-03-06 21:54:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:54:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:54:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 208 @ 10124 updates, score 13.362) (writing took 2.044370667077601 seconds)
2022-03-06 21:54:17 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-06 21:54:17 | INFO | train | epoch 208 | loss 1.948 | nll_loss 0.511 | ppl 1.42 | wps 25004 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10124 | lr 0.000314285 | gnorm 0.608 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 26315
2022-03-06 21:54:17 | INFO | fairseq.trainer | begin training epoch 209
2022-03-06 21:54:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:56:22 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.321 | nll_loss 12.77 | ppl 6984.93 | wps 43853.7 | wpb 510.9 | bsz 1 | num_updates 10173 | best_loss 8.725
2022-03-06 21:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10173 updates
2022-03-06 21:56:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:56:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 209 @ 10173 updates, score 13.321) (writing took 1.8298976439982653 seconds)
2022-03-06 21:56:24 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-06 21:56:24 | INFO | train | epoch 209 | loss 1.946 | nll_loss 0.51 | ppl 1.42 | wps 25078.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10173 | lr 0.000313527 | gnorm 0.609 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 26442
2022-03-06 21:56:24 | INFO | fairseq.trainer | begin training epoch 210
2022-03-06 21:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:57:31 | INFO | train_inner | epoch 210:     27 / 49 loss=1.946, nll_loss=0.509, ppl=1.42, wps=25073.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.609, loss_scale=32, train_wall=222, gb_free=8.8, wall=26509
2022-03-06 21:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:58:29 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.366 | nll_loss 12.822 | ppl 7242.4 | wps 43955.4 | wpb 510.9 | bsz 1 | num_updates 10222 | best_loss 8.725
2022-03-06 21:58:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10222 updates
2022-03-06 21:58:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 210 @ 10222 updates, score 13.366) (writing took 2.0892303120344877 seconds)
2022-03-06 21:58:31 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-06 21:58:31 | INFO | train | epoch 210 | loss 1.944 | nll_loss 0.507 | ppl 1.42 | wps 25012.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10222 | lr 0.000312775 | gnorm 0.615 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 26569
2022-03-06 21:58:31 | INFO | fairseq.trainer | begin training epoch 211
2022-03-06 21:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:59:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:00:36 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.437 | nll_loss 12.9 | ppl 7640.97 | wps 43790.9 | wpb 510.9 | bsz 1 | num_updates 10270 | best_loss 8.725
2022-03-06 22:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10270 updates
2022-03-06 22:00:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:00:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:00:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 211 @ 10270 updates, score 13.437) (writing took 1.9431883282959461 seconds)
2022-03-06 22:00:38 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-06 22:00:38 | INFO | train | epoch 211 | loss 1.941 | nll_loss 0.505 | ppl 1.42 | wps 24525.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 10270 | lr 0.000312043 | gnorm 0.608 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 26696
2022-03-06 22:00:38 | INFO | fairseq.trainer | begin training epoch 212
2022-03-06 22:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:01:52 | INFO | train_inner | epoch 212:     30 / 49 loss=1.941, nll_loss=0.505, ppl=1.42, wps=24821.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.607, loss_scale=16, train_wall=224, gb_free=8.8, wall=26770
2022-03-06 22:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:02:43 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.418 | nll_loss 12.882 | ppl 7547.63 | wps 43918.7 | wpb 510.9 | bsz 1 | num_updates 10319 | best_loss 8.725
2022-03-06 22:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10319 updates
2022-03-06 22:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 212 @ 10319 updates, score 13.418) (writing took 2.047497170045972 seconds)
2022-03-06 22:02:45 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-06 22:02:45 | INFO | train | epoch 212 | loss 1.937 | nll_loss 0.501 | ppl 1.41 | wps 25017.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10319 | lr 0.000311301 | gnorm 0.592 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 26823
2022-03-06 22:02:45 | INFO | fairseq.trainer | begin training epoch 213
2022-03-06 22:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:04:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:04:50 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.43 | nll_loss 12.896 | ppl 7623.3 | wps 43822 | wpb 510.9 | bsz 1 | num_updates 10368 | best_loss 8.725
2022-03-06 22:04:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10368 updates
2022-03-06 22:04:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:04:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:04:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 213 @ 10368 updates, score 13.43) (writing took 1.7657696651294827 seconds)
2022-03-06 22:04:52 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-06 22:04:52 | INFO | train | epoch 213 | loss 1.935 | nll_loss 0.499 | ppl 1.41 | wps 25067.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10368 | lr 0.000310565 | gnorm 0.602 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 26950
2022-03-06 22:04:52 | INFO | fairseq.trainer | begin training epoch 214
2022-03-06 22:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:06:11 | INFO | train_inner | epoch 214:     32 / 49 loss=1.934, nll_loss=0.499, ppl=1.41, wps=25065.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.601, loss_scale=32, train_wall=222, gb_free=8.8, wall=27029
2022-03-06 22:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:06:57 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.307 | nll_loss 12.757 | ppl 6922.03 | wps 44095.8 | wpb 510.9 | bsz 1 | num_updates 10417 | best_loss 8.725
2022-03-06 22:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10417 updates
2022-03-06 22:06:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:06:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 214 @ 10417 updates, score 13.307) (writing took 1.8887352393940091 seconds)
2022-03-06 22:06:59 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-06 22:06:59 | INFO | train | epoch 214 | loss 1.932 | nll_loss 0.497 | ppl 1.41 | wps 25053.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10417 | lr 0.000309834 | gnorm 0.6 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 27077
2022-03-06 22:06:59 | INFO | fairseq.trainer | begin training epoch 215
2022-03-06 22:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:09:03 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.406 | nll_loss 12.87 | ppl 7484.39 | wps 43989.5 | wpb 510.9 | bsz 1 | num_updates 10466 | best_loss 8.725
2022-03-06 22:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10466 updates
2022-03-06 22:09:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 215 @ 10466 updates, score 13.406) (writing took 1.918108582496643 seconds)
2022-03-06 22:09:05 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-06 22:09:05 | INFO | train | epoch 215 | loss 1.929 | nll_loss 0.494 | ppl 1.41 | wps 25044.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10466 | lr 0.000309108 | gnorm 0.598 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 27204
2022-03-06 22:09:05 | INFO | fairseq.trainer | begin training epoch 216
2022-03-06 22:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:09:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:10:32 | INFO | train_inner | epoch 216:     35 / 49 loss=1.93, nll_loss=0.495, ppl=1.41, wps=24856.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.604, loss_scale=16, train_wall=224, gb_free=8.8, wall=27290
2022-03-06 22:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:11:10 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.362 | nll_loss 12.823 | ppl 7244.74 | wps 44016.4 | wpb 510.9 | bsz 1 | num_updates 10514 | best_loss 8.725
2022-03-06 22:11:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10514 updates
2022-03-06 22:11:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:11:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:11:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 216 @ 10514 updates, score 13.362) (writing took 1.9438306326046586 seconds)
2022-03-06 22:11:12 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-06 22:11:12 | INFO | train | epoch 216 | loss 1.928 | nll_loss 0.493 | ppl 1.41 | wps 24568.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 10514 | lr 0.000308401 | gnorm 0.609 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 27330
2022-03-06 22:11:12 | INFO | fairseq.trainer | begin training epoch 217
2022-03-06 22:11:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:13:17 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.405 | nll_loss 12.867 | ppl 7472.06 | wps 44671.1 | wpb 510.9 | bsz 1 | num_updates 10563 | best_loss 8.725
2022-03-06 22:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10563 updates
2022-03-06 22:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:13:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:13:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 217 @ 10563 updates, score 13.405) (writing took 1.9282662086188793 seconds)
2022-03-06 22:13:19 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-06 22:13:19 | INFO | train | epoch 217 | loss 1.923 | nll_loss 0.489 | ppl 1.4 | wps 25127.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10563 | lr 0.000307685 | gnorm 0.595 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 27457
2022-03-06 22:13:19 | INFO | fairseq.trainer | begin training epoch 218
2022-03-06 22:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:14:50 | INFO | train_inner | epoch 218:     37 / 49 loss=1.922, nll_loss=0.488, ppl=1.4, wps=25153.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.593, loss_scale=16, train_wall=221, gb_free=8.8, wall=27548
2022-03-06 22:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:15:23 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.452 | nll_loss 12.921 | ppl 7753.84 | wps 44123.9 | wpb 510.9 | bsz 1 | num_updates 10612 | best_loss 8.725
2022-03-06 22:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10612 updates
2022-03-06 22:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 218 @ 10612 updates, score 13.452) (writing took 1.8095665462315083 seconds)
2022-03-06 22:15:25 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-06 22:15:25 | INFO | train | epoch 218 | loss 1.921 | nll_loss 0.487 | ppl 1.4 | wps 25159.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10612 | lr 0.000306974 | gnorm 0.595 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 27583
2022-03-06 22:15:25 | INFO | fairseq.trainer | begin training epoch 219
2022-03-06 22:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:29 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.426 | nll_loss 12.895 | ppl 7616.58 | wps 44740.5 | wpb 510.9 | bsz 1 | num_updates 10661 | best_loss 8.725
2022-03-06 22:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10661 updates
2022-03-06 22:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 219 @ 10661 updates, score 13.426) (writing took 1.9022180000320077 seconds)
2022-03-06 22:17:31 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-06 22:17:31 | INFO | train | epoch 219 | loss 1.92 | nll_loss 0.486 | ppl 1.4 | wps 25164.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10661 | lr 0.000306268 | gnorm 0.59 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 27709
2022-03-06 22:17:31 | INFO | fairseq.trainer | begin training epoch 220
2022-03-06 22:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:19:07 | INFO | train_inner | epoch 220:     39 / 49 loss=1.919, nll_loss=0.485, ppl=1.4, wps=25184.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.59, loss_scale=32, train_wall=221, gb_free=8.8, wall=27806
2022-03-06 22:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:19:36 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.372 | nll_loss 12.832 | ppl 7293.2 | wps 44732.9 | wpb 510.9 | bsz 1 | num_updates 10710 | best_loss 8.725
2022-03-06 22:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10710 updates
2022-03-06 22:19:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:19:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 220 @ 10710 updates, score 13.372) (writing took 1.88081578258425 seconds)
2022-03-06 22:19:38 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-06 22:19:38 | INFO | train | epoch 220 | loss 1.916 | nll_loss 0.483 | ppl 1.4 | wps 25151.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10710 | lr 0.000305566 | gnorm 0.587 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 27836
2022-03-06 22:19:38 | INFO | fairseq.trainer | begin training epoch 221
2022-03-06 22:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:21:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:21:42 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.348 | nll_loss 12.809 | ppl 7176.57 | wps 43846.1 | wpb 510.9 | bsz 1 | num_updates 10758 | best_loss 8.725
2022-03-06 22:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10758 updates
2022-03-06 22:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 221 @ 10758 updates, score 13.348) (writing took 2.0026406086981297 seconds)
2022-03-06 22:21:44 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-06 22:21:44 | INFO | train | epoch 221 | loss 1.914 | nll_loss 0.48 | ppl 1.39 | wps 24599.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 10758 | lr 0.000304884 | gnorm 0.594 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 27962
2022-03-06 22:21:44 | INFO | fairseq.trainer | begin training epoch 222
2022-03-06 22:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:23:28 | INFO | train_inner | epoch 222:     42 / 49 loss=1.913, nll_loss=0.48, ppl=1.39, wps=24924.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.585, loss_scale=32, train_wall=223, gb_free=8.8, wall=28066
2022-03-06 22:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:23:49 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.383 | nll_loss 12.842 | ppl 7340.17 | wps 44657.4 | wpb 510.9 | bsz 1 | num_updates 10807 | best_loss 8.725
2022-03-06 22:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10807 updates
2022-03-06 22:23:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:23:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:23:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 222 @ 10807 updates, score 13.383) (writing took 2.0043820776045322 seconds)
2022-03-06 22:23:51 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-06 22:23:51 | INFO | train | epoch 222 | loss 1.91 | nll_loss 0.478 | ppl 1.39 | wps 25124.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10807 | lr 0.000304192 | gnorm 0.572 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 28089
2022-03-06 22:23:51 | INFO | fairseq.trainer | begin training epoch 223
2022-03-06 22:23:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:25:55 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.449 | nll_loss 12.921 | ppl 7757.08 | wps 44187.2 | wpb 510.9 | bsz 1 | num_updates 10856 | best_loss 8.725
2022-03-06 22:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10856 updates
2022-03-06 22:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:25:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 223 @ 10856 updates, score 13.449) (writing took 1.9254543902352452 seconds)
2022-03-06 22:25:57 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-06 22:25:57 | INFO | train | epoch 223 | loss 1.911 | nll_loss 0.478 | ppl 1.39 | wps 25112.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10856 | lr 0.000303504 | gnorm 0.599 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 28215
2022-03-06 22:25:57 | INFO | fairseq.trainer | begin training epoch 224
2022-03-06 22:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:26:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:27:48 | INFO | train_inner | epoch 224:     45 / 49 loss=1.909, nll_loss=0.477, ppl=1.39, wps=24913.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.586, loss_scale=32, train_wall=223, gb_free=8.8, wall=28326
2022-03-06 22:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:02 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.345 | nll_loss 12.807 | ppl 7166.73 | wps 44271.1 | wpb 510.9 | bsz 1 | num_updates 10904 | best_loss 8.725
2022-03-06 22:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10904 updates
2022-03-06 22:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:28:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 224 @ 10904 updates, score 13.345) (writing took 1.8457178100943565 seconds)
2022-03-06 22:28:03 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-06 22:28:03 | INFO | train | epoch 224 | loss 1.907 | nll_loss 0.475 | ppl 1.39 | wps 24637.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 10904 | lr 0.000302836 | gnorm 0.571 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 28342
2022-03-06 22:28:03 | INFO | fairseq.trainer | begin training epoch 225
2022-03-06 22:28:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:30:08 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.36 | nll_loss 12.828 | ppl 7273.38 | wps 44161.6 | wpb 510.9 | bsz 1 | num_updates 10953 | best_loss 8.725
2022-03-06 22:30:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10953 updates
2022-03-06 22:30:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 225 @ 10953 updates, score 13.36) (writing took 1.8108948394656181 seconds)
2022-03-06 22:30:10 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-06 22:30:10 | INFO | train | epoch 225 | loss 1.905 | nll_loss 0.473 | ppl 1.39 | wps 25143.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 10953 | lr 0.000302158 | gnorm 0.578 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 28468
2022-03-06 22:30:10 | INFO | fairseq.trainer | begin training epoch 226
2022-03-06 22:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:06 | INFO | train_inner | epoch 226:     47 / 49 loss=1.904, nll_loss=0.473, ppl=1.39, wps=25160.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.581, loss_scale=32, train_wall=221, gb_free=8.8, wall=28584
2022-03-06 22:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:32:15 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.434 | nll_loss 12.903 | ppl 7657.34 | wps 43756.9 | wpb 510.9 | bsz 1 | num_updates 11002 | best_loss 8.725
2022-03-06 22:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 11002 updates
2022-03-06 22:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 226 @ 11002 updates, score 13.434) (writing took 1.719610882923007 seconds)
2022-03-06 22:32:16 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-06 22:32:16 | INFO | train | epoch 226 | loss 1.903 | nll_loss 0.472 | ppl 1.39 | wps 25133.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11002 | lr 0.000301484 | gnorm 0.586 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 28595
2022-03-06 22:32:16 | INFO | fairseq.trainer | begin training epoch 227
2022-03-06 22:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:34:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:34:21 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.396 | nll_loss 12.87 | ppl 7488.32 | wps 44025.3 | wpb 510.9 | bsz 1 | num_updates 11050 | best_loss 8.725
2022-03-06 22:34:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11050 updates
2022-03-06 22:34:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:34:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:34:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 227 @ 11050 updates, score 13.396) (writing took 1.8251791968941689 seconds)
2022-03-06 22:34:23 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-06 22:34:23 | INFO | train | epoch 227 | loss 1.9 | nll_loss 0.469 | ppl 1.38 | wps 24568.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11050 | lr 0.000300828 | gnorm 0.579 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 28721
2022-03-06 22:34:23 | INFO | fairseq.trainer | begin training epoch 228
2022-03-06 22:34:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:36:28 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.314 | nll_loss 12.775 | ppl 7008.9 | wps 43494.5 | wpb 510.9 | bsz 1 | num_updates 11099 | best_loss 8.725
2022-03-06 22:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11099 updates
2022-03-06 22:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:36:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:36:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 228 @ 11099 updates, score 13.314) (writing took 1.7445649923756719 seconds)
2022-03-06 22:36:30 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-06 22:36:30 | INFO | train | epoch 228 | loss 1.898 | nll_loss 0.468 | ppl 1.38 | wps 25106.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11099 | lr 0.000300164 | gnorm 0.567 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 28848
2022-03-06 22:36:30 | INFO | fairseq.trainer | begin training epoch 229
2022-03-06 22:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:36:32 | INFO | train_inner | epoch 229:      1 / 49 loss=1.899, nll_loss=0.468, ppl=1.38, wps=24235.3, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=11100, lr=0.00030015, gnorm=0.574, loss_scale=32, train_wall=223, gb_free=8.8, wall=28850
2022-03-06 22:38:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:38:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:38:34 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.324 | nll_loss 12.794 | ppl 7103.68 | wps 44024.4 | wpb 510.9 | bsz 1 | num_updates 11147 | best_loss 8.725
2022-03-06 22:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11147 updates
2022-03-06 22:38:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 229 @ 11147 updates, score 13.324) (writing took 1.980635772459209 seconds)
2022-03-06 22:38:36 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-06 22:38:36 | INFO | train | epoch 229 | loss 1.895 | nll_loss 0.465 | ppl 1.38 | wps 24525.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11147 | lr 0.000299517 | gnorm 0.569 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 28975
2022-03-06 22:38:36 | INFO | fairseq.trainer | begin training epoch 230
2022-03-06 22:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:40:41 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.437 | nll_loss 12.913 | ppl 7711.22 | wps 44078.9 | wpb 510.9 | bsz 1 | num_updates 11196 | best_loss 8.725
2022-03-06 22:40:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11196 updates
2022-03-06 22:40:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:40:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:40:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 230 @ 11196 updates, score 13.437) (writing took 1.7538001984357834 seconds)
2022-03-06 22:40:43 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-06 22:40:43 | INFO | train | epoch 230 | loss 1.894 | nll_loss 0.464 | ppl 1.38 | wps 25106.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11196 | lr 0.000298861 | gnorm 0.57 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 29101
2022-03-06 22:40:43 | INFO | fairseq.trainer | begin training epoch 231
2022-03-06 22:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:40:53 | INFO | train_inner | epoch 231:      4 / 49 loss=1.894, nll_loss=0.464, ppl=1.38, wps=24867.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.569, loss_scale=32, train_wall=224, gb_free=8.8, wall=29111
2022-03-06 22:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:42:48 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.369 | nll_loss 12.841 | ppl 7337.5 | wps 43955.9 | wpb 510.9 | bsz 1 | num_updates 11245 | best_loss 8.725
2022-03-06 22:42:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11245 updates
2022-03-06 22:42:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:42:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:42:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 231 @ 11245 updates, score 13.369) (writing took 1.8634764635935426 seconds)
2022-03-06 22:42:50 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-06 22:42:50 | INFO | train | epoch 231 | loss 1.891 | nll_loss 0.461 | ppl 1.38 | wps 24999.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11245 | lr 0.000298209 | gnorm 0.568 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 29228
2022-03-06 22:42:50 | INFO | fairseq.trainer | begin training epoch 232
2022-03-06 22:42:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:43:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:44:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:44:56 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.331 | nll_loss 12.801 | ppl 7138.9 | wps 44082.8 | wpb 510.9 | bsz 1 | num_updates 11293 | best_loss 8.725
2022-03-06 22:44:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11293 updates
2022-03-06 22:44:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:44:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 232 @ 11293 updates, score 13.331) (writing took 1.7397472094744444 seconds)
2022-03-06 22:44:57 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-06 22:44:57 | INFO | train | epoch 232 | loss 1.89 | nll_loss 0.461 | ppl 1.38 | wps 24457.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11293 | lr 0.000297574 | gnorm 0.565 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 29356
2022-03-06 22:44:57 | INFO | fairseq.trainer | begin training epoch 233
2022-03-06 22:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:45:15 | INFO | train_inner | epoch 233:      7 / 49 loss=1.89, nll_loss=0.461, ppl=1.38, wps=24777.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.566, loss_scale=32, train_wall=224, gb_free=8.8, wall=29373
2022-03-06 22:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:47:02 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.406 | nll_loss 12.872 | ppl 7495.3 | wps 43915.4 | wpb 510.9 | bsz 1 | num_updates 11342 | best_loss 8.725
2022-03-06 22:47:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11342 updates
2022-03-06 22:47:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 233 @ 11342 updates, score 13.406) (writing took 2.182819156907499 seconds)
2022-03-06 22:47:04 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-06 22:47:04 | INFO | train | epoch 233 | loss 1.887 | nll_loss 0.457 | ppl 1.37 | wps 25020.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11342 | lr 0.000296931 | gnorm 0.563 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 29483
2022-03-06 22:47:04 | INFO | fairseq.trainer | begin training epoch 234
2022-03-06 22:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:49:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:49:11 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.43 | nll_loss 12.907 | ppl 7680.55 | wps 44111.5 | wpb 510.9 | bsz 1 | num_updates 11391 | best_loss 8.725
2022-03-06 22:49:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11391 updates
2022-03-06 22:49:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:49:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 234 @ 11391 updates, score 13.43) (writing took 1.951382776722312 seconds)
2022-03-06 22:49:13 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-06 22:49:13 | INFO | train | epoch 234 | loss 1.885 | nll_loss 0.456 | ppl 1.37 | wps 24810.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11391 | lr 0.000296291 | gnorm 0.562 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 29611
2022-03-06 22:49:13 | INFO | fairseq.trainer | begin training epoch 235
2022-03-06 22:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:49:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:49:37 | INFO | train_inner | epoch 235:     10 / 49 loss=1.886, nll_loss=0.457, ppl=1.37, wps=24714.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.562, loss_scale=32, train_wall=225, gb_free=8.8, wall=29636
2022-03-06 22:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:51:17 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.376 | nll_loss 12.85 | ppl 7384.78 | wps 43990.4 | wpb 510.9 | bsz 1 | num_updates 11439 | best_loss 8.725
2022-03-06 22:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11439 updates
2022-03-06 22:51:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:51:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:51:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 235 @ 11439 updates, score 13.376) (writing took 1.7655409034341574 seconds)
2022-03-06 22:51:19 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-06 22:51:19 | INFO | train | epoch 235 | loss 1.884 | nll_loss 0.455 | ppl 1.37 | wps 24586.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11439 | lr 0.000295669 | gnorm 0.56 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 29737
2022-03-06 22:51:19 | INFO | fairseq.trainer | begin training epoch 236
2022-03-06 22:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:53:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:53:25 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.391 | nll_loss 12.868 | ppl 7475.29 | wps 43698.6 | wpb 510.9 | bsz 1 | num_updates 11488 | best_loss 8.725
2022-03-06 22:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11488 updates
2022-03-06 22:53:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:53:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 236 @ 11488 updates, score 13.391) (writing took 1.8981805322691798 seconds)
2022-03-06 22:53:27 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-06 22:53:27 | INFO | train | epoch 236 | loss 1.881 | nll_loss 0.453 | ppl 1.37 | wps 24950.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11488 | lr 0.000295038 | gnorm 0.558 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 29865
2022-03-06 22:53:27 | INFO | fairseq.trainer | begin training epoch 237
2022-03-06 22:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:53:56 | INFO | train_inner | epoch 237:     12 / 49 loss=1.882, nll_loss=0.454, ppl=1.37, wps=25053.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.558, loss_scale=32, train_wall=222, gb_free=8.8, wall=29894
2022-03-06 22:55:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:55:31 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.378 | nll_loss 12.848 | ppl 7372.59 | wps 43284 | wpb 510.9 | bsz 1 | num_updates 11536 | best_loss 8.725
2022-03-06 22:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11536 updates
2022-03-06 22:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:55:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 237 @ 11536 updates, score 13.378) (writing took 1.868753901682794 seconds)
2022-03-06 22:55:33 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-06 22:55:33 | INFO | train | epoch 237 | loss 1.88 | nll_loss 0.452 | ppl 1.37 | wps 24540.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11536 | lr 0.000294423 | gnorm 0.56 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 29992
2022-03-06 22:55:33 | INFO | fairseq.trainer | begin training epoch 238
2022-03-06 22:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:57:38 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.453 | nll_loss 12.937 | ppl 7843.32 | wps 44155.1 | wpb 510.9 | bsz 1 | num_updates 11585 | best_loss 8.725
2022-03-06 22:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11585 updates
2022-03-06 22:57:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 238 @ 11585 updates, score 13.453) (writing took 1.7451679706573486 seconds)
2022-03-06 22:57:40 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-06 22:57:40 | INFO | train | epoch 238 | loss 1.878 | nll_loss 0.45 | ppl 1.37 | wps 25096.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11585 | lr 0.0002938 | gnorm 0.561 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 30118
2022-03-06 22:57:40 | INFO | fairseq.trainer | begin training epoch 239
2022-03-06 22:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:58:17 | INFO | train_inner | epoch 239:     15 / 49 loss=1.878, nll_loss=0.45, ppl=1.37, wps=24866.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.561, loss_scale=32, train_wall=224, gb_free=8.8, wall=30155
2022-03-06 22:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:59:45 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.397 | nll_loss 12.87 | ppl 7484.19 | wps 43804.2 | wpb 510.9 | bsz 1 | num_updates 11634 | best_loss 8.725
2022-03-06 22:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11634 updates
2022-03-06 22:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:59:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 239 @ 11634 updates, score 13.397) (writing took 2.0596071146428585 seconds)
2022-03-06 22:59:47 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-06 22:59:47 | INFO | train | epoch 239 | loss 1.875 | nll_loss 0.447 | ppl 1.36 | wps 25002.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11634 | lr 0.000293181 | gnorm 0.558 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 30245
2022-03-06 22:59:47 | INFO | fairseq.trainer | begin training epoch 240
2022-03-06 22:59:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:01:52 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.41 | nll_loss 12.893 | ppl 7603.92 | wps 44047.8 | wpb 510.9 | bsz 1 | num_updates 11682 | best_loss 8.725
2022-03-06 23:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11682 updates
2022-03-06 23:01:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:01:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:01:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 240 @ 11682 updates, score 13.41) (writing took 1.8589276354759932 seconds)
2022-03-06 23:01:54 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-06 23:01:54 | INFO | train | epoch 240 | loss 1.872 | nll_loss 0.445 | ppl 1.36 | wps 24531.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11682 | lr 0.000292578 | gnorm 0.548 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 30372
2022-03-06 23:01:54 | INFO | fairseq.trainer | begin training epoch 241
2022-03-06 23:01:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:02:39 | INFO | train_inner | epoch 241:     18 / 49 loss=1.873, nll_loss=0.446, ppl=1.36, wps=24817.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.554, loss_scale=32, train_wall=224, gb_free=8.8, wall=30417
2022-03-06 23:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:03:59 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.41 | nll_loss 12.885 | ppl 7566.63 | wps 44139.2 | wpb 510.9 | bsz 1 | num_updates 11731 | best_loss 8.725
2022-03-06 23:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11731 updates
2022-03-06 23:03:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:04:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 241 @ 11731 updates, score 13.41) (writing took 1.906772991642356 seconds)
2022-03-06 23:04:01 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-06 23:04:01 | INFO | train | epoch 241 | loss 1.872 | nll_loss 0.446 | ppl 1.36 | wps 25061.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11731 | lr 0.000291966 | gnorm 0.569 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 30499
2022-03-06 23:04:01 | INFO | fairseq.trainer | begin training epoch 242
2022-03-06 23:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:06:06 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.324 | nll_loss 12.792 | ppl 7091.86 | wps 44111.9 | wpb 510.9 | bsz 1 | num_updates 11780 | best_loss 8.725
2022-03-06 23:06:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11780 updates
2022-03-06 23:06:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:06:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 242 @ 11780 updates, score 13.324) (writing took 1.9716061260551214 seconds)
2022-03-06 23:06:08 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-06 23:06:08 | INFO | train | epoch 242 | loss 1.87 | nll_loss 0.444 | ppl 1.36 | wps 25051.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11780 | lr 0.000291358 | gnorm 0.553 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 30626
2022-03-06 23:06:08 | INFO | fairseq.trainer | begin training epoch 243
2022-03-06 23:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:06:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:06:59 | INFO | train_inner | epoch 243:     21 / 49 loss=1.87, nll_loss=0.444, ppl=1.36, wps=24860, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.559, loss_scale=32, train_wall=224, gb_free=8.8, wall=30678
2022-03-06 23:08:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:08:12 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.417 | nll_loss 12.898 | ppl 7630.42 | wps 43741.9 | wpb 510.9 | bsz 1 | num_updates 11828 | best_loss 8.725
2022-03-06 23:08:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11828 updates
2022-03-06 23:08:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:08:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:08:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 243 @ 11828 updates, score 13.417) (writing took 1.992475745268166 seconds)
2022-03-06 23:08:14 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-06 23:08:14 | INFO | train | epoch 243 | loss 1.868 | nll_loss 0.442 | ppl 1.36 | wps 24546.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11828 | lr 0.000290766 | gnorm 0.554 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 30753
2022-03-06 23:08:14 | INFO | fairseq.trainer | begin training epoch 244
2022-03-06 23:08:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:10:19 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.437 | nll_loss 12.917 | ppl 7735.75 | wps 44842.8 | wpb 510.9 | bsz 1 | num_updates 11877 | best_loss 8.725
2022-03-06 23:10:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11877 updates
2022-03-06 23:10:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:10:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:10:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 244 @ 11877 updates, score 13.437) (writing took 1.8038522014394403 seconds)
2022-03-06 23:10:21 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-06 23:10:21 | INFO | train | epoch 244 | loss 1.865 | nll_loss 0.439 | ppl 1.36 | wps 25101.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11877 | lr 0.000290166 | gnorm 0.544 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 30879
2022-03-06 23:10:21 | INFO | fairseq.trainer | begin training epoch 245
2022-03-06 23:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:11:18 | INFO | train_inner | epoch 245:     23 / 49 loss=1.865, nll_loss=0.439, ppl=1.36, wps=25107.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.547, loss_scale=32, train_wall=221, gb_free=8.8, wall=30936
2022-03-06 23:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:12:26 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.421 | nll_loss 12.899 | ppl 7636.7 | wps 44632.2 | wpb 510.9 | bsz 1 | num_updates 11926 | best_loss 8.725
2022-03-06 23:12:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11926 updates
2022-03-06 23:12:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 245 @ 11926 updates, score 13.421) (writing took 1.8232061099261045 seconds)
2022-03-06 23:12:27 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-06 23:12:27 | INFO | train | epoch 245 | loss 1.864 | nll_loss 0.438 | ppl 1.35 | wps 25155 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 11926 | lr 0.000289569 | gnorm 0.549 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 31006
2022-03-06 23:12:27 | INFO | fairseq.trainer | begin training epoch 246
2022-03-06 23:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:12:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:14:32 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.46 | nll_loss 12.942 | ppl 7871.59 | wps 44517.6 | wpb 510.9 | bsz 1 | num_updates 11974 | best_loss 8.725
2022-03-06 23:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11974 updates
2022-03-06 23:14:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 246 @ 11974 updates, score 13.46) (writing took 1.9916348811239004 seconds)
2022-03-06 23:14:34 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-06 23:14:34 | INFO | train | epoch 246 | loss 1.862 | nll_loss 0.437 | ppl 1.35 | wps 24594.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 11974 | lr 0.000288988 | gnorm 0.554 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 31132
2022-03-06 23:14:34 | INFO | fairseq.trainer | begin training epoch 247
2022-03-06 23:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:15:38 | INFO | train_inner | epoch 247:     26 / 49 loss=1.862, nll_loss=0.437, ppl=1.35, wps=24930.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.551, loss_scale=32, train_wall=223, gb_free=8.8, wall=31196
2022-03-06 23:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:16:38 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.305 | nll_loss 12.777 | ppl 7018.25 | wps 44008.5 | wpb 510.9 | bsz 1 | num_updates 12023 | best_loss 8.725
2022-03-06 23:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12023 updates
2022-03-06 23:16:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:16:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 247 @ 12023 updates, score 13.305) (writing took 1.6997889215126634 seconds)
2022-03-06 23:16:40 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-06 23:16:40 | INFO | train | epoch 247 | loss 1.86 | nll_loss 0.435 | ppl 1.35 | wps 25180.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12023 | lr 0.000288399 | gnorm 0.54 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 31258
2022-03-06 23:16:40 | INFO | fairseq.trainer | begin training epoch 248
2022-03-06 23:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:18:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:45 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.428 | nll_loss 12.911 | ppl 7699.54 | wps 44458.3 | wpb 510.9 | bsz 1 | num_updates 12071 | best_loss 8.725
2022-03-06 23:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12071 updates
2022-03-06 23:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 248 @ 12071 updates, score 13.428) (writing took 1.7085612248629332 seconds)
2022-03-06 23:18:46 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-06 23:18:46 | INFO | train | epoch 248 | loss 1.859 | nll_loss 0.434 | ppl 1.35 | wps 24654 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12071 | lr 0.000287825 | gnorm 0.547 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 31385
2022-03-06 23:18:46 | INFO | fairseq.trainer | begin training epoch 249
2022-03-06 23:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:19:58 | INFO | train_inner | epoch 249:     29 / 49 loss=1.858, nll_loss=0.434, ppl=1.35, wps=24948.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.542, loss_scale=32, train_wall=223, gb_free=8.8, wall=31456
2022-03-06 23:20:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:20:51 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.455 | nll_loss 12.938 | ppl 7846.62 | wps 44273.2 | wpb 510.9 | bsz 1 | num_updates 12120 | best_loss 8.725
2022-03-06 23:20:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12120 updates
2022-03-06 23:20:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:20:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:20:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 249 @ 12120 updates, score 13.455) (writing took 1.9050973737612367 seconds)
2022-03-06 23:20:53 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-06 23:20:53 | INFO | train | epoch 249 | loss 1.857 | nll_loss 0.433 | ppl 1.35 | wps 25100.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12120 | lr 0.000287242 | gnorm 0.546 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 31511
2022-03-06 23:20:53 | INFO | fairseq.trainer | begin training epoch 250
2022-03-06 23:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:22:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:58 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.357 | nll_loss 12.836 | ppl 7314.05 | wps 43621 | wpb 510.9 | bsz 1 | num_updates 12168 | best_loss 8.725
2022-03-06 23:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12168 updates
2022-03-06 23:22:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:23:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:23:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 250 @ 12168 updates, score 13.357) (writing took 1.985767007805407 seconds)
2022-03-06 23:23:00 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-06 23:23:00 | INFO | train | epoch 250 | loss 1.854 | nll_loss 0.43 | ppl 1.35 | wps 24516.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12168 | lr 0.000286675 | gnorm 0.545 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 31638
2022-03-06 23:23:00 | INFO | fairseq.trainer | begin training epoch 251
2022-03-06 23:23:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:24:19 | INFO | train_inner | epoch 251:     32 / 49 loss=1.854, nll_loss=0.43, ppl=1.35, wps=24856.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.543, loss_scale=16, train_wall=224, gb_free=8.8, wall=31717
2022-03-06 23:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:05 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.416 | nll_loss 12.902 | ppl 7655.19 | wps 44037.3 | wpb 510.9 | bsz 1 | num_updates 12217 | best_loss 8.725
2022-03-06 23:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12217 updates
2022-03-06 23:25:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 251 @ 12217 updates, score 13.416) (writing took 1.8766816034913063 seconds)
2022-03-06 23:25:07 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-06 23:25:07 | INFO | train | epoch 251 | loss 1.853 | nll_loss 0.429 | ppl 1.35 | wps 25083.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12217 | lr 0.0002861 | gnorm 0.532 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 31765
2022-03-06 23:25:07 | INFO | fairseq.trainer | begin training epoch 252
2022-03-06 23:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:27:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:12 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.277 | nll_loss 12.749 | ppl 6886.19 | wps 43942.8 | wpb 510.9 | bsz 1 | num_updates 12266 | best_loss 8.725
2022-03-06 23:27:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12266 updates
2022-03-06 23:27:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:27:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 252 @ 12266 updates, score 13.277) (writing took 1.8496538680046797 seconds)
2022-03-06 23:27:14 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-06 23:27:14 | INFO | train | epoch 252 | loss 1.852 | nll_loss 0.428 | ppl 1.35 | wps 25049.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12266 | lr 0.000285528 | gnorm 0.535 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 31892
2022-03-06 23:27:14 | INFO | fairseq.trainer | begin training epoch 253
2022-03-06 23:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:28:38 | INFO | train_inner | epoch 253:     34 / 49 loss=1.852, nll_loss=0.428, ppl=1.35, wps=25086.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.534, loss_scale=32, train_wall=222, gb_free=8.8, wall=31976
2022-03-06 23:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:29:19 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.334 | nll_loss 12.811 | ppl 7188.32 | wps 43984 | wpb 510.9 | bsz 1 | num_updates 12315 | best_loss 8.725
2022-03-06 23:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12315 updates
2022-03-06 23:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 253 @ 12315 updates, score 13.334) (writing took 1.959438362158835 seconds)
2022-03-06 23:29:20 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-06 23:29:20 | INFO | train | epoch 253 | loss 1.85 | nll_loss 0.427 | ppl 1.34 | wps 25037.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12315 | lr 0.000284959 | gnorm 0.533 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32019
2022-03-06 23:29:21 | INFO | fairseq.trainer | begin training epoch 254
2022-03-06 23:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:31:26 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.402 | nll_loss 12.883 | ppl 7553.06 | wps 43799.4 | wpb 510.9 | bsz 1 | num_updates 12364 | best_loss 8.725
2022-03-06 23:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12364 updates
2022-03-06 23:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:31:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 254 @ 12364 updates, score 13.402) (writing took 1.7226517172530293 seconds)
2022-03-06 23:31:27 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-06 23:31:27 | INFO | train | epoch 254 | loss 1.848 | nll_loss 0.426 | ppl 1.34 | wps 25064.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12364 | lr 0.000284394 | gnorm 0.534 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32146
2022-03-06 23:31:27 | INFO | fairseq.trainer | begin training epoch 255
2022-03-06 23:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:32:56 | INFO | train_inner | epoch 255:     36 / 49 loss=1.848, nll_loss=0.425, ppl=1.34, wps=25081.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.531, loss_scale=32, train_wall=222, gb_free=8.8, wall=32235
2022-03-06 23:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:33:32 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.354 | nll_loss 12.83 | ppl 7283.39 | wps 44081.3 | wpb 510.9 | bsz 1 | num_updates 12413 | best_loss 8.725
2022-03-06 23:33:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12413 updates
2022-03-06 23:33:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 255 @ 12413 updates, score 13.354) (writing took 1.8452221704646945 seconds)
2022-03-06 23:33:34 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-06 23:33:34 | INFO | train | epoch 255 | loss 1.847 | nll_loss 0.424 | ppl 1.34 | wps 25056.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12413 | lr 0.000283832 | gnorm 0.529 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 32272
2022-03-06 23:33:34 | INFO | fairseq.trainer | begin training epoch 256
2022-03-06 23:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:35:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:35:39 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.303 | nll_loss 12.78 | ppl 7035.65 | wps 43922 | wpb 510.9 | bsz 1 | num_updates 12461 | best_loss 8.725
2022-03-06 23:35:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12461 updates
2022-03-06 23:35:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:35:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:35:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 256 @ 12461 updates, score 13.303) (writing took 1.8373066652566195 seconds)
2022-03-06 23:35:41 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-06 23:35:41 | INFO | train | epoch 256 | loss 1.844 | nll_loss 0.422 | ppl 1.34 | wps 24560.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12461 | lr 0.000283285 | gnorm 0.537 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32399
2022-03-06 23:35:41 | INFO | fairseq.trainer | begin training epoch 257
2022-03-06 23:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:17 | INFO | train_inner | epoch 257:     39 / 49 loss=1.844, nll_loss=0.422, ppl=1.34, wps=24864.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.531, loss_scale=32, train_wall=224, gb_free=8.8, wall=32495
2022-03-06 23:37:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:46 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.515 | nll_loss 13.006 | ppl 8226.04 | wps 43749.4 | wpb 510.9 | bsz 1 | num_updates 12510 | best_loss 8.725
2022-03-06 23:37:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12510 updates
2022-03-06 23:37:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:37:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 257 @ 12510 updates, score 13.515) (writing took 2.151774543337524 seconds)
2022-03-06 23:37:48 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-06 23:37:48 | INFO | train | epoch 257 | loss 1.843 | nll_loss 0.421 | ppl 1.34 | wps 25018.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12510 | lr 0.00028273 | gnorm 0.525 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32526
2022-03-06 23:37:48 | INFO | fairseq.trainer | begin training epoch 258
2022-03-06 23:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:39:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:39:53 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.382 | nll_loss 12.865 | ppl 7461.26 | wps 44131.6 | wpb 510.9 | bsz 1 | num_updates 12558 | best_loss 8.725
2022-03-06 23:39:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12558 updates
2022-03-06 23:39:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 258 @ 12558 updates, score 13.382) (writing took 1.7505729738622904 seconds)
2022-03-06 23:39:54 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-06 23:39:54 | INFO | train | epoch 258 | loss 1.841 | nll_loss 0.419 | ppl 1.34 | wps 24589.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12558 | lr 0.000282189 | gnorm 0.525 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 32653
2022-03-06 23:39:54 | INFO | fairseq.trainer | begin training epoch 259
2022-03-06 23:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:41:38 | INFO | train_inner | epoch 259:     42 / 49 loss=1.841, nll_loss=0.42, ppl=1.34, wps=24857.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.532, loss_scale=32, train_wall=224, gb_free=8.8, wall=32756
2022-03-06 23:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:41:59 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.3 | nll_loss 12.775 | ppl 7009.65 | wps 43916.9 | wpb 510.9 | bsz 1 | num_updates 12607 | best_loss 8.725
2022-03-06 23:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12607 updates
2022-03-06 23:41:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:42:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 259 @ 12607 updates, score 13.3) (writing took 1.7260491410270333 seconds)
2022-03-06 23:42:01 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-06 23:42:01 | INFO | train | epoch 259 | loss 1.84 | nll_loss 0.418 | ppl 1.34 | wps 25114.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12607 | lr 0.00028164 | gnorm 0.54 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32779
2022-03-06 23:42:01 | INFO | fairseq.trainer | begin training epoch 260
2022-03-06 23:42:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:44:06 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.386 | nll_loss 12.873 | ppl 7501.65 | wps 44208.1 | wpb 510.9 | bsz 1 | num_updates 12656 | best_loss 8.725
2022-03-06 23:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12656 updates
2022-03-06 23:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:44:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 260 @ 12656 updates, score 13.386) (writing took 1.8418554794043303 seconds)
2022-03-06 23:44:08 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-06 23:44:08 | INFO | train | epoch 260 | loss 1.838 | nll_loss 0.416 | ppl 1.33 | wps 25081.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12656 | lr 0.000281094 | gnorm 0.53 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32906
2022-03-06 23:44:08 | INFO | fairseq.trainer | begin training epoch 261
2022-03-06 23:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:45:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:45:59 | INFO | train_inner | epoch 261:     45 / 49 loss=1.837, nll_loss=0.416, ppl=1.33, wps=24875.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.527, loss_scale=32, train_wall=224, gb_free=8.8, wall=33017
2022-03-06 23:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:46:13 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.379 | nll_loss 12.863 | ppl 7451.36 | wps 43785.1 | wpb 510.9 | bsz 1 | num_updates 12704 | best_loss 8.725
2022-03-06 23:46:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12704 updates
2022-03-06 23:46:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 261 @ 12704 updates, score 13.379) (writing took 1.6992164514958858 seconds)
2022-03-06 23:46:14 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-06 23:46:14 | INFO | train | epoch 261 | loss 1.835 | nll_loss 0.414 | ppl 1.33 | wps 24576.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12704 | lr 0.000280563 | gnorm 0.521 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33033
2022-03-06 23:46:14 | INFO | fairseq.trainer | begin training epoch 262
2022-03-06 23:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:48:19 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.439 | nll_loss 12.935 | ppl 7828.51 | wps 44172.6 | wpb 510.9 | bsz 1 | num_updates 12753 | best_loss 8.725
2022-03-06 23:48:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12753 updates
2022-03-06 23:48:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 262 @ 12753 updates, score 13.439) (writing took 1.7431798772886395 seconds)
2022-03-06 23:48:21 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-06 23:48:21 | INFO | train | epoch 262 | loss 1.836 | nll_loss 0.415 | ppl 1.33 | wps 25111.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12753 | lr 0.000280023 | gnorm 0.53 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 33159
2022-03-06 23:48:21 | INFO | fairseq.trainer | begin training epoch 263
2022-03-06 23:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:50:17 | INFO | train_inner | epoch 263:     47 / 49 loss=1.834, nll_loss=0.414, ppl=1.33, wps=25128, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.526, loss_scale=32, train_wall=222, gb_free=8.8, wall=33275
2022-03-06 23:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:50:26 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.308 | nll_loss 12.785 | ppl 7058.65 | wps 43907.7 | wpb 510.9 | bsz 1 | num_updates 12802 | best_loss 8.725
2022-03-06 23:50:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12802 updates
2022-03-06 23:50:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 263 @ 12802 updates, score 13.308) (writing took 1.974291618913412 seconds)
2022-03-06 23:50:28 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-06 23:50:28 | INFO | train | epoch 263 | loss 1.833 | nll_loss 0.412 | ppl 1.33 | wps 25036.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12802 | lr 0.000279487 | gnorm 0.522 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33286
2022-03-06 23:50:28 | INFO | fairseq.trainer | begin training epoch 264
2022-03-06 23:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:52:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:33 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.505 | nll_loss 12.995 | ppl 8162.19 | wps 44187.7 | wpb 510.9 | bsz 1 | num_updates 12850 | best_loss 8.725
2022-03-06 23:52:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12850 updates
2022-03-06 23:52:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:52:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 264 @ 12850 updates, score 13.505) (writing took 1.8874167799949646 seconds)
2022-03-06 23:52:35 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-06 23:52:35 | INFO | train | epoch 264 | loss 1.832 | nll_loss 0.412 | ppl 1.33 | wps 24553.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12850 | lr 0.000278964 | gnorm 0.526 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33413
2022-03-06 23:52:35 | INFO | fairseq.trainer | begin training epoch 265
2022-03-06 23:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:39 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.374 | nll_loss 12.854 | ppl 7403.55 | wps 44344.7 | wpb 510.9 | bsz 1 | num_updates 12899 | best_loss 8.725
2022-03-06 23:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12899 updates
2022-03-06 23:54:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:54:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:54:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 265 @ 12899 updates, score 13.374) (writing took 1.9715661825612187 seconds)
2022-03-06 23:54:41 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-06 23:54:41 | INFO | train | epoch 265 | loss 1.831 | nll_loss 0.411 | ppl 1.33 | wps 25077.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12899 | lr 0.000278434 | gnorm 0.526 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 33540
2022-03-06 23:54:41 | INFO | fairseq.trainer | begin training epoch 266
2022-03-06 23:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:54:44 | INFO | train_inner | epoch 266:      1 / 49 loss=1.832, nll_loss=0.412, ppl=1.33, wps=24193.3, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=12900, lr=0.000278423, gnorm=0.528, loss_scale=32, train_wall=223, gb_free=8.8, wall=33542
2022-03-06 23:56:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:46 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.272 | nll_loss 12.753 | ppl 6905.22 | wps 44166.8 | wpb 510.9 | bsz 1 | num_updates 12948 | best_loss 8.725
2022-03-06 23:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12948 updates
2022-03-06 23:56:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:56:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 266 @ 12948 updates, score 13.272) (writing took 1.6842887932434678 seconds)
2022-03-06 23:56:48 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-06 23:56:48 | INFO | train | epoch 266 | loss 1.829 | nll_loss 0.409 | ppl 1.33 | wps 25163.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 12948 | lr 0.000277906 | gnorm 0.512 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 33666
2022-03-06 23:56:48 | INFO | fairseq.trainer | begin training epoch 267
2022-03-06 23:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:58:52 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.413 | nll_loss 12.902 | ppl 7651.75 | wps 44256 | wpb 510.9 | bsz 1 | num_updates 12996 | best_loss 8.725
2022-03-06 23:58:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12996 updates
2022-03-06 23:58:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:58:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 267 @ 12996 updates, score 13.413) (writing took 1.7646606247872114 seconds)
2022-03-06 23:58:54 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-06 23:58:54 | INFO | train | epoch 267 | loss 1.827 | nll_loss 0.407 | ppl 1.33 | wps 24652 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 12996 | lr 0.000277393 | gnorm 0.518 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 33792
2022-03-06 23:58:54 | INFO | fairseq.trainer | begin training epoch 268
2022-03-06 23:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:59:04 | INFO | train_inner | epoch 268:      4 / 49 loss=1.828, nll_loss=0.408, ppl=1.33, wps=24955.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.515, loss_scale=32, train_wall=223, gb_free=8.8, wall=33802
2022-03-07 00:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:00:58 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.339 | nll_loss 12.819 | ppl 7224.15 | wps 44458.8 | wpb 510.9 | bsz 1 | num_updates 13045 | best_loss 8.725
2022-03-07 00:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13045 updates
2022-03-07 00:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:01:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 268 @ 13045 updates, score 13.339) (writing took 1.8403094448149204 seconds)
2022-03-07 00:01:00 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 00:01:00 | INFO | train | epoch 268 | loss 1.827 | nll_loss 0.407 | ppl 1.33 | wps 25141.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13045 | lr 0.000276871 | gnorm 0.517 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 33919
2022-03-07 00:01:00 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 00:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:03:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:03:05 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.39 | nll_loss 12.877 | ppl 7522.2 | wps 44318.3 | wpb 510.9 | bsz 1 | num_updates 13093 | best_loss 8.725
2022-03-07 00:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13093 updates
2022-03-07 00:03:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 269 @ 13093 updates, score 13.39) (writing took 1.9649887112900615 seconds)
2022-03-07 00:03:07 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 00:03:07 | INFO | train | epoch 269 | loss 1.824 | nll_loss 0.405 | ppl 1.32 | wps 24608.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13093 | lr 0.000276363 | gnorm 0.511 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 34045
2022-03-07 00:03:07 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 00:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:03:24 | INFO | train_inner | epoch 270:      7 / 49 loss=1.825, nll_loss=0.406, ppl=1.32, wps=24923.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.515, loss_scale=32, train_wall=223, gb_free=8.8, wall=34062
2022-03-07 00:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:05:11 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.294 | nll_loss 12.775 | ppl 7008.72 | wps 44420 | wpb 510.9 | bsz 1 | num_updates 13142 | best_loss 8.725
2022-03-07 00:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13142 updates
2022-03-07 00:05:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:05:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 270 @ 13142 updates, score 13.294) (writing took 1.8228560239076614 seconds)
2022-03-07 00:05:13 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 00:05:13 | INFO | train | epoch 270 | loss 1.823 | nll_loss 0.404 | ppl 1.32 | wps 25158.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13142 | lr 0.000275848 | gnorm 0.518 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 34171
2022-03-07 00:05:13 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 00:05:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:07:18 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.456 | nll_loss 12.946 | ppl 7893.31 | wps 44048.7 | wpb 510.9 | bsz 1 | num_updates 13191 | best_loss 8.725
2022-03-07 00:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13191 updates
2022-03-07 00:07:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:07:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 271 @ 13191 updates, score 13.456) (writing took 1.9029341377317905 seconds)
2022-03-07 00:07:20 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 00:07:20 | INFO | train | epoch 271 | loss 1.822 | nll_loss 0.404 | ppl 1.32 | wps 25113.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13191 | lr 0.000275335 | gnorm 0.517 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 34298
2022-03-07 00:07:20 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 00:07:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:07:42 | INFO | train_inner | epoch 272:      9 / 49 loss=1.822, nll_loss=0.404, ppl=1.32, wps=25158.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.515, loss_scale=32, train_wall=221, gb_free=8.8, wall=34320
2022-03-07 00:08:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:09:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:09:25 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.311 | nll_loss 12.794 | ppl 7102.09 | wps 43861.4 | wpb 510.9 | bsz 1 | num_updates 13239 | best_loss 8.725
2022-03-07 00:09:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13239 updates
2022-03-07 00:09:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 272 @ 13239 updates, score 13.311) (writing took 1.9490183871239424 seconds)
2022-03-07 00:09:27 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 00:09:27 | INFO | train | epoch 272 | loss 1.821 | nll_loss 0.402 | ppl 1.32 | wps 24539.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13239 | lr 0.000274835 | gnorm 0.516 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34425
2022-03-07 00:09:27 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 00:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:11:31 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.444 | nll_loss 12.935 | ppl 7828.94 | wps 44012 | wpb 510.9 | bsz 1 | num_updates 13288 | best_loss 8.725
2022-03-07 00:11:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13288 updates
2022-03-07 00:11:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:11:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:11:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 273 @ 13288 updates, score 13.444) (writing took 1.7275443887338042 seconds)
2022-03-07 00:11:33 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 00:11:33 | INFO | train | epoch 273 | loss 1.819 | nll_loss 0.401 | ppl 1.32 | wps 25104.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13288 | lr 0.000274328 | gnorm 0.506 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34551
2022-03-07 00:11:33 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 00:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:12:03 | INFO | train_inner | epoch 274:     12 / 49 loss=1.819, nll_loss=0.401, ppl=1.32, wps=24868.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.514, loss_scale=32, train_wall=224, gb_free=8.8, wall=34581
2022-03-07 00:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:38 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.363 | nll_loss 12.854 | ppl 7402.46 | wps 44215.1 | wpb 510.9 | bsz 1 | num_updates 13337 | best_loss 8.725
2022-03-07 00:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13337 updates
2022-03-07 00:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 274 @ 13337 updates, score 13.363) (writing took 1.8943290365859866 seconds)
2022-03-07 00:13:40 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 00:13:40 | INFO | train | epoch 274 | loss 1.817 | nll_loss 0.4 | ppl 1.32 | wps 25075.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13337 | lr 0.000273824 | gnorm 0.512 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 34678
2022-03-07 00:13:40 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 00:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:13:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:45 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.311 | nll_loss 12.794 | ppl 7103.08 | wps 44257.4 | wpb 510.9 | bsz 1 | num_updates 13385 | best_loss 8.725
2022-03-07 00:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13385 updates
2022-03-07 00:15:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 275 @ 13385 updates, score 13.311) (writing took 1.8613354219123721 seconds)
2022-03-07 00:15:47 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 00:15:47 | INFO | train | epoch 275 | loss 1.815 | nll_loss 0.398 | ppl 1.32 | wps 24558.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13385 | lr 0.000273332 | gnorm 0.514 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34805
2022-03-07 00:15:47 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 00:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:16:24 | INFO | train_inner | epoch 276:     15 / 49 loss=1.816, nll_loss=0.398, ppl=1.32, wps=24870.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.51, loss_scale=32, train_wall=224, gb_free=8.8, wall=34842
2022-03-07 00:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:51 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.311 | nll_loss 12.799 | ppl 7129.02 | wps 44210.8 | wpb 510.9 | bsz 1 | num_updates 13434 | best_loss 8.725
2022-03-07 00:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13434 updates
2022-03-07 00:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:17:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 276 @ 13434 updates, score 13.311) (writing took 1.7423041090369225 seconds)
2022-03-07 00:17:53 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 00:17:53 | INFO | train | epoch 276 | loss 1.814 | nll_loss 0.396 | ppl 1.32 | wps 25114.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13434 | lr 0.000272833 | gnorm 0.502 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34931
2022-03-07 00:17:53 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 00:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:19:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:19:58 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.373 | nll_loss 12.861 | ppl 7439.19 | wps 43562.1 | wpb 510.9 | bsz 1 | num_updates 13482 | best_loss 8.725
2022-03-07 00:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13482 updates
2022-03-07 00:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 277 @ 13482 updates, score 13.373) (writing took 1.7458193367347121 seconds)
2022-03-07 00:20:00 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 00:20:00 | INFO | train | epoch 277 | loss 1.813 | nll_loss 0.397 | ppl 1.32 | wps 24598 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13482 | lr 0.000272347 | gnorm 0.504 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 35058
2022-03-07 00:20:00 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 00:20:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:20:44 | INFO | train_inner | epoch 278:     18 / 49 loss=1.813, nll_loss=0.396, ppl=1.32, wps=24904.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.502, loss_scale=32, train_wall=224, gb_free=8.8, wall=35102
2022-03-07 00:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:22:04 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.283 | nll_loss 12.765 | ppl 6960.48 | wps 43925.6 | wpb 510.9 | bsz 1 | num_updates 13531 | best_loss 8.725
2022-03-07 00:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13531 updates
2022-03-07 00:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 278 @ 13531 updates, score 13.283) (writing took 2.0589810786768794 seconds)
2022-03-07 00:22:07 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 00:22:07 | INFO | train | epoch 278 | loss 1.812 | nll_loss 0.396 | ppl 1.32 | wps 25043.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13531 | lr 0.000271854 | gnorm 0.51 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35185
2022-03-07 00:22:07 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 00:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:11 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.374 | nll_loss 12.862 | ppl 7443.23 | wps 43774.9 | wpb 510.9 | bsz 1 | num_updates 13580 | best_loss 8.725
2022-03-07 00:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13580 updates
2022-03-07 00:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 279 @ 13580 updates, score 13.374) (writing took 1.7993742460384965 seconds)
2022-03-07 00:24:13 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 00:24:13 | INFO | train | epoch 279 | loss 1.811 | nll_loss 0.395 | ppl 1.31 | wps 25093.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13580 | lr 0.000271363 | gnorm 0.51 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35311
2022-03-07 00:24:13 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 00:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:25:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:25:05 | INFO | train_inner | epoch 280:     21 / 49 loss=1.811, nll_loss=0.394, ppl=1.31, wps=24849.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.51, loss_scale=32, train_wall=224, gb_free=8.8, wall=35363
2022-03-07 00:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:18 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.479 | nll_loss 12.973 | ppl 8040.58 | wps 43906.3 | wpb 510.9 | bsz 1 | num_updates 13628 | best_loss 8.725
2022-03-07 00:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13628 updates
2022-03-07 00:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:26:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:26:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 280 @ 13628 updates, score 13.479) (writing took 2.004094323143363 seconds)
2022-03-07 00:26:20 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 00:26:20 | INFO | train | epoch 280 | loss 1.809 | nll_loss 0.392 | ppl 1.31 | wps 24505.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13628 | lr 0.000270884 | gnorm 0.504 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35438
2022-03-07 00:26:20 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 00:26:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:28:25 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.428 | nll_loss 12.926 | ppl 7780.5 | wps 44009.7 | wpb 510.9 | bsz 1 | num_updates 13677 | best_loss 8.725
2022-03-07 00:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13677 updates
2022-03-07 00:28:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:28:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:28:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 281 @ 13677 updates, score 13.428) (writing took 1.9583264915272593 seconds)
2022-03-07 00:28:27 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 00:28:27 | INFO | train | epoch 281 | loss 1.809 | nll_loss 0.393 | ppl 1.31 | wps 25056.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13677 | lr 0.000270399 | gnorm 0.506 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35565
2022-03-07 00:28:27 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 00:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:29:24 | INFO | train_inner | epoch 282:     23 / 49 loss=1.808, nll_loss=0.393, ppl=1.31, wps=25068.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.504, loss_scale=32, train_wall=222, gb_free=8.8, wall=35622
2022-03-07 00:30:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:32 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.468 | nll_loss 12.96 | ppl 7969.51 | wps 43662 | wpb 510.9 | bsz 1 | num_updates 13726 | best_loss 8.725
2022-03-07 00:30:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13726 updates
2022-03-07 00:30:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:30:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:30:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 282 @ 13726 updates, score 13.468) (writing took 1.8432888956740499 seconds)
2022-03-07 00:30:34 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 00:30:34 | INFO | train | epoch 282 | loss 1.808 | nll_loss 0.392 | ppl 1.31 | wps 25043.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13726 | lr 0.000269916 | gnorm 0.5 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35692
2022-03-07 00:30:34 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 00:30:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:30:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:32:39 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.378 | nll_loss 12.87 | ppl 7484.93 | wps 43864.6 | wpb 510.9 | bsz 1 | num_updates 13774 | best_loss 8.725
2022-03-07 00:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13774 updates
2022-03-07 00:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 283 @ 13774 updates, score 13.378) (writing took 1.793039709329605 seconds)
2022-03-07 00:32:41 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 00:32:41 | INFO | train | epoch 283 | loss 1.806 | nll_loss 0.391 | ppl 1.31 | wps 24571.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13774 | lr 0.000269445 | gnorm 0.509 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35819
2022-03-07 00:32:41 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 00:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:45 | INFO | train_inner | epoch 284:     26 / 49 loss=1.806, nll_loss=0.391, ppl=1.31, wps=24860.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.508, loss_scale=32, train_wall=224, gb_free=8.8, wall=35883
2022-03-07 00:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:34:45 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.461 | nll_loss 12.958 | ppl 7959.38 | wps 44099 | wpb 510.9 | bsz 1 | num_updates 13823 | best_loss 8.725
2022-03-07 00:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13823 updates
2022-03-07 00:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 284 @ 13823 updates, score 13.461) (writing took 1.7723004948347807 seconds)
2022-03-07 00:34:47 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 00:34:47 | INFO | train | epoch 284 | loss 1.805 | nll_loss 0.389 | ppl 1.31 | wps 25102 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13823 | lr 0.000268967 | gnorm 0.508 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35945
2022-03-07 00:34:47 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 00:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:36:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:36:52 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.3 | nll_loss 12.785 | ppl 7058.97 | wps 43207.6 | wpb 510.9 | bsz 1 | num_updates 13871 | best_loss 8.725
2022-03-07 00:36:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13871 updates
2022-03-07 00:36:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:36:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:36:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 285 @ 13871 updates, score 13.3) (writing took 1.7239415580406785 seconds)
2022-03-07 00:36:54 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 00:36:54 | INFO | train | epoch 285 | loss 1.803 | nll_loss 0.388 | ppl 1.31 | wps 24574.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 13871 | lr 0.000268501 | gnorm 0.498 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36072
2022-03-07 00:36:54 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 00:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:38:06 | INFO | train_inner | epoch 286:     29 / 49 loss=1.802, nll_loss=0.387, ppl=1.31, wps=24887.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.498, loss_scale=32, train_wall=224, gb_free=8.8, wall=36144
2022-03-07 00:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:38:59 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.403 | nll_loss 12.894 | ppl 7614.29 | wps 44043.5 | wpb 510.9 | bsz 1 | num_updates 13920 | best_loss 8.725
2022-03-07 00:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13920 updates
2022-03-07 00:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:39:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 286 @ 13920 updates, score 13.403) (writing took 1.8031713934615254 seconds)
2022-03-07 00:39:01 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 00:39:01 | INFO | train | epoch 286 | loss 1.801 | nll_loss 0.386 | ppl 1.31 | wps 25100.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13920 | lr 0.000268028 | gnorm 0.493 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36199
2022-03-07 00:39:01 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 00:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:41:05 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.441 | nll_loss 12.94 | ppl 7860.77 | wps 43958.5 | wpb 510.9 | bsz 1 | num_updates 13969 | best_loss 8.725
2022-03-07 00:41:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13969 updates
2022-03-07 00:41:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:41:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:41:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 287 @ 13969 updates, score 13.441) (writing took 1.7433377960696816 seconds)
2022-03-07 00:41:07 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 00:41:07 | INFO | train | epoch 287 | loss 1.801 | nll_loss 0.386 | ppl 1.31 | wps 25128 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 13969 | lr 0.000267558 | gnorm 0.501 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 36325
2022-03-07 00:41:07 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 00:41:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:42:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:42:26 | INFO | train_inner | epoch 288:     32 / 49 loss=1.801, nll_loss=0.386, ppl=1.31, wps=24922.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.498, loss_scale=32, train_wall=223, gb_free=8.8, wall=36404
2022-03-07 00:43:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:43:12 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.353 | nll_loss 12.843 | ppl 7348.95 | wps 44126.2 | wpb 510.9 | bsz 1 | num_updates 14017 | best_loss 8.725
2022-03-07 00:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14017 updates
2022-03-07 00:43:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:43:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:43:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 288 @ 14017 updates, score 13.353) (writing took 1.824933254159987 seconds)
2022-03-07 00:43:13 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 00:43:13 | INFO | train | epoch 288 | loss 1.8 | nll_loss 0.385 | ppl 1.31 | wps 24616.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14017 | lr 0.000267099 | gnorm 0.492 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 36452
2022-03-07 00:43:13 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 00:43:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:45:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:45:18 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.401 | nll_loss 12.897 | ppl 7625.67 | wps 44443.3 | wpb 510.9 | bsz 1 | num_updates 14066 | best_loss 8.725
2022-03-07 00:45:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14066 updates
2022-03-07 00:45:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:45:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 289 @ 14066 updates, score 13.401) (writing took 1.879766526632011 seconds)
2022-03-07 00:45:20 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 00:45:20 | INFO | train | epoch 289 | loss 1.798 | nll_loss 0.384 | ppl 1.3 | wps 25140.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14066 | lr 0.000266633 | gnorm 0.491 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 36578
2022-03-07 00:45:20 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 00:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:44 | INFO | train_inner | epoch 290:     34 / 49 loss=1.798, nll_loss=0.384, ppl=1.31, wps=25147.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.491, loss_scale=32, train_wall=221, gb_free=8.8, wall=36662
2022-03-07 00:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:47:24 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.301 | nll_loss 12.788 | ppl 7070.3 | wps 44553.5 | wpb 510.9 | bsz 1 | num_updates 14115 | best_loss 8.725
2022-03-07 00:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14115 updates
2022-03-07 00:47:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 290 @ 14115 updates, score 13.301) (writing took 2.0177790708839893 seconds)
2022-03-07 00:47:27 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 00:47:27 | INFO | train | epoch 290 | loss 1.798 | nll_loss 0.384 | ppl 1.31 | wps 25088.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14115 | lr 0.00026617 | gnorm 0.495 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 36705
2022-03-07 00:47:27 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 00:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:47:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:49:31 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.319 | nll_loss 12.808 | ppl 7170.16 | wps 44608.8 | wpb 510.9 | bsz 1 | num_updates 14163 | best_loss 8.725
2022-03-07 00:49:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14163 updates
2022-03-07 00:49:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:49:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:49:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 291 @ 14163 updates, score 13.319) (writing took 1.665252571925521 seconds)
2022-03-07 00:49:33 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 00:49:33 | INFO | train | epoch 291 | loss 1.795 | nll_loss 0.382 | ppl 1.3 | wps 24675.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14163 | lr 0.000265719 | gnorm 0.494 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 36831
2022-03-07 00:49:33 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 00:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:51:04 | INFO | train_inner | epoch 292:     37 / 49 loss=1.796, nll_loss=0.382, ppl=1.3, wps=24970.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.496, loss_scale=32, train_wall=223, gb_free=8.8, wall=36922
2022-03-07 00:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:37 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.475 | nll_loss 12.974 | ppl 8048.46 | wps 44343.2 | wpb 510.9 | bsz 1 | num_updates 14212 | best_loss 8.725
2022-03-07 00:51:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14212 updates
2022-03-07 00:51:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:51:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:51:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 292 @ 14212 updates, score 13.475) (writing took 1.768145740032196 seconds)
2022-03-07 00:51:39 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 00:51:39 | INFO | train | epoch 292 | loss 1.795 | nll_loss 0.382 | ppl 1.3 | wps 25214 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14212 | lr 0.00026526 | gnorm 0.498 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 36957
2022-03-07 00:51:39 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 00:51:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:53:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:53:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:53:43 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.499 | nll_loss 13.002 | ppl 8202.23 | wps 44309.4 | wpb 510.9 | bsz 1 | num_updates 14260 | best_loss 8.725
2022-03-07 00:53:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14260 updates
2022-03-07 00:53:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:53:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:53:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 293 @ 14260 updates, score 13.499) (writing took 1.7426864989101887 seconds)
2022-03-07 00:53:45 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 00:53:45 | INFO | train | epoch 293 | loss 1.792 | nll_loss 0.379 | ppl 1.3 | wps 24660.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14260 | lr 0.000264814 | gnorm 0.484 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 37083
2022-03-07 00:53:45 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 00:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:55:23 | INFO | train_inner | epoch 294:     40 / 49 loss=1.793, nll_loss=0.38, ppl=1.3, wps=24972.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.488, loss_scale=32, train_wall=223, gb_free=8.8, wall=37182
2022-03-07 00:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:55:49 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.403 | nll_loss 12.897 | ppl 7628.24 | wps 44367.7 | wpb 510.9 | bsz 1 | num_updates 14309 | best_loss 8.725
2022-03-07 00:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14309 updates
2022-03-07 00:55:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:55:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:55:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 294 @ 14309 updates, score 13.403) (writing took 1.7132502077147365 seconds)
2022-03-07 00:55:51 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 00:55:51 | INFO | train | epoch 294 | loss 1.792 | nll_loss 0.38 | ppl 1.3 | wps 25194.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14309 | lr 0.00026436 | gnorm 0.489 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 37209
2022-03-07 00:55:51 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 00:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:57:55 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.303 | nll_loss 12.795 | ppl 7105.81 | wps 44456.4 | wpb 510.9 | bsz 1 | num_updates 14358 | best_loss 8.725
2022-03-07 00:57:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14358 updates
2022-03-07 00:57:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:57:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 295 @ 14358 updates, score 13.303) (writing took 1.7652181331068277 seconds)
2022-03-07 00:57:57 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 00:57:57 | INFO | train | epoch 295 | loss 1.79 | nll_loss 0.378 | ppl 1.3 | wps 25202.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14358 | lr 0.000263908 | gnorm 0.484 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 37335
2022-03-07 00:57:57 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 00:57:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:59:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:59:43 | INFO | train_inner | epoch 296:     43 / 49 loss=1.79, nll_loss=0.378, ppl=1.3, wps=24978.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.487, loss_scale=32, train_wall=223, gb_free=8.8, wall=37441
2022-03-07 00:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:02 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.337 | nll_loss 12.829 | ppl 7274.23 | wps 44217.1 | wpb 510.9 | bsz 1 | num_updates 14406 | best_loss 8.725
2022-03-07 01:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14406 updates
2022-03-07 01:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 296 @ 14406 updates, score 13.337) (writing took 1.790217725560069 seconds)
2022-03-07 01:00:03 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 01:00:03 | INFO | train | epoch 296 | loss 1.79 | nll_loss 0.377 | ppl 1.3 | wps 24635.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14406 | lr 0.000263468 | gnorm 0.491 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 37462
2022-03-07 01:00:03 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 01:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:08 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.454 | nll_loss 12.953 | ppl 7931.46 | wps 44220.1 | wpb 510.9 | bsz 1 | num_updates 14455 | best_loss 8.725
2022-03-07 01:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14455 updates
2022-03-07 01:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 297 @ 14455 updates, score 13.454) (writing took 1.8599242130294442 seconds)
2022-03-07 01:02:10 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 01:02:10 | INFO | train | epoch 297 | loss 1.789 | nll_loss 0.376 | ppl 1.3 | wps 25131.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14455 | lr 0.000263021 | gnorm 0.49 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 37588
2022-03-07 01:02:10 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 01:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:04:01 | INFO | train_inner | epoch 298:     45 / 49 loss=1.788, nll_loss=0.376, ppl=1.3, wps=25175.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.484, loss_scale=32, train_wall=221, gb_free=8.8, wall=37699
2022-03-07 01:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:04:14 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.384 | nll_loss 12.879 | ppl 7532.24 | wps 44726.9 | wpb 510.9 | bsz 1 | num_updates 14504 | best_loss 8.725
2022-03-07 01:04:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14504 updates
2022-03-07 01:04:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:04:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:04:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 298 @ 14504 updates, score 13.384) (writing took 1.7988950666040182 seconds)
2022-03-07 01:04:16 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 01:04:16 | INFO | train | epoch 298 | loss 1.787 | nll_loss 0.375 | ppl 1.3 | wps 25180.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14504 | lr 0.000262577 | gnorm 0.478 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 37714
2022-03-07 01:04:16 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 01:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:04:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:06:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:06:21 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.324 | nll_loss 12.813 | ppl 7194.88 | wps 43847.7 | wpb 510.9 | bsz 1 | num_updates 14552 | best_loss 8.725
2022-03-07 01:06:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14552 updates
2022-03-07 01:06:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:06:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:06:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 299 @ 14552 updates, score 13.324) (writing took 1.9523957511410117 seconds)
2022-03-07 01:06:23 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 01:06:23 | INFO | train | epoch 299 | loss 1.787 | nll_loss 0.375 | ppl 1.3 | wps 24530.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14552 | lr 0.000262143 | gnorm 0.487 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37841
2022-03-07 01:06:23 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 01:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:08:22 | INFO | train_inner | epoch 300:     48 / 49 loss=1.786, nll_loss=0.374, ppl=1.3, wps=24883.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.483, loss_scale=32, train_wall=224, gb_free=8.8, wall=37960
2022-03-07 01:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:08:28 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.323 | nll_loss 12.819 | ppl 7226.85 | wps 44507.3 | wpb 510.9 | bsz 1 | num_updates 14601 | best_loss 8.725
2022-03-07 01:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14601 updates
2022-03-07 01:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:08:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:08:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 300 @ 14601 updates, score 13.323) (writing took 1.7927823327481747 seconds)
2022-03-07 01:08:30 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 01:08:30 | INFO | train | epoch 300 | loss 1.784 | nll_loss 0.373 | ppl 1.29 | wps 25127.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14601 | lr 0.000261703 | gnorm 0.479 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 37968
2022-03-07 01:08:30 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 01:08:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:10:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:10:34 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.396 | nll_loss 12.893 | ppl 7604.5 | wps 44143.4 | wpb 510.9 | bsz 1 | num_updates 14649 | best_loss 8.725
2022-03-07 01:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14649 updates
2022-03-07 01:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 301 @ 14649 updates, score 13.396) (writing took 1.7160343769937754 seconds)
2022-03-07 01:10:36 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 01:10:36 | INFO | train | epoch 301 | loss 1.784 | nll_loss 0.373 | ppl 1.29 | wps 24587.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14649 | lr 0.000261274 | gnorm 0.484 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38094
2022-03-07 01:10:36 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 01:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:12:40 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.35 | nll_loss 12.843 | ppl 7348.88 | wps 44457 | wpb 510.9 | bsz 1 | num_updates 14698 | best_loss 8.725
2022-03-07 01:12:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14698 updates
2022-03-07 01:12:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 302 @ 14698 updates, score 13.35) (writing took 1.7611007653176785 seconds)
2022-03-07 01:12:42 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 01:12:42 | INFO | train | epoch 302 | loss 1.783 | nll_loss 0.372 | ppl 1.29 | wps 25203 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14698 | lr 0.000260838 | gnorm 0.488 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 38220
2022-03-07 01:12:42 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 01:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:12:47 | INFO | train_inner | epoch 303:      2 / 49 loss=1.783, nll_loss=0.372, ppl=1.29, wps=24292.3, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.487, loss_scale=32, train_wall=222, gb_free=8.8, wall=38225
2022-03-07 01:14:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:14:47 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.415 | nll_loss 12.92 | ppl 7750.98 | wps 44461.2 | wpb 510.9 | bsz 1 | num_updates 14747 | best_loss 8.725
2022-03-07 01:14:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14747 updates
2022-03-07 01:14:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:14:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 303 @ 14747 updates, score 13.415) (writing took 1.773936241865158 seconds)
2022-03-07 01:14:48 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 01:14:48 | INFO | train | epoch 303 | loss 1.781 | nll_loss 0.37 | ppl 1.29 | wps 25202.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14747 | lr 0.000260404 | gnorm 0.478 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 38347
2022-03-07 01:14:48 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 01:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:16:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:16:53 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.402 | nll_loss 12.899 | ppl 7636.79 | wps 44208.2 | wpb 510.9 | bsz 1 | num_updates 14795 | best_loss 8.725
2022-03-07 01:16:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14795 updates
2022-03-07 01:16:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:16:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 304 @ 14795 updates, score 13.402) (writing took 1.9327734047546983 seconds)
2022-03-07 01:16:55 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 01:16:55 | INFO | train | epoch 304 | loss 1.781 | nll_loss 0.371 | ppl 1.29 | wps 24661.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14795 | lr 0.000259982 | gnorm 0.481 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 38473
2022-03-07 01:16:55 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 01:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:17:07 | INFO | train_inner | epoch 305:      5 / 49 loss=1.781, nll_loss=0.37, ppl=1.29, wps=24975.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.48, loss_scale=32, train_wall=223, gb_free=8.8, wall=38485
2022-03-07 01:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:18:59 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.327 | nll_loss 12.824 | ppl 7249.36 | wps 44232.2 | wpb 510.9 | bsz 1 | num_updates 14844 | best_loss 8.725
2022-03-07 01:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14844 updates
2022-03-07 01:18:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 305 @ 14844 updates, score 13.327) (writing took 1.9875978166237473 seconds)
2022-03-07 01:19:01 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 01:19:01 | INFO | train | epoch 305 | loss 1.779 | nll_loss 0.369 | ppl 1.29 | wps 25137.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14844 | lr 0.000259552 | gnorm 0.493 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 38599
2022-03-07 01:19:01 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 01:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:21:05 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.349 | nll_loss 12.841 | ppl 7338.8 | wps 44251.2 | wpb 510.9 | bsz 1 | num_updates 14893 | best_loss 8.725
2022-03-07 01:21:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14893 updates
2022-03-07 01:21:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:21:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:21:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 306 @ 14893 updates, score 13.349) (writing took 2.0346357710659504 seconds)
2022-03-07 01:21:07 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 01:21:07 | INFO | train | epoch 306 | loss 1.778 | nll_loss 0.367 | ppl 1.29 | wps 25131.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14893 | lr 0.000259125 | gnorm 0.475 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 38726
2022-03-07 01:21:07 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 01:21:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:21:25 | INFO | train_inner | epoch 307:      7 / 49 loss=1.778, nll_loss=0.368, ppl=1.29, wps=25171.8, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.483, loss_scale=32, train_wall=221, gb_free=8.8, wall=38743
2022-03-07 01:21:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:23:12 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.361 | nll_loss 12.858 | ppl 7425.09 | wps 44261.7 | wpb 510.9 | bsz 1 | num_updates 14941 | best_loss 8.725
2022-03-07 01:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14941 updates
2022-03-07 01:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 307 @ 14941 updates, score 13.361) (writing took 1.8177569452673197 seconds)
2022-03-07 01:23:14 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 01:23:14 | INFO | train | epoch 307 | loss 1.777 | nll_loss 0.367 | ppl 1.29 | wps 24672.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 14941 | lr 0.000258708 | gnorm 0.478 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 38852
2022-03-07 01:23:14 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 01:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:18 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.319 | nll_loss 12.813 | ppl 7197.86 | wps 44399.9 | wpb 510.9 | bsz 1 | num_updates 14990 | best_loss 8.725
2022-03-07 01:25:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14990 updates
2022-03-07 01:25:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 308 @ 14990 updates, score 13.319) (writing took 1.9011902883648872 seconds)
2022-03-07 01:25:20 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 01:25:20 | INFO | train | epoch 308 | loss 1.777 | nll_loss 0.367 | ppl 1.29 | wps 25151.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 14990 | lr 0.000258285 | gnorm 0.484 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 38978
2022-03-07 01:25:20 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 01:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:45 | INFO | train_inner | epoch 309:     10 / 49 loss=1.777, nll_loss=0.367, ppl=1.29, wps=24958.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.48, loss_scale=32, train_wall=223, gb_free=8.8, wall=39003
2022-03-07 01:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:27:24 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.314 | nll_loss 12.805 | ppl 7157.81 | wps 44116.7 | wpb 510.9 | bsz 1 | num_updates 15039 | best_loss 8.725
2022-03-07 01:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15039 updates
2022-03-07 01:27:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 309 @ 15039 updates, score 13.314) (writing took 1.7987608825787902 seconds)
2022-03-07 01:27:26 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 01:27:26 | INFO | train | epoch 309 | loss 1.775 | nll_loss 0.366 | ppl 1.29 | wps 25204 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15039 | lr 0.000257864 | gnorm 0.481 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 39104
2022-03-07 01:27:26 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 01:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:29:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:29:30 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.417 | nll_loss 12.917 | ppl 7734.42 | wps 44204.7 | wpb 510.9 | bsz 1 | num_updates 15087 | best_loss 8.725
2022-03-07 01:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15087 updates
2022-03-07 01:29:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 310 @ 15087 updates, score 13.417) (writing took 1.9920296790078282 seconds)
2022-03-07 01:29:32 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 01:29:32 | INFO | train | epoch 310 | loss 1.774 | nll_loss 0.365 | ppl 1.29 | wps 24617.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15087 | lr 0.000257453 | gnorm 0.475 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 39231
2022-03-07 01:29:32 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 01:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:04 | INFO | train_inner | epoch 311:     13 / 49 loss=1.774, nll_loss=0.365, ppl=1.29, wps=24958.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.478, loss_scale=32, train_wall=223, gb_free=8.8, wall=39263
2022-03-07 01:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:31:37 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.229 | nll_loss 12.714 | ppl 6719.58 | wps 43691.1 | wpb 510.9 | bsz 1 | num_updates 15136 | best_loss 8.725
2022-03-07 01:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15136 updates
2022-03-07 01:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:31:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:31:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 311 @ 15136 updates, score 13.229) (writing took 1.8808964155614376 seconds)
2022-03-07 01:31:39 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 01:31:39 | INFO | train | epoch 311 | loss 1.773 | nll_loss 0.364 | ppl 1.29 | wps 25143.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15136 | lr 0.000257036 | gnorm 0.473 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 39357
2022-03-07 01:31:39 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 01:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:33:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:33:44 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.327 | nll_loss 12.825 | ppl 7256.11 | wps 43964 | wpb 510.9 | bsz 1 | num_updates 15184 | best_loss 8.725
2022-03-07 01:33:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15184 updates
2022-03-07 01:33:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:33:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:33:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 312 @ 15184 updates, score 13.327) (writing took 1.7544722286984324 seconds)
2022-03-07 01:33:45 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 01:33:45 | INFO | train | epoch 312 | loss 1.772 | nll_loss 0.364 | ppl 1.29 | wps 24575.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15184 | lr 0.00025663 | gnorm 0.47 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 39484
2022-03-07 01:33:45 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 01:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:34:25 | INFO | train_inner | epoch 313:     16 / 49 loss=1.772, nll_loss=0.363, ppl=1.29, wps=24890.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.47, loss_scale=32, train_wall=224, gb_free=8.8, wall=39523
2022-03-07 01:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:35:50 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.445 | nll_loss 12.947 | ppl 7896.14 | wps 44712.2 | wpb 510.9 | bsz 1 | num_updates 15233 | best_loss 8.725
2022-03-07 01:35:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15233 updates
2022-03-07 01:35:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:35:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 313 @ 15233 updates, score 13.445) (writing took 1.7431980092078447 seconds)
2022-03-07 01:35:52 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 01:35:52 | INFO | train | epoch 313 | loss 1.771 | nll_loss 0.363 | ppl 1.29 | wps 25130.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15233 | lr 0.000256217 | gnorm 0.47 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 39610
2022-03-07 01:35:52 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 01:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:37:57 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.355 | nll_loss 12.849 | ppl 7378.2 | wps 44255.4 | wpb 510.9 | bsz 1 | num_updates 15282 | best_loss 8.725
2022-03-07 01:37:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15282 updates
2022-03-07 01:37:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:37:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:37:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 314 @ 15282 updates, score 13.355) (writing took 1.9402397936210036 seconds)
2022-03-07 01:37:59 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 01:37:59 | INFO | train | epoch 314 | loss 1.771 | nll_loss 0.363 | ppl 1.29 | wps 25100.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15282 | lr 0.000255806 | gnorm 0.477 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 39737
2022-03-07 01:37:59 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 01:37:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:38:43 | INFO | train_inner | epoch 315:     18 / 49 loss=1.771, nll_loss=0.362, ppl=1.29, wps=25154.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.473, loss_scale=32, train_wall=221, gb_free=8.8, wall=39781
2022-03-07 01:39:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:39:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:40:03 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.361 | nll_loss 12.861 | ppl 7437.58 | wps 44435.7 | wpb 510.9 | bsz 1 | num_updates 15330 | best_loss 8.725
2022-03-07 01:40:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15330 updates
2022-03-07 01:40:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:40:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:40:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 315 @ 15330 updates, score 13.361) (writing took 1.933240070939064 seconds)
2022-03-07 01:40:05 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 01:40:05 | INFO | train | epoch 315 | loss 1.769 | nll_loss 0.361 | ppl 1.28 | wps 24595.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15330 | lr 0.000255405 | gnorm 0.472 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 39863
2022-03-07 01:40:05 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 01:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:42:10 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.373 | nll_loss 12.872 | ppl 7496.85 | wps 44353.5 | wpb 510.9 | bsz 1 | num_updates 15379 | best_loss 8.725
2022-03-07 01:42:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15379 updates
2022-03-07 01:42:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 316 @ 15379 updates, score 13.373) (writing took 1.7117772800847888 seconds)
2022-03-07 01:42:11 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 01:42:11 | INFO | train | epoch 316 | loss 1.768 | nll_loss 0.36 | ppl 1.28 | wps 25155.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15379 | lr 0.000254998 | gnorm 0.475 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 39990
2022-03-07 01:42:11 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 01:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:43:03 | INFO | train_inner | epoch 317:     21 / 49 loss=1.768, nll_loss=0.36, ppl=1.28, wps=24932.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.473, loss_scale=32, train_wall=223, gb_free=8.8, wall=40041
2022-03-07 01:44:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:44:16 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.348 | nll_loss 12.846 | ppl 7361.86 | wps 44674.7 | wpb 510.9 | bsz 1 | num_updates 15428 | best_loss 8.725
2022-03-07 01:44:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15428 updates
2022-03-07 01:44:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:44:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 317 @ 15428 updates, score 13.348) (writing took 1.6737307161092758 seconds)
2022-03-07 01:44:18 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 01:44:18 | INFO | train | epoch 317 | loss 1.767 | nll_loss 0.359 | ppl 1.28 | wps 25196.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15428 | lr 0.000254592 | gnorm 0.465 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 40116
2022-03-07 01:44:18 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 01:44:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:46:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:46:22 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.442 | nll_loss 12.948 | ppl 7900.38 | wps 44510.8 | wpb 510.9 | bsz 1 | num_updates 15476 | best_loss 8.725
2022-03-07 01:46:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15476 updates
2022-03-07 01:46:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:46:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:46:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 318 @ 15476 updates, score 13.442) (writing took 1.7684426084160805 seconds)
2022-03-07 01:46:24 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 01:46:24 | INFO | train | epoch 318 | loss 1.766 | nll_loss 0.359 | ppl 1.28 | wps 24665.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15476 | lr 0.000254197 | gnorm 0.469 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 40242
2022-03-07 01:46:24 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 01:46:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:47:23 | INFO | train_inner | epoch 319:     24 / 49 loss=1.767, nll_loss=0.359, ppl=1.28, wps=24981.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.469, loss_scale=32, train_wall=223, gb_free=8.8, wall=40301
2022-03-07 01:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:48:28 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.384 | nll_loss 12.882 | ppl 7546.12 | wps 44392.9 | wpb 510.9 | bsz 1 | num_updates 15525 | best_loss 8.725
2022-03-07 01:48:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15525 updates
2022-03-07 01:48:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:48:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 319 @ 15525 updates, score 13.384) (writing took 1.6658615274354815 seconds)
2022-03-07 01:48:30 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 01:48:30 | INFO | train | epoch 319 | loss 1.767 | nll_loss 0.359 | ppl 1.28 | wps 25190.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15525 | lr 0.000253796 | gnorm 0.479 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 40368
2022-03-07 01:48:30 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 01:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:50:34 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.443 | nll_loss 12.947 | ppl 7897.3 | wps 44622.1 | wpb 510.9 | bsz 1 | num_updates 15573 | best_loss 8.725
2022-03-07 01:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15573 updates
2022-03-07 01:50:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:50:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:50:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 320 @ 15573 updates, score 13.443) (writing took 1.727524382993579 seconds)
2022-03-07 01:50:36 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 01:50:36 | INFO | train | epoch 320 | loss 1.764 | nll_loss 0.357 | ppl 1.28 | wps 24657.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15573 | lr 0.000253404 | gnorm 0.47 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 40494
2022-03-07 01:50:36 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 01:50:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:51:43 | INFO | train_inner | epoch 321:     27 / 49 loss=1.765, nll_loss=0.358, ppl=1.28, wps=24970.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.474, loss_scale=32, train_wall=223, gb_free=8.8, wall=40561
2022-03-07 01:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:52:41 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.388 | nll_loss 12.887 | ppl 7576.56 | wps 44478.3 | wpb 510.9 | bsz 1 | num_updates 15622 | best_loss 8.725
2022-03-07 01:52:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15622 updates
2022-03-07 01:52:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 321 @ 15622 updates, score 13.388) (writing took 1.7844011951237917 seconds)
2022-03-07 01:52:42 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 01:52:42 | INFO | train | epoch 321 | loss 1.763 | nll_loss 0.356 | ppl 1.28 | wps 25173.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15622 | lr 0.000253007 | gnorm 0.47 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 40621
2022-03-07 01:52:42 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 01:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:54:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:54:47 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.467 | nll_loss 12.971 | ppl 8028.51 | wps 44477.6 | wpb 510.9 | bsz 1 | num_updates 15671 | best_loss 8.725
2022-03-07 01:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15671 updates
2022-03-07 01:54:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:54:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 322 @ 15671 updates, score 13.467) (writing took 1.7191316606476903 seconds)
2022-03-07 01:54:49 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 01:54:49 | INFO | train | epoch 322 | loss 1.762 | nll_loss 0.355 | ppl 1.28 | wps 25156.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15671 | lr 0.000252611 | gnorm 0.47 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 40747
2022-03-07 01:54:49 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 01:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:55:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:56:03 | INFO | train_inner | epoch 323:     30 / 49 loss=1.762, nll_loss=0.355, ppl=1.28, wps=24944.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.468, loss_scale=32, train_wall=223, gb_free=8.8, wall=40821
2022-03-07 01:56:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:56:53 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.301 | nll_loss 12.8 | ppl 7133.4 | wps 44226 | wpb 510.9 | bsz 1 | num_updates 15719 | best_loss 8.725
2022-03-07 01:56:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15719 updates
2022-03-07 01:56:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:56:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 323 @ 15719 updates, score 13.301) (writing took 1.7121558506041765 seconds)
2022-03-07 01:56:55 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 01:56:55 | INFO | train | epoch 323 | loss 1.761 | nll_loss 0.355 | ppl 1.28 | wps 24650.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15719 | lr 0.000252225 | gnorm 0.469 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 40873
2022-03-07 01:56:55 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 01:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:59:00 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.451 | nll_loss 12.953 | ppl 7930.84 | wps 44637.4 | wpb 510.9 | bsz 1 | num_updates 15768 | best_loss 8.725
2022-03-07 01:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15768 updates
2022-03-07 01:59:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 324 @ 15768 updates, score 13.451) (writing took 1.7779661230742931 seconds)
2022-03-07 01:59:01 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 01:59:01 | INFO | train | epoch 324 | loss 1.76 | nll_loss 0.354 | ppl 1.28 | wps 25146.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15768 | lr 0.000251832 | gnorm 0.463 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 41000
2022-03-07 01:59:01 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 01:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:00:20 | INFO | train_inner | epoch 325:     32 / 49 loss=1.76, nll_loss=0.354, ppl=1.28, wps=25186.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.464, loss_scale=32, train_wall=221, gb_free=8.8, wall=41079
2022-03-07 02:01:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:01:06 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.355 | nll_loss 12.855 | ppl 7410.69 | wps 44420 | wpb 510.9 | bsz 1 | num_updates 15817 | best_loss 8.725
2022-03-07 02:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15817 updates
2022-03-07 02:01:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:01:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:01:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 325 @ 15817 updates, score 13.355) (writing took 1.7099735112860799 seconds)
2022-03-07 02:01:08 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 02:01:08 | INFO | train | epoch 325 | loss 1.759 | nll_loss 0.353 | ppl 1.28 | wps 25164.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15817 | lr 0.000251442 | gnorm 0.462 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 41126
2022-03-07 02:01:08 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 02:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:01:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:03:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:03:13 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.465 | nll_loss 12.974 | ppl 8045.48 | wps 43719.6 | wpb 510.9 | bsz 1 | num_updates 15865 | best_loss 8.725
2022-03-07 02:03:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15865 updates
2022-03-07 02:03:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 326 @ 15865 updates, score 13.465) (writing took 1.8893917743116617 seconds)
2022-03-07 02:03:14 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 02:03:14 | INFO | train | epoch 326 | loss 1.758 | nll_loss 0.352 | ppl 1.28 | wps 24548.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15865 | lr 0.000251061 | gnorm 0.466 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 41253
2022-03-07 02:03:14 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 02:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:04:41 | INFO | train_inner | epoch 327:     35 / 49 loss=1.758, nll_loss=0.353, ppl=1.28, wps=24886.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.467, loss_scale=32, train_wall=224, gb_free=8.8, wall=41339
2022-03-07 02:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:05:19 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.412 | nll_loss 12.919 | ppl 7745.13 | wps 43780 | wpb 510.9 | bsz 1 | num_updates 15914 | best_loss 8.725
2022-03-07 02:05:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15914 updates
2022-03-07 02:05:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:05:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:05:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 327 @ 15914 updates, score 13.412) (writing took 1.8526070220395923 seconds)
2022-03-07 02:05:21 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 02:05:21 | INFO | train | epoch 327 | loss 1.759 | nll_loss 0.353 | ppl 1.28 | wps 25072 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 15914 | lr 0.000250675 | gnorm 0.468 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41379
2022-03-07 02:05:21 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 02:05:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:07:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:07:26 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.47 | nll_loss 12.98 | ppl 8081.34 | wps 43922.4 | wpb 510.9 | bsz 1 | num_updates 15962 | best_loss 8.725
2022-03-07 02:07:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15962 updates
2022-03-07 02:07:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:07:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 328 @ 15962 updates, score 13.47) (writing took 1.932482066564262 seconds)
2022-03-07 02:07:28 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 02:07:28 | INFO | train | epoch 328 | loss 1.757 | nll_loss 0.352 | ppl 1.28 | wps 24549.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 15962 | lr 0.000250297 | gnorm 0.475 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 41506
2022-03-07 02:07:28 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 02:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:09:02 | INFO | train_inner | epoch 329:     38 / 49 loss=1.756, nll_loss=0.351, ppl=1.28, wps=24866.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.466, loss_scale=32, train_wall=224, gb_free=8.8, wall=41600
2022-03-07 02:09:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:09:33 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.324 | nll_loss 12.824 | ppl 7252.99 | wps 43951.5 | wpb 510.9 | bsz 1 | num_updates 16011 | best_loss 8.725
2022-03-07 02:09:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16011 updates
2022-03-07 02:09:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 329 @ 16011 updates, score 13.324) (writing took 1.83688956592232 seconds)
2022-03-07 02:09:35 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 02:09:35 | INFO | train | epoch 329 | loss 1.755 | nll_loss 0.35 | ppl 1.27 | wps 25092.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16011 | lr 0.000249914 | gnorm 0.461 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 41633
2022-03-07 02:09:35 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 02:09:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:11:40 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.295 | nll_loss 12.796 | ppl 7109.68 | wps 44162.8 | wpb 510.9 | bsz 1 | num_updates 16060 | best_loss 8.725
2022-03-07 02:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16060 updates
2022-03-07 02:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:11:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 330 @ 16060 updates, score 13.295) (writing took 1.7264549806714058 seconds)
2022-03-07 02:11:41 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 02:11:41 | INFO | train | epoch 330 | loss 1.755 | nll_loss 0.35 | ppl 1.27 | wps 25098.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16060 | lr 0.000249533 | gnorm 0.462 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41760
2022-03-07 02:11:41 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 02:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:13:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:13:23 | INFO | train_inner | epoch 331:     41 / 49 loss=1.755, nll_loss=0.35, ppl=1.27, wps=24873.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.461, loss_scale=32, train_wall=224, gb_free=8.8, wall=41861
2022-03-07 02:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:46 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.438 | nll_loss 12.944 | ppl 7879.14 | wps 44526.2 | wpb 510.9 | bsz 1 | num_updates 16108 | best_loss 8.725
2022-03-07 02:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16108 updates
2022-03-07 02:13:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:13:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:13:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 331 @ 16108 updates, score 13.438) (writing took 1.7753298925235868 seconds)
2022-03-07 02:13:48 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 02:13:48 | INFO | train | epoch 331 | loss 1.753 | nll_loss 0.348 | ppl 1.27 | wps 24579.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16108 | lr 0.00024916 | gnorm 0.454 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 41886
2022-03-07 02:13:48 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 02:13:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:15:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:15:53 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.398 | nll_loss 12.903 | ppl 7660.78 | wps 44226.1 | wpb 510.9 | bsz 1 | num_updates 16157 | best_loss 8.725
2022-03-07 02:15:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16157 updates
2022-03-07 02:15:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:15:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:15:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 332 @ 16157 updates, score 13.398) (writing took 1.8511408492922783 seconds)
2022-03-07 02:15:55 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 02:15:55 | INFO | train | epoch 332 | loss 1.753 | nll_loss 0.348 | ppl 1.27 | wps 25088 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16157 | lr 0.000248782 | gnorm 0.468 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 42013
2022-03-07 02:15:55 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 02:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:41 | INFO | train_inner | epoch 333:     43 / 49 loss=1.753, nll_loss=0.348, ppl=1.27, wps=25124.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.464, loss_scale=32, train_wall=221, gb_free=8.8, wall=42119
2022-03-07 02:17:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:18:00 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.433 | nll_loss 12.939 | ppl 7854 | wps 43405.4 | wpb 510.9 | bsz 1 | num_updates 16206 | best_loss 8.725
2022-03-07 02:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16206 updates
2022-03-07 02:18:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 333 @ 16206 updates, score 13.433) (writing took 1.7935571279376745 seconds)
2022-03-07 02:18:01 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 02:18:01 | INFO | train | epoch 333 | loss 1.752 | nll_loss 0.348 | ppl 1.27 | wps 25072.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16206 | lr 0.000248406 | gnorm 0.462 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42140
2022-03-07 02:18:01 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 02:18:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:18:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:20:06 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.39 | nll_loss 12.889 | ppl 7585.12 | wps 43120.3 | wpb 510.9 | bsz 1 | num_updates 16254 | best_loss 8.725
2022-03-07 02:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16254 updates
2022-03-07 02:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:20:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 334 @ 16254 updates, score 13.39) (writing took 1.7739851456135511 seconds)
2022-03-07 02:20:08 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 02:20:08 | INFO | train | epoch 334 | loss 1.752 | nll_loss 0.348 | ppl 1.27 | wps 24563.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16254 | lr 0.000248039 | gnorm 0.468 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 42266
2022-03-07 02:20:08 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 02:20:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:22:02 | INFO | train_inner | epoch 335:     46 / 49 loss=1.752, nll_loss=0.347, ppl=1.27, wps=24860.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.462, loss_scale=32, train_wall=224, gb_free=8.8, wall=42380
2022-03-07 02:22:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:13 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.442 | nll_loss 12.948 | ppl 7899.53 | wps 44150.7 | wpb 510.9 | bsz 1 | num_updates 16303 | best_loss 8.725
2022-03-07 02:22:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16303 updates
2022-03-07 02:22:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:22:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:22:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 335 @ 16303 updates, score 13.442) (writing took 1.9021307546645403 seconds)
2022-03-07 02:22:15 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 02:22:15 | INFO | train | epoch 335 | loss 1.75 | nll_loss 0.346 | ppl 1.27 | wps 25054.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16303 | lr 0.000247666 | gnorm 0.456 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42393
2022-03-07 02:22:15 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 02:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:24:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:20 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.364 | nll_loss 12.862 | ppl 7444.63 | wps 44090.9 | wpb 510.9 | bsz 1 | num_updates 16351 | best_loss 8.725
2022-03-07 02:24:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16351 updates
2022-03-07 02:24:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:24:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:24:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 336 @ 16351 updates, score 13.364) (writing took 1.8654681835323572 seconds)
2022-03-07 02:24:22 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 02:24:22 | INFO | train | epoch 336 | loss 1.749 | nll_loss 0.345 | ppl 1.27 | wps 24560.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16351 | lr 0.000247302 | gnorm 0.458 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42520
2022-03-07 02:24:22 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 02:24:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:26:21 | INFO | train_inner | epoch 337:     49 / 49 loss=1.749, nll_loss=0.345, ppl=1.27, wps=24856.9, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=16400, lr=0.000246932, gnorm=0.463, loss_scale=32, train_wall=223, gb_free=8.8, wall=42640
2022-03-07 02:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:26 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.486 | nll_loss 12.991 | ppl 8139.4 | wps 44198.7 | wpb 510.9 | bsz 1 | num_updates 16400 | best_loss 8.725
2022-03-07 02:26:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16400 updates
2022-03-07 02:26:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 337 @ 16400 updates, score 13.486) (writing took 1.991872494108975 seconds)
2022-03-07 02:26:28 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 02:26:28 | INFO | train | epoch 337 | loss 1.749 | nll_loss 0.345 | ppl 1.27 | wps 25058.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16400 | lr 0.000246932 | gnorm 0.466 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42647
2022-03-07 02:26:28 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 02:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:27:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:28:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:28:33 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.346 | nll_loss 12.849 | ppl 7376.63 | wps 44278 | wpb 510.9 | bsz 1 | num_updates 16448 | best_loss 8.725
2022-03-07 02:28:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16448 updates
2022-03-07 02:28:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:28:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:28:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 338 @ 16448 updates, score 13.346) (writing took 1.86464670766145 seconds)
2022-03-07 02:28:35 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 02:28:35 | INFO | train | epoch 338 | loss 1.748 | nll_loss 0.344 | ppl 1.27 | wps 24554.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16448 | lr 0.000246572 | gnorm 0.464 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 42773
2022-03-07 02:28:35 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 02:28:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:30:40 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.443 | nll_loss 12.952 | ppl 7924.35 | wps 43460.4 | wpb 510.9 | bsz 1 | num_updates 16497 | best_loss 8.725
2022-03-07 02:30:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16497 updates
2022-03-07 02:30:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:30:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:30:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 339 @ 16497 updates, score 13.443) (writing took 1.9558475138619542 seconds)
2022-03-07 02:30:42 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 02:30:42 | INFO | train | epoch 339 | loss 1.746 | nll_loss 0.343 | ppl 1.27 | wps 25058.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16497 | lr 0.000246205 | gnorm 0.458 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 42900
2022-03-07 02:30:42 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 02:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:30:50 | INFO | train_inner | epoch 340:      3 / 49 loss=1.747, nll_loss=0.343, ppl=1.27, wps=24199.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.46, loss_scale=16, train_wall=224, gb_free=8.8, wall=42908
2022-03-07 02:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:32:47 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.43 | nll_loss 12.939 | ppl 7852.41 | wps 44392.8 | wpb 510.9 | bsz 1 | num_updates 16546 | best_loss 8.725
2022-03-07 02:32:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16546 updates
2022-03-07 02:32:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 340 @ 16546 updates, score 13.43) (writing took 1.834906430914998 seconds)
2022-03-07 02:32:49 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 02:32:49 | INFO | train | epoch 340 | loss 1.746 | nll_loss 0.342 | ppl 1.27 | wps 25086.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16546 | lr 0.000245841 | gnorm 0.453 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43027
2022-03-07 02:32:49 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 02:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:34:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:34:54 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.437 | nll_loss 12.943 | ppl 7875.66 | wps 44105.6 | wpb 510.9 | bsz 1 | num_updates 16594 | best_loss 8.725
2022-03-07 02:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16594 updates
2022-03-07 02:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 341 @ 16594 updates, score 13.437) (writing took 1.750897509045899 seconds)
2022-03-07 02:34:55 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 02:34:55 | INFO | train | epoch 341 | loss 1.745 | nll_loss 0.342 | ppl 1.27 | wps 24599.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16594 | lr 0.000245485 | gnorm 0.466 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 43153
2022-03-07 02:34:55 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 02:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:35:10 | INFO | train_inner | epoch 342:      6 / 49 loss=1.745, nll_loss=0.342, ppl=1.27, wps=24894.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.46, loss_scale=16, train_wall=224, gb_free=8.8, wall=43168
2022-03-07 02:36:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:37:00 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.365 | nll_loss 12.869 | ppl 7480.94 | wps 44265.5 | wpb 510.9 | bsz 1 | num_updates 16643 | best_loss 8.725
2022-03-07 02:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16643 updates
2022-03-07 02:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:37:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:37:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 342 @ 16643 updates, score 13.365) (writing took 1.8777996907010674 seconds)
2022-03-07 02:37:02 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 02:37:02 | INFO | train | epoch 342 | loss 1.744 | nll_loss 0.341 | ppl 1.27 | wps 25093.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16643 | lr 0.000245123 | gnorm 0.46 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 43280
2022-03-07 02:37:02 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 02:37:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:39:07 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.364 | nll_loss 12.868 | ppl 7473.33 | wps 44308.5 | wpb 510.9 | bsz 1 | num_updates 16692 | best_loss 8.725
2022-03-07 02:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16692 updates
2022-03-07 02:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 343 @ 16692 updates, score 13.364) (writing took 1.7668904308229685 seconds)
2022-03-07 02:39:09 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 02:39:09 | INFO | train | epoch 343 | loss 1.743 | nll_loss 0.34 | ppl 1.27 | wps 25103.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16692 | lr 0.000244763 | gnorm 0.456 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 43407
2022-03-07 02:39:09 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 02:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:28 | INFO | train_inner | epoch 344:      8 / 49 loss=1.743, nll_loss=0.341, ppl=1.27, wps=25127.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.457, loss_scale=16, train_wall=221, gb_free=8.8, wall=43427
2022-03-07 02:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:41:13 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.365 | nll_loss 12.868 | ppl 7474.79 | wps 44441.7 | wpb 510.9 | bsz 1 | num_updates 16741 | best_loss 8.725
2022-03-07 02:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16741 updates
2022-03-07 02:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 344 @ 16741 updates, score 13.365) (writing took 1.697849434800446 seconds)
2022-03-07 02:41:15 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 02:41:15 | INFO | train | epoch 344 | loss 1.743 | nll_loss 0.341 | ppl 1.27 | wps 25192.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16741 | lr 0.000244405 | gnorm 0.452 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 43533
2022-03-07 02:41:15 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 02:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:43:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:43:19 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.385 | nll_loss 12.892 | ppl 7601.01 | wps 44531.5 | wpb 510.9 | bsz 1 | num_updates 16790 | best_loss 8.725
2022-03-07 02:43:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16790 updates
2022-03-07 02:43:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:43:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 345 @ 16790 updates, score 13.385) (writing took 1.9104941356927156 seconds)
2022-03-07 02:43:21 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 02:43:21 | INFO | train | epoch 345 | loss 1.742 | nll_loss 0.34 | ppl 1.27 | wps 25143.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16790 | lr 0.000244048 | gnorm 0.456 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 43659
2022-03-07 02:43:21 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 02:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:43:46 | INFO | train_inner | epoch 346:     10 / 49 loss=1.742, nll_loss=0.34, ppl=1.27, wps=25199.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.452, loss_scale=32, train_wall=221, gb_free=8.8, wall=43684
2022-03-07 02:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:45:25 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.488 | nll_loss 13.002 | ppl 8204.68 | wps 44438.9 | wpb 510.9 | bsz 1 | num_updates 16839 | best_loss 8.725
2022-03-07 02:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16839 updates
2022-03-07 02:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 346 @ 16839 updates, score 13.488) (writing took 1.777440714649856 seconds)
2022-03-07 02:45:27 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 02:45:27 | INFO | train | epoch 346 | loss 1.741 | nll_loss 0.339 | ppl 1.26 | wps 25186.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16839 | lr 0.000243692 | gnorm 0.452 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 43785
2022-03-07 02:45:27 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 02:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:45:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:47:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:47:32 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.467 | nll_loss 12.977 | ppl 8060.34 | wps 44700.1 | wpb 510.9 | bsz 1 | num_updates 16887 | best_loss 8.725
2022-03-07 02:47:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16887 updates
2022-03-07 02:47:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:47:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 347 @ 16887 updates, score 13.467) (writing took 1.8005662048235536 seconds)
2022-03-07 02:47:33 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 02:47:33 | INFO | train | epoch 347 | loss 1.741 | nll_loss 0.339 | ppl 1.26 | wps 24658.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16887 | lr 0.000243346 | gnorm 0.456 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 43912
2022-03-07 02:47:33 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 02:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:48:06 | INFO | train_inner | epoch 348:     13 / 49 loss=1.741, nll_loss=0.339, ppl=1.26, wps=24966.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.454, loss_scale=32, train_wall=223, gb_free=8.8, wall=43944
2022-03-07 02:49:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:49:38 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.489 | nll_loss 13.001 | ppl 8199.58 | wps 44881.8 | wpb 510.9 | bsz 1 | num_updates 16936 | best_loss 8.725
2022-03-07 02:49:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16936 updates
2022-03-07 02:49:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:49:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:49:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 348 @ 16936 updates, score 13.489) (writing took 1.7512487722560763 seconds)
2022-03-07 02:49:40 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 02:49:40 | INFO | train | epoch 348 | loss 1.74 | nll_loss 0.339 | ppl 1.26 | wps 25173.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 16936 | lr 0.000242993 | gnorm 0.453 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 44038
2022-03-07 02:49:40 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 02:49:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:51:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:51:44 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.406 | nll_loss 12.911 | ppl 7701.76 | wps 44394 | wpb 510.9 | bsz 1 | num_updates 16984 | best_loss 8.725
2022-03-07 02:51:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16984 updates
2022-03-07 02:51:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:51:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:51:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 349 @ 16984 updates, score 13.406) (writing took 1.9397448720410466 seconds)
2022-03-07 02:51:46 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 02:51:46 | INFO | train | epoch 349 | loss 1.739 | nll_loss 0.337 | ppl 1.26 | wps 24591.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 16984 | lr 0.00024265 | gnorm 0.459 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 44165
2022-03-07 02:51:46 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 02:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:52:26 | INFO | train_inner | epoch 350:     16 / 49 loss=1.739, nll_loss=0.338, ppl=1.26, wps=24921.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.456, loss_scale=32, train_wall=223, gb_free=8.8, wall=44204
2022-03-07 02:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:53:51 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.358 | nll_loss 12.86 | ppl 7432.88 | wps 44408.5 | wpb 510.9 | bsz 1 | num_updates 17033 | best_loss 8.725
2022-03-07 02:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17033 updates
2022-03-07 02:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:53:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 350 @ 17033 updates, score 13.358) (writing took 1.7390609858557582 seconds)
2022-03-07 02:53:53 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 02:53:53 | INFO | train | epoch 350 | loss 1.738 | nll_loss 0.336 | ppl 1.26 | wps 25128.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17033 | lr 0.000242301 | gnorm 0.451 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 44291
2022-03-07 02:53:53 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 02:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:55:57 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.37 | nll_loss 12.877 | ppl 7520.77 | wps 44429.3 | wpb 510.9 | bsz 1 | num_updates 17082 | best_loss 8.725
2022-03-07 02:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17082 updates
2022-03-07 02:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:55:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:55:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 351 @ 17082 updates, score 13.37) (writing took 2.0473294276744127 seconds)
2022-03-07 02:55:59 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 02:55:59 | INFO | train | epoch 351 | loss 1.738 | nll_loss 0.337 | ppl 1.26 | wps 25100 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17082 | lr 0.000241953 | gnorm 0.452 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 44418
2022-03-07 02:55:59 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 02:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:56:44 | INFO | train_inner | epoch 352:     18 / 49 loss=1.738, nll_loss=0.336, ppl=1.26, wps=25150.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.452, loss_scale=32, train_wall=221, gb_free=8.8, wall=44462
2022-03-07 02:57:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:58:04 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.371 | nll_loss 12.877 | ppl 7520.07 | wps 44354.6 | wpb 510.9 | bsz 1 | num_updates 17130 | best_loss 8.725
2022-03-07 02:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17130 updates
2022-03-07 02:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:58:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 352 @ 17130 updates, score 13.371) (writing took 1.7974834041669965 seconds)
2022-03-07 02:58:06 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 02:58:06 | INFO | train | epoch 352 | loss 1.737 | nll_loss 0.336 | ppl 1.26 | wps 24601.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17130 | lr 0.000241614 | gnorm 0.45 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 44544
2022-03-07 02:58:06 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 02:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:11 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.337 | nll_loss 12.838 | ppl 7322.1 | wps 44051.6 | wpb 510.9 | bsz 1 | num_updates 17179 | best_loss 8.725
2022-03-07 03:00:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17179 updates
2022-03-07 03:00:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:00:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:00:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 353 @ 17179 updates, score 13.337) (writing took 1.93365278840065 seconds)
2022-03-07 03:00:13 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 03:00:13 | INFO | train | epoch 353 | loss 1.735 | nll_loss 0.334 | ppl 1.26 | wps 25057.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17179 | lr 0.000241269 | gnorm 0.445 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44671
2022-03-07 03:00:13 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 03:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:01:05 | INFO | train_inner | epoch 354:     21 / 49 loss=1.735, nll_loss=0.334, ppl=1.26, wps=24864.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.446, loss_scale=32, train_wall=224, gb_free=8.8, wall=44723
2022-03-07 03:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:02:18 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.331 | nll_loss 12.836 | ppl 7310.49 | wps 43853.3 | wpb 510.9 | bsz 1 | num_updates 17228 | best_loss 8.725
2022-03-07 03:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17228 updates
2022-03-07 03:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:02:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:02:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 354 @ 17228 updates, score 13.331) (writing took 1.9246421325951815 seconds)
2022-03-07 03:02:20 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 03:02:20 | INFO | train | epoch 354 | loss 1.735 | nll_loss 0.334 | ppl 1.26 | wps 25051.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17228 | lr 0.000240925 | gnorm 0.447 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44798
2022-03-07 03:02:20 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 03:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:03:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:04:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:04:24 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.344 | nll_loss 12.845 | ppl 7355.25 | wps 44090.8 | wpb 510.9 | bsz 1 | num_updates 17276 | best_loss 8.725
2022-03-07 03:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17276 updates
2022-03-07 03:04:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:04:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:04:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 355 @ 17276 updates, score 13.344) (writing took 1.792165252380073 seconds)
2022-03-07 03:04:26 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 03:04:26 | INFO | train | epoch 355 | loss 1.734 | nll_loss 0.333 | ppl 1.26 | wps 24574.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17276 | lr 0.00024059 | gnorm 0.444 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44924
2022-03-07 03:04:26 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 03:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:05:26 | INFO | train_inner | epoch 356:     24 / 49 loss=1.734, nll_loss=0.333, ppl=1.26, wps=24857.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.446, loss_scale=32, train_wall=224, gb_free=8.8, wall=44984
2022-03-07 03:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:06:31 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.425 | nll_loss 12.931 | ppl 7810.9 | wps 44126 | wpb 510.9 | bsz 1 | num_updates 17325 | best_loss 8.725
2022-03-07 03:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17325 updates
2022-03-07 03:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 356 @ 17325 updates, score 13.425) (writing took 1.8422592682763934 seconds)
2022-03-07 03:06:33 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 03:06:33 | INFO | train | epoch 356 | loss 1.733 | nll_loss 0.333 | ppl 1.26 | wps 25062.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17325 | lr 0.00024025 | gnorm 0.452 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45051
2022-03-07 03:06:33 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 03:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:08:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:08:38 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.456 | nll_loss 12.97 | ppl 8021.31 | wps 44164.5 | wpb 510.9 | bsz 1 | num_updates 17374 | best_loss 8.725
2022-03-07 03:08:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17374 updates
2022-03-07 03:08:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 357 @ 17374 updates, score 13.456) (writing took 1.9115577088668942 seconds)
2022-03-07 03:08:40 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 03:08:40 | INFO | train | epoch 357 | loss 1.733 | nll_loss 0.333 | ppl 1.26 | wps 25063.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17374 | lr 0.000239911 | gnorm 0.448 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 45178
2022-03-07 03:08:40 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 03:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:08:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:09:47 | INFO | train_inner | epoch 358:     27 / 49 loss=1.733, nll_loss=0.333, ppl=1.26, wps=24856.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.449, loss_scale=32, train_wall=224, gb_free=8.8, wall=45245
2022-03-07 03:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:10:45 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.356 | nll_loss 12.86 | ppl 7435.53 | wps 43950.7 | wpb 510.9 | bsz 1 | num_updates 17422 | best_loss 8.725
2022-03-07 03:10:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17422 updates
2022-03-07 03:10:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 358 @ 17422 updates, score 13.356) (writing took 1.953909662552178 seconds)
2022-03-07 03:10:47 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 03:10:47 | INFO | train | epoch 358 | loss 1.731 | nll_loss 0.331 | ppl 1.26 | wps 24514.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17422 | lr 0.00023958 | gnorm 0.442 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45305
2022-03-07 03:10:47 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 03:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:12:52 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.415 | nll_loss 12.923 | ppl 7765.66 | wps 44091.2 | wpb 510.9 | bsz 1 | num_updates 17471 | best_loss 8.725
2022-03-07 03:12:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17471 updates
2022-03-07 03:12:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:12:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:12:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 359 @ 17471 updates, score 13.415) (writing took 1.789636512286961 seconds)
2022-03-07 03:12:53 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 03:12:53 | INFO | train | epoch 359 | loss 1.731 | nll_loss 0.332 | ppl 1.26 | wps 25099.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17471 | lr 0.000239244 | gnorm 0.445 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45432
2022-03-07 03:12:53 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 03:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:05 | INFO | train_inner | epoch 360:     29 / 49 loss=1.731, nll_loss=0.331, ppl=1.26, wps=25099.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.441, loss_scale=32, train_wall=222, gb_free=8.8, wall=45503
2022-03-07 03:14:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:58 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.384 | nll_loss 12.893 | ppl 7604.7 | wps 44214.8 | wpb 510.9 | bsz 1 | num_updates 17519 | best_loss 8.725
2022-03-07 03:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17519 updates
2022-03-07 03:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 360 @ 17519 updates, score 13.384) (writing took 1.7841228367760777 seconds)
2022-03-07 03:15:00 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 03:15:00 | INFO | train | epoch 360 | loss 1.729 | nll_loss 0.33 | ppl 1.26 | wps 24567.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17519 | lr 0.000238916 | gnorm 0.435 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45558
2022-03-07 03:15:00 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 03:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:17:05 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.413 | nll_loss 12.923 | ppl 7766.53 | wps 44114.9 | wpb 510.9 | bsz 1 | num_updates 17568 | best_loss 8.725
2022-03-07 03:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17568 updates
2022-03-07 03:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 361 @ 17568 updates, score 13.413) (writing took 1.7342990646138787 seconds)
2022-03-07 03:17:07 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 03:17:07 | INFO | train | epoch 361 | loss 1.73 | nll_loss 0.331 | ppl 1.26 | wps 25103.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17568 | lr 0.000238583 | gnorm 0.448 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 45685
2022-03-07 03:17:07 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 03:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:18:26 | INFO | train_inner | epoch 362:     32 / 49 loss=1.73, nll_loss=0.331, ppl=1.26, wps=24884.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.442, loss_scale=32, train_wall=224, gb_free=8.8, wall=45764
2022-03-07 03:19:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:19:12 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.306 | nll_loss 12.808 | ppl 7170.85 | wps 44025.4 | wpb 510.9 | bsz 1 | num_updates 17617 | best_loss 8.725
2022-03-07 03:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17617 updates
2022-03-07 03:19:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 362 @ 17617 updates, score 13.306) (writing took 1.7609639689326286 seconds)
2022-03-07 03:19:13 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 03:19:13 | INFO | train | epoch 362 | loss 1.729 | nll_loss 0.33 | ppl 1.26 | wps 25092.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17617 | lr 0.000238251 | gnorm 0.442 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45812
2022-03-07 03:19:13 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 03:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:20:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:21:18 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.428 | nll_loss 12.934 | ppl 7824.34 | wps 43792.4 | wpb 510.9 | bsz 1 | num_updates 17665 | best_loss 8.725
2022-03-07 03:21:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17665 updates
2022-03-07 03:21:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:21:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:21:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 363 @ 17665 updates, score 13.428) (writing took 1.7291307225823402 seconds)
2022-03-07 03:21:20 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 03:21:20 | INFO | train | epoch 363 | loss 1.728 | nll_loss 0.329 | ppl 1.26 | wps 24590.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17665 | lr 0.000237927 | gnorm 0.436 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 45938
2022-03-07 03:21:20 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 03:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:22:46 | INFO | train_inner | epoch 364:     35 / 49 loss=1.728, nll_loss=0.329, ppl=1.26, wps=24888.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.44, loss_scale=32, train_wall=224, gb_free=8.8, wall=46025
2022-03-07 03:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:25 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.436 | nll_loss 12.944 | ppl 7879.93 | wps 44017.3 | wpb 510.9 | bsz 1 | num_updates 17714 | best_loss 8.725
2022-03-07 03:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17714 updates
2022-03-07 03:23:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:23:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:23:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 364 @ 17714 updates, score 13.436) (writing took 1.8886494915932417 seconds)
2022-03-07 03:23:27 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 03:23:27 | INFO | train | epoch 364 | loss 1.728 | nll_loss 0.329 | ppl 1.26 | wps 25063.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17714 | lr 0.000237597 | gnorm 0.443 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46065
2022-03-07 03:23:27 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 03:23:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:25:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:25:32 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.445 | nll_loss 12.957 | ppl 7952.66 | wps 43662.4 | wpb 510.9 | bsz 1 | num_updates 17763 | best_loss 8.725
2022-03-07 03:25:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17763 updates
2022-03-07 03:25:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:25:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:25:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 365 @ 17763 updates, score 13.445) (writing took 1.84718135651201 seconds)
2022-03-07 03:25:34 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 03:25:34 | INFO | train | epoch 365 | loss 1.727 | nll_loss 0.329 | ppl 1.26 | wps 25066.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17763 | lr 0.000237269 | gnorm 0.444 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46192
2022-03-07 03:25:34 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 03:25:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:25:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:27:07 | INFO | train_inner | epoch 366:     38 / 49 loss=1.727, nll_loss=0.328, ppl=1.26, wps=24862.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.443, loss_scale=32, train_wall=224, gb_free=8.8, wall=46286
2022-03-07 03:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:27:38 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.354 | nll_loss 12.864 | ppl 7453.81 | wps 43903.2 | wpb 510.9 | bsz 1 | num_updates 17811 | best_loss 8.725
2022-03-07 03:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17811 updates
2022-03-07 03:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:27:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 366 @ 17811 updates, score 13.354) (writing took 1.770868663676083 seconds)
2022-03-07 03:27:40 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 03:27:40 | INFO | train | epoch 366 | loss 1.726 | nll_loss 0.327 | ppl 1.25 | wps 24577.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17811 | lr 0.00023695 | gnorm 0.44 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 46318
2022-03-07 03:27:40 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 03:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:29:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:29:45 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.433 | nll_loss 12.944 | ppl 7877.8 | wps 44462.2 | wpb 510.9 | bsz 1 | num_updates 17860 | best_loss 8.725
2022-03-07 03:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17860 updates
2022-03-07 03:29:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 367 @ 17860 updates, score 13.433) (writing took 1.740112081170082 seconds)
2022-03-07 03:29:47 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 03:29:47 | INFO | train | epoch 367 | loss 1.725 | nll_loss 0.327 | ppl 1.25 | wps 25123.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17860 | lr 0.000236624 | gnorm 0.441 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 46445
2022-03-07 03:29:47 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 03:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:31:26 | INFO | train_inner | epoch 368:     40 / 49 loss=1.724, nll_loss=0.326, ppl=1.25, wps=25117.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.438, loss_scale=64, train_wall=222, gb_free=8.8, wall=46544
2022-03-07 03:31:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:31:52 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.32 | nll_loss 12.823 | ppl 7244.93 | wps 43991 | wpb 510.9 | bsz 1 | num_updates 17909 | best_loss 8.725
2022-03-07 03:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17909 updates
2022-03-07 03:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:31:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:31:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 368 @ 17909 updates, score 13.32) (writing took 1.7332827467471361 seconds)
2022-03-07 03:31:53 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 03:31:53 | INFO | train | epoch 368 | loss 1.724 | nll_loss 0.326 | ppl 1.25 | wps 25064.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 17909 | lr 0.0002363 | gnorm 0.432 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 46572
2022-03-07 03:31:53 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 03:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:31:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:33:58 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.389 | nll_loss 12.894 | ppl 7613.24 | wps 44072.7 | wpb 510.9 | bsz 1 | num_updates 17957 | best_loss 8.725
2022-03-07 03:33:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17957 updates
2022-03-07 03:33:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:34:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:34:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 369 @ 17957 updates, score 13.389) (writing took 1.6959594944491982 seconds)
2022-03-07 03:34:00 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 03:34:00 | INFO | train | epoch 369 | loss 1.724 | nll_loss 0.326 | ppl 1.25 | wps 24613.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17957 | lr 0.000235984 | gnorm 0.439 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 46698
2022-03-07 03:34:00 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 03:34:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:35:46 | INFO | train_inner | epoch 370:     43 / 49 loss=1.724, nll_loss=0.326, ppl=1.25, wps=24895.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.439, loss_scale=32, train_wall=224, gb_free=8.8, wall=46804
2022-03-07 03:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:36:05 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.384 | nll_loss 12.894 | ppl 7611.57 | wps 43975.8 | wpb 510.9 | bsz 1 | num_updates 18006 | best_loss 8.725
2022-03-07 03:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18006 updates
2022-03-07 03:36:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 370 @ 18006 updates, score 13.384) (writing took 1.7830051351338625 seconds)
2022-03-07 03:36:07 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 03:36:07 | INFO | train | epoch 370 | loss 1.724 | nll_loss 0.326 | ppl 1.25 | wps 25076.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18006 | lr 0.000235663 | gnorm 0.44 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46825
2022-03-07 03:36:07 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 03:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:37:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:38:11 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.324 | nll_loss 12.829 | ppl 7274.26 | wps 43806.9 | wpb 510.9 | bsz 1 | num_updates 18054 | best_loss 8.725
2022-03-07 03:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18054 updates
2022-03-07 03:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 371 @ 18054 updates, score 13.324) (writing took 1.996929013170302 seconds)
2022-03-07 03:38:13 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 03:38:13 | INFO | train | epoch 371 | loss 1.724 | nll_loss 0.326 | ppl 1.25 | wps 24542.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18054 | lr 0.00023535 | gnorm 0.442 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46952
2022-03-07 03:38:13 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 03:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:40:07 | INFO | train_inner | epoch 372:     46 / 49 loss=1.723, nll_loss=0.326, ppl=1.25, wps=24880, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.442, loss_scale=32, train_wall=224, gb_free=8.8, wall=47065
2022-03-07 03:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:40:18 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.402 | nll_loss 12.909 | ppl 7690.66 | wps 44585 | wpb 510.9 | bsz 1 | num_updates 18103 | best_loss 8.725
2022-03-07 03:40:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18103 updates
2022-03-07 03:40:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:40:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:40:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 372 @ 18103 updates, score 13.402) (writing took 1.7543831719085574 seconds)
2022-03-07 03:40:20 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 03:40:20 | INFO | train | epoch 372 | loss 1.722 | nll_loss 0.325 | ppl 1.25 | wps 25136.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18103 | lr 0.000235031 | gnorm 0.443 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 47078
2022-03-07 03:40:20 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 03:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:42:25 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.303 | nll_loss 12.807 | ppl 7167.33 | wps 44119.6 | wpb 510.9 | bsz 1 | num_updates 18152 | best_loss 8.725
2022-03-07 03:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18152 updates
2022-03-07 03:42:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:42:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 373 @ 18152 updates, score 13.303) (writing took 1.8381925774738193 seconds)
2022-03-07 03:42:27 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 03:42:27 | INFO | train | epoch 373 | loss 1.722 | nll_loss 0.324 | ppl 1.25 | wps 25096.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18152 | lr 0.000234713 | gnorm 0.438 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 47205
2022-03-07 03:42:27 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 03:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:43:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:44:27 | INFO | train_inner | epoch 374:     49 / 49 loss=1.721, nll_loss=0.324, ppl=1.25, wps=24861.6, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=18200, lr=0.000234404, gnorm=0.438, loss_scale=32, train_wall=223, gb_free=8.8, wall=47325
2022-03-07 03:44:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:44:32 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.472 | nll_loss 12.988 | ppl 8122.84 | wps 44524.4 | wpb 510.9 | bsz 1 | num_updates 18200 | best_loss 8.725
2022-03-07 03:44:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18200 updates
2022-03-07 03:44:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:44:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 374 @ 18200 updates, score 13.472) (writing took 1.890904886648059 seconds)
2022-03-07 03:44:33 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 03:44:33 | INFO | train | epoch 374 | loss 1.721 | nll_loss 0.323 | ppl 1.25 | wps 24527.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18200 | lr 0.000234404 | gnorm 0.435 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47332
2022-03-07 03:44:33 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 03:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:46:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:46:38 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.322 | nll_loss 12.831 | ppl 7287.62 | wps 44343.3 | wpb 510.9 | bsz 1 | num_updates 18249 | best_loss 8.725
2022-03-07 03:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18249 updates
2022-03-07 03:46:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:46:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 375 @ 18249 updates, score 13.322) (writing took 1.9157439675182104 seconds)
2022-03-07 03:46:40 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 03:46:40 | INFO | train | epoch 375 | loss 1.72 | nll_loss 0.323 | ppl 1.25 | wps 25117.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18249 | lr 0.000234089 | gnorm 0.433 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 47458
2022-03-07 03:46:40 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 03:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:44 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.445 | nll_loss 12.955 | ppl 7939.27 | wps 44337.4 | wpb 510.9 | bsz 1 | num_updates 18298 | best_loss 8.725
2022-03-07 03:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18298 updates
2022-03-07 03:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 376 @ 18298 updates, score 13.445) (writing took 1.8498076647520065 seconds)
2022-03-07 03:48:46 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 03:48:46 | INFO | train | epoch 376 | loss 1.719 | nll_loss 0.322 | ppl 1.25 | wps 25163.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18298 | lr 0.000233775 | gnorm 0.435 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 47584
2022-03-07 03:48:46 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 03:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:48:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:48:54 | INFO | train_inner | epoch 377:      3 / 49 loss=1.719, nll_loss=0.322, ppl=1.25, wps=24282.1, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.434, loss_scale=32, train_wall=223, gb_free=8.8, wall=47592
2022-03-07 03:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:50:51 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.386 | nll_loss 12.893 | ppl 7604.58 | wps 42963.1 | wpb 510.9 | bsz 1 | num_updates 18346 | best_loss 8.725
2022-03-07 03:50:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18346 updates
2022-03-07 03:50:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:50:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:50:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 377 @ 18346 updates, score 13.386) (writing took 1.8189863301813602 seconds)
2022-03-07 03:50:53 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 03:50:53 | INFO | train | epoch 377 | loss 1.718 | nll_loss 0.321 | ppl 1.25 | wps 24552.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18346 | lr 0.000233469 | gnorm 0.433 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 47711
2022-03-07 03:50:53 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 03:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:52:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:58 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.488 | nll_loss 13.004 | ppl 8214.43 | wps 43962.1 | wpb 510.9 | bsz 1 | num_updates 18395 | best_loss 8.725
2022-03-07 03:52:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18395 updates
2022-03-07 03:52:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:53:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 378 @ 18395 updates, score 13.488) (writing took 1.9324932470917702 seconds)
2022-03-07 03:53:00 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 03:53:00 | INFO | train | epoch 378 | loss 1.718 | nll_loss 0.321 | ppl 1.25 | wps 25023.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18395 | lr 0.000233158 | gnorm 0.437 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47838
2022-03-07 03:53:00 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 03:53:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:53:13 | INFO | train_inner | epoch 379:      5 / 49 loss=1.718, nll_loss=0.321, ppl=1.25, wps=25071.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.436, loss_scale=32, train_wall=222, gb_free=8.8, wall=47851
2022-03-07 03:54:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:55:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:55:05 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.331 | nll_loss 12.833 | ppl 7297.02 | wps 44054.9 | wpb 510.9 | bsz 1 | num_updates 18443 | best_loss 8.725
2022-03-07 03:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18443 updates
2022-03-07 03:55:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:55:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 379 @ 18443 updates, score 13.331) (writing took 1.760574926622212 seconds)
2022-03-07 03:55:07 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 03:55:07 | INFO | train | epoch 379 | loss 1.718 | nll_loss 0.321 | ppl 1.25 | wps 24568.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18443 | lr 0.000232854 | gnorm 0.434 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47965
2022-03-07 03:55:07 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 03:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:12 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.446 | nll_loss 12.957 | ppl 7953.19 | wps 43947.1 | wpb 510.9 | bsz 1 | num_updates 18492 | best_loss 8.725
2022-03-07 03:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18492 updates
2022-03-07 03:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 380 @ 18492 updates, score 13.446) (writing took 1.8308133678510785 seconds)
2022-03-07 03:57:14 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 03:57:14 | INFO | train | epoch 380 | loss 1.717 | nll_loss 0.32 | ppl 1.25 | wps 25066.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18492 | lr 0.000232546 | gnorm 0.442 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48092
2022-03-07 03:57:14 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 03:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:57:33 | INFO | train_inner | epoch 381:      8 / 49 loss=1.717, nll_loss=0.32, ppl=1.25, wps=24862.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.437, loss_scale=32, train_wall=224, gb_free=8.8, wall=48112
2022-03-07 03:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:59:19 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.404 | nll_loss 12.914 | ppl 7719.28 | wps 43742.7 | wpb 510.9 | bsz 1 | num_updates 18541 | best_loss 8.725
2022-03-07 03:59:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18541 updates
2022-03-07 03:59:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 381 @ 18541 updates, score 13.404) (writing took 1.8131447155028582 seconds)
2022-03-07 03:59:20 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 03:59:20 | INFO | train | epoch 381 | loss 1.716 | nll_loss 0.319 | ppl 1.25 | wps 25054 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18541 | lr 0.000232238 | gnorm 0.432 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48219
2022-03-07 03:59:20 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 03:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:00:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:01:25 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.383 | nll_loss 12.892 | ppl 7600.52 | wps 44324 | wpb 510.9 | bsz 1 | num_updates 18589 | best_loss 8.725
2022-03-07 04:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18589 updates
2022-03-07 04:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 382 @ 18589 updates, score 13.383) (writing took 1.8749683694913983 seconds)
2022-03-07 04:01:27 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 04:01:27 | INFO | train | epoch 382 | loss 1.716 | nll_loss 0.32 | ppl 1.25 | wps 24557.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18589 | lr 0.000231938 | gnorm 0.439 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48345
2022-03-07 04:01:27 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 04:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:54 | INFO | train_inner | epoch 383:     11 / 49 loss=1.715, nll_loss=0.319, ppl=1.25, wps=24862.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.434, loss_scale=32, train_wall=224, gb_free=8.8, wall=48373
2022-03-07 04:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:03:32 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.404 | nll_loss 12.918 | ppl 7736.77 | wps 44187.8 | wpb 510.9 | bsz 1 | num_updates 18638 | best_loss 8.725
2022-03-07 04:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18638 updates
2022-03-07 04:03:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:03:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:03:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 383 @ 18638 updates, score 13.404) (writing took 1.7374582840129733 seconds)
2022-03-07 04:03:34 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 04:03:34 | INFO | train | epoch 383 | loss 1.714 | nll_loss 0.318 | ppl 1.25 | wps 25048.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18638 | lr 0.000231633 | gnorm 0.428 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48472
2022-03-07 04:03:34 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 04:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:05:39 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.36 | nll_loss 12.87 | ppl 7488.51 | wps 43946.1 | wpb 510.9 | bsz 1 | num_updates 18687 | best_loss 8.725
2022-03-07 04:05:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18687 updates
2022-03-07 04:05:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:05:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 384 @ 18687 updates, score 13.36) (writing took 1.777601309120655 seconds)
2022-03-07 04:05:41 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 04:05:41 | INFO | train | epoch 384 | loss 1.714 | nll_loss 0.319 | ppl 1.25 | wps 25097.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18687 | lr 0.000231329 | gnorm 0.428 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 48599
2022-03-07 04:05:41 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 04:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:06:15 | INFO | train_inner | epoch 385:     14 / 49 loss=1.714, nll_loss=0.318, ppl=1.25, wps=24866.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.431, loss_scale=32, train_wall=224, gb_free=8.8, wall=48633
2022-03-07 04:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:07:45 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.375 | nll_loss 12.884 | ppl 7559.92 | wps 44198.4 | wpb 510.9 | bsz 1 | num_updates 18735 | best_loss 8.725
2022-03-07 04:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18735 updates
2022-03-07 04:07:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:07:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 385 @ 18735 updates, score 13.375) (writing took 1.9975209292024374 seconds)
2022-03-07 04:07:47 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 04:07:47 | INFO | train | epoch 385 | loss 1.712 | nll_loss 0.317 | ppl 1.25 | wps 24551.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18735 | lr 0.000231033 | gnorm 0.435 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 48726
2022-03-07 04:07:47 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 04:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:09:52 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.366 | nll_loss 12.876 | ppl 7518.12 | wps 44437.4 | wpb 510.9 | bsz 1 | num_updates 18784 | best_loss 8.725
2022-03-07 04:09:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18784 updates
2022-03-07 04:09:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 386 @ 18784 updates, score 13.366) (writing took 1.714325557462871 seconds)
2022-03-07 04:09:54 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 04:09:54 | INFO | train | epoch 386 | loss 1.713 | nll_loss 0.317 | ppl 1.25 | wps 25126 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18784 | lr 0.000230731 | gnorm 0.428 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 48852
2022-03-07 04:09:54 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 04:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:10:33 | INFO | train_inner | epoch 387:     16 / 49 loss=1.713, nll_loss=0.317, ppl=1.25, wps=25132.2, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.43, loss_scale=32, train_wall=221, gb_free=8.8, wall=48892
2022-03-07 04:11:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:11:59 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.376 | nll_loss 12.888 | ppl 7579.05 | wps 43863.7 | wpb 510.9 | bsz 1 | num_updates 18832 | best_loss 8.725
2022-03-07 04:11:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18832 updates
2022-03-07 04:11:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:12:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:12:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 387 @ 18832 updates, score 13.376) (writing took 2.207472109235823 seconds)
2022-03-07 04:12:01 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 04:12:01 | INFO | train | epoch 387 | loss 1.712 | nll_loss 0.317 | ppl 1.25 | wps 24510.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18832 | lr 0.000230437 | gnorm 0.429 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 48979
2022-03-07 04:12:01 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 04:12:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:14:06 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.406 | nll_loss 12.92 | ppl 7747.86 | wps 44101.4 | wpb 510.9 | bsz 1 | num_updates 18881 | best_loss 8.725
2022-03-07 04:14:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18881 updates
2022-03-07 04:14:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:14:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:14:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 388 @ 18881 updates, score 13.406) (writing took 1.982304623350501 seconds)
2022-03-07 04:14:08 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 04:14:08 | INFO | train | epoch 388 | loss 1.712 | nll_loss 0.317 | ppl 1.25 | wps 25079 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18881 | lr 0.000230138 | gnorm 0.426 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49106
2022-03-07 04:14:08 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 04:14:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:55 | INFO | train_inner | epoch 389:     19 / 49 loss=1.712, nll_loss=0.317, ppl=1.25, wps=24837.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.429, loss_scale=32, train_wall=224, gb_free=8.8, wall=49153
2022-03-07 04:16:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:16:12 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.425 | nll_loss 12.938 | ppl 7847.02 | wps 44398.6 | wpb 510.9 | bsz 1 | num_updates 18930 | best_loss 8.725
2022-03-07 04:16:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18930 updates
2022-03-07 04:16:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:16:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:16:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 389 @ 18930 updates, score 13.425) (writing took 1.8394509106874466 seconds)
2022-03-07 04:16:14 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 04:16:14 | INFO | train | epoch 389 | loss 1.712 | nll_loss 0.317 | ppl 1.25 | wps 25120.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18930 | lr 0.00022984 | gnorm 0.439 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49232
2022-03-07 04:16:14 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 04:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:18:19 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.373 | nll_loss 12.881 | ppl 7542.77 | wps 44814.5 | wpb 510.9 | bsz 1 | num_updates 18978 | best_loss 8.725
2022-03-07 04:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18978 updates
2022-03-07 04:18:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:18:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:18:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 390 @ 18978 updates, score 13.373) (writing took 1.9575735544785857 seconds)
2022-03-07 04:18:20 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 04:18:20 | INFO | train | epoch 390 | loss 1.71 | nll_loss 0.315 | ppl 1.24 | wps 24624.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 18978 | lr 0.000229549 | gnorm 0.43 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49359
2022-03-07 04:18:21 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 04:18:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:19:15 | INFO | train_inner | epoch 391:     22 / 49 loss=1.711, nll_loss=0.316, ppl=1.24, wps=24930.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.433, loss_scale=32, train_wall=223, gb_free=8.8, wall=49413
2022-03-07 04:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:20:25 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.434 | nll_loss 12.949 | ppl 7907.23 | wps 44184.9 | wpb 510.9 | bsz 1 | num_updates 19027 | best_loss 8.725
2022-03-07 04:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19027 updates
2022-03-07 04:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 391 @ 19027 updates, score 13.434) (writing took 1.7424801429733634 seconds)
2022-03-07 04:20:27 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 04:20:27 | INFO | train | epoch 391 | loss 1.71 | nll_loss 0.315 | ppl 1.24 | wps 25177.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19027 | lr 0.000229253 | gnorm 0.43 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49485
2022-03-07 04:20:27 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 04:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:22:31 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.392 | nll_loss 12.905 | ppl 7669.53 | wps 44598 | wpb 510.9 | bsz 1 | num_updates 19076 | best_loss 8.725
2022-03-07 04:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19076 updates
2022-03-07 04:22:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:22:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 392 @ 19076 updates, score 13.392) (writing took 1.7645839666947722 seconds)
2022-03-07 04:22:33 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 04:22:33 | INFO | train | epoch 392 | loss 1.709 | nll_loss 0.314 | ppl 1.24 | wps 25160.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19076 | lr 0.000228958 | gnorm 0.422 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49611
2022-03-07 04:22:33 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 04:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:23:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:23:35 | INFO | train_inner | epoch 393:     25 / 49 loss=1.709, nll_loss=0.314, ppl=1.24, wps=24962.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.424, loss_scale=32, train_wall=223, gb_free=8.8, wall=49673
2022-03-07 04:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:24:37 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.345 | nll_loss 12.854 | ppl 7405.51 | wps 44244.2 | wpb 510.9 | bsz 1 | num_updates 19124 | best_loss 8.725
2022-03-07 04:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19124 updates
2022-03-07 04:24:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 393 @ 19124 updates, score 13.345) (writing took 1.754566814750433 seconds)
2022-03-07 04:24:39 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 04:24:39 | INFO | train | epoch 393 | loss 1.708 | nll_loss 0.314 | ppl 1.24 | wps 24660 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19124 | lr 0.000228671 | gnorm 0.428 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49737
2022-03-07 04:24:39 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 04:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:26:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:44 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.414 | nll_loss 12.932 | ppl 7816.29 | wps 44431.2 | wpb 510.9 | bsz 1 | num_updates 19173 | best_loss 8.725
2022-03-07 04:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19173 updates
2022-03-07 04:26:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 394 @ 19173 updates, score 13.414) (writing took 1.8553993292152882 seconds)
2022-03-07 04:26:46 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 04:26:46 | INFO | train | epoch 394 | loss 1.709 | nll_loss 0.315 | ppl 1.24 | wps 25154 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19173 | lr 0.000228378 | gnorm 0.437 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 49864
2022-03-07 04:26:46 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 04:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:52 | INFO | train_inner | epoch 395:     27 / 49 loss=1.709, nll_loss=0.315, ppl=1.24, wps=25184.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.435, loss_scale=32, train_wall=221, gb_free=8.8, wall=49930
2022-03-07 04:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:28:50 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.36 | nll_loss 12.869 | ppl 7482.05 | wps 44160.2 | wpb 510.9 | bsz 1 | num_updates 19222 | best_loss 8.725
2022-03-07 04:28:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19222 updates
2022-03-07 04:28:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 395 @ 19222 updates, score 13.36) (writing took 1.7845681300386786 seconds)
2022-03-07 04:28:52 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 04:28:52 | INFO | train | epoch 395 | loss 1.708 | nll_loss 0.314 | ppl 1.24 | wps 25152.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19222 | lr 0.000228087 | gnorm 0.431 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 49990
2022-03-07 04:28:52 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 04:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:28:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:30:57 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.401 | nll_loss 12.917 | ppl 7732.48 | wps 44585.5 | wpb 510.9 | bsz 1 | num_updates 19270 | best_loss 8.725
2022-03-07 04:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19270 updates
2022-03-07 04:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:30:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 396 @ 19270 updates, score 13.401) (writing took 1.7187712145969272 seconds)
2022-03-07 04:30:58 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 04:30:58 | INFO | train | epoch 396 | loss 1.706 | nll_loss 0.312 | ppl 1.24 | wps 24621.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19270 | lr 0.000227803 | gnorm 0.422 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 50117
2022-03-07 04:30:58 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 04:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:32:12 | INFO | train_inner | epoch 397:     30 / 49 loss=1.706, nll_loss=0.313, ppl=1.24, wps=24932.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.427, loss_scale=32, train_wall=223, gb_free=8.8, wall=50191
2022-03-07 04:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:33:03 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.412 | nll_loss 12.925 | ppl 7776.91 | wps 44428.4 | wpb 510.9 | bsz 1 | num_updates 19319 | best_loss 8.725
2022-03-07 04:33:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19319 updates
2022-03-07 04:33:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:33:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:33:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 397 @ 19319 updates, score 13.412) (writing took 1.7572665233165026 seconds)
2022-03-07 04:33:05 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 04:33:05 | INFO | train | epoch 397 | loss 1.706 | nll_loss 0.312 | ppl 1.24 | wps 25159 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19319 | lr 0.000227514 | gnorm 0.433 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 50243
2022-03-07 04:33:05 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 04:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:34:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:35:09 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.353 | nll_loss 12.864 | ppl 7456.09 | wps 44570.9 | wpb 510.9 | bsz 1 | num_updates 19367 | best_loss 8.725
2022-03-07 04:35:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19367 updates
2022-03-07 04:35:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:35:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:35:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 398 @ 19367 updates, score 13.353) (writing took 1.9595650909468532 seconds)
2022-03-07 04:35:11 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 04:35:11 | INFO | train | epoch 398 | loss 1.705 | nll_loss 0.312 | ppl 1.24 | wps 24612.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19367 | lr 0.000227232 | gnorm 0.431 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 50369
2022-03-07 04:35:11 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 04:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:33 | INFO | train_inner | epoch 399:     33 / 49 loss=1.705, nll_loss=0.312, ppl=1.24, wps=24924.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.427, loss_scale=32, train_wall=223, gb_free=8.8, wall=50451
2022-03-07 04:37:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:37:16 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.359 | nll_loss 12.87 | ppl 7486.17 | wps 42527.3 | wpb 510.9 | bsz 1 | num_updates 19416 | best_loss 8.725
2022-03-07 04:37:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19416 updates
2022-03-07 04:37:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:37:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 399 @ 19416 updates, score 13.359) (writing took 1.7243496486917138 seconds)
2022-03-07 04:37:18 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 04:37:18 | INFO | train | epoch 399 | loss 1.705 | nll_loss 0.312 | ppl 1.24 | wps 25085.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19416 | lr 0.000226945 | gnorm 0.423 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 50496
2022-03-07 04:37:18 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 04:37:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:39:23 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.401 | nll_loss 12.919 | ppl 7744.28 | wps 44195.2 | wpb 510.9 | bsz 1 | num_updates 19465 | best_loss 8.725
2022-03-07 04:39:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19465 updates
2022-03-07 04:39:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:39:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 400 @ 19465 updates, score 13.401) (writing took 1.74773991946131 seconds)
2022-03-07 04:39:25 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 04:39:25 | INFO | train | epoch 400 | loss 1.704 | nll_loss 0.31 | ppl 1.24 | wps 25080.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19465 | lr 0.000226659 | gnorm 0.424 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 50623
2022-03-07 04:39:25 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 04:39:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:40:54 | INFO | train_inner | epoch 401:     36 / 49 loss=1.704, nll_loss=0.311, ppl=1.24, wps=24856.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.423, loss_scale=32, train_wall=224, gb_free=8.8, wall=50712
2022-03-07 04:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:41:29 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.322 | nll_loss 12.83 | ppl 7281 | wps 44341.1 | wpb 510.9 | bsz 1 | num_updates 19513 | best_loss 8.725
2022-03-07 04:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19513 updates
2022-03-07 04:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:41:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 401 @ 19513 updates, score 13.322) (writing took 1.76489179674536 seconds)
2022-03-07 04:41:31 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 04:41:31 | INFO | train | epoch 401 | loss 1.703 | nll_loss 0.31 | ppl 1.24 | wps 24571.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19513 | lr 0.00022638 | gnorm 0.42 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 50749
2022-03-07 04:41:31 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 04:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:43:36 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.324 | nll_loss 12.832 | ppl 7293.05 | wps 44088.9 | wpb 510.9 | bsz 1 | num_updates 19562 | best_loss 8.725
2022-03-07 04:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19562 updates
2022-03-07 04:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:43:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:43:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 402 @ 19562 updates, score 13.324) (writing took 1.9705092692747712 seconds)
2022-03-07 04:43:38 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 04:43:38 | INFO | train | epoch 402 | loss 1.703 | nll_loss 0.31 | ppl 1.24 | wps 25041.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19562 | lr 0.000226096 | gnorm 0.428 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 50876
2022-03-07 04:43:38 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 04:43:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:45:12 | INFO | train_inner | epoch 403:     38 / 49 loss=1.703, nll_loss=0.31, ppl=1.24, wps=25112.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.424, loss_scale=32, train_wall=221, gb_free=8.8, wall=50970
2022-03-07 04:45:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:43 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.359 | nll_loss 12.874 | ppl 7505.25 | wps 44213.4 | wpb 510.9 | bsz 1 | num_updates 19610 | best_loss 8.725
2022-03-07 04:45:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19610 updates
2022-03-07 04:45:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:45:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:45:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 403 @ 19610 updates, score 13.359) (writing took 1.7974426448345184 seconds)
2022-03-07 04:45:45 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 04:45:45 | INFO | train | epoch 403 | loss 1.702 | nll_loss 0.31 | ppl 1.24 | wps 24587.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19610 | lr 0.000225819 | gnorm 0.419 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 51003
2022-03-07 04:45:45 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 04:45:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:47:50 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.401 | nll_loss 12.915 | ppl 7722.81 | wps 44283.9 | wpb 510.9 | bsz 1 | num_updates 19659 | best_loss 8.725
2022-03-07 04:47:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19659 updates
2022-03-07 04:47:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:47:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:47:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 404 @ 19659 updates, score 13.401) (writing took 1.7641417188569903 seconds)
2022-03-07 04:47:51 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 04:47:51 | INFO | train | epoch 404 | loss 1.702 | nll_loss 0.309 | ppl 1.24 | wps 25099.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19659 | lr 0.000225538 | gnorm 0.42 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51130
2022-03-07 04:47:51 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 04:47:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:49:33 | INFO | train_inner | epoch 405:     41 / 49 loss=1.701, nll_loss=0.309, ppl=1.24, wps=24877.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.421, loss_scale=32, train_wall=224, gb_free=8.8, wall=51231
2022-03-07 04:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:49:56 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.384 | nll_loss 12.899 | ppl 7640.42 | wps 43797.3 | wpb 510.9 | bsz 1 | num_updates 19708 | best_loss 8.725
2022-03-07 04:49:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19708 updates
2022-03-07 04:49:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:49:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:49:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 405 @ 19708 updates, score 13.384) (writing took 1.8021269217133522 seconds)
2022-03-07 04:49:58 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 04:49:58 | INFO | train | epoch 405 | loss 1.701 | nll_loss 0.308 | ppl 1.24 | wps 25072.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19708 | lr 0.000225257 | gnorm 0.422 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51256
2022-03-07 04:49:58 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 04:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:52:03 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.395 | nll_loss 12.912 | ppl 7706.74 | wps 44475.3 | wpb 510.9 | bsz 1 | num_updates 19756 | best_loss 8.725
2022-03-07 04:52:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19756 updates
2022-03-07 04:52:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:52:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:52:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 406 @ 19756 updates, score 13.395) (writing took 1.7499186675995588 seconds)
2022-03-07 04:52:05 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 04:52:05 | INFO | train | epoch 406 | loss 1.701 | nll_loss 0.308 | ppl 1.24 | wps 24559.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19756 | lr 0.000224983 | gnorm 0.424 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51383
2022-03-07 04:52:05 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 04:52:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:53:54 | INFO | train_inner | epoch 407:     44 / 49 loss=1.701, nll_loss=0.308, ppl=1.24, wps=24870.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.422, loss_scale=32, train_wall=224, gb_free=8.8, wall=51492
2022-03-07 04:54:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:54:10 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.415 | nll_loss 12.934 | ppl 7826.04 | wps 44213 | wpb 510.9 | bsz 1 | num_updates 19805 | best_loss 8.725
2022-03-07 04:54:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19805 updates
2022-03-07 04:54:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:54:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:54:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 407 @ 19805 updates, score 13.415) (writing took 1.7276683310046792 seconds)
2022-03-07 04:54:11 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 04:54:11 | INFO | train | epoch 407 | loss 1.701 | nll_loss 0.308 | ppl 1.24 | wps 25100.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19805 | lr 0.000224705 | gnorm 0.42 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51510
2022-03-07 04:54:11 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 04:54:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:56:16 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.384 | nll_loss 12.895 | ppl 7619.51 | wps 44116.9 | wpb 510.9 | bsz 1 | num_updates 19854 | best_loss 8.725
2022-03-07 04:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19854 updates
2022-03-07 04:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:56:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 408 @ 19854 updates, score 13.384) (writing took 1.8969675907865167 seconds)
2022-03-07 04:56:18 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 04:56:18 | INFO | train | epoch 408 | loss 1.7 | nll_loss 0.308 | ppl 1.24 | wps 25045 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19854 | lr 0.000224427 | gnorm 0.418 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51637
2022-03-07 04:56:18 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 04:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:56:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:58:15 | INFO | train_inner | epoch 409:     47 / 49 loss=1.7, nll_loss=0.308, ppl=1.24, wps=24857.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.42, loss_scale=32, train_wall=224, gb_free=8.8, wall=51753
2022-03-07 04:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:23 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.46 | nll_loss 12.978 | ppl 8066.49 | wps 44087.3 | wpb 510.9 | bsz 1 | num_updates 19902 | best_loss 8.725
2022-03-07 04:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19902 updates
2022-03-07 04:58:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:58:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:58:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 409 @ 19902 updates, score 13.46) (writing took 1.9987860936671495 seconds)
2022-03-07 04:58:25 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 04:58:25 | INFO | train | epoch 409 | loss 1.699 | nll_loss 0.307 | ppl 1.24 | wps 24517.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19902 | lr 0.000224157 | gnorm 0.423 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51764
2022-03-07 04:58:25 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 04:58:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:30 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.336 | nll_loss 12.85 | ppl 7381.08 | wps 44053.5 | wpb 510.9 | bsz 1 | num_updates 19951 | best_loss 8.725
2022-03-07 05:00:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19951 updates
2022-03-07 05:00:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:00:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 410 @ 19951 updates, score 13.336) (writing took 1.755017795599997 seconds)
2022-03-07 05:00:32 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 05:00:32 | INFO | train | epoch 410 | loss 1.698 | nll_loss 0.306 | ppl 1.24 | wps 25068.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 19951 | lr 0.000223881 | gnorm 0.413 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51890
2022-03-07 05:00:32 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 05:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:32 | INFO | train_inner | epoch 411:     49 / 49 loss=1.698, nll_loss=0.306, ppl=1.24, wps=25080.9, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=20000, lr=0.000223607, gnorm=0.415, loss_scale=64, train_wall=220, gb_free=8.8, wall=52010
2022-03-07 05:02:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:37 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.449 | nll_loss 12.965 | ppl 7994.05 | wps 44477.3 | wpb 510.9 | bsz 1 | num_updates 20000 | best_loss 8.725
2022-03-07 05:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20000 updates
2022-03-07 05:02:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:02:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 411 @ 20000 updates, score 13.449) (writing took 1.7874530302360654 seconds)
2022-03-07 05:02:39 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 05:02:39 | INFO | train | epoch 411 | loss 1.698 | nll_loss 0.306 | ppl 1.24 | wps 25105.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20000 | lr 0.000223607 | gnorm 0.414 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 52017
2022-03-07 05:02:39 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 05:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:43 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.401 | nll_loss 12.916 | ppl 7728.48 | wps 43997.9 | wpb 510.9 | bsz 1 | num_updates 20048 | best_loss 8.725
2022-03-07 05:04:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20048 updates
2022-03-07 05:04:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:04:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:04:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 412 @ 20048 updates, score 13.401) (writing took 2.0710847042500973 seconds)
2022-03-07 05:04:46 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 05:04:46 | INFO | train | epoch 412 | loss 1.698 | nll_loss 0.306 | ppl 1.24 | wps 24524.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20048 | lr 0.000223339 | gnorm 0.42 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52144
2022-03-07 05:04:46 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 05:04:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:06:50 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.395 | nll_loss 12.913 | ppl 7712.59 | wps 44212.8 | wpb 510.9 | bsz 1 | num_updates 20097 | best_loss 8.725
2022-03-07 05:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20097 updates
2022-03-07 05:06:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 413 @ 20097 updates, score 13.395) (writing took 1.9732169434428215 seconds)
2022-03-07 05:06:52 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 05:06:52 | INFO | train | epoch 413 | loss 1.697 | nll_loss 0.306 | ppl 1.24 | wps 25074.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20097 | lr 0.000223067 | gnorm 0.415 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52271
2022-03-07 05:06:52 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 05:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:07:00 | INFO | train_inner | epoch 414:      3 / 49 loss=1.697, nll_loss=0.306, ppl=1.24, wps=24212.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.417, loss_scale=32, train_wall=224, gb_free=8.8, wall=52278
2022-03-07 05:08:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:08:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:08:57 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.384 | nll_loss 12.897 | ppl 7628.49 | wps 44466.7 | wpb 510.9 | bsz 1 | num_updates 20145 | best_loss 8.725
2022-03-07 05:08:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20145 updates
2022-03-07 05:08:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:08:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:08:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 414 @ 20145 updates, score 13.384) (writing took 1.7404359010979533 seconds)
2022-03-07 05:08:59 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 05:08:59 | INFO | train | epoch 414 | loss 1.697 | nll_loss 0.305 | ppl 1.24 | wps 24635.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20145 | lr 0.000222801 | gnorm 0.416 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52397
2022-03-07 05:08:59 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 05:08:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:10:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:11:04 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.469 | nll_loss 12.989 | ppl 8129.22 | wps 44268.3 | wpb 510.9 | bsz 1 | num_updates 20194 | best_loss 8.725
2022-03-07 05:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20194 updates
2022-03-07 05:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 415 @ 20194 updates, score 13.469) (writing took 1.7805349109694362 seconds)
2022-03-07 05:11:05 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 05:11:05 | INFO | train | epoch 415 | loss 1.697 | nll_loss 0.306 | ppl 1.24 | wps 25062.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20194 | lr 0.00022253 | gnorm 0.423 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 52524
2022-03-07 05:11:05 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 05:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:20 | INFO | train_inner | epoch 416:      6 / 49 loss=1.697, nll_loss=0.305, ppl=1.24, wps=24901.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.42, loss_scale=32, train_wall=224, gb_free=8.8, wall=52539
2022-03-07 05:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:13:10 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.401 | nll_loss 12.916 | ppl 7728.4 | wps 44180.3 | wpb 510.9 | bsz 1 | num_updates 20243 | best_loss 8.725
2022-03-07 05:13:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20243 updates
2022-03-07 05:13:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:13:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:13:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 416 @ 20243 updates, score 13.401) (writing took 1.8268632153049111 seconds)
2022-03-07 05:13:12 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 05:13:12 | INFO | train | epoch 416 | loss 1.695 | nll_loss 0.304 | ppl 1.23 | wps 25102.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20243 | lr 0.000222261 | gnorm 0.413 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52650
2022-03-07 05:13:12 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 05:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:13:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:15:17 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.486 | nll_loss 13.005 | ppl 8218 | wps 44610.1 | wpb 510.9 | bsz 1 | num_updates 20291 | best_loss 8.725
2022-03-07 05:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20291 updates
2022-03-07 05:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 417 @ 20291 updates, score 13.486) (writing took 1.8412073608487844 seconds)
2022-03-07 05:15:18 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 05:15:18 | INFO | train | epoch 417 | loss 1.694 | nll_loss 0.303 | ppl 1.23 | wps 24626.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20291 | lr 0.000221998 | gnorm 0.416 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52777
2022-03-07 05:15:18 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 05:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:15:41 | INFO | train_inner | epoch 418:      9 / 49 loss=1.695, nll_loss=0.303, ppl=1.23, wps=24916, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.414, loss_scale=32, train_wall=223, gb_free=8.8, wall=52799
2022-03-07 05:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:17:23 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.413 | nll_loss 12.929 | ppl 7796.92 | wps 44521.3 | wpb 510.9 | bsz 1 | num_updates 20340 | best_loss 8.725
2022-03-07 05:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20340 updates
2022-03-07 05:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 418 @ 20340 updates, score 13.413) (writing took 1.7306700078770518 seconds)
2022-03-07 05:17:25 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 05:17:25 | INFO | train | epoch 418 | loss 1.694 | nll_loss 0.303 | ppl 1.23 | wps 25197 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20340 | lr 0.00022173 | gnorm 0.419 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 52903
2022-03-07 05:17:25 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 05:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:19:29 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.426 | nll_loss 12.942 | ppl 7867.97 | wps 44777.8 | wpb 510.9 | bsz 1 | num_updates 20389 | best_loss 8.725
2022-03-07 05:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20389 updates
2022-03-07 05:19:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:19:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:19:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 419 @ 20389 updates, score 13.426) (writing took 1.7484360598027706 seconds)
2022-03-07 05:19:31 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 05:19:31 | INFO | train | epoch 419 | loss 1.694 | nll_loss 0.303 | ppl 1.23 | wps 25192.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20389 | lr 0.000221463 | gnorm 0.418 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 53029
2022-03-07 05:19:31 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 05:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:19:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:20:00 | INFO | train_inner | epoch 420:     12 / 49 loss=1.694, nll_loss=0.303, ppl=1.23, wps=24988.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.419, loss_scale=32, train_wall=223, gb_free=8.8, wall=53059
2022-03-07 05:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:21:35 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.296 | nll_loss 12.808 | ppl 7170.98 | wps 44537.5 | wpb 510.9 | bsz 1 | num_updates 20437 | best_loss 8.725
2022-03-07 05:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20437 updates
2022-03-07 05:21:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 420 @ 20437 updates, score 13.296) (writing took 1.68180837854743 seconds)
2022-03-07 05:21:37 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 05:21:37 | INFO | train | epoch 420 | loss 1.694 | nll_loss 0.303 | ppl 1.23 | wps 24699.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20437 | lr 0.000221203 | gnorm 0.419 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 53155
2022-03-07 05:21:37 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 05:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:23:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:23:41 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.291 | nll_loss 12.802 | ppl 7141.08 | wps 44267.6 | wpb 510.9 | bsz 1 | num_updates 20486 | best_loss 8.725
2022-03-07 05:23:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20486 updates
2022-03-07 05:23:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:23:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:23:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 421 @ 20486 updates, score 13.291) (writing took 1.6873158402740955 seconds)
2022-03-07 05:23:43 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 05:23:43 | INFO | train | epoch 421 | loss 1.694 | nll_loss 0.303 | ppl 1.23 | wps 25188.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20486 | lr 0.000220939 | gnorm 0.413 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 53281
2022-03-07 05:23:43 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 05:23:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:24:17 | INFO | train_inner | epoch 422:     14 / 49 loss=1.693, nll_loss=0.303, ppl=1.23, wps=25228.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.414, loss_scale=32, train_wall=221, gb_free=8.8, wall=53316
2022-03-07 05:25:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:25:47 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.451 | nll_loss 12.971 | ppl 8026.8 | wps 44127.8 | wpb 510.9 | bsz 1 | num_updates 20534 | best_loss 8.725
2022-03-07 05:25:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20534 updates
2022-03-07 05:25:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:25:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 422 @ 20534 updates, score 13.451) (writing took 2.0863890005275607 seconds)
2022-03-07 05:25:50 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 05:25:50 | INFO | train | epoch 422 | loss 1.692 | nll_loss 0.302 | ppl 1.23 | wps 24576.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20534 | lr 0.00022068 | gnorm 0.414 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 53408
2022-03-07 05:25:50 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 05:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:27:54 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.441 | nll_loss 12.96 | ppl 7970.54 | wps 44840.8 | wpb 510.9 | bsz 1 | num_updates 20583 | best_loss 8.725
2022-03-07 05:27:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20583 updates
2022-03-07 05:27:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:27:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:27:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 423 @ 20583 updates, score 13.441) (writing took 1.7575458530336618 seconds)
2022-03-07 05:27:56 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 05:27:56 | INFO | train | epoch 423 | loss 1.692 | nll_loss 0.302 | ppl 1.23 | wps 25131.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20583 | lr 0.000220417 | gnorm 0.419 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 53534
2022-03-07 05:27:56 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 05:27:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:38 | INFO | train_inner | epoch 424:     17 / 49 loss=1.692, nll_loss=0.302, ppl=1.23, wps=24900.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.416, loss_scale=32, train_wall=223, gb_free=8.8, wall=53576
2022-03-07 05:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:30:01 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.413 | nll_loss 12.933 | ppl 7818.18 | wps 44697.1 | wpb 510.9 | bsz 1 | num_updates 20632 | best_loss 8.725
2022-03-07 05:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20632 updates
2022-03-07 05:30:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:30:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:30:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 424 @ 20632 updates, score 13.413) (writing took 1.9461278282105923 seconds)
2022-03-07 05:30:03 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 05:30:03 | INFO | train | epoch 424 | loss 1.692 | nll_loss 0.302 | ppl 1.23 | wps 25095.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20632 | lr 0.000220155 | gnorm 0.42 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 53661
2022-03-07 05:30:03 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 05:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:32:07 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.419 | nll_loss 12.933 | ppl 7820.37 | wps 44347.3 | wpb 510.9 | bsz 1 | num_updates 20681 | best_loss 8.725
2022-03-07 05:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20681 updates
2022-03-07 05:32:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 425 @ 20681 updates, score 13.419) (writing took 1.912172288633883 seconds)
2022-03-07 05:32:09 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 05:32:09 | INFO | train | epoch 425 | loss 1.69 | nll_loss 0.3 | ppl 1.23 | wps 25099.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20681 | lr 0.000219894 | gnorm 0.41 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 53787
2022-03-07 05:32:09 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 05:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:32:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:32:59 | INFO | train_inner | epoch 426:     20 / 49 loss=1.691, nll_loss=0.301, ppl=1.23, wps=24889.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.416, loss_scale=32, train_wall=224, gb_free=8.8, wall=53837
2022-03-07 05:34:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:34:14 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.431 | nll_loss 12.951 | ppl 7918.54 | wps 44038.5 | wpb 510.9 | bsz 1 | num_updates 20729 | best_loss 8.725
2022-03-07 05:34:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20729 updates
2022-03-07 05:34:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:34:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 426 @ 20729 updates, score 13.431) (writing took 1.7861855886876583 seconds)
2022-03-07 05:34:16 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 05:34:16 | INFO | train | epoch 426 | loss 1.69 | nll_loss 0.3 | ppl 1.23 | wps 24612 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 20729 | lr 0.00021964 | gnorm 0.413 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 53914
2022-03-07 05:34:16 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 05:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:21 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.446 | nll_loss 12.965 | ppl 7995.71 | wps 43700.7 | wpb 510.9 | bsz 1 | num_updates 20778 | best_loss 8.725
2022-03-07 05:36:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20778 updates
2022-03-07 05:36:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:36:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:36:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 427 @ 20778 updates, score 13.446) (writing took 1.9270088346675038 seconds)
2022-03-07 05:36:22 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 05:36:22 | INFO | train | epoch 427 | loss 1.689 | nll_loss 0.3 | ppl 1.23 | wps 25077.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20778 | lr 0.000219381 | gnorm 0.408 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 54041
2022-03-07 05:36:22 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 05:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:17 | INFO | train_inner | epoch 428:     22 / 49 loss=1.69, nll_loss=0.3, ppl=1.23, wps=25117.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.412, loss_scale=32, train_wall=221, gb_free=8.8, wall=54095
2022-03-07 05:37:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:38:27 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.378 | nll_loss 12.9 | ppl 7645.36 | wps 44338.6 | wpb 510.9 | bsz 1 | num_updates 20826 | best_loss 8.725
2022-03-07 05:38:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20826 updates
2022-03-07 05:38:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:38:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:38:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 428 @ 20826 updates, score 13.378) (writing took 1.8167116297408938 seconds)
2022-03-07 05:38:29 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 05:38:29 | INFO | train | epoch 428 | loss 1.69 | nll_loss 0.3 | ppl 1.23 | wps 24577.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20826 | lr 0.000219128 | gnorm 0.423 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 54167
2022-03-07 05:38:29 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 05:38:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:40:34 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.43 | nll_loss 12.949 | ppl 7905.04 | wps 44121.6 | wpb 510.9 | bsz 1 | num_updates 20875 | best_loss 8.725
2022-03-07 05:40:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20875 updates
2022-03-07 05:40:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:40:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:40:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 429 @ 20875 updates, score 13.43) (writing took 1.7696607541292906 seconds)
2022-03-07 05:40:36 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 05:40:36 | INFO | train | epoch 429 | loss 1.69 | nll_loss 0.3 | ppl 1.23 | wps 25045.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20875 | lr 0.00021887 | gnorm 0.416 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 54294
2022-03-07 05:40:36 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 05:40:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:41:38 | INFO | train_inner | epoch 430:     25 / 49 loss=1.69, nll_loss=0.3, ppl=1.23, wps=24857.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.416, loss_scale=32, train_wall=224, gb_free=8.8, wall=54356
2022-03-07 05:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:42:41 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.336 | nll_loss 12.853 | ppl 7397.76 | wps 43847.8 | wpb 510.9 | bsz 1 | num_updates 20924 | best_loss 8.725
2022-03-07 05:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20924 updates
2022-03-07 05:42:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:42:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 430 @ 20924 updates, score 13.336) (writing took 1.9081468852236867 seconds)
2022-03-07 05:42:43 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 05:42:43 | INFO | train | epoch 430 | loss 1.688 | nll_loss 0.299 | ppl 1.23 | wps 25035.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20924 | lr 0.000218614 | gnorm 0.41 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 54421
2022-03-07 05:42:43 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 05:42:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:44:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:44:48 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.442 | nll_loss 12.962 | ppl 7976.52 | wps 43567.5 | wpb 510.9 | bsz 1 | num_updates 20972 | best_loss 8.725
2022-03-07 05:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20972 updates
2022-03-07 05:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 431 @ 20972 updates, score 13.442) (writing took 1.858264520764351 seconds)
2022-03-07 05:44:50 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 05:44:50 | INFO | train | epoch 431 | loss 1.687 | nll_loss 0.298 | ppl 1.23 | wps 24518.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20972 | lr 0.000218364 | gnorm 0.407 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 54548
2022-03-07 05:44:50 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 05:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:45:59 | INFO | train_inner | epoch 432:     28 / 49 loss=1.687, nll_loss=0.298, ppl=1.23, wps=24829.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.41, loss_scale=32, train_wall=224, gb_free=8.8, wall=54617
2022-03-07 05:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:46:55 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.425 | nll_loss 12.95 | ppl 7910.3 | wps 44082.8 | wpb 510.9 | bsz 1 | num_updates 21021 | best_loss 8.725
2022-03-07 05:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21021 updates
2022-03-07 05:46:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 432 @ 21021 updates, score 13.425) (writing took 1.7262276550754905 seconds)
2022-03-07 05:46:57 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 05:46:57 | INFO | train | epoch 432 | loss 1.687 | nll_loss 0.298 | ppl 1.23 | wps 25104.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21021 | lr 0.000218109 | gnorm 0.412 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 54675
2022-03-07 05:46:57 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 05:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:49:01 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.4 | nll_loss 12.921 | ppl 7753.21 | wps 43766.6 | wpb 510.9 | bsz 1 | num_updates 21070 | best_loss 8.725
2022-03-07 05:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21070 updates
2022-03-07 05:49:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:49:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:49:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 433 @ 21070 updates, score 13.4) (writing took 2.239286223426461 seconds)
2022-03-07 05:49:04 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 05:49:04 | INFO | train | epoch 433 | loss 1.686 | nll_loss 0.297 | ppl 1.23 | wps 24977.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21070 | lr 0.000217855 | gnorm 0.406 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 54802
2022-03-07 05:49:04 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 05:49:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:50:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:50:20 | INFO | train_inner | epoch 434:     31 / 49 loss=1.687, nll_loss=0.297, ppl=1.23, wps=24820.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.407, loss_scale=32, train_wall=224, gb_free=8.8, wall=54879
2022-03-07 05:51:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:51:09 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.412 | nll_loss 12.933 | ppl 7817.85 | wps 43932.4 | wpb 510.9 | bsz 1 | num_updates 21118 | best_loss 8.725
2022-03-07 05:51:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21118 updates
2022-03-07 05:51:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:51:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:51:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 434 @ 21118 updates, score 13.412) (writing took 1.7429263470694423 seconds)
2022-03-07 05:51:10 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 05:51:10 | INFO | train | epoch 434 | loss 1.687 | nll_loss 0.298 | ppl 1.23 | wps 24560.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21118 | lr 0.000217607 | gnorm 0.412 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 54929
2022-03-07 05:51:10 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 05:51:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:53:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:53:15 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.438 | nll_loss 12.962 | ppl 7976.79 | wps 43990.8 | wpb 510.9 | bsz 1 | num_updates 21167 | best_loss 8.725
2022-03-07 05:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21167 updates
2022-03-07 05:53:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:53:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 435 @ 21167 updates, score 13.438) (writing took 1.733408753760159 seconds)
2022-03-07 05:53:17 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 05:53:17 | INFO | train | epoch 435 | loss 1.686 | nll_loss 0.297 | ppl 1.23 | wps 25091.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21167 | lr 0.000217355 | gnorm 0.412 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 55055
2022-03-07 05:53:17 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 05:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:54:39 | INFO | train_inner | epoch 436:     33 / 49 loss=1.686, nll_loss=0.297, ppl=1.23, wps=25121.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.409, loss_scale=32, train_wall=222, gb_free=8.8, wall=55137
2022-03-07 05:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:55:22 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.358 | nll_loss 12.878 | ppl 7528.74 | wps 43661.9 | wpb 510.9 | bsz 1 | num_updates 21216 | best_loss 8.725
2022-03-07 05:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21216 updates
2022-03-07 05:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:55:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 436 @ 21216 updates, score 13.358) (writing took 1.820099774748087 seconds)
2022-03-07 05:55:24 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 05:55:24 | INFO | train | epoch 436 | loss 1.684 | nll_loss 0.295 | ppl 1.23 | wps 25068.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21216 | lr 0.000217104 | gnorm 0.402 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 55182
2022-03-07 05:55:24 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 05:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:56:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:57:29 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.42 | nll_loss 12.938 | ppl 7845.85 | wps 44118.5 | wpb 510.9 | bsz 1 | num_updates 21264 | best_loss 8.725
2022-03-07 05:57:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21264 updates
2022-03-07 05:57:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:57:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:57:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 437 @ 21264 updates, score 13.42) (writing took 1.9813375817611814 seconds)
2022-03-07 05:57:31 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 05:57:31 | INFO | train | epoch 437 | loss 1.686 | nll_loss 0.297 | ppl 1.23 | wps 24557.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21264 | lr 0.000216859 | gnorm 0.414 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 55309
2022-03-07 05:57:31 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 05:57:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:59:00 | INFO | train_inner | epoch 438:     36 / 49 loss=1.685, nll_loss=0.296, ppl=1.23, wps=24854.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.408, loss_scale=32, train_wall=224, gb_free=8.8, wall=55398
2022-03-07 05:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:59:36 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.416 | nll_loss 12.936 | ppl 7835.27 | wps 44091.1 | wpb 510.9 | bsz 1 | num_updates 21313 | best_loss 8.725
2022-03-07 05:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21313 updates
2022-03-07 05:59:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:59:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:59:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 438 @ 21313 updates, score 13.416) (writing took 1.7812592945992947 seconds)
2022-03-07 05:59:37 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 05:59:37 | INFO | train | epoch 438 | loss 1.684 | nll_loss 0.296 | ppl 1.23 | wps 25065.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21313 | lr 0.00021661 | gnorm 0.405 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 55436
2022-03-07 05:59:37 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 05:59:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:01:42 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.426 | nll_loss 12.945 | ppl 7883.15 | wps 44288.5 | wpb 510.9 | bsz 1 | num_updates 21362 | best_loss 8.725
2022-03-07 06:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21362 updates
2022-03-07 06:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 439 @ 21362 updates, score 13.426) (writing took 1.8895101603120565 seconds)
2022-03-07 06:01:44 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 06:01:44 | INFO | train | epoch 439 | loss 1.684 | nll_loss 0.296 | ppl 1.23 | wps 25082.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21362 | lr 0.000216361 | gnorm 0.411 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 55562
2022-03-07 06:01:44 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 06:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:01:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:03:20 | INFO | train_inner | epoch 440:     39 / 49 loss=1.684, nll_loss=0.296, ppl=1.23, wps=24879.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.413, loss_scale=32, train_wall=224, gb_free=8.8, wall=55659
2022-03-07 06:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:03:49 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.403 | nll_loss 12.923 | ppl 7765.36 | wps 44352.7 | wpb 510.9 | bsz 1 | num_updates 21410 | best_loss 8.725
2022-03-07 06:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21410 updates
2022-03-07 06:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 440 @ 21410 updates, score 13.403) (writing took 1.910163032822311 seconds)
2022-03-07 06:03:51 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 06:03:51 | INFO | train | epoch 440 | loss 1.684 | nll_loss 0.296 | ppl 1.23 | wps 24573.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21410 | lr 0.000216118 | gnorm 0.414 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 55689
2022-03-07 06:03:51 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 06:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:05:56 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.43 | nll_loss 12.946 | ppl 7892.42 | wps 43854.5 | wpb 510.9 | bsz 1 | num_updates 21459 | best_loss 8.725
2022-03-07 06:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21459 updates
2022-03-07 06:05:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:05:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:05:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 441 @ 21459 updates, score 13.43) (writing took 1.9240702940151095 seconds)
2022-03-07 06:05:58 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 06:05:58 | INFO | train | epoch 441 | loss 1.681 | nll_loss 0.293 | ppl 1.23 | wps 25072.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21459 | lr 0.000215871 | gnorm 0.4 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 55816
2022-03-07 06:05:58 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 06:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:07:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:07:41 | INFO | train_inner | epoch 442:     42 / 49 loss=1.682, nll_loss=0.294, ppl=1.23, wps=24876, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.406, loss_scale=32, train_wall=224, gb_free=8.8, wall=55919
2022-03-07 06:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:08:02 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.486 | nll_loss 13.01 | ppl 8246.14 | wps 44126 | wpb 510.9 | bsz 1 | num_updates 21507 | best_loss 8.725
2022-03-07 06:08:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21507 updates
2022-03-07 06:08:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:08:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:08:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 442 @ 21507 updates, score 13.486) (writing took 1.8576048258692026 seconds)
2022-03-07 06:08:04 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 06:08:04 | INFO | train | epoch 442 | loss 1.682 | nll_loss 0.295 | ppl 1.23 | wps 24580.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21507 | lr 0.00021563 | gnorm 0.409 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 55942
2022-03-07 06:08:04 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 06:08:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:10:09 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.365 | nll_loss 12.881 | ppl 7541.66 | wps 44374.5 | wpb 510.9 | bsz 1 | num_updates 21556 | best_loss 8.725
2022-03-07 06:10:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21556 updates
2022-03-07 06:10:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:10:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:10:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 443 @ 21556 updates, score 13.365) (writing took 1.8608605340123177 seconds)
2022-03-07 06:10:11 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 06:10:11 | INFO | train | epoch 443 | loss 1.682 | nll_loss 0.294 | ppl 1.23 | wps 25125.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21556 | lr 0.000215385 | gnorm 0.407 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56069
2022-03-07 06:10:11 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 06:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:11:59 | INFO | train_inner | epoch 444:     44 / 49 loss=1.682, nll_loss=0.294, ppl=1.23, wps=25138.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.409, loss_scale=32, train_wall=221, gb_free=8.8, wall=56178
2022-03-07 06:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:12:15 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.476 | nll_loss 13 | ppl 8192.78 | wps 44727.9 | wpb 510.9 | bsz 1 | num_updates 21605 | best_loss 8.725
2022-03-07 06:12:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21605 updates
2022-03-07 06:12:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:12:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 444 @ 21605 updates, score 13.476) (writing took 1.7943959515541792 seconds)
2022-03-07 06:12:17 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 06:12:17 | INFO | train | epoch 444 | loss 1.682 | nll_loss 0.294 | ppl 1.23 | wps 25135 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21605 | lr 0.000215141 | gnorm 0.414 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56195
2022-03-07 06:12:17 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 06:12:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:13:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:22 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.385 | nll_loss 12.905 | ppl 7670.68 | wps 44659.7 | wpb 510.9 | bsz 1 | num_updates 21653 | best_loss 8.725
2022-03-07 06:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21653 updates
2022-03-07 06:14:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:14:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:14:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 445 @ 21653 updates, score 13.385) (writing took 1.7681719521060586 seconds)
2022-03-07 06:14:23 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 06:14:23 | INFO | train | epoch 445 | loss 1.681 | nll_loss 0.294 | ppl 1.23 | wps 24669.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21653 | lr 0.000214902 | gnorm 0.405 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56321
2022-03-07 06:14:23 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 06:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:16:19 | INFO | train_inner | epoch 446:     47 / 49 loss=1.681, nll_loss=0.294, ppl=1.23, wps=24965.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.408, loss_scale=32, train_wall=223, gb_free=8.8, wall=56437
2022-03-07 06:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:16:28 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.351 | nll_loss 12.871 | ppl 7489.52 | wps 44670.4 | wpb 510.9 | bsz 1 | num_updates 21702 | best_loss 8.725
2022-03-07 06:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21702 updates
2022-03-07 06:16:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:16:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:16:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 446 @ 21702 updates, score 13.351) (writing took 1.7997746169567108 seconds)
2022-03-07 06:16:30 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 06:16:30 | INFO | train | epoch 446 | loss 1.681 | nll_loss 0.293 | ppl 1.23 | wps 25153.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21702 | lr 0.00021466 | gnorm 0.41 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56448
2022-03-07 06:16:30 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 06:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:18:34 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.417 | nll_loss 12.937 | ppl 7839.64 | wps 44067.9 | wpb 510.9 | bsz 1 | num_updates 21751 | best_loss 8.725
2022-03-07 06:18:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21751 updates
2022-03-07 06:18:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:18:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 447 @ 21751 updates, score 13.417) (writing took 1.7800395209342241 seconds)
2022-03-07 06:18:36 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 06:18:36 | INFO | train | epoch 447 | loss 1.68 | nll_loss 0.293 | ppl 1.23 | wps 25142.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21751 | lr 0.000214418 | gnorm 0.406 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56574
2022-03-07 06:18:36 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 06:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:20:41 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.352 | nll_loss 12.868 | ppl 7477.82 | wps 44264 | wpb 510.9 | bsz 1 | num_updates 21799 | best_loss 8.725
2022-03-07 06:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21799 updates
2022-03-07 06:20:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 448 @ 21799 updates, score 13.352) (writing took 1.8552738120779395 seconds)
2022-03-07 06:20:42 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 06:20:42 | INFO | train | epoch 448 | loss 1.679 | nll_loss 0.292 | ppl 1.22 | wps 24633.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21799 | lr 0.000214181 | gnorm 0.402 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56701
2022-03-07 06:20:42 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 06:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:20:45 | INFO | train_inner | epoch 449:      1 / 49 loss=1.68, nll_loss=0.292, ppl=1.22, wps=24285.4, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.406, loss_scale=32, train_wall=222, gb_free=8.8, wall=56703
2022-03-07 06:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:22:47 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.442 | nll_loss 12.962 | ppl 7977.75 | wps 44379.1 | wpb 510.9 | bsz 1 | num_updates 21848 | best_loss 8.725
2022-03-07 06:22:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21848 updates
2022-03-07 06:22:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:22:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:22:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 449 @ 21848 updates, score 13.442) (writing took 1.8159475978463888 seconds)
2022-03-07 06:22:49 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 06:22:49 | INFO | train | epoch 449 | loss 1.679 | nll_loss 0.292 | ppl 1.22 | wps 25130.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21848 | lr 0.000213941 | gnorm 0.404 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56827
2022-03-07 06:22:49 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 06:22:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:24:54 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.355 | nll_loss 12.874 | ppl 7504.71 | wps 44216.3 | wpb 510.9 | bsz 1 | num_updates 21897 | best_loss 8.725
2022-03-07 06:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21897 updates
2022-03-07 06:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:24:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 450 @ 21897 updates, score 13.355) (writing took 1.924435080960393 seconds)
2022-03-07 06:24:56 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 06:24:56 | INFO | train | epoch 450 | loss 1.678 | nll_loss 0.291 | ppl 1.22 | wps 25088.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21897 | lr 0.000213702 | gnorm 0.403 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 56954
2022-03-07 06:24:56 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 06:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:25:03 | INFO | train_inner | epoch 451:      3 / 49 loss=1.679, nll_loss=0.292, ppl=1.22, wps=25138.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.403, loss_scale=32, train_wall=221, gb_free=8.8, wall=56961
2022-03-07 06:25:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:27:00 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.381 | nll_loss 12.901 | ppl 7650.07 | wps 44329.3 | wpb 510.9 | bsz 1 | num_updates 21945 | best_loss 8.725
2022-03-07 06:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21945 updates
2022-03-07 06:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 451 @ 21945 updates, score 13.381) (writing took 1.7037138426676393 seconds)
2022-03-07 06:27:02 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 06:27:02 | INFO | train | epoch 451 | loss 1.679 | nll_loss 0.292 | ppl 1.22 | wps 24648.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21945 | lr 0.000213468 | gnorm 0.408 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 57080
2022-03-07 06:27:02 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 06:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:29:07 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.39 | nll_loss 12.911 | ppl 7701.36 | wps 44561.5 | wpb 510.9 | bsz 1 | num_updates 21994 | best_loss 8.725
2022-03-07 06:29:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21994 updates
2022-03-07 06:29:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:29:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:29:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 452 @ 21994 updates, score 13.39) (writing took 1.7354372879490256 seconds)
2022-03-07 06:29:08 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 06:29:08 | INFO | train | epoch 452 | loss 1.678 | nll_loss 0.292 | ppl 1.22 | wps 25130.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 21994 | lr 0.00021323 | gnorm 0.401 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 57206
2022-03-07 06:29:08 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 06:29:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:29:23 | INFO | train_inner | epoch 453:      6 / 49 loss=1.678, nll_loss=0.291, ppl=1.22, wps=24935, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.404, loss_scale=32, train_wall=223, gb_free=8.8, wall=57221
2022-03-07 06:31:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:31:13 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.432 | nll_loss 12.952 | ppl 7921.52 | wps 44134.1 | wpb 510.9 | bsz 1 | num_updates 22043 | best_loss 8.725
2022-03-07 06:31:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22043 updates
2022-03-07 06:31:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:31:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 453 @ 22043 updates, score 13.432) (writing took 1.7622108487412333 seconds)
2022-03-07 06:31:15 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 06:31:15 | INFO | train | epoch 453 | loss 1.678 | nll_loss 0.291 | ppl 1.22 | wps 25107 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22043 | lr 0.000212993 | gnorm 0.397 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 57333
2022-03-07 06:31:15 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 06:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:32:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:33:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:33:20 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.366 | nll_loss 12.883 | ppl 7552.67 | wps 43940.6 | wpb 510.9 | bsz 1 | num_updates 22091 | best_loss 8.725
2022-03-07 06:33:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22091 updates
2022-03-07 06:33:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 454 @ 22091 updates, score 13.366) (writing took 1.8170693973079324 seconds)
2022-03-07 06:33:22 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 06:33:22 | INFO | train | epoch 454 | loss 1.677 | nll_loss 0.29 | ppl 1.22 | wps 24529.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 22091 | lr 0.000212761 | gnorm 0.399 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 57460
2022-03-07 06:33:22 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 06:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:33:44 | INFO | train_inner | epoch 455:      9 / 49 loss=1.677, nll_loss=0.291, ppl=1.22, wps=24869.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.399, loss_scale=32, train_wall=224, gb_free=8.8, wall=57482
2022-03-07 06:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:35:27 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.346 | nll_loss 12.866 | ppl 7463.91 | wps 43925.2 | wpb 510.9 | bsz 1 | num_updates 22140 | best_loss 8.725
2022-03-07 06:35:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22140 updates
2022-03-07 06:35:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:35:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:35:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 455 @ 22140 updates, score 13.346) (writing took 1.9656622288748622 seconds)
2022-03-07 06:35:29 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 06:35:29 | INFO | train | epoch 455 | loss 1.677 | nll_loss 0.29 | ppl 1.22 | wps 25046.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22140 | lr 0.000212526 | gnorm 0.406 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 57587
2022-03-07 06:35:29 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 06:35:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:37:34 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.543 | nll_loss 13.074 | ppl 8623.58 | wps 43982.9 | wpb 510.9 | bsz 1 | num_updates 22189 | best_loss 8.725
2022-03-07 06:37:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22189 updates
2022-03-07 06:37:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 456 @ 22189 updates, score 13.543) (writing took 1.8766401149332523 seconds)
2022-03-07 06:37:35 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 06:37:35 | INFO | train | epoch 456 | loss 1.677 | nll_loss 0.291 | ppl 1.22 | wps 25065.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22189 | lr 0.000212291 | gnorm 0.399 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 57714
2022-03-07 06:37:35 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 06:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:38:03 | INFO | train_inner | epoch 457:     11 / 49 loss=1.677, nll_loss=0.29, ppl=1.22, wps=25078.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.402, loss_scale=32, train_wall=222, gb_free=8.8, wall=57741
2022-03-07 06:38:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:39:40 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.395 | nll_loss 12.913 | ppl 7712.04 | wps 43978.3 | wpb 510.9 | bsz 1 | num_updates 22237 | best_loss 8.725
2022-03-07 06:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22237 updates
2022-03-07 06:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 457 @ 22237 updates, score 13.395) (writing took 1.9720429107546806 seconds)
2022-03-07 06:39:42 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 06:39:42 | INFO | train | epoch 457 | loss 1.675 | nll_loss 0.289 | ppl 1.22 | wps 24523.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 22237 | lr 0.000212062 | gnorm 0.404 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 57841
2022-03-07 06:39:42 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 06:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:41:48 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.414 | nll_loss 12.933 | ppl 7820.74 | wps 43729.2 | wpb 510.9 | bsz 1 | num_updates 22286 | best_loss 8.725
2022-03-07 06:41:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22286 updates
2022-03-07 06:41:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:41:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 458 @ 22286 updates, score 13.414) (writing took 1.9422745499759912 seconds)
2022-03-07 06:41:49 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 06:41:49 | INFO | train | epoch 458 | loss 1.676 | nll_loss 0.29 | ppl 1.22 | wps 24995.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22286 | lr 0.000211828 | gnorm 0.407 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 57968
2022-03-07 06:41:49 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 06:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:24 | INFO | train_inner | epoch 459:     14 / 49 loss=1.675, nll_loss=0.289, ppl=1.22, wps=24816.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.406, loss_scale=32, train_wall=224, gb_free=8.8, wall=58002
2022-03-07 06:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:43:54 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.37 | nll_loss 12.892 | ppl 7600.57 | wps 43904.8 | wpb 510.9 | bsz 1 | num_updates 22335 | best_loss 8.725
2022-03-07 06:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22335 updates
2022-03-07 06:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:43:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:43:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 459 @ 22335 updates, score 13.37) (writing took 1.7904928708449006 seconds)
2022-03-07 06:43:56 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 06:43:56 | INFO | train | epoch 459 | loss 1.674 | nll_loss 0.288 | ppl 1.22 | wps 25089.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22335 | lr 0.000211596 | gnorm 0.402 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 58094
2022-03-07 06:43:56 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 06:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:44:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:46:01 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.407 | nll_loss 12.929 | ppl 7800.37 | wps 44240.4 | wpb 510.9 | bsz 1 | num_updates 22383 | best_loss 8.725
2022-03-07 06:46:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22383 updates
2022-03-07 06:46:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:46:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:46:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 460 @ 22383 updates, score 13.407) (writing took 1.8026653863489628 seconds)
2022-03-07 06:46:03 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 06:46:03 | INFO | train | epoch 460 | loss 1.674 | nll_loss 0.288 | ppl 1.22 | wps 24549.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 22383 | lr 0.000211369 | gnorm 0.4 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 58221
2022-03-07 06:46:03 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 06:46:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:46:45 | INFO | train_inner | epoch 461:     17 / 49 loss=1.674, nll_loss=0.288, ppl=1.22, wps=24871.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.4, loss_scale=32, train_wall=224, gb_free=8.8, wall=58263
2022-03-07 06:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:48:08 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.384 | nll_loss 12.903 | ppl 7659.48 | wps 44223.3 | wpb 510.9 | bsz 1 | num_updates 22432 | best_loss 8.725
2022-03-07 06:48:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22432 updates
2022-03-07 06:48:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 461 @ 22432 updates, score 13.384) (writing took 1.8292853403836489 seconds)
2022-03-07 06:48:10 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 06:48:10 | INFO | train | epoch 461 | loss 1.674 | nll_loss 0.288 | ppl 1.22 | wps 25065.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22432 | lr 0.000211138 | gnorm 0.402 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 58348
2022-03-07 06:48:10 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 06:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:50:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:50:14 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.383 | nll_loss 12.903 | ppl 7659.01 | wps 43903.3 | wpb 510.9 | bsz 1 | num_updates 22480 | best_loss 8.725
2022-03-07 06:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22480 updates
2022-03-07 06:50:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:50:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 462 @ 22480 updates, score 13.383) (writing took 1.750959400087595 seconds)
2022-03-07 06:50:16 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 06:50:16 | INFO | train | epoch 462 | loss 1.673 | nll_loss 0.288 | ppl 1.22 | wps 24609.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 22480 | lr 0.000210912 | gnorm 0.402 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 58474
2022-03-07 06:50:16 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 06:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:06 | INFO | train_inner | epoch 463:     20 / 49 loss=1.674, nll_loss=0.288, ppl=1.22, wps=24874.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.403, loss_scale=32, train_wall=224, gb_free=8.8, wall=58524
2022-03-07 06:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:52:21 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.45 | nll_loss 12.971 | ppl 8028.79 | wps 44232.9 | wpb 510.9 | bsz 1 | num_updates 22529 | best_loss 8.725
2022-03-07 06:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22529 updates
2022-03-07 06:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:52:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 463 @ 22529 updates, score 13.45) (writing took 1.7968458868563175 seconds)
2022-03-07 06:52:23 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 06:52:23 | INFO | train | epoch 463 | loss 1.674 | nll_loss 0.288 | ppl 1.22 | wps 25084.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22529 | lr 0.000210683 | gnorm 0.404 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 58601
2022-03-07 06:52:23 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 06:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:54:28 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.387 | nll_loss 12.906 | ppl 7676.76 | wps 43930.9 | wpb 510.9 | bsz 1 | num_updates 22578 | best_loss 8.725
2022-03-07 06:54:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22578 updates
2022-03-07 06:54:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:54:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 464 @ 22578 updates, score 13.387) (writing took 1.9356611911207438 seconds)
2022-03-07 06:54:30 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 06:54:30 | INFO | train | epoch 464 | loss 1.672 | nll_loss 0.287 | ppl 1.22 | wps 25021.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22578 | lr 0.000210454 | gnorm 0.401 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 58728
2022-03-07 06:54:30 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 06:54:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:55:24 | INFO | train_inner | epoch 465:     22 / 49 loss=1.672, nll_loss=0.287, ppl=1.22, wps=25083.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.401, loss_scale=32, train_wall=222, gb_free=8.8, wall=58783
2022-03-07 06:56:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:56:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:56:35 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.397 | nll_loss 12.92 | ppl 7749.02 | wps 43580 | wpb 510.9 | bsz 1 | num_updates 22626 | best_loss 8.725
2022-03-07 06:56:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22626 updates
2022-03-07 06:56:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 465 @ 22626 updates, score 13.397) (writing took 1.8141779797151685 seconds)
2022-03-07 06:56:37 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 06:56:37 | INFO | train | epoch 465 | loss 1.672 | nll_loss 0.287 | ppl 1.22 | wps 24553.8 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 22626 | lr 0.000210231 | gnorm 0.4 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 58855
2022-03-07 06:56:37 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 06:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:58:42 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.511 | nll_loss 13.039 | ppl 8419.39 | wps 43673.9 | wpb 510.9 | bsz 1 | num_updates 22675 | best_loss 8.725
2022-03-07 06:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22675 updates
2022-03-07 06:58:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:58:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:58:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 466 @ 22675 updates, score 13.511) (writing took 1.9223529817536473 seconds)
2022-03-07 06:58:43 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 06:58:43 | INFO | train | epoch 466 | loss 1.672 | nll_loss 0.287 | ppl 1.22 | wps 25060.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22675 | lr 0.000210003 | gnorm 0.397 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 58982
2022-03-07 06:58:44 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 06:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:59:45 | INFO | train_inner | epoch 467:     25 / 49 loss=1.672, nll_loss=0.287, ppl=1.22, wps=24867.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.398, loss_scale=32, train_wall=224, gb_free=8.8, wall=59043
2022-03-07 07:00:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:00:48 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.466 | nll_loss 12.99 | ppl 8136.27 | wps 44311.2 | wpb 510.9 | bsz 1 | num_updates 22724 | best_loss 8.725
2022-03-07 07:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22724 updates
2022-03-07 07:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 467 @ 22724 updates, score 13.466) (writing took 1.8313762210309505 seconds)
2022-03-07 07:00:50 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 07:00:50 | INFO | train | epoch 467 | loss 1.671 | nll_loss 0.287 | ppl 1.22 | wps 25133.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22724 | lr 0.000209777 | gnorm 0.397 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59108
2022-03-07 07:00:50 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 07:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:01:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:02:55 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.356 | nll_loss 12.872 | ppl 7496.79 | wps 44413.3 | wpb 510.9 | bsz 1 | num_updates 22772 | best_loss 8.725
2022-03-07 07:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22772 updates
2022-03-07 07:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 468 @ 22772 updates, score 13.356) (writing took 1.7589766709133983 seconds)
2022-03-07 07:02:56 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 07:02:56 | INFO | train | epoch 468 | loss 1.671 | nll_loss 0.286 | ppl 1.22 | wps 24640.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 22772 | lr 0.000209556 | gnorm 0.398 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59234
2022-03-07 07:02:56 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 07:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:04:05 | INFO | train_inner | epoch 469:     28 / 49 loss=1.671, nll_loss=0.286, ppl=1.22, wps=24932.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.398, loss_scale=32, train_wall=223, gb_free=8.8, wall=59304
2022-03-07 07:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:05:01 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.404 | nll_loss 12.923 | ppl 7766.6 | wps 44241.4 | wpb 510.9 | bsz 1 | num_updates 22821 | best_loss 8.725
2022-03-07 07:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22821 updates
2022-03-07 07:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 469 @ 22821 updates, score 13.404) (writing took 1.7387438798323274 seconds)
2022-03-07 07:05:03 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 07:05:03 | INFO | train | epoch 469 | loss 1.671 | nll_loss 0.286 | ppl 1.22 | wps 25121.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22821 | lr 0.000209331 | gnorm 0.394 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59361
2022-03-07 07:05:03 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 07:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:07:08 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.402 | nll_loss 12.926 | ppl 7783.44 | wps 43923.3 | wpb 510.9 | bsz 1 | num_updates 22870 | best_loss 8.725
2022-03-07 07:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22870 updates
2022-03-07 07:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 470 @ 22870 updates, score 13.402) (writing took 1.9224292021244764 seconds)
2022-03-07 07:07:10 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 07:07:10 | INFO | train | epoch 470 | loss 1.671 | nll_loss 0.286 | ppl 1.22 | wps 25008.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22870 | lr 0.000209106 | gnorm 0.403 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 59488
2022-03-07 07:07:10 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 07:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:08:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:08:26 | INFO | train_inner | epoch 471:     31 / 49 loss=1.67, nll_loss=0.285, ppl=1.22, wps=24852.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.395, loss_scale=32, train_wall=224, gb_free=8.8, wall=59565
2022-03-07 07:09:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:09:15 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.44 | nll_loss 12.968 | ppl 8014.43 | wps 44312 | wpb 510.9 | bsz 1 | num_updates 22918 | best_loss 8.725
2022-03-07 07:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22918 updates
2022-03-07 07:09:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 471 @ 22918 updates, score 13.44) (writing took 1.9646687442436814 seconds)
2022-03-07 07:09:17 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 07:09:17 | INFO | train | epoch 471 | loss 1.669 | nll_loss 0.284 | ppl 1.22 | wps 24557.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 22918 | lr 0.000208887 | gnorm 0.391 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59615
2022-03-07 07:09:17 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 07:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:11:21 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.348 | nll_loss 12.868 | ppl 7477.13 | wps 44329.6 | wpb 510.9 | bsz 1 | num_updates 22967 | best_loss 8.725
2022-03-07 07:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22967 updates
2022-03-07 07:11:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:11:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:11:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 472 @ 22967 updates, score 13.348) (writing took 1.9041849300265312 seconds)
2022-03-07 07:11:23 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 07:11:23 | INFO | train | epoch 472 | loss 1.669 | nll_loss 0.285 | ppl 1.22 | wps 25135.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 22967 | lr 0.000208664 | gnorm 0.394 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59741
2022-03-07 07:11:23 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 07:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:12:44 | INFO | train_inner | epoch 473:     33 / 49 loss=1.669, nll_loss=0.285, ppl=1.22, wps=25139, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.394, loss_scale=32, train_wall=221, gb_free=8.8, wall=59823
2022-03-07 07:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:13:28 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.378 | nll_loss 12.898 | ppl 7635.3 | wps 44069.1 | wpb 510.9 | bsz 1 | num_updates 23016 | best_loss 8.725
2022-03-07 07:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23016 updates
2022-03-07 07:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 473 @ 23016 updates, score 13.378) (writing took 1.7658228436484933 seconds)
2022-03-07 07:13:30 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 07:13:30 | INFO | train | epoch 473 | loss 1.669 | nll_loss 0.284 | ppl 1.22 | wps 25126.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23016 | lr 0.000208442 | gnorm 0.392 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 59868
2022-03-07 07:13:30 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 07:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:14:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:15:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:15:34 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.366 | nll_loss 12.886 | ppl 7568.99 | wps 43808.7 | wpb 510.9 | bsz 1 | num_updates 23064 | best_loss 8.725
2022-03-07 07:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23064 updates
2022-03-07 07:15:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:15:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 474 @ 23064 updates, score 13.366) (writing took 1.7602321468293667 seconds)
2022-03-07 07:15:36 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 07:15:36 | INFO | train | epoch 474 | loss 1.669 | nll_loss 0.284 | ppl 1.22 | wps 24562.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23064 | lr 0.000208225 | gnorm 0.395 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 59994
2022-03-07 07:15:36 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 07:15:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:17:05 | INFO | train_inner | epoch 475:     36 / 49 loss=1.669, nll_loss=0.285, ppl=1.22, wps=24877.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.396, loss_scale=32, train_wall=224, gb_free=8.8, wall=60083
2022-03-07 07:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:41 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.469 | nll_loss 12.996 | ppl 8167.19 | wps 44024.9 | wpb 510.9 | bsz 1 | num_updates 23113 | best_loss 8.725
2022-03-07 07:17:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23113 updates
2022-03-07 07:17:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:17:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:17:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 475 @ 23113 updates, score 13.469) (writing took 1.8743928894400597 seconds)
2022-03-07 07:17:43 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 07:17:43 | INFO | train | epoch 475 | loss 1.669 | nll_loss 0.285 | ppl 1.22 | wps 25058.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23113 | lr 0.000208004 | gnorm 0.399 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 60121
2022-03-07 07:17:43 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 07:17:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:48 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.383 | nll_loss 12.907 | ppl 7678.13 | wps 43575.8 | wpb 510.9 | bsz 1 | num_updates 23162 | best_loss 8.725
2022-03-07 07:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23162 updates
2022-03-07 07:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 476 @ 23162 updates, score 13.383) (writing took 2.002174010500312 seconds)
2022-03-07 07:19:50 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 07:19:50 | INFO | train | epoch 476 | loss 1.668 | nll_loss 0.284 | ppl 1.22 | wps 25005.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23162 | lr 0.000207784 | gnorm 0.391 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 60248
2022-03-07 07:19:50 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 07:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:20:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:21:27 | INFO | train_inner | epoch 477:     39 / 49 loss=1.668, nll_loss=0.284, ppl=1.22, wps=24832.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.394, loss_scale=32, train_wall=224, gb_free=8.8, wall=60345
2022-03-07 07:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:21:55 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.363 | nll_loss 12.887 | ppl 7572.75 | wps 43824.3 | wpb 510.9 | bsz 1 | num_updates 23210 | best_loss 8.725
2022-03-07 07:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23210 updates
2022-03-07 07:21:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 477 @ 23210 updates, score 13.363) (writing took 1.8773594964295626 seconds)
2022-03-07 07:21:57 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 07:21:57 | INFO | train | epoch 477 | loss 1.667 | nll_loss 0.283 | ppl 1.22 | wps 24554.4 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 23210 | lr 0.000207569 | gnorm 0.395 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 60375
2022-03-07 07:21:57 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 07:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:24:02 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.399 | nll_loss 12.923 | ppl 7767.89 | wps 44043.6 | wpb 510.9 | bsz 1 | num_updates 23259 | best_loss 8.725
2022-03-07 07:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23259 updates
2022-03-07 07:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 478 @ 23259 updates, score 13.399) (writing took 1.797994090244174 seconds)
2022-03-07 07:24:04 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 07:24:04 | INFO | train | epoch 478 | loss 1.668 | nll_loss 0.283 | ppl 1.22 | wps 25092.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23259 | lr 0.00020735 | gnorm 0.4 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 60502
2022-03-07 07:24:04 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 07:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:25:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:25:47 | INFO | train_inner | epoch 479:     42 / 49 loss=1.667, nll_loss=0.283, ppl=1.22, wps=24869.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.397, loss_scale=32, train_wall=224, gb_free=8.8, wall=60606
2022-03-07 07:26:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:08 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.416 | nll_loss 12.941 | ppl 7861.29 | wps 43630.7 | wpb 510.9 | bsz 1 | num_updates 23307 | best_loss 8.725
2022-03-07 07:26:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23307 updates
2022-03-07 07:26:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:26:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:26:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 479 @ 23307 updates, score 13.416) (writing took 1.7096700370311737 seconds)
2022-03-07 07:26:10 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 07:26:10 | INFO | train | epoch 479 | loss 1.667 | nll_loss 0.283 | ppl 1.22 | wps 24581.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23307 | lr 0.000207137 | gnorm 0.398 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 60628
2022-03-07 07:26:10 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 07:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:28:15 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.392 | nll_loss 12.915 | ppl 7723.07 | wps 44037 | wpb 510.9 | bsz 1 | num_updates 23356 | best_loss 8.725
2022-03-07 07:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23356 updates
2022-03-07 07:28:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 480 @ 23356 updates, score 13.392) (writing took 1.9477573372423649 seconds)
2022-03-07 07:28:17 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 07:28:17 | INFO | train | epoch 480 | loss 1.666 | nll_loss 0.282 | ppl 1.22 | wps 25062.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23356 | lr 0.000206919 | gnorm 0.393 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 60755
2022-03-07 07:28:17 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 07:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:06 | INFO | train_inner | epoch 481:     44 / 49 loss=1.666, nll_loss=0.283, ppl=1.22, wps=25103.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.397, loss_scale=32, train_wall=221, gb_free=8.8, wall=60864
2022-03-07 07:30:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:22 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.478 | nll_loss 13.004 | ppl 8215.28 | wps 43902.1 | wpb 510.9 | bsz 1 | num_updates 23405 | best_loss 8.725
2022-03-07 07:30:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23405 updates
2022-03-07 07:30:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:30:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:30:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 481 @ 23405 updates, score 13.478) (writing took 1.8010167824104428 seconds)
2022-03-07 07:30:24 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 07:30:24 | INFO | train | epoch 481 | loss 1.666 | nll_loss 0.282 | ppl 1.22 | wps 25075 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23405 | lr 0.000206702 | gnorm 0.396 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 60882
2022-03-07 07:30:24 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 07:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:31:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:32:29 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.421 | nll_loss 12.944 | ppl 7881.67 | wps 43973 | wpb 510.9 | bsz 1 | num_updates 23453 | best_loss 8.725
2022-03-07 07:32:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23453 updates
2022-03-07 07:32:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:32:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:32:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 482 @ 23453 updates, score 13.421) (writing took 1.8555039474740624 seconds)
2022-03-07 07:32:31 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 07:32:31 | INFO | train | epoch 482 | loss 1.665 | nll_loss 0.281 | ppl 1.22 | wps 24538.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23453 | lr 0.000206491 | gnorm 0.393 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 61009
2022-03-07 07:32:31 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 07:32:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:34:27 | INFO | train_inner | epoch 483:     47 / 49 loss=1.665, nll_loss=0.281, ppl=1.22, wps=24868.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.395, loss_scale=32, train_wall=224, gb_free=8.8, wall=61125
2022-03-07 07:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:34:35 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.423 | nll_loss 12.948 | ppl 7900.43 | wps 44290.9 | wpb 510.9 | bsz 1 | num_updates 23502 | best_loss 8.725
2022-03-07 07:34:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23502 updates
2022-03-07 07:34:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 483 @ 23502 updates, score 13.423) (writing took 1.755606271326542 seconds)
2022-03-07 07:34:37 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 07:34:37 | INFO | train | epoch 483 | loss 1.665 | nll_loss 0.281 | ppl 1.22 | wps 25117 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23502 | lr 0.000206275 | gnorm 0.398 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 61135
2022-03-07 07:34:37 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 07:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:36:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:36:42 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.349 | nll_loss 12.871 | ppl 7492.46 | wps 44271.9 | wpb 510.9 | bsz 1 | num_updates 23551 | best_loss 8.725
2022-03-07 07:36:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23551 updates
2022-03-07 07:36:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:36:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:36:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 484 @ 23551 updates, score 13.349) (writing took 1.8964451206848025 seconds)
2022-03-07 07:36:44 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 07:36:44 | INFO | train | epoch 484 | loss 1.664 | nll_loss 0.281 | ppl 1.21 | wps 25100 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23551 | lr 0.000206061 | gnorm 0.386 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 61262
2022-03-07 07:36:44 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 07:36:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:37:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:38:49 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.425 | nll_loss 12.951 | ppl 7917.29 | wps 44356.2 | wpb 510.9 | bsz 1 | num_updates 23599 | best_loss 8.725
2022-03-07 07:38:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23599 updates
2022-03-07 07:38:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:38:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 485 @ 23599 updates, score 13.425) (writing took 1.909760027192533 seconds)
2022-03-07 07:38:51 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 07:38:51 | INFO | train | epoch 485 | loss 1.664 | nll_loss 0.281 | ppl 1.22 | wps 24543 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23599 | lr 0.000205851 | gnorm 0.396 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 61389
2022-03-07 07:38:51 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 07:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:38:53 | INFO | train_inner | epoch 486:      1 / 49 loss=1.664, nll_loss=0.281, ppl=1.21, wps=24221.3, ups=0.38, wpb=64539.7, bsz=126.1, num_updates=23600, lr=0.000205847, gnorm=0.392, loss_scale=32, train_wall=223, gb_free=8.8, wall=61391
2022-03-07 07:40:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:40:56 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.389 | nll_loss 12.914 | ppl 7716.48 | wps 43986.7 | wpb 510.9 | bsz 1 | num_updates 23648 | best_loss 8.725
2022-03-07 07:40:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23648 updates
2022-03-07 07:40:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 486 @ 23648 updates, score 13.389) (writing took 2.046711213886738 seconds)
2022-03-07 07:40:58 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 07:40:58 | INFO | train | epoch 486 | loss 1.664 | nll_loss 0.281 | ppl 1.21 | wps 25007.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23648 | lr 0.000205638 | gnorm 0.396 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 61516
2022-03-07 07:40:58 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 07:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:42:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:43:02 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.476 | nll_loss 13.005 | ppl 8220.25 | wps 44026.7 | wpb 510.9 | bsz 1 | num_updates 23696 | best_loss 8.725
2022-03-07 07:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23696 updates
2022-03-07 07:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:43:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 487 @ 23696 updates, score 13.476) (writing took 1.8438131306320429 seconds)
2022-03-07 07:43:04 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 07:43:04 | INFO | train | epoch 487 | loss 1.664 | nll_loss 0.281 | ppl 1.21 | wps 24579.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23696 | lr 0.000205429 | gnorm 0.397 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 61642
2022-03-07 07:43:04 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 07:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:43:14 | INFO | train_inner | epoch 488:      4 / 49 loss=1.664, nll_loss=0.281, ppl=1.21, wps=24843.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.396, loss_scale=32, train_wall=224, gb_free=8.8, wall=61652
2022-03-07 07:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:09 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.538 | nll_loss 13.072 | ppl 8609.41 | wps 44350.3 | wpb 510.9 | bsz 1 | num_updates 23745 | best_loss 8.725
2022-03-07 07:45:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23745 updates
2022-03-07 07:45:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:45:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:45:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 488 @ 23745 updates, score 13.538) (writing took 1.7373552285134792 seconds)
2022-03-07 07:45:11 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 07:45:11 | INFO | train | epoch 488 | loss 1.663 | nll_loss 0.28 | ppl 1.21 | wps 25148.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23745 | lr 0.000205217 | gnorm 0.392 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 61769
2022-03-07 07:45:11 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 07:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:47:15 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.32 | nll_loss 12.84 | ppl 7332.4 | wps 44261.7 | wpb 510.9 | bsz 1 | num_updates 23794 | best_loss 8.725
2022-03-07 07:47:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23794 updates
2022-03-07 07:47:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:47:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:47:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 489 @ 23794 updates, score 13.32) (writing took 1.7188004674389958 seconds)
2022-03-07 07:47:17 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 07:47:17 | INFO | train | epoch 489 | loss 1.663 | nll_loss 0.28 | ppl 1.21 | wps 25146.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23794 | lr 0.000205006 | gnorm 0.393 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 61895
2022-03-07 07:47:17 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 07:47:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:32 | INFO | train_inner | epoch 490:      6 / 49 loss=1.663, nll_loss=0.28, ppl=1.21, wps=25175.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.393, loss_scale=32, train_wall=221, gb_free=8.8, wall=61910
2022-03-07 07:48:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:22 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.387 | nll_loss 12.913 | ppl 7710.39 | wps 44515.5 | wpb 510.9 | bsz 1 | num_updates 23842 | best_loss 8.725
2022-03-07 07:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23842 updates
2022-03-07 07:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:49:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 490 @ 23842 updates, score 13.387) (writing took 1.881926003843546 seconds)
2022-03-07 07:49:24 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 07:49:24 | INFO | train | epoch 490 | loss 1.662 | nll_loss 0.279 | ppl 1.21 | wps 24531.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23842 | lr 0.000204799 | gnorm 0.388 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 62022
2022-03-07 07:49:24 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 07:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:51:29 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.383 | nll_loss 12.904 | ppl 7664.25 | wps 44155.1 | wpb 510.9 | bsz 1 | num_updates 23891 | best_loss 8.725
2022-03-07 07:51:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23891 updates
2022-03-07 07:51:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:51:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:51:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 491 @ 23891 updates, score 13.383) (writing took 1.7696533547714353 seconds)
2022-03-07 07:51:30 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 07:51:30 | INFO | train | epoch 491 | loss 1.662 | nll_loss 0.28 | ppl 1.21 | wps 25132.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23891 | lr 0.000204589 | gnorm 0.392 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62149
2022-03-07 07:51:30 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 07:51:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:53 | INFO | train_inner | epoch 492:      9 / 49 loss=1.662, nll_loss=0.279, ppl=1.21, wps=24881.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.389, loss_scale=32, train_wall=224, gb_free=8.8, wall=62171
2022-03-07 07:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:53:35 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.452 | nll_loss 12.982 | ppl 8091.03 | wps 44506.2 | wpb 510.9 | bsz 1 | num_updates 23940 | best_loss 8.725
2022-03-07 07:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23940 updates
2022-03-07 07:53:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:53:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 492 @ 23940 updates, score 13.452) (writing took 1.936099337413907 seconds)
2022-03-07 07:53:37 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 07:53:37 | INFO | train | epoch 492 | loss 1.661 | nll_loss 0.278 | ppl 1.21 | wps 25115.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 23940 | lr 0.00020438 | gnorm 0.389 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62275
2022-03-07 07:53:37 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 07:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:55:41 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.403 | nll_loss 12.927 | ppl 7787.53 | wps 44866.6 | wpb 510.9 | bsz 1 | num_updates 23988 | best_loss 8.725
2022-03-07 07:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23988 updates
2022-03-07 07:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:55:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 493 @ 23988 updates, score 13.403) (writing took 1.884382744319737 seconds)
2022-03-07 07:55:43 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 07:55:43 | INFO | train | epoch 493 | loss 1.661 | nll_loss 0.279 | ppl 1.21 | wps 24663.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23988 | lr 0.000204175 | gnorm 0.393 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62401
2022-03-07 07:55:43 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 07:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:56:13 | INFO | train_inner | epoch 494:     12 / 49 loss=1.661, nll_loss=0.278, ppl=1.21, wps=24944.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.391, loss_scale=32, train_wall=223, gb_free=8.8, wall=62431
2022-03-07 07:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:57:48 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.49 | nll_loss 13.022 | ppl 8319.04 | wps 44254 | wpb 510.9 | bsz 1 | num_updates 24037 | best_loss 8.725
2022-03-07 07:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24037 updates
2022-03-07 07:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:57:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 494 @ 24037 updates, score 13.49) (writing took 1.6981593258678913 seconds)
2022-03-07 07:57:49 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 07:57:49 | INFO | train | epoch 494 | loss 1.661 | nll_loss 0.279 | ppl 1.21 | wps 25185.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24037 | lr 0.000203967 | gnorm 0.394 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62527
2022-03-07 07:57:49 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 07:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:59:54 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.372 | nll_loss 12.895 | ppl 7619.2 | wps 44411.1 | wpb 510.9 | bsz 1 | num_updates 24086 | best_loss 8.725
2022-03-07 07:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24086 updates
2022-03-07 07:59:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:59:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:59:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 495 @ 24086 updates, score 13.372) (writing took 1.9017413910478354 seconds)
2022-03-07 07:59:56 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 07:59:56 | INFO | train | epoch 495 | loss 1.66 | nll_loss 0.278 | ppl 1.21 | wps 25116.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24086 | lr 0.000203759 | gnorm 0.389 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62654
2022-03-07 07:59:56 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 07:59:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:00:33 | INFO | train_inner | epoch 496:     15 / 49 loss=1.661, nll_loss=0.279, ppl=1.21, wps=24938.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.392, loss_scale=32, train_wall=223, gb_free=8.8, wall=62691
2022-03-07 08:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:02:01 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.36 | nll_loss 12.877 | ppl 7523.57 | wps 44340.8 | wpb 510.9 | bsz 1 | num_updates 24134 | best_loss 8.725
2022-03-07 08:02:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24134 updates
2022-03-07 08:02:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:02:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:02:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 496 @ 24134 updates, score 13.36) (writing took 1.7701355321332812 seconds)
2022-03-07 08:02:02 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 08:02:02 | INFO | train | epoch 496 | loss 1.66 | nll_loss 0.278 | ppl 1.21 | wps 24583.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 24134 | lr 0.000203557 | gnorm 0.391 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 62781
2022-03-07 08:02:02 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 08:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:04:07 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.431 | nll_loss 12.959 | ppl 7961.94 | wps 44276.9 | wpb 510.9 | bsz 1 | num_updates 24183 | best_loss 8.725
2022-03-07 08:04:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24183 updates
2022-03-07 08:04:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 497 @ 24183 updates, score 13.431) (writing took 1.8821521336212754 seconds)
2022-03-07 08:04:09 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 08:04:09 | INFO | train | epoch 497 | loss 1.66 | nll_loss 0.278 | ppl 1.21 | wps 25147.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24183 | lr 0.00020335 | gnorm 0.39 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62907
2022-03-07 08:04:09 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 08:04:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:04:51 | INFO | train_inner | epoch 498:     17 / 49 loss=1.66, nll_loss=0.278, ppl=1.21, wps=25144.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.39, loss_scale=32, train_wall=221, gb_free=8.8, wall=62949
2022-03-07 08:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:06:14 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.511 | nll_loss 13.039 | ppl 8417.05 | wps 43908.5 | wpb 510.9 | bsz 1 | num_updates 24232 | best_loss 8.725
2022-03-07 08:06:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24232 updates
2022-03-07 08:06:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:06:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:06:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 498 @ 24232 updates, score 13.511) (writing took 1.8897648165002465 seconds)
2022-03-07 08:06:15 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 08:06:15 | INFO | train | epoch 498 | loss 1.659 | nll_loss 0.277 | ppl 1.21 | wps 25090 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24232 | lr 0.000203145 | gnorm 0.391 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 63034
2022-03-07 08:06:15 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 08:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:06:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:08:20 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.396 | nll_loss 12.919 | ppl 7746.47 | wps 44008.8 | wpb 510.9 | bsz 1 | num_updates 24280 | best_loss 8.725
2022-03-07 08:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24280 updates
2022-03-07 08:08:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:08:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 499 @ 24280 updates, score 13.396) (writing took 1.7441466404125094 seconds)
2022-03-07 08:08:22 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 08:08:22 | INFO | train | epoch 499 | loss 1.659 | nll_loss 0.277 | ppl 1.21 | wps 24573.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 24280 | lr 0.000202944 | gnorm 0.387 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 63160
2022-03-07 08:08:22 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 08:08:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:09:12 | INFO | train_inner | epoch 500:     20 / 49 loss=1.658, nll_loss=0.277, ppl=1.21, wps=24882.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.387, loss_scale=32, train_wall=224, gb_free=8.8, wall=63210
2022-03-07 08:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:10:27 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.402 | nll_loss 12.925 | ppl 7777.49 | wps 44068.9 | wpb 510.9 | bsz 1 | num_updates 24329 | best_loss 8.725
2022-03-07 08:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24329 updates
2022-03-07 08:10:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:10:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:10:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 500 @ 24329 updates, score 13.402) (writing took 1.8022120362147689 seconds)
2022-03-07 08:10:29 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 08:10:29 | INFO | train | epoch 500 | loss 1.659 | nll_loss 0.277 | ppl 1.21 | wps 25076.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24329 | lr 0.000202739 | gnorm 0.387 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 63287
2022-03-07 08:10:29 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 08:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:12:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:12:34 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.404 | nll_loss 12.93 | ppl 7805.31 | wps 43932.4 | wpb 510.9 | bsz 1 | num_updates 24377 | best_loss 8.725
2022-03-07 08:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24377 updates
2022-03-07 08:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 501 @ 24377 updates, score 13.404) (writing took 1.723403842188418 seconds)
2022-03-07 08:12:36 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 08:12:36 | INFO | train | epoch 501 | loss 1.658 | nll_loss 0.276 | ppl 1.21 | wps 24556.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 24377 | lr 0.00020254 | gnorm 0.385 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 63414
2022-03-07 08:12:36 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 08:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:13:33 | INFO | train_inner | epoch 502:     23 / 49 loss=1.658, nll_loss=0.277, ppl=1.21, wps=24854.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.388, loss_scale=32, train_wall=224, gb_free=8.8, wall=63471
2022-03-07 08:14:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:14:41 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.409 | nll_loss 12.933 | ppl 7821.73 | wps 44052.7 | wpb 510.9 | bsz 1 | num_updates 24426 | best_loss 8.725
2022-03-07 08:14:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24426 updates
2022-03-07 08:14:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:14:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 502 @ 24426 updates, score 13.409) (writing took 1.7379057733342052 seconds)
2022-03-07 08:14:42 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 08:14:42 | INFO | train | epoch 502 | loss 1.658 | nll_loss 0.277 | ppl 1.21 | wps 25077.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24426 | lr 0.000202336 | gnorm 0.39 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 63541
2022-03-07 08:14:42 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 08:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:16:47 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.375 | nll_loss 12.901 | ppl 7646.91 | wps 44162 | wpb 510.9 | bsz 1 | num_updates 24475 | best_loss 8.725
2022-03-07 08:16:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24475 updates
2022-03-07 08:16:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 503 @ 24475 updates, score 13.375) (writing took 1.7676960565149784 seconds)
2022-03-07 08:16:49 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 08:16:49 | INFO | train | epoch 503 | loss 1.657 | nll_loss 0.276 | ppl 1.21 | wps 25082.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24475 | lr 0.000202134 | gnorm 0.385 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 63667
2022-03-07 08:16:49 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 08:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:17:51 | INFO | train_inner | epoch 504:     25 / 49 loss=1.657, nll_loss=0.276, ppl=1.21, wps=25115.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.385, loss_scale=32, train_wall=222, gb_free=8.8, wall=63729
2022-03-07 08:18:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:18:54 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.416 | nll_loss 12.944 | ppl 7881.24 | wps 43936.9 | wpb 510.9 | bsz 1 | num_updates 24523 | best_loss 8.725
2022-03-07 08:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24523 updates
2022-03-07 08:18:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 504 @ 24523 updates, score 13.416) (writing took 1.911989625543356 seconds)
2022-03-07 08:18:56 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 08:18:56 | INFO | train | epoch 504 | loss 1.657 | nll_loss 0.275 | ppl 1.21 | wps 24555.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 24523 | lr 0.000201936 | gnorm 0.385 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 63794
2022-03-07 08:18:56 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 08:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:21:01 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.386 | nll_loss 12.91 | ppl 7698.87 | wps 43846.3 | wpb 510.9 | bsz 1 | num_updates 24572 | best_loss 8.725
2022-03-07 08:21:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24572 updates
2022-03-07 08:21:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:21:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:21:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 505 @ 24572 updates, score 13.386) (writing took 2.028254235163331 seconds)
2022-03-07 08:21:03 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 08:21:03 | INFO | train | epoch 505 | loss 1.657 | nll_loss 0.275 | ppl 1.21 | wps 24973.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24572 | lr 0.000201734 | gnorm 0.384 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 63921
2022-03-07 08:21:03 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 08:21:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:22:12 | INFO | train_inner | epoch 506:     28 / 49 loss=1.657, nll_loss=0.275, ppl=1.21, wps=24795.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.384, loss_scale=32, train_wall=224, gb_free=8.8, wall=63991
2022-03-07 08:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:23:08 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.355 | nll_loss 12.88 | ppl 7536.93 | wps 43370.1 | wpb 510.9 | bsz 1 | num_updates 24621 | best_loss 8.725
2022-03-07 08:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24621 updates
2022-03-07 08:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:23:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 506 @ 24621 updates, score 13.355) (writing took 1.7491741962730885 seconds)
2022-03-07 08:23:10 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 08:23:10 | INFO | train | epoch 506 | loss 1.656 | nll_loss 0.275 | ppl 1.21 | wps 25033.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24621 | lr 0.000201533 | gnorm 0.383 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 64048
2022-03-07 08:23:10 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 08:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:24:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:25:15 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.478 | nll_loss 13.007 | ppl 8229.78 | wps 43845 | wpb 510.9 | bsz 1 | num_updates 24669 | best_loss 8.725
2022-03-07 08:25:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24669 updates
2022-03-07 08:25:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:25:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 507 @ 24669 updates, score 13.478) (writing took 1.8904938763007522 seconds)
2022-03-07 08:25:17 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 08:25:17 | INFO | train | epoch 507 | loss 1.657 | nll_loss 0.276 | ppl 1.21 | wps 24545.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 24669 | lr 0.000201337 | gnorm 0.388 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 64175
2022-03-07 08:25:17 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 08:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:33 | INFO | train_inner | epoch 508:     31 / 49 loss=1.656, nll_loss=0.276, ppl=1.21, wps=24857.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.386, loss_scale=32, train_wall=224, gb_free=8.8, wall=64252
2022-03-07 08:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:27:22 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.469 | nll_loss 12.995 | ppl 8164.72 | wps 44479.9 | wpb 510.9 | bsz 1 | num_updates 24718 | best_loss 8.725
2022-03-07 08:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24718 updates
2022-03-07 08:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 508 @ 24718 updates, score 13.469) (writing took 1.8873183550313115 seconds)
2022-03-07 08:27:24 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 08:27:24 | INFO | train | epoch 508 | loss 1.657 | nll_loss 0.276 | ppl 1.21 | wps 25075.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24718 | lr 0.000201138 | gnorm 0.391 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 64302
2022-03-07 08:27:24 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 08:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:29:29 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.453 | nll_loss 12.978 | ppl 8070.16 | wps 43758.1 | wpb 510.9 | bsz 1 | num_updates 24767 | best_loss 8.725
2022-03-07 08:29:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24767 updates
2022-03-07 08:29:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:29:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 509 @ 24767 updates, score 13.453) (writing took 1.9225308988243341 seconds)
2022-03-07 08:29:31 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 08:29:31 | INFO | train | epoch 509 | loss 1.655 | nll_loss 0.274 | ppl 1.21 | wps 24887.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24767 | lr 0.000200939 | gnorm 0.385 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 64429
2022-03-07 08:29:31 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 08:29:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:30:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:30:55 | INFO | train_inner | epoch 510:     34 / 49 loss=1.656, nll_loss=0.275, ppl=1.21, wps=24794.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.387, loss_scale=32, train_wall=224, gb_free=8.8, wall=64513
2022-03-07 08:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:31:36 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.448 | nll_loss 12.974 | ppl 8046.63 | wps 44417.2 | wpb 510.9 | bsz 1 | num_updates 24815 | best_loss 8.725
2022-03-07 08:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24815 updates
2022-03-07 08:31:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 510 @ 24815 updates, score 13.448) (writing took 1.9026024043560028 seconds)
2022-03-07 08:31:38 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 08:31:38 | INFO | train | epoch 510 | loss 1.655 | nll_loss 0.274 | ppl 1.21 | wps 24612.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 24815 | lr 0.000200744 | gnorm 0.385 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 64556
2022-03-07 08:31:38 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 08:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:43 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.318 | nll_loss 12.842 | ppl 7340.19 | wps 44540.6 | wpb 510.9 | bsz 1 | num_updates 24864 | best_loss 8.725
2022-03-07 08:33:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24864 updates
2022-03-07 08:33:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:33:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 511 @ 24864 updates, score 13.318) (writing took 1.854762309230864 seconds)
2022-03-07 08:33:44 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 08:33:44 | INFO | train | epoch 511 | loss 1.655 | nll_loss 0.274 | ppl 1.21 | wps 25078.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24864 | lr 0.000200546 | gnorm 0.384 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 64683
2022-03-07 08:33:44 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 08:33:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:35:13 | INFO | train_inner | epoch 512:     36 / 49 loss=1.655, nll_loss=0.274, ppl=1.21, wps=25127.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.386, loss_scale=32, train_wall=221, gb_free=8.8, wall=64771
2022-03-07 08:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:35:49 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.479 | nll_loss 13.009 | ppl 8242.66 | wps 44265.8 | wpb 510.9 | bsz 1 | num_updates 24913 | best_loss 8.725
2022-03-07 08:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24913 updates
2022-03-07 08:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 512 @ 24913 updates, score 13.479) (writing took 1.7152408277615905 seconds)
2022-03-07 08:35:51 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 08:35:51 | INFO | train | epoch 512 | loss 1.654 | nll_loss 0.273 | ppl 1.21 | wps 25157.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 24913 | lr 0.000200349 | gnorm 0.385 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 64809
2022-03-07 08:35:51 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 08:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:36:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:55 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.383 | nll_loss 12.908 | ppl 7687.54 | wps 44306.3 | wpb 510.9 | bsz 1 | num_updates 24961 | best_loss 8.725
2022-03-07 08:37:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24961 updates
2022-03-07 08:37:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:37:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 513 @ 24961 updates, score 13.383) (writing took 1.7808132655918598 seconds)
2022-03-07 08:37:57 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 08:37:57 | INFO | train | epoch 513 | loss 1.654 | nll_loss 0.274 | ppl 1.21 | wps 24636.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 24961 | lr 0.000200156 | gnorm 0.385 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 64935
2022-03-07 08:37:57 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 08:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:39:33 | INFO | train_inner | epoch 514:     39 / 49 loss=1.654, nll_loss=0.273, ppl=1.21, wps=24951.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.385, loss_scale=32, train_wall=223, gb_free=8.8, wall=65031
2022-03-07 08:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:40:02 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.391 | nll_loss 12.923 | ppl 7767.04 | wps 44202 | wpb 510.9 | bsz 1 | num_updates 25010 | best_loss 8.725
2022-03-07 08:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25010 updates
2022-03-07 08:40:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 514 @ 25010 updates, score 13.391) (writing took 1.8246007906273007 seconds)
2022-03-07 08:40:03 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 08:40:03 | INFO | train | epoch 514 | loss 1.654 | nll_loss 0.273 | ppl 1.21 | wps 25153.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25010 | lr 0.00019996 | gnorm 0.384 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65062
2022-03-07 08:40:03 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 08:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:42:08 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.367 | nll_loss 12.892 | ppl 7601.28 | wps 44390.2 | wpb 510.9 | bsz 1 | num_updates 25059 | best_loss 8.725
2022-03-07 08:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25059 updates
2022-03-07 08:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 515 @ 25059 updates, score 13.367) (writing took 1.8424544287845492 seconds)
2022-03-07 08:42:10 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 08:42:10 | INFO | train | epoch 515 | loss 1.654 | nll_loss 0.273 | ppl 1.21 | wps 25144.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25059 | lr 0.000199764 | gnorm 0.386 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65188
2022-03-07 08:42:10 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 08:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:43:53 | INFO | train_inner | epoch 516:     42 / 49 loss=1.653, nll_loss=0.273, ppl=1.21, wps=24939.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.383, loss_scale=32, train_wall=223, gb_free=8.8, wall=65292
2022-03-07 08:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:44:14 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.415 | nll_loss 12.944 | ppl 7882.18 | wps 45196.2 | wpb 510.9 | bsz 1 | num_updates 25107 | best_loss 8.725
2022-03-07 08:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25107 updates
2022-03-07 08:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:44:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:44:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 516 @ 25107 updates, score 13.415) (writing took 1.8213197058066726 seconds)
2022-03-07 08:44:16 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 08:44:16 | INFO | train | epoch 516 | loss 1.652 | nll_loss 0.272 | ppl 1.21 | wps 24641.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25107 | lr 0.000199573 | gnorm 0.381 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65314
2022-03-07 08:44:16 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 08:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:20 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.441 | nll_loss 12.971 | ppl 8030.08 | wps 44210.4 | wpb 510.9 | bsz 1 | num_updates 25156 | best_loss 8.725
2022-03-07 08:46:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25156 updates
2022-03-07 08:46:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:46:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 517 @ 25156 updates, score 13.441) (writing took 1.7938730968162417 seconds)
2022-03-07 08:46:22 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 08:46:22 | INFO | train | epoch 517 | loss 1.653 | nll_loss 0.273 | ppl 1.21 | wps 25194.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25156 | lr 0.000199379 | gnorm 0.389 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65441
2022-03-07 08:46:22 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 08:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:48:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:48:13 | INFO | train_inner | epoch 518:     45 / 49 loss=1.653, nll_loss=0.273, ppl=1.21, wps=24979.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.386, loss_scale=32, train_wall=223, gb_free=8.8, wall=65551
2022-03-07 08:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:48:27 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.314 | nll_loss 12.836 | ppl 7310.42 | wps 44646.4 | wpb 510.9 | bsz 1 | num_updates 25204 | best_loss 8.725
2022-03-07 08:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25204 updates
2022-03-07 08:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:48:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 518 @ 25204 updates, score 13.314) (writing took 1.8835399756208062 seconds)
2022-03-07 08:48:29 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 08:48:29 | INFO | train | epoch 518 | loss 1.652 | nll_loss 0.272 | ppl 1.21 | wps 24658.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25204 | lr 0.000199189 | gnorm 0.385 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65567
2022-03-07 08:48:29 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 08:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:50:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:50:33 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.373 | nll_loss 12.901 | ppl 7646.29 | wps 44598.9 | wpb 510.9 | bsz 1 | num_updates 25253 | best_loss 8.725
2022-03-07 08:50:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25253 updates
2022-03-07 08:50:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:50:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:50:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 519 @ 25253 updates, score 13.373) (writing took 1.852052355185151 seconds)
2022-03-07 08:50:35 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 08:50:35 | INFO | train | epoch 519 | loss 1.651 | nll_loss 0.271 | ppl 1.21 | wps 25190.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25253 | lr 0.000198996 | gnorm 0.378 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65693
2022-03-07 08:50:35 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 08:50:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:52:30 | INFO | train_inner | epoch 520:     47 / 49 loss=1.651, nll_loss=0.272, ppl=1.21, wps=25211.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.38, loss_scale=32, train_wall=221, gb_free=8.8, wall=65809
2022-03-07 08:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:39 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.438 | nll_loss 12.965 | ppl 7994.07 | wps 43892.4 | wpb 510.9 | bsz 1 | num_updates 25302 | best_loss 8.725
2022-03-07 08:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25302 updates
2022-03-07 08:52:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 520 @ 25302 updates, score 13.438) (writing took 1.8893582755699754 seconds)
2022-03-07 08:52:41 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 08:52:41 | INFO | train | epoch 520 | loss 1.651 | nll_loss 0.272 | ppl 1.21 | wps 25153.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25302 | lr 0.000198803 | gnorm 0.382 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65819
2022-03-07 08:52:41 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 08:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:54:46 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.41 | nll_loss 12.936 | ppl 7834.74 | wps 44097.2 | wpb 510.9 | bsz 1 | num_updates 25350 | best_loss 8.725
2022-03-07 08:54:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25350 updates
2022-03-07 08:54:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:54:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:54:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 521 @ 25350 updates, score 13.41) (writing took 1.97667495906353 seconds)
2022-03-07 08:54:48 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 08:54:48 | INFO | train | epoch 521 | loss 1.652 | nll_loss 0.272 | ppl 1.21 | wps 24587.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25350 | lr 0.000198615 | gnorm 0.387 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 65946
2022-03-07 08:54:48 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 08:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:52 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.409 | nll_loss 12.937 | ppl 7841.28 | wps 44258.2 | wpb 510.9 | bsz 1 | num_updates 25399 | best_loss 8.725
2022-03-07 08:56:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25399 updates
2022-03-07 08:56:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:56:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:56:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 522 @ 25399 updates, score 13.409) (writing took 1.9290346559137106 seconds)
2022-03-07 08:56:54 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 08:56:54 | INFO | train | epoch 522 | loss 1.651 | nll_loss 0.271 | ppl 1.21 | wps 25127.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25399 | lr 0.000198423 | gnorm 0.377 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 66072
2022-03-07 08:56:54 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 08:56:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:56:57 | INFO | train_inner | epoch 523:      1 / 49 loss=1.652, nll_loss=0.272, ppl=1.21, wps=24239.7, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=25400, lr=0.000198419, gnorm=0.384, loss_scale=32, train_wall=222, gb_free=8.8, wall=66075
2022-03-07 08:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:58:59 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.403 | nll_loss 12.935 | ppl 7831.35 | wps 44387.9 | wpb 510.9 | bsz 1 | num_updates 25448 | best_loss 8.725
2022-03-07 08:58:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25448 updates
2022-03-07 08:58:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 523 @ 25448 updates, score 13.403) (writing took 1.8935738950967789 seconds)
2022-03-07 08:59:01 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 08:59:01 | INFO | train | epoch 523 | loss 1.65 | nll_loss 0.27 | ppl 1.21 | wps 25082.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25448 | lr 0.000198232 | gnorm 0.38 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 66199
2022-03-07 08:59:01 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 08:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:01:05 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.387 | nll_loss 12.911 | ppl 7702.05 | wps 44430.4 | wpb 510.9 | bsz 1 | num_updates 25496 | best_loss 8.725
2022-03-07 09:01:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25496 updates
2022-03-07 09:01:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:01:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:01:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 524 @ 25496 updates, score 13.387) (writing took 1.8118752045556903 seconds)
2022-03-07 09:01:07 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 09:01:07 | INFO | train | epoch 524 | loss 1.65 | nll_loss 0.271 | ppl 1.21 | wps 24616.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25496 | lr 0.000198045 | gnorm 0.381 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 66325
2022-03-07 09:01:07 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 09:01:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:01:17 | INFO | train_inner | epoch 525:      4 / 49 loss=1.65, nll_loss=0.271, ppl=1.21, wps=24901.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.381, loss_scale=32, train_wall=223, gb_free=8.8, wall=66335
2022-03-07 09:03:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:03:12 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.354 | nll_loss 12.878 | ppl 7528.29 | wps 44202.7 | wpb 510.9 | bsz 1 | num_updates 25545 | best_loss 8.725
2022-03-07 09:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25545 updates
2022-03-07 09:03:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 525 @ 25545 updates, score 13.354) (writing took 1.7496423684060574 seconds)
2022-03-07 09:03:14 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 09:03:14 | INFO | train | epoch 525 | loss 1.65 | nll_loss 0.271 | ppl 1.21 | wps 25112.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25545 | lr 0.000197855 | gnorm 0.378 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 66452
2022-03-07 09:03:14 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 09:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:18 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.375 | nll_loss 12.9 | ppl 7643.28 | wps 44386.4 | wpb 510.9 | bsz 1 | num_updates 25594 | best_loss 8.725
2022-03-07 09:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25594 updates
2022-03-07 09:05:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:05:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:05:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 526 @ 25594 updates, score 13.375) (writing took 1.7473917789757252 seconds)
2022-03-07 09:05:20 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 09:05:20 | INFO | train | epoch 526 | loss 1.65 | nll_loss 0.27 | ppl 1.21 | wps 25131.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25594 | lr 0.000197666 | gnorm 0.38 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 66578
2022-03-07 09:05:20 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 09:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:05:35 | INFO | train_inner | epoch 527:      6 / 49 loss=1.65, nll_loss=0.27, ppl=1.21, wps=25145.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.379, loss_scale=32, train_wall=221, gb_free=8.8, wall=66593
2022-03-07 09:06:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:07:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:07:25 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.468 | nll_loss 13.001 | ppl 8197.73 | wps 44231.8 | wpb 510.9 | bsz 1 | num_updates 25642 | best_loss 8.725
2022-03-07 09:07:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25642 updates
2022-03-07 09:07:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:07:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 527 @ 25642 updates, score 13.468) (writing took 1.7136967098340392 seconds)
2022-03-07 09:07:27 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 09:07:27 | INFO | train | epoch 527 | loss 1.649 | nll_loss 0.27 | ppl 1.21 | wps 24585.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25642 | lr 0.00019748 | gnorm 0.381 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 66705
2022-03-07 09:07:27 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 09:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:09:32 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.503 | nll_loss 13.041 | ppl 8426.96 | wps 43642.9 | wpb 510.9 | bsz 1 | num_updates 25691 | best_loss 8.725
2022-03-07 09:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25691 updates
2022-03-07 09:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 528 @ 25691 updates, score 13.503) (writing took 1.7303276034072042 seconds)
2022-03-07 09:09:33 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 09:09:33 | INFO | train | epoch 528 | loss 1.65 | nll_loss 0.271 | ppl 1.21 | wps 25119.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25691 | lr 0.000197292 | gnorm 0.383 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 66832
2022-03-07 09:09:33 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 09:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:09:56 | INFO | train_inner | epoch 529:      9 / 49 loss=1.65, nll_loss=0.271, ppl=1.21, wps=24905.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.382, loss_scale=32, train_wall=224, gb_free=8.8, wall=66854
2022-03-07 09:11:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:11:38 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.407 | nll_loss 12.935 | ppl 7831.52 | wps 44299.4 | wpb 510.9 | bsz 1 | num_updates 25740 | best_loss 8.725
2022-03-07 09:11:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25740 updates
2022-03-07 09:11:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 529 @ 25740 updates, score 13.407) (writing took 1.8692969707772136 seconds)
2022-03-07 09:11:40 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 09:11:40 | INFO | train | epoch 529 | loss 1.649 | nll_loss 0.27 | ppl 1.21 | wps 25106.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25740 | lr 0.000197104 | gnorm 0.386 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 66958
2022-03-07 09:11:40 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 09:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:11:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:13:45 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.478 | nll_loss 13.013 | ppl 8264.02 | wps 43876.2 | wpb 510.9 | bsz 1 | num_updates 25788 | best_loss 8.725
2022-03-07 09:13:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25788 updates
2022-03-07 09:13:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:13:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:13:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 530 @ 25788 updates, score 13.478) (writing took 1.7208461798727512 seconds)
2022-03-07 09:13:46 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 09:13:46 | INFO | train | epoch 530 | loss 1.648 | nll_loss 0.269 | ppl 1.2 | wps 24595.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25788 | lr 0.000196921 | gnorm 0.379 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 67085
2022-03-07 09:13:46 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 09:13:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:14:16 | INFO | train_inner | epoch 531:     12 / 49 loss=1.648, nll_loss=0.269, ppl=1.21, wps=24896.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.382, loss_scale=32, train_wall=224, gb_free=8.8, wall=67114
2022-03-07 09:15:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:15:52 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.37 | nll_loss 12.894 | ppl 7610.03 | wps 43196.8 | wpb 510.9 | bsz 1 | num_updates 25837 | best_loss 8.725
2022-03-07 09:15:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25837 updates
2022-03-07 09:15:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:15:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:15:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 531 @ 25837 updates, score 13.37) (writing took 1.8615351356565952 seconds)
2022-03-07 09:15:53 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 09:15:53 | INFO | train | epoch 531 | loss 1.648 | nll_loss 0.27 | ppl 1.21 | wps 25039.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25837 | lr 0.000196734 | gnorm 0.377 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 67212
2022-03-07 09:15:53 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 09:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:17:58 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.278 | nll_loss 12.794 | ppl 7102.65 | wps 44393.4 | wpb 510.9 | bsz 1 | num_updates 25886 | best_loss 8.725
2022-03-07 09:17:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25886 updates
2022-03-07 09:17:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 532 @ 25886 updates, score 13.278) (writing took 1.7816787734627724 seconds)
2022-03-07 09:18:00 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 09:18:00 | INFO | train | epoch 532 | loss 1.648 | nll_loss 0.269 | ppl 1.2 | wps 25123.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25886 | lr 0.000196548 | gnorm 0.38 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 67338
2022-03-07 09:18:00 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 09:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:18:35 | INFO | train_inner | epoch 533:     14 / 49 loss=1.648, nll_loss=0.269, ppl=1.21, wps=25106.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.379, loss_scale=64, train_wall=222, gb_free=8.8, wall=67373
2022-03-07 09:18:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:20:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:05 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.356 | nll_loss 12.881 | ppl 7544.3 | wps 44062.2 | wpb 510.9 | bsz 1 | num_updates 25934 | best_loss 8.725
2022-03-07 09:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25934 updates
2022-03-07 09:20:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 533 @ 25934 updates, score 13.356) (writing took 1.7115333685651422 seconds)
2022-03-07 09:20:06 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 09:20:06 | INFO | train | epoch 533 | loss 1.648 | nll_loss 0.269 | ppl 1.2 | wps 24591 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25934 | lr 0.000196366 | gnorm 0.378 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 67465
2022-03-07 09:20:06 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 09:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:22:11 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.461 | nll_loss 12.987 | ppl 8119.76 | wps 43984.5 | wpb 510.9 | bsz 1 | num_updates 25983 | best_loss 8.725
2022-03-07 09:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25983 updates
2022-03-07 09:22:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:22:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:22:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 534 @ 25983 updates, score 13.461) (writing took 1.8972137365490198 seconds)
2022-03-07 09:22:13 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 09:22:13 | INFO | train | epoch 534 | loss 1.648 | nll_loss 0.269 | ppl 1.21 | wps 25052.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 25983 | lr 0.00019618 | gnorm 0.383 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 67592
2022-03-07 09:22:13 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 09:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:22:55 | INFO | train_inner | epoch 535:     17 / 49 loss=1.648, nll_loss=0.269, ppl=1.2, wps=24872.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.381, loss_scale=32, train_wall=224, gb_free=8.8, wall=67634
2022-03-07 09:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:18 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.405 | nll_loss 12.933 | ppl 7820.02 | wps 44105.6 | wpb 510.9 | bsz 1 | num_updates 26032 | best_loss 8.725
2022-03-07 09:24:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26032 updates
2022-03-07 09:24:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:24:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:24:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 535 @ 26032 updates, score 13.405) (writing took 1.9023288525640965 seconds)
2022-03-07 09:24:20 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 09:24:20 | INFO | train | epoch 535 | loss 1.647 | nll_loss 0.269 | ppl 1.2 | wps 25091.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26032 | lr 0.000195996 | gnorm 0.384 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 67718
2022-03-07 09:24:20 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 09:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:24:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:26:25 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.407 | nll_loss 12.932 | ppl 7815.26 | wps 44053.9 | wpb 510.9 | bsz 1 | num_updates 26080 | best_loss 8.725
2022-03-07 09:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26080 updates
2022-03-07 09:26:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:26:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 536 @ 26080 updates, score 13.407) (writing took 1.8609513491392136 seconds)
2022-03-07 09:26:27 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 09:26:27 | INFO | train | epoch 536 | loss 1.646 | nll_loss 0.268 | ppl 1.2 | wps 24577.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 26080 | lr 0.000195815 | gnorm 0.378 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 67845
2022-03-07 09:26:27 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 09:26:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:27:16 | INFO | train_inner | epoch 537:     20 / 49 loss=1.646, nll_loss=0.268, ppl=1.2, wps=24854, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.38, loss_scale=32, train_wall=224, gb_free=8.8, wall=67895
2022-03-07 09:28:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:28:32 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.374 | nll_loss 12.903 | ppl 7659.53 | wps 43954.6 | wpb 510.9 | bsz 1 | num_updates 26129 | best_loss 8.725
2022-03-07 09:28:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26129 updates
2022-03-07 09:28:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:28:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:28:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 537 @ 26129 updates, score 13.374) (writing took 1.7526710527017713 seconds)
2022-03-07 09:28:34 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 09:28:34 | INFO | train | epoch 537 | loss 1.646 | nll_loss 0.268 | ppl 1.2 | wps 25015.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26129 | lr 0.000195631 | gnorm 0.38 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 67972
2022-03-07 09:28:34 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 09:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:30:39 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.398 | nll_loss 12.93 | ppl 7803.62 | wps 44433 | wpb 510.9 | bsz 1 | num_updates 26178 | best_loss 8.725
2022-03-07 09:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26178 updates
2022-03-07 09:30:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 538 @ 26178 updates, score 13.398) (writing took 1.6971731213852763 seconds)
2022-03-07 09:30:40 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 09:30:40 | INFO | train | epoch 538 | loss 1.645 | nll_loss 0.267 | ppl 1.2 | wps 25102.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26178 | lr 0.000195448 | gnorm 0.373 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 68099
2022-03-07 09:30:40 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 09:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:31:37 | INFO | train_inner | epoch 539:     23 / 49 loss=1.646, nll_loss=0.268, ppl=1.2, wps=24885.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.377, loss_scale=32, train_wall=224, gb_free=8.8, wall=68155
2022-03-07 09:32:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:32:45 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.386 | nll_loss 12.917 | ppl 7731.65 | wps 44257.3 | wpb 510.9 | bsz 1 | num_updates 26226 | best_loss 8.725
2022-03-07 09:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26226 updates
2022-03-07 09:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 539 @ 26226 updates, score 13.386) (writing took 1.868432524614036 seconds)
2022-03-07 09:32:47 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 09:32:47 | INFO | train | epoch 539 | loss 1.646 | nll_loss 0.268 | ppl 1.2 | wps 24606.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 26226 | lr 0.000195269 | gnorm 0.38 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 68225
2022-03-07 09:32:47 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 09:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:34:52 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.369 | nll_loss 12.894 | ppl 7609.32 | wps 44360.2 | wpb 510.9 | bsz 1 | num_updates 26275 | best_loss 8.725
2022-03-07 09:34:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26275 updates
2022-03-07 09:34:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:34:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 540 @ 26275 updates, score 13.369) (writing took 1.8537904443219304 seconds)
2022-03-07 09:34:53 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 09:34:53 | INFO | train | epoch 540 | loss 1.645 | nll_loss 0.267 | ppl 1.2 | wps 25080.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26275 | lr 0.000195087 | gnorm 0.374 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 68352
2022-03-07 09:34:53 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 09:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:35:55 | INFO | train_inner | epoch 541:     25 / 49 loss=1.645, nll_loss=0.267, ppl=1.2, wps=25134.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.379, loss_scale=32, train_wall=221, gb_free=8.8, wall=68413
2022-03-07 09:36:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:36:58 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.456 | nll_loss 12.987 | ppl 8116.21 | wps 44366.2 | wpb 510.9 | bsz 1 | num_updates 26323 | best_loss 8.725
2022-03-07 09:36:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26323 updates
2022-03-07 09:36:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:37:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:37:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 541 @ 26323 updates, score 13.456) (writing took 1.8583292746916413 seconds)
2022-03-07 09:37:00 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 09:37:00 | INFO | train | epoch 541 | loss 1.645 | nll_loss 0.267 | ppl 1.2 | wps 24605.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 26323 | lr 0.000194909 | gnorm 0.384 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 68478
2022-03-07 09:37:00 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 09:37:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:39:05 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.3 | nll_loss 12.819 | ppl 7225.21 | wps 44195.8 | wpb 510.9 | bsz 1 | num_updates 26372 | best_loss 8.725
2022-03-07 09:39:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26372 updates
2022-03-07 09:39:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:39:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 542 @ 26372 updates, score 13.3) (writing took 1.9886303497478366 seconds)
2022-03-07 09:39:07 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 09:39:07 | INFO | train | epoch 542 | loss 1.645 | nll_loss 0.267 | ppl 1.2 | wps 25081.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26372 | lr 0.000194728 | gnorm 0.378 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 68605
2022-03-07 09:39:07 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 09:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:16 | INFO | train_inner | epoch 543:     28 / 49 loss=1.645, nll_loss=0.267, ppl=1.2, wps=24884.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.377, loss_scale=32, train_wall=223, gb_free=8.8, wall=68674
2022-03-07 09:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:41:11 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.337 | nll_loss 12.862 | ppl 7442.37 | wps 44273.7 | wpb 510.9 | bsz 1 | num_updates 26421 | best_loss 8.725
2022-03-07 09:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26421 updates
2022-03-07 09:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 543 @ 26421 updates, score 13.337) (writing took 1.7676588417962193 seconds)
2022-03-07 09:41:13 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 09:41:13 | INFO | train | epoch 543 | loss 1.644 | nll_loss 0.267 | ppl 1.2 | wps 25139.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26421 | lr 0.000194547 | gnorm 0.375 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 68731
2022-03-07 09:41:13 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 09:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:43:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:43:17 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.406 | nll_loss 12.934 | ppl 7823.04 | wps 44246.3 | wpb 510.9 | bsz 1 | num_updates 26469 | best_loss 8.725
2022-03-07 09:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26469 updates
2022-03-07 09:43:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:43:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 544 @ 26469 updates, score 13.406) (writing took 1.9325814731419086 seconds)
2022-03-07 09:43:19 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 09:43:19 | INFO | train | epoch 544 | loss 1.644 | nll_loss 0.266 | ppl 1.2 | wps 24639.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 26469 | lr 0.000194371 | gnorm 0.371 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 68858
2022-03-07 09:43:19 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 09:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:44:36 | INFO | train_inner | epoch 545:     31 / 49 loss=1.644, nll_loss=0.266, ppl=1.2, wps=24950.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.375, loss_scale=32, train_wall=223, gb_free=8.8, wall=68934
2022-03-07 09:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:45:24 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.39 | nll_loss 12.918 | ppl 7741.78 | wps 44540.2 | wpb 510.9 | bsz 1 | num_updates 26518 | best_loss 8.725
2022-03-07 09:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26518 updates
2022-03-07 09:45:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:45:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 545 @ 26518 updates, score 13.39) (writing took 1.7224488770589232 seconds)
2022-03-07 09:45:26 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 09:45:26 | INFO | train | epoch 545 | loss 1.644 | nll_loss 0.267 | ppl 1.2 | wps 25198.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26518 | lr 0.000194191 | gnorm 0.379 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 68984
2022-03-07 09:45:26 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 09:45:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:47:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:47:30 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.412 | nll_loss 12.937 | ppl 7844.13 | wps 44436.7 | wpb 510.9 | bsz 1 | num_updates 26567 | best_loss 8.725
2022-03-07 09:47:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26567 updates
2022-03-07 09:47:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:47:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 546 @ 26567 updates, score 13.412) (writing took 1.8754205256700516 seconds)
2022-03-07 09:47:32 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 09:47:32 | INFO | train | epoch 546 | loss 1.644 | nll_loss 0.266 | ppl 1.2 | wps 25153.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26567 | lr 0.000194012 | gnorm 0.378 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 69110
2022-03-07 09:47:32 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 09:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:48:53 | INFO | train_inner | epoch 547:     33 / 49 loss=1.643, nll_loss=0.266, ppl=1.2, wps=25208.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.375, loss_scale=64, train_wall=221, gb_free=8.8, wall=69191
2022-03-07 09:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:49:36 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.369 | nll_loss 12.894 | ppl 7610.25 | wps 44293.9 | wpb 510.9 | bsz 1 | num_updates 26616 | best_loss 8.725
2022-03-07 09:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26616 updates
2022-03-07 09:49:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:49:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 547 @ 26616 updates, score 13.369) (writing took 1.8415315551683307 seconds)
2022-03-07 09:49:38 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 09:49:38 | INFO | train | epoch 547 | loss 1.643 | nll_loss 0.266 | ppl 1.2 | wps 25154 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26616 | lr 0.000193833 | gnorm 0.372 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 69236
2022-03-07 09:49:38 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 09:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:50:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:51:43 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.441 | nll_loss 12.969 | ppl 8017.79 | wps 44294.3 | wpb 510.9 | bsz 1 | num_updates 26664 | best_loss 8.725
2022-03-07 09:51:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26664 updates
2022-03-07 09:51:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:51:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:51:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 548 @ 26664 updates, score 13.441) (writing took 1.8634635666385293 seconds)
2022-03-07 09:51:45 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 09:51:45 | INFO | train | epoch 548 | loss 1.643 | nll_loss 0.265 | ppl 1.2 | wps 24599.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 26664 | lr 0.000193659 | gnorm 0.371 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 69363
2022-03-07 09:51:45 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 09:51:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:14 | INFO | train_inner | epoch 549:     36 / 49 loss=1.643, nll_loss=0.266, ppl=1.2, wps=24909.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.374, loss_scale=32, train_wall=223, gb_free=8.8, wall=69452
2022-03-07 09:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:49 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.441 | nll_loss 12.973 | ppl 8042.5 | wps 44020.8 | wpb 510.9 | bsz 1 | num_updates 26713 | best_loss 8.725
2022-03-07 09:53:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26713 updates
2022-03-07 09:53:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 549 @ 26713 updates, score 13.441) (writing took 1.710574404336512 seconds)
2022-03-07 09:53:51 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 09:53:51 | INFO | train | epoch 549 | loss 1.643 | nll_loss 0.265 | ppl 1.2 | wps 25137.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26713 | lr 0.000193481 | gnorm 0.373 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 69489
2022-03-07 09:53:51 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 09:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:55:56 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.446 | nll_loss 12.974 | ppl 8046.52 | wps 43966.7 | wpb 510.9 | bsz 1 | num_updates 26762 | best_loss 8.725
2022-03-07 09:55:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26762 updates
2022-03-07 09:55:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 550 @ 26762 updates, score 13.446) (writing took 1.7333117220550776 seconds)
2022-03-07 09:55:58 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 09:55:58 | INFO | train | epoch 550 | loss 1.642 | nll_loss 0.265 | ppl 1.2 | wps 25128.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26762 | lr 0.000193304 | gnorm 0.376 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 69616
2022-03-07 09:55:58 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 09:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:56:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:57:34 | INFO | train_inner | epoch 551:     39 / 49 loss=1.642, nll_loss=0.265, ppl=1.2, wps=24928.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.374, loss_scale=32, train_wall=223, gb_free=8.8, wall=69712
2022-03-07 09:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:58:02 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.407 | nll_loss 12.937 | ppl 7842.42 | wps 44056.2 | wpb 510.9 | bsz 1 | num_updates 26810 | best_loss 8.725
2022-03-07 09:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26810 updates
2022-03-07 09:58:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:58:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 551 @ 26810 updates, score 13.407) (writing took 1.85290755238384 seconds)
2022-03-07 09:58:04 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 09:58:04 | INFO | train | epoch 551 | loss 1.641 | nll_loss 0.264 | ppl 1.2 | wps 24603.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 26810 | lr 0.000193131 | gnorm 0.375 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 69742
2022-03-07 09:58:04 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 09:58:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:00:09 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.436 | nll_loss 12.968 | ppl 8010.98 | wps 43683.2 | wpb 510.9 | bsz 1 | num_updates 26859 | best_loss 8.725
2022-03-07 10:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26859 updates
2022-03-07 10:00:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 552 @ 26859 updates, score 13.436) (writing took 1.9735369570553303 seconds)
2022-03-07 10:00:11 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 10:00:11 | INFO | train | epoch 552 | loss 1.641 | nll_loss 0.264 | ppl 1.2 | wps 25065.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26859 | lr 0.000192955 | gnorm 0.372 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 69869
2022-03-07 10:00:11 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 10:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:01:53 | INFO | train_inner | epoch 553:     41 / 49 loss=1.641, nll_loss=0.264, ppl=1.2, wps=25061.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.373, loss_scale=32, train_wall=222, gb_free=8.8, wall=69971
2022-03-07 10:02:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:02:16 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.449 | nll_loss 12.985 | ppl 8106.78 | wps 44068.9 | wpb 510.9 | bsz 1 | num_updates 26907 | best_loss 8.725
2022-03-07 10:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26907 updates
2022-03-07 10:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 553 @ 26907 updates, score 13.449) (writing took 1.7358486466109753 seconds)
2022-03-07 10:02:18 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 10:02:18 | INFO | train | epoch 553 | loss 1.641 | nll_loss 0.265 | ppl 1.2 | wps 24505.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 26907 | lr 0.000192782 | gnorm 0.372 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 69996
2022-03-07 10:02:18 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 10:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:04:23 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.387 | nll_loss 12.919 | ppl 7742.74 | wps 43923.8 | wpb 510.9 | bsz 1 | num_updates 26956 | best_loss 8.725
2022-03-07 10:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26956 updates
2022-03-07 10:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 554 @ 26956 updates, score 13.387) (writing took 1.822353438474238 seconds)
2022-03-07 10:04:25 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 10:04:25 | INFO | train | epoch 554 | loss 1.641 | nll_loss 0.264 | ppl 1.2 | wps 25068.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 26956 | lr 0.000192607 | gnorm 0.37 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 70123
2022-03-07 10:04:25 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 10:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:06:14 | INFO | train_inner | epoch 555:     44 / 49 loss=1.641, nll_loss=0.265, ppl=1.2, wps=24873.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.373, loss_scale=32, train_wall=224, gb_free=8.8, wall=70232
2022-03-07 10:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:06:30 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.377 | nll_loss 12.907 | ppl 7679.09 | wps 43663.1 | wpb 510.9 | bsz 1 | num_updates 27005 | best_loss 8.725
2022-03-07 10:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27005 updates
2022-03-07 10:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:06:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 555 @ 27005 updates, score 13.377) (writing took 1.7938147969543934 seconds)
2022-03-07 10:06:31 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 10:06:31 | INFO | train | epoch 555 | loss 1.641 | nll_loss 0.264 | ppl 1.2 | wps 25076 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27005 | lr 0.000192432 | gnorm 0.376 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 70250
2022-03-07 10:06:32 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 10:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:07:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:36 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.322 | nll_loss 12.845 | ppl 7359.54 | wps 43746.9 | wpb 510.9 | bsz 1 | num_updates 27053 | best_loss 8.725
2022-03-07 10:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27053 updates
2022-03-07 10:08:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:08:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:08:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 556 @ 27053 updates, score 13.322) (writing took 1.7438130602240562 seconds)
2022-03-07 10:08:38 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 10:08:38 | INFO | train | epoch 556 | loss 1.64 | nll_loss 0.264 | ppl 1.2 | wps 24570.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27053 | lr 0.000192261 | gnorm 0.377 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 70376
2022-03-07 10:08:38 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 10:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:10:35 | INFO | train_inner | epoch 557:     47 / 49 loss=1.64, nll_loss=0.264, ppl=1.2, wps=24853.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.376, loss_scale=32, train_wall=224, gb_free=8.8, wall=70493
2022-03-07 10:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:10:43 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.402 | nll_loss 12.932 | ppl 7816.88 | wps 44424.7 | wpb 510.9 | bsz 1 | num_updates 27102 | best_loss 8.725
2022-03-07 10:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27102 updates
2022-03-07 10:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 557 @ 27102 updates, score 13.402) (writing took 1.7434603655710816 seconds)
2022-03-07 10:10:45 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 10:10:45 | INFO | train | epoch 557 | loss 1.64 | nll_loss 0.264 | ppl 1.2 | wps 25062.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27102 | lr 0.000192088 | gnorm 0.374 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 70503
2022-03-07 10:10:45 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 10:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:12:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:50 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.332 | nll_loss 12.858 | ppl 7422.8 | wps 44003.7 | wpb 510.9 | bsz 1 | num_updates 27151 | best_loss 8.725
2022-03-07 10:12:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27151 updates
2022-03-07 10:12:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:12:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:12:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 558 @ 27151 updates, score 13.332) (writing took 1.7328600427135825 seconds)
2022-03-07 10:12:51 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 10:12:51 | INFO | train | epoch 558 | loss 1.639 | nll_loss 0.263 | ppl 1.2 | wps 25120.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27151 | lr 0.000191914 | gnorm 0.372 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 70630
2022-03-07 10:12:51 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 10:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:14:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:14:56 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.43 | nll_loss 12.961 | ppl 7971.01 | wps 44092.3 | wpb 510.9 | bsz 1 | num_updates 27199 | best_loss 8.725
2022-03-07 10:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27199 updates
2022-03-07 10:14:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:14:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:14:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 559 @ 27199 updates, score 13.43) (writing took 1.9190645338967443 seconds)
2022-03-07 10:14:58 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 10:14:58 | INFO | train | epoch 559 | loss 1.64 | nll_loss 0.263 | ppl 1.2 | wps 24551.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27199 | lr 0.000191745 | gnorm 0.373 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 70756
2022-03-07 10:14:58 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 10:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:15:01 | INFO | train_inner | epoch 560:      1 / 49 loss=1.64, nll_loss=0.263, ppl=1.2, wps=24239.4, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=27200, lr=0.000191741, gnorm=0.374, loss_scale=32, train_wall=223, gb_free=8.8, wall=70759
2022-03-07 10:16:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:03 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.363 | nll_loss 12.891 | ppl 7596.63 | wps 43799.9 | wpb 510.9 | bsz 1 | num_updates 27248 | best_loss 8.725
2022-03-07 10:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27248 updates
2022-03-07 10:17:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 560 @ 27248 updates, score 13.363) (writing took 1.9117739172652364 seconds)
2022-03-07 10:17:05 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 10:17:05 | INFO | train | epoch 560 | loss 1.639 | nll_loss 0.263 | ppl 1.2 | wps 25051.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27248 | lr 0.000191572 | gnorm 0.37 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 70883
2022-03-07 10:17:05 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 10:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:19:10 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.388 | nll_loss 12.915 | ppl 7721.71 | wps 44049.4 | wpb 510.9 | bsz 1 | num_updates 27297 | best_loss 8.725
2022-03-07 10:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27297 updates
2022-03-07 10:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:19:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 561 @ 27297 updates, score 13.388) (writing took 2.190447637811303 seconds)
2022-03-07 10:19:12 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 10:19:12 | INFO | train | epoch 561 | loss 1.64 | nll_loss 0.263 | ppl 1.2 | wps 24985.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27297 | lr 0.0001914 | gnorm 0.374 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 71011
2022-03-07 10:19:12 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 10:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:19:22 | INFO | train_inner | epoch 562:      4 / 49 loss=1.639, nll_loss=0.263, ppl=1.2, wps=24810.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.373, loss_scale=32, train_wall=224, gb_free=8.8, wall=71021
2022-03-07 10:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:21:17 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.422 | nll_loss 12.949 | ppl 7908.81 | wps 44056.1 | wpb 510.9 | bsz 1 | num_updates 27345 | best_loss 8.725
2022-03-07 10:21:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27345 updates
2022-03-07 10:21:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:21:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 562 @ 27345 updates, score 13.422) (writing took 1.7462427634745836 seconds)
2022-03-07 10:21:19 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 10:21:19 | INFO | train | epoch 562 | loss 1.638 | nll_loss 0.262 | ppl 1.2 | wps 24572.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27345 | lr 0.000191232 | gnorm 0.369 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 71137
2022-03-07 10:21:19 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 10:21:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:23:24 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.408 | nll_loss 12.938 | ppl 7849.67 | wps 43836 | wpb 510.9 | bsz 1 | num_updates 27394 | best_loss 8.725
2022-03-07 10:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27394 updates
2022-03-07 10:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 563 @ 27394 updates, score 13.408) (writing took 1.8495090659707785 seconds)
2022-03-07 10:23:26 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 10:23:26 | INFO | train | epoch 563 | loss 1.638 | nll_loss 0.262 | ppl 1.2 | wps 25063.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27394 | lr 0.000191061 | gnorm 0.375 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 71264
2022-03-07 10:23:26 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 10:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:23:41 | INFO | train_inner | epoch 564:      6 / 49 loss=1.638, nll_loss=0.262, ppl=1.2, wps=25104.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.372, loss_scale=32, train_wall=222, gb_free=8.8, wall=71279
2022-03-07 10:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:25:31 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.384 | nll_loss 12.916 | ppl 7730.38 | wps 44177.1 | wpb 510.9 | bsz 1 | num_updates 27443 | best_loss 8.725
2022-03-07 10:25:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27443 updates
2022-03-07 10:25:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:25:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:25:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 564 @ 27443 updates, score 13.384) (writing took 1.9302349705249071 seconds)
2022-03-07 10:25:33 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 10:25:33 | INFO | train | epoch 564 | loss 1.638 | nll_loss 0.262 | ppl 1.2 | wps 25036.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27443 | lr 0.00019089 | gnorm 0.373 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 71391
2022-03-07 10:25:33 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 10:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:38 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.366 | nll_loss 12.891 | ppl 7594.8 | wps 43983.3 | wpb 510.9 | bsz 1 | num_updates 27491 | best_loss 8.725
2022-03-07 10:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27491 updates
2022-03-07 10:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:27:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:27:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 565 @ 27491 updates, score 13.366) (writing took 1.8005246799439192 seconds)
2022-03-07 10:27:39 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 10:27:39 | INFO | train | epoch 565 | loss 1.637 | nll_loss 0.262 | ppl 1.2 | wps 24553.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27491 | lr 0.000190724 | gnorm 0.37 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 71518
2022-03-07 10:27:40 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 10:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:28:02 | INFO | train_inner | epoch 566:      9 / 49 loss=1.637, nll_loss=0.262, ppl=1.2, wps=24846.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.371, loss_scale=32, train_wall=224, gb_free=8.8, wall=71540
2022-03-07 10:29:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:29:44 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.383 | nll_loss 12.914 | ppl 7715.3 | wps 44300.3 | wpb 510.9 | bsz 1 | num_updates 27540 | best_loss 8.725
2022-03-07 10:29:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27540 updates
2022-03-07 10:29:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:29:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 566 @ 27540 updates, score 13.383) (writing took 1.8699405463412404 seconds)
2022-03-07 10:29:46 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 10:29:46 | INFO | train | epoch 566 | loss 1.637 | nll_loss 0.262 | ppl 1.2 | wps 25058.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27540 | lr 0.000190554 | gnorm 0.371 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 71645
2022-03-07 10:29:46 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 10:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:51 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.398 | nll_loss 12.928 | ppl 7793.74 | wps 44329 | wpb 510.9 | bsz 1 | num_updates 27589 | best_loss 8.725
2022-03-07 10:31:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27589 updates
2022-03-07 10:31:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:31:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:31:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 567 @ 27589 updates, score 13.398) (writing took 1.8035988621413708 seconds)
2022-03-07 10:31:53 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 10:31:53 | INFO | train | epoch 567 | loss 1.637 | nll_loss 0.262 | ppl 1.2 | wps 25104.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27589 | lr 0.000190385 | gnorm 0.37 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 71771
2022-03-07 10:31:53 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 10:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:32:20 | INFO | train_inner | epoch 568:     11 / 49 loss=1.637, nll_loss=0.262, ppl=1.2, wps=25114.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.371, loss_scale=32, train_wall=221, gb_free=8.8, wall=71798
2022-03-07 10:33:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:33:58 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.446 | nll_loss 12.98 | ppl 8077.13 | wps 44108.2 | wpb 510.9 | bsz 1 | num_updates 27637 | best_loss 8.725
2022-03-07 10:33:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27637 updates
2022-03-07 10:33:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:33:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 568 @ 27637 updates, score 13.446) (writing took 1.7006868897005916 seconds)
2022-03-07 10:33:59 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 10:33:59 | INFO | train | epoch 568 | loss 1.637 | nll_loss 0.262 | ppl 1.2 | wps 24626 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27637 | lr 0.000190219 | gnorm 0.368 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 71898
2022-03-07 10:33:59 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 10:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:36:04 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.363 | nll_loss 12.895 | ppl 7615.27 | wps 43947.2 | wpb 510.9 | bsz 1 | num_updates 27686 | best_loss 8.725
2022-03-07 10:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27686 updates
2022-03-07 10:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 569 @ 27686 updates, score 13.363) (writing took 1.6941656926646829 seconds)
2022-03-07 10:36:06 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 10:36:06 | INFO | train | epoch 569 | loss 1.637 | nll_loss 0.261 | ppl 1.2 | wps 25115.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27686 | lr 0.000190051 | gnorm 0.376 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 72024
2022-03-07 10:36:06 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 10:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:36:41 | INFO | train_inner | epoch 570:     14 / 49 loss=1.637, nll_loss=0.261, ppl=1.2, wps=24909.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.371, loss_scale=32, train_wall=224, gb_free=8.8, wall=72059
2022-03-07 10:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:38:11 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.441 | nll_loss 12.972 | ppl 8036.39 | wps 43907.2 | wpb 510.9 | bsz 1 | num_updates 27735 | best_loss 8.725
2022-03-07 10:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27735 updates
2022-03-07 10:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 570 @ 27735 updates, score 13.441) (writing took 1.8374021090567112 seconds)
2022-03-07 10:38:13 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 10:38:13 | INFO | train | epoch 570 | loss 1.636 | nll_loss 0.26 | ppl 1.2 | wps 25050.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27735 | lr 0.000189883 | gnorm 0.369 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 72151
2022-03-07 10:38:13 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 10:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:40:17 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.423 | nll_loss 12.956 | ppl 7944.7 | wps 44387.1 | wpb 510.9 | bsz 1 | num_updates 27783 | best_loss 8.725
2022-03-07 10:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27783 updates
2022-03-07 10:40:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:40:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:40:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 571 @ 27783 updates, score 13.423) (writing took 1.779270313680172 seconds)
2022-03-07 10:40:19 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 10:40:19 | INFO | train | epoch 571 | loss 1.636 | nll_loss 0.261 | ppl 1.2 | wps 24598.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27783 | lr 0.000189719 | gnorm 0.374 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 72277
2022-03-07 10:40:19 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 10:40:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:41:01 | INFO | train_inner | epoch 572:     17 / 49 loss=1.636, nll_loss=0.261, ppl=1.2, wps=24878.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.374, loss_scale=32, train_wall=224, gb_free=8.8, wall=72319
2022-03-07 10:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:42:24 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.39 | nll_loss 12.921 | ppl 7756.39 | wps 44196.4 | wpb 510.9 | bsz 1 | num_updates 27832 | best_loss 8.725
2022-03-07 10:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27832 updates
2022-03-07 10:42:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 572 @ 27832 updates, score 13.39) (writing took 1.8565451251342893 seconds)
2022-03-07 10:42:26 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 10:42:26 | INFO | train | epoch 572 | loss 1.636 | nll_loss 0.261 | ppl 1.2 | wps 25108.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27832 | lr 0.000189552 | gnorm 0.373 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 72404
2022-03-07 10:42:26 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 10:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:44:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:44:30 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.364 | nll_loss 12.894 | ppl 7610.44 | wps 44218.1 | wpb 510.9 | bsz 1 | num_updates 27880 | best_loss 8.725
2022-03-07 10:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27880 updates
2022-03-07 10:44:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 573 @ 27880 updates, score 13.364) (writing took 1.6968267522752285 seconds)
2022-03-07 10:44:32 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 10:44:32 | INFO | train | epoch 573 | loss 1.636 | nll_loss 0.26 | ppl 1.2 | wps 24631.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27880 | lr 0.000189389 | gnorm 0.369 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 72530
2022-03-07 10:44:32 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 10:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:45:21 | INFO | train_inner | epoch 574:     20 / 49 loss=1.636, nll_loss=0.26, ppl=1.2, wps=24928, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.369, loss_scale=32, train_wall=223, gb_free=8.8, wall=72580
2022-03-07 10:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:37 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.419 | nll_loss 12.952 | ppl 7924.91 | wps 44188.5 | wpb 510.9 | bsz 1 | num_updates 27929 | best_loss 8.725
2022-03-07 10:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27929 updates
2022-03-07 10:46:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:46:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:46:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 574 @ 27929 updates, score 13.419) (writing took 2.006096752360463 seconds)
2022-03-07 10:46:39 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 10:46:39 | INFO | train | epoch 574 | loss 1.635 | nll_loss 0.26 | ppl 1.2 | wps 25106.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27929 | lr 0.000189222 | gnorm 0.371 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 72657
2022-03-07 10:46:39 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 10:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:48:43 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.316 | nll_loss 12.84 | ppl 7333.94 | wps 43504.1 | wpb 510.9 | bsz 1 | num_updates 27978 | best_loss 8.725
2022-03-07 10:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27978 updates
2022-03-07 10:48:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:48:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 575 @ 27978 updates, score 13.316) (writing took 1.7911087283864617 seconds)
2022-03-07 10:48:45 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 10:48:45 | INFO | train | epoch 575 | loss 1.635 | nll_loss 0.259 | ppl 1.2 | wps 25132.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 27978 | lr 0.000189057 | gnorm 0.369 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 72783
2022-03-07 10:48:45 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 10:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:49:40 | INFO | train_inner | epoch 576:     22 / 49 loss=1.635, nll_loss=0.26, ppl=1.2, wps=25118.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.37, loss_scale=32, train_wall=221, gb_free=8.8, wall=72838
2022-03-07 10:50:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:50:50 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.374 | nll_loss 12.901 | ppl 7650.19 | wps 43971 | wpb 510.9 | bsz 1 | num_updates 28027 | best_loss 8.725
2022-03-07 10:50:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28027 updates
2022-03-07 10:50:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 576 @ 28027 updates, score 13.374) (writing took 1.7469700444489717 seconds)
2022-03-07 10:50:52 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 10:50:52 | INFO | train | epoch 576 | loss 1.635 | nll_loss 0.26 | ppl 1.2 | wps 25083.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28027 | lr 0.000188891 | gnorm 0.368 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 72910
2022-03-07 10:50:52 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 10:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:51:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:52:57 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.397 | nll_loss 12.928 | ppl 7791.29 | wps 44068.1 | wpb 510.9 | bsz 1 | num_updates 28075 | best_loss 8.725
2022-03-07 10:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28075 updates
2022-03-07 10:52:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:52:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 577 @ 28075 updates, score 13.397) (writing took 1.7218823814764619 seconds)
2022-03-07 10:52:59 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 10:52:59 | INFO | train | epoch 577 | loss 1.634 | nll_loss 0.259 | ppl 1.2 | wps 24581.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28075 | lr 0.00018873 | gnorm 0.366 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73037
2022-03-07 10:52:59 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 10:52:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:54:00 | INFO | train_inner | epoch 578:     25 / 49 loss=1.634, nll_loss=0.259, ppl=1.2, wps=24900.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.367, loss_scale=32, train_wall=224, gb_free=8.8, wall=73099
2022-03-07 10:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:03 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.34 | nll_loss 12.866 | ppl 7465.04 | wps 44018.8 | wpb 510.9 | bsz 1 | num_updates 28124 | best_loss 8.725
2022-03-07 10:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28124 updates
2022-03-07 10:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:55:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 578 @ 28124 updates, score 13.34) (writing took 1.9750671153888106 seconds)
2022-03-07 10:55:05 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 10:55:05 | INFO | train | epoch 578 | loss 1.634 | nll_loss 0.26 | ppl 1.2 | wps 25070.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28124 | lr 0.000188565 | gnorm 0.369 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 73164
2022-03-07 10:55:05 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 10:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:57:10 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 13.374 | nll_loss 12.9 | ppl 7642.48 | wps 43914.4 | wpb 510.9 | bsz 1 | num_updates 28173 | best_loss 8.725
2022-03-07 10:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28173 updates
2022-03-07 10:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:57:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:57:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 579 @ 28173 updates, score 13.374) (writing took 1.8264148458838463 seconds)
2022-03-07 10:57:12 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 10:57:12 | INFO | train | epoch 579 | loss 1.634 | nll_loss 0.259 | ppl 1.2 | wps 25068.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28173 | lr 0.000188401 | gnorm 0.37 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 73290
2022-03-07 10:57:12 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 10:57:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:58:19 | INFO | train_inner | epoch 580:     27 / 49 loss=1.634, nll_loss=0.259, ppl=1.2, wps=25096.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.369, loss_scale=64, train_wall=222, gb_free=8.8, wall=73357
2022-03-07 10:58:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:59:17 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 13.412 | nll_loss 12.948 | ppl 7904.11 | wps 43993.7 | wpb 510.9 | bsz 1 | num_updates 28221 | best_loss 8.725
2022-03-07 10:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28221 updates
2022-03-07 10:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 580 @ 28221 updates, score 13.412) (writing took 1.7329308148473501 seconds)
2022-03-07 10:59:19 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 10:59:19 | INFO | train | epoch 580 | loss 1.634 | nll_loss 0.259 | ppl 1.2 | wps 24556.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28221 | lr 0.000188241 | gnorm 0.37 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73417
2022-03-07 10:59:19 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 10:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:01:24 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 13.414 | nll_loss 12.943 | ppl 7876.95 | wps 43833.6 | wpb 510.9 | bsz 1 | num_updates 28270 | best_loss 8.725
2022-03-07 11:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28270 updates
2022-03-07 11:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 581 @ 28270 updates, score 13.414) (writing took 1.8491229061037302 seconds)
2022-03-07 11:01:26 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 11:01:26 | INFO | train | epoch 581 | loss 1.633 | nll_loss 0.259 | ppl 1.2 | wps 25070.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28270 | lr 0.000188078 | gnorm 0.372 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73544
2022-03-07 11:01:26 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 11:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:02:40 | INFO | train_inner | epoch 582:     30 / 49 loss=1.633, nll_loss=0.259, ppl=1.2, wps=24852.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.37, loss_scale=32, train_wall=224, gb_free=8.8, wall=73618
2022-03-07 11:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:03:31 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 13.352 | nll_loss 12.88 | ppl 7539.33 | wps 44091.8 | wpb 510.9 | bsz 1 | num_updates 28319 | best_loss 8.725
2022-03-07 11:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28319 updates
2022-03-07 11:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:03:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:03:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 582 @ 28319 updates, score 13.352) (writing took 1.9275525975972414 seconds)
2022-03-07 11:03:32 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 11:03:32 | INFO | train | epoch 582 | loss 1.634 | nll_loss 0.259 | ppl 1.2 | wps 25047.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28319 | lr 0.000187915 | gnorm 0.368 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73671
2022-03-07 11:03:32 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 11:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:04:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:37 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 13.325 | nll_loss 12.855 | ppl 7407.01 | wps 44373.8 | wpb 510.9 | bsz 1 | num_updates 28367 | best_loss 8.725
2022-03-07 11:05:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28367 updates
2022-03-07 11:05:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:05:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 583 @ 28367 updates, score 13.325) (writing took 1.8619645796716213 seconds)
2022-03-07 11:05:39 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 11:05:39 | INFO | train | epoch 583 | loss 1.632 | nll_loss 0.258 | ppl 1.2 | wps 24578.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28367 | lr 0.000187756 | gnorm 0.368 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73797
2022-03-07 11:05:39 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 11:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:07:01 | INFO | train_inner | epoch 584:     33 / 49 loss=1.633, nll_loss=0.259, ppl=1.2, wps=24865.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.371, loss_scale=32, train_wall=224, gb_free=8.8, wall=73879
2022-03-07 11:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:07:44 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 13.41 | nll_loss 12.945 | ppl 7883.24 | wps 44222.6 | wpb 510.9 | bsz 1 | num_updates 28416 | best_loss 8.725
2022-03-07 11:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28416 updates
2022-03-07 11:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 584 @ 28416 updates, score 13.41) (writing took 1.888129954226315 seconds)
2022-03-07 11:07:46 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 11:07:46 | INFO | train | epoch 584 | loss 1.633 | nll_loss 0.258 | ppl 1.2 | wps 25058.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28416 | lr 0.000187594 | gnorm 0.37 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 73924
2022-03-07 11:07:46 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 11:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:09:51 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 13.447 | nll_loss 12.98 | ppl 8077.36 | wps 44452.4 | wpb 510.9 | bsz 1 | num_updates 28465 | best_loss 8.725
2022-03-07 11:09:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28465 updates
2022-03-07 11:09:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:09:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:09:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 585 @ 28465 updates, score 13.447) (writing took 1.7906023915857077 seconds)
2022-03-07 11:09:53 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 11:09:53 | INFO | train | epoch 585 | loss 1.632 | nll_loss 0.258 | ppl 1.2 | wps 25073.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28465 | lr 0.000187432 | gnorm 0.361 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 74051
2022-03-07 11:09:53 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 11:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:10:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:11:22 | INFO | train_inner | epoch 586:     36 / 49 loss=1.632, nll_loss=0.258, ppl=1.2, wps=24845, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.363, loss_scale=32, train_wall=224, gb_free=8.8, wall=74140
2022-03-07 11:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:11:58 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 13.413 | nll_loss 12.944 | ppl 7882.84 | wps 43646.2 | wpb 510.9 | bsz 1 | num_updates 28513 | best_loss 8.725
2022-03-07 11:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28513 updates
2022-03-07 11:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:11:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 586 @ 28513 updates, score 13.413) (writing took 1.8021867256611586 seconds)
2022-03-07 11:12:00 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 11:12:00 | INFO | train | epoch 586 | loss 1.632 | nll_loss 0.258 | ppl 1.2 | wps 24537.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28513 | lr 0.000187274 | gnorm 0.366 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 74178
2022-03-07 11:12:00 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 11:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:13:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:14:04 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 13.387 | nll_loss 12.913 | ppl 7711.62 | wps 43884.3 | wpb 510.9 | bsz 1 | num_updates 28562 | best_loss 8.725
2022-03-07 11:14:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28562 updates
2022-03-07 11:14:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 587 @ 28562 updates, score 13.387) (writing took 1.7273041112348437 seconds)
2022-03-07 11:14:06 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 11:14:06 | INFO | train | epoch 587 | loss 1.632 | nll_loss 0.258 | ppl 1.2 | wps 25109.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28562 | lr 0.000187114 | gnorm 0.37 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 74304
2022-03-07 11:14:06 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 11:14:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:15:40 | INFO | train_inner | epoch 588:     38 / 49 loss=1.632, nll_loss=0.258, ppl=1.2, wps=25123, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.37, loss_scale=32, train_wall=222, gb_free=8.8, wall=74398
2022-03-07 11:15:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:16:11 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 13.444 | nll_loss 12.978 | ppl 8069.35 | wps 44703.7 | wpb 510.9 | bsz 1 | num_updates 28610 | best_loss 8.725
2022-03-07 11:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28610 updates
2022-03-07 11:16:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 588 @ 28610 updates, score 13.444) (writing took 1.804354795254767 seconds)
2022-03-07 11:16:13 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 11:16:13 | INFO | train | epoch 588 | loss 1.632 | nll_loss 0.258 | ppl 1.2 | wps 24599.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28610 | lr 0.000186957 | gnorm 0.371 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 74431
2022-03-07 11:16:13 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 11:16:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:18:17 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 13.393 | nll_loss 12.925 | ppl 7778.34 | wps 44002.4 | wpb 510.9 | bsz 1 | num_updates 28659 | best_loss 8.725
2022-03-07 11:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28659 updates
2022-03-07 11:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 589 @ 28659 updates, score 13.393) (writing took 2.2950782189145684 seconds)
2022-03-07 11:18:19 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 11:18:19 | INFO | train | epoch 589 | loss 1.631 | nll_loss 0.257 | ppl 1.2 | wps 25048.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28659 | lr 0.000186797 | gnorm 0.366 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 74558
2022-03-07 11:18:19 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 11:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:20:01 | INFO | train_inner | epoch 590:     41 / 49 loss=1.631, nll_loss=0.257, ppl=1.2, wps=24880.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.366, loss_scale=32, train_wall=223, gb_free=8.8, wall=74659
2022-03-07 11:20:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:20:24 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 13.389 | nll_loss 12.92 | ppl 7752.42 | wps 44224.4 | wpb 510.9 | bsz 1 | num_updates 28708 | best_loss 8.725
2022-03-07 11:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28708 updates
2022-03-07 11:20:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 590 @ 28708 updates, score 13.389) (writing took 1.695516161620617 seconds)
2022-03-07 11:20:26 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 11:20:26 | INFO | train | epoch 590 | loss 1.631 | nll_loss 0.257 | ppl 1.2 | wps 25135.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28708 | lr 0.000186637 | gnorm 0.362 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 74684
2022-03-07 11:20:26 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 11:20:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:22:31 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 13.41 | nll_loss 12.941 | ppl 7861.13 | wps 44201.7 | wpb 510.9 | bsz 1 | num_updates 28756 | best_loss 8.725
2022-03-07 11:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28756 updates
2022-03-07 11:22:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:22:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 591 @ 28756 updates, score 13.41) (writing took 1.7687301747500896 seconds)
2022-03-07 11:22:32 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 11:22:32 | INFO | train | epoch 591 | loss 1.631 | nll_loss 0.257 | ppl 1.19 | wps 24610.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28756 | lr 0.000186482 | gnorm 0.362 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 74811
2022-03-07 11:22:32 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 11:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:24:21 | INFO | train_inner | epoch 592:     44 / 49 loss=1.631, nll_loss=0.257, ppl=1.2, wps=24925.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.364, loss_scale=32, train_wall=223, gb_free=8.8, wall=74919
2022-03-07 11:24:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:24:37 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 13.405 | nll_loss 12.937 | ppl 7843.35 | wps 43815.2 | wpb 510.9 | bsz 1 | num_updates 28805 | best_loss 8.725
2022-03-07 11:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28805 updates
2022-03-07 11:24:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 592 @ 28805 updates, score 13.405) (writing took 1.7880004569888115 seconds)
2022-03-07 11:24:39 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 11:24:39 | INFO | train | epoch 592 | loss 1.631 | nll_loss 0.257 | ppl 1.19 | wps 25111 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28805 | lr 0.000186323 | gnorm 0.366 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 74937
2022-03-07 11:24:39 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 11:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:26:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:26:44 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 13.43 | nll_loss 12.964 | ppl 7987.69 | wps 43875.7 | wpb 510.9 | bsz 1 | num_updates 28854 | best_loss 8.725
2022-03-07 11:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28854 updates
2022-03-07 11:26:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 593 @ 28854 updates, score 13.43) (writing took 2.0412711687386036 seconds)
2022-03-07 11:26:46 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 11:26:46 | INFO | train | epoch 593 | loss 1.63 | nll_loss 0.256 | ppl 1.19 | wps 25049.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28854 | lr 0.000186165 | gnorm 0.366 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 75064
2022-03-07 11:26:46 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 11:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:28:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:28:42 | INFO | train_inner | epoch 594:     47 / 49 loss=1.63, nll_loss=0.257, ppl=1.19, wps=24861, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28900, lr=0.000186016, gnorm=0.367, loss_scale=32, train_wall=224, gb_free=8.8, wall=75180
2022-03-07 11:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:28:51 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 13.428 | nll_loss 12.962 | ppl 7980.94 | wps 44285.4 | wpb 510.9 | bsz 1 | num_updates 28902 | best_loss 8.725
2022-03-07 11:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28902 updates
2022-03-07 11:28:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 594 @ 28902 updates, score 13.428) (writing took 1.8439828399568796 seconds)
2022-03-07 11:28:52 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 11:28:52 | INFO | train | epoch 594 | loss 1.63 | nll_loss 0.257 | ppl 1.19 | wps 24575.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28902 | lr 0.00018601 | gnorm 0.368 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 75191
2022-03-07 11:28:52 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 11:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:30:57 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 13.326 | nll_loss 12.852 | ppl 7393.4 | wps 44413.9 | wpb 510.9 | bsz 1 | num_updates 28951 | best_loss 8.725
2022-03-07 11:30:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28951 updates
2022-03-07 11:30:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 595 @ 28951 updates, score 13.326) (writing took 1.7279606591910124 seconds)
2022-03-07 11:30:59 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 11:30:59 | INFO | train | epoch 595 | loss 1.63 | nll_loss 0.256 | ppl 1.19 | wps 25144 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 28951 | lr 0.000185852 | gnorm 0.37 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 75317
2022-03-07 11:30:59 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 11:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:32:59 | INFO | train_inner | epoch 596:     49 / 49 loss=1.63, nll_loss=0.256, ppl=1.19, wps=25152.2, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=29000, lr=0.000185695, gnorm=0.367, loss_scale=32, train_wall=220, gb_free=8.8, wall=75437
2022-03-07 11:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:33:04 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 13.426 | nll_loss 12.958 | ppl 7955.49 | wps 44315.9 | wpb 510.9 | bsz 1 | num_updates 29000 | best_loss 8.725
2022-03-07 11:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 29000 updates
2022-03-07 11:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:33:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:33:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 596 @ 29000 updates, score 13.426) (writing took 1.746848619543016 seconds)
2022-03-07 11:33:05 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 11:33:05 | INFO | train | epoch 596 | loss 1.629 | nll_loss 0.256 | ppl 1.19 | wps 25141.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29000 | lr 0.000185695 | gnorm 0.362 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 75444
2022-03-07 11:33:05 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 11:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:35:10 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 13.311 | nll_loss 12.838 | ppl 7322.72 | wps 44073.1 | wpb 510.9 | bsz 1 | num_updates 29049 | best_loss 8.725
2022-03-07 11:35:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29049 updates
2022-03-07 11:35:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:35:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:35:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 597 @ 29049 updates, score 13.311) (writing took 1.8639217279851437 seconds)
2022-03-07 11:35:12 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 11:35:12 | INFO | train | epoch 597 | loss 1.63 | nll_loss 0.256 | ppl 1.19 | wps 25104 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29049 | lr 0.000185539 | gnorm 0.365 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 75570
2022-03-07 11:35:12 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 11:35:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:37:17 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 13.441 | nll_loss 12.975 | ppl 8049.58 | wps 43584.8 | wpb 510.9 | bsz 1 | num_updates 29097 | best_loss 8.725
2022-03-07 11:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29097 updates
2022-03-07 11:37:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:37:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:37:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 598 @ 29097 updates, score 13.441) (writing took 2.1627767207100987 seconds)
2022-03-07 11:37:19 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 11:37:19 | INFO | train | epoch 598 | loss 1.629 | nll_loss 0.256 | ppl 1.19 | wps 24466.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29097 | lr 0.000185386 | gnorm 0.363 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 75697
2022-03-07 11:37:19 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 11:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:37:27 | INFO | train_inner | epoch 599:      3 / 49 loss=1.629, nll_loss=0.256, ppl=1.19, wps=24200, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.364, loss_scale=32, train_wall=224, gb_free=8.8, wall=75705
2022-03-07 11:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:39:24 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 13.555 | nll_loss 13.097 | ppl 8763.14 | wps 43840.3 | wpb 510.9 | bsz 1 | num_updates 29146 | best_loss 8.725
2022-03-07 11:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29146 updates
2022-03-07 11:39:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:39:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:39:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 599 @ 29146 updates, score 13.555) (writing took 1.7351143769919872 seconds)
2022-03-07 11:39:26 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 11:39:26 | INFO | train | epoch 599 | loss 1.629 | nll_loss 0.256 | ppl 1.19 | wps 25073.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29146 | lr 0.00018523 | gnorm 0.376 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 75824
2022-03-07 11:39:26 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 11:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:41:31 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 13.382 | nll_loss 12.912 | ppl 7708.42 | wps 44306.5 | wpb 510.9 | bsz 1 | num_updates 29195 | best_loss 8.725
2022-03-07 11:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29195 updates
2022-03-07 11:41:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:41:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 600 @ 29195 updates, score 13.382) (writing took 1.8310728762298822 seconds)
2022-03-07 11:41:33 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 11:41:33 | INFO | train | epoch 600 | loss 1.628 | nll_loss 0.255 | ppl 1.19 | wps 25085.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29195 | lr 0.000185074 | gnorm 0.361 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 75951
2022-03-07 11:41:33 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 11:41:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:45 | INFO | train_inner | epoch 601:      5 / 49 loss=1.629, nll_loss=0.256, ppl=1.19, wps=25107.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.368, loss_scale=32, train_wall=222, gb_free=8.8, wall=75963
2022-03-07 11:43:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:37 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 13.401 | nll_loss 12.935 | ppl 7830.83 | wps 44358.5 | wpb 510.9 | bsz 1 | num_updates 29243 | best_loss 8.725
2022-03-07 11:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29243 updates
2022-03-07 11:43:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 601 @ 29243 updates, score 13.401) (writing took 1.780339757911861 seconds)
2022-03-07 11:43:39 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 11:43:39 | INFO | train | epoch 601 | loss 1.628 | nll_loss 0.255 | ppl 1.19 | wps 24566.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29243 | lr 0.000184922 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 76077
2022-03-07 11:43:39 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 11:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:45:44 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 13.387 | nll_loss 12.924 | ppl 7773.71 | wps 43824.3 | wpb 510.9 | bsz 1 | num_updates 29292 | best_loss 8.725
2022-03-07 11:45:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29292 updates
2022-03-07 11:45:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 602 @ 29292 updates, score 13.387) (writing took 1.7541067637503147 seconds)
2022-03-07 11:45:46 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 11:45:46 | INFO | train | epoch 602 | loss 1.628 | nll_loss 0.255 | ppl 1.19 | wps 25089.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29292 | lr 0.000184767 | gnorm 0.365 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 76204
2022-03-07 11:45:46 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 11:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:06 | INFO | train_inner | epoch 603:      8 / 49 loss=1.628, nll_loss=0.255, ppl=1.19, wps=24880, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.363, loss_scale=32, train_wall=224, gb_free=8.8, wall=76224
2022-03-07 11:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:47:51 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 13.423 | nll_loss 12.957 | ppl 7952.84 | wps 43720.9 | wpb 510.9 | bsz 1 | num_updates 29341 | best_loss 8.725
2022-03-07 11:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29341 updates
2022-03-07 11:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 603 @ 29341 updates, score 13.423) (writing took 1.9686887003481388 seconds)
2022-03-07 11:47:53 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 11:47:53 | INFO | train | epoch 603 | loss 1.627 | nll_loss 0.255 | ppl 1.19 | wps 25069.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29341 | lr 0.000184613 | gnorm 0.362 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 76331
2022-03-07 11:47:53 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 11:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:48:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:49:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:49:58 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 13.411 | nll_loss 12.945 | ppl 7887.08 | wps 43661.1 | wpb 510.9 | bsz 1 | num_updates 29389 | best_loss 8.725
2022-03-07 11:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29389 updates
2022-03-07 11:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 604 @ 29389 updates, score 13.411) (writing took 1.7694128891453147 seconds)
2022-03-07 11:50:00 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 11:50:00 | INFO | train | epoch 604 | loss 1.627 | nll_loss 0.254 | ppl 1.19 | wps 24523.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29389 | lr 0.000184462 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 76458
2022-03-07 11:50:00 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 11:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:50:27 | INFO | train_inner | epoch 605:     11 / 49 loss=1.627, nll_loss=0.254, ppl=1.19, wps=24848, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.361, loss_scale=32, train_wall=224, gb_free=8.8, wall=76485
2022-03-07 11:51:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:52:04 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 13.475 | nll_loss 13.011 | ppl 8254.56 | wps 43203.6 | wpb 510.9 | bsz 1 | num_updates 29438 | best_loss 8.725
2022-03-07 11:52:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29438 updates
2022-03-07 11:52:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:52:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:52:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 605 @ 29438 updates, score 13.475) (writing took 1.9820174099877477 seconds)
2022-03-07 11:52:06 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 11:52:06 | INFO | train | epoch 605 | loss 1.627 | nll_loss 0.255 | ppl 1.19 | wps 25049 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29438 | lr 0.000184309 | gnorm 0.366 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 76585
2022-03-07 11:52:06 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 11:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:54:11 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 13.375 | nll_loss 12.905 | ppl 7672.17 | wps 44157.4 | wpb 510.9 | bsz 1 | num_updates 29487 | best_loss 8.725
2022-03-07 11:54:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29487 updates
2022-03-07 11:54:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:54:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:54:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 606 @ 29487 updates, score 13.375) (writing took 1.8526911167427897 seconds)
2022-03-07 11:54:13 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 11:54:13 | INFO | train | epoch 606 | loss 1.627 | nll_loss 0.254 | ppl 1.19 | wps 25065.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29487 | lr 0.000184156 | gnorm 0.363 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 76711
2022-03-07 11:54:13 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 11:54:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:54:45 | INFO | train_inner | epoch 607:     13 / 49 loss=1.627, nll_loss=0.255, ppl=1.19, wps=25076.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.364, loss_scale=64, train_wall=222, gb_free=8.8, wall=76744
2022-03-07 11:55:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:56:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:56:18 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 13.48 | nll_loss 13.017 | ppl 8288.38 | wps 44345.9 | wpb 510.9 | bsz 1 | num_updates 29535 | best_loss 8.725
2022-03-07 11:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29535 updates
2022-03-07 11:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 607 @ 29535 updates, score 13.48) (writing took 1.9314757287502289 seconds)
2022-03-07 11:56:20 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 11:56:20 | INFO | train | epoch 607 | loss 1.626 | nll_loss 0.254 | ppl 1.19 | wps 24549.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29535 | lr 0.000184006 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 76838
2022-03-07 11:56:20 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 11:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:58:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:58:25 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 13.408 | nll_loss 12.939 | ppl 7852.38 | wps 44359.2 | wpb 510.9 | bsz 1 | num_updates 29584 | best_loss 8.725
2022-03-07 11:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29584 updates
2022-03-07 11:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 608 @ 29584 updates, score 13.408) (writing took 1.7440632237121463 seconds)
2022-03-07 11:58:27 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 11:58:27 | INFO | train | epoch 608 | loss 1.627 | nll_loss 0.255 | ppl 1.19 | wps 25113.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29584 | lr 0.000183853 | gnorm 0.359 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 76965
2022-03-07 11:58:27 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 11:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:06 | INFO | train_inner | epoch 609:     16 / 49 loss=1.626, nll_loss=0.254, ppl=1.19, wps=24886.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.36, loss_scale=32, train_wall=224, gb_free=8.8, wall=77004
2022-03-07 12:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:32 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 13.494 | nll_loss 13.033 | ppl 8383.95 | wps 43962.7 | wpb 510.9 | bsz 1 | num_updates 29633 | best_loss 8.725
2022-03-07 12:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29633 updates
2022-03-07 12:00:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:00:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:00:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 609 @ 29633 updates, score 13.494) (writing took 1.8268371736630797 seconds)
2022-03-07 12:00:33 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 12:00:33 | INFO | train | epoch 609 | loss 1.626 | nll_loss 0.254 | ppl 1.19 | wps 25058.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29633 | lr 0.000183701 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 77092
2022-03-07 12:00:33 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 12:00:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:01:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:02:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:38 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 13.415 | nll_loss 12.948 | ppl 7902.92 | wps 44179.2 | wpb 510.9 | bsz 1 | num_updates 29681 | best_loss 8.725
2022-03-07 12:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29681 updates
2022-03-07 12:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 610 @ 29681 updates, score 13.415) (writing took 1.935681775212288 seconds)
2022-03-07 12:02:40 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 12:02:40 | INFO | train | epoch 610 | loss 1.626 | nll_loss 0.253 | ppl 1.19 | wps 24580.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29681 | lr 0.000183553 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 77218
2022-03-07 12:02:40 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 12:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:03:27 | INFO | train_inner | epoch 611:     19 / 49 loss=1.626, nll_loss=0.254, ppl=1.19, wps=24876.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.362, loss_scale=32, train_wall=224, gb_free=8.8, wall=77265
2022-03-07 12:04:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:04:45 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 13.49 | nll_loss 13.028 | ppl 8354.33 | wps 44318.7 | wpb 510.9 | bsz 1 | num_updates 29730 | best_loss 8.725
2022-03-07 12:04:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29730 updates
2022-03-07 12:04:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:04:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:04:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 611 @ 29730 updates, score 13.49) (writing took 1.8709967928007245 seconds)
2022-03-07 12:04:47 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 12:04:47 | INFO | train | epoch 611 | loss 1.626 | nll_loss 0.253 | ppl 1.19 | wps 25119.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29730 | lr 0.000183401 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 77345
2022-03-07 12:04:47 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 12:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:06:51 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 13.376 | nll_loss 12.912 | ppl 7705.62 | wps 44170.8 | wpb 510.9 | bsz 1 | num_updates 29779 | best_loss 8.725
2022-03-07 12:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29779 updates
2022-03-07 12:06:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:06:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:06:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 612 @ 29779 updates, score 13.376) (writing took 1.861773444339633 seconds)
2022-03-07 12:06:53 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 12:06:53 | INFO | train | epoch 612 | loss 1.625 | nll_loss 0.253 | ppl 1.19 | wps 25115.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29779 | lr 0.00018325 | gnorm 0.364 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 77471
2022-03-07 12:06:53 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 12:06:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:07:45 | INFO | train_inner | epoch 613:     21 / 49 loss=1.625, nll_loss=0.253, ppl=1.19, wps=25139.2, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.361, loss_scale=64, train_wall=221, gb_free=8.8, wall=77523
2022-03-07 12:08:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:08:58 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 13.383 | nll_loss 12.916 | ppl 7727.31 | wps 43939.3 | wpb 510.9 | bsz 1 | num_updates 29827 | best_loss 8.725
2022-03-07 12:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29827 updates
2022-03-07 12:08:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:09:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 613 @ 29827 updates, score 13.383) (writing took 1.744959993287921 seconds)
2022-03-07 12:09:00 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 12:09:00 | INFO | train | epoch 613 | loss 1.625 | nll_loss 0.253 | ppl 1.19 | wps 24588.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29827 | lr 0.000183103 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 77598
2022-03-07 12:09:00 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 12:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:11:04 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 13.477 | nll_loss 13.014 | ppl 8269.37 | wps 44422.9 | wpb 510.9 | bsz 1 | num_updates 29876 | best_loss 8.725
2022-03-07 12:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29876 updates
2022-03-07 12:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 614 @ 29876 updates, score 13.477) (writing took 1.7336694495752454 seconds)
2022-03-07 12:11:06 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 12:11:06 | INFO | train | epoch 614 | loss 1.625 | nll_loss 0.253 | ppl 1.19 | wps 25118.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29876 | lr 0.000182953 | gnorm 0.365 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 77724
2022-03-07 12:11:06 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 12:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:12:05 | INFO | train_inner | epoch 615:     24 / 49 loss=1.626, nll_loss=0.254, ppl=1.19, wps=24908.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.365, loss_scale=32, train_wall=223, gb_free=8.8, wall=77784
2022-03-07 12:13:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:13:11 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 13.404 | nll_loss 12.94 | ppl 7856.69 | wps 44142.6 | wpb 510.9 | bsz 1 | num_updates 29925 | best_loss 8.725
2022-03-07 12:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29925 updates
2022-03-07 12:13:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:13:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 615 @ 29925 updates, score 13.404) (writing took 1.7315061325207353 seconds)
2022-03-07 12:13:13 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 12:13:13 | INFO | train | epoch 615 | loss 1.625 | nll_loss 0.253 | ppl 1.19 | wps 25151.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 29925 | lr 0.000182803 | gnorm 0.364 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 77851
2022-03-07 12:13:13 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 12:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:14:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:17 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 13.487 | nll_loss 13.027 | ppl 8343.95 | wps 44454.2 | wpb 510.9 | bsz 1 | num_updates 29973 | best_loss 8.725
2022-03-07 12:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29973 updates
2022-03-07 12:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:15:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:15:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 616 @ 29973 updates, score 13.487) (writing took 1.6880358401685953 seconds)
2022-03-07 12:15:19 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 12:15:19 | INFO | train | epoch 616 | loss 1.624 | nll_loss 0.252 | ppl 1.19 | wps 24656.9 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 29973 | lr 0.000182656 | gnorm 0.365 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 77977
2022-03-07 12:15:19 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 12:15:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:16:25 | INFO | train_inner | epoch 617:     27 / 49 loss=1.624, nll_loss=0.252, ppl=1.19, wps=24958.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.362, loss_scale=32, train_wall=223, gb_free=8.8, wall=78044
2022-03-07 12:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:17:23 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 13.473 | nll_loss 13.005 | ppl 8222.15 | wps 44462.9 | wpb 510.9 | bsz 1 | num_updates 30022 | best_loss 8.725
2022-03-07 12:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30022 updates
2022-03-07 12:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 617 @ 30022 updates, score 13.473) (writing took 1.6880356157198548 seconds)
2022-03-07 12:17:25 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 12:17:25 | INFO | train | epoch 617 | loss 1.624 | nll_loss 0.253 | ppl 1.19 | wps 25188.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30022 | lr 0.000182507 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78103
2022-03-07 12:17:25 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 12:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:30 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 13.428 | nll_loss 12.961 | ppl 7974.79 | wps 44075.1 | wpb 510.9 | bsz 1 | num_updates 30071 | best_loss 8.725
2022-03-07 12:19:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30071 updates
2022-03-07 12:19:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:19:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:19:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 618 @ 30071 updates, score 13.428) (writing took 1.6901740664616227 seconds)
2022-03-07 12:19:31 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 12:19:31 | INFO | train | epoch 618 | loss 1.624 | nll_loss 0.252 | ppl 1.19 | wps 25140.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30071 | lr 0.000182359 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78230
2022-03-07 12:19:31 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 12:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:20:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:20:45 | INFO | train_inner | epoch 619:     30 / 49 loss=1.624, nll_loss=0.252, ppl=1.19, wps=24945.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.361, loss_scale=32, train_wall=223, gb_free=8.8, wall=78304
2022-03-07 12:21:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:36 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 13.44 | nll_loss 12.976 | ppl 8054.06 | wps 43936.8 | wpb 510.9 | bsz 1 | num_updates 30119 | best_loss 8.725
2022-03-07 12:21:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30119 updates
2022-03-07 12:21:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:21:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:21:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 619 @ 30119 updates, score 13.44) (writing took 1.7868771255016327 seconds)
2022-03-07 12:21:38 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 12:21:38 | INFO | train | epoch 619 | loss 1.623 | nll_loss 0.252 | ppl 1.19 | wps 24618.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30119 | lr 0.000182213 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78356
2022-03-07 12:21:38 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 12:21:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:23:42 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 13.415 | nll_loss 12.956 | ppl 7943.51 | wps 44759.4 | wpb 510.9 | bsz 1 | num_updates 30168 | best_loss 8.725
2022-03-07 12:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30168 updates
2022-03-07 12:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:23:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:23:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 620 @ 30168 updates, score 13.415) (writing took 1.8078238628804684 seconds)
2022-03-07 12:23:44 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 12:23:44 | INFO | train | epoch 620 | loss 1.623 | nll_loss 0.252 | ppl 1.19 | wps 25158.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30168 | lr 0.000182065 | gnorm 0.365 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78482
2022-03-07 12:23:44 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 12:23:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:25:03 | INFO | train_inner | epoch 621:     32 / 49 loss=1.623, nll_loss=0.252, ppl=1.19, wps=25176.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.363, loss_scale=32, train_wall=221, gb_free=8.8, wall=78561
2022-03-07 12:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:25:49 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 13.365 | nll_loss 12.898 | ppl 7631.12 | wps 44628.2 | wpb 510.9 | bsz 1 | num_updates 30217 | best_loss 8.725
2022-03-07 12:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30217 updates
2022-03-07 12:25:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:25:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 621 @ 30217 updates, score 13.365) (writing took 1.7683455422520638 seconds)
2022-03-07 12:25:51 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 12:25:51 | INFO | train | epoch 621 | loss 1.623 | nll_loss 0.252 | ppl 1.19 | wps 25147.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30217 | lr 0.000181917 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78609
2022-03-07 12:25:51 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 12:25:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:26:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:27:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:27:55 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 13.394 | nll_loss 12.931 | ppl 7807.99 | wps 44444.5 | wpb 510.9 | bsz 1 | num_updates 30265 | best_loss 8.725
2022-03-07 12:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30265 updates
2022-03-07 12:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:27:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:27:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 622 @ 30265 updates, score 13.394) (writing took 1.8524757092818618 seconds)
2022-03-07 12:27:57 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 12:27:57 | INFO | train | epoch 622 | loss 1.623 | nll_loss 0.251 | ppl 1.19 | wps 24619.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30265 | lr 0.000181773 | gnorm 0.359 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78735
2022-03-07 12:27:57 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 12:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:29:23 | INFO | train_inner | epoch 623:     35 / 49 loss=1.623, nll_loss=0.251, ppl=1.19, wps=24925.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.357, loss_scale=32, train_wall=223, gb_free=8.8, wall=78822
2022-03-07 12:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:30:02 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 13.389 | nll_loss 12.924 | ppl 7769.04 | wps 44410.5 | wpb 510.9 | bsz 1 | num_updates 30314 | best_loss 8.725
2022-03-07 12:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30314 updates
2022-03-07 12:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:30:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:30:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 623 @ 30314 updates, score 13.389) (writing took 1.89691701810807 seconds)
2022-03-07 12:30:04 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 12:30:04 | INFO | train | epoch 623 | loss 1.622 | nll_loss 0.251 | ppl 1.19 | wps 25105.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30314 | lr 0.000181626 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78862
2022-03-07 12:30:04 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 12:30:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:32:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:32:08 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 13.393 | nll_loss 12.921 | ppl 7757.83 | wps 44556.9 | wpb 510.9 | bsz 1 | num_updates 30363 | best_loss 8.725
2022-03-07 12:32:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30363 updates
2022-03-07 12:32:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 624 @ 30363 updates, score 13.393) (writing took 2.056527675129473 seconds)
2022-03-07 12:32:10 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 12:32:10 | INFO | train | epoch 624 | loss 1.622 | nll_loss 0.251 | ppl 1.19 | wps 25094.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30363 | lr 0.00018148 | gnorm 0.363 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 78988
2022-03-07 12:32:10 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 12:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:32:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:33:44 | INFO | train_inner | epoch 625:     38 / 49 loss=1.622, nll_loss=0.251, ppl=1.19, wps=24881.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.362, loss_scale=32, train_wall=224, gb_free=8.8, wall=79082
2022-03-07 12:34:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:15 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 13.29 | nll_loss 12.819 | ppl 7228.44 | wps 44056.9 | wpb 510.9 | bsz 1 | num_updates 30411 | best_loss 8.725
2022-03-07 12:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30411 updates
2022-03-07 12:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:34:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:34:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 625 @ 30411 updates, score 13.29) (writing took 1.8861431330442429 seconds)
2022-03-07 12:34:17 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 12:34:17 | INFO | train | epoch 625 | loss 1.622 | nll_loss 0.251 | ppl 1.19 | wps 24559.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30411 | lr 0.000181336 | gnorm 0.361 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 79115
2022-03-07 12:34:17 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 12:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:36:22 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 13.459 | nll_loss 12.997 | ppl 8176.94 | wps 44321 | wpb 510.9 | bsz 1 | num_updates 30460 | best_loss 8.725
2022-03-07 12:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30460 updates
2022-03-07 12:36:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:36:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:36:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 626 @ 30460 updates, score 13.459) (writing took 2.0201251935213804 seconds)
2022-03-07 12:36:24 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 12:36:24 | INFO | train | epoch 626 | loss 1.622 | nll_loss 0.251 | ppl 1.19 | wps 25036.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30460 | lr 0.00018119 | gnorm 0.361 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 79242
2022-03-07 12:36:24 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 12:36:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:38:03 | INFO | train_inner | epoch 627:     40 / 49 loss=1.622, nll_loss=0.251, ppl=1.19, wps=25067.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.357, loss_scale=64, train_wall=222, gb_free=8.8, wall=79341
2022-03-07 12:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:38:29 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 13.412 | nll_loss 12.947 | ppl 7894.97 | wps 43739.3 | wpb 510.9 | bsz 1 | num_updates 30509 | best_loss 8.725
2022-03-07 12:38:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30509 updates
2022-03-07 12:38:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:38:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 627 @ 30509 updates, score 13.412) (writing took 1.8505438510328531 seconds)
2022-03-07 12:38:31 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 12:38:31 | INFO | train | epoch 627 | loss 1.621 | nll_loss 0.25 | ppl 1.19 | wps 25035.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30509 | lr 0.000181045 | gnorm 0.354 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 79369
2022-03-07 12:38:31 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 12:38:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:38:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:40:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:40:36 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 13.452 | nll_loss 12.99 | ppl 8135.99 | wps 43893.4 | wpb 510.9 | bsz 1 | num_updates 30557 | best_loss 8.725
2022-03-07 12:40:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30557 updates
2022-03-07 12:40:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 628 @ 30557 updates, score 13.452) (writing took 2.0460251327604055 seconds)
2022-03-07 12:40:38 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 12:40:38 | INFO | train | epoch 628 | loss 1.622 | nll_loss 0.251 | ppl 1.19 | wps 24511 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30557 | lr 0.000180903 | gnorm 0.364 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 79496
2022-03-07 12:40:38 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 12:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:42:24 | INFO | train_inner | epoch 629:     43 / 49 loss=1.622, nll_loss=0.251, ppl=1.19, wps=24844.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.363, loss_scale=32, train_wall=224, gb_free=8.8, wall=79602
2022-03-07 12:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:42:43 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 13.489 | nll_loss 13.032 | ppl 8374.24 | wps 44049 | wpb 510.9 | bsz 1 | num_updates 30606 | best_loss 8.725
2022-03-07 12:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30606 updates
2022-03-07 12:42:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:42:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 629 @ 30606 updates, score 13.489) (writing took 1.9430345240980387 seconds)
2022-03-07 12:42:45 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 12:42:45 | INFO | train | epoch 629 | loss 1.621 | nll_loss 0.25 | ppl 1.19 | wps 25071.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30606 | lr 0.000180758 | gnorm 0.362 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 79623
2022-03-07 12:42:45 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 12:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:44:49 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 13.433 | nll_loss 12.972 | ppl 8033.11 | wps 44204.1 | wpb 510.9 | bsz 1 | num_updates 30655 | best_loss 8.725
2022-03-07 12:44:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30655 updates
2022-03-07 12:44:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:44:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 630 @ 30655 updates, score 13.433) (writing took 1.9307276792824268 seconds)
2022-03-07 12:44:51 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 12:44:51 | INFO | train | epoch 630 | loss 1.621 | nll_loss 0.25 | ppl 1.19 | wps 25058.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30655 | lr 0.000180613 | gnorm 0.358 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 79750
2022-03-07 12:44:51 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 12:44:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:44:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:46:45 | INFO | train_inner | epoch 631:     46 / 49 loss=1.621, nll_loss=0.25, ppl=1.19, wps=24837.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30700, lr=0.000180481, gnorm=0.358, loss_scale=32, train_wall=224, gb_free=8.8, wall=79863
2022-03-07 12:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:46:56 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 13.364 | nll_loss 12.895 | ppl 7617.64 | wps 43936 | wpb 510.9 | bsz 1 | num_updates 30703 | best_loss 8.725
2022-03-07 12:46:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30703 updates
2022-03-07 12:46:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:46:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:46:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 631 @ 30703 updates, score 13.364) (writing took 1.6868706177920103 seconds)
2022-03-07 12:46:58 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 12:46:58 | INFO | train | epoch 631 | loss 1.62 | nll_loss 0.25 | ppl 1.19 | wps 24563.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30703 | lr 0.000180472 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 79876
2022-03-07 12:46:58 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 12:46:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:48:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:49:03 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 13.391 | nll_loss 12.924 | ppl 7772.79 | wps 43915.9 | wpb 510.9 | bsz 1 | num_updates 30752 | best_loss 8.725
2022-03-07 12:49:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30752 updates
2022-03-07 12:49:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:49:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:49:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 632 @ 30752 updates, score 13.391) (writing took 1.8525332231074572 seconds)
2022-03-07 12:49:05 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 12:49:05 | INFO | train | epoch 632 | loss 1.621 | nll_loss 0.25 | ppl 1.19 | wps 25098.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30752 | lr 0.000180328 | gnorm 0.361 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 80003
2022-03-07 12:49:05 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 12:49:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:51:03 | INFO | train_inner | epoch 633:     48 / 49 loss=1.621, nll_loss=0.25, ppl=1.19, wps=25125.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.358, loss_scale=64, train_wall=221, gb_free=8.8, wall=80122
2022-03-07 12:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:51:10 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 13.419 | nll_loss 12.953 | ppl 7927.21 | wps 43991.5 | wpb 510.9 | bsz 1 | num_updates 30801 | best_loss 8.725
2022-03-07 12:51:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30801 updates
2022-03-07 12:51:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:51:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:51:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 633 @ 30801 updates, score 13.419) (writing took 1.8430828461423516 seconds)
2022-03-07 12:51:11 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 12:51:11 | INFO | train | epoch 633 | loss 1.62 | nll_loss 0.249 | ppl 1.19 | wps 25068.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30801 | lr 0.000180185 | gnorm 0.356 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 80130
2022-03-07 12:51:11 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 12:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:51:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:53:17 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 13.398 | nll_loss 12.932 | ppl 7814.72 | wps 43856.1 | wpb 510.9 | bsz 1 | num_updates 30849 | best_loss 8.725
2022-03-07 12:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30849 updates
2022-03-07 12:53:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:53:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 634 @ 30849 updates, score 13.398) (writing took 2.103141536936164 seconds)
2022-03-07 12:53:19 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 12:53:19 | INFO | train | epoch 634 | loss 1.62 | nll_loss 0.249 | ppl 1.19 | wps 24477.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30849 | lr 0.000180044 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 80257
2022-03-07 12:53:19 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 12:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:55:24 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 13.357 | nll_loss 12.889 | ppl 7583.92 | wps 43990.8 | wpb 510.9 | bsz 1 | num_updates 30898 | best_loss 8.725
2022-03-07 12:55:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30898 updates
2022-03-07 12:55:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:55:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:55:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 635 @ 30898 updates, score 13.357) (writing took 2.2363780615851283 seconds)
2022-03-07 12:55:26 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 12:55:26 | INFO | train | epoch 635 | loss 1.62 | nll_loss 0.249 | ppl 1.19 | wps 24995 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30898 | lr 0.000179902 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 80384
2022-03-07 12:55:26 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 12:55:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:31 | INFO | train_inner | epoch 636:      2 / 49 loss=1.62, nll_loss=0.249, ppl=1.19, wps=24127.9, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=30900, lr=0.000179896, gnorm=0.358, loss_scale=32, train_wall=223, gb_free=8.8, wall=80389
2022-03-07 12:57:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:57:31 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 13.426 | nll_loss 12.958 | ppl 7955.99 | wps 44159.5 | wpb 510.9 | bsz 1 | num_updates 30947 | best_loss 8.725
2022-03-07 12:57:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30947 updates
2022-03-07 12:57:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:57:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:57:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 636 @ 30947 updates, score 13.426) (writing took 1.9930544178932905 seconds)
2022-03-07 12:57:33 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 12:57:33 | INFO | train | epoch 636 | loss 1.62 | nll_loss 0.249 | ppl 1.19 | wps 25043.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30947 | lr 0.000179759 | gnorm 0.361 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 80511
2022-03-07 12:57:33 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 12:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:58:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:37 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 13.478 | nll_loss 13.016 | ppl 8281.99 | wps 44441.2 | wpb 510.9 | bsz 1 | num_updates 30995 | best_loss 8.725
2022-03-07 12:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 30995 updates
2022-03-07 12:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 637 @ 30995 updates, score 13.478) (writing took 1.8859492605552077 seconds)
2022-03-07 12:59:39 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 12:59:39 | INFO | train | epoch 637 | loss 1.619 | nll_loss 0.249 | ppl 1.19 | wps 24592.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30995 | lr 0.00017962 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 80637
2022-03-07 12:59:39 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 12:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:52 | INFO | train_inner | epoch 638:      5 / 49 loss=1.619, nll_loss=0.249, ppl=1.19, wps=24875.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.359, loss_scale=32, train_wall=224, gb_free=8.8, wall=80650
2022-03-07 13:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:01:44 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 13.46 | nll_loss 12.999 | ppl 8186.91 | wps 44398.2 | wpb 510.9 | bsz 1 | num_updates 31044 | best_loss 8.725
2022-03-07 13:01:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31044 updates
2022-03-07 13:01:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:01:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:01:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 638 @ 31044 updates, score 13.46) (writing took 2.111838494427502 seconds)
2022-03-07 13:01:46 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 13:01:46 | INFO | train | epoch 638 | loss 1.62 | nll_loss 0.249 | ppl 1.19 | wps 25064.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31044 | lr 0.000179478 | gnorm 0.358 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 80764
2022-03-07 13:01:46 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 13:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:03:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:03:51 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 13.436 | nll_loss 12.972 | ppl 8032.61 | wps 43921.3 | wpb 510.9 | bsz 1 | num_updates 31093 | best_loss 8.725
2022-03-07 13:03:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31093 updates
2022-03-07 13:03:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:03:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 639 @ 31093 updates, score 13.436) (writing took 1.776896907016635 seconds)
2022-03-07 13:03:52 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 13:03:52 | INFO | train | epoch 639 | loss 1.619 | nll_loss 0.249 | ppl 1.19 | wps 25145.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31093 | lr 0.000179336 | gnorm 0.36 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 80891
2022-03-07 13:03:52 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 13:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:10 | INFO | train_inner | epoch 640:      7 / 49 loss=1.619, nll_loss=0.249, ppl=1.19, wps=25131.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.359, loss_scale=32, train_wall=221, gb_free=8.8, wall=80908
2022-03-07 13:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:05:57 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 13.402 | nll_loss 12.936 | ppl 7839.09 | wps 43883.9 | wpb 510.9 | bsz 1 | num_updates 31142 | best_loss 8.725
2022-03-07 13:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31142 updates
2022-03-07 13:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 640 @ 31142 updates, score 13.402) (writing took 1.69038394279778 seconds)
2022-03-07 13:05:59 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 13:05:59 | INFO | train | epoch 640 | loss 1.619 | nll_loss 0.248 | ppl 1.19 | wps 25112.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31142 | lr 0.000179195 | gnorm 0.354 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 81017
2022-03-07 13:05:59 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 13:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:06:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:07:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:04 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 13.484 | nll_loss 13.024 | ppl 8329.5 | wps 43299.9 | wpb 510.9 | bsz 1 | num_updates 31190 | best_loss 8.725
2022-03-07 13:08:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31190 updates
2022-03-07 13:08:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:08:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:08:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 641 @ 31190 updates, score 13.484) (writing took 1.8771875854581594 seconds)
2022-03-07 13:08:06 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 13:08:06 | INFO | train | epoch 641 | loss 1.618 | nll_loss 0.248 | ppl 1.19 | wps 24542.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31190 | lr 0.000179057 | gnorm 0.355 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 81144
2022-03-07 13:08:06 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 13:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:31 | INFO | train_inner | epoch 642:     10 / 49 loss=1.618, nll_loss=0.248, ppl=1.19, wps=24876.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.354, loss_scale=32, train_wall=224, gb_free=8.8, wall=81169
2022-03-07 13:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:10:10 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 13.416 | nll_loss 12.952 | ppl 7921.28 | wps 44520.1 | wpb 510.9 | bsz 1 | num_updates 31239 | best_loss 8.725
2022-03-07 13:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31239 updates
2022-03-07 13:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:10:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:10:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 642 @ 31239 updates, score 13.416) (writing took 2.2643792936578393 seconds)
2022-03-07 13:10:13 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 13:10:13 | INFO | train | epoch 642 | loss 1.619 | nll_loss 0.249 | ppl 1.19 | wps 25050.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31239 | lr 0.000178917 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 81271
2022-03-07 13:10:13 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 13:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:11:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:12:17 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 13.405 | nll_loss 12.94 | ppl 7860.56 | wps 44632.8 | wpb 510.9 | bsz 1 | num_updates 31287 | best_loss 8.725
2022-03-07 13:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31287 updates
2022-03-07 13:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 643 @ 31287 updates, score 13.405) (writing took 1.9360384307801723 seconds)
2022-03-07 13:12:19 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 13:12:19 | INFO | train | epoch 643 | loss 1.618 | nll_loss 0.249 | ppl 1.19 | wps 24620.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31287 | lr 0.00017878 | gnorm 0.358 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 81397
2022-03-07 13:12:19 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 13:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:51 | INFO | train_inner | epoch 644:     13 / 49 loss=1.618, nll_loss=0.248, ppl=1.19, wps=24890.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=31300, lr=0.000178743, gnorm=0.355, loss_scale=32, train_wall=223, gb_free=8.8, wall=81429
2022-03-07 13:14:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:14:24 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 13.491 | nll_loss 13.031 | ppl 8369.37 | wps 44701.9 | wpb 510.9 | bsz 1 | num_updates 31336 | best_loss 8.725
2022-03-07 13:14:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31336 updates
2022-03-07 13:14:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:14:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:14:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 644 @ 31336 updates, score 13.491) (writing took 1.7506172684952617 seconds)
2022-03-07 13:14:25 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 13:14:25 | INFO | train | epoch 644 | loss 1.618 | nll_loss 0.248 | ppl 1.19 | wps 25173.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31336 | lr 0.00017864 | gnorm 0.356 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 81524
2022-03-07 13:14:25 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 13:14:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:16:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:16:30 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 13.481 | nll_loss 13.02 | ppl 8308.97 | wps 44482.6 | wpb 510.9 | bsz 1 | num_updates 31385 | best_loss 8.725
2022-03-07 13:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31385 updates
2022-03-07 13:16:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:16:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 645 @ 31385 updates, score 13.481) (writing took 1.9893083786591887 seconds)
2022-03-07 13:16:32 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 13:16:32 | INFO | train | epoch 645 | loss 1.618 | nll_loss 0.248 | ppl 1.19 | wps 25123.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31385 | lr 0.0001785 | gnorm 0.354 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 81650
2022-03-07 13:16:32 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 13:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:17:09 | INFO | train_inner | epoch 646:     15 / 49 loss=1.618, nll_loss=0.248, ppl=1.19, wps=25175.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.355, loss_scale=32, train_wall=221, gb_free=8.8, wall=81687
2022-03-07 13:17:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:18:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:36 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 13.444 | nll_loss 12.983 | ppl 8095.54 | wps 44172.2 | wpb 510.9 | bsz 1 | num_updates 31433 | best_loss 8.725
2022-03-07 13:18:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31433 updates
2022-03-07 13:18:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:18:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:18:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 646 @ 31433 updates, score 13.444) (writing took 1.7929984536021948 seconds)
2022-03-07 13:18:38 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 13:18:38 | INFO | train | epoch 646 | loss 1.618 | nll_loss 0.248 | ppl 1.19 | wps 24617.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31433 | lr 0.000178364 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 81776
2022-03-07 13:18:38 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 13:18:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:20:43 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 13.358 | nll_loss 12.892 | ppl 7602.86 | wps 44519.7 | wpb 510.9 | bsz 1 | num_updates 31482 | best_loss 8.725
2022-03-07 13:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31482 updates
2022-03-07 13:20:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 647 @ 31482 updates, score 13.358) (writing took 1.8660171190276742 seconds)
2022-03-07 13:20:45 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 13:20:45 | INFO | train | epoch 647 | loss 1.617 | nll_loss 0.248 | ppl 1.19 | wps 25133.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31482 | lr 0.000178225 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 81903
2022-03-07 13:20:45 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 13:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:21:29 | INFO | train_inner | epoch 648:     18 / 49 loss=1.618, nll_loss=0.248, ppl=1.19, wps=24924.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.355, loss_scale=32, train_wall=223, gb_free=8.8, wall=81947
2022-03-07 13:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:22:49 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 13.431 | nll_loss 12.969 | ppl 8018.46 | wps 44618.3 | wpb 510.9 | bsz 1 | num_updates 31531 | best_loss 8.725
2022-03-07 13:22:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31531 updates
2022-03-07 13:22:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:22:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 648 @ 31531 updates, score 13.431) (writing took 1.8811908597126603 seconds)
2022-03-07 13:22:51 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 13:22:51 | INFO | train | epoch 648 | loss 1.617 | nll_loss 0.247 | ppl 1.19 | wps 25144.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31531 | lr 0.000178087 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 82029
2022-03-07 13:22:51 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 13:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:23:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:24:56 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 13.474 | nll_loss 13.01 | ppl 8247.84 | wps 44280.3 | wpb 510.9 | bsz 1 | num_updates 31579 | best_loss 8.725
2022-03-07 13:24:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31579 updates
2022-03-07 13:24:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:24:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:24:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 649 @ 31579 updates, score 13.474) (writing took 1.8212786763906479 seconds)
2022-03-07 13:24:58 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 13:24:58 | INFO | train | epoch 649 | loss 1.617 | nll_loss 0.247 | ppl 1.19 | wps 24571.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31579 | lr 0.000177951 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 82156
2022-03-07 13:24:58 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 13:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:25:50 | INFO | train_inner | epoch 650:     21 / 49 loss=1.617, nll_loss=0.247, ppl=1.19, wps=24906.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.353, loss_scale=32, train_wall=223, gb_free=8.8, wall=82208
2022-03-07 13:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:27:02 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 13.424 | nll_loss 12.963 | ppl 7986.14 | wps 44196 | wpb 510.9 | bsz 1 | num_updates 31628 | best_loss 8.725
2022-03-07 13:27:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31628 updates
2022-03-07 13:27:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:27:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:27:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 650 @ 31628 updates, score 13.424) (writing took 1.8509981948882341 seconds)
2022-03-07 13:27:04 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 13:27:04 | INFO | train | epoch 650 | loss 1.618 | nll_loss 0.248 | ppl 1.19 | wps 25123.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31628 | lr 0.000177813 | gnorm 0.36 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 82282
2022-03-07 13:27:04 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 13:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:29:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:29:09 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 13.39 | nll_loss 12.928 | ppl 7793.22 | wps 44532.1 | wpb 510.9 | bsz 1 | num_updates 31677 | best_loss 8.725
2022-03-07 13:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31677 updates
2022-03-07 13:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:29:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:29:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 651 @ 31677 updates, score 13.39) (writing took 1.7974928859621286 seconds)
2022-03-07 13:29:11 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 13:29:11 | INFO | train | epoch 651 | loss 1.616 | nll_loss 0.246 | ppl 1.19 | wps 25169.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31677 | lr 0.000177676 | gnorm 0.353 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 82409
2022-03-07 13:29:11 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 13:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:29:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:30:10 | INFO | train_inner | epoch 652:     24 / 49 loss=1.617, nll_loss=0.247, ppl=1.19, wps=24931.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.357, loss_scale=32, train_wall=223, gb_free=8.8, wall=82468
2022-03-07 13:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:31:15 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 13.428 | nll_loss 12.967 | ppl 8005.41 | wps 44160.5 | wpb 510.9 | bsz 1 | num_updates 31725 | best_loss 8.725
2022-03-07 13:31:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31725 updates
2022-03-07 13:31:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:31:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:31:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 652 @ 31725 updates, score 13.428) (writing took 1.770871115848422 seconds)
2022-03-07 13:31:17 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 13:31:17 | INFO | train | epoch 652 | loss 1.616 | nll_loss 0.247 | ppl 1.19 | wps 24605.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31725 | lr 0.000177541 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 82535
2022-03-07 13:31:17 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 13:31:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:33:22 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 13.469 | nll_loss 13.005 | ppl 8220.54 | wps 43739.5 | wpb 510.9 | bsz 1 | num_updates 31774 | best_loss 8.725
2022-03-07 13:33:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31774 updates
2022-03-07 13:33:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:33:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:33:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 653 @ 31774 updates, score 13.469) (writing took 1.9642935683950782 seconds)
2022-03-07 13:33:24 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 13:33:24 | INFO | train | epoch 653 | loss 1.616 | nll_loss 0.247 | ppl 1.19 | wps 25040.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31774 | lr 0.000177404 | gnorm 0.362 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 82662
2022-03-07 13:33:24 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 13:33:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:34:28 | INFO | train_inner | epoch 654:     26 / 49 loss=1.616, nll_loss=0.246, ppl=1.19, wps=25109.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.358, loss_scale=32, train_wall=221, gb_free=8.8, wall=82726
2022-03-07 13:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:29 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 13.465 | nll_loss 13.005 | ppl 8220.29 | wps 44461.6 | wpb 510.9 | bsz 1 | num_updates 31823 | best_loss 8.725
2022-03-07 13:35:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31823 updates
2022-03-07 13:35:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:35:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 654 @ 31823 updates, score 13.465) (writing took 1.7680377149954438 seconds)
2022-03-07 13:35:31 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 13:35:31 | INFO | train | epoch 654 | loss 1.615 | nll_loss 0.246 | ppl 1.19 | wps 25094.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31823 | lr 0.000177268 | gnorm 0.355 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 82789
2022-03-07 13:35:31 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 13:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:35 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 13.43 | nll_loss 12.972 | ppl 8033 | wps 44299.9 | wpb 510.9 | bsz 1 | num_updates 31871 | best_loss 8.725
2022-03-07 13:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31871 updates
2022-03-07 13:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:37:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:37:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 655 @ 31871 updates, score 13.43) (writing took 1.7822660114616156 seconds)
2022-03-07 13:37:37 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 13:37:37 | INFO | train | epoch 655 | loss 1.616 | nll_loss 0.247 | ppl 1.19 | wps 24571 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31871 | lr 0.000177134 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 82915
2022-03-07 13:37:37 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 13:37:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:38:49 | INFO | train_inner | epoch 656:     29 / 49 loss=1.616, nll_loss=0.246, ppl=1.19, wps=24882.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.354, loss_scale=32, train_wall=224, gb_free=8.8, wall=82987
2022-03-07 13:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:39:42 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 13.525 | nll_loss 13.067 | ppl 8584.12 | wps 44257.2 | wpb 510.9 | bsz 1 | num_updates 31920 | best_loss 8.725
2022-03-07 13:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31920 updates
2022-03-07 13:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 656 @ 31920 updates, score 13.525) (writing took 1.8856550212949514 seconds)
2022-03-07 13:39:44 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 13:39:44 | INFO | train | epoch 656 | loss 1.615 | nll_loss 0.246 | ppl 1.19 | wps 25091 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 31920 | lr 0.000176998 | gnorm 0.356 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 83042
2022-03-07 13:39:44 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 13:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:49 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 13.44 | nll_loss 12.982 | ppl 8090.94 | wps 44014.7 | wpb 510.9 | bsz 1 | num_updates 31968 | best_loss 8.725
2022-03-07 13:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31968 updates
2022-03-07 13:41:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:41:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:41:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 657 @ 31968 updates, score 13.44) (writing took 1.8987631667405367 seconds)
2022-03-07 13:41:51 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 13:41:51 | INFO | train | epoch 657 | loss 1.615 | nll_loss 0.246 | ppl 1.19 | wps 24564.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31968 | lr 0.000176865 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 83169
2022-03-07 13:41:51 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 13:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:43:10 | INFO | train_inner | epoch 658:     32 / 49 loss=1.615, nll_loss=0.246, ppl=1.19, wps=24871.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.356, loss_scale=32, train_wall=224, gb_free=8.8, wall=83248
2022-03-07 13:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:43:55 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 13.405 | nll_loss 12.942 | ppl 7869.48 | wps 44244.9 | wpb 510.9 | bsz 1 | num_updates 32017 | best_loss 8.725
2022-03-07 13:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32017 updates
2022-03-07 13:43:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:43:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 658 @ 32017 updates, score 13.405) (writing took 1.9196782959625125 seconds)
2022-03-07 13:43:57 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 13:43:57 | INFO | train | epoch 658 | loss 1.614 | nll_loss 0.246 | ppl 1.19 | wps 25084.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32017 | lr 0.00017673 | gnorm 0.354 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 83296
2022-03-07 13:43:57 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 13:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:45:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:02 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 13.464 | nll_loss 13.004 | ppl 8213.1 | wps 43793.7 | wpb 510.9 | bsz 1 | num_updates 32066 | best_loss 8.725
2022-03-07 13:46:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32066 updates
2022-03-07 13:46:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:46:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:46:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 659 @ 32066 updates, score 13.464) (writing took 1.7229287177324295 seconds)
2022-03-07 13:46:04 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 13:46:04 | INFO | train | epoch 659 | loss 1.615 | nll_loss 0.246 | ppl 1.19 | wps 25072.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32066 | lr 0.000176595 | gnorm 0.355 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 83422
2022-03-07 13:46:04 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 13:46:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:47:31 | INFO | train_inner | epoch 660:     35 / 49 loss=1.614, nll_loss=0.246, ppl=1.19, wps=24856.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.356, loss_scale=32, train_wall=224, gb_free=8.8, wall=83509
2022-03-07 13:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:48:09 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 13.464 | nll_loss 13.006 | ppl 8226 | wps 44009.1 | wpb 510.9 | bsz 1 | num_updates 32114 | best_loss 8.725
2022-03-07 13:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32114 updates
2022-03-07 13:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 660 @ 32114 updates, score 13.464) (writing took 1.7846597954630852 seconds)
2022-03-07 13:48:11 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 13:48:11 | INFO | train | epoch 660 | loss 1.614 | nll_loss 0.245 | ppl 1.19 | wps 24563.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32114 | lr 0.000176463 | gnorm 0.356 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 83549
2022-03-07 13:48:11 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 13:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:50:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:16 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 13.325 | nll_loss 12.854 | ppl 7404.63 | wps 43724.7 | wpb 510.9 | bsz 1 | num_updates 32163 | best_loss 8.725
2022-03-07 13:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32163 updates
2022-03-07 13:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:50:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 661 @ 32163 updates, score 13.325) (writing took 1.7599163139238954 seconds)
2022-03-07 13:50:18 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 13:50:18 | INFO | train | epoch 661 | loss 1.614 | nll_loss 0.245 | ppl 1.19 | wps 25066.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32163 | lr 0.000176328 | gnorm 0.353 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 83676
2022-03-07 13:50:18 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 13:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:51:49 | INFO | train_inner | epoch 662:     37 / 49 loss=1.614, nll_loss=0.245, ppl=1.19, wps=25117.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.351, loss_scale=32, train_wall=222, gb_free=8.8, wall=83767
2022-03-07 13:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:52:22 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 13.403 | nll_loss 12.94 | ppl 7857.7 | wps 44259.4 | wpb 510.9 | bsz 1 | num_updates 32212 | best_loss 8.725
2022-03-07 13:52:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32212 updates
2022-03-07 13:52:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:52:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:52:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 662 @ 32212 updates, score 13.403) (writing took 1.843424964696169 seconds)
2022-03-07 13:52:24 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 13:52:24 | INFO | train | epoch 662 | loss 1.614 | nll_loss 0.246 | ppl 1.19 | wps 25104 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32212 | lr 0.000176194 | gnorm 0.349 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 83802
2022-03-07 13:52:24 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 13:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:54:29 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 13.342 | nll_loss 12.879 | ppl 7533.8 | wps 43280.2 | wpb 510.9 | bsz 1 | num_updates 32260 | best_loss 8.725
2022-03-07 13:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32260 updates
2022-03-07 13:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:54:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 663 @ 32260 updates, score 13.342) (writing took 1.8163595078513026 seconds)
2022-03-07 13:54:31 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 13:54:31 | INFO | train | epoch 663 | loss 1.614 | nll_loss 0.245 | ppl 1.19 | wps 24555.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32260 | lr 0.000176063 | gnorm 0.355 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 83929
2022-03-07 13:54:31 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 13:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:56:10 | INFO | train_inner | epoch 664:     40 / 49 loss=1.614, nll_loss=0.245, ppl=1.19, wps=24882.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.354, loss_scale=32, train_wall=224, gb_free=8.8, wall=84028
2022-03-07 13:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:56:36 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 13.372 | nll_loss 12.906 | ppl 7675.88 | wps 44363.6 | wpb 510.9 | bsz 1 | num_updates 32309 | best_loss 8.725
2022-03-07 13:56:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32309 updates
2022-03-07 13:56:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 664 @ 32309 updates, score 13.372) (writing took 1.8764373064041138 seconds)
2022-03-07 13:56:37 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 13:56:37 | INFO | train | epoch 664 | loss 1.614 | nll_loss 0.245 | ppl 1.19 | wps 25122.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32309 | lr 0.000175929 | gnorm 0.357 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 84056
2022-03-07 13:56:37 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 13:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:58:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:58:42 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 13.497 | nll_loss 13.037 | ppl 8403.24 | wps 44409.7 | wpb 510.9 | bsz 1 | num_updates 32357 | best_loss 8.725
2022-03-07 13:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32357 updates
2022-03-07 13:58:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:58:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:58:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 665 @ 32357 updates, score 13.497) (writing took 1.8918737163767219 seconds)
2022-03-07 13:58:44 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 13:58:44 | INFO | train | epoch 665 | loss 1.613 | nll_loss 0.245 | ppl 1.18 | wps 24611 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32357 | lr 0.000175799 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 84182
2022-03-07 13:58:44 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 13:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:00:30 | INFO | train_inner | epoch 666:     43 / 49 loss=1.613, nll_loss=0.245, ppl=1.18, wps=24923.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.354, loss_scale=32, train_wall=223, gb_free=8.8, wall=84288
2022-03-07 14:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:00:48 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 13.361 | nll_loss 12.895 | ppl 7617.21 | wps 44294.4 | wpb 510.9 | bsz 1 | num_updates 32406 | best_loss 8.725
2022-03-07 14:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32406 updates
2022-03-07 14:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 666 @ 32406 updates, score 13.361) (writing took 1.9506825739517808 seconds)
2022-03-07 14:00:50 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 14:00:50 | INFO | train | epoch 666 | loss 1.613 | nll_loss 0.244 | ppl 1.18 | wps 25117.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32406 | lr 0.000175666 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 84309
2022-03-07 14:00:50 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 14:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:02:57 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 13.398 | nll_loss 12.934 | ppl 7826.89 | wps 44776.1 | wpb 510.9 | bsz 1 | num_updates 32455 | best_loss 8.725
2022-03-07 14:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32455 updates
2022-03-07 14:02:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 667 @ 32455 updates, score 13.398) (writing took 1.727113014087081 seconds)
2022-03-07 14:02:59 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 14:02:59 | INFO | train | epoch 667 | loss 1.613 | nll_loss 0.244 | ppl 1.18 | wps 24810 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32455 | lr 0.000175533 | gnorm 0.351 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 84437
2022-03-07 14:02:59 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 14:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:49 | INFO | train_inner | epoch 668:     45 / 49 loss=1.613, nll_loss=0.245, ppl=1.18, wps=25002.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=32500, lr=0.000175412, gnorm=0.351, loss_scale=64, train_wall=222, gb_free=8.8, wall=84548
2022-03-07 14:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:03 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 13.416 | nll_loss 12.951 | ppl 7920.8 | wps 44337.2 | wpb 510.9 | bsz 1 | num_updates 32504 | best_loss 8.725
2022-03-07 14:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32504 updates
2022-03-07 14:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 668 @ 32504 updates, score 13.416) (writing took 1.8619439033791423 seconds)
2022-03-07 14:05:05 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 14:05:05 | INFO | train | epoch 668 | loss 1.613 | nll_loss 0.245 | ppl 1.18 | wps 25155.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32504 | lr 0.000175401 | gnorm 0.35 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 84563
2022-03-07 14:05:05 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 14:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:06:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:07:09 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 13.44 | nll_loss 12.979 | ppl 8072.68 | wps 44241.3 | wpb 510.9 | bsz 1 | num_updates 32552 | best_loss 8.725
2022-03-07 14:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32552 updates
2022-03-07 14:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 669 @ 32552 updates, score 13.44) (writing took 1.9272077549248934 seconds)
2022-03-07 14:07:11 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 14:07:11 | INFO | train | epoch 669 | loss 1.613 | nll_loss 0.244 | ppl 1.18 | wps 24634.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32552 | lr 0.000175271 | gnorm 0.353 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 84689
2022-03-07 14:07:11 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 14:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:09:10 | INFO | train_inner | epoch 670:     48 / 49 loss=1.613, nll_loss=0.244, ppl=1.18, wps=24931.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.353, loss_scale=32, train_wall=223, gb_free=8.8, wall=84808
2022-03-07 14:09:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:09:16 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 13.376 | nll_loss 12.912 | ppl 7705.6 | wps 44583 | wpb 510.9 | bsz 1 | num_updates 32601 | best_loss 8.725
2022-03-07 14:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32601 updates
2022-03-07 14:09:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:09:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:09:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 670 @ 32601 updates, score 13.376) (writing took 1.7848382806405425 seconds)
2022-03-07 14:09:18 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 14:09:18 | INFO | train | epoch 670 | loss 1.613 | nll_loss 0.244 | ppl 1.18 | wps 25146.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32601 | lr 0.00017514 | gnorm 0.353 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 84816
2022-03-07 14:09:18 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 14:09:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:11:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:11:22 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 13.544 | nll_loss 13.092 | ppl 8729.66 | wps 43916.5 | wpb 510.9 | bsz 1 | num_updates 32650 | best_loss 8.725
2022-03-07 14:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32650 updates
2022-03-07 14:11:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:11:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 671 @ 32650 updates, score 13.544) (writing took 1.8174048466607928 seconds)
2022-03-07 14:11:24 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 14:11:24 | INFO | train | epoch 671 | loss 1.612 | nll_loss 0.244 | ppl 1.18 | wps 25079.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32650 | lr 0.000175008 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 84943
2022-03-07 14:11:24 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 14:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:12:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:29 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 13.355 | nll_loss 12.89 | ppl 7593.14 | wps 44605 | wpb 510.9 | bsz 1 | num_updates 32698 | best_loss 8.725
2022-03-07 14:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32698 updates
2022-03-07 14:13:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 672 @ 32698 updates, score 13.355) (writing took 1.8549994872882962 seconds)
2022-03-07 14:13:31 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 14:13:31 | INFO | train | epoch 672 | loss 1.612 | nll_loss 0.244 | ppl 1.18 | wps 24638.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32698 | lr 0.00017488 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 85069
2022-03-07 14:13:31 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 14:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:13:36 | INFO | train_inner | epoch 673:      2 / 49 loss=1.612, nll_loss=0.244, ppl=1.18, wps=24259.3, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=32700, lr=0.000174874, gnorm=0.352, loss_scale=32, train_wall=222, gb_free=8.8, wall=85074
2022-03-07 14:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:15:37 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 13.378 | nll_loss 12.911 | ppl 7704.58 | wps 44670.5 | wpb 510.9 | bsz 1 | num_updates 32747 | best_loss 8.725
2022-03-07 14:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32747 updates
2022-03-07 14:15:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:15:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 673 @ 32747 updates, score 13.378) (writing took 1.8442174652591348 seconds)
2022-03-07 14:15:38 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 14:15:38 | INFO | train | epoch 673 | loss 1.612 | nll_loss 0.244 | ppl 1.18 | wps 24871.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32747 | lr 0.000174749 | gnorm 0.357 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 85197
2022-03-07 14:15:38 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 14:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:45 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 13.395 | nll_loss 12.932 | ppl 7815 | wps 44368.3 | wpb 510.9 | bsz 1 | num_updates 32796 | best_loss 8.725
2022-03-07 14:17:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32796 updates
2022-03-07 14:17:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:17:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:17:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 674 @ 32796 updates, score 13.395) (writing took 1.9641621317714453 seconds)
2022-03-07 14:17:47 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 14:17:47 | INFO | train | epoch 674 | loss 1.612 | nll_loss 0.244 | ppl 1.18 | wps 24760.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32796 | lr 0.000174618 | gnorm 0.358 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 85325
2022-03-07 14:17:47 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 14:17:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:57 | INFO | train_inner | epoch 675:      4 / 49 loss=1.612, nll_loss=0.244, ppl=1.18, wps=24850, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.358, loss_scale=32, train_wall=223, gb_free=8.8, wall=85335
2022-03-07 14:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:19:52 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 13.471 | nll_loss 13.012 | ppl 8258.64 | wps 44136.5 | wpb 510.9 | bsz 1 | num_updates 32845 | best_loss 8.725
2022-03-07 14:19:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32845 updates
2022-03-07 14:19:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:19:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:19:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 675 @ 32845 updates, score 13.471) (writing took 1.876017726957798 seconds)
2022-03-07 14:19:54 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 14:19:54 | INFO | train | epoch 675 | loss 1.612 | nll_loss 0.244 | ppl 1.18 | wps 25070.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32845 | lr 0.000174488 | gnorm 0.351 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85452
2022-03-07 14:19:54 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 14:19:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:20:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:21:59 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 13.387 | nll_loss 12.922 | ppl 7759.42 | wps 43775.6 | wpb 510.9 | bsz 1 | num_updates 32893 | best_loss 8.725
2022-03-07 14:21:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32893 updates
2022-03-07 14:21:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:22:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 676 @ 32893 updates, score 13.387) (writing took 1.9817901933565736 seconds)
2022-03-07 14:22:01 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 14:22:01 | INFO | train | epoch 676 | loss 1.612 | nll_loss 0.244 | ppl 1.18 | wps 24508.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32893 | lr 0.000174361 | gnorm 0.352 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 85579
2022-03-07 14:22:01 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 14:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:18 | INFO | train_inner | epoch 677:      7 / 49 loss=1.611, nll_loss=0.244, ppl=1.18, wps=24833.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.351, loss_scale=32, train_wall=224, gb_free=8.8, wall=85596
2022-03-07 14:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:05 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 13.352 | nll_loss 12.887 | ppl 7573.68 | wps 44183.1 | wpb 510.9 | bsz 1 | num_updates 32942 | best_loss 8.725
2022-03-07 14:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32942 updates
2022-03-07 14:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 677 @ 32942 updates, score 13.352) (writing took 2.035500385798514 seconds)
2022-03-07 14:24:07 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 14:24:07 | INFO | train | epoch 677 | loss 1.61 | nll_loss 0.242 | ppl 1.18 | wps 25034.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32942 | lr 0.000174231 | gnorm 0.354 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 85706
2022-03-07 14:24:07 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 14:24:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:26:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:26:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:26:12 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 13.4 | nll_loss 12.936 | ppl 7834.46 | wps 43900.8 | wpb 510.9 | bsz 1 | num_updates 32990 | best_loss 8.725
2022-03-07 14:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 32990 updates
2022-03-07 14:26:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 678 @ 32990 updates, score 13.4) (writing took 1.8903809497132897 seconds)
2022-03-07 14:26:14 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 14:26:14 | INFO | train | epoch 678 | loss 1.611 | nll_loss 0.243 | ppl 1.18 | wps 24572.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32990 | lr 0.000174104 | gnorm 0.355 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 85832
2022-03-07 14:26:14 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 14:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:26:39 | INFO | train_inner | epoch 679:     10 / 49 loss=1.61, nll_loss=0.243, ppl=1.18, wps=24859.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.354, loss_scale=32, train_wall=224, gb_free=8.8, wall=85857
2022-03-07 14:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:28:19 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 13.446 | nll_loss 12.984 | ppl 8100.3 | wps 43788.8 | wpb 510.9 | bsz 1 | num_updates 33039 | best_loss 8.725
2022-03-07 14:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33039 updates
2022-03-07 14:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:28:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:28:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 679 @ 33039 updates, score 13.446) (writing took 1.8994590668007731 seconds)
2022-03-07 14:28:21 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 14:28:21 | INFO | train | epoch 679 | loss 1.61 | nll_loss 0.242 | ppl 1.18 | wps 25050.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33039 | lr 0.000173975 | gnorm 0.351 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 85959
2022-03-07 14:28:21 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 14:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:30:27 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 13.442 | nll_loss 12.982 | ppl 8090.98 | wps 43716.7 | wpb 510.9 | bsz 1 | num_updates 33088 | best_loss 8.725
2022-03-07 14:30:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33088 updates
2022-03-07 14:30:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:30:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 680 @ 33088 updates, score 13.442) (writing took 1.8295402452349663 seconds)
2022-03-07 14:30:29 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 14:30:29 | INFO | train | epoch 680 | loss 1.61 | nll_loss 0.243 | ppl 1.18 | wps 24882.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33088 | lr 0.000173846 | gnorm 0.353 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 86087
2022-03-07 14:30:29 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 14:30:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:30:59 | INFO | train_inner | epoch 681:     12 / 49 loss=1.61, nll_loss=0.243, ppl=1.18, wps=24988.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.352, loss_scale=32, train_wall=222, gb_free=8.8, wall=86117
2022-03-07 14:32:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:32:36 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 13.362 | nll_loss 12.897 | ppl 7625.82 | wps 37259.9 | wpb 510.9 | bsz 1 | num_updates 33136 | best_loss 8.725
2022-03-07 14:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33136 updates
2022-03-07 14:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 681 @ 33136 updates, score 13.362) (writing took 2.107082398608327 seconds)
2022-03-07 14:32:38 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-07 14:32:38 | INFO | train | epoch 681 | loss 1.61 | nll_loss 0.242 | ppl 1.18 | wps 24090.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 33136 | lr 0.00017372 | gnorm 0.349 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 86216
2022-03-07 14:32:38 | INFO | fairseq.trainer | begin training epoch 682
2022-03-07 14:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:34:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:34:45 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 13.45 | nll_loss 12.99 | ppl 8136.47 | wps 43721.4 | wpb 510.9 | bsz 1 | num_updates 33185 | best_loss 8.725
2022-03-07 14:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33185 updates
2022-03-07 14:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:34:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:34:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 682 @ 33185 updates, score 13.45) (writing took 1.9580267407000065 seconds)
2022-03-07 14:34:46 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-07 14:34:46 | INFO | train | epoch 682 | loss 1.611 | nll_loss 0.243 | ppl 1.18 | wps 24721.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33185 | lr 0.000173592 | gnorm 0.351 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 86345
2022-03-07 14:34:47 | INFO | fairseq.trainer | begin training epoch 683
2022-03-07 14:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:35:24 | INFO | train_inner | epoch 683:     15 / 49 loss=1.61, nll_loss=0.243, ppl=1.18, wps=24466.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.35, loss_scale=32, train_wall=226, gb_free=8.8, wall=86382
2022-03-07 14:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:36:57 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 13.342 | nll_loss 12.876 | ppl 7519.19 | wps 41039 | wpb 510.9 | bsz 1 | num_updates 33234 | best_loss 8.725
2022-03-07 14:36:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33234 updates
2022-03-07 14:36:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 683 @ 33234 updates, score 13.342) (writing took 2.2029404481872916 seconds)
2022-03-07 14:36:59 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-07 14:36:59 | INFO | train | epoch 683 | loss 1.61 | nll_loss 0.242 | ppl 1.18 | wps 24000.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33234 | lr 0.000173464 | gnorm 0.35 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 86477
2022-03-07 14:36:59 | INFO | fairseq.trainer | begin training epoch 684
2022-03-07 14:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:39:04 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 13.413 | nll_loss 12.95 | ppl 7911.15 | wps 43849.4 | wpb 510.9 | bsz 1 | num_updates 33283 | best_loss 8.725
2022-03-07 14:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33283 updates
2022-03-07 14:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:39:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 684 @ 33283 updates, score 13.413) (writing took 1.7950968742370605 seconds)
2022-03-07 14:39:06 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-07 14:39:06 | INFO | train | epoch 684 | loss 1.61 | nll_loss 0.242 | ppl 1.18 | wps 25055.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33283 | lr 0.000173336 | gnorm 0.353 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 86604
2022-03-07 14:39:06 | INFO | fairseq.trainer | begin training epoch 685
2022-03-07 14:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:39:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:39:50 | INFO | train_inner | epoch 685:     18 / 49 loss=1.61, nll_loss=0.242, ppl=1.18, wps=24327, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.351, loss_scale=32, train_wall=227, gb_free=8.8, wall=86649
2022-03-07 14:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:41:11 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 13.446 | nll_loss 12.987 | ppl 8119.86 | wps 43581 | wpb 510.9 | bsz 1 | num_updates 33331 | best_loss 8.725
2022-03-07 14:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33331 updates
2022-03-07 14:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 685 @ 33331 updates, score 13.446) (writing took 2.1146501218900084 seconds)
2022-03-07 14:41:13 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-07 14:41:13 | INFO | train | epoch 685 | loss 1.609 | nll_loss 0.242 | ppl 1.18 | wps 24470.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33331 | lr 0.000173211 | gnorm 0.349 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 86731
2022-03-07 14:41:13 | INFO | fairseq.trainer | begin training epoch 686
2022-03-07 14:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:43:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:43:23 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 13.39 | nll_loss 12.927 | ppl 7790.21 | wps 43667.4 | wpb 510.9 | bsz 1 | num_updates 33380 | best_loss 8.725
2022-03-07 14:43:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33380 updates
2022-03-07 14:43:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:43:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 686 @ 33380 updates, score 13.39) (writing took 1.901184719055891 seconds)
2022-03-07 14:43:25 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-07 14:43:25 | INFO | train | epoch 686 | loss 1.609 | nll_loss 0.242 | ppl 1.18 | wps 24098.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33380 | lr 0.000173084 | gnorm 0.346 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 86863
2022-03-07 14:43:25 | INFO | fairseq.trainer | begin training epoch 687
2022-03-07 14:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:44:14 | INFO | train_inner | epoch 687:     20 / 49 loss=1.609, nll_loss=0.242, ppl=1.18, wps=24569.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.348, loss_scale=32, train_wall=225, gb_free=8.8, wall=86913
2022-03-07 14:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:45:30 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 13.352 | nll_loss 12.887 | ppl 7576.47 | wps 44246.2 | wpb 510.9 | bsz 1 | num_updates 33429 | best_loss 8.725
2022-03-07 14:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33429 updates
2022-03-07 14:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:45:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 687 @ 33429 updates, score 13.352) (writing took 1.849260587245226 seconds)
2022-03-07 14:45:32 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-07 14:45:32 | INFO | train | epoch 687 | loss 1.609 | nll_loss 0.242 | ppl 1.18 | wps 25073 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33429 | lr 0.000172957 | gnorm 0.351 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 86990
2022-03-07 14:45:32 | INFO | fairseq.trainer | begin training epoch 688
2022-03-07 14:45:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:46:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:47:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:47:36 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 13.364 | nll_loss 12.896 | ppl 7622.51 | wps 43534 | wpb 510.9 | bsz 1 | num_updates 33477 | best_loss 8.725
2022-03-07 14:47:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33477 updates
2022-03-07 14:47:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:47:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:47:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 688 @ 33477 updates, score 13.364) (writing took 1.8390282122418284 seconds)
2022-03-07 14:47:38 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-07 14:47:38 | INFO | train | epoch 688 | loss 1.609 | nll_loss 0.242 | ppl 1.18 | wps 24557.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33477 | lr 0.000172833 | gnorm 0.352 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 87117
2022-03-07 14:47:38 | INFO | fairseq.trainer | begin training epoch 689
2022-03-07 14:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:36 | INFO | train_inner | epoch 689:     23 / 49 loss=1.609, nll_loss=0.242, ppl=1.18, wps=24761, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.351, loss_scale=32, train_wall=225, gb_free=8.8, wall=87175
2022-03-07 14:49:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:49:45 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 13.316 | nll_loss 12.852 | ppl 7391.85 | wps 43860.9 | wpb 510.9 | bsz 1 | num_updates 33526 | best_loss 8.725
2022-03-07 14:49:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33526 updates
2022-03-07 14:49:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 689 @ 33526 updates, score 13.316) (writing took 1.9708481002599 seconds)
2022-03-07 14:49:47 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-07 14:49:47 | INFO | train | epoch 689 | loss 1.609 | nll_loss 0.241 | ppl 1.18 | wps 24762.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33526 | lr 0.000172707 | gnorm 0.35 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 87245
2022-03-07 14:49:47 | INFO | fairseq.trainer | begin training epoch 690
2022-03-07 14:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:51:52 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 13.352 | nll_loss 12.889 | ppl 7586.61 | wps 43717.5 | wpb 510.9 | bsz 1 | num_updates 33575 | best_loss 8.725
2022-03-07 14:51:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33575 updates
2022-03-07 14:51:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:51:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 690 @ 33575 updates, score 13.352) (writing took 1.851951953023672 seconds)
2022-03-07 14:51:53 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-07 14:51:53 | INFO | train | epoch 690 | loss 1.609 | nll_loss 0.242 | ppl 1.18 | wps 25062.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33575 | lr 0.000172581 | gnorm 0.351 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 87372
2022-03-07 14:51:53 | INFO | fairseq.trainer | begin training epoch 691
2022-03-07 14:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:52:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:52:58 | INFO | train_inner | epoch 691:     26 / 49 loss=1.609, nll_loss=0.242, ppl=1.18, wps=24822.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.35, loss_scale=32, train_wall=224, gb_free=8.8, wall=87436
2022-03-07 14:53:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:53:59 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 13.428 | nll_loss 12.968 | ppl 8013.3 | wps 43668.4 | wpb 510.9 | bsz 1 | num_updates 33623 | best_loss 8.725
2022-03-07 14:53:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33623 updates
2022-03-07 14:53:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 691 @ 33623 updates, score 13.428) (writing took 1.8880041036754847 seconds)
2022-03-07 14:54:01 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-07 14:54:01 | INFO | train | epoch 691 | loss 1.608 | nll_loss 0.242 | ppl 1.18 | wps 24443.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33623 | lr 0.000172457 | gnorm 0.349 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 87499
2022-03-07 14:54:01 | INFO | fairseq.trainer | begin training epoch 692
2022-03-07 14:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:56:06 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 13.467 | nll_loss 13.009 | ppl 8242.74 | wps 43480.2 | wpb 510.9 | bsz 1 | num_updates 33672 | best_loss 8.725
2022-03-07 14:56:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33672 updates
2022-03-07 14:56:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 692 @ 33672 updates, score 13.467) (writing took 2.3867065124213696 seconds)
2022-03-07 14:56:08 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-07 14:56:08 | INFO | train | epoch 692 | loss 1.608 | nll_loss 0.241 | ppl 1.18 | wps 24963.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33672 | lr 0.000172332 | gnorm 0.345 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 87626
2022-03-07 14:56:08 | INFO | fairseq.trainer | begin training epoch 693
2022-03-07 14:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:57:17 | INFO | train_inner | epoch 693:     28 / 49 loss=1.608, nll_loss=0.241, ppl=1.18, wps=24975.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.346, loss_scale=32, train_wall=222, gb_free=8.8, wall=87696
2022-03-07 14:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:58:13 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 13.421 | nll_loss 12.96 | ppl 7970.08 | wps 44033.2 | wpb 510.9 | bsz 1 | num_updates 33721 | best_loss 8.725
2022-03-07 14:58:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33721 updates
2022-03-07 14:58:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:58:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:58:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 693 @ 33721 updates, score 13.421) (writing took 2.1033843643963337 seconds)
2022-03-07 14:58:15 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-07 14:58:15 | INFO | train | epoch 693 | loss 1.608 | nll_loss 0.241 | ppl 1.18 | wps 25012.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33721 | lr 0.000172207 | gnorm 0.346 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 87753
2022-03-07 14:58:15 | INFO | fairseq.trainer | begin training epoch 694
2022-03-07 14:58:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:00:25 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 13.451 | nll_loss 12.995 | ppl 8165.86 | wps 43775.9 | wpb 510.9 | bsz 1 | num_updates 33769 | best_loss 8.725
2022-03-07 15:00:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33769 updates
2022-03-07 15:00:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:00:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:00:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 694 @ 33769 updates, score 13.451) (writing took 1.983649275265634 seconds)
2022-03-07 15:00:27 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-07 15:00:27 | INFO | train | epoch 694 | loss 1.607 | nll_loss 0.241 | ppl 1.18 | wps 23648.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33769 | lr 0.000172084 | gnorm 0.344 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 87885
2022-03-07 15:00:27 | INFO | fairseq.trainer | begin training epoch 695
2022-03-07 15:00:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:01:44 | INFO | train_inner | epoch 695:     31 / 49 loss=1.608, nll_loss=0.241, ppl=1.18, wps=24374.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.347, loss_scale=32, train_wall=227, gb_free=8.8, wall=87962
2022-03-07 15:02:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:02:32 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 13.344 | nll_loss 12.879 | ppl 7535 | wps 44122.2 | wpb 510.9 | bsz 1 | num_updates 33818 | best_loss 8.725
2022-03-07 15:02:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33818 updates
2022-03-07 15:02:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:02:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:02:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 695 @ 33818 updates, score 13.344) (writing took 2.040600777603686 seconds)
2022-03-07 15:02:34 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-07 15:02:34 | INFO | train | epoch 695 | loss 1.608 | nll_loss 0.241 | ppl 1.18 | wps 24991.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33818 | lr 0.000171959 | gnorm 0.35 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 88012
2022-03-07 15:02:34 | INFO | fairseq.trainer | begin training epoch 696
2022-03-07 15:02:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:04:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:04:40 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 13.451 | nll_loss 12.994 | ppl 8157.64 | wps 38092 | wpb 510.9 | bsz 1 | num_updates 33867 | best_loss 8.725
2022-03-07 15:04:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33867 updates
2022-03-07 15:04:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:04:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:04:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 696 @ 33867 updates, score 13.451) (writing took 2.0719688115641475 seconds)
2022-03-07 15:04:42 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-07 15:04:42 | INFO | train | epoch 696 | loss 1.607 | nll_loss 0.24 | ppl 1.18 | wps 24747.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33867 | lr 0.000171835 | gnorm 0.344 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88141
2022-03-07 15:04:42 | INFO | fairseq.trainer | begin training epoch 697
2022-03-07 15:04:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:05:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:06:14 | INFO | train_inner | epoch 697:     34 / 49 loss=1.607, nll_loss=0.24, ppl=1.18, wps=24000.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.347, loss_scale=32, train_wall=229, gb_free=8.8, wall=88232
2022-03-07 15:06:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:06:56 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 13.529 | nll_loss 13.071 | ppl 8605.52 | wps 43948 | wpb 510.9 | bsz 1 | num_updates 33915 | best_loss 8.725
2022-03-07 15:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33915 updates
2022-03-07 15:06:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:06:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:06:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 697 @ 33915 updates, score 13.529) (writing took 1.944431490264833 seconds)
2022-03-07 15:06:58 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-07 15:06:58 | INFO | train | epoch 697 | loss 1.607 | nll_loss 0.241 | ppl 1.18 | wps 22939.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 33915 | lr 0.000171713 | gnorm 0.351 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 88276
2022-03-07 15:06:58 | INFO | fairseq.trainer | begin training epoch 698
2022-03-07 15:06:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:09:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:08 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 13.426 | nll_loss 12.967 | ppl 8007.12 | wps 43601.2 | wpb 510.9 | bsz 1 | num_updates 33964 | best_loss 8.725
2022-03-07 15:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33964 updates
2022-03-07 15:09:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:09:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 698 @ 33964 updates, score 13.426) (writing took 1.8691571662202477 seconds)
2022-03-07 15:09:10 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-07 15:09:10 | INFO | train | epoch 698 | loss 1.606 | nll_loss 0.24 | ppl 1.18 | wps 24048.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33964 | lr 0.000171589 | gnorm 0.346 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 88408
2022-03-07 15:09:10 | INFO | fairseq.trainer | begin training epoch 699
2022-03-07 15:09:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:10:39 | INFO | train_inner | epoch 699:     36 / 49 loss=1.607, nll_loss=0.24, ppl=1.18, wps=24460.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.348, loss_scale=32, train_wall=225, gb_free=8.8, wall=88497
2022-03-07 15:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:11:15 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 13.456 | nll_loss 12.996 | ppl 8171.77 | wps 43635.5 | wpb 510.9 | bsz 1 | num_updates 34013 | best_loss 8.725
2022-03-07 15:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34013 updates
2022-03-07 15:11:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:11:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 699 @ 34013 updates, score 13.456) (writing took 2.010646402835846 seconds)
2022-03-07 15:11:17 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-07 15:11:17 | INFO | train | epoch 699 | loss 1.607 | nll_loss 0.241 | ppl 1.18 | wps 25069.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34013 | lr 0.000171466 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 88535
2022-03-07 15:11:17 | INFO | fairseq.trainer | begin training epoch 700
2022-03-07 15:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:12:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:13:22 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 13.476 | nll_loss 13.018 | ppl 8293.96 | wps 43861.6 | wpb 510.9 | bsz 1 | num_updates 34061 | best_loss 8.725
2022-03-07 15:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34061 updates
2022-03-07 15:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 700 @ 34061 updates, score 13.476) (writing took 2.039097996428609 seconds)
2022-03-07 15:13:24 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-07 15:13:24 | INFO | train | epoch 700 | loss 1.607 | nll_loss 0.24 | ppl 1.18 | wps 24515.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34061 | lr 0.000171345 | gnorm 0.345 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 88662
2022-03-07 15:13:24 | INFO | fairseq.trainer | begin training epoch 701
2022-03-07 15:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:15:02 | INFO | train_inner | epoch 701:     39 / 49 loss=1.607, nll_loss=0.24, ppl=1.18, wps=24660.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.347, loss_scale=32, train_wall=225, gb_free=8.8, wall=88760
2022-03-07 15:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:15:31 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 13.429 | nll_loss 12.974 | ppl 8043.85 | wps 43651.8 | wpb 510.9 | bsz 1 | num_updates 34110 | best_loss 8.725
2022-03-07 15:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34110 updates
2022-03-07 15:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 701 @ 34110 updates, score 13.429) (writing took 1.8284221813082695 seconds)
2022-03-07 15:15:33 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-07 15:15:33 | INFO | train | epoch 701 | loss 1.607 | nll_loss 0.24 | ppl 1.18 | wps 24711.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34110 | lr 0.000171222 | gnorm 0.349 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 88791
2022-03-07 15:15:33 | INFO | fairseq.trainer | begin training epoch 702
2022-03-07 15:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:17:45 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 13.402 | nll_loss 12.937 | ppl 7843.22 | wps 43598.2 | wpb 510.9 | bsz 1 | num_updates 34159 | best_loss 8.725
2022-03-07 15:17:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34159 updates
2022-03-07 15:17:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 702 @ 34159 updates, score 13.402) (writing took 1.8578580198809505 seconds)
2022-03-07 15:17:46 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-07 15:17:46 | INFO | train | epoch 702 | loss 1.606 | nll_loss 0.24 | ppl 1.18 | wps 23736.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34159 | lr 0.000171099 | gnorm 0.349 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 88925
2022-03-07 15:17:46 | INFO | fairseq.trainer | begin training epoch 703
2022-03-07 15:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:19:28 | INFO | train_inner | epoch 703:     41 / 49 loss=1.606, nll_loss=0.24, ppl=1.18, wps=24418.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.348, loss_scale=64, train_wall=226, gb_free=8.8, wall=89026
2022-03-07 15:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:19:51 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 13.492 | nll_loss 13.037 | ppl 8403.52 | wps 43789.1 | wpb 510.9 | bsz 1 | num_updates 34208 | best_loss 8.725
2022-03-07 15:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34208 updates
2022-03-07 15:19:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:19:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:19:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 703 @ 34208 updates, score 13.492) (writing took 1.9304396780207753 seconds)
2022-03-07 15:19:53 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-07 15:19:53 | INFO | train | epoch 703 | loss 1.605 | nll_loss 0.239 | ppl 1.18 | wps 25036.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34208 | lr 0.000170976 | gnorm 0.346 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89052
2022-03-07 15:19:53 | INFO | fairseq.trainer | begin training epoch 704
2022-03-07 15:19:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:21:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:21:58 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 13.331 | nll_loss 12.866 | ppl 7466.78 | wps 43764.1 | wpb 510.9 | bsz 1 | num_updates 34256 | best_loss 8.725
2022-03-07 15:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34256 updates
2022-03-07 15:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 704 @ 34256 updates, score 13.331) (writing took 2.0477917063981295 seconds)
2022-03-07 15:22:00 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-07 15:22:00 | INFO | train | epoch 704 | loss 1.605 | nll_loss 0.239 | ppl 1.18 | wps 24524 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34256 | lr 0.000170857 | gnorm 0.344 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 89179
2022-03-07 15:22:00 | INFO | fairseq.trainer | begin training epoch 705
2022-03-07 15:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:23:49 | INFO | train_inner | epoch 705:     44 / 49 loss=1.605, nll_loss=0.239, ppl=1.18, wps=24827.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34300, lr=0.000170747, gnorm=0.344, loss_scale=32, train_wall=224, gb_free=8.8, wall=89287
2022-03-07 15:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:05 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 13.415 | nll_loss 12.955 | ppl 7940.67 | wps 43989.4 | wpb 510.9 | bsz 1 | num_updates 34305 | best_loss 8.725
2022-03-07 15:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34305 updates
2022-03-07 15:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 705 @ 34305 updates, score 13.415) (writing took 2.004947970621288 seconds)
2022-03-07 15:24:07 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-07 15:24:07 | INFO | train | epoch 705 | loss 1.605 | nll_loss 0.239 | ppl 1.18 | wps 25035.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34305 | lr 0.000170735 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 89305
2022-03-07 15:24:07 | INFO | fairseq.trainer | begin training epoch 706
2022-03-07 15:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:26:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:26:12 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 13.521 | nll_loss 13.066 | ppl 8574.57 | wps 43750.1 | wpb 510.9 | bsz 1 | num_updates 34354 | best_loss 8.725
2022-03-07 15:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34354 updates
2022-03-07 15:26:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 706 @ 34354 updates, score 13.521) (writing took 1.8754024868831038 seconds)
2022-03-07 15:26:14 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-07 15:26:14 | INFO | train | epoch 706 | loss 1.606 | nll_loss 0.24 | ppl 1.18 | wps 25057.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34354 | lr 0.000170613 | gnorm 0.348 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89432
2022-03-07 15:26:14 | INFO | fairseq.trainer | begin training epoch 707
2022-03-07 15:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:27:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:28:11 | INFO | train_inner | epoch 707:     47 / 49 loss=1.606, nll_loss=0.24, ppl=1.18, wps=24759.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.35, loss_scale=32, train_wall=224, gb_free=8.8, wall=89549
2022-03-07 15:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:28:21 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 13.471 | nll_loss 13.011 | ppl 8251.95 | wps 37508.1 | wpb 510.9 | bsz 1 | num_updates 34402 | best_loss 8.725
2022-03-07 15:28:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34402 updates
2022-03-07 15:28:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 707 @ 34402 updates, score 13.471) (writing took 2.2880316926166415 seconds)
2022-03-07 15:28:23 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-07 15:28:23 | INFO | train | epoch 707 | loss 1.606 | nll_loss 0.24 | ppl 1.18 | wps 24082.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 34402 | lr 0.000170494 | gnorm 0.351 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 89562
2022-03-07 15:28:23 | INFO | fairseq.trainer | begin training epoch 708
2022-03-07 15:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:30:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:30:37 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 13.452 | nll_loss 12.995 | ppl 8164.1 | wps 44463.2 | wpb 510.9 | bsz 1 | num_updates 34451 | best_loss 8.725
2022-03-07 15:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34451 updates
2022-03-07 15:30:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:30:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 708 @ 34451 updates, score 13.452) (writing took 1.8485547164455056 seconds)
2022-03-07 15:30:39 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-07 15:30:39 | INFO | train | epoch 708 | loss 1.605 | nll_loss 0.239 | ppl 1.18 | wps 23396.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34451 | lr 0.000170372 | gnorm 0.348 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 89697
2022-03-07 15:30:39 | INFO | fairseq.trainer | begin training epoch 709
2022-03-07 15:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:32:39 | INFO | train_inner | epoch 709:     49 / 49 loss=1.605, nll_loss=0.239, ppl=1.18, wps=24107.1, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=34500, lr=0.000170251, gnorm=0.352, loss_scale=32, train_wall=226, gb_free=8.8, wall=89817
2022-03-07 15:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:32:44 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 13.429 | nll_loss 12.971 | ppl 8027.46 | wps 44402.8 | wpb 510.9 | bsz 1 | num_updates 34500 | best_loss 8.725
2022-03-07 15:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34500 updates
2022-03-07 15:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:32:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:32:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 709 @ 34500 updates, score 13.429) (writing took 1.7257267097011209 seconds)
2022-03-07 15:32:46 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-07 15:32:46 | INFO | train | epoch 709 | loss 1.605 | nll_loss 0.239 | ppl 1.18 | wps 25148.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34500 | lr 0.000170251 | gnorm 0.354 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 89824
2022-03-07 15:32:46 | INFO | fairseq.trainer | begin training epoch 710
2022-03-07 15:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:34:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:34:50 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 13.525 | nll_loss 13.067 | ppl 8582.79 | wps 44395.9 | wpb 510.9 | bsz 1 | num_updates 34548 | best_loss 8.725
2022-03-07 15:34:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34548 updates
2022-03-07 15:34:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:34:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:34:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 710 @ 34548 updates, score 13.525) (writing took 1.7185898972675204 seconds)
2022-03-07 15:34:52 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-07 15:34:52 | INFO | train | epoch 710 | loss 1.605 | nll_loss 0.239 | ppl 1.18 | wps 24687.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34548 | lr 0.000170133 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 89950
2022-03-07 15:34:52 | INFO | fairseq.trainer | begin training epoch 711
2022-03-07 15:34:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:36:56 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 13.411 | nll_loss 12.954 | ppl 7935.29 | wps 44577.3 | wpb 510.9 | bsz 1 | num_updates 34597 | best_loss 8.725
2022-03-07 15:36:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34597 updates
2022-03-07 15:36:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:36:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:36:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 711 @ 34597 updates, score 13.411) (writing took 1.9422281105071306 seconds)
2022-03-07 15:36:58 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-07 15:36:58 | INFO | train | epoch 711 | loss 1.605 | nll_loss 0.239 | ppl 1.18 | wps 25180.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34597 | lr 0.000170012 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90076
2022-03-07 15:36:58 | INFO | fairseq.trainer | begin training epoch 712
2022-03-07 15:36:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:37:05 | INFO | train_inner | epoch 712:      3 / 49 loss=1.605, nll_loss=0.239, ppl=1.18, wps=24345.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.349, loss_scale=32, train_wall=223, gb_free=8.8, wall=90084
2022-03-07 15:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:39:02 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 13.471 | nll_loss 13.017 | ppl 8286.97 | wps 44397.6 | wpb 510.9 | bsz 1 | num_updates 34646 | best_loss 8.725
2022-03-07 15:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34646 updates
2022-03-07 15:39:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:39:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 712 @ 34646 updates, score 13.471) (writing took 1.9387764716520905 seconds)
2022-03-07 15:39:04 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-07 15:39:04 | INFO | train | epoch 712 | loss 1.604 | nll_loss 0.238 | ppl 1.18 | wps 25118.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34646 | lr 0.000169892 | gnorm 0.344 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90203
2022-03-07 15:39:04 | INFO | fairseq.trainer | begin training epoch 713
2022-03-07 15:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:41:09 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 13.42 | nll_loss 12.959 | ppl 7964.15 | wps 44537.1 | wpb 510.9 | bsz 1 | num_updates 34694 | best_loss 8.725
2022-03-07 15:41:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34694 updates
2022-03-07 15:41:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 713 @ 34694 updates, score 13.42) (writing took 1.9699801662936807 seconds)
2022-03-07 15:41:11 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-07 15:41:11 | INFO | train | epoch 713 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 24570.9 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 34694 | lr 0.000169775 | gnorm 0.344 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90329
2022-03-07 15:41:11 | INFO | fairseq.trainer | begin training epoch 714
2022-03-07 15:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:41:26 | INFO | train_inner | epoch 714:      6 / 49 loss=1.603, nll_loss=0.238, ppl=1.18, wps=24894, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.344, loss_scale=32, train_wall=223, gb_free=8.8, wall=90344
2022-03-07 15:43:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:43:16 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 13.519 | nll_loss 13.068 | ppl 8587.43 | wps 44548.2 | wpb 510.9 | bsz 1 | num_updates 34743 | best_loss 8.725
2022-03-07 15:43:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34743 updates
2022-03-07 15:43:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:43:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:43:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 714 @ 34743 updates, score 13.519) (writing took 1.9339429279789329 seconds)
2022-03-07 15:43:18 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-07 15:43:18 | INFO | train | epoch 714 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 25128.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34743 | lr 0.000169655 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90456
2022-03-07 15:43:18 | INFO | fairseq.trainer | begin training epoch 715
2022-03-07 15:43:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:45:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:45:22 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 13.436 | nll_loss 12.976 | ppl 8055.86 | wps 44654.7 | wpb 510.9 | bsz 1 | num_updates 34792 | best_loss 8.725
2022-03-07 15:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34792 updates
2022-03-07 15:45:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:45:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 715 @ 34792 updates, score 13.436) (writing took 1.8654254078865051 seconds)
2022-03-07 15:45:24 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-07 15:45:24 | INFO | train | epoch 715 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 25146.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34792 | lr 0.000169535 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90582
2022-03-07 15:45:24 | INFO | fairseq.trainer | begin training epoch 716
2022-03-07 15:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:45:44 | INFO | train_inner | epoch 716:      8 / 49 loss=1.603, nll_loss=0.238, ppl=1.18, wps=25164.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.342, loss_scale=64, train_wall=221, gb_free=8.8, wall=90602
2022-03-07 15:45:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:47:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:28 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 13.45 | nll_loss 12.992 | ppl 8145.09 | wps 44540.6 | wpb 510.9 | bsz 1 | num_updates 34840 | best_loss 8.725
2022-03-07 15:47:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34840 updates
2022-03-07 15:47:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:47:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:47:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 716 @ 34840 updates, score 13.45) (writing took 1.7824056018143892 seconds)
2022-03-07 15:47:30 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-07 15:47:30 | INFO | train | epoch 716 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 24658.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34840 | lr 0.000169419 | gnorm 0.34 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90708
2022-03-07 15:47:30 | INFO | fairseq.trainer | begin training epoch 717
2022-03-07 15:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:35 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 13.503 | nll_loss 13.045 | ppl 8452.39 | wps 44394.6 | wpb 510.9 | bsz 1 | num_updates 34889 | best_loss 8.725
2022-03-07 15:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34889 updates
2022-03-07 15:49:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:49:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 717 @ 34889 updates, score 13.503) (writing took 1.8900852166116238 seconds)
2022-03-07 15:49:37 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-07 15:49:37 | INFO | train | epoch 717 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 25127.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34889 | lr 0.0001693 | gnorm 0.345 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 90835
2022-03-07 15:49:37 | INFO | fairseq.trainer | begin training epoch 718
2022-03-07 15:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:50:04 | INFO | train_inner | epoch 718:     11 / 49 loss=1.603, nll_loss=0.238, ppl=1.18, wps=24943.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.344, loss_scale=32, train_wall=223, gb_free=8.8, wall=90862
2022-03-07 15:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:51:42 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 13.469 | nll_loss 13.011 | ppl 8256.86 | wps 39730.6 | wpb 510.9 | bsz 1 | num_updates 34938 | best_loss 8.725
2022-03-07 15:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34938 updates
2022-03-07 15:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:51:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:51:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 718 @ 34938 updates, score 13.469) (writing took 1.8049368662759662 seconds)
2022-03-07 15:51:44 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-07 15:51:44 | INFO | train | epoch 718 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 25020 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 34938 | lr 0.000169181 | gnorm 0.348 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 90962
2022-03-07 15:51:44 | INFO | fairseq.trainer | begin training epoch 719
2022-03-07 15:51:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:53:48 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 13.432 | nll_loss 12.974 | ppl 8043.26 | wps 44368.5 | wpb 510.9 | bsz 1 | num_updates 34986 | best_loss 8.725
2022-03-07 15:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 34986 updates
2022-03-07 15:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 719 @ 34986 updates, score 13.432) (writing took 2.135388190858066 seconds)
2022-03-07 15:53:50 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-07 15:53:50 | INFO | train | epoch 719 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 24552.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34986 | lr 0.000169065 | gnorm 0.345 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 91089
2022-03-07 15:53:50 | INFO | fairseq.trainer | begin training epoch 720
2022-03-07 15:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:25 | INFO | train_inner | epoch 720:     14 / 49 loss=1.603, nll_loss=0.238, ppl=1.18, wps=24837.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.346, loss_scale=32, train_wall=223, gb_free=8.8, wall=91123
2022-03-07 15:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:55:55 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 13.443 | nll_loss 12.982 | ppl 8091.43 | wps 44223.1 | wpb 510.9 | bsz 1 | num_updates 35035 | best_loss 8.725
2022-03-07 15:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35035 updates
2022-03-07 15:55:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:55:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 720 @ 35035 updates, score 13.443) (writing took 1.8581627123057842 seconds)
2022-03-07 15:55:57 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-07 15:55:57 | INFO | train | epoch 720 | loss 1.603 | nll_loss 0.237 | ppl 1.18 | wps 25137.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35035 | lr 0.000168946 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 91215
2022-03-07 15:55:57 | INFO | fairseq.trainer | begin training epoch 721
2022-03-07 15:55:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:57:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:57:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:58:03 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 13.427 | nll_loss 12.968 | ppl 8013.45 | wps 43894.2 | wpb 510.9 | bsz 1 | num_updates 35083 | best_loss 8.725
2022-03-07 15:58:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35083 updates
2022-03-07 15:58:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:58:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:58:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 721 @ 35083 updates, score 13.427) (writing took 2.0201984513550997 seconds)
2022-03-07 15:58:05 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-07 15:58:05 | INFO | train | epoch 721 | loss 1.602 | nll_loss 0.237 | ppl 1.18 | wps 24230.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 35083 | lr 0.000168831 | gnorm 0.344 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 91343
2022-03-07 15:58:05 | INFO | fairseq.trainer | begin training epoch 722
2022-03-07 15:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:47 | INFO | train_inner | epoch 722:     17 / 49 loss=1.602, nll_loss=0.237, ppl=1.18, wps=24714.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.345, loss_scale=32, train_wall=225, gb_free=8.8, wall=91386
2022-03-07 16:00:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:00:10 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 13.441 | nll_loss 12.982 | ppl 8090.94 | wps 44328 | wpb 510.9 | bsz 1 | num_updates 35132 | best_loss 8.725
2022-03-07 16:00:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35132 updates
2022-03-07 16:00:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:00:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:00:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 722 @ 35132 updates, score 13.441) (writing took 2.0158203886821866 seconds)
2022-03-07 16:00:12 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-07 16:00:12 | INFO | train | epoch 722 | loss 1.602 | nll_loss 0.237 | ppl 1.18 | wps 25055.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35132 | lr 0.000168713 | gnorm 0.345 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 91470
2022-03-07 16:00:12 | INFO | fairseq.trainer | begin training epoch 723
2022-03-07 16:00:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:02:19 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 13.463 | nll_loss 13.006 | ppl 8227.75 | wps 43627.5 | wpb 510.9 | bsz 1 | num_updates 35181 | best_loss 8.725
2022-03-07 16:02:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35181 updates
2022-03-07 16:02:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 723 @ 35181 updates, score 13.463) (writing took 1.8465297343209386 seconds)
2022-03-07 16:02:21 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-07 16:02:21 | INFO | train | epoch 723 | loss 1.603 | nll_loss 0.238 | ppl 1.18 | wps 24650.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35181 | lr 0.000168595 | gnorm 0.352 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 91599
2022-03-07 16:02:21 | INFO | fairseq.trainer | begin training epoch 724
2022-03-07 16:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:08 | INFO | train_inner | epoch 724:     19 / 49 loss=1.603, nll_loss=0.238, ppl=1.18, wps=24886.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.348, loss_scale=32, train_wall=223, gb_free=8.8, wall=91646
2022-03-07 16:03:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:04:27 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 13.519 | nll_loss 13.065 | ppl 8570.4 | wps 36604.7 | wpb 510.9 | bsz 1 | num_updates 35229 | best_loss 8.725
2022-03-07 16:04:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35229 updates
2022-03-07 16:04:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:04:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:04:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 724 @ 35229 updates, score 13.519) (writing took 2.0223304852843285 seconds)
2022-03-07 16:04:29 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-07 16:04:29 | INFO | train | epoch 724 | loss 1.602 | nll_loss 0.237 | ppl 1.18 | wps 24346.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35229 | lr 0.000168481 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 91727
2022-03-07 16:04:29 | INFO | fairseq.trainer | begin training epoch 725
2022-03-07 16:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:06:38 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 13.371 | nll_loss 12.907 | ppl 7679.98 | wps 43807.1 | wpb 510.9 | bsz 1 | num_updates 35278 | best_loss 8.725
2022-03-07 16:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35278 updates
2022-03-07 16:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:06:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 725 @ 35278 updates, score 13.371) (writing took 2.1065062880516052 seconds)
2022-03-07 16:06:40 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-07 16:06:40 | INFO | train | epoch 725 | loss 1.601 | nll_loss 0.236 | ppl 1.18 | wps 24214 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35278 | lr 0.000168364 | gnorm 0.344 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 91858
2022-03-07 16:06:40 | INFO | fairseq.trainer | begin training epoch 726
2022-03-07 16:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:07:35 | INFO | train_inner | epoch 726:     22 / 49 loss=1.602, nll_loss=0.237, ppl=1.18, wps=24348.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.345, loss_scale=32, train_wall=226, gb_free=8.8, wall=91913
2022-03-07 16:08:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:08:45 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 13.431 | nll_loss 12.976 | ppl 8054.23 | wps 43390.8 | wpb 510.9 | bsz 1 | num_updates 35327 | best_loss 8.725
2022-03-07 16:08:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35327 updates
2022-03-07 16:08:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 726 @ 35327 updates, score 13.431) (writing took 2.231628234498203 seconds)
2022-03-07 16:08:47 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-07 16:08:47 | INFO | train | epoch 726 | loss 1.602 | nll_loss 0.237 | ppl 1.18 | wps 24977.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35327 | lr 0.000168247 | gnorm 0.344 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 91986
2022-03-07 16:08:47 | INFO | fairseq.trainer | begin training epoch 727
2022-03-07 16:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:09:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:10:57 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 13.545 | nll_loss 13.092 | ppl 8729.85 | wps 43759.1 | wpb 510.9 | bsz 1 | num_updates 35375 | best_loss 8.725
2022-03-07 16:10:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35375 updates
2022-03-07 16:10:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:10:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:10:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 727 @ 35375 updates, score 13.545) (writing took 2.122214777395129 seconds)
2022-03-07 16:10:59 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-07 16:10:59 | INFO | train | epoch 727 | loss 1.602 | nll_loss 0.237 | ppl 1.18 | wps 23608.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35375 | lr 0.000168133 | gnorm 0.347 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 92117
2022-03-07 16:10:59 | INFO | fairseq.trainer | begin training epoch 728
2022-03-07 16:10:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:12:03 | INFO | train_inner | epoch 728:     25 / 49 loss=1.602, nll_loss=0.237, ppl=1.18, wps=24132, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.346, loss_scale=32, train_wall=228, gb_free=8.8, wall=92182
2022-03-07 16:13:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:13:08 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 13.399 | nll_loss 12.939 | ppl 7854.92 | wps 37362.4 | wpb 510.9 | bsz 1 | num_updates 35424 | best_loss 8.725
2022-03-07 16:13:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35424 updates
2022-03-07 16:13:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:13:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:13:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 728 @ 35424 updates, score 13.399) (writing took 2.293606492690742 seconds)
2022-03-07 16:13:10 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-07 16:13:10 | INFO | train | epoch 728 | loss 1.601 | nll_loss 0.236 | ppl 1.18 | wps 24265.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35424 | lr 0.000168016 | gnorm 0.348 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 92248
2022-03-07 16:13:10 | INFO | fairseq.trainer | begin training epoch 729
2022-03-07 16:13:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:15:26 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 13.455 | nll_loss 12.998 | ppl 8181.43 | wps 43247.3 | wpb 510.9 | bsz 1 | num_updates 35473 | best_loss 8.725
2022-03-07 16:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35473 updates
2022-03-07 16:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 729 @ 35473 updates, score 13.455) (writing took 2.093172444961965 seconds)
2022-03-07 16:15:28 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-07 16:15:28 | INFO | train | epoch 729 | loss 1.602 | nll_loss 0.237 | ppl 1.18 | wps 23080.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35473 | lr 0.0001679 | gnorm 0.342 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 92386
2022-03-07 16:15:28 | INFO | fairseq.trainer | begin training epoch 730
2022-03-07 16:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:16:35 | INFO | train_inner | epoch 730:     27 / 49 loss=1.601, nll_loss=0.237, ppl=1.18, wps=23916, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.344, loss_scale=64, train_wall=228, gb_free=8.8, wall=92453
2022-03-07 16:17:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:17:33 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 13.499 | nll_loss 13.048 | ppl 8467.05 | wps 43500.5 | wpb 510.9 | bsz 1 | num_updates 35521 | best_loss 8.725
2022-03-07 16:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35521 updates
2022-03-07 16:17:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:17:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 730 @ 35521 updates, score 13.499) (writing took 1.9295591358095407 seconds)
2022-03-07 16:17:35 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-07 16:17:35 | INFO | train | epoch 730 | loss 1.601 | nll_loss 0.236 | ppl 1.18 | wps 24531 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35521 | lr 0.000167787 | gnorm 0.344 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 92513
2022-03-07 16:17:35 | INFO | fairseq.trainer | begin training epoch 731
2022-03-07 16:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:19:44 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 13.392 | nll_loss 12.928 | ppl 7794.6 | wps 37229.4 | wpb 510.9 | bsz 1 | num_updates 35570 | best_loss 8.725
2022-03-07 16:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35570 updates
2022-03-07 16:19:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:19:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:19:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 731 @ 35570 updates, score 13.392) (writing took 2.16914227232337 seconds)
2022-03-07 16:19:46 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-07 16:19:46 | INFO | train | epoch 731 | loss 1.601 | nll_loss 0.236 | ppl 1.18 | wps 24244.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35570 | lr 0.000167671 | gnorm 0.346 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 92644
2022-03-07 16:19:46 | INFO | fairseq.trainer | begin training epoch 732
2022-03-07 16:19:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:21:02 | INFO | train_inner | epoch 732:     30 / 49 loss=1.601, nll_loss=0.236, ppl=1.18, wps=24218.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.345, loss_scale=32, train_wall=227, gb_free=8.8, wall=92721
2022-03-07 16:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:21:52 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 13.412 | nll_loss 12.95 | ppl 7913.47 | wps 44555.4 | wpb 510.9 | bsz 1 | num_updates 35619 | best_loss 8.725
2022-03-07 16:21:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35619 updates
2022-03-07 16:21:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:21:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:21:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 732 @ 35619 updates, score 13.412) (writing took 2.2866594921797514 seconds)
2022-03-07 16:21:55 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-07 16:21:55 | INFO | train | epoch 732 | loss 1.6 | nll_loss 0.236 | ppl 1.18 | wps 24679.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35619 | lr 0.000167556 | gnorm 0.342 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 92773
2022-03-07 16:21:55 | INFO | fairseq.trainer | begin training epoch 733
2022-03-07 16:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:24:05 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 13.444 | nll_loss 12.986 | ppl 8111.41 | wps 39291.7 | wpb 510.9 | bsz 1 | num_updates 35668 | best_loss 8.725
2022-03-07 16:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35668 updates
2022-03-07 16:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 733 @ 35668 updates, score 13.444) (writing took 2.266509957611561 seconds)
2022-03-07 16:24:07 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-07 16:24:07 | INFO | train | epoch 733 | loss 1.6 | nll_loss 0.235 | ppl 1.18 | wps 23918.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35668 | lr 0.000167441 | gnorm 0.343 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 92906
2022-03-07 16:24:07 | INFO | fairseq.trainer | begin training epoch 734
2022-03-07 16:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:24:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:25:33 | INFO | train_inner | epoch 734:     33 / 49 loss=1.6, nll_loss=0.236, ppl=1.18, wps=23973.7, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.342, loss_scale=32, train_wall=229, gb_free=8.8, wall=92991
2022-03-07 16:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:26:15 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 13.47 | nll_loss 13.016 | ppl 8281.22 | wps 47304.9 | wpb 510.9 | bsz 1 | num_updates 35716 | best_loss 8.725
2022-03-07 16:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35716 updates
2022-03-07 16:26:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:26:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 734 @ 35716 updates, score 13.47) (writing took 1.8305248338729143 seconds)
2022-03-07 16:26:17 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-07 16:26:17 | INFO | train | epoch 734 | loss 1.6 | nll_loss 0.236 | ppl 1.18 | wps 24016.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 35716 | lr 0.000167328 | gnorm 0.341 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 93035
2022-03-07 16:26:17 | INFO | fairseq.trainer | begin training epoch 735
2022-03-07 16:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:28:29 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 13.461 | nll_loss 13.004 | ppl 8214.41 | wps 39292.4 | wpb 510.9 | bsz 1 | num_updates 35765 | best_loss 8.725
2022-03-07 16:28:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35765 updates
2022-03-07 16:28:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 735 @ 35765 updates, score 13.461) (writing took 1.8874714663252234 seconds)
2022-03-07 16:28:31 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-07 16:28:31 | INFO | train | epoch 735 | loss 1.601 | nll_loss 0.236 | ppl 1.18 | wps 23774.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35765 | lr 0.000167213 | gnorm 0.345 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 93169
2022-03-07 16:28:31 | INFO | fairseq.trainer | begin training epoch 736
2022-03-07 16:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:03 | INFO | train_inner | epoch 736:     35 / 49 loss=1.6, nll_loss=0.236, ppl=1.18, wps=24008.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.343, loss_scale=32, train_wall=228, gb_free=8.8, wall=93261
2022-03-07 16:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:30:44 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 13.43 | nll_loss 12.972 | ppl 8034.95 | wps 39354.6 | wpb 510.9 | bsz 1 | num_updates 35814 | best_loss 8.725
2022-03-07 16:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35814 updates
2022-03-07 16:30:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 736 @ 35814 updates, score 13.43) (writing took 1.8758396413177252 seconds)
2022-03-07 16:30:46 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-07 16:30:46 | INFO | train | epoch 736 | loss 1.6 | nll_loss 0.236 | ppl 1.18 | wps 23499.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35814 | lr 0.000167099 | gnorm 0.343 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 93304
2022-03-07 16:30:46 | INFO | fairseq.trainer | begin training epoch 737
2022-03-07 16:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:32:59 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 13.42 | nll_loss 12.963 | ppl 7982.01 | wps 39349.7 | wpb 510.9 | bsz 1 | num_updates 35863 | best_loss 8.725
2022-03-07 16:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35863 updates
2022-03-07 16:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 737 @ 35863 updates, score 13.42) (writing took 2.0952097326517105 seconds)
2022-03-07 16:33:01 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-07 16:33:01 | INFO | train | epoch 737 | loss 1.599 | nll_loss 0.235 | ppl 1.18 | wps 23559.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35863 | lr 0.000166985 | gnorm 0.343 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 93439
2022-03-07 16:33:01 | INFO | fairseq.trainer | begin training epoch 738
2022-03-07 16:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:33:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:34:38 | INFO | train_inner | epoch 738:     38 / 49 loss=1.599, nll_loss=0.235, ppl=1.18, wps=23619.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.343, loss_scale=32, train_wall=231, gb_free=8.8, wall=93536
2022-03-07 16:35:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:35:08 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 13.458 | nll_loss 13 | ppl 8193.8 | wps 47075.3 | wpb 510.9 | bsz 1 | num_updates 35911 | best_loss 8.725
2022-03-07 16:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35911 updates
2022-03-07 16:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 738 @ 35911 updates, score 13.458) (writing took 1.9521831553429365 seconds)
2022-03-07 16:35:10 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-07 16:35:10 | INFO | train | epoch 738 | loss 1.599 | nll_loss 0.235 | ppl 1.18 | wps 24091.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 35911 | lr 0.000166873 | gnorm 0.341 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 93568
2022-03-07 16:35:10 | INFO | fairseq.trainer | begin training epoch 739
2022-03-07 16:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:12 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 13.479 | nll_loss 13.026 | ppl 8340.83 | wps 46893.2 | wpb 510.9 | bsz 1 | num_updates 35960 | best_loss 8.725
2022-03-07 16:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35960 updates
2022-03-07 16:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:37:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 739 @ 35960 updates, score 13.479) (writing took 2.056506160646677 seconds)
2022-03-07 16:37:15 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-07 16:37:15 | INFO | train | epoch 739 | loss 1.599 | nll_loss 0.235 | ppl 1.18 | wps 25536 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35960 | lr 0.000166759 | gnorm 0.34 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 93693
2022-03-07 16:37:15 | INFO | fairseq.trainer | begin training epoch 740
2022-03-07 16:37:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:38:52 | INFO | train_inner | epoch 740:     40 / 49 loss=1.599, nll_loss=0.235, ppl=1.18, wps=25569.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.341, loss_scale=32, train_wall=218, gb_free=8.8, wall=93790
2022-03-07 16:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:17 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 13.467 | nll_loss 13.008 | ppl 8236.73 | wps 47311.1 | wpb 510.9 | bsz 1 | num_updates 36009 | best_loss 8.725
2022-03-07 16:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36009 updates
2022-03-07 16:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:39:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:39:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 740 @ 36009 updates, score 13.467) (writing took 2.0644638622179627 seconds)
2022-03-07 16:39:19 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-07 16:39:19 | INFO | train | epoch 740 | loss 1.6 | nll_loss 0.236 | ppl 1.18 | wps 25541.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36009 | lr 0.000166646 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 93817
2022-03-07 16:39:19 | INFO | fairseq.trainer | begin training epoch 741
2022-03-07 16:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:39:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:41:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:41:21 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 13.462 | nll_loss 13.006 | ppl 8226.03 | wps 45355.8 | wpb 510.9 | bsz 1 | num_updates 36057 | best_loss 8.725
2022-03-07 16:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36057 updates
2022-03-07 16:41:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:41:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:41:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 741 @ 36057 updates, score 13.462) (writing took 2.1341655952855945 seconds)
2022-03-07 16:41:24 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-07 16:41:24 | INFO | train | epoch 741 | loss 1.599 | nll_loss 0.235 | ppl 1.18 | wps 24983 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 36057 | lr 0.000166535 | gnorm 0.341 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 93942
2022-03-07 16:41:24 | INFO | fairseq.trainer | begin training epoch 742
2022-03-07 16:41:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:08 | INFO | train_inner | epoch 742:     43 / 49 loss=1.599, nll_loss=0.236, ppl=1.18, wps=25293.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36100, lr=0.000166436, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=94046
2022-03-07 16:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:43:26 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 13.386 | nll_loss 12.928 | ppl 7790.96 | wps 46265.6 | wpb 510.9 | bsz 1 | num_updates 36106 | best_loss 8.725
2022-03-07 16:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36106 updates
2022-03-07 16:43:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:43:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 742 @ 36106 updates, score 13.386) (writing took 1.900935884565115 seconds)
2022-03-07 16:43:28 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-07 16:43:28 | INFO | train | epoch 742 | loss 1.599 | nll_loss 0.235 | ppl 1.18 | wps 25509.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36106 | lr 0.000166422 | gnorm 0.341 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 94066
2022-03-07 16:43:28 | INFO | fairseq.trainer | begin training epoch 743
2022-03-07 16:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:45:31 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 13.456 | nll_loss 12.997 | ppl 8175.45 | wps 46980.6 | wpb 510.9 | bsz 1 | num_updates 36155 | best_loss 8.725
2022-03-07 16:45:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36155 updates
2022-03-07 16:45:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:45:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 743 @ 36155 updates, score 13.456) (writing took 2.0169746223837137 seconds)
2022-03-07 16:45:33 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-07 16:45:33 | INFO | train | epoch 743 | loss 1.599 | nll_loss 0.235 | ppl 1.18 | wps 25503.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36155 | lr 0.000166309 | gnorm 0.344 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 94191
2022-03-07 16:45:33 | INFO | fairseq.trainer | begin training epoch 744
2022-03-07 16:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:47:24 | INFO | train_inner | epoch 744:     46 / 49 loss=1.599, nll_loss=0.235, ppl=1.18, wps=25342.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=94302
2022-03-07 16:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:47:35 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 13.52 | nll_loss 13.067 | ppl 8579.88 | wps 47441.9 | wpb 510.9 | bsz 1 | num_updates 36203 | best_loss 8.725
2022-03-07 16:47:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36203 updates
2022-03-07 16:47:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:47:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:47:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 744 @ 36203 updates, score 13.52) (writing took 1.8813855797052383 seconds)
2022-03-07 16:47:37 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-07 16:47:37 | INFO | train | epoch 744 | loss 1.598 | nll_loss 0.234 | ppl 1.18 | wps 25113.8 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 36203 | lr 0.000166199 | gnorm 0.338 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 94315
2022-03-07 16:47:37 | INFO | fairseq.trainer | begin training epoch 745
2022-03-07 16:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:39 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 13.388 | nll_loss 12.928 | ppl 7791.02 | wps 47348.9 | wpb 510.9 | bsz 1 | num_updates 36252 | best_loss 8.725
2022-03-07 16:49:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36252 updates
2022-03-07 16:49:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 745 @ 36252 updates, score 13.388) (writing took 2.0177426505833864 seconds)
2022-03-07 16:49:42 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-07 16:49:42 | INFO | train | epoch 745 | loss 1.599 | nll_loss 0.235 | ppl 1.18 | wps 25455.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36252 | lr 0.000166086 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 94440
2022-03-07 16:49:42 | INFO | fairseq.trainer | begin training epoch 746
2022-03-07 16:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:51:38 | INFO | train_inner | epoch 746:     48 / 49 loss=1.599, nll_loss=0.235, ppl=1.18, wps=25565.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.341, loss_scale=32, train_wall=218, gb_free=8.8, wall=94556
2022-03-07 16:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:44 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 13.399 | nll_loss 12.939 | ppl 7852.67 | wps 46897.2 | wpb 510.9 | bsz 1 | num_updates 36301 | best_loss 8.725
2022-03-07 16:51:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36301 updates
2022-03-07 16:51:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:51:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:51:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 746 @ 36301 updates, score 13.399) (writing took 1.9717334117740393 seconds)
2022-03-07 16:51:46 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-07 16:51:46 | INFO | train | epoch 746 | loss 1.598 | nll_loss 0.235 | ppl 1.18 | wps 25585.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36301 | lr 0.000165974 | gnorm 0.344 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 94564
2022-03-07 16:51:46 | INFO | fairseq.trainer | begin training epoch 747
2022-03-07 16:51:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:52:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:53:48 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 13.387 | nll_loss 12.922 | ppl 7758.65 | wps 47191.4 | wpb 510.9 | bsz 1 | num_updates 36349 | best_loss 8.725
2022-03-07 16:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36349 updates
2022-03-07 16:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 747 @ 36349 updates, score 13.387) (writing took 1.9943200619891286 seconds)
2022-03-07 16:53:50 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-07 16:53:50 | INFO | train | epoch 747 | loss 1.598 | nll_loss 0.234 | ppl 1.18 | wps 25000.5 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 36349 | lr 0.000165865 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 94688
2022-03-07 16:53:50 | INFO | fairseq.trainer | begin training epoch 748
2022-03-07 16:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:55:52 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 13.447 | nll_loss 12.992 | ppl 8145.89 | wps 47096.4 | wpb 510.9 | bsz 1 | num_updates 36398 | best_loss 8.725
2022-03-07 16:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36398 updates
2022-03-07 16:55:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:55:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 748 @ 36398 updates, score 13.447) (writing took 1.899634432978928 seconds)
2022-03-07 16:55:54 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-07 16:55:54 | INFO | train | epoch 748 | loss 1.598 | nll_loss 0.234 | ppl 1.18 | wps 25613.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36398 | lr 0.000165753 | gnorm 0.346 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 94813
2022-03-07 16:55:54 | INFO | fairseq.trainer | begin training epoch 749
2022-03-07 16:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:55:59 | INFO | train_inner | epoch 749:      2 / 49 loss=1.598, nll_loss=0.234, ppl=1.18, wps=24689.4, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=36400, lr=0.000165748, gnorm=0.344, loss_scale=32, train_wall=219, gb_free=8.8, wall=94817
2022-03-07 16:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:57:57 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 13.381 | nll_loss 12.919 | ppl 7743.3 | wps 46814.9 | wpb 510.9 | bsz 1 | num_updates 36447 | best_loss 8.725
2022-03-07 16:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36447 updates
2022-03-07 16:57:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 749 @ 36447 updates, score 13.381) (writing took 2.0463948706164956 seconds)
2022-03-07 16:57:59 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-07 16:57:59 | INFO | train | epoch 749 | loss 1.597 | nll_loss 0.234 | ppl 1.18 | wps 25563.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36447 | lr 0.000165641 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 94937
2022-03-07 16:57:59 | INFO | fairseq.trainer | begin training epoch 750
2022-03-07 16:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:59:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:59:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:00:01 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 13.491 | nll_loss 13.036 | ppl 8396.11 | wps 47046.4 | wpb 510.9 | bsz 1 | num_updates 36495 | best_loss 8.725
2022-03-07 17:00:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36495 updates
2022-03-07 17:00:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 750 @ 36495 updates, score 13.491) (writing took 2.0339803295210004 seconds)
2022-03-07 17:00:03 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-07 17:00:03 | INFO | train | epoch 750 | loss 1.597 | nll_loss 0.233 | ppl 1.18 | wps 25050.4 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 36495 | lr 0.000165533 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 95061
2022-03-07 17:00:03 | INFO | fairseq.trainer | begin training epoch 751
2022-03-07 17:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:15 | INFO | train_inner | epoch 751:      5 / 49 loss=1.597, nll_loss=0.233, ppl=1.18, wps=25359.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.336, loss_scale=32, train_wall=220, gb_free=8.8, wall=95073
2022-03-07 17:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:02:06 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 13.491 | nll_loss 13.035 | ppl 8395.64 | wps 44750.3 | wpb 510.9 | bsz 1 | num_updates 36544 | best_loss 8.725
2022-03-07 17:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36544 updates
2022-03-07 17:02:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 751 @ 36544 updates, score 13.491) (writing took 1.9955579340457916 seconds)
2022-03-07 17:02:08 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-07 17:02:08 | INFO | train | epoch 751 | loss 1.597 | nll_loss 0.233 | ppl 1.18 | wps 25450.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36544 | lr 0.000165422 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 95186
2022-03-07 17:02:08 | INFO | fairseq.trainer | begin training epoch 752
2022-03-07 17:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:04:10 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 13.45 | nll_loss 12.992 | ppl 8146.82 | wps 47076.1 | wpb 510.9 | bsz 1 | num_updates 36593 | best_loss 8.725
2022-03-07 17:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36593 updates
2022-03-07 17:04:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:04:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:04:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 752 @ 36593 updates, score 13.45) (writing took 1.9264209270477295 seconds)
2022-03-07 17:04:12 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-07 17:04:12 | INFO | train | epoch 752 | loss 1.598 | nll_loss 0.234 | ppl 1.18 | wps 25564 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36593 | lr 0.000165311 | gnorm 0.341 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 95310
2022-03-07 17:04:12 | INFO | fairseq.trainer | begin training epoch 753
2022-03-07 17:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:29 | INFO | train_inner | epoch 753:      7 / 49 loss=1.597, nll_loss=0.234, ppl=1.18, wps=25524.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.339, loss_scale=32, train_wall=218, gb_free=8.8, wall=95327
2022-03-07 17:06:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:06:16 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 13.465 | nll_loss 13.011 | ppl 8251.93 | wps 47001.3 | wpb 510.9 | bsz 1 | num_updates 36641 | best_loss 8.725
2022-03-07 17:06:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36641 updates
2022-03-07 17:06:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:06:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 753 @ 36641 updates, score 13.465) (writing took 1.9994206503033638 seconds)
2022-03-07 17:06:18 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-07 17:06:18 | INFO | train | epoch 753 | loss 1.597 | nll_loss 0.234 | ppl 1.18 | wps 24805.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36641 | lr 0.000165202 | gnorm 0.338 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 95436
2022-03-07 17:06:18 | INFO | fairseq.trainer | begin training epoch 754
2022-03-07 17:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:08:20 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 13.517 | nll_loss 13.065 | ppl 8570.15 | wps 46995.4 | wpb 510.9 | bsz 1 | num_updates 36690 | best_loss 8.725
2022-03-07 17:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36690 updates
2022-03-07 17:08:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:08:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:08:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 754 @ 36690 updates, score 13.517) (writing took 1.9541998421773314 seconds)
2022-03-07 17:08:22 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-07 17:08:22 | INFO | train | epoch 754 | loss 1.597 | nll_loss 0.234 | ppl 1.18 | wps 25587.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36690 | lr 0.000165092 | gnorm 0.34 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 95560
2022-03-07 17:08:22 | INFO | fairseq.trainer | begin training epoch 755
2022-03-07 17:08:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:08:46 | INFO | train_inner | epoch 755:     10 / 49 loss=1.597, nll_loss=0.233, ppl=1.18, wps=25254, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.339, loss_scale=32, train_wall=221, gb_free=8.8, wall=95584
2022-03-07 17:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:10:24 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 13.472 | nll_loss 13.018 | ppl 8295.59 | wps 46611.2 | wpb 510.9 | bsz 1 | num_updates 36739 | best_loss 8.725
2022-03-07 17:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36739 updates
2022-03-07 17:10:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:10:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:10:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 755 @ 36739 updates, score 13.472) (writing took 1.7903263345360756 seconds)
2022-03-07 17:10:26 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-07 17:10:26 | INFO | train | epoch 755 | loss 1.597 | nll_loss 0.234 | ppl 1.18 | wps 25529.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36739 | lr 0.000164982 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 95684
2022-03-07 17:10:26 | INFO | fairseq.trainer | begin training epoch 756
2022-03-07 17:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:11:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:12:28 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 13.472 | nll_loss 13.016 | ppl 8283.5 | wps 47196.7 | wpb 510.9 | bsz 1 | num_updates 36787 | best_loss 8.725
2022-03-07 17:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36787 updates
2022-03-07 17:12:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 756 @ 36787 updates, score 13.472) (writing took 1.8056085454300046 seconds)
2022-03-07 17:12:30 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-07 17:12:30 | INFO | train | epoch 756 | loss 1.597 | nll_loss 0.233 | ppl 1.18 | wps 25093 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 36787 | lr 0.000164874 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 95808
2022-03-07 17:12:30 | INFO | fairseq.trainer | begin training epoch 757
2022-03-07 17:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:13:02 | INFO | train_inner | epoch 757:     13 / 49 loss=1.597, nll_loss=0.233, ppl=1.18, wps=25367.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=95840
2022-03-07 17:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:14:32 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 13.413 | nll_loss 12.954 | ppl 7932.95 | wps 47255.8 | wpb 510.9 | bsz 1 | num_updates 36836 | best_loss 8.725
2022-03-07 17:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36836 updates
2022-03-07 17:14:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 757 @ 36836 updates, score 13.413) (writing took 1.7805151352658868 seconds)
2022-03-07 17:14:34 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-07 17:14:34 | INFO | train | epoch 757 | loss 1.596 | nll_loss 0.233 | ppl 1.18 | wps 25656.6 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 36836 | lr 0.000164765 | gnorm 0.339 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 95932
2022-03-07 17:14:34 | INFO | fairseq.trainer | begin training epoch 758
2022-03-07 17:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:16:36 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 13.406 | nll_loss 12.948 | ppl 7904.14 | wps 47394.8 | wpb 510.9 | bsz 1 | num_updates 36885 | best_loss 8.725
2022-03-07 17:16:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36885 updates
2022-03-07 17:16:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:16:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:16:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 758 @ 36885 updates, score 13.406) (writing took 1.822809524834156 seconds)
2022-03-07 17:16:38 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-07 17:16:38 | INFO | train | epoch 758 | loss 1.596 | nll_loss 0.233 | ppl 1.18 | wps 25654.7 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 36885 | lr 0.000164655 | gnorm 0.338 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 96056
2022-03-07 17:16:38 | INFO | fairseq.trainer | begin training epoch 759
2022-03-07 17:16:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:14 | INFO | train_inner | epoch 759:     15 / 49 loss=1.596, nll_loss=0.233, ppl=1.18, wps=25689.7, ups=0.4, wpb=64876.2, bsz=126.7, num_updates=36900, lr=0.000164622, gnorm=0.338, loss_scale=64, train_wall=217, gb_free=8.8, wall=96093
2022-03-07 17:18:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:18:41 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 13.43 | nll_loss 12.97 | ppl 8022.92 | wps 47029 | wpb 510.9 | bsz 1 | num_updates 36933 | best_loss 8.725
2022-03-07 17:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36933 updates
2022-03-07 17:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 759 @ 36933 updates, score 13.43) (writing took 1.8192552039399743 seconds)
2022-03-07 17:18:43 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-07 17:18:43 | INFO | train | epoch 759 | loss 1.596 | nll_loss 0.233 | ppl 1.18 | wps 24961.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36933 | lr 0.000164548 | gnorm 0.34 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 96181
2022-03-07 17:18:43 | INFO | fairseq.trainer | begin training epoch 760
2022-03-07 17:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:20:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:20:46 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 13.485 | nll_loss 13.029 | ppl 8359.38 | wps 47219.4 | wpb 510.9 | bsz 1 | num_updates 36982 | best_loss 8.725
2022-03-07 17:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36982 updates
2022-03-07 17:20:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:20:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:20:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 760 @ 36982 updates, score 13.485) (writing took 1.9236512845382094 seconds)
2022-03-07 17:20:48 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-07 17:20:48 | INFO | train | epoch 760 | loss 1.596 | nll_loss 0.233 | ppl 1.18 | wps 25320.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36982 | lr 0.000164439 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 96306
2022-03-07 17:20:48 | INFO | fairseq.trainer | begin training epoch 761
2022-03-07 17:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:21:32 | INFO | train_inner | epoch 761:     18 / 49 loss=1.596, nll_loss=0.233, ppl=1.18, wps=25190.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.342, loss_scale=32, train_wall=221, gb_free=8.8, wall=96350
2022-03-07 17:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:22:51 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 13.435 | nll_loss 12.974 | ppl 8046.08 | wps 47139.1 | wpb 510.9 | bsz 1 | num_updates 37031 | best_loss 8.725
2022-03-07 17:22:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37031 updates
2022-03-07 17:22:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:22:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 761 @ 37031 updates, score 13.435) (writing took 1.7900839550420642 seconds)
2022-03-07 17:22:53 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-07 17:22:53 | INFO | train | epoch 761 | loss 1.596 | nll_loss 0.233 | ppl 1.17 | wps 25485.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37031 | lr 0.00016433 | gnorm 0.34 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 96431
2022-03-07 17:22:53 | INFO | fairseq.trainer | begin training epoch 762
2022-03-07 17:22:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:23:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:24:55 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 13.419 | nll_loss 12.964 | ppl 7988.06 | wps 46790.5 | wpb 510.9 | bsz 1 | num_updates 37079 | best_loss 8.725
2022-03-07 17:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37079 updates
2022-03-07 17:24:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:24:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 762 @ 37079 updates, score 13.419) (writing took 1.9548713602125645 seconds)
2022-03-07 17:24:57 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-07 17:24:57 | INFO | train | epoch 762 | loss 1.595 | nll_loss 0.233 | ppl 1.17 | wps 25029.7 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 37079 | lr 0.000164224 | gnorm 0.341 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 96556
2022-03-07 17:24:57 | INFO | fairseq.trainer | begin training epoch 763
2022-03-07 17:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:25:48 | INFO | train_inner | epoch 763:     21 / 49 loss=1.596, nll_loss=0.233, ppl=1.18, wps=25296.2, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=96607
2022-03-07 17:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:27:00 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 13.44 | nll_loss 12.984 | ppl 8103.34 | wps 47157.1 | wpb 510.9 | bsz 1 | num_updates 37128 | best_loss 8.725
2022-03-07 17:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37128 updates
2022-03-07 17:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 763 @ 37128 updates, score 13.44) (writing took 1.8772516939789057 seconds)
2022-03-07 17:27:02 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-07 17:27:02 | INFO | train | epoch 763 | loss 1.595 | nll_loss 0.233 | ppl 1.18 | wps 25583 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37128 | lr 0.000164115 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 96680
2022-03-07 17:27:02 | INFO | fairseq.trainer | begin training epoch 764
2022-03-07 17:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:28:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:29:04 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 13.418 | nll_loss 12.957 | ppl 7951.37 | wps 47028.3 | wpb 510.9 | bsz 1 | num_updates 37177 | best_loss 8.725
2022-03-07 17:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37177 updates
2022-03-07 17:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:29:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 764 @ 37177 updates, score 13.418) (writing took 1.9342918768525124 seconds)
2022-03-07 17:29:06 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-07 17:29:06 | INFO | train | epoch 764 | loss 1.595 | nll_loss 0.233 | ppl 1.17 | wps 25622.4 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 37177 | lr 0.000164007 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 96804
2022-03-07 17:29:06 | INFO | fairseq.trainer | begin training epoch 765
2022-03-07 17:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:02 | INFO | train_inner | epoch 765:     23 / 49 loss=1.595, nll_loss=0.232, ppl=1.17, wps=25616.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.339, loss_scale=64, train_wall=218, gb_free=8.8, wall=96860
2022-03-07 17:30:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:08 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 13.4 | nll_loss 12.944 | ppl 7879.89 | wps 47214.5 | wpb 510.9 | bsz 1 | num_updates 37225 | best_loss 8.725
2022-03-07 17:31:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37225 updates
2022-03-07 17:31:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:31:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:31:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 765 @ 37225 updates, score 13.4) (writing took 1.934727804735303 seconds)
2022-03-07 17:31:10 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-07 17:31:10 | INFO | train | epoch 765 | loss 1.595 | nll_loss 0.232 | ppl 1.17 | wps 25026.7 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 37225 | lr 0.000163901 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 96928
2022-03-07 17:31:10 | INFO | fairseq.trainer | begin training epoch 766
2022-03-07 17:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:33:12 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 13.479 | nll_loss 13.025 | ppl 8333.34 | wps 47222.8 | wpb 510.9 | bsz 1 | num_updates 37274 | best_loss 8.725
2022-03-07 17:33:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37274 updates
2022-03-07 17:33:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:33:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:33:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 766 @ 37274 updates, score 13.479) (writing took 1.9139694077894092 seconds)
2022-03-07 17:33:14 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-07 17:33:14 | INFO | train | epoch 766 | loss 1.595 | nll_loss 0.232 | ppl 1.17 | wps 25584.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37274 | lr 0.000163794 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 97052
2022-03-07 17:33:14 | INFO | fairseq.trainer | begin training epoch 767
2022-03-07 17:33:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:34:17 | INFO | train_inner | epoch 767:     26 / 49 loss=1.595, nll_loss=0.232, ppl=1.17, wps=25378.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=97115
2022-03-07 17:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:35:16 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 13.51 | nll_loss 13.056 | ppl 8517.9 | wps 47154.7 | wpb 510.9 | bsz 1 | num_updates 37323 | best_loss 8.725
2022-03-07 17:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37323 updates
2022-03-07 17:35:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:35:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 767 @ 37323 updates, score 13.51) (writing took 1.9505396988242865 seconds)
2022-03-07 17:35:18 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-07 17:35:18 | INFO | train | epoch 767 | loss 1.595 | nll_loss 0.233 | ppl 1.18 | wps 25597 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37323 | lr 0.000163686 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 97177
2022-03-07 17:35:18 | INFO | fairseq.trainer | begin training epoch 768
2022-03-07 17:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:36:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:37:21 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 13.403 | nll_loss 12.947 | ppl 7896.34 | wps 46301.3 | wpb 510.9 | bsz 1 | num_updates 37371 | best_loss 8.725
2022-03-07 17:37:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37371 updates
2022-03-07 17:37:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:37:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 768 @ 37371 updates, score 13.403) (writing took 1.8524082163348794 seconds)
2022-03-07 17:37:23 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-07 17:37:23 | INFO | train | epoch 768 | loss 1.595 | nll_loss 0.232 | ppl 1.17 | wps 24927 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37371 | lr 0.000163581 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 97301
2022-03-07 17:37:23 | INFO | fairseq.trainer | begin training epoch 769
2022-03-07 17:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:38:33 | INFO | train_inner | epoch 769:     29 / 49 loss=1.595, nll_loss=0.232, ppl=1.17, wps=25311.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=97372
2022-03-07 17:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:39:25 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 13.375 | nll_loss 12.917 | ppl 7732.54 | wps 47349.6 | wpb 510.9 | bsz 1 | num_updates 37420 | best_loss 8.725
2022-03-07 17:39:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37420 updates
2022-03-07 17:39:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:39:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 769 @ 37420 updates, score 13.375) (writing took 1.9820227846503258 seconds)
2022-03-07 17:39:27 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-07 17:39:27 | INFO | train | epoch 769 | loss 1.594 | nll_loss 0.232 | ppl 1.17 | wps 25594 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37420 | lr 0.000163474 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 97426
2022-03-07 17:39:27 | INFO | fairseq.trainer | begin training epoch 770
2022-03-07 17:39:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:41:30 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 13.433 | nll_loss 12.976 | ppl 8055.63 | wps 47233.9 | wpb 510.9 | bsz 1 | num_updates 37469 | best_loss 8.725
2022-03-07 17:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37469 updates
2022-03-07 17:41:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 770 @ 37469 updates, score 13.433) (writing took 1.899093084037304 seconds)
2022-03-07 17:41:32 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-07 17:41:32 | INFO | train | epoch 770 | loss 1.595 | nll_loss 0.232 | ppl 1.17 | wps 25516.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37469 | lr 0.000163367 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 97550
2022-03-07 17:41:32 | INFO | fairseq.trainer | begin training epoch 771
2022-03-07 17:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:42:50 | INFO | train_inner | epoch 771:     32 / 49 loss=1.594, nll_loss=0.232, ppl=1.17, wps=25292, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=97628
2022-03-07 17:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:43:35 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 13.445 | nll_loss 12.99 | ppl 8136.37 | wps 47296.3 | wpb 510.9 | bsz 1 | num_updates 37517 | best_loss 8.725
2022-03-07 17:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37517 updates
2022-03-07 17:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 771 @ 37517 updates, score 13.445) (writing took 1.9382936917245388 seconds)
2022-03-07 17:43:36 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-07 17:43:36 | INFO | train | epoch 771 | loss 1.594 | nll_loss 0.231 | ppl 1.17 | wps 24976.2 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 37517 | lr 0.000163262 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 97675
2022-03-07 17:43:37 | INFO | fairseq.trainer | begin training epoch 772
2022-03-07 17:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:45:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:39 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 13.379 | nll_loss 12.918 | ppl 7739.83 | wps 47121.9 | wpb 510.9 | bsz 1 | num_updates 37566 | best_loss 8.725
2022-03-07 17:45:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37566 updates
2022-03-07 17:45:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:45:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:45:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 772 @ 37566 updates, score 13.379) (writing took 1.7577612195163965 seconds)
2022-03-07 17:45:41 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-07 17:45:41 | INFO | train | epoch 772 | loss 1.594 | nll_loss 0.232 | ppl 1.17 | wps 25577.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37566 | lr 0.000163156 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 97799
2022-03-07 17:45:41 | INFO | fairseq.trainer | begin training epoch 773
2022-03-07 17:45:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:47:03 | INFO | train_inner | epoch 773:     34 / 49 loss=1.594, nll_loss=0.232, ppl=1.17, wps=25633.4, ups=0.4, wpb=64871.8, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.337, loss_scale=32, train_wall=218, gb_free=8.8, wall=97881
2022-03-07 17:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:47:43 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 13.445 | nll_loss 12.99 | ppl 8137.77 | wps 47212.9 | wpb 510.9 | bsz 1 | num_updates 37615 | best_loss 8.725
2022-03-07 17:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37615 updates
2022-03-07 17:47:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:47:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 773 @ 37615 updates, score 13.445) (writing took 1.9754708716645837 seconds)
2022-03-07 17:47:45 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-07 17:47:45 | INFO | train | epoch 773 | loss 1.594 | nll_loss 0.232 | ppl 1.17 | wps 25617.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37615 | lr 0.000163049 | gnorm 0.338 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 97923
2022-03-07 17:47:45 | INFO | fairseq.trainer | begin training epoch 774
2022-03-07 17:47:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:49:47 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 13.372 | nll_loss 12.911 | ppl 7699.85 | wps 47231.9 | wpb 510.9 | bsz 1 | num_updates 37664 | best_loss 8.725
2022-03-07 17:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37664 updates
2022-03-07 17:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:49:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 774 @ 37664 updates, score 13.372) (writing took 1.9458278622478247 seconds)
2022-03-07 17:49:49 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-07 17:49:49 | INFO | train | epoch 774 | loss 1.594 | nll_loss 0.232 | ppl 1.17 | wps 25506.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37664 | lr 0.000162943 | gnorm 0.338 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 98048
2022-03-07 17:49:49 | INFO | fairseq.trainer | begin training epoch 775
2022-03-07 17:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:50:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:51:21 | INFO | train_inner | epoch 775:     37 / 49 loss=1.594, nll_loss=0.231, ppl=1.17, wps=25179.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.337, loss_scale=32, train_wall=221, gb_free=8.8, wall=98139
2022-03-07 17:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:51:54 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 13.498 | nll_loss 13.044 | ppl 8445.94 | wps 46794.5 | wpb 510.9 | bsz 1 | num_updates 37712 | best_loss 8.725
2022-03-07 17:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37712 updates
2022-03-07 17:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:51:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:51:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 775 @ 37712 updates, score 13.498) (writing took 1.8054073192179203 seconds)
2022-03-07 17:51:56 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-07 17:51:56 | INFO | train | epoch 775 | loss 1.593 | nll_loss 0.231 | ppl 1.17 | wps 24649.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37712 | lr 0.00016284 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 98174
2022-03-07 17:51:56 | INFO | fairseq.trainer | begin training epoch 776
2022-03-07 17:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:53:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:53:59 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 13.403 | nll_loss 12.945 | ppl 7885.44 | wps 44235.7 | wpb 510.9 | bsz 1 | num_updates 37761 | best_loss 8.725
2022-03-07 17:53:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37761 updates
2022-03-07 17:53:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 776 @ 37761 updates, score 13.403) (writing took 1.9649424161762 seconds)
2022-03-07 17:54:01 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-07 17:54:01 | INFO | train | epoch 776 | loss 1.594 | nll_loss 0.231 | ppl 1.17 | wps 25317.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37761 | lr 0.000162734 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98299
2022-03-07 17:54:01 | INFO | fairseq.trainer | begin training epoch 777
2022-03-07 17:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:55:39 | INFO | train_inner | epoch 777:     39 / 49 loss=1.594, nll_loss=0.232, ppl=1.17, wps=25118.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37800, lr=0.00016265, gnorm=0.337, loss_scale=64, train_wall=221, gb_free=8.8, wall=98397
2022-03-07 17:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:56:07 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 13.471 | nll_loss 13.014 | ppl 8273.27 | wps 47165.5 | wpb 510.9 | bsz 1 | num_updates 37810 | best_loss 8.725
2022-03-07 17:56:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37810 updates
2022-03-07 17:56:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:56:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:56:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 777 @ 37810 updates, score 13.471) (writing took 1.774590670131147 seconds)
2022-03-07 17:56:09 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-07 17:56:09 | INFO | train | epoch 777 | loss 1.594 | nll_loss 0.232 | ppl 1.17 | wps 24953.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37810 | lr 0.000162629 | gnorm 0.337 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 98427
2022-03-07 17:56:09 | INFO | fairseq.trainer | begin training epoch 778
2022-03-07 17:56:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:58:11 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 13.432 | nll_loss 12.978 | ppl 8066.99 | wps 47439.9 | wpb 510.9 | bsz 1 | num_updates 37858 | best_loss 8.725
2022-03-07 17:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37858 updates
2022-03-07 17:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:58:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 778 @ 37858 updates, score 13.432) (writing took 1.8821253590285778 seconds)
2022-03-07 17:58:13 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-07 17:58:13 | INFO | train | epoch 778 | loss 1.593 | nll_loss 0.231 | ppl 1.17 | wps 25090.9 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 37858 | lr 0.000162525 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98551
2022-03-07 17:58:13 | INFO | fairseq.trainer | begin training epoch 779
2022-03-07 17:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:59:55 | INFO | train_inner | epoch 779:     42 / 49 loss=1.593, nll_loss=0.231, ppl=1.17, wps=25337.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=98653
2022-03-07 18:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:00:16 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 13.436 | nll_loss 12.979 | ppl 8071.33 | wps 44483.6 | wpb 510.9 | bsz 1 | num_updates 37907 | best_loss 8.725
2022-03-07 18:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37907 updates
2022-03-07 18:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:00:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:00:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 779 @ 37907 updates, score 13.436) (writing took 1.7305550565943122 seconds)
2022-03-07 18:00:18 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-07 18:00:18 | INFO | train | epoch 779 | loss 1.593 | nll_loss 0.231 | ppl 1.17 | wps 25443.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37907 | lr 0.00016242 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98676
2022-03-07 18:00:18 | INFO | fairseq.trainer | begin training epoch 780
2022-03-07 18:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:02:20 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 13.43 | nll_loss 12.974 | ppl 8048.03 | wps 46938.8 | wpb 510.9 | bsz 1 | num_updates 37956 | best_loss 8.725
2022-03-07 18:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37956 updates
2022-03-07 18:02:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:02:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 780 @ 37956 updates, score 13.43) (writing took 1.9440387962386012 seconds)
2022-03-07 18:02:22 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-07 18:02:22 | INFO | train | epoch 780 | loss 1.593 | nll_loss 0.231 | ppl 1.17 | wps 25529.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37956 | lr 0.000162315 | gnorm 0.336 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 98800
2022-03-07 18:02:22 | INFO | fairseq.trainer | begin training epoch 781
2022-03-07 18:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:04:09 | INFO | train_inner | epoch 781:     44 / 49 loss=1.593, nll_loss=0.231, ppl=1.17, wps=25529.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.337, loss_scale=64, train_wall=218, gb_free=8.8, wall=98907
2022-03-07 18:04:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:25 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 13.368 | nll_loss 12.907 | ppl 7678.42 | wps 45802.2 | wpb 510.9 | bsz 1 | num_updates 38005 | best_loss 8.725
2022-03-07 18:04:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 38005 updates
2022-03-07 18:04:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:04:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 781 @ 38005 updates, score 13.368) (writing took 1.947293863631785 seconds)
2022-03-07 18:04:27 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-07 18:04:27 | INFO | train | epoch 781 | loss 1.593 | nll_loss 0.231 | ppl 1.17 | wps 25470.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38005 | lr 0.000162211 | gnorm 0.337 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 98925
2022-03-07 18:04:27 | INFO | fairseq.trainer | begin training epoch 782
2022-03-07 18:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:04:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:06:33 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 13.409 | nll_loss 12.953 | ppl 7927.26 | wps 44951.7 | wpb 510.9 | bsz 1 | num_updates 38053 | best_loss 8.725
2022-03-07 18:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38053 updates
2022-03-07 18:06:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:06:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:06:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 782 @ 38053 updates, score 13.409) (writing took 2.0791043043136597 seconds)
2022-03-07 18:06:35 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-07 18:06:35 | INFO | train | epoch 782 | loss 1.592 | nll_loss 0.231 | ppl 1.17 | wps 24252.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38053 | lr 0.000162108 | gnorm 0.337 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 99053
2022-03-07 18:06:35 | INFO | fairseq.trainer | begin training epoch 783
2022-03-07 18:06:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:08:31 | INFO | train_inner | epoch 783:     47 / 49 loss=1.593, nll_loss=0.231, ppl=1.17, wps=24796.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.337, loss_scale=32, train_wall=224, gb_free=8.8, wall=99169
2022-03-07 18:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:08:39 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 13.469 | nll_loss 13.018 | ppl 8292.07 | wps 45041.2 | wpb 510.9 | bsz 1 | num_updates 38102 | best_loss 8.725
2022-03-07 18:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38102 updates
2022-03-07 18:08:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:08:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 783 @ 38102 updates, score 13.469) (writing took 1.8869537031278014 seconds)
2022-03-07 18:08:41 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-07 18:08:41 | INFO | train | epoch 783 | loss 1.592 | nll_loss 0.23 | ppl 1.17 | wps 25204.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38102 | lr 0.000162004 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99179
2022-03-07 18:08:41 | INFO | fairseq.trainer | begin training epoch 784
2022-03-07 18:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:10:46 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 13.416 | nll_loss 12.957 | ppl 7951.45 | wps 44590.4 | wpb 510.9 | bsz 1 | num_updates 38151 | best_loss 8.725
2022-03-07 18:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38151 updates
2022-03-07 18:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:10:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 784 @ 38151 updates, score 13.416) (writing took 2.0302819991484284 seconds)
2022-03-07 18:10:48 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-07 18:10:48 | INFO | train | epoch 784 | loss 1.592 | nll_loss 0.23 | ppl 1.17 | wps 25153 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38151 | lr 0.0001619 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 99306
2022-03-07 18:10:48 | INFO | fairseq.trainer | begin training epoch 785
2022-03-07 18:10:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:12:52 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 13.449 | nll_loss 12.993 | ppl 8154.96 | wps 44862.3 | wpb 510.9 | bsz 1 | num_updates 38199 | best_loss 8.725
2022-03-07 18:12:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38199 updates
2022-03-07 18:12:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:12:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:12:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 785 @ 38199 updates, score 13.449) (writing took 1.8832646887749434 seconds)
2022-03-07 18:12:54 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-07 18:12:54 | INFO | train | epoch 785 | loss 1.592 | nll_loss 0.23 | ppl 1.17 | wps 24684.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38199 | lr 0.000161798 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99432
2022-03-07 18:12:54 | INFO | fairseq.trainer | begin training epoch 786
2022-03-07 18:12:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:12:56 | INFO | train_inner | epoch 786:      1 / 49 loss=1.592, nll_loss=0.23, ppl=1.17, wps=24303.5, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=38200, lr=0.000161796, gnorm=0.336, loss_scale=32, train_wall=221, gb_free=8.8, wall=99434
2022-03-07 18:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:14:58 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 13.426 | nll_loss 12.97 | ppl 8022.92 | wps 44742.5 | wpb 510.9 | bsz 1 | num_updates 38248 | best_loss 8.725
2022-03-07 18:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38248 updates
2022-03-07 18:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 786 @ 38248 updates, score 13.426) (writing took 1.9469315083697438 seconds)
2022-03-07 18:15:00 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-07 18:15:00 | INFO | train | epoch 786 | loss 1.591 | nll_loss 0.23 | ppl 1.17 | wps 25137.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38248 | lr 0.000161695 | gnorm 0.338 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99558
2022-03-07 18:15:00 | INFO | fairseq.trainer | begin training epoch 787
2022-03-07 18:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:16:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:17:04 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 13.469 | nll_loss 13.015 | ppl 8280.13 | wps 44838.2 | wpb 510.9 | bsz 1 | num_updates 38296 | best_loss 8.725
2022-03-07 18:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38296 updates
2022-03-07 18:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 787 @ 38296 updates, score 13.469) (writing took 1.9322495609521866 seconds)
2022-03-07 18:17:06 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-07 18:17:06 | INFO | train | epoch 787 | loss 1.592 | nll_loss 0.23 | ppl 1.17 | wps 24678.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38296 | lr 0.000161593 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99684
2022-03-07 18:17:06 | INFO | fairseq.trainer | begin training epoch 788
2022-03-07 18:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:17:16 | INFO | train_inner | epoch 788:      4 / 49 loss=1.592, nll_loss=0.23, ppl=1.17, wps=24968.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.337, loss_scale=32, train_wall=223, gb_free=8.8, wall=99694
2022-03-07 18:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:19:10 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 13.52 | nll_loss 13.069 | ppl 8590.91 | wps 44948.5 | wpb 510.9 | bsz 1 | num_updates 38345 | best_loss 8.725
2022-03-07 18:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38345 updates
2022-03-07 18:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:19:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 788 @ 38345 updates, score 13.52) (writing took 2.004996344447136 seconds)
2022-03-07 18:19:12 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-07 18:19:12 | INFO | train | epoch 788 | loss 1.591 | nll_loss 0.23 | ppl 1.17 | wps 25189 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38345 | lr 0.00016149 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99811
2022-03-07 18:19:12 | INFO | fairseq.trainer | begin training epoch 789
2022-03-07 18:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:17 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 13.511 | nll_loss 13.059 | ppl 8533.42 | wps 44912 | wpb 510.9 | bsz 1 | num_updates 38394 | best_loss 8.725
2022-03-07 18:21:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38394 updates
2022-03-07 18:21:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:21:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 789 @ 38394 updates, score 13.511) (writing took 1.953025445342064 seconds)
2022-03-07 18:21:18 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-07 18:21:18 | INFO | train | epoch 789 | loss 1.592 | nll_loss 0.23 | ppl 1.17 | wps 25201.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38394 | lr 0.000161387 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 99937
2022-03-07 18:21:18 | INFO | fairseq.trainer | begin training epoch 790
2022-03-07 18:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:21:33 | INFO | train_inner | epoch 790:      6 / 49 loss=1.591, nll_loss=0.23, ppl=1.17, wps=25223, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.333, loss_scale=32, train_wall=220, gb_free=8.8, wall=99952
2022-03-07 18:22:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:23:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:23 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 13.554 | nll_loss 13.106 | ppl 8815.62 | wps 45008.7 | wpb 510.9 | bsz 1 | num_updates 38442 | best_loss 8.725
2022-03-07 18:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38442 updates
2022-03-07 18:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:23:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 790 @ 38442 updates, score 13.554) (writing took 2.0376933785155416 seconds)
2022-03-07 18:23:25 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-07 18:23:25 | INFO | train | epoch 790 | loss 1.592 | nll_loss 0.23 | ppl 1.17 | wps 24651.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38442 | lr 0.000161286 | gnorm 0.338 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100063
2022-03-07 18:23:25 | INFO | fairseq.trainer | begin training epoch 791
2022-03-07 18:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:25:29 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 13.407 | nll_loss 12.954 | ppl 7933.1 | wps 44740.5 | wpb 510.9 | bsz 1 | num_updates 38491 | best_loss 8.725
2022-03-07 18:25:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38491 updates
2022-03-07 18:25:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:25:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:25:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 791 @ 38491 updates, score 13.407) (writing took 1.9639529408887029 seconds)
2022-03-07 18:25:31 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-07 18:25:31 | INFO | train | epoch 791 | loss 1.591 | nll_loss 0.23 | ppl 1.17 | wps 25195.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38491 | lr 0.000161183 | gnorm 0.34 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100189
2022-03-07 18:25:31 | INFO | fairseq.trainer | begin training epoch 792
2022-03-07 18:25:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:53 | INFO | train_inner | epoch 792:      9 / 49 loss=1.591, nll_loss=0.23, ppl=1.17, wps=24972.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.338, loss_scale=32, train_wall=222, gb_free=8.8, wall=100211
2022-03-07 18:27:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:27:35 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 13.534 | nll_loss 13.085 | ppl 8690.37 | wps 45001.7 | wpb 510.9 | bsz 1 | num_updates 38540 | best_loss 8.725
2022-03-07 18:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38540 updates
2022-03-07 18:27:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:27:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:27:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 792 @ 38540 updates, score 13.534) (writing took 1.9693946987390518 seconds)
2022-03-07 18:27:37 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-07 18:27:37 | INFO | train | epoch 792 | loss 1.59 | nll_loss 0.229 | ppl 1.17 | wps 25223.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38540 | lr 0.000161081 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 100315
2022-03-07 18:27:37 | INFO | fairseq.trainer | begin training epoch 793
2022-03-07 18:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:28:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:29:41 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 13.356 | nll_loss 12.895 | ppl 7615.91 | wps 45098.6 | wpb 510.9 | bsz 1 | num_updates 38588 | best_loss 8.725
2022-03-07 18:29:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38588 updates
2022-03-07 18:29:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:29:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 793 @ 38588 updates, score 13.356) (writing took 1.9332477385178208 seconds)
2022-03-07 18:29:43 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-07 18:29:43 | INFO | train | epoch 793 | loss 1.591 | nll_loss 0.229 | ppl 1.17 | wps 24709.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38588 | lr 0.000160981 | gnorm 0.338 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100441
2022-03-07 18:29:43 | INFO | fairseq.trainer | begin training epoch 794
2022-03-07 18:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:30:13 | INFO | train_inner | epoch 794:     12 / 49 loss=1.59, nll_loss=0.229, ppl=1.17, wps=24988.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.335, loss_scale=32, train_wall=222, gb_free=8.8, wall=100471
2022-03-07 18:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:31:47 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 13.422 | nll_loss 12.967 | ppl 8005.43 | wps 44765.7 | wpb 510.9 | bsz 1 | num_updates 38637 | best_loss 8.725
2022-03-07 18:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38637 updates
2022-03-07 18:31:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:31:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:31:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 794 @ 38637 updates, score 13.422) (writing took 1.9851575968787074 seconds)
2022-03-07 18:31:49 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-07 18:31:49 | INFO | train | epoch 794 | loss 1.59 | nll_loss 0.229 | ppl 1.17 | wps 25150.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38637 | lr 0.000160879 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 100567
2022-03-07 18:31:49 | INFO | fairseq.trainer | begin training epoch 795
2022-03-07 18:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:33:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:33:54 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 13.434 | nll_loss 12.976 | ppl 8056.04 | wps 44846.7 | wpb 510.9 | bsz 1 | num_updates 38686 | best_loss 8.725
2022-03-07 18:33:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38686 updates
2022-03-07 18:33:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 795 @ 38686 updates, score 13.434) (writing took 1.9342380966991186 seconds)
2022-03-07 18:33:56 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-07 18:33:56 | INFO | train | epoch 795 | loss 1.591 | nll_loss 0.23 | ppl 1.17 | wps 25088.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38686 | lr 0.000160777 | gnorm 0.339 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 100694
2022-03-07 18:33:56 | INFO | fairseq.trainer | begin training epoch 796
2022-03-07 18:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:34:30 | INFO | train_inner | epoch 796:     14 / 49 loss=1.591, nll_loss=0.23, ppl=1.17, wps=25173.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.336, loss_scale=64, train_wall=221, gb_free=8.8, wall=100729
2022-03-07 18:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:36:00 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 13.331 | nll_loss 12.871 | ppl 7489.18 | wps 44622 | wpb 510.9 | bsz 1 | num_updates 38735 | best_loss 8.725
2022-03-07 18:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38735 updates
2022-03-07 18:36:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:36:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 796 @ 38735 updates, score 13.331) (writing took 1.8815357303246856 seconds)
2022-03-07 18:36:02 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-07 18:36:02 | INFO | train | epoch 796 | loss 1.591 | nll_loss 0.229 | ppl 1.17 | wps 25181.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38735 | lr 0.000160675 | gnorm 0.335 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 100820
2022-03-07 18:36:02 | INFO | fairseq.trainer | begin training epoch 797
2022-03-07 18:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:38:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:38:06 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 13.462 | nll_loss 13.011 | ppl 8254.58 | wps 44741.2 | wpb 510.9 | bsz 1 | num_updates 38784 | best_loss 8.725
2022-03-07 18:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38784 updates
2022-03-07 18:38:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 797 @ 38784 updates, score 13.462) (writing took 1.795346993021667 seconds)
2022-03-07 18:38:08 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-07 18:38:08 | INFO | train | epoch 797 | loss 1.59 | nll_loss 0.229 | ppl 1.17 | wps 25247.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38784 | lr 0.000160573 | gnorm 0.333 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 100946
2022-03-07 18:38:08 | INFO | fairseq.trainer | begin training epoch 798
2022-03-07 18:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:38:47 | INFO | train_inner | epoch 798:     16 / 49 loss=1.59, nll_loss=0.229, ppl=1.17, wps=25246.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=38800, lr=0.00016054, gnorm=0.334, loss_scale=64, train_wall=220, gb_free=8.8, wall=100986
2022-03-07 18:39:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:39:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:12 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 13.442 | nll_loss 12.986 | ppl 8114.54 | wps 44470.4 | wpb 510.9 | bsz 1 | num_updates 38831 | best_loss 8.725
2022-03-07 18:40:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38831 updates
2022-03-07 18:40:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:40:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 798 @ 38831 updates, score 13.442) (writing took 1.8309983825311065 seconds)
2022-03-07 18:40:14 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-07 18:40:14 | INFO | train | epoch 798 | loss 1.589 | nll_loss 0.228 | ppl 1.17 | wps 24204.3 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 38831 | lr 0.000160476 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101072
2022-03-07 18:40:14 | INFO | fairseq.trainer | begin training epoch 799
2022-03-07 18:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:42:18 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 13.448 | nll_loss 12.993 | ppl 8154.61 | wps 45140.4 | wpb 510.9 | bsz 1 | num_updates 38880 | best_loss 8.725
2022-03-07 18:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38880 updates
2022-03-07 18:42:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:42:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:42:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 799 @ 38880 updates, score 13.448) (writing took 1.9083967003971338 seconds)
2022-03-07 18:42:20 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-07 18:42:20 | INFO | train | epoch 799 | loss 1.59 | nll_loss 0.229 | ppl 1.17 | wps 25238.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38880 | lr 0.000160375 | gnorm 0.336 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101198
2022-03-07 18:42:20 | INFO | fairseq.trainer | begin training epoch 800
2022-03-07 18:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:43:09 | INFO | train_inner | epoch 800:     20 / 49 loss=1.59, nll_loss=0.228, ppl=1.17, wps=24797.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.335, loss_scale=32, train_wall=224, gb_free=8.8, wall=101247
2022-03-07 18:44:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:44:24 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 13.416 | nll_loss 12.959 | ppl 7962.36 | wps 43597.1 | wpb 510.9 | bsz 1 | num_updates 38929 | best_loss 8.725
2022-03-07 18:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38929 updates
2022-03-07 18:44:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:44:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 800 @ 38929 updates, score 13.416) (writing took 1.8608263516798615 seconds)
2022-03-07 18:44:26 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-07 18:44:26 | INFO | train | epoch 800 | loss 1.59 | nll_loss 0.229 | ppl 1.17 | wps 25210 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38929 | lr 0.000160274 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101324
2022-03-07 18:44:26 | INFO | fairseq.trainer | begin training epoch 801
2022-03-07 18:44:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:46:30 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 13.427 | nll_loss 12.971 | ppl 8027.94 | wps 45032.5 | wpb 510.9 | bsz 1 | num_updates 38977 | best_loss 8.725
2022-03-07 18:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38977 updates
2022-03-07 18:46:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 801 @ 38977 updates, score 13.427) (writing took 1.8113342951983213 seconds)
2022-03-07 18:46:32 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-07 18:46:32 | INFO | train | epoch 801 | loss 1.59 | nll_loss 0.229 | ppl 1.17 | wps 24748.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38977 | lr 0.000160175 | gnorm 0.336 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101450
2022-03-07 18:46:32 | INFO | fairseq.trainer | begin training epoch 802
2022-03-07 18:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:47:28 | INFO | train_inner | epoch 802:     23 / 49 loss=1.59, nll_loss=0.229, ppl=1.17, wps=25021.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.338, loss_scale=32, train_wall=222, gb_free=8.8, wall=101506
2022-03-07 18:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:48:36 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 13.398 | nll_loss 12.939 | ppl 7853.43 | wps 44893.8 | wpb 510.9 | bsz 1 | num_updates 39026 | best_loss 8.725
2022-03-07 18:48:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39026 updates
2022-03-07 18:48:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 802 @ 39026 updates, score 13.398) (writing took 1.9196068542078137 seconds)
2022-03-07 18:48:38 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-07 18:48:38 | INFO | train | epoch 802 | loss 1.589 | nll_loss 0.229 | ppl 1.17 | wps 25221.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39026 | lr 0.000160075 | gnorm 0.34 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101576
2022-03-07 18:48:38 | INFO | fairseq.trainer | begin training epoch 803
2022-03-07 18:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:50:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:50:42 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 13.457 | nll_loss 13.004 | ppl 8216.45 | wps 45061.2 | wpb 510.9 | bsz 1 | num_updates 39075 | best_loss 8.725
2022-03-07 18:50:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39075 updates
2022-03-07 18:50:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 803 @ 39075 updates, score 13.457) (writing took 1.899760289117694 seconds)
2022-03-07 18:50:43 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-07 18:50:43 | INFO | train | epoch 803 | loss 1.59 | nll_loss 0.229 | ppl 1.17 | wps 25244.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39075 | lr 0.000159974 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101702
2022-03-07 18:50:44 | INFO | fairseq.trainer | begin training epoch 804
2022-03-07 18:50:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:50:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:51:47 | INFO | train_inner | epoch 804:     26 / 49 loss=1.589, nll_loss=0.228, ppl=1.17, wps=25032.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.336, loss_scale=32, train_wall=222, gb_free=8.8, wall=101766
2022-03-07 18:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:52:47 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 13.46 | nll_loss 13.007 | ppl 8230.12 | wps 44977.5 | wpb 510.9 | bsz 1 | num_updates 39123 | best_loss 8.725
2022-03-07 18:52:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39123 updates
2022-03-07 18:52:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:52:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:52:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 804 @ 39123 updates, score 13.46) (writing took 1.8123064702376723 seconds)
2022-03-07 18:52:49 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-07 18:52:49 | INFO | train | epoch 804 | loss 1.589 | nll_loss 0.228 | ppl 1.17 | wps 24746.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39123 | lr 0.000159876 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101827
2022-03-07 18:52:49 | INFO | fairseq.trainer | begin training epoch 805
2022-03-07 18:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:54:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:54:53 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 13.463 | nll_loss 13.011 | ppl 8252.62 | wps 44990.3 | wpb 510.9 | bsz 1 | num_updates 39172 | best_loss 8.725
2022-03-07 18:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39172 updates
2022-03-07 18:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 805 @ 39172 updates, score 13.463) (writing took 1.9143603164702654 seconds)
2022-03-07 18:54:55 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-07 18:54:55 | INFO | train | epoch 805 | loss 1.589 | nll_loss 0.228 | ppl 1.17 | wps 25217.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39172 | lr 0.000159776 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 101954
2022-03-07 18:54:55 | INFO | fairseq.trainer | begin training epoch 806
2022-03-07 18:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:56:04 | INFO | train_inner | epoch 806:     28 / 49 loss=1.589, nll_loss=0.228, ppl=1.17, wps=25271.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.334, loss_scale=32, train_wall=220, gb_free=8.8, wall=102022
2022-03-07 18:56:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:56:59 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 13.474 | nll_loss 13.02 | ppl 8305.05 | wps 44931.4 | wpb 510.9 | bsz 1 | num_updates 39220 | best_loss 8.725
2022-03-07 18:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39220 updates
2022-03-07 18:56:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:57:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 806 @ 39220 updates, score 13.474) (writing took 1.7686793776229024 seconds)
2022-03-07 18:57:01 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-07 18:57:01 | INFO | train | epoch 806 | loss 1.589 | nll_loss 0.228 | ppl 1.17 | wps 24743.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39220 | lr 0.000159678 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102079
2022-03-07 18:57:01 | INFO | fairseq.trainer | begin training epoch 807
2022-03-07 18:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:05 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 13.394 | nll_loss 12.936 | ppl 7836.14 | wps 45050.8 | wpb 510.9 | bsz 1 | num_updates 39269 | best_loss 8.725
2022-03-07 18:59:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39269 updates
2022-03-07 18:59:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:59:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 807 @ 39269 updates, score 13.394) (writing took 1.9783963477239013 seconds)
2022-03-07 18:59:07 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-07 18:59:07 | INFO | train | epoch 807 | loss 1.588 | nll_loss 0.228 | ppl 1.17 | wps 25216.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39269 | lr 0.000159579 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102205
2022-03-07 18:59:07 | INFO | fairseq.trainer | begin training epoch 808
2022-03-07 18:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:00:23 | INFO | train_inner | epoch 808:     31 / 49 loss=1.589, nll_loss=0.228, ppl=1.17, wps=25022.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.334, loss_scale=32, train_wall=222, gb_free=8.8, wall=102282
2022-03-07 19:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:01:11 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 13.397 | nll_loss 12.941 | ppl 7865.86 | wps 45007.9 | wpb 510.9 | bsz 1 | num_updates 39318 | best_loss 8.725
2022-03-07 19:01:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39318 updates
2022-03-07 19:01:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:01:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:01:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 808 @ 39318 updates, score 13.397) (writing took 1.8617122061550617 seconds)
2022-03-07 19:01:13 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-07 19:01:13 | INFO | train | epoch 808 | loss 1.589 | nll_loss 0.228 | ppl 1.17 | wps 25250.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39318 | lr 0.000159479 | gnorm 0.336 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102331
2022-03-07 19:01:13 | INFO | fairseq.trainer | begin training epoch 809
2022-03-07 19:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:02:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:03:17 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 13.487 | nll_loss 13.037 | ppl 8406.82 | wps 45218.2 | wpb 510.9 | bsz 1 | num_updates 39366 | best_loss 8.725
2022-03-07 19:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39366 updates
2022-03-07 19:03:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:03:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:03:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 809 @ 39366 updates, score 13.487) (writing took 1.8197919055819511 seconds)
2022-03-07 19:03:19 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-07 19:03:19 | INFO | train | epoch 809 | loss 1.588 | nll_loss 0.228 | ppl 1.17 | wps 24731.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39366 | lr 0.000159382 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102457
2022-03-07 19:03:19 | INFO | fairseq.trainer | begin training epoch 810
2022-03-07 19:03:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:04:42 | INFO | train_inner | epoch 810:     34 / 49 loss=1.588, nll_loss=0.228, ppl=1.17, wps=25045.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.334, loss_scale=32, train_wall=222, gb_free=8.8, wall=102541
2022-03-07 19:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:05:23 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 13.419 | nll_loss 12.965 | ppl 7997.08 | wps 44808.4 | wpb 510.9 | bsz 1 | num_updates 39415 | best_loss 8.725
2022-03-07 19:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39415 updates
2022-03-07 19:05:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:05:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:05:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 810 @ 39415 updates, score 13.419) (writing took 1.8305783234536648 seconds)
2022-03-07 19:05:25 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-07 19:05:25 | INFO | train | epoch 810 | loss 1.588 | nll_loss 0.228 | ppl 1.17 | wps 25247.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39415 | lr 0.000159283 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102583
2022-03-07 19:05:25 | INFO | fairseq.trainer | begin training epoch 811
2022-03-07 19:05:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:07:29 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 13.474 | nll_loss 13.02 | ppl 8304.77 | wps 45126.5 | wpb 510.9 | bsz 1 | num_updates 39464 | best_loss 8.725
2022-03-07 19:07:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39464 updates
2022-03-07 19:07:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:07:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:07:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 811 @ 39464 updates, score 13.474) (writing took 1.8290086956694722 seconds)
2022-03-07 19:07:30 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-07 19:07:30 | INFO | train | epoch 811 | loss 1.588 | nll_loss 0.227 | ppl 1.17 | wps 25273.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39464 | lr 0.000159184 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102709
2022-03-07 19:07:30 | INFO | fairseq.trainer | begin training epoch 812
2022-03-07 19:07:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:08:59 | INFO | train_inner | epoch 812:     36 / 49 loss=1.588, nll_loss=0.227, ppl=1.17, wps=25275.8, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.332, loss_scale=64, train_wall=220, gb_free=8.8, wall=102797
2022-03-07 19:09:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:09:34 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 13.443 | nll_loss 12.987 | ppl 8118.08 | wps 44989.6 | wpb 510.9 | bsz 1 | num_updates 39512 | best_loss 8.725
2022-03-07 19:09:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39512 updates
2022-03-07 19:09:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:09:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:09:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 812 @ 39512 updates, score 13.443) (writing took 1.8357650926336646 seconds)
2022-03-07 19:09:36 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-07 19:09:36 | INFO | train | epoch 812 | loss 1.588 | nll_loss 0.227 | ppl 1.17 | wps 24728.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39512 | lr 0.000159087 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102835
2022-03-07 19:09:36 | INFO | fairseq.trainer | begin training epoch 813
2022-03-07 19:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:11:41 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 13.382 | nll_loss 12.922 | ppl 7761.03 | wps 44687.6 | wpb 510.9 | bsz 1 | num_updates 39561 | best_loss 8.725
2022-03-07 19:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39561 updates
2022-03-07 19:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 813 @ 39561 updates, score 13.382) (writing took 1.7959942687302828 seconds)
2022-03-07 19:11:42 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-07 19:11:42 | INFO | train | epoch 813 | loss 1.588 | nll_loss 0.228 | ppl 1.17 | wps 25210.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39561 | lr 0.000158989 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 102961
2022-03-07 19:11:42 | INFO | fairseq.trainer | begin training epoch 814
2022-03-07 19:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:13:18 | INFO | train_inner | epoch 814:     39 / 49 loss=1.588, nll_loss=0.228, ppl=1.17, wps=25031.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39600, lr=0.00015891, gnorm=0.335, loss_scale=32, train_wall=222, gb_free=8.8, wall=103056
2022-03-07 19:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:13:46 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 13.487 | nll_loss 13.034 | ppl 8386.75 | wps 45268.1 | wpb 510.9 | bsz 1 | num_updates 39610 | best_loss 8.725
2022-03-07 19:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39610 updates
2022-03-07 19:13:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:13:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:13:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 814 @ 39610 updates, score 13.487) (writing took 2.005435992963612 seconds)
2022-03-07 19:13:48 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-07 19:13:48 | INFO | train | epoch 814 | loss 1.588 | nll_loss 0.228 | ppl 1.17 | wps 25233.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39610 | lr 0.00015889 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103087
2022-03-07 19:13:48 | INFO | fairseq.trainer | begin training epoch 815
2022-03-07 19:13:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:14:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:15:52 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 13.451 | nll_loss 12.999 | ppl 8185.56 | wps 45214 | wpb 510.9 | bsz 1 | num_updates 39658 | best_loss 8.725
2022-03-07 19:15:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39658 updates
2022-03-07 19:15:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:15:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 815 @ 39658 updates, score 13.451) (writing took 1.8493153527379036 seconds)
2022-03-07 19:15:54 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-07 19:15:54 | INFO | train | epoch 815 | loss 1.587 | nll_loss 0.227 | ppl 1.17 | wps 24753.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39658 | lr 0.000158794 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103212
2022-03-07 19:15:54 | INFO | fairseq.trainer | begin training epoch 816
2022-03-07 19:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:17:37 | INFO | train_inner | epoch 816:     42 / 49 loss=1.588, nll_loss=0.227, ppl=1.17, wps=25043.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.332, loss_scale=32, train_wall=222, gb_free=8.8, wall=103315
2022-03-07 19:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:17:58 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 13.45 | nll_loss 12.997 | ppl 8175.32 | wps 44746.8 | wpb 510.9 | bsz 1 | num_updates 39707 | best_loss 8.725
2022-03-07 19:17:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39707 updates
2022-03-07 19:17:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 816 @ 39707 updates, score 13.45) (writing took 1.9797848174348474 seconds)
2022-03-07 19:18:00 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-07 19:18:00 | INFO | train | epoch 816 | loss 1.588 | nll_loss 0.227 | ppl 1.17 | wps 25232.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39707 | lr 0.000158696 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103338
2022-03-07 19:18:00 | INFO | fairseq.trainer | begin training epoch 817
2022-03-07 19:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:04 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 13.464 | nll_loss 13.014 | ppl 8271.78 | wps 44972 | wpb 510.9 | bsz 1 | num_updates 39756 | best_loss 8.725
2022-03-07 19:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39756 updates
2022-03-07 19:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 817 @ 39756 updates, score 13.464) (writing took 1.9259420484304428 seconds)
2022-03-07 19:20:06 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-07 19:20:06 | INFO | train | epoch 817 | loss 1.588 | nll_loss 0.227 | ppl 1.17 | wps 25255.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39756 | lr 0.000158598 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103464
2022-03-07 19:20:06 | INFO | fairseq.trainer | begin training epoch 818
2022-03-07 19:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:21:54 | INFO | train_inner | epoch 818:     44 / 49 loss=1.588, nll_loss=0.227, ppl=1.17, wps=25281.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.333, loss_scale=64, train_wall=220, gb_free=8.8, wall=103572
2022-03-07 19:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:22:10 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 13.461 | nll_loss 13.009 | ppl 8242.58 | wps 44721.3 | wpb 510.9 | bsz 1 | num_updates 39805 | best_loss 8.725
2022-03-07 19:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39805 updates
2022-03-07 19:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 818 @ 39805 updates, score 13.461) (writing took 2.0242877015843987 seconds)
2022-03-07 19:22:12 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-07 19:22:12 | INFO | train | epoch 818 | loss 1.587 | nll_loss 0.227 | ppl 1.17 | wps 25237.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39805 | lr 0.000158501 | gnorm 0.333 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 103590
2022-03-07 19:22:12 | INFO | fairseq.trainer | begin training epoch 819
2022-03-07 19:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:23:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:24:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:24:16 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 13.368 | nll_loss 12.908 | ppl 7685.65 | wps 45091.4 | wpb 510.9 | bsz 1 | num_updates 39853 | best_loss 8.725
2022-03-07 19:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39853 updates
2022-03-07 19:24:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 819 @ 39853 updates, score 13.368) (writing took 1.8649305095896125 seconds)
2022-03-07 19:24:18 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-07 19:24:18 | INFO | train | epoch 819 | loss 1.587 | nll_loss 0.227 | ppl 1.17 | wps 24739.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39853 | lr 0.000158405 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103716
2022-03-07 19:24:18 | INFO | fairseq.trainer | begin training epoch 820
2022-03-07 19:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:26:13 | INFO | train_inner | epoch 820:     47 / 49 loss=1.587, nll_loss=0.227, ppl=1.17, wps=25011.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.333, loss_scale=32, train_wall=222, gb_free=8.8, wall=103831
2022-03-07 19:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:26:22 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 13.456 | nll_loss 13 | ppl 8193.27 | wps 44510.1 | wpb 510.9 | bsz 1 | num_updates 39902 | best_loss 8.725
2022-03-07 19:26:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39902 updates
2022-03-07 19:26:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:26:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 820 @ 39902 updates, score 13.456) (writing took 1.9104153057560325 seconds)
2022-03-07 19:26:24 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-07 19:26:24 | INFO | train | epoch 820 | loss 1.587 | nll_loss 0.227 | ppl 1.17 | wps 25209.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39902 | lr 0.000158308 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103842
2022-03-07 19:26:24 | INFO | fairseq.trainer | begin training epoch 821
2022-03-07 19:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:28:27 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 13.506 | nll_loss 13.056 | ppl 8515.19 | wps 45155.1 | wpb 510.9 | bsz 1 | num_updates 39951 | best_loss 8.725
2022-03-07 19:28:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39951 updates
2022-03-07 19:28:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:28:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:28:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 821 @ 39951 updates, score 13.506) (writing took 1.928294195793569 seconds)
2022-03-07 19:28:29 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-07 19:28:29 | INFO | train | epoch 821 | loss 1.587 | nll_loss 0.227 | ppl 1.17 | wps 25268 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39951 | lr 0.000158211 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103968
2022-03-07 19:28:29 | INFO | fairseq.trainer | begin training epoch 822
2022-03-07 19:28:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:29:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:30:33 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 13.408 | nll_loss 12.95 | ppl 7914.8 | wps 45125.7 | wpb 510.9 | bsz 1 | num_updates 39999 | best_loss 8.725
2022-03-07 19:30:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 39999 updates
2022-03-07 19:30:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:30:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 822 @ 39999 updates, score 13.408) (writing took 1.9197133462876081 seconds)
2022-03-07 19:30:35 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-07 19:30:35 | INFO | train | epoch 822 | loss 1.586 | nll_loss 0.226 | ppl 1.17 | wps 24743.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39999 | lr 0.000158116 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104093
2022-03-07 19:30:35 | INFO | fairseq.trainer | begin training epoch 823
2022-03-07 19:30:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:30:38 | INFO | train_inner | epoch 823:      1 / 49 loss=1.587, nll_loss=0.227, ppl=1.17, wps=24387.5, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=40000, lr=0.000158114, gnorm=0.334, loss_scale=32, train_wall=221, gb_free=8.8, wall=104096
2022-03-07 19:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:32:39 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 13.385 | nll_loss 12.928 | ppl 7794.2 | wps 45134.6 | wpb 510.9 | bsz 1 | num_updates 40048 | best_loss 8.725
2022-03-07 19:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40048 updates
2022-03-07 19:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 823 @ 40048 updates, score 13.385) (writing took 2.015761627815664 seconds)
2022-03-07 19:32:41 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-07 19:32:41 | INFO | train | epoch 823 | loss 1.586 | nll_loss 0.226 | ppl 1.17 | wps 25246.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40048 | lr 0.000158019 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104219
2022-03-07 19:32:41 | INFO | fairseq.trainer | begin training epoch 824
2022-03-07 19:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:34:45 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 13.386 | nll_loss 12.928 | ppl 7793.15 | wps 45116 | wpb 510.9 | bsz 1 | num_updates 40097 | best_loss 8.725
2022-03-07 19:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40097 updates
2022-03-07 19:34:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:34:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 824 @ 40097 updates, score 13.386) (writing took 1.9484126353636384 seconds)
2022-03-07 19:34:47 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-07 19:34:47 | INFO | train | epoch 824 | loss 1.586 | nll_loss 0.227 | ppl 1.17 | wps 25264.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40097 | lr 0.000157923 | gnorm 0.331 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104345
2022-03-07 19:34:47 | INFO | fairseq.trainer | begin training epoch 825
2022-03-07 19:34:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:34:54 | INFO | train_inner | epoch 825:      3 / 49 loss=1.586, nll_loss=0.226, ppl=1.17, wps=25287, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.329, loss_scale=64, train_wall=220, gb_free=8.8, wall=104353
2022-03-07 19:35:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:36:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:36:51 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 13.466 | nll_loss 13.013 | ppl 8264.62 | wps 45199.1 | wpb 510.9 | bsz 1 | num_updates 40145 | best_loss 8.725
2022-03-07 19:36:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40145 updates
2022-03-07 19:36:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 825 @ 40145 updates, score 13.466) (writing took 2.048548983410001 seconds)
2022-03-07 19:36:53 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-07 19:36:53 | INFO | train | epoch 825 | loss 1.586 | nll_loss 0.226 | ppl 1.17 | wps 24705.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40145 | lr 0.000157828 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104471
2022-03-07 19:36:53 | INFO | fairseq.trainer | begin training epoch 826
2022-03-07 19:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:38:57 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 13.462 | nll_loss 13.011 | ppl 8251.88 | wps 45089.8 | wpb 510.9 | bsz 1 | num_updates 40194 | best_loss 8.725
2022-03-07 19:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40194 updates
2022-03-07 19:38:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:38:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:38:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 826 @ 40194 updates, score 13.462) (writing took 1.9195925816893578 seconds)
2022-03-07 19:38:59 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-07 19:38:59 | INFO | train | epoch 826 | loss 1.586 | nll_loss 0.226 | ppl 1.17 | wps 25231 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40194 | lr 0.000157732 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104597
2022-03-07 19:38:59 | INFO | fairseq.trainer | begin training epoch 827
2022-03-07 19:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:39:14 | INFO | train_inner | epoch 827:      6 / 49 loss=1.586, nll_loss=0.226, ppl=1.17, wps=25009.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.331, loss_scale=32, train_wall=222, gb_free=8.8, wall=104612
2022-03-07 19:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:41:03 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 13.511 | nll_loss 13.058 | ppl 8527.08 | wps 44819.7 | wpb 510.9 | bsz 1 | num_updates 40243 | best_loss 8.725
2022-03-07 19:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40243 updates
2022-03-07 19:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 827 @ 40243 updates, score 13.511) (writing took 1.9724945211783051 seconds)
2022-03-07 19:41:05 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-07 19:41:05 | INFO | train | epoch 827 | loss 1.586 | nll_loss 0.226 | ppl 1.17 | wps 25241.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40243 | lr 0.000157636 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104723
2022-03-07 19:41:05 | INFO | fairseq.trainer | begin training epoch 828
2022-03-07 19:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:43:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:43:09 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 13.539 | nll_loss 13.092 | ppl 8729.04 | wps 45240.6 | wpb 510.9 | bsz 1 | num_updates 40292 | best_loss 8.725
2022-03-07 19:43:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40292 updates
2022-03-07 19:43:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:43:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:43:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 828 @ 40292 updates, score 13.539) (writing took 1.8701908700168133 seconds)
2022-03-07 19:43:11 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-07 19:43:11 | INFO | train | epoch 828 | loss 1.585 | nll_loss 0.226 | ppl 1.17 | wps 25261.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40292 | lr 0.00015754 | gnorm 0.331 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104849
2022-03-07 19:43:11 | INFO | fairseq.trainer | begin training epoch 829
2022-03-07 19:43:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:43:30 | INFO | train_inner | epoch 829:      8 / 49 loss=1.586, nll_loss=0.226, ppl=1.17, wps=25285.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.332, loss_scale=64, train_wall=220, gb_free=8.8, wall=104868
2022-03-07 19:44:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:45:15 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 13.424 | nll_loss 12.969 | ppl 8016.09 | wps 44744.8 | wpb 510.9 | bsz 1 | num_updates 40340 | best_loss 8.725
2022-03-07 19:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40340 updates
2022-03-07 19:45:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:45:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 829 @ 40340 updates, score 13.424) (writing took 1.9917877977713943 seconds)
2022-03-07 19:45:17 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-07 19:45:17 | INFO | train | epoch 829 | loss 1.586 | nll_loss 0.226 | ppl 1.17 | wps 24711.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40340 | lr 0.000157446 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 104975
2022-03-07 19:45:17 | INFO | fairseq.trainer | begin training epoch 830
2022-03-07 19:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:47:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:47:20 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 13.367 | nll_loss 12.907 | ppl 7681.08 | wps 44886.5 | wpb 510.9 | bsz 1 | num_updates 40389 | best_loss 8.725
2022-03-07 19:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40389 updates
2022-03-07 19:47:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 830 @ 40389 updates, score 13.367) (writing took 1.9473973074927926 seconds)
2022-03-07 19:47:22 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-07 19:47:22 | INFO | train | epoch 830 | loss 1.585 | nll_loss 0.226 | ppl 1.17 | wps 25261.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40389 | lr 0.000157351 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105101
2022-03-07 19:47:22 | INFO | fairseq.trainer | begin training epoch 831
2022-03-07 19:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:47:50 | INFO | train_inner | epoch 831:     11 / 49 loss=1.585, nll_loss=0.226, ppl=1.17, wps=25022.3, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.332, loss_scale=32, train_wall=222, gb_free=8.8, wall=105128
2022-03-07 19:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:49:26 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 13.332 | nll_loss 12.874 | ppl 7508.49 | wps 45206.5 | wpb 510.9 | bsz 1 | num_updates 40438 | best_loss 8.725
2022-03-07 19:49:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40438 updates
2022-03-07 19:49:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:49:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 831 @ 40438 updates, score 13.332) (writing took 1.8970561129972339 seconds)
2022-03-07 19:49:28 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-07 19:49:28 | INFO | train | epoch 831 | loss 1.585 | nll_loss 0.226 | ppl 1.17 | wps 25222.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40438 | lr 0.000157255 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105227
2022-03-07 19:49:28 | INFO | fairseq.trainer | begin training epoch 832
2022-03-07 19:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:51:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:51:32 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 13.401 | nll_loss 12.943 | ppl 7877.24 | wps 44759.1 | wpb 510.9 | bsz 1 | num_updates 40486 | best_loss 8.725
2022-03-07 19:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40486 updates
2022-03-07 19:51:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:51:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 832 @ 40486 updates, score 13.401) (writing took 1.9071541735902429 seconds)
2022-03-07 19:51:34 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-07 19:51:34 | INFO | train | epoch 832 | loss 1.585 | nll_loss 0.226 | ppl 1.17 | wps 24715.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40486 | lr 0.000157162 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105352
2022-03-07 19:51:34 | INFO | fairseq.trainer | begin training epoch 833
2022-03-07 19:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:52:09 | INFO | train_inner | epoch 833:     14 / 49 loss=1.585, nll_loss=0.226, ppl=1.17, wps=25038.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.328, loss_scale=32, train_wall=222, gb_free=8.8, wall=105387
2022-03-07 19:53:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:53:38 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 13.408 | nll_loss 12.951 | ppl 7917.63 | wps 45233.6 | wpb 510.9 | bsz 1 | num_updates 40535 | best_loss 8.725
2022-03-07 19:53:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40535 updates
2022-03-07 19:53:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:53:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:53:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 833 @ 40535 updates, score 13.408) (writing took 1.9043577387928963 seconds)
2022-03-07 19:53:40 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-07 19:53:40 | INFO | train | epoch 833 | loss 1.585 | nll_loss 0.225 | ppl 1.17 | wps 25268.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40535 | lr 0.000157067 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105478
2022-03-07 19:53:40 | INFO | fairseq.trainer | begin training epoch 834
2022-03-07 19:53:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:55:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:55:44 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 13.39 | nll_loss 12.934 | ppl 7823.27 | wps 44346.4 | wpb 510.9 | bsz 1 | num_updates 40584 | best_loss 8.725
2022-03-07 19:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40584 updates
2022-03-07 19:55:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:55:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:55:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 834 @ 40584 updates, score 13.39) (writing took 1.9245084170252085 seconds)
2022-03-07 19:55:46 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-07 19:55:46 | INFO | train | epoch 834 | loss 1.585 | nll_loss 0.225 | ppl 1.17 | wps 25228 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40584 | lr 0.000156972 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105604
2022-03-07 19:55:46 | INFO | fairseq.trainer | begin training epoch 835
2022-03-07 19:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:56:25 | INFO | train_inner | epoch 835:     16 / 49 loss=1.585, nll_loss=0.226, ppl=1.17, wps=25279.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.331, loss_scale=32, train_wall=220, gb_free=8.8, wall=105643
2022-03-07 19:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:57:50 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 13.357 | nll_loss 12.899 | ppl 7638.17 | wps 45345.2 | wpb 510.9 | bsz 1 | num_updates 40633 | best_loss 8.725
2022-03-07 19:57:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40633 updates
2022-03-07 19:57:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:57:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:57:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 835 @ 40633 updates, score 13.357) (writing took 1.8695154348388314 seconds)
2022-03-07 19:57:52 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-07 19:57:52 | INFO | train | epoch 835 | loss 1.585 | nll_loss 0.225 | ppl 1.17 | wps 25278 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40633 | lr 0.000156877 | gnorm 0.331 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 105730
2022-03-07 19:57:52 | INFO | fairseq.trainer | begin training epoch 836
2022-03-07 19:57:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:59:56 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 13.413 | nll_loss 12.96 | ppl 7967.97 | wps 45070.4 | wpb 510.9 | bsz 1 | num_updates 40681 | best_loss 8.725
2022-03-07 19:59:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40681 updates
2022-03-07 19:59:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:59:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 836 @ 40681 updates, score 13.413) (writing took 1.9891581954434514 seconds)
2022-03-07 19:59:58 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-07 19:59:58 | INFO | train | epoch 836 | loss 1.584 | nll_loss 0.225 | ppl 1.17 | wps 24724.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40681 | lr 0.000156785 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105856
2022-03-07 19:59:58 | INFO | fairseq.trainer | begin training epoch 837
2022-03-07 19:59:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:00:44 | INFO | train_inner | epoch 837:     19 / 49 loss=1.584, nll_loss=0.225, ppl=1.17, wps=25030.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.331, loss_scale=32, train_wall=222, gb_free=8.8, wall=105903
2022-03-07 20:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:02:02 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 13.34 | nll_loss 12.879 | ppl 7534.69 | wps 45231.2 | wpb 510.9 | bsz 1 | num_updates 40730 | best_loss 8.725
2022-03-07 20:02:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40730 updates
2022-03-07 20:02:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:02:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:02:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 837 @ 40730 updates, score 13.34) (writing took 1.8424033923074603 seconds)
2022-03-07 20:02:04 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-07 20:02:04 | INFO | train | epoch 837 | loss 1.585 | nll_loss 0.226 | ppl 1.17 | wps 25228.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40730 | lr 0.000156691 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105982
2022-03-07 20:02:04 | INFO | fairseq.trainer | begin training epoch 838
2022-03-07 20:02:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:04:08 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 13.535 | nll_loss 13.084 | ppl 8685.61 | wps 44553.2 | wpb 510.9 | bsz 1 | num_updates 40779 | best_loss 8.725
2022-03-07 20:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40779 updates
2022-03-07 20:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:04:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 838 @ 40779 updates, score 13.535) (writing took 1.880918157286942 seconds)
2022-03-07 20:04:09 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-07 20:04:09 | INFO | train | epoch 838 | loss 1.584 | nll_loss 0.225 | ppl 1.17 | wps 25251.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40779 | lr 0.000156596 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106108
2022-03-07 20:04:09 | INFO | fairseq.trainer | begin training epoch 839
2022-03-07 20:04:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:05:01 | INFO | train_inner | epoch 839:     21 / 49 loss=1.584, nll_loss=0.225, ppl=1.17, wps=25280.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.33, loss_scale=32, train_wall=220, gb_free=8.8, wall=106159
2022-03-07 20:05:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:06:13 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 13.378 | nll_loss 12.92 | ppl 7747.75 | wps 44961.3 | wpb 510.9 | bsz 1 | num_updates 40827 | best_loss 8.725
2022-03-07 20:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40827 updates
2022-03-07 20:06:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:06:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:06:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 839 @ 40827 updates, score 13.378) (writing took 1.9701828202232718 seconds)
2022-03-07 20:06:15 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-07 20:06:15 | INFO | train | epoch 839 | loss 1.584 | nll_loss 0.225 | ppl 1.17 | wps 24729.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40827 | lr 0.000156504 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106234
2022-03-07 20:06:15 | INFO | fairseq.trainer | begin training epoch 840
2022-03-07 20:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:08:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:08:21 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 13.469 | nll_loss 13.017 | ppl 8290.22 | wps 41918.9 | wpb 510.9 | bsz 1 | num_updates 40876 | best_loss 8.725
2022-03-07 20:08:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 40876 updates
2022-03-07 20:08:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:08:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 840 @ 40876 updates, score 13.469) (writing took 1.8837804645299911 seconds)
2022-03-07 20:08:23 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2022-03-07 20:08:23 | INFO | train | epoch 840 | loss 1.583 | nll_loss 0.224 | ppl 1.17 | wps 24839.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40876 | lr 0.00015641 | gnorm 0.327 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 106361
2022-03-07 20:08:23 | INFO | fairseq.trainer | begin training epoch 841
2022-03-07 20:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:23 | INFO | train_inner | epoch 841:     24 / 49 loss=1.584, nll_loss=0.225, ppl=1.17, wps=24719.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40900, lr=0.000156365, gnorm=0.329, loss_scale=32, train_wall=225, gb_free=8.8, wall=106422
2022-03-07 20:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:10:28 | INFO | valid | epoch 841 | valid on 'valid' subset | loss 13.465 | nll_loss 13.012 | ppl 8262.6 | wps 44742.1 | wpb 510.9 | bsz 1 | num_updates 40925 | best_loss 8.725
2022-03-07 20:10:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 841 @ 40925 updates
2022-03-07 20:10:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:10:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:10:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 841 @ 40925 updates, score 13.465) (writing took 1.734394745901227 seconds)
2022-03-07 20:10:30 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2022-03-07 20:10:30 | INFO | train | epoch 841 | loss 1.584 | nll_loss 0.225 | ppl 1.17 | wps 25027.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40925 | lr 0.000156317 | gnorm 0.33 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 106488
2022-03-07 20:10:30 | INFO | fairseq.trainer | begin training epoch 842
2022-03-07 20:10:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:11:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:12:34 | INFO | valid | epoch 842 | valid on 'valid' subset | loss 13.521 | nll_loss 13.074 | ppl 8624.33 | wps 44810.3 | wpb 510.9 | bsz 1 | num_updates 40973 | best_loss 8.725
2022-03-07 20:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 842 @ 40973 updates
2022-03-07 20:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 842 @ 40973 updates, score 13.521) (writing took 1.7604931220412254 seconds)
2022-03-07 20:12:36 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2022-03-07 20:12:36 | INFO | train | epoch 842 | loss 1.584 | nll_loss 0.225 | ppl 1.17 | wps 24737.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40973 | lr 0.000156225 | gnorm 0.327 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106614
2022-03-07 20:12:36 | INFO | fairseq.trainer | begin training epoch 843
2022-03-07 20:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:13:42 | INFO | train_inner | epoch 843:     27 / 49 loss=1.584, nll_loss=0.225, ppl=1.17, wps=25059.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=41000, lr=0.000156174, gnorm=0.328, loss_scale=32, train_wall=222, gb_free=8.8, wall=106681
2022-03-07 20:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:14:40 | INFO | valid | epoch 843 | valid on 'valid' subset | loss 13.426 | nll_loss 12.971 | ppl 8027.35 | wps 45176.3 | wpb 510.9 | bsz 1 | num_updates 41022 | best_loss 8.725
2022-03-07 20:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 843 @ 41022 updates
2022-03-07 20:14:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:14:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 843 @ 41022 updates, score 13.426) (writing took 1.91487786360085 seconds)
2022-03-07 20:14:42 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2022-03-07 20:14:42 | INFO | train | epoch 843 | loss 1.583 | nll_loss 0.225 | ppl 1.17 | wps 25257.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41022 | lr 0.000156132 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106740
2022-03-07 20:14:42 | INFO | fairseq.trainer | begin training epoch 844
2022-03-07 20:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:16:46 | INFO | valid | epoch 844 | valid on 'valid' subset | loss 13.489 | nll_loss 13.037 | ppl 8404.16 | wps 44865 | wpb 510.9 | bsz 1 | num_updates 41071 | best_loss 8.725
2022-03-07 20:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 844 @ 41071 updates
2022-03-07 20:16:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:16:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:16:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 844 @ 41071 updates, score 13.489) (writing took 1.8423930443823338 seconds)
2022-03-07 20:16:48 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)
2022-03-07 20:16:48 | INFO | train | epoch 844 | loss 1.584 | nll_loss 0.225 | ppl 1.17 | wps 25169.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41071 | lr 0.000156039 | gnorm 0.334 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106866
2022-03-07 20:16:48 | INFO | fairseq.trainer | begin training epoch 845
2022-03-07 20:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:17:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:18:02 | INFO | train_inner | epoch 845:     30 / 49 loss=1.584, nll_loss=0.225, ppl=1.17, wps=25006.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=41100, lr=0.000155984, gnorm=0.331, loss_scale=32, train_wall=223, gb_free=8.8, wall=106940
2022-03-07 20:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:18:52 | INFO | valid | epoch 845 | valid on 'valid' subset | loss 13.429 | nll_loss 12.977 | ppl 8060.07 | wps 45285.6 | wpb 510.9 | bsz 1 | num_updates 41119 | best_loss 8.725
2022-03-07 20:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 845 @ 41119 updates
2022-03-07 20:18:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:18:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:18:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 845 @ 41119 updates, score 13.429) (writing took 1.7322711190208793 seconds)
2022-03-07 20:18:54 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)
2022-03-07 20:18:54 | INFO | train | epoch 845 | loss 1.584 | nll_loss 0.225 | ppl 1.17 | wps 24774 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41119 | lr 0.000155948 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 106992
2022-03-07 20:18:54 | INFO | fairseq.trainer | begin training epoch 846
2022-03-07 20:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:20:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:20:58 | INFO | valid | epoch 846 | valid on 'valid' subset | loss 13.438 | nll_loss 12.983 | ppl 8096.33 | wps 45079.7 | wpb 510.9 | bsz 1 | num_updates 41168 | best_loss 8.725
2022-03-07 20:20:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 846 @ 41168 updates
2022-03-07 20:20:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 846 @ 41168 updates, score 13.438) (writing took 1.7771559413522482 seconds)
2022-03-07 20:21:00 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)
2022-03-07 20:21:00 | INFO | train | epoch 846 | loss 1.583 | nll_loss 0.224 | ppl 1.17 | wps 25256.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41168 | lr 0.000155855 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107118
2022-03-07 20:21:00 | INFO | fairseq.trainer | begin training epoch 847
2022-03-07 20:21:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:22:18 | INFO | train_inner | epoch 847:     32 / 49 loss=1.583, nll_loss=0.224, ppl=1.17, wps=25295.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41200, lr=0.000155794, gnorm=0.331, loss_scale=32, train_wall=220, gb_free=8.8, wall=107196
2022-03-07 20:22:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:23:04 | INFO | valid | epoch 847 | valid on 'valid' subset | loss 13.398 | nll_loss 12.939 | ppl 7851.14 | wps 44887.2 | wpb 510.9 | bsz 1 | num_updates 41217 | best_loss 8.725
2022-03-07 20:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 847 @ 41217 updates
2022-03-07 20:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:23:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 847 @ 41217 updates, score 13.398) (writing took 1.7878826623782516 seconds)
2022-03-07 20:23:05 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)
2022-03-07 20:23:05 | INFO | train | epoch 847 | loss 1.583 | nll_loss 0.224 | ppl 1.17 | wps 25257.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41217 | lr 0.000155762 | gnorm 0.329 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107244
2022-03-07 20:23:05 | INFO | fairseq.trainer | begin training epoch 848
2022-03-07 20:23:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:25:09 | INFO | valid | epoch 848 | valid on 'valid' subset | loss 13.512 | nll_loss 13.063 | ppl 8556.63 | wps 44904.9 | wpb 510.9 | bsz 1 | num_updates 41266 | best_loss 8.725
2022-03-07 20:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 848 @ 41266 updates
2022-03-07 20:25:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 848 @ 41266 updates, score 13.512) (writing took 1.8826491879299283 seconds)
2022-03-07 20:25:11 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)
2022-03-07 20:25:11 | INFO | train | epoch 848 | loss 1.583 | nll_loss 0.224 | ppl 1.17 | wps 25243.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41266 | lr 0.00015567 | gnorm 0.331 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107370
2022-03-07 20:25:11 | INFO | fairseq.trainer | begin training epoch 849
2022-03-07 20:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:26:35 | INFO | train_inner | epoch 849:     34 / 49 loss=1.583, nll_loss=0.224, ppl=1.17, wps=25282.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41300, lr=0.000155606, gnorm=0.329, loss_scale=64, train_wall=220, gb_free=8.8, wall=107453
2022-03-07 20:26:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:27:15 | INFO | valid | epoch 849 | valid on 'valid' subset | loss 13.481 | nll_loss 13.029 | ppl 8356.79 | wps 45226.4 | wpb 510.9 | bsz 1 | num_updates 41314 | best_loss 8.725
2022-03-07 20:27:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 849 @ 41314 updates
2022-03-07 20:27:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:27:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:27:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 849 @ 41314 updates, score 13.481) (writing took 1.8398329447954893 seconds)
2022-03-07 20:27:17 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)
2022-03-07 20:27:17 | INFO | train | epoch 849 | loss 1.583 | nll_loss 0.224 | ppl 1.17 | wps 24757.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41314 | lr 0.000155579 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107495
2022-03-07 20:27:17 | INFO | fairseq.trainer | begin training epoch 850
2022-03-07 20:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:21 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 13.464 | nll_loss 13.011 | ppl 8253.83 | wps 44971.1 | wpb 510.9 | bsz 1 | num_updates 41363 | best_loss 8.725
2022-03-07 20:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 41363 updates
2022-03-07 20:29:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:29:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:29:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 850 @ 41363 updates, score 13.464) (writing took 1.8614967968314886 seconds)
2022-03-07 20:29:23 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)
2022-03-07 20:29:23 | INFO | train | epoch 850 | loss 1.583 | nll_loss 0.224 | ppl 1.17 | wps 25212 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41363 | lr 0.000155487 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107621
2022-03-07 20:29:23 | INFO | fairseq.trainer | begin training epoch 851
2022-03-07 20:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:30:54 | INFO | train_inner | epoch 851:     37 / 49 loss=1.583, nll_loss=0.224, ppl=1.17, wps=25016.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41400, lr=0.000155417, gnorm=0.331, loss_scale=32, train_wall=222, gb_free=8.8, wall=107712
2022-03-07 20:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:31:28 | INFO | valid | epoch 851 | valid on 'valid' subset | loss 13.388 | nll_loss 12.931 | ppl 7810.75 | wps 45091.7 | wpb 510.9 | bsz 1 | num_updates 41412 | best_loss 8.725
2022-03-07 20:31:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 851 @ 41412 updates
2022-03-07 20:31:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 851 @ 41412 updates, score 13.388) (writing took 1.7600345071405172 seconds)
2022-03-07 20:31:29 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)
2022-03-07 20:31:29 | INFO | train | epoch 851 | loss 1.583 | nll_loss 0.224 | ppl 1.17 | wps 25178.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41412 | lr 0.000155395 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107748
2022-03-07 20:31:29 | INFO | fairseq.trainer | begin training epoch 852
2022-03-07 20:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:32:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:33:33 | INFO | valid | epoch 852 | valid on 'valid' subset | loss 13.432 | nll_loss 12.979 | ppl 8073.04 | wps 44710.3 | wpb 510.9 | bsz 1 | num_updates 41460 | best_loss 8.725
2022-03-07 20:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 852 @ 41460 updates
2022-03-07 20:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 852 @ 41460 updates, score 13.432) (writing took 1.7736945105716586 seconds)
2022-03-07 20:33:35 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)
2022-03-07 20:33:35 | INFO | train | epoch 852 | loss 1.582 | nll_loss 0.224 | ppl 1.17 | wps 24724.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41460 | lr 0.000155305 | gnorm 0.327 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107873
2022-03-07 20:33:35 | INFO | fairseq.trainer | begin training epoch 853
2022-03-07 20:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:35:14 | INFO | train_inner | epoch 853:     40 / 49 loss=1.582, nll_loss=0.224, ppl=1.17, wps=25006.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41500, lr=0.00015523, gnorm=0.328, loss_scale=32, train_wall=223, gb_free=8.8, wall=107972
2022-03-07 20:35:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:35:39 | INFO | valid | epoch 853 | valid on 'valid' subset | loss 13.45 | nll_loss 12.996 | ppl 8171.74 | wps 44677.9 | wpb 510.9 | bsz 1 | num_updates 41509 | best_loss 8.725
2022-03-07 20:35:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 853 @ 41509 updates
2022-03-07 20:35:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:35:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:35:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 853 @ 41509 updates, score 13.45) (writing took 1.8835082091391087 seconds)
2022-03-07 20:35:41 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)
2022-03-07 20:35:41 | INFO | train | epoch 853 | loss 1.582 | nll_loss 0.224 | ppl 1.17 | wps 25221.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41509 | lr 0.000155213 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 107999
2022-03-07 20:35:41 | INFO | fairseq.trainer | begin training epoch 854
2022-03-07 20:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:37:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:37:46 | INFO | valid | epoch 854 | valid on 'valid' subset | loss 13.467 | nll_loss 13.015 | ppl 8278.04 | wps 44588.4 | wpb 510.9 | bsz 1 | num_updates 41558 | best_loss 8.725
2022-03-07 20:37:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 854 @ 41558 updates
2022-03-07 20:37:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:37:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:37:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 854 @ 41558 updates, score 13.467) (writing took 1.7053091209381819 seconds)
2022-03-07 20:37:47 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)
2022-03-07 20:37:47 | INFO | train | epoch 854 | loss 1.582 | nll_loss 0.224 | ppl 1.17 | wps 25180.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41558 | lr 0.000155122 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108126
2022-03-07 20:37:47 | INFO | fairseq.trainer | begin training epoch 855
2022-03-07 20:37:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:39:33 | INFO | train_inner | epoch 855:     43 / 49 loss=1.582, nll_loss=0.224, ppl=1.17, wps=24984.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41600, lr=0.000155043, gnorm=0.33, loss_scale=32, train_wall=223, gb_free=8.8, wall=108231
2022-03-07 20:39:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:39:52 | INFO | valid | epoch 855 | valid on 'valid' subset | loss 13.406 | nll_loss 12.95 | ppl 7912.98 | wps 44578.8 | wpb 510.9 | bsz 1 | num_updates 41606 | best_loss 8.725
2022-03-07 20:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 855 @ 41606 updates
2022-03-07 20:39:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:39:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 855 @ 41606 updates, score 13.406) (writing took 1.8965472225099802 seconds)
2022-03-07 20:39:54 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)
2022-03-07 20:39:54 | INFO | train | epoch 855 | loss 1.582 | nll_loss 0.224 | ppl 1.17 | wps 24678 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41606 | lr 0.000155032 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108252
2022-03-07 20:39:54 | INFO | fairseq.trainer | begin training epoch 856
2022-03-07 20:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:41:58 | INFO | valid | epoch 856 | valid on 'valid' subset | loss 13.506 | nll_loss 13.057 | ppl 8519.67 | wps 41959.5 | wpb 510.9 | bsz 1 | num_updates 41655 | best_loss 8.725
2022-03-07 20:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 856 @ 41655 updates
2022-03-07 20:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:42:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 856 @ 41655 updates, score 13.506) (writing took 1.8414160488173366 seconds)
2022-03-07 20:42:00 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)
2022-03-07 20:42:00 | INFO | train | epoch 856 | loss 1.582 | nll_loss 0.224 | ppl 1.17 | wps 25125.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41655 | lr 0.000154941 | gnorm 0.327 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108378
2022-03-07 20:42:00 | INFO | fairseq.trainer | begin training epoch 857
2022-03-07 20:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:43:51 | INFO | train_inner | epoch 857:     45 / 49 loss=1.582, nll_loss=0.224, ppl=1.17, wps=25151.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41700, lr=0.000154857, gnorm=0.327, loss_scale=32, train_wall=221, gb_free=8.8, wall=108489
2022-03-07 20:44:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:44:05 | INFO | valid | epoch 857 | valid on 'valid' subset | loss 13.478 | nll_loss 13.026 | ppl 8342.59 | wps 43987.2 | wpb 510.9 | bsz 1 | num_updates 41704 | best_loss 8.725
2022-03-07 20:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 857 @ 41704 updates
2022-03-07 20:44:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 857 @ 41704 updates, score 13.478) (writing took 1.8266955893486738 seconds)
2022-03-07 20:44:07 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)
2022-03-07 20:44:07 | INFO | train | epoch 857 | loss 1.582 | nll_loss 0.224 | ppl 1.17 | wps 25126.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41704 | lr 0.00015485 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108505
2022-03-07 20:44:07 | INFO | fairseq.trainer | begin training epoch 858
2022-03-07 20:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:46:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:46:11 | INFO | valid | epoch 858 | valid on 'valid' subset | loss 13.486 | nll_loss 13.034 | ppl 8385.27 | wps 45149.8 | wpb 510.9 | bsz 1 | num_updates 41752 | best_loss 8.725
2022-03-07 20:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 858 @ 41752 updates
2022-03-07 20:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 858 @ 41752 updates, score 13.486) (writing took 1.8791130604222417 seconds)
2022-03-07 20:46:13 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)
2022-03-07 20:46:13 | INFO | train | epoch 858 | loss 1.582 | nll_loss 0.223 | ppl 1.17 | wps 24703.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41752 | lr 0.000154761 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108631
2022-03-07 20:46:13 | INFO | fairseq.trainer | begin training epoch 859
2022-03-07 20:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:48:11 | INFO | train_inner | epoch 859:     48 / 49 loss=1.582, nll_loss=0.223, ppl=1.17, wps=25005.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41800, lr=0.000154672, gnorm=0.33, loss_scale=32, train_wall=222, gb_free=8.8, wall=108749
2022-03-07 20:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:17 | INFO | valid | epoch 859 | valid on 'valid' subset | loss 13.495 | nll_loss 13.048 | ppl 8470.72 | wps 44940.2 | wpb 510.9 | bsz 1 | num_updates 41801 | best_loss 8.725
2022-03-07 20:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 859 @ 41801 updates
2022-03-07 20:48:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 859 @ 41801 updates, score 13.495) (writing took 1.8382376320660114 seconds)
2022-03-07 20:48:18 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)
2022-03-07 20:48:18 | INFO | train | epoch 859 | loss 1.582 | nll_loss 0.223 | ppl 1.17 | wps 25226.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41801 | lr 0.00015467 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108757
2022-03-07 20:48:18 | INFO | fairseq.trainer | begin training epoch 860
2022-03-07 20:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:50:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:50:23 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 13.398 | nll_loss 12.943 | ppl 7875.73 | wps 44876.6 | wpb 510.9 | bsz 1 | num_updates 41850 | best_loss 8.725
2022-03-07 20:50:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 41850 updates
2022-03-07 20:50:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 860 @ 41850 updates, score 13.398) (writing took 1.8299735356122255 seconds)
2022-03-07 20:50:24 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)
2022-03-07 20:50:24 | INFO | train | epoch 860 | loss 1.581 | nll_loss 0.223 | ppl 1.17 | wps 25224.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41850 | lr 0.00015458 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108883
2022-03-07 20:50:24 | INFO | fairseq.trainer | begin training epoch 861
2022-03-07 20:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:52:29 | INFO | valid | epoch 861 | valid on 'valid' subset | loss 13.393 | nll_loss 12.935 | ppl 7832.9 | wps 44925.6 | wpb 510.9 | bsz 1 | num_updates 41899 | best_loss 8.725
2022-03-07 20:52:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 861 @ 41899 updates
2022-03-07 20:52:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 861 @ 41899 updates, score 13.393) (writing took 1.891093066893518 seconds)
2022-03-07 20:52:30 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)
2022-03-07 20:52:30 | INFO | train | epoch 861 | loss 1.581 | nll_loss 0.223 | ppl 1.17 | wps 25233.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41899 | lr 0.000154489 | gnorm 0.327 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 109009
2022-03-07 20:52:30 | INFO | fairseq.trainer | begin training epoch 862
2022-03-07 20:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:52:33 | INFO | train_inner | epoch 862:      1 / 49 loss=1.581, nll_loss=0.223, ppl=1.17, wps=24593.6, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=41900, lr=0.000154487, gnorm=0.33, loss_scale=64, train_wall=219, gb_free=8.8, wall=109011
2022-03-07 20:53:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:54:34 | INFO | valid | epoch 862 | valid on 'valid' subset | loss 13.345 | nll_loss 12.888 | ppl 7578.19 | wps 44954.5 | wpb 510.9 | bsz 1 | num_updates 41947 | best_loss 8.725
2022-03-07 20:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 862 @ 41947 updates
2022-03-07 20:54:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 862 @ 41947 updates, score 13.345) (writing took 1.8866223273798823 seconds)
2022-03-07 20:54:36 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)
2022-03-07 20:54:36 | INFO | train | epoch 862 | loss 1.581 | nll_loss 0.223 | ppl 1.17 | wps 24723.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41947 | lr 0.000154401 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109135
2022-03-07 20:54:36 | INFO | fairseq.trainer | begin training epoch 863
2022-03-07 20:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:56:41 | INFO | valid | epoch 863 | valid on 'valid' subset | loss 13.486 | nll_loss 13.039 | ppl 8413.87 | wps 44895.5 | wpb 510.9 | bsz 1 | num_updates 41996 | best_loss 8.725
2022-03-07 20:56:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 863 @ 41996 updates
2022-03-07 20:56:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:56:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 863 @ 41996 updates, score 13.486) (writing took 1.9337862189859152 seconds)
2022-03-07 20:56:43 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)
2022-03-07 20:56:43 | INFO | train | epoch 863 | loss 1.581 | nll_loss 0.223 | ppl 1.17 | wps 25178.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41996 | lr 0.000154311 | gnorm 0.327 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109261
2022-03-07 20:56:43 | INFO | fairseq.trainer | begin training epoch 864
2022-03-07 20:56:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:56:52 | INFO | train_inner | epoch 864:      4 / 49 loss=1.581, nll_loss=0.223, ppl=1.17, wps=24995.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42000, lr=0.000154303, gnorm=0.329, loss_scale=32, train_wall=223, gb_free=8.8, wall=109271
2022-03-07 20:58:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:58:47 | INFO | valid | epoch 864 | valid on 'valid' subset | loss 13.499 | nll_loss 13.049 | ppl 8475.78 | wps 45041.5 | wpb 510.9 | bsz 1 | num_updates 42045 | best_loss 8.725
2022-03-07 20:58:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 864 @ 42045 updates
2022-03-07 20:58:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 864 @ 42045 updates, score 13.499) (writing took 1.7870836295187473 seconds)
2022-03-07 20:58:48 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)
2022-03-07 20:58:48 | INFO | train | epoch 864 | loss 1.581 | nll_loss 0.223 | ppl 1.17 | wps 25247.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42045 | lr 0.000154221 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109387
2022-03-07 20:58:48 | INFO | fairseq.trainer | begin training epoch 865
2022-03-07 20:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:00:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:00:53 | INFO | valid | epoch 865 | valid on 'valid' subset | loss 13.348 | nll_loss 12.894 | ppl 7612.24 | wps 44799 | wpb 510.9 | bsz 1 | num_updates 42093 | best_loss 8.725
2022-03-07 21:00:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 865 @ 42093 updates
2022-03-07 21:00:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:00:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:00:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 865 @ 42093 updates, score 13.348) (writing took 1.8337031127884984 seconds)
2022-03-07 21:00:54 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)
2022-03-07 21:00:54 | INFO | train | epoch 865 | loss 1.58 | nll_loss 0.222 | ppl 1.17 | wps 24709.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42093 | lr 0.000154133 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109513
2022-03-07 21:00:54 | INFO | fairseq.trainer | begin training epoch 866
2022-03-07 21:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:01:12 | INFO | train_inner | epoch 866:      7 / 49 loss=1.58, nll_loss=0.222, ppl=1.17, wps=25026.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42100, lr=0.00015412, gnorm=0.327, loss_scale=32, train_wall=222, gb_free=8.8, wall=109530
2022-03-07 21:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:02:58 | INFO | valid | epoch 866 | valid on 'valid' subset | loss 13.401 | nll_loss 12.948 | ppl 7903.22 | wps 44841.9 | wpb 510.9 | bsz 1 | num_updates 42142 | best_loss 8.725
2022-03-07 21:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 866 @ 42142 updates
2022-03-07 21:02:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:03:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 866 @ 42142 updates, score 13.401) (writing took 1.8979912791401148 seconds)
2022-03-07 21:03:00 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)
2022-03-07 21:03:00 | INFO | train | epoch 866 | loss 1.58 | nll_loss 0.222 | ppl 1.17 | wps 25226 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42142 | lr 0.000154043 | gnorm 0.323 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109639
2022-03-07 21:03:00 | INFO | fairseq.trainer | begin training epoch 867
2022-03-07 21:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:05:04 | INFO | valid | epoch 867 | valid on 'valid' subset | loss 13.456 | nll_loss 13.001 | ppl 8198.21 | wps 45113.3 | wpb 510.9 | bsz 1 | num_updates 42191 | best_loss 8.725
2022-03-07 21:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 867 @ 42191 updates
2022-03-07 21:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 867 @ 42191 updates, score 13.456) (writing took 1.8152023199945688 seconds)
2022-03-07 21:05:06 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)
2022-03-07 21:05:06 | INFO | train | epoch 867 | loss 1.581 | nll_loss 0.223 | ppl 1.17 | wps 25240 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42191 | lr 0.000153954 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109764
2022-03-07 21:05:06 | INFO | fairseq.trainer | begin training epoch 868
2022-03-07 21:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:28 | INFO | train_inner | epoch 868:      9 / 49 loss=1.581, nll_loss=0.223, ppl=1.17, wps=25260.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=42200, lr=0.000153937, gnorm=0.327, loss_scale=32, train_wall=220, gb_free=8.8, wall=109787
2022-03-07 21:06:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:07:10 | INFO | valid | epoch 868 | valid on 'valid' subset | loss 13.513 | nll_loss 13.064 | ppl 8562.23 | wps 45155.3 | wpb 510.9 | bsz 1 | num_updates 42239 | best_loss 8.725
2022-03-07 21:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 868 @ 42239 updates
2022-03-07 21:07:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 868 @ 42239 updates, score 13.513) (writing took 1.9285818105563521 seconds)
2022-03-07 21:07:12 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)
2022-03-07 21:07:12 | INFO | train | epoch 868 | loss 1.58 | nll_loss 0.222 | ppl 1.17 | wps 24696.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42239 | lr 0.000153866 | gnorm 0.328 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109891
2022-03-07 21:07:12 | INFO | fairseq.trainer | begin training epoch 869
2022-03-07 21:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:09:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:09:16 | INFO | valid | epoch 869 | valid on 'valid' subset | loss 13.547 | nll_loss 13.099 | ppl 8776.12 | wps 46532.9 | wpb 510.9 | bsz 1 | num_updates 42288 | best_loss 8.725
2022-03-07 21:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 869 @ 42288 updates
2022-03-07 21:09:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:09:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:09:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 869 @ 42288 updates, score 13.547) (writing took 1.7915250128135085 seconds)
2022-03-07 21:09:18 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)
2022-03-07 21:09:18 | INFO | train | epoch 869 | loss 1.58 | nll_loss 0.222 | ppl 1.17 | wps 25344.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42288 | lr 0.000153777 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110016
2022-03-07 21:09:18 | INFO | fairseq.trainer | begin training epoch 870
2022-03-07 21:09:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:09:47 | INFO | train_inner | epoch 870:     12 / 49 loss=1.58, nll_loss=0.222, ppl=1.17, wps=25124.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=42300, lr=0.000153755, gnorm=0.33, loss_scale=32, train_wall=222, gb_free=8.8, wall=110045
2022-03-07 21:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:11:19 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 13.419 | nll_loss 12.964 | ppl 7988.88 | wps 47349.8 | wpb 510.9 | bsz 1 | num_updates 42337 | best_loss 8.725
2022-03-07 21:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 42337 updates
2022-03-07 21:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:11:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 870 @ 42337 updates, score 13.419) (writing took 1.7731292638927698 seconds)
2022-03-07 21:11:21 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)
2022-03-07 21:11:21 | INFO | train | epoch 870 | loss 1.58 | nll_loss 0.222 | ppl 1.17 | wps 25756.5 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 42337 | lr 0.000153688 | gnorm 0.331 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 110139
2022-03-07 21:11:21 | INFO | fairseq.trainer | begin training epoch 871
2022-03-07 21:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:11:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:13:23 | INFO | valid | epoch 871 | valid on 'valid' subset | loss 13.538 | nll_loss 13.091 | ppl 8726.22 | wps 47258.7 | wpb 510.9 | bsz 1 | num_updates 42385 | best_loss 8.725
2022-03-07 21:13:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 871 @ 42385 updates
2022-03-07 21:13:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:13:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 871 @ 42385 updates, score 13.538) (writing took 1.7995126154273748 seconds)
2022-03-07 21:13:25 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)
2022-03-07 21:13:25 | INFO | train | epoch 871 | loss 1.58 | nll_loss 0.223 | ppl 1.17 | wps 25214.7 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 42385 | lr 0.000153601 | gnorm 0.332 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 110263
2022-03-07 21:13:25 | INFO | fairseq.trainer | begin training epoch 872
2022-03-07 21:13:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:14:01 | INFO | train_inner | epoch 872:     15 / 49 loss=1.58, nll_loss=0.222, ppl=1.17, wps=25527.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=42400, lr=0.000153574, gnorm=0.329, loss_scale=32, train_wall=219, gb_free=8.8, wall=110299
2022-03-07 21:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:15:26 | INFO | valid | epoch 872 | valid on 'valid' subset | loss 13.485 | nll_loss 13.034 | ppl 8388.68 | wps 47280.4 | wpb 510.9 | bsz 1 | num_updates 42434 | best_loss 8.725
2022-03-07 21:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 872 @ 42434 updates
2022-03-07 21:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 872 @ 42434 updates, score 13.485) (writing took 1.8560774745419621 seconds)
2022-03-07 21:15:28 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)
2022-03-07 21:15:28 | INFO | train | epoch 872 | loss 1.58 | nll_loss 0.222 | ppl 1.17 | wps 25713.6 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 42434 | lr 0.000153512 | gnorm 0.326 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 110386
2022-03-07 21:15:28 | INFO | fairseq.trainer | begin training epoch 873
2022-03-07 21:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:17:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:17:32 | INFO | valid | epoch 873 | valid on 'valid' subset | loss 13.462 | nll_loss 13.008 | ppl 8239.58 | wps 40577.4 | wpb 510.9 | bsz 1 | num_updates 42483 | best_loss 8.725
2022-03-07 21:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 873 @ 42483 updates
2022-03-07 21:17:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:17:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:17:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 873 @ 42483 updates, score 13.462) (writing took 2.0238410839810967 seconds)
2022-03-07 21:17:34 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)
2022-03-07 21:17:34 | INFO | train | epoch 873 | loss 1.579 | nll_loss 0.222 | ppl 1.17 | wps 25166.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42483 | lr 0.000153424 | gnorm 0.327 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 110513
2022-03-07 21:17:34 | INFO | fairseq.trainer | begin training epoch 874
2022-03-07 21:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:17:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:18:18 | INFO | train_inner | epoch 874:     18 / 49 loss=1.58, nll_loss=0.222, ppl=1.17, wps=25217.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42500, lr=0.000153393, gnorm=0.327, loss_scale=32, train_wall=221, gb_free=8.8, wall=110556
2022-03-07 21:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:19:37 | INFO | valid | epoch 874 | valid on 'valid' subset | loss 13.546 | nll_loss 13.101 | ppl 8787.46 | wps 47091.3 | wpb 510.9 | bsz 1 | num_updates 42531 | best_loss 8.725
2022-03-07 21:19:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 874 @ 42531 updates
2022-03-07 21:19:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:19:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 874 @ 42531 updates, score 13.546) (writing took 1.6869722856208682 seconds)
2022-03-07 21:19:39 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)
2022-03-07 21:19:39 | INFO | train | epoch 874 | loss 1.58 | nll_loss 0.222 | ppl 1.17 | wps 25050.7 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 42531 | lr 0.000153337 | gnorm 0.327 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 110637
2022-03-07 21:19:39 | INFO | fairseq.trainer | begin training epoch 875
2022-03-07 21:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:21:40 | INFO | valid | epoch 875 | valid on 'valid' subset | loss 13.402 | nll_loss 12.948 | ppl 7902.94 | wps 47405.6 | wpb 510.9 | bsz 1 | num_updates 42580 | best_loss 8.725
2022-03-07 21:21:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 875 @ 42580 updates
2022-03-07 21:21:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:21:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 875 @ 42580 updates, score 13.402) (writing took 1.6449218466877937 seconds)
2022-03-07 21:21:42 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)
2022-03-07 21:21:42 | INFO | train | epoch 875 | loss 1.579 | nll_loss 0.222 | ppl 1.17 | wps 25738.4 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 42580 | lr 0.000153249 | gnorm 0.333 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 110760
2022-03-07 21:21:42 | INFO | fairseq.trainer | begin training epoch 876
2022-03-07 21:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:31 | INFO | train_inner | epoch 876:     20 / 49 loss=1.579, nll_loss=0.222, ppl=1.17, wps=25699.7, ups=0.4, wpb=64876.2, bsz=126.7, num_updates=42600, lr=0.000153213, gnorm=0.331, loss_scale=32, train_wall=218, gb_free=8.8, wall=110809
2022-03-07 21:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:23:44 | INFO | valid | epoch 876 | valid on 'valid' subset | loss 13.416 | nll_loss 12.959 | ppl 7959.8 | wps 47425.1 | wpb 510.9 | bsz 1 | num_updates 42629 | best_loss 8.725
2022-03-07 21:23:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 876 @ 42629 updates
2022-03-07 21:23:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:23:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:23:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 876 @ 42629 updates, score 13.416) (writing took 1.7781223366037011 seconds)
2022-03-07 21:23:46 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)
2022-03-07 21:23:46 | INFO | train | epoch 876 | loss 1.579 | nll_loss 0.222 | ppl 1.17 | wps 25719.2 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 42629 | lr 0.000153161 | gnorm 0.329 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 110884
2022-03-07 21:23:46 | INFO | fairseq.trainer | begin training epoch 877
2022-03-07 21:23:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:25:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:25:55 | INFO | valid | epoch 877 | valid on 'valid' subset | loss 13.56 | nll_loss 13.114 | ppl 8865.83 | wps 41220 | wpb 510.9 | bsz 1 | num_updates 42677 | best_loss 8.725
2022-03-07 21:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 877 @ 42677 updates
2022-03-07 21:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:25:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 877 @ 42677 updates, score 13.56) (writing took 2.026297620497644 seconds)
2022-03-07 21:25:57 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)
2022-03-07 21:25:57 | INFO | train | epoch 877 | loss 1.579 | nll_loss 0.222 | ppl 1.17 | wps 23705.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 42677 | lr 0.000153075 | gnorm 0.331 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111015
2022-03-07 21:25:57 | INFO | fairseq.trainer | begin training epoch 878
2022-03-07 21:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:26:55 | INFO | train_inner | epoch 878:     23 / 49 loss=1.579, nll_loss=0.222, ppl=1.17, wps=24563.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42700, lr=0.000153033, gnorm=0.329, loss_scale=32, train_wall=223, gb_free=8.8, wall=111073
2022-03-07 21:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:28:03 | INFO | valid | epoch 878 | valid on 'valid' subset | loss 13.506 | nll_loss 13.057 | ppl 8522.1 | wps 47748.6 | wpb 510.9 | bsz 1 | num_updates 42726 | best_loss 8.725
2022-03-07 21:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 878 @ 42726 updates
2022-03-07 21:28:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:28:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 878 @ 42726 updates, score 13.506) (writing took 1.6930179335176945 seconds)
2022-03-07 21:28:04 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)
2022-03-07 21:28:04 | INFO | train | epoch 878 | loss 1.579 | nll_loss 0.222 | ppl 1.17 | wps 24973.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42726 | lr 0.000152987 | gnorm 0.325 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111142
2022-03-07 21:28:04 | INFO | fairseq.trainer | begin training epoch 879
2022-03-07 21:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:30:06 | INFO | valid | epoch 879 | valid on 'valid' subset | loss 13.439 | nll_loss 12.984 | ppl 8103.18 | wps 47161.4 | wpb 510.9 | bsz 1 | num_updates 42775 | best_loss 8.725
2022-03-07 21:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 879 @ 42775 updates
2022-03-07 21:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 879 @ 42775 updates, score 13.439) (writing took 1.7093572868034244 seconds)
2022-03-07 21:30:08 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)
2022-03-07 21:30:08 | INFO | train | epoch 879 | loss 1.579 | nll_loss 0.221 | ppl 1.17 | wps 25692.5 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 42775 | lr 0.000152899 | gnorm 0.324 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 111266
2022-03-07 21:30:08 | INFO | fairseq.trainer | begin training epoch 880
2022-03-07 21:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:31:13 | INFO | train_inner | epoch 880:     26 / 49 loss=1.579, nll_loss=0.221, ppl=1.17, wps=25094.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42800, lr=0.000152854, gnorm=0.326, loss_scale=32, train_wall=222, gb_free=8.8, wall=111331
2022-03-07 21:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:32:15 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 13.458 | nll_loss 13.005 | ppl 8220.46 | wps 42855.6 | wpb 510.9 | bsz 1 | num_updates 42823 | best_loss 8.725
2022-03-07 21:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 42823 updates
2022-03-07 21:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 880 @ 42823 updates, score 13.458) (writing took 1.8061193926259875 seconds)
2022-03-07 21:32:17 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)
2022-03-07 21:32:17 | INFO | train | epoch 880 | loss 1.579 | nll_loss 0.221 | ppl 1.17 | wps 24114.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 42823 | lr 0.000152813 | gnorm 0.331 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 111395
2022-03-07 21:32:17 | INFO | fairseq.trainer | begin training epoch 881
2022-03-07 21:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:34:23 | INFO | valid | epoch 881 | valid on 'valid' subset | loss 13.502 | nll_loss 13.054 | ppl 8504.14 | wps 46281 | wpb 510.9 | bsz 1 | num_updates 42872 | best_loss 8.725
2022-03-07 21:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 881 @ 42872 updates
2022-03-07 21:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:34:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 881 @ 42872 updates, score 13.502) (writing took 1.8510444294661283 seconds)
2022-03-07 21:34:25 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)
2022-03-07 21:34:25 | INFO | train | epoch 881 | loss 1.579 | nll_loss 0.222 | ppl 1.17 | wps 24864 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42872 | lr 0.000152726 | gnorm 0.325 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 111523
2022-03-07 21:34:25 | INFO | fairseq.trainer | begin training epoch 882
2022-03-07 21:34:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:33 | INFO | train_inner | epoch 882:     28 / 49 loss=1.579, nll_loss=0.222, ppl=1.17, wps=24925.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42900, lr=0.000152676, gnorm=0.326, loss_scale=32, train_wall=223, gb_free=8.8, wall=111592
2022-03-07 21:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:36:28 | INFO | valid | epoch 882 | valid on 'valid' subset | loss 13.444 | nll_loss 12.992 | ppl 8147.23 | wps 47542.7 | wpb 510.9 | bsz 1 | num_updates 42921 | best_loss 8.725
2022-03-07 21:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 882 @ 42921 updates
2022-03-07 21:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 882 @ 42921 updates, score 13.444) (writing took 2.55790104996413 seconds)
2022-03-07 21:36:31 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)
2022-03-07 21:36:31 | INFO | train | epoch 882 | loss 1.579 | nll_loss 0.222 | ppl 1.17 | wps 25240.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42921 | lr 0.000152639 | gnorm 0.328 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 111649
2022-03-07 21:36:31 | INFO | fairseq.trainer | begin training epoch 883
2022-03-07 21:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:36:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:38:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:38:33 | INFO | valid | epoch 883 | valid on 'valid' subset | loss 13.465 | nll_loss 13.013 | ppl 8266.91 | wps 47661.1 | wpb 510.9 | bsz 1 | num_updates 42969 | best_loss 8.725
2022-03-07 21:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 883 @ 42969 updates
2022-03-07 21:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 883 @ 42969 updates, score 13.465) (writing took 2.5152828861027956 seconds)
2022-03-07 21:38:36 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)
2022-03-07 21:38:36 | INFO | train | epoch 883 | loss 1.579 | nll_loss 0.221 | ppl 1.17 | wps 24875.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42969 | lr 0.000152554 | gnorm 0.325 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 111774
2022-03-07 21:38:36 | INFO | fairseq.trainer | begin training epoch 884
2022-03-07 21:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:52 | INFO | train_inner | epoch 884:     31 / 49 loss=1.579, nll_loss=0.221, ppl=1.17, wps=25090.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=43000, lr=0.000152499, gnorm=0.327, loss_scale=32, train_wall=221, gb_free=8.8, wall=111850
2022-03-07 21:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:40:39 | INFO | valid | epoch 884 | valid on 'valid' subset | loss 13.434 | nll_loss 12.979 | ppl 8073.25 | wps 47678.8 | wpb 510.9 | bsz 1 | num_updates 43018 | best_loss 8.725
2022-03-07 21:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 884 @ 43018 updates
2022-03-07 21:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 884 @ 43018 updates, score 13.434) (writing took 2.4836763376370072 seconds)
2022-03-07 21:40:42 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)
2022-03-07 21:40:42 | INFO | train | epoch 884 | loss 1.578 | nll_loss 0.222 | ppl 1.17 | wps 25260 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43018 | lr 0.000152467 | gnorm 0.327 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111900
2022-03-07 21:40:42 | INFO | fairseq.trainer | begin training epoch 885
2022-03-07 21:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:42:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:42:44 | INFO | valid | epoch 885 | valid on 'valid' subset | loss 13.47 | nll_loss 13.017 | ppl 8289.05 | wps 47867.2 | wpb 510.9 | bsz 1 | num_updates 43067 | best_loss 8.725
2022-03-07 21:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 885 @ 43067 updates
2022-03-07 21:42:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:42:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 885 @ 43067 updates, score 13.47) (writing took 1.8702979451045394 seconds)
2022-03-07 21:42:46 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)
2022-03-07 21:42:46 | INFO | train | epoch 885 | loss 1.578 | nll_loss 0.221 | ppl 1.17 | wps 25615.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43067 | lr 0.00015238 | gnorm 0.326 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 112024
2022-03-07 21:42:46 | INFO | fairseq.trainer | begin training epoch 886
2022-03-07 21:42:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:42:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:44:09 | INFO | train_inner | epoch 886:     34 / 49 loss=1.578, nll_loss=0.221, ppl=1.17, wps=25261.9, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=43100, lr=0.000152322, gnorm=0.327, loss_scale=32, train_wall=221, gb_free=8.8, wall=112107
2022-03-07 21:44:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:44:49 | INFO | valid | epoch 886 | valid on 'valid' subset | loss 13.533 | nll_loss 13.085 | ppl 8690.86 | wps 45485.4 | wpb 510.9 | bsz 1 | num_updates 43115 | best_loss 8.725
2022-03-07 21:44:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 886 @ 43115 updates
2022-03-07 21:44:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:44:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 886 @ 43115 updates, score 13.533) (writing took 1.8947842689231038 seconds)
2022-03-07 21:44:51 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)
2022-03-07 21:44:51 | INFO | train | epoch 886 | loss 1.578 | nll_loss 0.221 | ppl 1.17 | wps 24902.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43115 | lr 0.000152295 | gnorm 0.327 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 112149
2022-03-07 21:44:51 | INFO | fairseq.trainer | begin training epoch 887
2022-03-07 21:44:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:53 | INFO | valid | epoch 887 | valid on 'valid' subset | loss 13.453 | nll_loss 13.003 | ppl 8207.83 | wps 47258.8 | wpb 510.9 | bsz 1 | num_updates 43164 | best_loss 8.725
2022-03-07 21:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 887 @ 43164 updates
2022-03-07 21:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 887 @ 43164 updates, score 13.453) (writing took 1.9873155476525426 seconds)
2022-03-07 21:46:55 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)
2022-03-07 21:46:55 | INFO | train | epoch 887 | loss 1.578 | nll_loss 0.221 | ppl 1.17 | wps 25497.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43164 | lr 0.000152209 | gnorm 0.324 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 112274
2022-03-07 21:46:55 | INFO | fairseq.trainer | begin training epoch 888
2022-03-07 21:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:23 | INFO | train_inner | epoch 888:     36 / 49 loss=1.578, nll_loss=0.221, ppl=1.17, wps=25521.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=43200, lr=0.000152145, gnorm=0.324, loss_scale=64, train_wall=218, gb_free=8.8, wall=112361
2022-03-07 21:48:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:48:58 | INFO | valid | epoch 888 | valid on 'valid' subset | loss 13.495 | nll_loss 13.046 | ppl 8459.93 | wps 45131 | wpb 510.9 | bsz 1 | num_updates 43213 | best_loss 8.725
2022-03-07 21:48:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 888 @ 43213 updates
2022-03-07 21:48:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:49:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:49:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 888 @ 43213 updates, score 13.495) (writing took 1.9295280184596777 seconds)
2022-03-07 21:49:00 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)
2022-03-07 21:49:00 | INFO | train | epoch 888 | loss 1.578 | nll_loss 0.221 | ppl 1.17 | wps 25475.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43213 | lr 0.000152122 | gnorm 0.325 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 112398
2022-03-07 21:49:00 | INFO | fairseq.trainer | begin training epoch 889
2022-03-07 21:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:51:06 | INFO | valid | epoch 889 | valid on 'valid' subset | loss 13.472 | nll_loss 13.021 | ppl 8312.59 | wps 43804.5 | wpb 510.9 | bsz 1 | num_updates 43261 | best_loss 8.725
2022-03-07 21:51:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 889 @ 43261 updates
2022-03-07 21:51:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 889 @ 43261 updates, score 13.472) (writing took 1.8565727472305298 seconds)
2022-03-07 21:51:07 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)
2022-03-07 21:51:07 | INFO | train | epoch 889 | loss 1.578 | nll_loss 0.221 | ppl 1.17 | wps 24452.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43261 | lr 0.000152038 | gnorm 0.329 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 112526
2022-03-07 21:51:07 | INFO | fairseq.trainer | begin training epoch 890
2022-03-07 21:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:42 | INFO | train_inner | epoch 890:     39 / 49 loss=1.578, nll_loss=0.221, ppl=1.17, wps=25009.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=43300, lr=0.000151969, gnorm=0.328, loss_scale=32, train_wall=222, gb_free=8.8, wall=112621
2022-03-07 21:53:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:53:10 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 13.466 | nll_loss 13.015 | ppl 8278.99 | wps 46822.4 | wpb 510.9 | bsz 1 | num_updates 43310 | best_loss 8.725
2022-03-07 21:53:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 43310 updates
2022-03-07 21:53:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:53:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:53:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 890 @ 43310 updates, score 13.466) (writing took 1.9359220946207643 seconds)
2022-03-07 21:53:12 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)
2022-03-07 21:53:12 | INFO | train | epoch 890 | loss 1.578 | nll_loss 0.221 | ppl 1.17 | wps 25530.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43310 | lr 0.000151952 | gnorm 0.328 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 112650
2022-03-07 21:53:12 | INFO | fairseq.trainer | begin training epoch 891
2022-03-07 21:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:55:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:55:17 | INFO | valid | epoch 891 | valid on 'valid' subset | loss 13.493 | nll_loss 13.042 | ppl 8433.03 | wps 39461.8 | wpb 510.9 | bsz 1 | num_updates 43358 | best_loss 8.725
2022-03-07 21:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 891 @ 43358 updates
2022-03-07 21:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:55:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:55:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 891 @ 43358 updates, score 13.493) (writing took 2.592773620970547 seconds)
2022-03-07 21:55:20 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)
2022-03-07 21:55:20 | INFO | train | epoch 891 | loss 1.578 | nll_loss 0.221 | ppl 1.17 | wps 24319.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43358 | lr 0.000151868 | gnorm 0.325 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112778
2022-03-07 21:55:20 | INFO | fairseq.trainer | begin training epoch 892
2022-03-07 21:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:57:06 | INFO | train_inner | epoch 892:     42 / 49 loss=1.578, nll_loss=0.221, ppl=1.17, wps=24616.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43400, lr=0.000151794, gnorm=0.326, loss_scale=32, train_wall=225, gb_free=8.8, wall=112884
2022-03-07 21:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:57:28 | INFO | valid | epoch 892 | valid on 'valid' subset | loss 13.509 | nll_loss 13.063 | ppl 8559.56 | wps 39904.3 | wpb 510.9 | bsz 1 | num_updates 43407 | best_loss 8.725
2022-03-07 21:57:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 892 @ 43407 updates
2022-03-07 21:57:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:57:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:57:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 892 @ 43407 updates, score 13.509) (writing took 2.4862582832574844 seconds)
2022-03-07 21:57:30 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)
2022-03-07 21:57:30 | INFO | train | epoch 892 | loss 1.577 | nll_loss 0.22 | ppl 1.16 | wps 24370.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43407 | lr 0.000151782 | gnorm 0.326 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 112909
2022-03-07 21:57:30 | INFO | fairseq.trainer | begin training epoch 893
2022-03-07 21:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:59:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:59:37 | INFO | valid | epoch 893 | valid on 'valid' subset | loss 13.49 | nll_loss 13.037 | ppl 8407.56 | wps 45171.2 | wpb 510.9 | bsz 1 | num_updates 43456 | best_loss 8.725
2022-03-07 21:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 893 @ 43456 updates
2022-03-07 21:59:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 893 @ 43456 updates, score 13.49) (writing took 1.8244229080155492 seconds)
2022-03-07 21:59:38 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)
2022-03-07 21:59:38 | INFO | train | epoch 893 | loss 1.577 | nll_loss 0.22 | ppl 1.17 | wps 24807.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43456 | lr 0.000151696 | gnorm 0.327 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 113037
2022-03-07 21:59:38 | INFO | fairseq.trainer | begin training epoch 894
2022-03-07 21:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:01:25 | INFO | train_inner | epoch 894:     44 / 49 loss=1.577, nll_loss=0.22, ppl=1.16, wps=25033.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43500, lr=0.00015162, gnorm=0.325, loss_scale=64, train_wall=221, gb_free=8.8, wall=113143
2022-03-07 22:01:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:01:41 | INFO | valid | epoch 894 | valid on 'valid' subset | loss 13.462 | nll_loss 13.012 | ppl 8259.83 | wps 46301.5 | wpb 510.9 | bsz 1 | num_updates 43504 | best_loss 8.725
2022-03-07 22:01:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 894 @ 43504 updates
2022-03-07 22:01:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 894 @ 43504 updates, score 13.462) (writing took 1.905992149375379 seconds)
2022-03-07 22:01:43 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)
2022-03-07 22:01:43 | INFO | train | epoch 894 | loss 1.577 | nll_loss 0.22 | ppl 1.16 | wps 25063.4 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 43504 | lr 0.000151613 | gnorm 0.324 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113161
2022-03-07 22:01:43 | INFO | fairseq.trainer | begin training epoch 895
2022-03-07 22:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:03:45 | INFO | valid | epoch 895 | valid on 'valid' subset | loss 13.512 | nll_loss 13.065 | ppl 8569.33 | wps 45572.4 | wpb 510.9 | bsz 1 | num_updates 43553 | best_loss 8.725
2022-03-07 22:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 895 @ 43553 updates
2022-03-07 22:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:03:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:03:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 895 @ 43553 updates, score 13.512) (writing took 1.8557976558804512 seconds)
2022-03-07 22:03:47 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)
2022-03-07 22:03:47 | INFO | train | epoch 895 | loss 1.577 | nll_loss 0.22 | ppl 1.16 | wps 25546 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43553 | lr 0.000151527 | gnorm 0.33 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113285
2022-03-07 22:03:47 | INFO | fairseq.trainer | begin training epoch 896
2022-03-07 22:03:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:05:42 | INFO | train_inner | epoch 896:     47 / 49 loss=1.577, nll_loss=0.22, ppl=1.17, wps=25243, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43600, lr=0.000151446, gnorm=0.328, loss_scale=32, train_wall=221, gb_free=8.8, wall=113400
2022-03-07 22:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:05:51 | INFO | valid | epoch 896 | valid on 'valid' subset | loss 13.509 | nll_loss 13.062 | ppl 8551.95 | wps 39373.8 | wpb 510.9 | bsz 1 | num_updates 43602 | best_loss 8.725
2022-03-07 22:05:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 896 @ 43602 updates
2022-03-07 22:05:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:05:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 896 @ 43602 updates, score 13.509) (writing took 2.389888158068061 seconds)
2022-03-07 22:05:54 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)
2022-03-07 22:05:54 | INFO | train | epoch 896 | loss 1.577 | nll_loss 0.22 | ppl 1.16 | wps 25076.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43602 | lr 0.000151442 | gnorm 0.324 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113412
2022-03-07 22:05:54 | INFO | fairseq.trainer | begin training epoch 897
2022-03-07 22:05:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:07:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:08:00 | INFO | valid | epoch 897 | valid on 'valid' subset | loss 13.482 | nll_loss 13.033 | ppl 8382.34 | wps 45273.9 | wpb 510.9 | bsz 1 | num_updates 43650 | best_loss 8.725
2022-03-07 22:08:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 897 @ 43650 updates
2022-03-07 22:08:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:08:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 897 @ 43650 updates, score 13.482) (writing took 1.8930653519928455 seconds)
2022-03-07 22:08:02 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)
2022-03-07 22:08:02 | INFO | train | epoch 897 | loss 1.577 | nll_loss 0.22 | ppl 1.16 | wps 24356.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43650 | lr 0.000151359 | gnorm 0.322 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 113540
2022-03-07 22:08:02 | INFO | fairseq.trainer | begin training epoch 898
2022-03-07 22:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:10:04 | INFO | valid | epoch 898 | valid on 'valid' subset | loss 13.563 | nll_loss 13.119 | ppl 8898.55 | wps 47437.7 | wpb 510.9 | bsz 1 | num_updates 43699 | best_loss 8.725
2022-03-07 22:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 898 @ 43699 updates
2022-03-07 22:10:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:10:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:10:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 898 @ 43699 updates, score 13.563) (writing took 1.8528173929080367 seconds)
2022-03-07 22:10:06 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)
2022-03-07 22:10:06 | INFO | train | epoch 898 | loss 1.577 | nll_loss 0.22 | ppl 1.17 | wps 25590.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43699 | lr 0.000151274 | gnorm 0.332 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113664
2022-03-07 22:10:06 | INFO | fairseq.trainer | begin training epoch 899
2022-03-07 22:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:10:08 | INFO | train_inner | epoch 899:      1 / 49 loss=1.577, nll_loss=0.22, ppl=1.16, wps=24241.7, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=43700, lr=0.000151272, gnorm=0.328, loss_scale=32, train_wall=222, gb_free=8.8, wall=113666
2022-03-07 22:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:12:10 | INFO | valid | epoch 899 | valid on 'valid' subset | loss 13.485 | nll_loss 13.038 | ppl 8410.95 | wps 41376.7 | wpb 510.9 | bsz 1 | num_updates 43748 | best_loss 8.725
2022-03-07 22:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 899 @ 43748 updates
2022-03-07 22:12:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:12:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 899 @ 43748 updates, score 13.485) (writing took 2.4531331975013018 seconds)
2022-03-07 22:12:12 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)
2022-03-07 22:12:12 | INFO | train | epoch 899 | loss 1.576 | nll_loss 0.22 | ppl 1.16 | wps 25149.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43748 | lr 0.000151189 | gnorm 0.325 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113790
2022-03-07 22:12:12 | INFO | fairseq.trainer | begin training epoch 900
2022-03-07 22:12:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:14:18 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 13.411 | nll_loss 12.961 | ppl 7970.81 | wps 46032.2 | wpb 510.9 | bsz 1 | num_updates 43797 | best_loss 8.725
2022-03-07 22:14:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 43797 updates
2022-03-07 22:14:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:14:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:14:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 900 @ 43797 updates, score 13.411) (writing took 1.866258087567985 seconds)
2022-03-07 22:14:20 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)
2022-03-07 22:14:20 | INFO | train | epoch 900 | loss 1.576 | nll_loss 0.22 | ppl 1.16 | wps 24817.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43797 | lr 0.000151105 | gnorm 0.322 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 113918
2022-03-07 22:14:20 | INFO | fairseq.trainer | begin training epoch 901
2022-03-07 22:14:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:14:28 | INFO | train_inner | epoch 901:      3 / 49 loss=1.576, nll_loss=0.22, ppl=1.16, wps=25015, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43800, lr=0.000151099, gnorm=0.324, loss_scale=64, train_wall=222, gb_free=8.8, wall=113926
2022-03-07 22:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:16:23 | INFO | valid | epoch 901 | valid on 'valid' subset | loss 13.417 | nll_loss 12.965 | ppl 7995.24 | wps 46186.5 | wpb 510.9 | bsz 1 | num_updates 43846 | best_loss 8.725
2022-03-07 22:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 901 @ 43846 updates
2022-03-07 22:16:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:16:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:16:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 901 @ 43846 updates, score 13.417) (writing took 1.905890661291778 seconds)
2022-03-07 22:16:25 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)
2022-03-07 22:16:25 | INFO | train | epoch 901 | loss 1.576 | nll_loss 0.22 | ppl 1.16 | wps 25511.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43846 | lr 0.00015102 | gnorm 0.323 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 114043
2022-03-07 22:16:25 | INFO | fairseq.trainer | begin training epoch 902
2022-03-07 22:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:18:29 | INFO | valid | epoch 902 | valid on 'valid' subset | loss 13.489 | nll_loss 13.04 | ppl 8425.02 | wps 40805.8 | wpb 510.9 | bsz 1 | num_updates 43895 | best_loss 8.725
2022-03-07 22:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 902 @ 43895 updates
2022-03-07 22:18:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:18:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 902 @ 43895 updates, score 13.489) (writing took 2.423025713302195 seconds)
2022-03-07 22:18:31 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)
2022-03-07 22:18:31 | INFO | train | epoch 902 | loss 1.576 | nll_loss 0.219 | ppl 1.16 | wps 25064.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43895 | lr 0.000150936 | gnorm 0.321 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 114170
2022-03-07 22:18:32 | INFO | fairseq.trainer | begin training epoch 903
2022-03-07 22:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:18:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:18:46 | INFO | train_inner | epoch 903:      6 / 49 loss=1.576, nll_loss=0.219, ppl=1.16, wps=25051.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43900, lr=0.000150927, gnorm=0.322, loss_scale=32, train_wall=222, gb_free=8.8, wall=114185
2022-03-07 22:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:20:38 | INFO | valid | epoch 903 | valid on 'valid' subset | loss 13.451 | nll_loss 13 | ppl 8191.54 | wps 44908.1 | wpb 510.9 | bsz 1 | num_updates 43943 | best_loss 8.725
2022-03-07 22:20:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 903 @ 43943 updates
2022-03-07 22:20:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 903 @ 43943 updates, score 13.451) (writing took 1.883943835273385 seconds)
2022-03-07 22:20:40 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)
2022-03-07 22:20:40 | INFO | train | epoch 903 | loss 1.576 | nll_loss 0.22 | ppl 1.16 | wps 24263.9 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 43943 | lr 0.000150853 | gnorm 0.325 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 114298
2022-03-07 22:20:40 | INFO | fairseq.trainer | begin training epoch 904
2022-03-07 22:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:22:42 | INFO | valid | epoch 904 | valid on 'valid' subset | loss 13.454 | nll_loss 13.003 | ppl 8207.56 | wps 47544.4 | wpb 510.9 | bsz 1 | num_updates 43992 | best_loss 8.725
2022-03-07 22:22:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 904 @ 43992 updates
2022-03-07 22:22:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:22:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 904 @ 43992 updates, score 13.454) (writing took 1.8923391541466117 seconds)
2022-03-07 22:22:44 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)
2022-03-07 22:22:44 | INFO | train | epoch 904 | loss 1.576 | nll_loss 0.22 | ppl 1.16 | wps 25585.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43992 | lr 0.000150769 | gnorm 0.326 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 114422
2022-03-07 22:22:44 | INFO | fairseq.trainer | begin training epoch 905
2022-03-07 22:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:23:03 | INFO | train_inner | epoch 905:      8 / 49 loss=1.576, nll_loss=0.22, ppl=1.16, wps=25251, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=44000, lr=0.000150756, gnorm=0.325, loss_scale=32, train_wall=221, gb_free=8.8, wall=114442
2022-03-07 22:24:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:24:46 | INFO | valid | epoch 905 | valid on 'valid' subset | loss 13.457 | nll_loss 13.004 | ppl 8215.89 | wps 46621.5 | wpb 510.9 | bsz 1 | num_updates 44041 | best_loss 8.725
2022-03-07 22:24:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 905 @ 44041 updates
2022-03-07 22:24:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 905 @ 44041 updates, score 13.457) (writing took 1.8326105559244752 seconds)
2022-03-07 22:24:48 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)
2022-03-07 22:24:48 | INFO | train | epoch 905 | loss 1.576 | nll_loss 0.22 | ppl 1.16 | wps 25575 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44041 | lr 0.000150685 | gnorm 0.326 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 114546
2022-03-07 22:24:48 | INFO | fairseq.trainer | begin training epoch 906
2022-03-07 22:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:25:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:26:55 | INFO | valid | epoch 906 | valid on 'valid' subset | loss 13.528 | nll_loss 13.08 | ppl 8660 | wps 40548.3 | wpb 510.9 | bsz 1 | num_updates 44089 | best_loss 8.725
2022-03-07 22:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 906 @ 44089 updates
2022-03-07 22:26:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:26:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 906 @ 44089 updates, score 13.528) (writing took 2.826289507560432 seconds)
2022-03-07 22:26:58 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)
2022-03-07 22:26:58 | INFO | train | epoch 906 | loss 1.576 | nll_loss 0.219 | ppl 1.16 | wps 23973 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 44089 | lr 0.000150603 | gnorm 0.325 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 114676
2022-03-07 22:26:58 | INFO | fairseq.trainer | begin training epoch 907
2022-03-07 22:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:27:26 | INFO | train_inner | epoch 907:     11 / 49 loss=1.576, nll_loss=0.22, ppl=1.16, wps=24689.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44100, lr=0.000150585, gnorm=0.325, loss_scale=32, train_wall=224, gb_free=8.8, wall=114704
2022-03-07 22:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:29:06 | INFO | valid | epoch 907 | valid on 'valid' subset | loss 13.528 | nll_loss 13.082 | ppl 8673.38 | wps 40124.3 | wpb 510.9 | bsz 1 | num_updates 44138 | best_loss 8.725
2022-03-07 22:29:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 907 @ 44138 updates
2022-03-07 22:29:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:29:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 907 @ 44138 updates, score 13.528) (writing took 2.5422778548672795 seconds)
2022-03-07 22:29:09 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)
2022-03-07 22:29:09 | INFO | train | epoch 907 | loss 1.576 | nll_loss 0.219 | ppl 1.16 | wps 24299.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44138 | lr 0.00015052 | gnorm 0.321 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 114807
2022-03-07 22:29:09 | INFO | fairseq.trainer | begin training epoch 908
2022-03-07 22:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:30:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:31:14 | INFO | valid | epoch 908 | valid on 'valid' subset | loss 13.523 | nll_loss 13.075 | ppl 8628.32 | wps 47244.1 | wpb 510.9 | bsz 1 | num_updates 44186 | best_loss 8.725
2022-03-07 22:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 908 @ 44186 updates
2022-03-07 22:31:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:31:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:31:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 908 @ 44186 updates, score 13.523) (writing took 1.9106180761009455 seconds)
2022-03-07 22:31:16 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)
2022-03-07 22:31:16 | INFO | train | epoch 908 | loss 1.576 | nll_loss 0.22 | ppl 1.16 | wps 24441.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44186 | lr 0.000150438 | gnorm 0.329 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 114934
2022-03-07 22:31:16 | INFO | fairseq.trainer | begin training epoch 909
2022-03-07 22:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:31:50 | INFO | train_inner | epoch 909:     14 / 49 loss=1.576, nll_loss=0.22, ppl=1.16, wps=24566.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44200, lr=0.000150414, gnorm=0.325, loss_scale=32, train_wall=226, gb_free=8.8, wall=114968
2022-03-07 22:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:33:19 | INFO | valid | epoch 909 | valid on 'valid' subset | loss 13.491 | nll_loss 13.04 | ppl 8424.63 | wps 45567.9 | wpb 510.9 | bsz 1 | num_updates 44235 | best_loss 8.725
2022-03-07 22:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 909 @ 44235 updates
2022-03-07 22:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:33:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:33:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 909 @ 44235 updates, score 13.491) (writing took 1.8480396177619696 seconds)
2022-03-07 22:33:21 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)
2022-03-07 22:33:21 | INFO | train | epoch 909 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 25561.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44235 | lr 0.000150355 | gnorm 0.325 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 115059
2022-03-07 22:33:21 | INFO | fairseq.trainer | begin training epoch 910
2022-03-07 22:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:35:23 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 13.574 | nll_loss 13.131 | ppl 8973.18 | wps 47270.5 | wpb 510.9 | bsz 1 | num_updates 44284 | best_loss 8.725
2022-03-07 22:35:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 44284 updates
2022-03-07 22:35:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 910 @ 44284 updates, score 13.574) (writing took 2.0597772104665637 seconds)
2022-03-07 22:35:25 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)
2022-03-07 22:35:25 | INFO | train | epoch 910 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 25533 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44284 | lr 0.000150271 | gnorm 0.324 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 115183
2022-03-07 22:35:25 | INFO | fairseq.trainer | begin training epoch 911
2022-03-07 22:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:36:04 | INFO | train_inner | epoch 911:     16 / 49 loss=1.575, nll_loss=0.219, ppl=1.16, wps=25560.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44300, lr=0.000150244, gnorm=0.324, loss_scale=32, train_wall=218, gb_free=8.8, wall=115222
2022-03-07 22:36:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:37:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:37:28 | INFO | valid | epoch 911 | valid on 'valid' subset | loss 13.55 | nll_loss 13.105 | ppl 8809.91 | wps 47317.9 | wpb 510.9 | bsz 1 | num_updates 44332 | best_loss 8.725
2022-03-07 22:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 911 @ 44332 updates
2022-03-07 22:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 911 @ 44332 updates, score 13.55) (writing took 1.9142046011984348 seconds)
2022-03-07 22:37:30 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)
2022-03-07 22:37:30 | INFO | train | epoch 911 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 24970 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 44332 | lr 0.00015019 | gnorm 0.327 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 115308
2022-03-07 22:37:30 | INFO | fairseq.trainer | begin training epoch 912
2022-03-07 22:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:39:35 | INFO | valid | epoch 912 | valid on 'valid' subset | loss 13.516 | nll_loss 13.07 | ppl 8599.2 | wps 40313.4 | wpb 510.9 | bsz 1 | num_updates 44381 | best_loss 8.725
2022-03-07 22:39:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 912 @ 44381 updates
2022-03-07 22:39:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:39:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:39:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 912 @ 44381 updates, score 13.516) (writing took 2.5819309633225203 seconds)
2022-03-07 22:39:37 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)
2022-03-07 22:39:37 | INFO | train | epoch 912 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 24932.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44381 | lr 0.000150107 | gnorm 0.326 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115435
2022-03-07 22:39:37 | INFO | fairseq.trainer | begin training epoch 913
2022-03-07 22:39:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:40:25 | INFO | train_inner | epoch 913:     19 / 49 loss=1.575, nll_loss=0.219, ppl=1.16, wps=24819.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=44400, lr=0.000150075, gnorm=0.326, loss_scale=32, train_wall=223, gb_free=8.8, wall=115484
2022-03-07 22:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:41:45 | INFO | valid | epoch 913 | valid on 'valid' subset | loss 13.541 | nll_loss 13.095 | ppl 8748.45 | wps 39268.2 | wpb 510.9 | bsz 1 | num_updates 44430 | best_loss 8.725
2022-03-07 22:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 913 @ 44430 updates
2022-03-07 22:41:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:41:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:41:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 913 @ 44430 updates, score 13.541) (writing took 2.478525766171515 seconds)
2022-03-07 22:41:48 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)
2022-03-07 22:41:48 | INFO | train | epoch 913 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 24294.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 44430 | lr 0.000150024 | gnorm 0.325 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 115566
2022-03-07 22:41:48 | INFO | fairseq.trainer | begin training epoch 914
2022-03-07 22:41:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:43:57 | INFO | valid | epoch 914 | valid on 'valid' subset | loss 13.504 | nll_loss 13.053 | ppl 8500.04 | wps 39668.7 | wpb 510.9 | bsz 1 | num_updates 44478 | best_loss 8.725
2022-03-07 22:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 914 @ 44478 updates
2022-03-07 22:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:44:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:44:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 914 @ 44478 updates, score 13.504) (writing took 2.8104657121002674 seconds)
2022-03-07 22:44:00 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)
2022-03-07 22:44:00 | INFO | train | epoch 914 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 23641.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 44478 | lr 0.000149943 | gnorm 0.322 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 115698
2022-03-07 22:44:00 | INFO | fairseq.trainer | begin training epoch 915
2022-03-07 22:44:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:44:53 | INFO | train_inner | epoch 915:     22 / 49 loss=1.575, nll_loss=0.219, ppl=1.16, wps=24234.5, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=44500, lr=0.000149906, gnorm=0.323, loss_scale=32, train_wall=227, gb_free=8.8, wall=115751
2022-03-07 22:45:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:46:02 | INFO | valid | epoch 915 | valid on 'valid' subset | loss 13.512 | nll_loss 13.066 | ppl 8573.62 | wps 46325.6 | wpb 510.9 | bsz 1 | num_updates 44527 | best_loss 8.725
2022-03-07 22:46:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 915 @ 44527 updates
2022-03-07 22:46:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:46:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:46:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 915 @ 44527 updates, score 13.512) (writing took 1.8877276256680489 seconds)
2022-03-07 22:46:04 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)
2022-03-07 22:46:04 | INFO | train | epoch 915 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 25528.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44527 | lr 0.000149861 | gnorm 0.325 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 115822
2022-03-07 22:46:04 | INFO | fairseq.trainer | begin training epoch 916
2022-03-07 22:46:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:48:06 | INFO | valid | epoch 916 | valid on 'valid' subset | loss 13.567 | nll_loss 13.123 | ppl 8923.84 | wps 47221.2 | wpb 510.9 | bsz 1 | num_updates 44576 | best_loss 8.725
2022-03-07 22:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 916 @ 44576 updates
2022-03-07 22:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:48:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:48:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 916 @ 44576 updates, score 13.567) (writing took 1.8916290672495961 seconds)
2022-03-07 22:48:08 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)
2022-03-07 22:48:08 | INFO | train | epoch 916 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 25625.2 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 44576 | lr 0.000149778 | gnorm 0.323 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 115946
2022-03-07 22:48:08 | INFO | fairseq.trainer | begin training epoch 917
2022-03-07 22:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:49:09 | INFO | train_inner | epoch 917:     25 / 49 loss=1.575, nll_loss=0.219, ppl=1.16, wps=25375.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44600, lr=0.000149738, gnorm=0.324, loss_scale=32, train_wall=220, gb_free=8.8, wall=116007
2022-03-07 22:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:50:11 | INFO | valid | epoch 917 | valid on 'valid' subset | loss 13.408 | nll_loss 12.955 | ppl 7938.22 | wps 46942 | wpb 510.9 | bsz 1 | num_updates 44624 | best_loss 8.725
2022-03-07 22:50:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 917 @ 44624 updates
2022-03-07 22:50:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:50:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 917 @ 44624 updates, score 13.408) (writing took 1.984600697644055 seconds)
2022-03-07 22:50:13 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)
2022-03-07 22:50:13 | INFO | train | epoch 917 | loss 1.575 | nll_loss 0.219 | ppl 1.16 | wps 25014.5 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 44624 | lr 0.000149698 | gnorm 0.328 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116071
2022-03-07 22:50:13 | INFO | fairseq.trainer | begin training epoch 918
2022-03-07 22:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:52:15 | INFO | valid | epoch 918 | valid on 'valid' subset | loss 13.528 | nll_loss 13.083 | ppl 8676.62 | wps 46467.8 | wpb 510.9 | bsz 1 | num_updates 44673 | best_loss 8.725
2022-03-07 22:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 918 @ 44673 updates
2022-03-07 22:52:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 918 @ 44673 updates, score 13.528) (writing took 2.0445211799815297 seconds)
2022-03-07 22:52:17 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)
2022-03-07 22:52:17 | INFO | train | epoch 918 | loss 1.574 | nll_loss 0.219 | ppl 1.16 | wps 25497.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44673 | lr 0.000149616 | gnorm 0.323 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116195
2022-03-07 22:52:17 | INFO | fairseq.trainer | begin training epoch 919
2022-03-07 22:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:53:23 | INFO | train_inner | epoch 919:     27 / 49 loss=1.575, nll_loss=0.219, ppl=1.16, wps=25527.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=44700, lr=0.000149571, gnorm=0.325, loss_scale=32, train_wall=218, gb_free=8.8, wall=116261
2022-03-07 22:54:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:54:20 | INFO | valid | epoch 919 | valid on 'valid' subset | loss 13.478 | nll_loss 13.027 | ppl 8346.71 | wps 45401.4 | wpb 510.9 | bsz 1 | num_updates 44722 | best_loss 8.725
2022-03-07 22:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 919 @ 44722 updates
2022-03-07 22:54:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:54:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 919 @ 44722 updates, score 13.478) (writing took 1.8663539979606867 seconds)
2022-03-07 22:54:22 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)
2022-03-07 22:54:22 | INFO | train | epoch 919 | loss 1.574 | nll_loss 0.218 | ppl 1.16 | wps 25553.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44722 | lr 0.000149534 | gnorm 0.324 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 116320
2022-03-07 22:54:22 | INFO | fairseq.trainer | begin training epoch 920
2022-03-07 22:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:56:25 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 13.54 | nll_loss 13.095 | ppl 8752.32 | wps 45149.2 | wpb 510.9 | bsz 1 | num_updates 44770 | best_loss 8.725
2022-03-07 22:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 44770 updates
2022-03-07 22:56:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 920 @ 44770 updates, score 13.54) (writing took 1.8891368694603443 seconds)
2022-03-07 22:56:26 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)
2022-03-07 22:56:26 | INFO | train | epoch 920 | loss 1.574 | nll_loss 0.218 | ppl 1.16 | wps 24918.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44770 | lr 0.000149454 | gnorm 0.323 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116445
2022-03-07 22:56:26 | INFO | fairseq.trainer | begin training epoch 921
2022-03-07 22:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:57:39 | INFO | train_inner | epoch 921:     30 / 49 loss=1.574, nll_loss=0.218, ppl=1.16, wps=25306.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44800, lr=0.000149404, gnorm=0.324, loss_scale=32, train_wall=220, gb_free=8.8, wall=116517
2022-03-07 22:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:58:29 | INFO | valid | epoch 921 | valid on 'valid' subset | loss 13.456 | nll_loss 13.006 | ppl 8226.75 | wps 45805.8 | wpb 510.9 | bsz 1 | num_updates 44819 | best_loss 8.725
2022-03-07 22:58:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 921 @ 44819 updates
2022-03-07 22:58:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 921 @ 44819 updates, score 13.456) (writing took 1.8582770163193345 seconds)
2022-03-07 22:58:31 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)
2022-03-07 22:58:31 | INFO | train | epoch 921 | loss 1.574 | nll_loss 0.218 | ppl 1.16 | wps 25552.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44819 | lr 0.000149372 | gnorm 0.325 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116569
2022-03-07 22:58:31 | INFO | fairseq.trainer | begin training epoch 922
2022-03-07 22:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:00:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:00:33 | INFO | valid | epoch 922 | valid on 'valid' subset | loss 13.487 | nll_loss 13.038 | ppl 8407.74 | wps 45266.7 | wpb 510.9 | bsz 1 | num_updates 44868 | best_loss 8.725
2022-03-07 23:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 922 @ 44868 updates
2022-03-07 23:00:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 922 @ 44868 updates, score 13.487) (writing took 1.9211812671273947 seconds)
2022-03-07 23:00:35 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)
2022-03-07 23:00:35 | INFO | train | epoch 922 | loss 1.574 | nll_loss 0.218 | ppl 1.16 | wps 25514.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44868 | lr 0.00014929 | gnorm 0.322 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 116694
2022-03-07 23:00:35 | INFO | fairseq.trainer | begin training epoch 923
2022-03-07 23:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:00:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:01:57 | INFO | train_inner | epoch 923:     33 / 49 loss=1.574, nll_loss=0.218, ppl=1.16, wps=25198.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=44900, lr=0.000149237, gnorm=0.325, loss_scale=32, train_wall=221, gb_free=8.8, wall=116775
2022-03-07 23:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:02:41 | INFO | valid | epoch 923 | valid on 'valid' subset | loss 13.454 | nll_loss 13.004 | ppl 8213.67 | wps 42147.4 | wpb 510.9 | bsz 1 | num_updates 44916 | best_loss 8.725
2022-03-07 23:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 923 @ 44916 updates
2022-03-07 23:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 923 @ 44916 updates, score 13.454) (writing took 2.2132070874795318 seconds)
2022-03-07 23:02:43 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)
2022-03-07 23:02:43 | INFO | train | epoch 923 | loss 1.574 | nll_loss 0.218 | ppl 1.16 | wps 24370.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44916 | lr 0.000149211 | gnorm 0.327 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 116821
2022-03-07 23:02:43 | INFO | fairseq.trainer | begin training epoch 924
2022-03-07 23:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:04:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:04:46 | INFO | valid | epoch 924 | valid on 'valid' subset | loss 13.557 | nll_loss 13.112 | ppl 8853.34 | wps 46430 | wpb 510.9 | bsz 1 | num_updates 44965 | best_loss 8.725
2022-03-07 23:04:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 924 @ 44965 updates
2022-03-07 23:04:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 924 @ 44965 updates, score 13.557) (writing took 1.8736560111865401 seconds)
2022-03-07 23:04:48 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)
2022-03-07 23:04:48 | INFO | train | epoch 924 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 25421.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44965 | lr 0.000149129 | gnorm 0.319 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116946
2022-03-07 23:04:48 | INFO | fairseq.trainer | begin training epoch 925
2022-03-07 23:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:06:13 | INFO | train_inner | epoch 925:     35 / 49 loss=1.573, nll_loss=0.218, ppl=1.16, wps=25300.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=45000, lr=0.000149071, gnorm=0.32, loss_scale=32, train_wall=220, gb_free=8.8, wall=117031
2022-03-07 23:06:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:06:50 | INFO | valid | epoch 925 | valid on 'valid' subset | loss 13.45 | nll_loss 12.997 | ppl 8176.09 | wps 47127.6 | wpb 510.9 | bsz 1 | num_updates 45013 | best_loss 8.725
2022-03-07 23:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 925 @ 45013 updates
2022-03-07 23:06:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 925 @ 45013 updates, score 13.45) (writing took 1.796269222162664 seconds)
2022-03-07 23:06:52 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)
2022-03-07 23:06:52 | INFO | train | epoch 925 | loss 1.574 | nll_loss 0.218 | ppl 1.16 | wps 25094.2 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 45013 | lr 0.00014905 | gnorm 0.323 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117070
2022-03-07 23:06:52 | INFO | fairseq.trainer | begin training epoch 926
2022-03-07 23:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:08:55 | INFO | valid | epoch 926 | valid on 'valid' subset | loss 13.463 | nll_loss 13.011 | ppl 8254.97 | wps 45458.3 | wpb 510.9 | bsz 1 | num_updates 45062 | best_loss 8.725
2022-03-07 23:08:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 926 @ 45062 updates
2022-03-07 23:08:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:08:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 926 @ 45062 updates, score 13.463) (writing took 2.020665637217462 seconds)
2022-03-07 23:08:57 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)
2022-03-07 23:08:57 | INFO | train | epoch 926 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 25481.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45062 | lr 0.000148969 | gnorm 0.325 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117195
2022-03-07 23:08:57 | INFO | fairseq.trainer | begin training epoch 927
2022-03-07 23:08:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:30 | INFO | train_inner | epoch 927:     38 / 49 loss=1.573, nll_loss=0.218, ppl=1.16, wps=25211.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=45100, lr=0.000148906, gnorm=0.322, loss_scale=32, train_wall=221, gb_free=8.8, wall=117289
2022-03-07 23:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:11:03 | INFO | valid | epoch 927 | valid on 'valid' subset | loss 13.515 | nll_loss 13.068 | ppl 8590.34 | wps 38353.3 | wpb 510.9 | bsz 1 | num_updates 45111 | best_loss 8.725
2022-03-07 23:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 927 @ 45111 updates
2022-03-07 23:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 927 @ 45111 updates, score 13.515) (writing took 2.686102951876819 seconds)
2022-03-07 23:11:06 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)
2022-03-07 23:11:06 | INFO | train | epoch 927 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 24647.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45111 | lr 0.000148888 | gnorm 0.319 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 117324
2022-03-07 23:11:06 | INFO | fairseq.trainer | begin training epoch 928
2022-03-07 23:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:12:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:13:14 | INFO | valid | epoch 928 | valid on 'valid' subset | loss 13.502 | nll_loss 13.051 | ppl 8487.2 | wps 43852.8 | wpb 510.9 | bsz 1 | num_updates 45159 | best_loss 8.725
2022-03-07 23:13:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 928 @ 45159 updates
2022-03-07 23:13:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:13:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:13:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 928 @ 45159 updates, score 13.502) (writing took 2.7130460664629936 seconds)
2022-03-07 23:13:17 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)
2022-03-07 23:13:17 | INFO | train | epoch 928 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 23729 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 45159 | lr 0.000148809 | gnorm 0.324 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 117455
2022-03-07 23:13:17 | INFO | fairseq.trainer | begin training epoch 929
2022-03-07 23:13:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:15:01 | INFO | train_inner | epoch 929:     41 / 49 loss=1.573, nll_loss=0.218, ppl=1.16, wps=23938.9, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=45200, lr=0.000148741, gnorm=0.323, loss_scale=32, train_wall=230, gb_free=8.8, wall=117560
2022-03-07 23:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:15:25 | INFO | valid | epoch 929 | valid on 'valid' subset | loss 13.466 | nll_loss 13.012 | ppl 8259.92 | wps 42192.5 | wpb 510.9 | bsz 1 | num_updates 45208 | best_loss 8.725
2022-03-07 23:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 929 @ 45208 updates
2022-03-07 23:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 929 @ 45208 updates, score 13.466) (writing took 2.877381883561611 seconds)
2022-03-07 23:15:28 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)
2022-03-07 23:15:28 | INFO | train | epoch 929 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 24247.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45208 | lr 0.000148728 | gnorm 0.322 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 117586
2022-03-07 23:15:28 | INFO | fairseq.trainer | begin training epoch 930
2022-03-07 23:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:17:37 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 13.528 | nll_loss 13.083 | ppl 8678.27 | wps 39271.8 | wpb 510.9 | bsz 1 | num_updates 45257 | best_loss 8.725
2022-03-07 23:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 45257 updates
2022-03-07 23:17:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 930 @ 45257 updates, score 13.528) (writing took 2.9214980266988277 seconds)
2022-03-07 23:17:40 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)
2022-03-07 23:17:40 | INFO | train | epoch 930 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 24102.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45257 | lr 0.000148647 | gnorm 0.321 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 117718
2022-03-07 23:17:40 | INFO | fairseq.trainer | begin training epoch 931
2022-03-07 23:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:19:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:19:32 | INFO | train_inner | epoch 931:     44 / 49 loss=1.573, nll_loss=0.218, ppl=1.16, wps=23990.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=45300, lr=0.000148577, gnorm=0.323, loss_scale=32, train_wall=229, gb_free=8.8, wall=117830
2022-03-07 23:19:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:19:49 | INFO | valid | epoch 931 | valid on 'valid' subset | loss 13.495 | nll_loss 13.049 | ppl 8473 | wps 37575.5 | wpb 510.9 | bsz 1 | num_updates 45305 | best_loss 8.725
2022-03-07 23:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 931 @ 45305 updates
2022-03-07 23:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 931 @ 45305 updates, score 13.495) (writing took 2.603279027156532 seconds)
2022-03-07 23:19:52 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)
2022-03-07 23:19:52 | INFO | train | epoch 931 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 23576.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 45305 | lr 0.000148569 | gnorm 0.325 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 117850
2022-03-07 23:19:52 | INFO | fairseq.trainer | begin training epoch 932
2022-03-07 23:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:22:01 | INFO | valid | epoch 932 | valid on 'valid' subset | loss 13.514 | nll_loss 13.065 | ppl 8572.17 | wps 36656.3 | wpb 510.9 | bsz 1 | num_updates 45354 | best_loss 8.725
2022-03-07 23:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 932 @ 45354 updates
2022-03-07 23:22:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:22:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 932 @ 45354 updates, score 13.514) (writing took 2.730017109774053 seconds)
2022-03-07 23:22:04 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)
2022-03-07 23:22:04 | INFO | train | epoch 932 | loss 1.573 | nll_loss 0.218 | ppl 1.16 | wps 24116.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45354 | lr 0.000148488 | gnorm 0.324 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 117982
2022-03-07 23:22:04 | INFO | fairseq.trainer | begin training epoch 933
2022-03-07 23:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:24:01 | INFO | train_inner | epoch 933:     46 / 49 loss=1.573, nll_loss=0.217, ppl=1.16, wps=24132.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=45400, lr=0.000148413, gnorm=0.322, loss_scale=32, train_wall=227, gb_free=8.8, wall=118099
2022-03-07 23:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:24:13 | INFO | valid | epoch 933 | valid on 'valid' subset | loss 13.497 | nll_loss 13.047 | ppl 8460.89 | wps 39018.1 | wpb 510.9 | bsz 1 | num_updates 45403 | best_loss 8.725
2022-03-07 23:24:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 933 @ 45403 updates
2022-03-07 23:24:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:24:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 933 @ 45403 updates, score 13.497) (writing took 2.567909335717559 seconds)
2022-03-07 23:24:15 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)
2022-03-07 23:24:15 | INFO | train | epoch 933 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 24175.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45403 | lr 0.000148408 | gnorm 0.32 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 118113
2022-03-07 23:24:15 | INFO | fairseq.trainer | begin training epoch 934
2022-03-07 23:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:25:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:26:25 | INFO | valid | epoch 934 | valid on 'valid' subset | loss 13.533 | nll_loss 13.088 | ppl 8708.3 | wps 39064.8 | wpb 510.9 | bsz 1 | num_updates 45451 | best_loss 8.725
2022-03-07 23:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 934 @ 45451 updates
2022-03-07 23:26:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 934 @ 45451 updates, score 13.533) (writing took 2.527444602921605 seconds)
2022-03-07 23:26:28 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)
2022-03-07 23:26:28 | INFO | train | epoch 934 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 23521.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 45451 | lr 0.00014833 | gnorm 0.321 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 118246
2022-03-07 23:26:28 | INFO | fairseq.trainer | begin training epoch 935
2022-03-07 23:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:28:31 | INFO | train_inner | epoch 935:     49 / 49 loss=1.573, nll_loss=0.218, ppl=1.16, wps=23876.5, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=45500, lr=0.00014825, gnorm=0.324, loss_scale=32, train_wall=230, gb_free=8.8, wall=118369
2022-03-07 23:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:28:36 | INFO | valid | epoch 935 | valid on 'valid' subset | loss 13.499 | nll_loss 13.051 | ppl 8485.08 | wps 42238.8 | wpb 510.9 | bsz 1 | num_updates 45500 | best_loss 8.725
2022-03-07 23:28:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 935 @ 45500 updates
2022-03-07 23:28:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 935 @ 45500 updates, score 13.499) (writing took 2.845462800003588 seconds)
2022-03-07 23:28:39 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)
2022-03-07 23:28:39 | INFO | train | epoch 935 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 24169.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45500 | lr 0.00014825 | gnorm 0.324 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 118377
2022-03-07 23:28:39 | INFO | fairseq.trainer | begin training epoch 936
2022-03-07 23:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:30:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:30:49 | INFO | valid | epoch 936 | valid on 'valid' subset | loss 13.482 | nll_loss 13.03 | ppl 8362.98 | wps 37640.2 | wpb 510.9 | bsz 1 | num_updates 45549 | best_loss 8.725
2022-03-07 23:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 936 @ 45549 updates
2022-03-07 23:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:30:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 936 @ 45549 updates, score 13.482) (writing took 2.6417705677449703 seconds)
2022-03-07 23:30:51 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)
2022-03-07 23:30:51 | INFO | train | epoch 936 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 24004.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45549 | lr 0.00014817 | gnorm 0.322 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 118510
2022-03-07 23:30:51 | INFO | fairseq.trainer | begin training epoch 937
2022-03-07 23:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:33:01 | INFO | valid | epoch 937 | valid on 'valid' subset | loss 13.543 | nll_loss 13.098 | ppl 8766.76 | wps 39868.7 | wpb 510.9 | bsz 1 | num_updates 45598 | best_loss 8.725
2022-03-07 23:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 937 @ 45598 updates
2022-03-07 23:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 937 @ 45598 updates, score 13.543) (writing took 2.6998287169262767 seconds)
2022-03-07 23:33:04 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)
2022-03-07 23:33:04 | INFO | train | epoch 937 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 23988.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45598 | lr 0.00014809 | gnorm 0.324 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 118642
2022-03-07 23:33:04 | INFO | fairseq.trainer | begin training epoch 938
2022-03-07 23:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:33:09 | INFO | train_inner | epoch 938:      2 / 49 loss=1.572, nll_loss=0.217, ppl=1.16, wps=23322.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=45600, lr=0.000148087, gnorm=0.323, loss_scale=64, train_wall=229, gb_free=8.8, wall=118647
2022-03-07 23:33:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:35:13 | INFO | valid | epoch 938 | valid on 'valid' subset | loss 13.451 | nll_loss 13.002 | ppl 8204.59 | wps 37685.6 | wpb 510.9 | bsz 1 | num_updates 45646 | best_loss 8.725
2022-03-07 23:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 938 @ 45646 updates
2022-03-07 23:35:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 938 @ 45646 updates, score 13.451) (writing took 2.9116872381418943 seconds)
2022-03-07 23:35:16 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)
2022-03-07 23:35:16 | INFO | train | epoch 938 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 23562.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 45646 | lr 0.000148013 | gnorm 0.323 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 118774
2022-03-07 23:35:16 | INFO | fairseq.trainer | begin training epoch 939
2022-03-07 23:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:37:25 | INFO | valid | epoch 939 | valid on 'valid' subset | loss 13.525 | nll_loss 13.079 | ppl 8652.33 | wps 45902.6 | wpb 510.9 | bsz 1 | num_updates 45695 | best_loss 8.725
2022-03-07 23:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 939 @ 45695 updates
2022-03-07 23:37:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:37:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:37:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 939 @ 45695 updates, score 13.525) (writing took 2.524854172952473 seconds)
2022-03-07 23:37:28 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)
2022-03-07 23:37:28 | INFO | train | epoch 939 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 24130.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45695 | lr 0.000147933 | gnorm 0.323 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 118906
2022-03-07 23:37:28 | INFO | fairseq.trainer | begin training epoch 940
2022-03-07 23:37:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:40 | INFO | train_inner | epoch 940:      5 / 49 loss=1.572, nll_loss=0.217, ppl=1.16, wps=23902.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=45700, lr=0.000147925, gnorm=0.323, loss_scale=32, train_wall=231, gb_free=8.8, wall=118919
2022-03-07 23:39:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:39:37 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 13.459 | nll_loss 13.006 | ppl 8228.73 | wps 38630.5 | wpb 510.9 | bsz 1 | num_updates 45744 | best_loss 8.725
2022-03-07 23:39:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 45744 updates
2022-03-07 23:39:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:39:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 940 @ 45744 updates, score 13.459) (writing took 2.6430499916896224 seconds)
2022-03-07 23:39:40 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)
2022-03-07 23:39:40 | INFO | train | epoch 940 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 24008.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45744 | lr 0.000147854 | gnorm 0.322 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 119038
2022-03-07 23:39:40 | INFO | fairseq.trainer | begin training epoch 941
2022-03-07 23:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:39:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:41:48 | INFO | valid | epoch 941 | valid on 'valid' subset | loss 13.491 | nll_loss 13.041 | ppl 8426.98 | wps 39601.3 | wpb 510.9 | bsz 1 | num_updates 45792 | best_loss 8.725
2022-03-07 23:41:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 941 @ 45792 updates
2022-03-07 23:41:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:41:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:41:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 941 @ 45792 updates, score 13.491) (writing took 2.5903427079319954 seconds)
2022-03-07 23:41:51 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)
2022-03-07 23:41:51 | INFO | train | epoch 941 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 23848.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 45792 | lr 0.000147776 | gnorm 0.319 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 119169
2022-03-07 23:41:51 | INFO | fairseq.trainer | begin training epoch 942
2022-03-07 23:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:42:11 | INFO | train_inner | epoch 942:      8 / 49 loss=1.572, nll_loss=0.217, ppl=1.16, wps=24014.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=45800, lr=0.000147764, gnorm=0.32, loss_scale=32, train_wall=229, gb_free=8.8, wall=119189
2022-03-07 23:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:43:58 | INFO | valid | epoch 942 | valid on 'valid' subset | loss 13.462 | nll_loss 13.013 | ppl 8268.97 | wps 45351.7 | wpb 510.9 | bsz 1 | num_updates 45841 | best_loss 8.725
2022-03-07 23:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 942 @ 45841 updates
2022-03-07 23:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 942 @ 45841 updates, score 13.462) (writing took 2.5330635886639357 seconds)
2022-03-07 23:44:01 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)
2022-03-07 23:44:01 | INFO | train | epoch 942 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 24425.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45841 | lr 0.000147697 | gnorm 0.324 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 119299
2022-03-07 23:44:01 | INFO | fairseq.trainer | begin training epoch 943
2022-03-07 23:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:09 | INFO | valid | epoch 943 | valid on 'valid' subset | loss 13.501 | nll_loss 13.05 | ppl 8482.84 | wps 41326.9 | wpb 510.9 | bsz 1 | num_updates 45889 | best_loss 8.725
2022-03-07 23:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 943 @ 45889 updates
2022-03-07 23:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 943 @ 45889 updates, score 13.501) (writing took 2.752749635837972 seconds)
2022-03-07 23:46:12 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)
2022-03-07 23:46:12 | INFO | train | epoch 943 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 23654.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 45889 | lr 0.00014762 | gnorm 0.322 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 119430
2022-03-07 23:46:12 | INFO | fairseq.trainer | begin training epoch 944
2022-03-07 23:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:40 | INFO | train_inner | epoch 944:     11 / 49 loss=1.572, nll_loss=0.217, ppl=1.16, wps=24054.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=45900, lr=0.000147602, gnorm=0.322, loss_scale=32, train_wall=230, gb_free=8.8, wall=119459
2022-03-07 23:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:48:19 | INFO | valid | epoch 944 | valid on 'valid' subset | loss 13.554 | nll_loss 13.113 | ppl 8860.31 | wps 45782.1 | wpb 510.9 | bsz 1 | num_updates 45938 | best_loss 8.725
2022-03-07 23:48:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 944 @ 45938 updates
2022-03-07 23:48:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 944 @ 45938 updates, score 13.554) (writing took 1.9724559085443616 seconds)
2022-03-07 23:48:21 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)
2022-03-07 23:48:21 | INFO | train | epoch 944 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 24596.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45938 | lr 0.000147541 | gnorm 0.319 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 119560
2022-03-07 23:48:21 | INFO | fairseq.trainer | begin training epoch 945
2022-03-07 23:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:50:24 | INFO | valid | epoch 945 | valid on 'valid' subset | loss 13.545 | nll_loss 13.1 | ppl 8777.46 | wps 46599.9 | wpb 510.9 | bsz 1 | num_updates 45987 | best_loss 8.725
2022-03-07 23:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 945 @ 45987 updates
2022-03-07 23:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:50:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 945 @ 45987 updates, score 13.545) (writing took 1.892953203059733 seconds)
2022-03-07 23:50:26 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)
2022-03-07 23:50:26 | INFO | train | epoch 945 | loss 1.572 | nll_loss 0.217 | ppl 1.16 | wps 25613.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45987 | lr 0.000147463 | gnorm 0.325 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119684
2022-03-07 23:50:26 | INFO | fairseq.trainer | begin training epoch 946
2022-03-07 23:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:57 | INFO | train_inner | epoch 946:     13 / 49 loss=1.572, nll_loss=0.217, ppl=1.16, wps=25244.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46000, lr=0.000147442, gnorm=0.322, loss_scale=32, train_wall=221, gb_free=8.8, wall=119715
2022-03-07 23:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:52:28 | INFO | valid | epoch 946 | valid on 'valid' subset | loss 13.487 | nll_loss 13.04 | ppl 8423.44 | wps 45545.9 | wpb 510.9 | bsz 1 | num_updates 46036 | best_loss 8.725
2022-03-07 23:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 946 @ 46036 updates
2022-03-07 23:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 946 @ 46036 updates, score 13.487) (writing took 1.864823279902339 seconds)
2022-03-07 23:52:30 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)
2022-03-07 23:52:30 | INFO | train | epoch 946 | loss 1.571 | nll_loss 0.217 | ppl 1.16 | wps 25540.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46036 | lr 0.000147384 | gnorm 0.321 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 119808
2022-03-07 23:52:30 | INFO | fairseq.trainer | begin training epoch 947
2022-03-07 23:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:53:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:54:32 | INFO | valid | epoch 947 | valid on 'valid' subset | loss 13.53 | nll_loss 13.085 | ppl 8690.18 | wps 47666.1 | wpb 510.9 | bsz 1 | num_updates 46084 | best_loss 8.725
2022-03-07 23:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 947 @ 46084 updates
2022-03-07 23:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 947 @ 46084 updates, score 13.53) (writing took 1.913130302913487 seconds)
2022-03-07 23:54:34 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)
2022-03-07 23:54:34 | INFO | train | epoch 947 | loss 1.571 | nll_loss 0.216 | ppl 1.16 | wps 25064.9 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 46084 | lr 0.000147308 | gnorm 0.321 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119932
2022-03-07 23:54:34 | INFO | fairseq.trainer | begin training epoch 948
2022-03-07 23:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:55:13 | INFO | train_inner | epoch 948:     16 / 49 loss=1.571, nll_loss=0.217, ppl=1.16, wps=25361.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46100, lr=0.000147282, gnorm=0.32, loss_scale=32, train_wall=220, gb_free=8.8, wall=119971
2022-03-07 23:56:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:56:36 | INFO | valid | epoch 948 | valid on 'valid' subset | loss 13.555 | nll_loss 13.111 | ppl 8848.94 | wps 47434.4 | wpb 510.9 | bsz 1 | num_updates 46133 | best_loss 8.725
2022-03-07 23:56:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 948 @ 46133 updates
2022-03-07 23:56:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:56:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:56:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 948 @ 46133 updates, score 13.555) (writing took 1.9170258156955242 seconds)
2022-03-07 23:56:38 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)
2022-03-07 23:56:38 | INFO | train | epoch 948 | loss 1.571 | nll_loss 0.216 | ppl 1.16 | wps 25615.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46133 | lr 0.000147229 | gnorm 0.319 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120056
2022-03-07 23:56:38 | INFO | fairseq.trainer | begin training epoch 949
2022-03-07 23:56:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:58:41 | INFO | valid | epoch 949 | valid on 'valid' subset | loss 13.494 | nll_loss 13.044 | ppl 8443.15 | wps 45864.5 | wpb 510.9 | bsz 1 | num_updates 46182 | best_loss 8.725
2022-03-07 23:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 949 @ 46182 updates
2022-03-07 23:58:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:58:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:58:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 949 @ 46182 updates, score 13.494) (writing took 1.9432874014601111 seconds)
2022-03-07 23:58:43 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)
2022-03-07 23:58:43 | INFO | train | epoch 949 | loss 1.571 | nll_loss 0.217 | ppl 1.16 | wps 25520.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46182 | lr 0.000147151 | gnorm 0.318 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 120181
2022-03-07 23:58:43 | INFO | fairseq.trainer | begin training epoch 950
2022-03-07 23:58:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:27 | INFO | train_inner | epoch 950:     18 / 49 loss=1.571, nll_loss=0.216, ppl=1.16, wps=25579.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46200, lr=0.000147122, gnorm=0.319, loss_scale=64, train_wall=218, gb_free=8.8, wall=120225
2022-03-08 00:00:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:00:45 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 13.471 | nll_loss 13.023 | ppl 8321.98 | wps 47226.3 | wpb 510.9 | bsz 1 | num_updates 46230 | best_loss 8.725
2022-03-08 00:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 46230 updates
2022-03-08 00:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 950 @ 46230 updates, score 13.471) (writing took 1.8874106081202626 seconds)
2022-03-08 00:00:47 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)
2022-03-08 00:00:47 | INFO | train | epoch 950 | loss 1.571 | nll_loss 0.216 | ppl 1.16 | wps 24991.5 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 46230 | lr 0.000147075 | gnorm 0.321 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120306
2022-03-08 00:00:47 | INFO | fairseq.trainer | begin training epoch 951
2022-03-08 00:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:02:50 | INFO | valid | epoch 951 | valid on 'valid' subset | loss 13.489 | nll_loss 13.043 | ppl 8441.14 | wps 46747.7 | wpb 510.9 | bsz 1 | num_updates 46279 | best_loss 8.725
2022-03-08 00:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 951 @ 46279 updates
2022-03-08 00:02:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:02:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 951 @ 46279 updates, score 13.489) (writing took 1.899142561480403 seconds)
2022-03-08 00:02:52 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)
2022-03-08 00:02:52 | INFO | train | epoch 951 | loss 1.571 | nll_loss 0.216 | ppl 1.16 | wps 25567.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46279 | lr 0.000146997 | gnorm 0.321 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120430
2022-03-08 00:02:52 | INFO | fairseq.trainer | begin training epoch 952
2022-03-08 00:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:03:43 | INFO | train_inner | epoch 952:     21 / 49 loss=1.571, nll_loss=0.216, ppl=1.16, wps=25343.8, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=46300, lr=0.000146964, gnorm=0.321, loss_scale=32, train_wall=220, gb_free=8.8, wall=120481
2022-03-08 00:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:04:54 | INFO | valid | epoch 952 | valid on 'valid' subset | loss 13.512 | nll_loss 13.063 | ppl 8556.82 | wps 47297.4 | wpb 510.9 | bsz 1 | num_updates 46328 | best_loss 8.725
2022-03-08 00:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 952 @ 46328 updates
2022-03-08 00:04:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 952 @ 46328 updates, score 13.512) (writing took 1.877315977588296 seconds)
2022-03-08 00:04:56 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)
2022-03-08 00:04:56 | INFO | train | epoch 952 | loss 1.571 | nll_loss 0.216 | ppl 1.16 | wps 25594.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46328 | lr 0.000146919 | gnorm 0.322 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120554
2022-03-08 00:04:56 | INFO | fairseq.trainer | begin training epoch 953
2022-03-08 00:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:06:58 | INFO | valid | epoch 953 | valid on 'valid' subset | loss 13.463 | nll_loss 13.014 | ppl 8270.19 | wps 45564.6 | wpb 510.9 | bsz 1 | num_updates 46376 | best_loss 8.725
2022-03-08 00:06:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 953 @ 46376 updates
2022-03-08 00:06:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:07:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 953 @ 46376 updates, score 13.463) (writing took 1.9140938585624099 seconds)
2022-03-08 00:07:00 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)
2022-03-08 00:07:00 | INFO | train | epoch 953 | loss 1.57 | nll_loss 0.216 | ppl 1.16 | wps 24987.2 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 46376 | lr 0.000146843 | gnorm 0.32 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120679
2022-03-08 00:07:00 | INFO | fairseq.trainer | begin training epoch 954
2022-03-08 00:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:07:59 | INFO | train_inner | epoch 954:     24 / 49 loss=1.57, nll_loss=0.216, ppl=1.16, wps=25339.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46400, lr=0.000146805, gnorm=0.321, loss_scale=32, train_wall=220, gb_free=8.8, wall=120737
2022-03-08 00:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:09:03 | INFO | valid | epoch 954 | valid on 'valid' subset | loss 13.516 | nll_loss 13.073 | ppl 8615.9 | wps 45305.3 | wpb 510.9 | bsz 1 | num_updates 46425 | best_loss 8.725
2022-03-08 00:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 954 @ 46425 updates
2022-03-08 00:09:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 954 @ 46425 updates, score 13.516) (writing took 1.8681092774495482 seconds)
2022-03-08 00:09:05 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)
2022-03-08 00:09:05 | INFO | train | epoch 954 | loss 1.57 | nll_loss 0.216 | ppl 1.16 | wps 25525 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46425 | lr 0.000146766 | gnorm 0.32 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120803
2022-03-08 00:09:05 | INFO | fairseq.trainer | begin training epoch 955
2022-03-08 00:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:11:07 | INFO | valid | epoch 955 | valid on 'valid' subset | loss 13.564 | nll_loss 13.122 | ppl 8916.84 | wps 47371.9 | wpb 510.9 | bsz 1 | num_updates 46474 | best_loss 8.725
2022-03-08 00:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 955 @ 46474 updates
2022-03-08 00:11:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 955 @ 46474 updates, score 13.564) (writing took 1.9142001373693347 seconds)
2022-03-08 00:11:09 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)
2022-03-08 00:11:09 | INFO | train | epoch 955 | loss 1.57 | nll_loss 0.216 | ppl 1.16 | wps 25547 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46474 | lr 0.000146688 | gnorm 0.319 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120927
2022-03-08 00:11:09 | INFO | fairseq.trainer | begin training epoch 956
2022-03-08 00:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:12:12 | INFO | train_inner | epoch 956:     26 / 49 loss=1.57, nll_loss=0.216, ppl=1.16, wps=25567.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=46500, lr=0.000146647, gnorm=0.318, loss_scale=32, train_wall=218, gb_free=8.8, wall=120991
2022-03-08 00:13:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:13:12 | INFO | valid | epoch 956 | valid on 'valid' subset | loss 13.582 | nll_loss 13.137 | ppl 9008.95 | wps 47385.4 | wpb 510.9 | bsz 1 | num_updates 46523 | best_loss 8.725
2022-03-08 00:13:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 956 @ 46523 updates
2022-03-08 00:13:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:13:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 956 @ 46523 updates, score 13.582) (writing took 1.8458123439922929 seconds)
2022-03-08 00:13:14 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)
2022-03-08 00:13:14 | INFO | train | epoch 956 | loss 1.57 | nll_loss 0.216 | ppl 1.16 | wps 25542.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46523 | lr 0.000146611 | gnorm 0.319 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 121052
2022-03-08 00:13:14 | INFO | fairseq.trainer | begin training epoch 957
2022-03-08 00:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:13:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:15:16 | INFO | valid | epoch 957 | valid on 'valid' subset | loss 13.466 | nll_loss 13.018 | ppl 8294.83 | wps 45531.9 | wpb 510.9 | bsz 1 | num_updates 46571 | best_loss 8.725
2022-03-08 00:15:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 957 @ 46571 updates
2022-03-08 00:15:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 957 @ 46571 updates, score 13.466) (writing took 1.9626875203102827 seconds)
2022-03-08 00:15:18 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)
2022-03-08 00:15:18 | INFO | train | epoch 957 | loss 1.57 | nll_loss 0.216 | ppl 1.16 | wps 24982.7 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 46571 | lr 0.000146535 | gnorm 0.321 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121176
2022-03-08 00:15:18 | INFO | fairseq.trainer | begin training epoch 958
2022-03-08 00:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:16:29 | INFO | train_inner | epoch 958:     29 / 49 loss=1.57, nll_loss=0.216, ppl=1.16, wps=25312.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=46600, lr=0.00014649, gnorm=0.321, loss_scale=32, train_wall=220, gb_free=8.8, wall=121247
2022-03-08 00:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:17:21 | INFO | valid | epoch 958 | valid on 'valid' subset | loss 13.57 | nll_loss 13.127 | ppl 8946.92 | wps 47514.6 | wpb 510.9 | bsz 1 | num_updates 46620 | best_loss 8.725
2022-03-08 00:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 958 @ 46620 updates
2022-03-08 00:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:17:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:17:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 958 @ 46620 updates, score 13.57) (writing took 1.8518480025231838 seconds)
2022-03-08 00:17:22 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)
2022-03-08 00:17:22 | INFO | train | epoch 958 | loss 1.57 | nll_loss 0.215 | ppl 1.16 | wps 25579.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46620 | lr 0.000146458 | gnorm 0.32 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121301
2022-03-08 00:17:22 | INFO | fairseq.trainer | begin training epoch 959
2022-03-08 00:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:19:25 | INFO | valid | epoch 959 | valid on 'valid' subset | loss 13.553 | nll_loss 13.108 | ppl 8826.99 | wps 46105.9 | wpb 510.9 | bsz 1 | num_updates 46669 | best_loss 8.725
2022-03-08 00:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 959 @ 46669 updates
2022-03-08 00:19:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 959 @ 46669 updates, score 13.553) (writing took 1.915958896279335 seconds)
2022-03-08 00:19:27 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)
2022-03-08 00:19:27 | INFO | train | epoch 959 | loss 1.57 | nll_loss 0.215 | ppl 1.16 | wps 25535.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46669 | lr 0.000146381 | gnorm 0.318 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 121425
2022-03-08 00:19:27 | INFO | fairseq.trainer | begin training epoch 960
2022-03-08 00:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:20:45 | INFO | train_inner | epoch 960:     32 / 49 loss=1.57, nll_loss=0.215, ppl=1.16, wps=25331.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46700, lr=0.000146333, gnorm=0.319, loss_scale=32, train_wall=220, gb_free=8.8, wall=121503
2022-03-08 00:21:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:21:31 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 13.52 | nll_loss 13.075 | ppl 8628.29 | wps 41465.6 | wpb 510.9 | bsz 1 | num_updates 46717 | best_loss 8.725
2022-03-08 00:21:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 46717 updates
2022-03-08 00:21:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:21:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 960 @ 46717 updates, score 13.52) (writing took 2.1529929731041193 seconds)
2022-03-08 00:21:33 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)
2022-03-08 00:21:33 | INFO | train | epoch 960 | loss 1.57 | nll_loss 0.215 | ppl 1.16 | wps 24671.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46717 | lr 0.000146306 | gnorm 0.32 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 121551
2022-03-08 00:21:33 | INFO | fairseq.trainer | begin training epoch 961
2022-03-08 00:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:23:36 | INFO | valid | epoch 961 | valid on 'valid' subset | loss 13.503 | nll_loss 13.055 | ppl 8511.29 | wps 46914.9 | wpb 510.9 | bsz 1 | num_updates 46766 | best_loss 8.725
2022-03-08 00:23:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 961 @ 46766 updates
2022-03-08 00:23:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:23:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 961 @ 46766 updates, score 13.503) (writing took 1.8297713678330183 seconds)
2022-03-08 00:23:38 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)
2022-03-08 00:23:38 | INFO | train | epoch 961 | loss 1.57 | nll_loss 0.216 | ppl 1.16 | wps 25540.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46766 | lr 0.000146229 | gnorm 0.322 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121676
2022-03-08 00:23:38 | INFO | fairseq.trainer | begin training epoch 962
2022-03-08 00:23:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:25:00 | INFO | train_inner | epoch 962:     34 / 49 loss=1.57, nll_loss=0.215, ppl=1.16, wps=25385.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=46800, lr=0.000146176, gnorm=0.321, loss_scale=64, train_wall=219, gb_free=8.8, wall=121759
2022-03-08 00:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:25:40 | INFO | valid | epoch 962 | valid on 'valid' subset | loss 13.617 | nll_loss 13.179 | ppl 9272.97 | wps 46413.4 | wpb 510.9 | bsz 1 | num_updates 46815 | best_loss 8.725
2022-03-08 00:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 962 @ 46815 updates
2022-03-08 00:25:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:25:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 962 @ 46815 updates, score 13.617) (writing took 2.5916579784825444 seconds)
2022-03-08 00:25:43 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)
2022-03-08 00:25:43 | INFO | train | epoch 962 | loss 1.57 | nll_loss 0.215 | ppl 1.16 | wps 25363.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46815 | lr 0.000146153 | gnorm 0.321 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 121801
2022-03-08 00:25:43 | INFO | fairseq.trainer | begin training epoch 963
2022-03-08 00:25:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:26:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:27:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:52 | INFO | valid | epoch 963 | valid on 'valid' subset | loss 13.469 | nll_loss 13.019 | ppl 8300.8 | wps 44116.9 | wpb 510.9 | bsz 1 | num_updates 46863 | best_loss 8.725
2022-03-08 00:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 963 @ 46863 updates
2022-03-08 00:27:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 963 @ 46863 updates, score 13.469) (writing took 2.81061515212059 seconds)
2022-03-08 00:27:54 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)
2022-03-08 00:27:54 | INFO | train | epoch 963 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 23651.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 46863 | lr 0.000146078 | gnorm 0.322 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 121933
2022-03-08 00:27:54 | INFO | fairseq.trainer | begin training epoch 964
2022-03-08 00:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:28 | INFO | train_inner | epoch 964:     37 / 49 loss=1.569, nll_loss=0.215, ppl=1.16, wps=24197, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=46900, lr=0.00014602, gnorm=0.321, loss_scale=32, train_wall=229, gb_free=8.8, wall=122027
2022-03-08 00:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:30:03 | INFO | valid | epoch 964 | valid on 'valid' subset | loss 13.538 | nll_loss 13.094 | ppl 8743.45 | wps 38010.1 | wpb 510.9 | bsz 1 | num_updates 46912 | best_loss 8.725
2022-03-08 00:30:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 964 @ 46912 updates
2022-03-08 00:30:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:30:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:30:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 964 @ 46912 updates, score 13.538) (writing took 2.5391792356967926 seconds)
2022-03-08 00:30:06 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)
2022-03-08 00:30:06 | INFO | train | epoch 964 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 24228.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 46912 | lr 0.000146002 | gnorm 0.318 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 122064
2022-03-08 00:30:06 | INFO | fairseq.trainer | begin training epoch 965
2022-03-08 00:30:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:32:16 | INFO | valid | epoch 965 | valid on 'valid' subset | loss 13.547 | nll_loss 13.104 | ppl 8804.58 | wps 38344.1 | wpb 510.9 | bsz 1 | num_updates 46961 | best_loss 8.725
2022-03-08 00:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 965 @ 46961 updates
2022-03-08 00:32:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:32:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 965 @ 46961 updates, score 13.547) (writing took 2.8389052655547857 seconds)
2022-03-08 00:32:18 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)
2022-03-08 00:32:18 | INFO | train | epoch 965 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 23914.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 46961 | lr 0.000145926 | gnorm 0.318 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 122197
2022-03-08 00:32:19 | INFO | fairseq.trainer | begin training epoch 966
2022-03-08 00:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:32:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:34:00 | INFO | train_inner | epoch 966:     40 / 49 loss=1.569, nll_loss=0.215, ppl=1.16, wps=23866.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=47000, lr=0.000145865, gnorm=0.319, loss_scale=32, train_wall=231, gb_free=8.8, wall=122298
2022-03-08 00:34:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:34:27 | INFO | valid | epoch 966 | valid on 'valid' subset | loss 13.596 | nll_loss 13.155 | ppl 9122.88 | wps 39454.5 | wpb 510.9 | bsz 1 | num_updates 47009 | best_loss 8.725
2022-03-08 00:34:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 966 @ 47009 updates
2022-03-08 00:34:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:34:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:34:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 966 @ 47009 updates, score 13.596) (writing took 2.6308814687654376 seconds)
2022-03-08 00:34:30 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)
2022-03-08 00:34:30 | INFO | train | epoch 966 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 23705 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47009 | lr 0.000145851 | gnorm 0.322 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 122328
2022-03-08 00:34:30 | INFO | fairseq.trainer | begin training epoch 967
2022-03-08 00:34:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:36:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:36:38 | INFO | valid | epoch 967 | valid on 'valid' subset | loss 13.523 | nll_loss 13.078 | ppl 8644.48 | wps 44640.5 | wpb 510.9 | bsz 1 | num_updates 47058 | best_loss 8.725
2022-03-08 00:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 967 @ 47058 updates
2022-03-08 00:36:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:36:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:36:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 967 @ 47058 updates, score 13.523) (writing took 2.8162224860861897 seconds)
2022-03-08 00:36:41 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)
2022-03-08 00:36:41 | INFO | train | epoch 967 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 24189.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 47058 | lr 0.000145775 | gnorm 0.322 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 122459
2022-03-08 00:36:41 | INFO | fairseq.trainer | begin training epoch 968
2022-03-08 00:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:38:28 | INFO | train_inner | epoch 968:     42 / 49 loss=1.569, nll_loss=0.215, ppl=1.16, wps=24266, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=47100, lr=0.00014571, gnorm=0.321, loss_scale=32, train_wall=227, gb_free=8.8, wall=122566
2022-03-08 00:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:38:50 | INFO | valid | epoch 968 | valid on 'valid' subset | loss 13.498 | nll_loss 13.055 | ppl 8508.51 | wps 39564.4 | wpb 510.9 | bsz 1 | num_updates 47107 | best_loss 8.725
2022-03-08 00:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 968 @ 47107 updates
2022-03-08 00:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:38:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 968 @ 47107 updates, score 13.498) (writing took 2.653809112496674 seconds)
2022-03-08 00:38:52 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)
2022-03-08 00:38:52 | INFO | train | epoch 968 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 24235.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 47107 | lr 0.000145699 | gnorm 0.319 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 122591
2022-03-08 00:38:52 | INFO | fairseq.trainer | begin training epoch 969
2022-03-08 00:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:38:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:41:03 | INFO | valid | epoch 969 | valid on 'valid' subset | loss 13.532 | nll_loss 13.084 | ppl 8683.97 | wps 39583.7 | wpb 510.9 | bsz 1 | num_updates 47155 | best_loss 8.725
2022-03-08 00:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 969 @ 47155 updates
2022-03-08 00:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 969 @ 47155 updates, score 13.532) (writing took 2.527414315380156 seconds)
2022-03-08 00:41:05 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)
2022-03-08 00:41:05 | INFO | train | epoch 969 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 23400.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 47155 | lr 0.000145625 | gnorm 0.318 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 122724
2022-03-08 00:41:05 | INFO | fairseq.trainer | begin training epoch 970
2022-03-08 00:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:43:17 | INFO | train_inner | epoch 970:     45 / 49 loss=1.569, nll_loss=0.215, ppl=1.16, wps=22373, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=47200, lr=0.000145556, gnorm=0.318, loss_scale=32, train_wall=246, gb_free=8.8, wall=122856
2022-03-08 00:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:43:34 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 13.491 | nll_loss 13.044 | ppl 8446.53 | wps 39873.9 | wpb 510.9 | bsz 1 | num_updates 47204 | best_loss 8.725
2022-03-08 00:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 47204 updates
2022-03-08 00:43:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:43:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 970 @ 47204 updates, score 13.491) (writing took 3.1228693164885044 seconds)
2022-03-08 00:43:37 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)
2022-03-08 00:43:37 | INFO | train | epoch 970 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 21003.8 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 47204 | lr 0.000145549 | gnorm 0.319 | loss_scale 32 | train_wall 128 | gb_free 8.8 | wall 122875
2022-03-08 00:43:37 | INFO | fairseq.trainer | begin training epoch 971
2022-03-08 00:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:45:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:45:52 | INFO | valid | epoch 971 | valid on 'valid' subset | loss 13.566 | nll_loss 13.126 | ppl 8938.58 | wps 47459.2 | wpb 510.9 | bsz 1 | num_updates 47252 | best_loss 8.725
2022-03-08 00:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 971 @ 47252 updates
2022-03-08 00:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:45:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:45:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 971 @ 47252 updates, score 13.566) (writing took 2.456471282057464 seconds)
2022-03-08 00:45:54 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)
2022-03-08 00:45:54 | INFO | train | epoch 971 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 22650.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 47252 | lr 0.000145476 | gnorm 0.319 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 123012
2022-03-08 00:45:54 | INFO | fairseq.trainer | begin training epoch 972
2022-03-08 00:45:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:47:53 | INFO | train_inner | epoch 972:     48 / 49 loss=1.569, nll_loss=0.215, ppl=1.16, wps=23586, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=47300, lr=0.000145402, gnorm=0.319, loss_scale=32, train_wall=234, gb_free=8.8, wall=123131
2022-03-08 00:47:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:47:59 | INFO | valid | epoch 972 | valid on 'valid' subset | loss 13.506 | nll_loss 13.059 | ppl 8534.1 | wps 39683.5 | wpb 510.9 | bsz 1 | num_updates 47301 | best_loss 8.725
2022-03-08 00:47:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 972 @ 47301 updates
2022-03-08 00:47:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:48:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:48:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 972 @ 47301 updates, score 13.506) (writing took 2.5671129738911986 seconds)
2022-03-08 00:48:02 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)
2022-03-08 00:48:02 | INFO | train | epoch 972 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 24837.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47301 | lr 0.0001454 | gnorm 0.318 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 123140
2022-03-08 00:48:02 | INFO | fairseq.trainer | begin training epoch 973
2022-03-08 00:48:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:50:06 | INFO | valid | epoch 973 | valid on 'valid' subset | loss 13.479 | nll_loss 13.035 | ppl 8395.34 | wps 47314 | wpb 510.9 | bsz 1 | num_updates 47350 | best_loss 8.725
2022-03-08 00:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 973 @ 47350 updates
2022-03-08 00:50:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:50:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 973 @ 47350 updates, score 13.479) (writing took 2.6772650545462966 seconds)
2022-03-08 00:50:09 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)
2022-03-08 00:50:09 | INFO | train | epoch 973 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 25025.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47350 | lr 0.000145325 | gnorm 0.32 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 123267
2022-03-08 00:50:09 | INFO | fairseq.trainer | begin training epoch 974
2022-03-08 00:50:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:52:21 | INFO | valid | epoch 974 | valid on 'valid' subset | loss 13.457 | nll_loss 13.008 | ppl 8237.27 | wps 47457.2 | wpb 510.9 | bsz 1 | num_updates 47399 | best_loss 8.725
2022-03-08 00:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 974 @ 47399 updates
2022-03-08 00:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:52:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 974 @ 47399 updates, score 13.457) (writing took 2.4643761683255434 seconds)
2022-03-08 00:52:23 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)
2022-03-08 00:52:23 | INFO | train | epoch 974 | loss 1.568 | nll_loss 0.215 | ppl 1.16 | wps 23629.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 47399 | lr 0.00014525 | gnorm 0.319 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 123402
2022-03-08 00:52:24 | INFO | fairseq.trainer | begin training epoch 975
2022-03-08 00:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:52:26 | INFO | train_inner | epoch 975:      1 / 49 loss=1.569, nll_loss=0.215, ppl=1.16, wps=23600.5, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=47400, lr=0.000145248, gnorm=0.321, loss_scale=64, train_wall=226, gb_free=8.8, wall=123404
2022-03-08 00:52:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:54:26 | INFO | valid | epoch 975 | valid on 'valid' subset | loss 13.495 | nll_loss 13.05 | ppl 8481.56 | wps 47860.5 | wpb 510.9 | bsz 1 | num_updates 47447 | best_loss 8.725
2022-03-08 00:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 975 @ 47447 updates
2022-03-08 00:54:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:54:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:54:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 975 @ 47447 updates, score 13.495) (writing took 2.0716296043246984 seconds)
2022-03-08 00:54:28 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)
2022-03-08 00:54:28 | INFO | train | epoch 975 | loss 1.568 | nll_loss 0.215 | ppl 1.16 | wps 24916.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47447 | lr 0.000145176 | gnorm 0.32 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123527
2022-03-08 00:54:28 | INFO | fairseq.trainer | begin training epoch 976
2022-03-08 00:54:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:56:30 | INFO | valid | epoch 976 | valid on 'valid' subset | loss 13.492 | nll_loss 13.045 | ppl 8452.4 | wps 47660.8 | wpb 510.9 | bsz 1 | num_updates 47496 | best_loss 8.725
2022-03-08 00:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 976 @ 47496 updates
2022-03-08 00:56:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:56:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 976 @ 47496 updates, score 13.492) (writing took 2.0265230238437653 seconds)
2022-03-08 00:56:33 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)
2022-03-08 00:56:33 | INFO | train | epoch 976 | loss 1.568 | nll_loss 0.214 | ppl 1.16 | wps 25607.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47496 | lr 0.000145101 | gnorm 0.316 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123651
2022-03-08 00:56:33 | INFO | fairseq.trainer | begin training epoch 977
2022-03-08 00:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:56:42 | INFO | train_inner | epoch 977:      4 / 49 loss=1.568, nll_loss=0.215, ppl=1.16, wps=25318.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=47500, lr=0.000145095, gnorm=0.318, loss_scale=32, train_wall=220, gb_free=8.8, wall=123660
2022-03-08 00:58:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:58:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:34 | INFO | valid | epoch 977 | valid on 'valid' subset | loss 13.508 | nll_loss 13.062 | ppl 8551.84 | wps 47121.8 | wpb 510.9 | bsz 1 | num_updates 47544 | best_loss 8.725
2022-03-08 00:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 977 @ 47544 updates
2022-03-08 00:58:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:58:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:58:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 977 @ 47544 updates, score 13.508) (writing took 2.1312105050310493 seconds)
2022-03-08 00:58:36 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)
2022-03-08 00:58:36 | INFO | train | epoch 977 | loss 1.568 | nll_loss 0.214 | ppl 1.16 | wps 25145.3 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 47544 | lr 0.000145028 | gnorm 0.319 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 123775
2022-03-08 00:58:36 | INFO | fairseq.trainer | begin training epoch 978
2022-03-08 00:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:00:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:00:38 | INFO | valid | epoch 978 | valid on 'valid' subset | loss 13.397 | nll_loss 12.943 | ppl 7875.24 | wps 47629.1 | wpb 510.9 | bsz 1 | num_updates 47593 | best_loss 8.725
2022-03-08 01:00:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 978 @ 47593 updates
2022-03-08 01:00:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:00:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 978 @ 47593 updates, score 13.397) (writing took 1.778613612987101 seconds)
2022-03-08 01:00:40 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)
2022-03-08 01:00:40 | INFO | train | epoch 978 | loss 1.569 | nll_loss 0.215 | ppl 1.16 | wps 25723.4 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 47593 | lr 0.000144953 | gnorm 0.321 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 123898
2022-03-08 01:00:40 | INFO | fairseq.trainer | begin training epoch 979
2022-03-08 01:00:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:00:57 | INFO | train_inner | epoch 979:      7 / 49 loss=1.568, nll_loss=0.215, ppl=1.16, wps=25483.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=47600, lr=0.000144943, gnorm=0.321, loss_scale=32, train_wall=219, gb_free=8.8, wall=123915
2022-03-08 01:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:02:42 | INFO | valid | epoch 979 | valid on 'valid' subset | loss 13.535 | nll_loss 13.087 | ppl 8703.04 | wps 47688.6 | wpb 510.9 | bsz 1 | num_updates 47642 | best_loss 8.725
2022-03-08 01:02:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 979 @ 47642 updates
2022-03-08 01:02:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 979 @ 47642 updates, score 13.535) (writing took 1.892993395216763 seconds)
2022-03-08 01:02:43 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)
2022-03-08 01:02:43 | INFO | train | epoch 979 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 25721.8 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 47642 | lr 0.000144879 | gnorm 0.32 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124022
2022-03-08 01:02:43 | INFO | fairseq.trainer | begin training epoch 980
2022-03-08 01:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:04:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:04:45 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 13.526 | nll_loss 13.082 | ppl 8672.51 | wps 47663.8 | wpb 510.9 | bsz 1 | num_updates 47691 | best_loss 8.725
2022-03-08 01:04:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 47691 updates
2022-03-08 01:04:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:04:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:04:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 980 @ 47691 updates, score 13.526) (writing took 2.0102431448176503 seconds)
2022-03-08 01:04:47 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)
2022-03-08 01:04:47 | INFO | train | epoch 980 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 25691 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 47691 | lr 0.000144804 | gnorm 0.318 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 124145
2022-03-08 01:04:47 | INFO | fairseq.trainer | begin training epoch 981
2022-03-08 01:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:05:09 | INFO | train_inner | epoch 981:      9 / 49 loss=1.567, nll_loss=0.214, ppl=1.16, wps=25733.2, ups=0.4, wpb=64871.8, bsz=126.7, num_updates=47700, lr=0.000144791, gnorm=0.318, loss_scale=64, train_wall=217, gb_free=8.8, wall=124167
2022-03-08 01:06:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:06:49 | INFO | valid | epoch 981 | valid on 'valid' subset | loss 13.397 | nll_loss 12.945 | ppl 7886.52 | wps 47404.5 | wpb 510.9 | bsz 1 | num_updates 47739 | best_loss 8.725
2022-03-08 01:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 981 @ 47739 updates
2022-03-08 01:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:06:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 981 @ 47739 updates, score 13.397) (writing took 1.9973467076197267 seconds)
2022-03-08 01:06:51 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)
2022-03-08 01:06:51 | INFO | train | epoch 981 | loss 1.568 | nll_loss 0.214 | ppl 1.16 | wps 25176.5 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 47739 | lr 0.000144732 | gnorm 0.317 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124269
2022-03-08 01:06:51 | INFO | fairseq.trainer | begin training epoch 982
2022-03-08 01:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:08:52 | INFO | valid | epoch 982 | valid on 'valid' subset | loss 13.45 | nll_loss 13 | ppl 8190.42 | wps 47576.7 | wpb 510.9 | bsz 1 | num_updates 47788 | best_loss 8.725
2022-03-08 01:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 982 @ 47788 updates
2022-03-08 01:08:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:08:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:08:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 982 @ 47788 updates, score 13.45) (writing took 1.9524971526116133 seconds)
2022-03-08 01:08:54 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)
2022-03-08 01:08:54 | INFO | train | epoch 982 | loss 1.568 | nll_loss 0.214 | ppl 1.16 | wps 25690.7 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 47788 | lr 0.000144657 | gnorm 0.32 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124393
2022-03-08 01:08:54 | INFO | fairseq.trainer | begin training epoch 983
2022-03-08 01:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:09:23 | INFO | train_inner | epoch 983:     12 / 49 loss=1.568, nll_loss=0.214, ppl=1.16, wps=25486.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=47800, lr=0.000144639, gnorm=0.319, loss_scale=32, train_wall=219, gb_free=8.8, wall=124422
2022-03-08 01:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:10:56 | INFO | valid | epoch 983 | valid on 'valid' subset | loss 13.536 | nll_loss 13.09 | ppl 8718.16 | wps 47663.5 | wpb 510.9 | bsz 1 | num_updates 47837 | best_loss 8.725
2022-03-08 01:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 983 @ 47837 updates
2022-03-08 01:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 983 @ 47837 updates, score 13.536) (writing took 2.0154828438535333 seconds)
2022-03-08 01:10:58 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)
2022-03-08 01:10:58 | INFO | train | epoch 983 | loss 1.568 | nll_loss 0.214 | ppl 1.16 | wps 25688.4 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 47837 | lr 0.000144583 | gnorm 0.318 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124516
2022-03-08 01:10:58 | INFO | fairseq.trainer | begin training epoch 984
2022-03-08 01:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:12:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:13:00 | INFO | valid | epoch 984 | valid on 'valid' subset | loss 13.553 | nll_loss 13.109 | ppl 8835.19 | wps 47809.2 | wpb 510.9 | bsz 1 | num_updates 47885 | best_loss 8.725
2022-03-08 01:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 984 @ 47885 updates
2022-03-08 01:13:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:13:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:13:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 984 @ 47885 updates, score 13.553) (writing took 1.9500750629231334 seconds)
2022-03-08 01:13:02 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)
2022-03-08 01:13:02 | INFO | train | epoch 984 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 25201.6 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 47885 | lr 0.000144511 | gnorm 0.321 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124640
2022-03-08 01:13:02 | INFO | fairseq.trainer | begin training epoch 985
2022-03-08 01:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:38 | INFO | train_inner | epoch 985:     15 / 49 loss=1.567, nll_loss=0.214, ppl=1.16, wps=25489.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=47900, lr=0.000144488, gnorm=0.319, loss_scale=32, train_wall=219, gb_free=8.8, wall=124676
2022-03-08 01:14:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:15:03 | INFO | valid | epoch 985 | valid on 'valid' subset | loss 13.544 | nll_loss 13.099 | ppl 8775.16 | wps 47539.9 | wpb 510.9 | bsz 1 | num_updates 47934 | best_loss 8.725
2022-03-08 01:15:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 985 @ 47934 updates
2022-03-08 01:15:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:15:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:15:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 985 @ 47934 updates, score 13.544) (writing took 1.9771285904571414 seconds)
2022-03-08 01:15:05 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)
2022-03-08 01:15:05 | INFO | train | epoch 985 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 25689.8 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 47934 | lr 0.000144437 | gnorm 0.317 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124764
2022-03-08 01:15:05 | INFO | fairseq.trainer | begin training epoch 986
2022-03-08 01:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:12 | INFO | valid | epoch 986 | valid on 'valid' subset | loss 13.531 | nll_loss 13.089 | ppl 8710.67 | wps 40061.3 | wpb 510.9 | bsz 1 | num_updates 47983 | best_loss 8.725
2022-03-08 01:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 986 @ 47983 updates
2022-03-08 01:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:17:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:17:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 986 @ 47983 updates, score 13.531) (writing took 2.5561421187594533 seconds)
2022-03-08 01:17:14 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)
2022-03-08 01:17:14 | INFO | train | epoch 986 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 24613.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47983 | lr 0.000144363 | gnorm 0.316 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 124893
2022-03-08 01:17:14 | INFO | fairseq.trainer | begin training epoch 987
2022-03-08 01:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:17:57 | INFO | train_inner | epoch 987:     17 / 49 loss=1.567, nll_loss=0.214, ppl=1.16, wps=24996.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48000, lr=0.000144338, gnorm=0.316, loss_scale=64, train_wall=222, gb_free=8.8, wall=124936
2022-03-08 01:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:19:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:19:23 | INFO | valid | epoch 987 | valid on 'valid' subset | loss 13.476 | nll_loss 13.031 | ppl 8371.23 | wps 39767.3 | wpb 510.9 | bsz 1 | num_updates 48031 | best_loss 8.725
2022-03-08 01:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 987 @ 48031 updates
2022-03-08 01:19:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:19:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:19:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 987 @ 48031 updates, score 13.476) (writing took 2.586805457249284 seconds)
2022-03-08 01:19:25 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)
2022-03-08 01:19:25 | INFO | train | epoch 987 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 23798.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 48031 | lr 0.000144291 | gnorm 0.318 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 125023
2022-03-08 01:19:25 | INFO | fairseq.trainer | begin training epoch 988
2022-03-08 01:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:21:34 | INFO | valid | epoch 988 | valid on 'valid' subset | loss 13.557 | nll_loss 13.113 | ppl 8859.31 | wps 39130.7 | wpb 510.9 | bsz 1 | num_updates 48080 | best_loss 8.725
2022-03-08 01:21:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 988 @ 48080 updates
2022-03-08 01:21:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 988 @ 48080 updates, score 13.557) (writing took 2.41894843056798 seconds)
2022-03-08 01:21:36 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)
2022-03-08 01:21:36 | INFO | train | epoch 988 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 24232 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 48080 | lr 0.000144217 | gnorm 0.318 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 125155
2022-03-08 01:21:36 | INFO | fairseq.trainer | begin training epoch 989
2022-03-08 01:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:22:27 | INFO | train_inner | epoch 989:     20 / 49 loss=1.567, nll_loss=0.214, ppl=1.16, wps=24053.1, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=48100, lr=0.000144187, gnorm=0.319, loss_scale=32, train_wall=230, gb_free=8.8, wall=125205
2022-03-08 01:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:23:45 | INFO | valid | epoch 989 | valid on 'valid' subset | loss 13.459 | nll_loss 13.011 | ppl 8254.44 | wps 40177.8 | wpb 510.9 | bsz 1 | num_updates 48129 | best_loss 8.725
2022-03-08 01:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 989 @ 48129 updates
2022-03-08 01:23:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:23:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:23:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 989 @ 48129 updates, score 13.459) (writing took 2.631909392774105 seconds)
2022-03-08 01:23:48 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)
2022-03-08 01:23:48 | INFO | train | epoch 989 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 24216.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 48129 | lr 0.000144144 | gnorm 0.318 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 125286
2022-03-08 01:23:48 | INFO | fairseq.trainer | begin training epoch 990
2022-03-08 01:23:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:24:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:25:56 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 13.594 | nll_loss 13.152 | ppl 9105.21 | wps 39920 | wpb 510.9 | bsz 1 | num_updates 48177 | best_loss 8.725
2022-03-08 01:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 48177 updates
2022-03-08 01:25:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:25:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:25:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 990 @ 48177 updates, score 13.594) (writing took 2.5414703330025077 seconds)
2022-03-08 01:25:59 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)
2022-03-08 01:25:59 | INFO | train | epoch 990 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 23764.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 48177 | lr 0.000144072 | gnorm 0.317 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 125417
2022-03-08 01:25:59 | INFO | fairseq.trainer | begin training epoch 991
2022-03-08 01:25:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:26:57 | INFO | train_inner | epoch 991:     23 / 49 loss=1.567, nll_loss=0.214, ppl=1.16, wps=24050.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=48200, lr=0.000144038, gnorm=0.317, loss_scale=32, train_wall=229, gb_free=8.8, wall=125475
2022-03-08 01:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:28:07 | INFO | valid | epoch 991 | valid on 'valid' subset | loss 13.503 | nll_loss 13.055 | ppl 8510.16 | wps 40641.6 | wpb 510.9 | bsz 1 | num_updates 48226 | best_loss 8.725
2022-03-08 01:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 991 @ 48226 updates
2022-03-08 01:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:28:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 991 @ 48226 updates, score 13.503) (writing took 2.6795826349407434 seconds)
2022-03-08 01:28:10 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)
2022-03-08 01:28:10 | INFO | train | epoch 991 | loss 1.567 | nll_loss 0.214 | ppl 1.16 | wps 24257.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 48226 | lr 0.000143999 | gnorm 0.319 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 125548
2022-03-08 01:28:10 | INFO | fairseq.trainer | begin training epoch 992
2022-03-08 01:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:30:19 | INFO | valid | epoch 992 | valid on 'valid' subset | loss 13.483 | nll_loss 13.034 | ppl 8386.89 | wps 39946.5 | wpb 510.9 | bsz 1 | num_updates 48275 | best_loss 8.725
2022-03-08 01:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 992 @ 48275 updates
2022-03-08 01:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 992 @ 48275 updates, score 13.483) (writing took 2.501380769535899 seconds)
2022-03-08 01:30:21 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)
2022-03-08 01:30:21 | INFO | train | epoch 992 | loss 1.567 | nll_loss 0.213 | ppl 1.16 | wps 24174.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 48275 | lr 0.000143926 | gnorm 0.319 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 125679
2022-03-08 01:30:21 | INFO | fairseq.trainer | begin training epoch 993
2022-03-08 01:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:30:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:31:27 | INFO | train_inner | epoch 993:     26 / 49 loss=1.566, nll_loss=0.213, ppl=1.16, wps=24012.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=48300, lr=0.000143889, gnorm=0.318, loss_scale=32, train_wall=230, gb_free=8.8, wall=125745
2022-03-08 01:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:32:30 | INFO | valid | epoch 993 | valid on 'valid' subset | loss 13.494 | nll_loss 13.047 | ppl 8463.92 | wps 39435.4 | wpb 510.9 | bsz 1 | num_updates 48323 | best_loss 8.725
2022-03-08 01:32:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 993 @ 48323 updates
2022-03-08 01:32:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:32:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 993 @ 48323 updates, score 13.494) (writing took 2.7099684718996286 seconds)
2022-03-08 01:32:33 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)
2022-03-08 01:32:33 | INFO | train | epoch 993 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 23666 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 48323 | lr 0.000143854 | gnorm 0.314 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 125811
2022-03-08 01:32:33 | INFO | fairseq.trainer | begin training epoch 994
2022-03-08 01:32:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:34:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:42 | INFO | valid | epoch 994 | valid on 'valid' subset | loss 13.536 | nll_loss 13.096 | ppl 8753.09 | wps 39408.4 | wpb 510.9 | bsz 1 | num_updates 48372 | best_loss 8.725
2022-03-08 01:34:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 994 @ 48372 updates
2022-03-08 01:34:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:34:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:34:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 994 @ 48372 updates, score 13.536) (writing took 2.6634964114055037 seconds)
2022-03-08 01:34:44 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)
2022-03-08 01:34:44 | INFO | train | epoch 994 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 24157 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 48372 | lr 0.000143781 | gnorm 0.316 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 125942
2022-03-08 01:34:44 | INFO | fairseq.trainer | begin training epoch 995
2022-03-08 01:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:35:55 | INFO | train_inner | epoch 995:     28 / 49 loss=1.566, nll_loss=0.213, ppl=1.16, wps=24170.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=48400, lr=0.00014374, gnorm=0.315, loss_scale=32, train_wall=228, gb_free=8.8, wall=126014
2022-03-08 01:36:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:53 | INFO | valid | epoch 995 | valid on 'valid' subset | loss 13.571 | nll_loss 13.129 | ppl 8959.38 | wps 39884.4 | wpb 510.9 | bsz 1 | num_updates 48421 | best_loss 8.725
2022-03-08 01:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 995 @ 48421 updates
2022-03-08 01:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:36:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:36:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 995 @ 48421 updates, score 13.571) (writing took 2.669036596082151 seconds)
2022-03-08 01:36:56 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)
2022-03-08 01:36:56 | INFO | train | epoch 995 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 24144 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 48421 | lr 0.000143709 | gnorm 0.315 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 126074
2022-03-08 01:36:56 | INFO | fairseq.trainer | begin training epoch 996
2022-03-08 01:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:37:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:04 | INFO | valid | epoch 996 | valid on 'valid' subset | loss 13.494 | nll_loss 13.049 | ppl 8475.35 | wps 39782.1 | wpb 510.9 | bsz 1 | num_updates 48469 | best_loss 8.725
2022-03-08 01:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 996 @ 48469 updates
2022-03-08 01:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:39:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 996 @ 48469 updates, score 13.494) (writing took 2.6675293082371354 seconds)
2022-03-08 01:39:07 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)
2022-03-08 01:39:07 | INFO | train | epoch 996 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 23757.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 48469 | lr 0.000143638 | gnorm 0.316 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 126205
2022-03-08 01:39:07 | INFO | fairseq.trainer | begin training epoch 997
2022-03-08 01:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:40:25 | INFO | train_inner | epoch 997:     31 / 49 loss=1.566, nll_loss=0.213, ppl=1.16, wps=24092.9, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=48500, lr=0.000143592, gnorm=0.316, loss_scale=32, train_wall=229, gb_free=8.8, wall=126283
2022-03-08 01:41:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:41:11 | INFO | valid | epoch 997 | valid on 'valid' subset | loss 13.45 | nll_loss 13.001 | ppl 8199.16 | wps 47900.6 | wpb 510.9 | bsz 1 | num_updates 48518 | best_loss 8.725
2022-03-08 01:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 997 @ 48518 updates
2022-03-08 01:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 997 @ 48518 updates, score 13.45) (writing took 1.9278879538178444 seconds)
2022-03-08 01:41:13 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)
2022-03-08 01:41:13 | INFO | train | epoch 997 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 25109.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48518 | lr 0.000143565 | gnorm 0.319 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 126332
2022-03-08 01:41:13 | INFO | fairseq.trainer | begin training epoch 998
2022-03-08 01:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:15 | INFO | valid | epoch 998 | valid on 'valid' subset | loss 13.525 | nll_loss 13.081 | ppl 8663.52 | wps 47636.6 | wpb 510.9 | bsz 1 | num_updates 48567 | best_loss 8.725
2022-03-08 01:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 998 @ 48567 updates
2022-03-08 01:43:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:43:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:43:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 998 @ 48567 updates, score 13.525) (writing took 1.8478247290477157 seconds)
2022-03-08 01:43:17 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)
2022-03-08 01:43:17 | INFO | train | epoch 998 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 25736.9 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 48567 | lr 0.000143493 | gnorm 0.317 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 126455
2022-03-08 01:43:17 | INFO | fairseq.trainer | begin training epoch 999
2022-03-08 01:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:43:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:44:39 | INFO | train_inner | epoch 999:     34 / 49 loss=1.566, nll_loss=0.213, ppl=1.16, wps=25525.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=48600, lr=0.000143444, gnorm=0.318, loss_scale=32, train_wall=219, gb_free=8.8, wall=126537
2022-03-08 01:45:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:45:18 | INFO | valid | epoch 999 | valid on 'valid' subset | loss 13.582 | nll_loss 13.14 | ppl 9025.74 | wps 47681.1 | wpb 510.9 | bsz 1 | num_updates 48615 | best_loss 8.725
2022-03-08 01:45:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 999 @ 48615 updates
2022-03-08 01:45:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:45:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 999 @ 48615 updates, score 13.582) (writing took 1.9748054705560207 seconds)
2022-03-08 01:45:20 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)
2022-03-08 01:45:20 | INFO | train | epoch 999 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 25188.3 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 48615 | lr 0.000143422 | gnorm 0.319 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 126579
2022-03-08 01:45:20 | INFO | fairseq.trainer | begin training epoch 1000
2022-03-08 01:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:47:22 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 13.559 | nll_loss 13.117 | ppl 8885.46 | wps 47778.2 | wpb 510.9 | bsz 1 | num_updates 48664 | best_loss 8.725
2022-03-08 01:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 48664 updates
2022-03-08 01:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:47:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1000 @ 48664 updates, score 13.559) (writing took 1.9427286442369223 seconds)
2022-03-08 01:47:24 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)
2022-03-08 01:47:24 | INFO | train | epoch 1000 | loss 1.566 | nll_loss 0.213 | ppl 1.16 | wps 25715.9 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 48664 | lr 0.000143349 | gnorm 0.319 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 126702
2022-03-08 01:47:24 | INFO | fairseq.trainer | begin training epoch 1001
2022-03-08 01:47:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:48:51 | INFO | train_inner | epoch 1001:     36 / 49 loss=1.566, nll_loss=0.213, ppl=1.16, wps=25731.4, ups=0.4, wpb=64867.4, bsz=126.7, num_updates=48700, lr=0.000143296, gnorm=0.318, loss_scale=32, train_wall=217, gb_free=8.8, wall=126789
2022-03-08 01:49:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:49:26 | INFO | valid | epoch 1001 | valid on 'valid' subset | loss 13.528 | nll_loss 13.085 | ppl 8688.79 | wps 47571.6 | wpb 510.9 | bsz 1 | num_updates 48713 | best_loss 8.725
2022-03-08 01:49:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1001 @ 48713 updates
2022-03-08 01:49:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:49:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1001 @ 48713 updates, score 13.528) (writing took 1.9947198694571853 seconds)
2022-03-08 01:49:28 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)
2022-03-08 01:49:28 | INFO | train | epoch 1001 | loss 1.565 | nll_loss 0.213 | ppl 1.16 | wps 25685.5 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 48713 | lr 0.000143277 | gnorm 0.315 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 126826
2022-03-08 01:49:28 | INFO | fairseq.trainer | begin training epoch 1002
2022-03-08 01:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:49:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:51:29 | INFO | valid | epoch 1002 | valid on 'valid' subset | loss 13.544 | nll_loss 13.098 | ppl 8770.5 | wps 47643.1 | wpb 510.9 | bsz 1 | num_updates 48761 | best_loss 8.725
2022-03-08 01:51:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1002 @ 48761 updates
2022-03-08 01:51:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1002 @ 48761 updates, score 13.544) (writing took 1.9467095509171486 seconds)
2022-03-08 01:51:31 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)
2022-03-08 01:51:31 | INFO | train | epoch 1002 | loss 1.565 | nll_loss 0.213 | ppl 1.16 | wps 25176.6 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 48761 | lr 0.000143207 | gnorm 0.32 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 126950
2022-03-08 01:51:31 | INFO | fairseq.trainer | begin training epoch 1003
2022-03-08 01:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:53:05 | INFO | train_inner | epoch 1003:     39 / 49 loss=1.565, nll_loss=0.213, ppl=1.16, wps=25489.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48800, lr=0.00014315, gnorm=0.319, loss_scale=32, train_wall=219, gb_free=8.8, wall=127044
2022-03-08 01:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:53:33 | INFO | valid | epoch 1003 | valid on 'valid' subset | loss 13.639 | nll_loss 13.2 | ppl 9410.4 | wps 47534 | wpb 510.9 | bsz 1 | num_updates 48810 | best_loss 8.725
2022-03-08 01:53:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1003 @ 48810 updates
2022-03-08 01:53:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1003 @ 48810 updates, score 13.639) (writing took 1.971581150777638 seconds)
2022-03-08 01:53:35 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)
2022-03-08 01:53:35 | INFO | train | epoch 1003 | loss 1.565 | nll_loss 0.213 | ppl 1.16 | wps 25706.3 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 48810 | lr 0.000143135 | gnorm 0.317 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 127073
2022-03-08 01:53:35 | INFO | fairseq.trainer | begin training epoch 1004
2022-03-08 01:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:55:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:55:37 | INFO | valid | epoch 1004 | valid on 'valid' subset | loss 13.51 | nll_loss 13.064 | ppl 8565.75 | wps 47473.8 | wpb 510.9 | bsz 1 | num_updates 48858 | best_loss 8.725
2022-03-08 01:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1004 @ 48858 updates
2022-03-08 01:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1004 @ 48858 updates, score 13.51) (writing took 1.950471485964954 seconds)
2022-03-08 01:55:39 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)
2022-03-08 01:55:39 | INFO | train | epoch 1004 | loss 1.565 | nll_loss 0.213 | ppl 1.16 | wps 25158.5 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 48858 | lr 0.000143065 | gnorm 0.318 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 127197
2022-03-08 01:55:39 | INFO | fairseq.trainer | begin training epoch 1005
2022-03-08 01:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:57:20 | INFO | train_inner | epoch 1005:     42 / 49 loss=1.565, nll_loss=0.213, ppl=1.16, wps=25475.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48900, lr=0.000143003, gnorm=0.318, loss_scale=32, train_wall=219, gb_free=8.8, wall=127298
2022-03-08 01:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:57:40 | INFO | valid | epoch 1005 | valid on 'valid' subset | loss 13.533 | nll_loss 13.091 | ppl 8725.14 | wps 47479.7 | wpb 510.9 | bsz 1 | num_updates 48907 | best_loss 8.725
2022-03-08 01:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1005 @ 48907 updates
2022-03-08 01:57:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1005 @ 48907 updates, score 13.533) (writing took 1.9769226629287004 seconds)
2022-03-08 01:57:42 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)
2022-03-08 01:57:42 | INFO | train | epoch 1005 | loss 1.565 | nll_loss 0.212 | ppl 1.16 | wps 25688.4 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 48907 | lr 0.000142993 | gnorm 0.32 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 127321
2022-03-08 01:57:42 | INFO | fairseq.trainer | begin training epoch 1006
2022-03-08 01:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:59:44 | INFO | valid | epoch 1006 | valid on 'valid' subset | loss 13.578 | nll_loss 13.138 | ppl 9013.93 | wps 47324.5 | wpb 510.9 | bsz 1 | num_updates 48956 | best_loss 8.725
2022-03-08 01:59:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1006 @ 48956 updates
2022-03-08 01:59:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:59:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:59:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1006 @ 48956 updates, score 13.578) (writing took 1.9657956380397081 seconds)
2022-03-08 01:59:46 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)
2022-03-08 01:59:46 | INFO | train | epoch 1006 | loss 1.565 | nll_loss 0.212 | ppl 1.16 | wps 25682.5 | ups 0.4 | wpb 64858.2 | bsz 126.7 | num_updates 48956 | lr 0.000142921 | gnorm 0.314 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 127444
2022-03-08 01:59:46 | INFO | fairseq.trainer | begin training epoch 1007
2022-03-08 01:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:01:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:01:35 | INFO | train_inner | epoch 1007:     45 / 49 loss=1.565, nll_loss=0.213, ppl=1.16, wps=25432.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49000, lr=0.000142857, gnorm=0.316, loss_scale=32, train_wall=219, gb_free=8.8, wall=127553
2022-03-08 02:01:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:01:49 | INFO | valid | epoch 1007 | valid on 'valid' subset | loss 13.561 | nll_loss 13.119 | ppl 8893.7 | wps 45783.9 | wpb 510.9 | bsz 1 | num_updates 49004 | best_loss 8.725
2022-03-08 02:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1007 @ 49004 updates
2022-03-08 02:01:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:01:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:01:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1007 @ 49004 updates, score 13.561) (writing took 1.9874208373948932 seconds)
2022-03-08 02:01:51 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)
2022-03-08 02:01:51 | INFO | train | epoch 1007 | loss 1.565 | nll_loss 0.213 | ppl 1.16 | wps 25032.8 | ups 0.39 | wpb 64844.1 | bsz 126.7 | num_updates 49004 | lr 0.000142851 | gnorm 0.319 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127569
2022-03-08 02:01:51 | INFO | fairseq.trainer | begin training epoch 1008
2022-03-08 02:01:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:55 | INFO | valid | epoch 1008 | valid on 'valid' subset | loss 13.548 | nll_loss 13.105 | ppl 8811.42 | wps 45894 | wpb 510.9 | bsz 1 | num_updates 49053 | best_loss 8.725
2022-03-08 02:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1008 @ 49053 updates
2022-03-08 02:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:03:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:03:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1008 @ 49053 updates, score 13.548) (writing took 1.805001682601869 seconds)
2022-03-08 02:03:56 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)
2022-03-08 02:03:56 | INFO | train | epoch 1008 | loss 1.565 | nll_loss 0.213 | ppl 1.16 | wps 25248.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49053 | lr 0.00014278 | gnorm 0.319 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 127695
2022-03-08 02:03:56 | INFO | fairseq.trainer | begin training epoch 1009
2022-03-08 02:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:05:51 | INFO | train_inner | epoch 1009:     47 / 49 loss=1.565, nll_loss=0.213, ppl=1.16, wps=25315.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49100, lr=0.000142712, gnorm=0.318, loss_scale=32, train_wall=220, gb_free=8.8, wall=127810
2022-03-08 02:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:06:00 | INFO | valid | epoch 1009 | valid on 'valid' subset | loss 13.51 | nll_loss 13.064 | ppl 8561.2 | wps 45925.4 | wpb 510.9 | bsz 1 | num_updates 49102 | best_loss 8.725
2022-03-08 02:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1009 @ 49102 updates
2022-03-08 02:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:06:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1009 @ 49102 updates, score 13.51) (writing took 1.8667041882872581 seconds)
2022-03-08 02:06:02 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)
2022-03-08 02:06:02 | INFO | train | epoch 1009 | loss 1.565 | nll_loss 0.212 | ppl 1.16 | wps 25341.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49102 | lr 0.000142709 | gnorm 0.317 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 127820
2022-03-08 02:06:02 | INFO | fairseq.trainer | begin training epoch 1010
2022-03-08 02:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:08:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:05 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 13.562 | nll_loss 13.119 | ppl 8894.86 | wps 45956.9 | wpb 510.9 | bsz 1 | num_updates 49150 | best_loss 8.725
2022-03-08 02:08:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 49150 updates
2022-03-08 02:08:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:08:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:08:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1010 @ 49150 updates, score 13.562) (writing took 1.7581614758819342 seconds)
2022-03-08 02:08:07 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)
2022-03-08 02:08:07 | INFO | train | epoch 1010 | loss 1.565 | nll_loss 0.213 | ppl 1.16 | wps 24859.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49150 | lr 0.000142639 | gnorm 0.317 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127945
2022-03-08 02:08:07 | INFO | fairseq.trainer | begin training epoch 1011
2022-03-08 02:08:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:10:10 | INFO | valid | epoch 1011 | valid on 'valid' subset | loss 13.536 | nll_loss 13.091 | ppl 8727.71 | wps 45878.1 | wpb 510.9 | bsz 1 | num_updates 49199 | best_loss 8.725
2022-03-08 02:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1011 @ 49199 updates
2022-03-08 02:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:10:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1011 @ 49199 updates, score 13.536) (writing took 1.799467139877379 seconds)
2022-03-08 02:10:12 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)
2022-03-08 02:10:12 | INFO | train | epoch 1011 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 25371.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49199 | lr 0.000142568 | gnorm 0.315 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128070
2022-03-08 02:10:12 | INFO | fairseq.trainer | begin training epoch 1012
2022-03-08 02:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:10:15 | INFO | train_inner | epoch 1012:      1 / 49 loss=1.565, nll_loss=0.212, ppl=1.16, wps=24506, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=49200, lr=0.000142566, gnorm=0.317, loss_scale=32, train_wall=221, gb_free=8.8, wall=128073
2022-03-08 02:12:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:12:16 | INFO | valid | epoch 1012 | valid on 'valid' subset | loss 13.507 | nll_loss 13.064 | ppl 8562.25 | wps 44553.1 | wpb 510.9 | bsz 1 | num_updates 49248 | best_loss 8.725
2022-03-08 02:12:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1012 @ 49248 updates
2022-03-08 02:12:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:12:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1012 @ 49248 updates, score 13.507) (writing took 1.8340587262064219 seconds)
2022-03-08 02:12:18 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)
2022-03-08 02:12:18 | INFO | train | epoch 1012 | loss 1.565 | nll_loss 0.212 | ppl 1.16 | wps 25251.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49248 | lr 0.000142497 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128196
2022-03-08 02:12:18 | INFO | fairseq.trainer | begin training epoch 1013
2022-03-08 02:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:13:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:14:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:14:22 | INFO | valid | epoch 1013 | valid on 'valid' subset | loss 13.592 | nll_loss 13.154 | ppl 9112.36 | wps 45784 | wpb 510.9 | bsz 1 | num_updates 49296 | best_loss 8.725
2022-03-08 02:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1013 @ 49296 updates
2022-03-08 02:14:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:14:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:14:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1013 @ 49296 updates, score 13.592) (writing took 1.7928260397166014 seconds)
2022-03-08 02:14:24 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)
2022-03-08 02:14:24 | INFO | train | epoch 1013 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 24772.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49296 | lr 0.000142428 | gnorm 0.313 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128322
2022-03-08 02:14:24 | INFO | fairseq.trainer | begin training epoch 1014
2022-03-08 02:14:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:14:34 | INFO | train_inner | epoch 1014:      4 / 49 loss=1.564, nll_loss=0.212, ppl=1.16, wps=25056.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49300, lr=0.000142422, gnorm=0.315, loss_scale=32, train_wall=222, gb_free=8.8, wall=128332
2022-03-08 02:16:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:16:29 | INFO | valid | epoch 1014 | valid on 'valid' subset | loss 13.54 | nll_loss 13.096 | ppl 8757.84 | wps 44558.1 | wpb 510.9 | bsz 1 | num_updates 49345 | best_loss 8.725
2022-03-08 02:16:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1014 @ 49345 updates
2022-03-08 02:16:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:16:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:16:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1014 @ 49345 updates, score 13.54) (writing took 1.7672895528376102 seconds)
2022-03-08 02:16:31 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)
2022-03-08 02:16:31 | INFO | train | epoch 1014 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 25070.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49345 | lr 0.000142357 | gnorm 0.312 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128449
2022-03-08 02:16:31 | INFO | fairseq.trainer | begin training epoch 1015
2022-03-08 02:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:18:35 | INFO | valid | epoch 1015 | valid on 'valid' subset | loss 13.554 | nll_loss 13.113 | ppl 8860.87 | wps 43909.5 | wpb 510.9 | bsz 1 | num_updates 49394 | best_loss 8.725
2022-03-08 02:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1015 @ 49394 updates
2022-03-08 02:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:18:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1015 @ 49394 updates, score 13.554) (writing took 1.782109823077917 seconds)
2022-03-08 02:18:37 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)
2022-03-08 02:18:37 | INFO | train | epoch 1015 | loss 1.565 | nll_loss 0.212 | ppl 1.16 | wps 25216.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49394 | lr 0.000142286 | gnorm 0.317 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128575
2022-03-08 02:18:37 | INFO | fairseq.trainer | begin training epoch 1016
2022-03-08 02:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:18:52 | INFO | train_inner | epoch 1016:      6 / 49 loss=1.564, nll_loss=0.212, ppl=1.16, wps=25164.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49400, lr=0.000142278, gnorm=0.315, loss_scale=32, train_wall=221, gb_free=8.8, wall=128590
2022-03-08 02:20:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:20:41 | INFO | valid | epoch 1016 | valid on 'valid' subset | loss 13.495 | nll_loss 13.051 | ppl 8485.8 | wps 45388 | wpb 510.9 | bsz 1 | num_updates 49442 | best_loss 8.725
2022-03-08 02:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1016 @ 49442 updates
2022-03-08 02:20:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1016 @ 49442 updates, score 13.495) (writing took 1.775391450151801 seconds)
2022-03-08 02:20:42 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)
2022-03-08 02:20:42 | INFO | train | epoch 1016 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 24726.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49442 | lr 0.000142217 | gnorm 0.314 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128701
2022-03-08 02:20:42 | INFO | fairseq.trainer | begin training epoch 1017
2022-03-08 02:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:22:46 | INFO | valid | epoch 1017 | valid on 'valid' subset | loss 13.49 | nll_loss 13.044 | ppl 8448.28 | wps 45914.2 | wpb 510.9 | bsz 1 | num_updates 49491 | best_loss 8.725
2022-03-08 02:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1017 @ 49491 updates
2022-03-08 02:22:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1017 @ 49491 updates, score 13.49) (writing took 1.8783144559711218 seconds)
2022-03-08 02:22:48 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)
2022-03-08 02:22:48 | INFO | train | epoch 1017 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 25242.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49491 | lr 0.000142147 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128827
2022-03-08 02:22:48 | INFO | fairseq.trainer | begin training epoch 1018
2022-03-08 02:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:23:11 | INFO | train_inner | epoch 1018:      9 / 49 loss=1.564, nll_loss=0.212, ppl=1.16, wps=25047, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49500, lr=0.000142134, gnorm=0.315, loss_scale=32, train_wall=222, gb_free=8.8, wall=128849
2022-03-08 02:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:24:54 | INFO | valid | epoch 1018 | valid on 'valid' subset | loss 13.562 | nll_loss 13.122 | ppl 8915.69 | wps 44960 | wpb 510.9 | bsz 1 | num_updates 49540 | best_loss 8.725
2022-03-08 02:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1018 @ 49540 updates
2022-03-08 02:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1018 @ 49540 updates, score 13.562) (writing took 1.7721875766292214 seconds)
2022-03-08 02:24:56 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)
2022-03-08 02:24:56 | INFO | train | epoch 1018 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 24929.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49540 | lr 0.000142076 | gnorm 0.314 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 128954
2022-03-08 02:24:56 | INFO | fairseq.trainer | begin training epoch 1019
2022-03-08 02:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:26:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:27:00 | INFO | valid | epoch 1019 | valid on 'valid' subset | loss 13.569 | nll_loss 13.126 | ppl 8937.83 | wps 45548.6 | wpb 510.9 | bsz 1 | num_updates 49588 | best_loss 8.725
2022-03-08 02:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1019 @ 49588 updates
2022-03-08 02:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1019 @ 49588 updates, score 13.569) (writing took 1.796468086540699 seconds)
2022-03-08 02:27:02 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)
2022-03-08 02:27:02 | INFO | train | epoch 1019 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 24751.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49588 | lr 0.000142008 | gnorm 0.319 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129080
2022-03-08 02:27:02 | INFO | fairseq.trainer | begin training epoch 1020
2022-03-08 02:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:27:31 | INFO | train_inner | epoch 1020:     12 / 49 loss=1.564, nll_loss=0.212, ppl=1.16, wps=24897.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49600, lr=0.00014199, gnorm=0.317, loss_scale=32, train_wall=224, gb_free=8.8, wall=129109
2022-03-08 02:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:29:05 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 13.473 | nll_loss 13.026 | ppl 8341.61 | wps 46181.3 | wpb 510.9 | bsz 1 | num_updates 49637 | best_loss 8.725
2022-03-08 02:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 49637 updates
2022-03-08 02:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:29:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1020 @ 49637 updates, score 13.473) (writing took 1.7814047243446112 seconds)
2022-03-08 02:29:07 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)
2022-03-08 02:29:07 | INFO | train | epoch 1020 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 25322.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49637 | lr 0.000141938 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129205
2022-03-08 02:29:07 | INFO | fairseq.trainer | begin training epoch 1021
2022-03-08 02:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:31:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:31:11 | INFO | valid | epoch 1021 | valid on 'valid' subset | loss 13.609 | nll_loss 13.172 | ppl 9227.45 | wps 47440.8 | wpb 510.9 | bsz 1 | num_updates 49686 | best_loss 8.725
2022-03-08 02:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1021 @ 49686 updates
2022-03-08 02:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1021 @ 49686 updates, score 13.609) (writing took 1.8388112606480718 seconds)
2022-03-08 02:31:12 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)
2022-03-08 02:31:12 | INFO | train | epoch 1021 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 25363.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49686 | lr 0.000141868 | gnorm 0.315 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129331
2022-03-08 02:31:12 | INFO | fairseq.trainer | begin training epoch 1022
2022-03-08 02:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:31:47 | INFO | train_inner | epoch 1022:     14 / 49 loss=1.564, nll_loss=0.212, ppl=1.16, wps=25386.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=49700, lr=0.000141848, gnorm=0.316, loss_scale=64, train_wall=220, gb_free=8.8, wall=129365
2022-03-08 02:32:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:33:16 | INFO | valid | epoch 1022 | valid on 'valid' subset | loss 13.555 | nll_loss 13.112 | ppl 8855.18 | wps 44038 | wpb 510.9 | bsz 1 | num_updates 49734 | best_loss 8.725
2022-03-08 02:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1022 @ 49734 updates
2022-03-08 02:33:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:33:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1022 @ 49734 updates, score 13.555) (writing took 1.8065220694988966 seconds)
2022-03-08 02:33:18 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)
2022-03-08 02:33:18 | INFO | train | epoch 1022 | loss 1.564 | nll_loss 0.212 | ppl 1.16 | wps 24844.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49734 | lr 0.000141799 | gnorm 0.316 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129456
2022-03-08 02:33:18 | INFO | fairseq.trainer | begin training epoch 1023
2022-03-08 02:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:35:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:35:22 | INFO | valid | epoch 1023 | valid on 'valid' subset | loss 13.497 | nll_loss 13.053 | ppl 8498.79 | wps 45622.4 | wpb 510.9 | bsz 1 | num_updates 49783 | best_loss 8.725
2022-03-08 02:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1023 @ 49783 updates
2022-03-08 02:35:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:35:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:35:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1023 @ 49783 updates, score 13.497) (writing took 1.8460802612826228 seconds)
2022-03-08 02:35:24 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)
2022-03-08 02:35:24 | INFO | train | epoch 1023 | loss 1.563 | nll_loss 0.211 | ppl 1.16 | wps 25121.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49783 | lr 0.000141729 | gnorm 0.316 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129582
2022-03-08 02:35:24 | INFO | fairseq.trainer | begin training epoch 1024
2022-03-08 02:35:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:36:06 | INFO | train_inner | epoch 1024:     17 / 49 loss=1.563, nll_loss=0.211, ppl=1.16, wps=24995.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=49800, lr=0.000141705, gnorm=0.315, loss_scale=32, train_wall=223, gb_free=8.8, wall=129624
2022-03-08 02:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:29 | INFO | valid | epoch 1024 | valid on 'valid' subset | loss 13.502 | nll_loss 13.058 | ppl 8525.72 | wps 43947.1 | wpb 510.9 | bsz 1 | num_updates 49832 | best_loss 8.725
2022-03-08 02:37:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1024 @ 49832 updates
2022-03-08 02:37:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:37:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1024 @ 49832 updates, score 13.502) (writing took 1.8396665137261152 seconds)
2022-03-08 02:37:31 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)
2022-03-08 02:37:31 | INFO | train | epoch 1024 | loss 1.563 | nll_loss 0.211 | ppl 1.16 | wps 25098.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49832 | lr 0.00014166 | gnorm 0.312 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 129709
2022-03-08 02:37:31 | INFO | fairseq.trainer | begin training epoch 1025
2022-03-08 02:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:39:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:39:36 | INFO | valid | epoch 1025 | valid on 'valid' subset | loss 13.481 | nll_loss 13.037 | ppl 8406.73 | wps 43628.6 | wpb 510.9 | bsz 1 | num_updates 49881 | best_loss 8.725
2022-03-08 02:39:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1025 @ 49881 updates
2022-03-08 02:39:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:39:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:39:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1025 @ 49881 updates, score 13.481) (writing took 1.8554406147450209 seconds)
2022-03-08 02:39:38 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)
2022-03-08 02:39:38 | INFO | train | epoch 1025 | loss 1.563 | nll_loss 0.211 | ppl 1.16 | wps 25034.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49881 | lr 0.00014159 | gnorm 0.314 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 129836
2022-03-08 02:39:38 | INFO | fairseq.trainer | begin training epoch 1026
2022-03-08 02:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:40:25 | INFO | train_inner | epoch 1026:     19 / 49 loss=1.563, nll_loss=0.211, ppl=1.16, wps=25070.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=49900, lr=0.000141563, gnorm=0.314, loss_scale=64, train_wall=222, gb_free=8.8, wall=129883
2022-03-08 02:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:43 | INFO | valid | epoch 1026 | valid on 'valid' subset | loss 13.544 | nll_loss 13.101 | ppl 8787.87 | wps 43211.4 | wpb 510.9 | bsz 1 | num_updates 49929 | best_loss 8.725
2022-03-08 02:41:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1026 @ 49929 updates
2022-03-08 02:41:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:41:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:41:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1026 @ 49929 updates, score 13.544) (writing took 1.7943736221641302 seconds)
2022-03-08 02:41:45 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)
2022-03-08 02:41:45 | INFO | train | epoch 1026 | loss 1.563 | nll_loss 0.211 | ppl 1.16 | wps 24439.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49929 | lr 0.000141522 | gnorm 0.316 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 129963
2022-03-08 02:41:45 | INFO | fairseq.trainer | begin training epoch 1027
2022-03-08 02:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:43:51 | INFO | valid | epoch 1027 | valid on 'valid' subset | loss 13.493 | nll_loss 13.048 | ppl 8470.18 | wps 43598.7 | wpb 510.9 | bsz 1 | num_updates 49978 | best_loss 8.725
2022-03-08 02:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1027 @ 49978 updates
2022-03-08 02:43:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:43:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:43:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1027 @ 49978 updates, score 13.493) (writing took 1.9245796659961343 seconds)
2022-03-08 02:43:53 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)
2022-03-08 02:43:53 | INFO | train | epoch 1027 | loss 1.563 | nll_loss 0.211 | ppl 1.16 | wps 24790.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49978 | lr 0.000141452 | gnorm 0.314 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 130092
2022-03-08 02:43:53 | INFO | fairseq.trainer | begin training epoch 1028
2022-03-08 02:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:44:48 | INFO | train_inner | epoch 1028:     22 / 49 loss=1.563, nll_loss=0.211, ppl=1.16, wps=24623.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=50000, lr=0.000141421, gnorm=0.315, loss_scale=32, train_wall=225, gb_free=8.8, wall=130147
2022-03-08 02:44:48 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 02:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:44:54 | INFO | valid | epoch 1028 | valid on 'valid' subset | loss 13.574 | nll_loss 13.133 | ppl 8983.27 | wps 42655.9 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 8.725
2022-03-08 02:44:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1028 @ 50000 updates
2022-03-08 02:44:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 1028 @ 50000 updates, score 13.574) (writing took 1.8874893840402365 seconds)
2022-03-08 02:44:55 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)
2022-03-08 02:44:55 | INFO | train | epoch 1028 | loss 1.562 | nll_loss 0.21 | ppl 1.16 | wps 23203.6 | ups 0.35 | wpb 65536 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.31 | loss_scale 32 | train_wall 50 | gb_free 8.8 | wall 130154
2022-03-08 02:44:55 | INFO | fairseq_cli.train | done training in 130153.5 seconds
