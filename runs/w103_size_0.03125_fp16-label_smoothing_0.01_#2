Sender: LSF System <lsfadmin@eu-g2-14>
Subject: Job 207345737: <w103_size_0.03125_fp16_label_smoothing_0.01_#2> in cluster <euler> Done

Job <w103_size_0.03125_fp16_label_smoothing_0.01_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:01:28 2022
Job was executed on host(s) <eu-g2-14>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 13:01:48 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 13:01:48 2022
Terminated at Tue Mar  8 04:10:43 2022
Results reported at Tue Mar  8 04:10:43 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.01 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575622 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   148802.09 sec.
    Max Memory :                                 5746 MB
    Average Memory :                             3385.99 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14254.00 MB
    Max Swap :                                   85 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   140934 sec.
    Turnaround time :                            140955 sec.

The output (if any) follows:

2022-03-06 13:01:56 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.01, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 13:01:56 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 13:01:58 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 13:01:58 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 13:01:58 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 13:01:58 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 13:01:58 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 13:01:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 13:01:58 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 13:02:05 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 13:02:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:05 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-03-06 13:02:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:05 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 13:02:05 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 13:02:05 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 13:02:05 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 13:02:05 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 13:02:05 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 13:02:05 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 13:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:02:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 13:02:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:02:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 13:02:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 13:04:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 13:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:04:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.327 | nll_loss 15.307 | ppl 40526.6 | wps 37186.5 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 13:04:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 13:04:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:04:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:04:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.327) (writing took 4.926869615912437 seconds)
2022-03-06 13:04:54 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 13:04:54 | INFO | train | epoch 001 | loss 16.513 | nll_loss 16.505 | ppl 92973.1 | wps 19947.5 | ups 0.31 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.192 | loss_scale 4 | train_wall 145 | gb_free 8.8 | wall 169
2022-03-06 13:04:54 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 13:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:07:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:07:23 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.86 | nll_loss 13.825 | ppl 14508.1 | wps 36829.6 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.86
2022-03-06 13:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 13:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:17:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.86) (writing took 578.2972841560841 seconds)
2022-03-06 13:17:02 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:17:02 | INFO | train | epoch 002 | loss 14.618 | nll_loss 14.59 | ppl 24668.8 | wps 4367.6 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.234 | loss_scale 4 | train_wall 130 | gb_free 8.8 | wall 897
2022-03-06 13:17:02 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:17:22 | INFO | train_inner | epoch 003:      7 / 49 loss=15.403, nll_loss=15.383, ppl=42742, wps=7230, ups=0.11, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.485, loss_scale=4, train_wall=294, gb_free=8.8, wall=918
2022-03-06 13:19:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:19:32 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.194 | nll_loss 13.152 | ppl 9102.43 | wps 36440.1 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.194
2022-03-06 13:19:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 13:19:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:19:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:28:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.194) (writing took 541.4659199677408 seconds)
2022-03-06 13:28:33 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:28:33 | INFO | train | epoch 003 | loss 13.669 | nll_loss 13.632 | ppl 12694.1 | wps 4594 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.422 | loss_scale 4 | train_wall 131 | gb_free 8.8 | wall 1588
2022-03-06 13:28:33 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:31:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.369 | nll_loss 12.318 | ppl 5106.86 | wps 36643.2 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.369
2022-03-06 13:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 13:31:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:31:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.369) (writing took 4.856205800548196 seconds)
2022-03-06 13:31:09 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:31:09 | INFO | train | epoch 004 | loss 12.923 | nll_loss 12.878 | ppl 7528.31 | wps 20363.6 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.245 | loss_scale 8 | train_wall 132 | gb_free 8.8 | wall 1745
2022-03-06 13:31:09 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:31:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:31:36 | INFO | train_inner | epoch 005:      9 / 49 loss=13.167, nll_loss=13.125, ppl=8933.87, wps=7596.5, ups=0.12, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.299, loss_scale=8, train_wall=269, gb_free=8.8, wall=1772
2022-03-06 13:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:33:41 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.568 | nll_loss 11.506 | ppl 2909.08 | wps 36203.3 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.568
2022-03-06 13:33:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 13:33:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:33:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:33:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.568) (writing took 4.6899646278470755 seconds)
2022-03-06 13:33:45 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:33:45 | INFO | train | epoch 005 | loss 12.049 | nll_loss 11.994 | ppl 4080.35 | wps 20378.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.994 | loss_scale 8 | train_wall 132 | gb_free 8.8 | wall 1901
2022-03-06 13:33:45 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:36:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:36:17 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.918 | nll_loss 10.846 | ppl 1841.28 | wps 35963.1 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 10.918
2022-03-06 13:36:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 13:36:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:36:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:44:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 10.918) (writing took 510.03199866972864 seconds)
2022-03-06 13:44:47 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:44:47 | INFO | train | epoch 006 | loss 11.283 | nll_loss 11.217 | ppl 2381.2 | wps 4802.8 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.776 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 2562
2022-03-06 13:44:47 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:44:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:45:20 | INFO | train_inner | epoch 007:     11 / 49 loss=11.513, nll_loss=11.451, ppl=2798.84, wps=7878.1, ups=0.12, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.845, loss_scale=16, train_wall=269, gb_free=8.8, wall=2595
2022-03-06 13:47:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:47:18 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.489 | nll_loss 10.409 | ppl 1359.57 | wps 35277.2 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.489
2022-03-06 13:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 13:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:47:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.489) (writing took 4.903277425095439 seconds)
2022-03-06 13:47:23 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:47:23 | INFO | train | epoch 007 | loss 10.7 | nll_loss 10.625 | ppl 1579.45 | wps 20364.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.61 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 2718
2022-03-06 13:47:23 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:49:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:49:54 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.217 | nll_loss 10.129 | ppl 1120.07 | wps 36289.4 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.217
2022-03-06 13:49:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 13:49:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:49:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:49:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.217) (writing took 4.791657911613584 seconds)
2022-03-06 13:49:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:49:59 | INFO | train | epoch 008 | loss 10.327 | nll_loss 10.244 | ppl 1212.28 | wps 20399 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.513 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 2874
2022-03-06 13:49:59 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:50:38 | INFO | train_inner | epoch 009:     13 / 49 loss=10.427, nll_loss=10.346, ppl=1301.09, wps=20402, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.532, loss_scale=16, train_wall=269, gb_free=8.8, wall=2913
2022-03-06 13:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:52:30 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.032 | nll_loss 9.939 | ppl 981.27 | wps 36498.5 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.032
2022-03-06 13:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 13:52:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:52:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.032) (writing took 4.877251714468002 seconds)
2022-03-06 13:52:35 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:52:35 | INFO | train | epoch 009 | loss 10.083 | nll_loss 9.993 | ppl 1019.06 | wps 20398.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.5 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 3030
2022-03-06 13:52:35 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:55:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:55:06 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.875 | nll_loss 9.779 | ppl 878.28 | wps 36582.7 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 9.875
2022-03-06 13:55:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 13:55:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:55:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 9.875) (writing took 4.677854172885418 seconds)
2022-03-06 13:55:10 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:55:10 | INFO | train | epoch 010 | loss 9.891 | nll_loss 9.797 | ppl 889.4 | wps 20425.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.522 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 3185
2022-03-06 13:55:10 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:55:56 | INFO | train_inner | epoch 011:     15 / 49 loss=9.931, nll_loss=9.837, ppl=914.65, wps=20407.5, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.524, loss_scale=32, train_wall=269, gb_free=8.8, wall=3231
2022-03-06 13:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:57:42 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.723 | nll_loss 9.622 | ppl 788.18 | wps 36355.7 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 9.723
2022-03-06 13:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 13:57:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 13:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 9.723) (writing took 4.735203078016639 seconds)
2022-03-06 13:57:46 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:57:46 | INFO | train | epoch 011 | loss 9.717 | nll_loss 9.618 | ppl 786 | wps 20359.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.582 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 3342
2022-03-06 13:57:46 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:58:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:00:17 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.599 | nll_loss 9.496 | ppl 722.05 | wps 36451.3 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.599
2022-03-06 14:00:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 14:00:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:00:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.599) (writing took 4.905083643272519 seconds)
2022-03-06 14:00:22 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 14:00:22 | INFO | train | epoch 012 | loss 9.551 | nll_loss 9.449 | ppl 698.95 | wps 19959.7 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.674 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 3497
2022-03-06 14:00:22 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 14:00:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:01:16 | INFO | train_inner | epoch 013:     18 / 49 loss=9.578, nll_loss=9.477, ppl=712.72, wps=20249.5, ups=0.31, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.655, loss_scale=32, train_wall=271, gb_free=8.8, wall=3551
2022-03-06 14:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:02:53 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.483 | nll_loss 9.379 | ppl 665.65 | wps 36331.1 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.483
2022-03-06 14:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 14:02:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.483) (writing took 4.677133213728666 seconds)
2022-03-06 14:02:58 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 14:02:58 | INFO | train | epoch 013 | loss 9.398 | nll_loss 9.293 | ppl 627.4 | wps 20441.8 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.699 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 3653
2022-03-06 14:02:58 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 14:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:05:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:05:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:05:29 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.373 | nll_loss 9.266 | ppl 615.63 | wps 36454.4 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.373
2022-03-06 14:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 14:05:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:05:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.373) (writing took 4.750977069139481 seconds)
2022-03-06 14:05:33 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 14:05:33 | INFO | train | epoch 014 | loss 9.251 | nll_loss 9.144 | ppl 565.63 | wps 20019.8 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.756 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 3808
2022-03-06 14:05:33 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 14:05:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:06:37 | INFO | train_inner | epoch 015:     21 / 49 loss=9.266, nll_loss=9.159, ppl=571.8, wps=20201.2, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.757, loss_scale=32, train_wall=272, gb_free=8.8, wall=3872
2022-03-06 14:07:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:08:06 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.263 | nll_loss 9.154 | ppl 569.53 | wps 35279.7 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.263
2022-03-06 14:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 14:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:08:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.263) (writing took 4.935155112296343 seconds)
2022-03-06 14:08:11 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 14:08:11 | INFO | train | epoch 015 | loss 9.108 | nll_loss 8.999 | ppl 511.52 | wps 20206.7 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.812 | loss_scale 32 | train_wall 133 | gb_free 8.8 | wall 3966
2022-03-06 14:08:11 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 14:08:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:10:41 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.158 | nll_loss 9.046 | ppl 528.76 | wps 35885.3 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.158
2022-03-06 14:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 14:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.158) (writing took 5.404704449698329 seconds)
2022-03-06 14:10:47 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 14:10:47 | INFO | train | epoch 016 | loss 8.968 | nll_loss 8.856 | ppl 463.43 | wps 20380.6 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.846 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 4122
2022-03-06 14:10:47 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 14:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:11:55 | INFO | train_inner | epoch 017:     23 / 49 loss=8.975, nll_loss=8.863, ppl=465.53, wps=20394.6, ups=0.31, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.82, loss_scale=32, train_wall=268, gb_free=8.8, wall=4190
2022-03-06 14:12:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:13:17 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.06 | nll_loss 8.946 | ppl 493.13 | wps 35576.2 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.06
2022-03-06 14:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 14:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.06) (writing took 4.763714360073209 seconds)
2022-03-06 14:13:22 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 14:13:22 | INFO | train | epoch 017 | loss 8.833 | nll_loss 8.719 | ppl 421.33 | wps 19997.2 | ups 0.31 | wpb 64853.3 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.875 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 4277
2022-03-06 14:13:22 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 14:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:15:53 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.967 | nll_loss 8.852 | ppl 462.07 | wps 36511.6 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 8.967
2022-03-06 14:15:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 14:15:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:15:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:15:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 8.967) (writing took 4.95632902905345 seconds)
2022-03-06 14:15:58 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 14:15:58 | INFO | train | epoch 018 | loss 8.704 | nll_loss 8.587 | ppl 384.42 | wps 20375.6 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.903 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 4433
2022-03-06 14:15:58 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 14:15:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:17:16 | INFO | train_inner | epoch 019:     26 / 49 loss=8.703, nll_loss=8.586, ppl=384.16, wps=20252.7, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.924, loss_scale=32, train_wall=271, gb_free=8.8, wall=4511
2022-03-06 14:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:18:29 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.879 | nll_loss 8.761 | ppl 433.83 | wps 35281.6 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 8.879
2022-03-06 14:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 14:18:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 8.879) (writing took 282.424319319427 seconds)
2022-03-06 14:23:11 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 14:23:12 | INFO | train | epoch 019 | loss 8.58 | nll_loss 8.461 | ppl 352.33 | wps 7333.7 | ups 0.11 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.989 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 4867
2022-03-06 14:23:12 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 14:23:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:23:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:25:44 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.811 | nll_loss 8.693 | ppl 413.97 | wps 35376.1 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 8.811
2022-03-06 14:25:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 14:25:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:35:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 8.811) (writing took 579.2570726796985 seconds)
2022-03-06 14:35:23 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:35:23 | INFO | train | epoch 020 | loss 8.458 | nll_loss 8.336 | ppl 323.17 | wps 4255.8 | ups 0.07 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.917 | loss_scale 32 | train_wall 133 | gb_free 8.8 | wall 5598
2022-03-06 14:35:23 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:35:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:36:49 | INFO | train_inner | epoch 021:     29 / 49 loss=8.451, nll_loss=8.329, ppl=321.67, wps=5529.8, ups=0.09, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.943, loss_scale=32, train_wall=272, gb_free=8.8, wall=5684
2022-03-06 14:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:37:52 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.753 | nll_loss 8.631 | ppl 396.47 | wps 36737.6 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 8.753
2022-03-06 14:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 14:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:37:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 8.753) (writing took 4.970779234543443 seconds)
2022-03-06 14:37:57 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:37:57 | INFO | train | epoch 021 | loss 8.343 | nll_loss 8.219 | ppl 298.05 | wps 20559.2 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.943 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 5753
2022-03-06 14:37:57 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:40:28 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.686 | nll_loss 8.563 | ppl 378.15 | wps 36718.6 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 8.686
2022-03-06 14:40:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-06 14:40:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:40:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 8.686) (writing took 5.14334006793797 seconds)
2022-03-06 14:40:33 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:40:33 | INFO | train | epoch 022 | loss 8.231 | nll_loss 8.105 | ppl 275.35 | wps 20432.6 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.971 | loss_scale 64 | train_wall 131 | gb_free 8.8 | wall 5908
2022-03-06 14:40:33 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:40:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:42:07 | INFO | train_inner | epoch 023:     32 / 49 loss=8.218, nll_loss=8.091, ppl=272.72, wps=20366, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.962, loss_scale=32, train_wall=269, gb_free=8.8, wall=6003
2022-03-06 14:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:43:02 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.65 | nll_loss 8.526 | ppl 368.62 | wps 35645.2 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 8.65
2022-03-06 14:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 14:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:43:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 8.65) (writing took 4.985999196767807 seconds)
2022-03-06 14:43:07 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:43:07 | INFO | train | epoch 023 | loss 8.124 | nll_loss 7.996 | ppl 255.29 | wps 20160.6 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.981 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 6063
2022-03-06 14:43:07 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:45:35 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.594 | nll_loss 8.468 | ppl 354.21 | wps 37142.2 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 8.594
2022-03-06 14:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 14:45:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 8.594) (writing took 292.23937948420644 seconds)
2022-03-06 14:50:28 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:50:28 | INFO | train | epoch 024 | loss 8.014 | nll_loss 7.884 | ppl 236.25 | wps 7218.1 | ups 0.11 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.934 | loss_scale 32 | train_wall 129 | gb_free 8.8 | wall 6503
2022-03-06 14:50:28 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:52:09 | INFO | train_inner | epoch 025:     34 / 49 loss=7.997, nll_loss=7.867, ppl=233.42, wps=10789.6, ups=0.17, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.969, loss_scale=64, train_wall=265, gb_free=8.8, wall=6604
2022-03-06 14:52:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:52:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:52:57 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.541 | nll_loss 8.413 | ppl 340.8 | wps 36889.2 | wpb 510.9 | bsz 1 | num_updates 1214 | best_loss 8.541
2022-03-06 14:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1214 updates
2022-03-06 14:52:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 25 @ 1214 updates, score 8.541) (writing took 4.746007289737463 seconds)
2022-03-06 14:53:02 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:53:02 | INFO | train | epoch 025 | loss 7.911 | nll_loss 7.778 | ppl 219.53 | wps 20142.2 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 1214 | lr 0.00015182 | gnorm 0.987 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 6657
2022-03-06 14:53:02 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:55:31 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.514 | nll_loss 8.384 | ppl 334.08 | wps 36871.4 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.514
2022-03-06 14:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 14:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.514) (writing took 4.679724117740989 seconds)
2022-03-06 14:55:36 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:55:36 | INFO | train | epoch 026 | loss 7.807 | nll_loss 7.673 | ppl 204.13 | wps 20661.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 1.003 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 6811
2022-03-06 14:55:36 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:57:26 | INFO | train_inner | epoch 027:     37 / 49 loss=7.783, nll_loss=7.648, ppl=200.6, wps=20430.3, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=1.001, loss_scale=32, train_wall=269, gb_free=8.8, wall=6921
2022-03-06 14:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:58:07 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.461 | nll_loss 8.33 | ppl 321.85 | wps 36070.3 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.461
2022-03-06 14:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 14:58:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 14:58:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.461) (writing took 4.686574507504702 seconds)
2022-03-06 14:58:11 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 14:58:11 | INFO | train | epoch 027 | loss 7.703 | nll_loss 7.567 | ppl 189.58 | wps 20439.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.998 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 6967
2022-03-06 14:58:11 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 14:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:00:43 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.419 | nll_loss 8.287 | ppl 312.26 | wps 36011.5 | wpb 510.9 | bsz 1 | num_updates 1360 | best_loss 8.419
2022-03-06 15:00:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1360 updates
2022-03-06 15:00:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:00:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:00:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 28 @ 1360 updates, score 8.419) (writing took 4.701181836426258 seconds)
2022-03-06 15:00:48 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:00:48 | INFO | train | epoch 028 | loss 7.599 | nll_loss 7.461 | ppl 176.18 | wps 19880.7 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 1360 | lr 0.000170066 | gnorm 1.027 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 7123
2022-03-06 15:00:48 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:00:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:02:48 | INFO | train_inner | epoch 029:     40 / 49 loss=7.569, nll_loss=7.43, ppl=172.5, wps=20140.4, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=1.025, loss_scale=32, train_wall=273, gb_free=8.8, wall=7243
2022-03-06 15:03:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:03:20 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.392 | nll_loss 8.257 | ppl 305.97 | wps 36141.7 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.392
2022-03-06 15:03:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 15:03:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:03:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.392) (writing took 558.1752534192055 seconds)
2022-03-06 15:12:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:12:38 | INFO | train | epoch 029 | loss 7.498 | nll_loss 7.358 | ppl 164.02 | wps 4475.9 | ups 0.07 | wpb 64858.2 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 1.018 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 7833
2022-03-06 15:12:38 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:15:11 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.359 | nll_loss 8.223 | ppl 298.77 | wps 36180.3 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.359
2022-03-06 15:15:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 15:15:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:15:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.359) (writing took 4.749470988288522 seconds)
2022-03-06 15:15:16 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:15:16 | INFO | train | epoch 030 | loss 7.393 | nll_loss 7.251 | ppl 152.36 | wps 20152.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 1.014 | loss_scale 32 | train_wall 133 | gb_free 8.8 | wall 7991
2022-03-06 15:15:16 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:16:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:17:25 | INFO | train_inner | epoch 031:     43 / 49 loss=7.357, nll_loss=7.215, ppl=148.53, wps=7399.4, ups=0.11, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=1.019, loss_scale=32, train_wall=274, gb_free=8.8, wall=8120
2022-03-06 15:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:17:48 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.339 | nll_loss 8.202 | ppl 294.45 | wps 36178 | wpb 510.9 | bsz 1 | num_updates 1506 | best_loss 8.339
2022-03-06 15:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1506 updates
2022-03-06 15:17:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:17:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 31 @ 1506 updates, score 8.339) (writing took 4.637640060856938 seconds)
2022-03-06 15:17:52 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:17:52 | INFO | train | epoch 031 | loss 7.29 | nll_loss 7.146 | ppl 141.65 | wps 19886.6 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 1506 | lr 0.000188312 | gnorm 1.028 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 8147
2022-03-06 15:17:52 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:20:24 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.314 | nll_loss 8.176 | ppl 289.21 | wps 36056.1 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.314
2022-03-06 15:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 15:20:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 8.314) (writing took 4.613035894930363 seconds)
2022-03-06 15:20:29 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:20:29 | INFO | train | epoch 032 | loss 7.187 | nll_loss 7.042 | ppl 131.76 | wps 20291.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 1.033 | loss_scale 32 | train_wall 133 | gb_free 8.8 | wall 8304
2022-03-06 15:20:29 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:22:44 | INFO | train_inner | epoch 033:     45 / 49 loss=7.146, nll_loss=7, ppl=127.96, wps=20342, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=1.035, loss_scale=32, train_wall=270, gb_free=8.8, wall=8439
2022-03-06 15:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:23:01 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.291 | nll_loss 8.151 | ppl 284.31 | wps 35977.3 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.291
2022-03-06 15:23:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 15:23:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:23:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.291) (writing took 4.563239527866244 seconds)
2022-03-06 15:23:05 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:23:05 | INFO | train | epoch 033 | loss 7.084 | nll_loss 6.936 | ppl 122.49 | wps 20339.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 1.042 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 8460
2022-03-06 15:23:05 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:23:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:23:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:25:36 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.282 | nll_loss 8.143 | ppl 282.75 | wps 36247.4 | wpb 510.9 | bsz 1 | num_updates 1652 | best_loss 8.282
2022-03-06 15:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1652 updates
2022-03-06 15:25:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:34:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 34 @ 1652 updates, score 8.282) (writing took 516.3325346894562 seconds)
2022-03-06 15:34:13 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:34:13 | INFO | train | epoch 034 | loss 6.983 | nll_loss 6.833 | ppl 114.02 | wps 4663 | ups 0.07 | wpb 64844.1 | bsz 126.7 | num_updates 1652 | lr 0.000206559 | gnorm 1.079 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 9128
2022-03-06 15:34:13 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:36:36 | INFO | train_inner | epoch 035:     48 / 49 loss=6.938, nll_loss=6.787, ppl=110.46, wps=7794, ups=0.12, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.057, loss_scale=32, train_wall=272, gb_free=8.8, wall=9271
2022-03-06 15:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:36:44 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.277 | nll_loss 8.136 | ppl 281.36 | wps 36308.5 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.277
2022-03-06 15:36:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 15:36:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:36:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 35 @ 1701 updates, score 8.277) (writing took 5.261203603819013 seconds)
2022-03-06 15:36:49 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:36:49 | INFO | train | epoch 035 | loss 6.882 | nll_loss 6.731 | ppl 106.22 | wps 20314.7 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 1.036 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 9284
2022-03-06 15:36:49 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:39:21 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.257 | nll_loss 8.115 | ppl 277.27 | wps 36246.5 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.257
2022-03-06 15:39:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 15:39:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:39:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.257) (writing took 5.019490752369165 seconds)
2022-03-06 15:39:26 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:39:26 | INFO | train | epoch 036 | loss 6.781 | nll_loss 6.628 | ppl 98.88 | wps 20194.7 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 1.097 | loss_scale 64 | train_wall 133 | gb_free 8.8 | wall 9442
2022-03-06 15:39:26 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:40:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:41:58 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.241 | nll_loss 8.097 | ppl 273.83 | wps 36145.7 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.241
2022-03-06 15:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 15:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 37 @ 1798 updates, score 8.241) (writing took 567.7140456046909 seconds)
2022-03-06 15:51:26 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:51:26 | INFO | train | epoch 037 | loss 6.679 | nll_loss 6.524 | ppl 92.03 | wps 4325.6 | ups 0.07 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 1.081 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 10161
2022-03-06 15:51:26 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:51:32 | INFO | train_inner | epoch 038:      2 / 49 loss=6.729, nll_loss=6.574, ppl=95.29, wps=7203.7, ups=0.11, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.086, loss_scale=32, train_wall=272, gb_free=8.8, wall=10167
2022-03-06 15:53:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:53:58 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.265 | nll_loss 8.121 | ppl 278.32 | wps 35406.7 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.241
2022-03-06 15:53:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 15:53:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:54:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.265) (writing took 2.8559508845210075 seconds)
2022-03-06 15:54:01 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:54:01 | INFO | train | epoch 038 | loss 6.585 | nll_loss 6.428 | ppl 86.09 | wps 20554.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 1.115 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 10316
2022-03-06 15:54:01 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:56:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:56:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:56:32 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.238 | nll_loss 8.092 | ppl 272.85 | wps 36257.5 | wpb 510.9 | bsz 1 | num_updates 1895 | best_loss 8.238
2022-03-06 15:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1895 updates
2022-03-06 15:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt
2022-03-06 15:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_best.pt (epoch 39 @ 1895 updates, score 8.238) (writing took 4.92915890365839 seconds)
2022-03-06 15:56:37 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:56:37 | INFO | train | epoch 039 | loss 6.483 | nll_loss 6.323 | ppl 80.08 | wps 19929 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 1895 | lr 0.000236928 | gnorm 1.069 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 10472
2022-03-06 15:56:37 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:56:52 | INFO | train_inner | epoch 040:      5 / 49 loss=6.525, nll_loss=6.367, ppl=82.52, wps=20293.9, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.098, loss_scale=32, train_wall=272, gb_free=8.8, wall=10487
2022-03-06 15:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:59:08 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.273 | nll_loss 8.127 | ppl 279.65 | wps 35154.4 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.238
2022-03-06 15:59:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 15:59:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:59:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 15:59:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.273) (writing took 3.196348475292325 seconds)
2022-03-06 15:59:12 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 15:59:12 | INFO | train | epoch 040 | loss 6.393 | nll_loss 6.232 | ppl 75.15 | wps 20534.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.141 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 10627
2022-03-06 15:59:12 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 15:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:01:43 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.246 | nll_loss 8.099 | ppl 274.17 | wps 36335.2 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.238
2022-03-06 16:01:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 16:01:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:01:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.246) (writing took 3.386841583997011 seconds)
2022-03-06 16:01:47 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:01:47 | INFO | train | epoch 041 | loss 6.295 | nll_loss 6.132 | ppl 70.14 | wps 20492.2 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.143 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 10782
2022-03-06 16:01:47 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:01:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:02:08 | INFO | train_inner | epoch 042:      7 / 49 loss=6.331, nll_loss=6.169, ppl=71.97, wps=20529.7, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.137, loss_scale=32, train_wall=270, gb_free=8.8, wall=10803
2022-03-06 16:03:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:04:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:04:18 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.307 | nll_loss 8.162 | ppl 286.4 | wps 36123.2 | wpb 510.9 | bsz 1 | num_updates 2041 | best_loss 8.238
2022-03-06 16:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2041 updates
2022-03-06 16:04:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:04:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:04:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 42 @ 2041 updates, score 8.307) (writing took 3.028617976233363 seconds)
2022-03-06 16:04:21 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:04:21 | INFO | train | epoch 042 | loss 6.2 | nll_loss 6.035 | ppl 65.58 | wps 20109.6 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 2041 | lr 0.000255174 | gnorm 1.179 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 10937
2022-03-06 16:04:21 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:06:53 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.362 | nll_loss 8.215 | ppl 297.13 | wps 35299.8 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.238
2022-03-06 16:06:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-06 16:06:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 43 @ 2090 updates, score 8.362) (writing took 3.1208841782063246 seconds)
2022-03-06 16:06:56 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:06:56 | INFO | train | epoch 043 | loss 6.101 | nll_loss 5.934 | ppl 61.14 | wps 20589.6 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.096 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 11091
2022-03-06 16:06:56 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:07:26 | INFO | train_inner | epoch 044:     10 / 49 loss=6.131, nll_loss=5.965, ppl=62.47, wps=20396.9, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.129, loss_scale=32, train_wall=272, gb_free=8.8, wall=11121
2022-03-06 16:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:09:27 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.381 | nll_loss 8.234 | ppl 301.01 | wps 36332.4 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.238
2022-03-06 16:09:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-06 16:09:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:09:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:09:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 44 @ 2139 updates, score 8.381) (writing took 2.8255342170596123 seconds)
2022-03-06 16:09:30 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:09:30 | INFO | train | epoch 044 | loss 6.01 | nll_loss 5.842 | ppl 57.35 | wps 20594.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.147 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 11245
2022-03-06 16:09:30 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:10:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:12:01 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.416 | nll_loss 8.27 | ppl 308.79 | wps 36621.1 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.238
2022-03-06 16:12:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-06 16:12:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:12:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 45 @ 2187 updates, score 8.416) (writing took 3.225772302597761 seconds)
2022-03-06 16:12:04 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:12:04 | INFO | train | epoch 045 | loss 5.914 | nll_loss 5.743 | ppl 53.56 | wps 20265.2 | ups 0.31 | wpb 64853.3 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.214 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 11399
2022-03-06 16:12:04 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:12:42 | INFO | train_inner | epoch 046:     13 / 49 loss=5.939, nll_loss=5.769, ppl=54.51, wps=20512, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.194, loss_scale=32, train_wall=271, gb_free=8.8, wall=11437
2022-03-06 16:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:14:33 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.43 | nll_loss 8.285 | ppl 311.87 | wps 36821.1 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.238
2022-03-06 16:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 16:14:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:14:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:14:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 46 @ 2236 updates, score 8.43) (writing took 2.909631609916687 seconds)
2022-03-06 16:14:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:14:35 | INFO | train | epoch 046 | loss 5.82 | nll_loss 5.647 | ppl 50.1 | wps 20944.6 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.153 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 11551
2022-03-06 16:14:35 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:14:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:17:03 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.458 | nll_loss 8.31 | ppl 317.26 | wps 37008.7 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.238
2022-03-06 16:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-06 16:17:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 47 @ 2285 updates, score 8.458) (writing took 2.916865011677146 seconds)
2022-03-06 16:17:06 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:17:06 | INFO | train | epoch 047 | loss 5.73 | nll_loss 5.555 | ppl 47.01 | wps 21118.6 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.237 | loss_scale 64 | train_wall 129 | gb_free 8.8 | wall 11701
2022-03-06 16:17:06 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:17:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:17:53 | INFO | train_inner | epoch 048:     16 / 49 loss=5.747, nll_loss=5.573, ppl=47.59, wps=20892.9, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.221, loss_scale=32, train_wall=266, gb_free=8.8, wall=11748
2022-03-06 16:19:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:19:34 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.466 | nll_loss 8.318 | ppl 319.06 | wps 37182.2 | wpb 510.9 | bsz 1 | num_updates 2333 | best_loss 8.238
2022-03-06 16:19:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2333 updates
2022-03-06 16:19:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:19:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:19:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 48 @ 2333 updates, score 8.466) (writing took 3.0146563425660133 seconds)
2022-03-06 16:19:37 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:19:37 | INFO | train | epoch 048 | loss 5.634 | nll_loss 5.457 | ppl 43.93 | wps 20671.6 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 2333 | lr 0.000291667 | gnorm 1.249 | loss_scale 32 | train_wall 129 | gb_free 8.8 | wall 11852
2022-03-06 16:19:37 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:19:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:22:04 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.584 | nll_loss 8.431 | ppl 345.16 | wps 37347.1 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 8.238
2022-03-06 16:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-06 16:22:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 49 @ 2382 updates, score 8.584) (writing took 2.735507171601057 seconds)
2022-03-06 16:22:07 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:22:07 | INFO | train | epoch 049 | loss 5.545 | nll_loss 5.366 | ppl 41.24 | wps 21119 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.266 | loss_scale 32 | train_wall 129 | gb_free 8.8 | wall 12002
2022-03-06 16:22:07 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:23:00 | INFO | train_inner | epoch 050:     18 / 49 loss=5.556, nll_loss=5.377, ppl=41.57, wps=21140, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.237, loss_scale=32, train_wall=263, gb_free=8.8, wall=12055
2022-03-06 16:23:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:23:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:24:35 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.563 | nll_loss 8.414 | ppl 341.15 | wps 36712.2 | wpb 510.9 | bsz 1 | num_updates 2429 | best_loss 8.238
2022-03-06 16:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2429 updates
2022-03-06 16:24:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:24:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 50 @ 2429 updates, score 8.563) (writing took 2.7886010240763426 seconds)
2022-03-06 16:24:38 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:24:38 | INFO | train | epoch 050 | loss 5.448 | nll_loss 5.268 | ppl 38.53 | wps 20217.3 | ups 0.31 | wpb 64829.4 | bsz 126.6 | num_updates 2429 | lr 0.000303664 | gnorm 1.256 | loss_scale 16 | train_wall 129 | gb_free 8.8 | wall 12153
2022-03-06 16:24:38 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:27:08 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.587 | nll_loss 8.436 | ppl 346.33 | wps 36301.9 | wpb 510.9 | bsz 1 | num_updates 2478 | best_loss 8.238
2022-03-06 16:27:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2478 updates
2022-03-06 16:27:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:27:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:27:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 51 @ 2478 updates, score 8.587) (writing took 2.7398575078696012 seconds)
2022-03-06 16:27:10 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:27:10 | INFO | train | epoch 051 | loss 5.364 | nll_loss 5.181 | ppl 36.27 | wps 20827.9 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2478 | lr 0.000309788 | gnorm 1.313 | loss_scale 16 | train_wall 131 | gb_free 8.8 | wall 12305
2022-03-06 16:27:10 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:28:16 | INFO | train_inner | epoch 052:     22 / 49 loss=5.367, nll_loss=5.185, ppl=36.38, wps=20491.3, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.317, loss_scale=16, train_wall=271, gb_free=8.8, wall=12371
2022-03-06 16:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:29:41 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.666 | nll_loss 8.513 | ppl 365.23 | wps 36300.9 | wpb 510.9 | bsz 1 | num_updates 2527 | best_loss 8.238
2022-03-06 16:29:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2527 updates
2022-03-06 16:29:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:29:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 52 @ 2527 updates, score 8.666) (writing took 2.591533610597253 seconds)
2022-03-06 16:29:44 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:29:44 | INFO | train | epoch 052 | loss 5.271 | nll_loss 5.086 | ppl 33.97 | wps 20685.6 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2527 | lr 0.000315912 | gnorm 1.281 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 12459
2022-03-06 16:29:44 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:32:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:32:15 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.622 | nll_loss 8.47 | ppl 354.64 | wps 36332.4 | wpb 510.9 | bsz 1 | num_updates 2576 | best_loss 8.238
2022-03-06 16:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2576 updates
2022-03-06 16:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 53 @ 2576 updates, score 8.622) (writing took 2.5614020694047213 seconds)
2022-03-06 16:32:18 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 16:32:18 | INFO | train | epoch 053 | loss 5.183 | nll_loss 4.996 | ppl 31.92 | wps 20692.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2576 | lr 0.000322036 | gnorm 1.368 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 12613
2022-03-06 16:32:18 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 16:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:33:29 | INFO | train_inner | epoch 054:     24 / 49 loss=5.183, nll_loss=4.996, ppl=31.91, wps=20712.8, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.317, loss_scale=32, train_wall=269, gb_free=8.8, wall=12685
2022-03-06 16:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:34:49 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.764 | nll_loss 8.61 | ppl 390.65 | wps 36279.7 | wpb 510.9 | bsz 1 | num_updates 2625 | best_loss 8.238
2022-03-06 16:34:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2625 updates
2022-03-06 16:34:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:34:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:34:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 54 @ 2625 updates, score 8.764) (writing took 2.7667325865477324 seconds)
2022-03-06 16:34:51 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 16:34:51 | INFO | train | epoch 054 | loss 5.087 | nll_loss 4.898 | ppl 29.83 | wps 20641.8 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2625 | lr 0.000328159 | gnorm 1.322 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 12767
2022-03-06 16:34:52 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 16:34:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:37:23 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 8.807 | nll_loss 8.654 | ppl 402.73 | wps 36493.6 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.238
2022-03-06 16:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-06 16:37:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 55 @ 2674 updates, score 8.807) (writing took 2.552283065393567 seconds)
2022-03-06 16:37:25 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 16:37:25 | INFO | train | epoch 055 | loss 5.005 | nll_loss 4.814 | ppl 28.14 | wps 20677.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.417 | loss_scale 64 | train_wall 132 | gb_free 8.8 | wall 12920
2022-03-06 16:37:25 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 16:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:37:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 16:38:46 | INFO | train_inner | epoch 056:     27 / 49 loss=5, nll_loss=4.809, ppl=28.04, wps=20482.6, ups=0.32, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.35, loss_scale=32, train_wall=272, gb_free=8.8, wall=13001
2022-03-06 16:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:39:56 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 8.822 | nll_loss 8.665 | ppl 406 | wps 36336.5 | wpb 510.9 | bsz 1 | num_updates 2722 | best_loss 8.238
2022-03-06 16:39:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2722 updates
2022-03-06 16:39:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:39:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:39:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 56 @ 2722 updates, score 8.822) (writing took 3.0866789743304253 seconds)
2022-03-06 16:39:59 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 16:39:59 | INFO | train | epoch 056 | loss 4.909 | nll_loss 4.716 | ppl 26.29 | wps 20185.3 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 2722 | lr 0.000340282 | gnorm 1.356 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 13075
2022-03-06 16:39:59 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 16:39:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:42:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:42:30 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 8.864 | nll_loss 8.707 | ppl 417.76 | wps 35761.1 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.238
2022-03-06 16:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-06 16:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 57 @ 2771 updates, score 8.864) (writing took 3.1598665080964565 seconds)
2022-03-06 16:42:33 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 16:42:33 | INFO | train | epoch 057 | loss 4.817 | nll_loss 4.622 | ppl 24.62 | wps 20660 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.313 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 13228
2022-03-06 16:42:33 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 16:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:42:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:44:03 | INFO | train_inner | epoch 058:     30 / 49 loss=4.817, nll_loss=4.622, ppl=24.62, wps=20485.1, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.429, loss_scale=16, train_wall=271, gb_free=8.8, wall=13318
2022-03-06 16:44:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:45:04 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 8.908 | nll_loss 8.75 | ppl 430.69 | wps 36735.2 | wpb 510.9 | bsz 1 | num_updates 2819 | best_loss 8.238
2022-03-06 16:45:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2819 updates
2022-03-06 16:45:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:45:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 58 @ 2819 updates, score 8.908) (writing took 3.11442350409925 seconds)
2022-03-06 16:45:07 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 16:45:07 | INFO | train | epoch 058 | loss 4.743 | nll_loss 4.546 | ppl 23.36 | wps 20247.2 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 2819 | lr 0.000352405 | gnorm 1.462 | loss_scale 16 | train_wall 131 | gb_free 8.8 | wall 13382
2022-03-06 16:45:07 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 16:45:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:47:38 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 8.918 | nll_loss 8.763 | ppl 434.31 | wps 36317.8 | wpb 510.9 | bsz 1 | num_updates 2868 | best_loss 8.238
2022-03-06 16:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2868 updates
2022-03-06 16:47:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:47:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 59 @ 2868 updates, score 8.918) (writing took 3.510012563318014 seconds)
2022-03-06 16:47:42 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 16:47:42 | INFO | train | epoch 059 | loss 4.646 | nll_loss 4.446 | ppl 21.8 | wps 20546.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2868 | lr 0.000358528 | gnorm 1.411 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 13537
2022-03-06 16:47:42 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 16:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:49:17 | INFO | train_inner | epoch 060:     32 / 49 loss=4.635, nll_loss=4.435, ppl=21.63, wps=20632.8, ups=0.32, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.397, loss_scale=16, train_wall=269, gb_free=8.8, wall=13632
2022-03-06 16:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:50:12 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.059 | nll_loss 8.905 | ppl 479.42 | wps 36458.1 | wpb 510.9 | bsz 1 | num_updates 2917 | best_loss 8.238
2022-03-06 16:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2917 updates
2022-03-06 16:50:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:50:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 60 @ 2917 updates, score 9.059) (writing took 3.5035711135715246 seconds)
2022-03-06 16:50:16 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 16:50:16 | INFO | train | epoch 060 | loss 4.562 | nll_loss 4.361 | ppl 20.55 | wps 20603.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 2917 | lr 0.000364652 | gnorm 1.445 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 13691
2022-03-06 16:50:16 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 16:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:52:48 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.107 | nll_loss 8.949 | ppl 494.33 | wps 36162.1 | wpb 510.9 | bsz 1 | num_updates 2965 | best_loss 8.238
2022-03-06 16:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2965 updates
2022-03-06 16:52:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:52:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:52:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 61 @ 2965 updates, score 9.107) (writing took 3.298007635399699 seconds)
2022-03-06 16:52:51 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 16:52:51 | INFO | train | epoch 061 | loss 4.474 | nll_loss 4.27 | ppl 19.3 | wps 20052.2 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 2965 | lr 0.000370651 | gnorm 1.463 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 13846
2022-03-06 16:52:51 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 16:52:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:54:36 | INFO | train_inner | epoch 062:     35 / 49 loss=4.455, nll_loss=4.251, ppl=19.04, wps=20363.8, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.431, loss_scale=16, train_wall=272, gb_free=8.8, wall=13951
2022-03-06 16:55:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:55:22 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.136 | nll_loss 8.979 | ppl 504.75 | wps 36396.4 | wpb 510.9 | bsz 1 | num_updates 3014 | best_loss 8.238
2022-03-06 16:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3014 updates
2022-03-06 16:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:55:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:55:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 62 @ 3014 updates, score 9.136) (writing took 3.4960816986858845 seconds)
2022-03-06 16:55:25 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 16:55:25 | INFO | train | epoch 062 | loss 4.389 | nll_loss 4.183 | ppl 18.16 | wps 20603.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3014 | lr 0.000376775 | gnorm 1.469 | loss_scale 16 | train_wall 131 | gb_free 8.8 | wall 14000
2022-03-06 16:55:25 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 16:55:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:57:57 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.243 | nll_loss 9.084 | ppl 542.75 | wps 36348.5 | wpb 510.9 | bsz 1 | num_updates 3063 | best_loss 8.238
2022-03-06 16:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3063 updates
2022-03-06 16:57:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 16:58:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 63 @ 3063 updates, score 9.243) (writing took 2.936402400955558 seconds)
2022-03-06 16:58:00 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 16:58:00 | INFO | train | epoch 063 | loss 4.306 | nll_loss 4.099 | ppl 17.13 | wps 20534.9 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3063 | lr 0.000382898 | gnorm 1.489 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 14155
2022-03-06 16:58:00 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 16:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:59:51 | INFO | train_inner | epoch 064:     37 / 49 loss=4.289, nll_loss=4.081, ppl=16.92, wps=20588.9, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.497, loss_scale=32, train_wall=269, gb_free=8.8, wall=14266
2022-03-06 17:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:00:31 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.26 | nll_loss 9.1 | ppl 548.89 | wps 36360.7 | wpb 510.9 | bsz 1 | num_updates 3112 | best_loss 8.238
2022-03-06 17:00:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3112 updates
2022-03-06 17:00:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:00:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 64 @ 3112 updates, score 9.26) (writing took 3.116433857008815 seconds)
2022-03-06 17:00:34 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 17:00:34 | INFO | train | epoch 064 | loss 4.217 | nll_loss 4.007 | ppl 16.08 | wps 20600.9 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3112 | lr 0.000389022 | gnorm 1.443 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 14310
2022-03-06 17:00:34 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 17:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:03:05 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.333 | nll_loss 9.171 | ppl 576.57 | wps 36323.3 | wpb 510.9 | bsz 1 | num_updates 3161 | best_loss 8.238
2022-03-06 17:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3161 updates
2022-03-06 17:03:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 65 @ 3161 updates, score 9.333) (writing took 3.084818698465824 seconds)
2022-03-06 17:03:08 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 17:03:08 | INFO | train | epoch 065 | loss 4.133 | nll_loss 3.921 | ppl 15.15 | wps 20626.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3161 | lr 0.000395146 | gnorm 1.5 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 14464
2022-03-06 17:03:08 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 17:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:03:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:05:08 | INFO | train_inner | epoch 066:     40 / 49 loss=4.109, nll_loss=3.896, ppl=14.89, wps=20446.8, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.479, loss_scale=16, train_wall=271, gb_free=8.8, wall=14583
2022-03-06 17:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:05:40 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.378 | nll_loss 9.218 | ppl 595.34 | wps 36171.1 | wpb 510.9 | bsz 1 | num_updates 3209 | best_loss 8.238
2022-03-06 17:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3209 updates
2022-03-06 17:05:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:05:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:05:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 66 @ 3209 updates, score 9.378) (writing took 2.7471520118415356 seconds)
2022-03-06 17:05:42 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 17:05:42 | INFO | train | epoch 066 | loss 4.05 | nll_loss 3.835 | ppl 14.28 | wps 20221.6 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 3209 | lr 0.000401145 | gnorm 1.481 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 14618
2022-03-06 17:05:42 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 17:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:08:14 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.449 | nll_loss 9.29 | ppl 625.98 | wps 36242.4 | wpb 510.9 | bsz 1 | num_updates 3258 | best_loss 8.238
2022-03-06 17:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3258 updates
2022-03-06 17:08:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:08:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 67 @ 3258 updates, score 9.449) (writing took 2.8000099565833807 seconds)
2022-03-06 17:08:17 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 17:08:17 | INFO | train | epoch 067 | loss 3.974 | nll_loss 3.757 | ppl 13.52 | wps 20612.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3258 | lr 0.000407269 | gnorm 1.532 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 14772
2022-03-06 17:08:17 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 17:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:10:22 | INFO | train_inner | epoch 068:     42 / 49 loss=3.949, nll_loss=3.732, ppl=13.29, wps=20649.5, ups=0.32, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.572, loss_scale=16, train_wall=269, gb_free=8.8, wall=14897
2022-03-06 17:10:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:10:48 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.467 | nll_loss 9.306 | ppl 632.86 | wps 36390.7 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 8.238
2022-03-06 17:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-06 17:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:10:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:10:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 68 @ 3307 updates, score 9.467) (writing took 2.6233457177877426 seconds)
2022-03-06 17:10:50 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 17:10:50 | INFO | train | epoch 068 | loss 3.897 | nll_loss 3.679 | ppl 12.81 | wps 20652.2 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.597 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 14926
2022-03-06 17:10:50 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 17:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:13:22 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.568 | nll_loss 9.41 | ppl 680.25 | wps 36093.8 | wpb 510.9 | bsz 1 | num_updates 3356 | best_loss 8.238
2022-03-06 17:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3356 updates
2022-03-06 17:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 69 @ 3356 updates, score 9.568) (writing took 2.774656515568495 seconds)
2022-03-06 17:13:24 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 17:13:24 | INFO | train | epoch 069 | loss 3.802 | nll_loss 3.581 | ppl 11.97 | wps 20633 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3356 | lr 0.000419516 | gnorm 1.446 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 15080
2022-03-06 17:13:24 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 17:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:15:36 | INFO | train_inner | epoch 070:     44 / 49 loss=3.774, nll_loss=3.553, ppl=11.73, wps=20688.4, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.476, loss_scale=32, train_wall=269, gb_free=8.8, wall=15211
2022-03-06 17:15:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:15:55 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.632 | nll_loss 9.473 | ppl 710.5 | wps 36051.3 | wpb 510.9 | bsz 1 | num_updates 3405 | best_loss 8.238
2022-03-06 17:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3405 updates
2022-03-06 17:15:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:15:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:15:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 70 @ 3405 updates, score 9.632) (writing took 2.818396456539631 seconds)
2022-03-06 17:15:58 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 17:15:58 | INFO | train | epoch 070 | loss 3.726 | nll_loss 3.503 | ppl 11.33 | wps 20664.8 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3405 | lr 0.00042564 | gnorm 1.537 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 15233
2022-03-06 17:15:58 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 17:15:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:17:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 17:18:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:18:29 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.796 | nll_loss 9.638 | ppl 796.57 | wps 36273.5 | wpb 510.9 | bsz 1 | num_updates 3452 | best_loss 8.238
2022-03-06 17:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3452 updates
2022-03-06 17:18:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:18:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 71 @ 3452 updates, score 9.796) (writing took 2.7081645131111145 seconds)
2022-03-06 17:18:32 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 17:18:32 | INFO | train | epoch 071 | loss 3.649 | nll_loss 3.423 | ppl 10.73 | wps 19803.1 | ups 0.31 | wpb 64829.4 | bsz 126.6 | num_updates 3452 | lr 0.000431514 | gnorm 1.596 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 15387
2022-03-06 17:18:32 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 17:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:20:56 | INFO | train_inner | epoch 072:     48 / 49 loss=3.618, nll_loss=3.392, ppl=10.5, wps=20289.9, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.564, loss_scale=16, train_wall=274, gb_free=8.8, wall=15531
2022-03-06 17:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:21:03 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.819 | nll_loss 9.656 | ppl 806.9 | wps 36316.3 | wpb 510.9 | bsz 1 | num_updates 3501 | best_loss 8.238
2022-03-06 17:21:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3501 updates
2022-03-06 17:21:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:21:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:21:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 72 @ 3501 updates, score 9.819) (writing took 2.6789490338414907 seconds)
2022-03-06 17:21:06 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 17:21:06 | INFO | train | epoch 072 | loss 3.574 | nll_loss 3.346 | ppl 10.17 | wps 20672.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3501 | lr 0.000437637 | gnorm 1.529 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 15541
2022-03-06 17:21:06 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 17:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:23:37 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.827 | nll_loss 9.668 | ppl 813.36 | wps 36354.8 | wpb 510.9 | bsz 1 | num_updates 3550 | best_loss 8.238
2022-03-06 17:23:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3550 updates
2022-03-06 17:23:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:23:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:23:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 73 @ 3550 updates, score 9.827) (writing took 2.6859805826097727 seconds)
2022-03-06 17:23:40 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 17:23:40 | INFO | train | epoch 073 | loss 3.5 | nll_loss 3.27 | ppl 9.65 | wps 20657.1 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3550 | lr 0.000443761 | gnorm 1.563 | loss_scale 16 | train_wall 132 | gb_free 8.8 | wall 15695
2022-03-06 17:23:40 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 17:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:26:11 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.029 | nll_loss 9.863 | ppl 931.19 | wps 36359.3 | wpb 510.9 | bsz 1 | num_updates 3599 | best_loss 8.238
2022-03-06 17:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3599 updates
2022-03-06 17:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 74 @ 3599 updates, score 10.029) (writing took 3.4533900786191225 seconds)
2022-03-06 17:26:14 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 17:26:14 | INFO | train | epoch 074 | loss 3.417 | nll_loss 3.185 | ppl 9.09 | wps 20586 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3599 | lr 0.000449885 | gnorm 1.501 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 15849
2022-03-06 17:26:14 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 17:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:26:17 | INFO | train_inner | epoch 075:      1 / 49 loss=3.458, nll_loss=3.227, ppl=9.36, wps=20071.5, ups=0.31, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.539, loss_scale=32, train_wall=267, gb_free=8.8, wall=15852
2022-03-06 17:26:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:28:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:28:45 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.048 | nll_loss 9.886 | ppl 946.25 | wps 35604.4 | wpb 510.9 | bsz 1 | num_updates 3647 | best_loss 8.238
2022-03-06 17:28:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3647 updates
2022-03-06 17:28:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:28:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 75 @ 3647 updates, score 10.048) (writing took 3.3260573260486126 seconds)
2022-03-06 17:28:48 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 17:28:48 | INFO | train | epoch 075 | loss 3.357 | nll_loss 3.123 | ppl 8.71 | wps 20211.4 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 3647 | lr 0.000455884 | gnorm 1.685 | loss_scale 16 | train_wall 131 | gb_free 8.8 | wall 16003
2022-03-06 17:28:48 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 17:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:31:17 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.104 | nll_loss 9.936 | ppl 979.57 | wps 36388.3 | wpb 510.9 | bsz 1 | num_updates 3696 | best_loss 8.238
2022-03-06 17:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3696 updates
2022-03-06 17:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:31:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 76 @ 3696 updates, score 10.104) (writing took 3.0562513675540686 seconds)
2022-03-06 17:31:20 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 17:31:20 | INFO | train | epoch 076 | loss 3.27 | nll_loss 3.033 | ppl 8.19 | wps 20952.8 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 3696 | lr 0.000462008 | gnorm 1.524 | loss_scale 16 | train_wall 129 | gb_free 8.8 | wall 16155
2022-03-06 17:31:20 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 17:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:31:32 | INFO | train_inner | epoch 077:      4 / 49 loss=3.307, nll_loss=3.072, ppl=8.41, wps=20631.2, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.604, loss_scale=16, train_wall=268, gb_free=8.8, wall=16167
2022-03-06 17:33:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:33:54 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.153 | nll_loss 9.987 | ppl 1014.91 | wps 35642.2 | wpb 510.9 | bsz 1 | num_updates 3745 | best_loss 8.238
2022-03-06 17:33:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3745 updates
2022-03-06 17:33:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:33:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 77 @ 3745 updates, score 10.153) (writing took 3.219816669821739 seconds)
2022-03-06 17:33:58 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 17:33:58 | INFO | train | epoch 077 | loss 3.206 | nll_loss 2.967 | ppl 7.82 | wps 20127.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3745 | lr 0.000468131 | gnorm 1.607 | loss_scale 32 | train_wall 135 | gb_free 8.8 | wall 16313
2022-03-06 17:33:58 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 17:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:35:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:36:34 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.2 | nll_loss 10.039 | ppl 1052.3 | wps 35333.4 | wpb 510.9 | bsz 1 | num_updates 3793 | best_loss 8.238
2022-03-06 17:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3793 updates
2022-03-06 17:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 78 @ 3793 updates, score 10.2) (writing took 2.8960912358015776 seconds)
2022-03-06 17:36:37 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 17:36:37 | INFO | train | epoch 078 | loss 3.128 | nll_loss 2.887 | ppl 7.4 | wps 19506.6 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 3793 | lr 0.00047413 | gnorm 1.566 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 16472
2022-03-06 17:36:37 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 17:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:36:59 | INFO | train_inner | epoch 079:      7 / 49 loss=3.158, nll_loss=2.918, ppl=7.56, wps=19820.7, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.598, loss_scale=16, train_wall=280, gb_free=8.8, wall=16494
2022-03-06 17:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:39:14 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.385 | nll_loss 10.225 | ppl 1196.53 | wps 35478.5 | wpb 510.9 | bsz 1 | num_updates 3842 | best_loss 8.238
2022-03-06 17:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3842 updates
2022-03-06 17:39:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:39:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:39:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 79 @ 3842 updates, score 10.385) (writing took 3.1897848788648844 seconds)
2022-03-06 17:39:17 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 17:39:17 | INFO | train | epoch 079 | loss 3.066 | nll_loss 2.823 | ppl 7.08 | wps 19866.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3842 | lr 0.000480254 | gnorm 1.618 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 16632
2022-03-06 17:39:17 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 17:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:41:53 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.411 | nll_loss 10.238 | ppl 1207.94 | wps 34823.1 | wpb 510.9 | bsz 1 | num_updates 3891 | best_loss 8.238
2022-03-06 17:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3891 updates
2022-03-06 17:41:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:41:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 80 @ 3891 updates, score 10.411) (writing took 3.253905162215233 seconds)
2022-03-06 17:41:57 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 17:41:57 | INFO | train | epoch 080 | loss 2.994 | nll_loss 2.749 | ppl 6.72 | wps 19942.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3891 | lr 0.000486378 | gnorm 1.468 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 16792
2022-03-06 17:41:57 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 17:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:42:24 | INFO | train_inner | epoch 081:      9 / 49 loss=3.017, nll_loss=2.772, ppl=6.83, wps=19942.5, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.547, loss_scale=16, train_wall=278, gb_free=8.8, wall=16819
2022-03-06 17:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:44:32 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.471 | nll_loss 10.303 | ppl 1263.42 | wps 34311.3 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 8.238
2022-03-06 17:44:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-06 17:44:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:44:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 81 @ 3940 updates, score 10.471) (writing took 3.154022319242358 seconds)
2022-03-06 17:44:35 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 17:44:35 | INFO | train | epoch 081 | loss 2.928 | nll_loss 2.68 | ppl 6.41 | wps 20071.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.563 | loss_scale 32 | train_wall 135 | gb_free 8.8 | wall 16950
2022-03-06 17:44:35 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 17:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:44:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:47:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:47:11 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.607 | nll_loss 10.438 | ppl 1387.6 | wps 35374.7 | wpb 510.9 | bsz 1 | num_updates 3988 | best_loss 8.238
2022-03-06 17:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3988 updates
2022-03-06 17:47:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 82 @ 3988 updates, score 10.607) (writing took 2.7905510906130075 seconds)
2022-03-06 17:47:14 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 17:47:14 | INFO | train | epoch 082 | loss 2.856 | nll_loss 2.607 | ppl 6.09 | wps 19596.7 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 3988 | lr 0.0004985 | gnorm 1.572 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 17109
2022-03-06 17:47:14 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 17:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:47:51 | INFO | train_inner | epoch 083:     12 / 49 loss=2.875, nll_loss=2.626, ppl=6.17, wps=19862.8, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.565, loss_scale=16, train_wall=279, gb_free=8.8, wall=17146
2022-03-06 17:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:49:49 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.735 | nll_loss 10.571 | ppl 1520.85 | wps 35594 | wpb 510.9 | bsz 1 | num_updates 4037 | best_loss 8.238
2022-03-06 17:49:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4037 updates
2022-03-06 17:49:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:49:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 83 @ 4037 updates, score 10.735) (writing took 2.9527151752263308 seconds)
2022-03-06 17:49:52 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 17:49:52 | INFO | train | epoch 083 | loss 2.796 | nll_loss 2.544 | ppl 5.83 | wps 20049.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4037 | lr 0.000497703 | gnorm 1.576 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 17267
2022-03-06 17:49:52 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 17:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:51:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:52:27 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 10.771 | nll_loss 10.607 | ppl 1560.02 | wps 35439.8 | wpb 510.9 | bsz 1 | num_updates 4085 | best_loss 8.238
2022-03-06 17:52:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4085 updates
2022-03-06 17:52:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:52:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 84 @ 4085 updates, score 10.771) (writing took 2.8123890087008476 seconds)
2022-03-06 17:52:30 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 17:52:30 | INFO | train | epoch 084 | loss 2.723 | nll_loss 2.469 | ppl 5.54 | wps 19775.5 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 4085 | lr 0.000494771 | gnorm 1.533 | loss_scale 16 | train_wall 135 | gb_free 8.8 | wall 17425
2022-03-06 17:52:30 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 17:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:53:16 | INFO | train_inner | epoch 085:     15 / 49 loss=2.739, nll_loss=2.486, ppl=5.6, wps=19951.3, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.518, loss_scale=16, train_wall=279, gb_free=8.8, wall=17471
2022-03-06 17:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:55:05 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.813 | nll_loss 10.646 | ppl 1602.66 | wps 35650.9 | wpb 510.9 | bsz 1 | num_updates 4134 | best_loss 8.238
2022-03-06 17:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4134 updates
2022-03-06 17:55:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:55:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:55:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 85 @ 4134 updates, score 10.813) (writing took 2.791356310248375 seconds)
2022-03-06 17:55:08 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 17:55:08 | INFO | train | epoch 085 | loss 2.659 | nll_loss 2.403 | ppl 5.29 | wps 20124.1 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4134 | lr 0.00049183 | gnorm 1.518 | loss_scale 16 | train_wall 135 | gb_free 8.8 | wall 17583
2022-03-06 17:55:08 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 17:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:57:42 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.861 | nll_loss 10.691 | ppl 1653.64 | wps 35446.8 | wpb 510.9 | bsz 1 | num_updates 4183 | best_loss 8.238
2022-03-06 17:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4183 updates
2022-03-06 17:57:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 17:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 86 @ 4183 updates, score 10.861) (writing took 2.7585413847118616 seconds)
2022-03-06 17:57:45 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 17:57:45 | INFO | train | epoch 086 | loss 2.597 | nll_loss 2.338 | ppl 5.06 | wps 20164.8 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4183 | lr 0.000488941 | gnorm 1.507 | loss_scale 16 | train_wall 135 | gb_free 8.8 | wall 17740
2022-03-06 17:57:45 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 17:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:58:38 | INFO | train_inner | epoch 087:     17 / 49 loss=2.605, nll_loss=2.346, ppl=5.09, wps=20160.9, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.509, loss_scale=16, train_wall=276, gb_free=8.8, wall=17793
2022-03-06 18:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:00:22 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.002 | nll_loss 10.837 | ppl 1828.78 | wps 35713.8 | wpb 510.9 | bsz 1 | num_updates 4232 | best_loss 8.238
2022-03-06 18:00:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4232 updates
2022-03-06 18:00:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:00:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:00:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 87 @ 4232 updates, score 11.002) (writing took 2.8049809597432613 seconds)
2022-03-06 18:00:25 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 18:00:25 | INFO | train | epoch 087 | loss 2.526 | nll_loss 2.265 | ppl 4.81 | wps 19933.8 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4232 | lr 0.000486102 | gnorm 1.466 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 17900
2022-03-06 18:00:25 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 18:00:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:03:00 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.123 | nll_loss 10.949 | ppl 1977.5 | wps 35312.6 | wpb 510.9 | bsz 1 | num_updates 4281 | best_loss 8.238
2022-03-06 18:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4281 updates
2022-03-06 18:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:03:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:03:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 88 @ 4281 updates, score 11.123) (writing took 2.797094536945224 seconds)
2022-03-06 18:03:03 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 18:03:03 | INFO | train | epoch 088 | loss 2.464 | nll_loss 2.2 | ppl 4.6 | wps 20085.8 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4281 | lr 0.000483312 | gnorm 1.456 | loss_scale 32 | train_wall 135 | gb_free 8.8 | wall 18058
2022-03-06 18:03:03 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 18:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:04:02 | INFO | train_inner | epoch 089:     19 / 49 loss=2.471, nll_loss=2.208, ppl=4.62, wps=20026.6, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.456, loss_scale=32, train_wall=278, gb_free=8.8, wall=18117
2022-03-06 18:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:05:39 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.168 | nll_loss 11.001 | ppl 2049.76 | wps 35286.7 | wpb 510.9 | bsz 1 | num_updates 4330 | best_loss 8.238
2022-03-06 18:05:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4330 updates
2022-03-06 18:05:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:05:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:05:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 89 @ 4330 updates, score 11.168) (writing took 2.741455728188157 seconds)
2022-03-06 18:05:42 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 18:05:42 | INFO | train | epoch 089 | loss 2.403 | nll_loss 2.138 | ppl 4.4 | wps 19985.6 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4330 | lr 0.000480569 | gnorm 1.445 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 18217
2022-03-06 18:05:42 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 18:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:06:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:08:18 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.285 | nll_loss 11.115 | ppl 2218.4 | wps 35216.8 | wpb 510.9 | bsz 1 | num_updates 4378 | best_loss 8.238
2022-03-06 18:08:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4378 updates
2022-03-06 18:08:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:08:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:08:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 90 @ 4378 updates, score 11.285) (writing took 2.7086755614727736 seconds)
2022-03-06 18:08:21 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 18:08:21 | INFO | train | epoch 090 | loss 2.342 | nll_loss 2.075 | ppl 4.21 | wps 19598.9 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 4378 | lr 0.000477928 | gnorm 1.446 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 18376
2022-03-06 18:08:21 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 18:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:09:29 | INFO | train_inner | epoch 091:     22 / 49 loss=2.35, nll_loss=2.083, ppl=4.24, wps=19835.2, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.453, loss_scale=32, train_wall=280, gb_free=8.8, wall=18444
2022-03-06 18:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:10:57 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.365 | nll_loss 11.197 | ppl 2346.88 | wps 35042.3 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 8.238
2022-03-06 18:10:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-06 18:10:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:10:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 91 @ 4427 updates, score 11.365) (writing took 2.7990040853619576 seconds)
2022-03-06 18:11:00 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 18:11:00 | INFO | train | epoch 091 | loss 2.29 | nll_loss 2.021 | ppl 4.06 | wps 19992.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.424 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 18535
2022-03-06 18:11:00 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 18:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:12:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:13:36 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.402 | nll_loss 11.234 | ppl 2408.79 | wps 35378.5 | wpb 510.9 | bsz 1 | num_updates 4475 | best_loss 8.238
2022-03-06 18:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4475 updates
2022-03-06 18:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 92 @ 4475 updates, score 11.402) (writing took 2.688118288293481 seconds)
2022-03-06 18:13:39 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 18:13:39 | INFO | train | epoch 092 | loss 2.238 | nll_loss 1.967 | ppl 3.91 | wps 19545.8 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 4475 | lr 0.000472719 | gnorm 1.425 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 18694
2022-03-06 18:13:39 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 18:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:14:56 | INFO | train_inner | epoch 093:     25 / 49 loss=2.235, nll_loss=1.963, ppl=3.9, wps=19811.3, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.387, loss_scale=32, train_wall=281, gb_free=8.8, wall=18771
2022-03-06 18:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:16:15 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.527 | nll_loss 11.357 | ppl 2622.25 | wps 35302.9 | wpb 510.9 | bsz 1 | num_updates 4524 | best_loss 8.238
2022-03-06 18:16:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4524 updates
2022-03-06 18:16:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:16:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:16:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 93 @ 4524 updates, score 11.527) (writing took 2.7255358081310987 seconds)
2022-03-06 18:16:18 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 18:16:18 | INFO | train | epoch 093 | loss 2.183 | nll_loss 1.91 | ppl 3.76 | wps 19971 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4524 | lr 0.000470152 | gnorm 1.391 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 18853
2022-03-06 18:16:18 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 18:16:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:18:55 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.559 | nll_loss 11.389 | ppl 2682.35 | wps 34803.8 | wpb 510.9 | bsz 1 | num_updates 4573 | best_loss 8.238
2022-03-06 18:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4573 updates
2022-03-06 18:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:18:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 94 @ 4573 updates, score 11.559) (writing took 2.814524557441473 seconds)
2022-03-06 18:18:58 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 18:18:58 | INFO | train | epoch 094 | loss 2.132 | nll_loss 1.857 | ppl 3.62 | wps 19864.8 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4573 | lr 0.000467627 | gnorm 1.361 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 19013
2022-03-06 18:18:58 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 18:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:20:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:20:25 | INFO | train_inner | epoch 095:     28 / 49 loss=2.135, nll_loss=1.859, ppl=3.63, wps=19720.5, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.397, loss_scale=32, train_wall=282, gb_free=8.8, wall=19100
2022-03-06 18:20:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:21:35 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.675 | nll_loss 11.503 | ppl 2902.33 | wps 35052.7 | wpb 510.9 | bsz 1 | num_updates 4620 | best_loss 8.238
2022-03-06 18:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4620 updates
2022-03-06 18:21:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 95 @ 4620 updates, score 11.675) (writing took 2.6153144873678684 seconds)
2022-03-06 18:21:37 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 18:21:37 | INFO | train | epoch 095 | loss 2.085 | nll_loss 1.808 | ppl 3.5 | wps 19111.6 | ups 0.29 | wpb 64838.8 | bsz 126.6 | num_updates 4620 | lr 0.000465242 | gnorm 1.393 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 19173
2022-03-06 18:21:37 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 18:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:24:14 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.758 | nll_loss 11.588 | ppl 3079.08 | wps 35077.6 | wpb 510.9 | bsz 1 | num_updates 4669 | best_loss 8.238
2022-03-06 18:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4669 updates
2022-03-06 18:24:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:24:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 96 @ 4669 updates, score 11.758) (writing took 2.6733143404126167 seconds)
2022-03-06 18:24:16 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 18:24:16 | INFO | train | epoch 096 | loss 2.037 | nll_loss 1.758 | ppl 3.38 | wps 19980.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4669 | lr 0.000462794 | gnorm 1.32 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 19332
2022-03-06 18:24:16 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 18:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:25:52 | INFO | train_inner | epoch 097:     31 / 49 loss=2.031, nll_loss=1.751, ppl=3.37, wps=19823.7, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.34, loss_scale=16, train_wall=281, gb_free=8.8, wall=19427
2022-03-06 18:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:26:53 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.825 | nll_loss 11.653 | ppl 3219.26 | wps 35196.2 | wpb 510.9 | bsz 1 | num_updates 4718 | best_loss 8.238
2022-03-06 18:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4718 updates
2022-03-06 18:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:26:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 97 @ 4718 updates, score 11.825) (writing took 2.6792773008346558 seconds)
2022-03-06 18:26:55 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 18:26:55 | INFO | train | epoch 097 | loss 1.994 | nll_loss 1.713 | ppl 3.28 | wps 20003.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4718 | lr 0.000460385 | gnorm 1.338 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 19490
2022-03-06 18:26:55 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 18:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:28:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:29:32 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.939 | nll_loss 11.769 | ppl 3489.68 | wps 35187.4 | wpb 510.9 | bsz 1 | num_updates 4766 | best_loss 8.238
2022-03-06 18:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4766 updates
2022-03-06 18:29:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 98 @ 4766 updates, score 11.939) (writing took 2.7938776034861803 seconds)
2022-03-06 18:29:35 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 18:29:35 | INFO | train | epoch 098 | loss 1.951 | nll_loss 1.668 | ppl 3.18 | wps 19541.5 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 4766 | lr 0.000458061 | gnorm 1.317 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 19650
2022-03-06 18:29:35 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 18:29:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:31:20 | INFO | train_inner | epoch 099:     34 / 49 loss=1.947, nll_loss=1.664, ppl=3.17, wps=19819.7, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.312, loss_scale=16, train_wall=281, gb_free=8.8, wall=19755
2022-03-06 18:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:32:11 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.049 | nll_loss 11.879 | ppl 3767.53 | wps 35171 | wpb 510.9 | bsz 1 | num_updates 4815 | best_loss 8.238
2022-03-06 18:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4815 updates
2022-03-06 18:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:32:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 99 @ 4815 updates, score 12.049) (writing took 3.0267553236335516 seconds)
2022-03-06 18:32:14 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 18:32:14 | INFO | train | epoch 099 | loss 1.911 | nll_loss 1.626 | ppl 3.09 | wps 19939.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4815 | lr 0.000455724 | gnorm 1.329 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 19809
2022-03-06 18:32:14 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 18:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:34:50 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.127 | nll_loss 11.96 | ppl 3984.54 | wps 35281.6 | wpb 510.9 | bsz 1 | num_updates 4864 | best_loss 8.238
2022-03-06 18:34:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4864 updates
2022-03-06 18:34:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:34:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 100 @ 4864 updates, score 12.127) (writing took 3.3313888255506754 seconds)
2022-03-06 18:34:53 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 18:34:53 | INFO | train | epoch 100 | loss 1.867 | nll_loss 1.581 | ppl 2.99 | wps 19973.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4864 | lr 0.000453423 | gnorm 1.302 | loss_scale 16 | train_wall 136 | gb_free 8.8 | wall 19968
2022-03-06 18:34:53 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 18:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:36:43 | INFO | train_inner | epoch 101:     36 / 49 loss=1.861, nll_loss=1.574, ppl=2.98, wps=20042.7, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.323, loss_scale=32, train_wall=276, gb_free=8.8, wall=20078
2022-03-06 18:37:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:37:28 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.118 | nll_loss 11.948 | ppl 3950.49 | wps 34038.2 | wpb 510.9 | bsz 1 | num_updates 4913 | best_loss 8.238
2022-03-06 18:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4913 updates
2022-03-06 18:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:37:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:37:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 101 @ 4913 updates, score 12.118) (writing took 3.209094861522317 seconds)
2022-03-06 18:37:31 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 18:37:31 | INFO | train | epoch 101 | loss 1.828 | nll_loss 1.54 | ppl 2.91 | wps 20067.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 4913 | lr 0.000451156 | gnorm 1.3 | loss_scale 32 | train_wall 135 | gb_free 8.8 | wall 20127
2022-03-06 18:37:31 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 18:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:40:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:40:09 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.242 | nll_loss 12.07 | ppl 4300.23 | wps 34411.4 | wpb 510.9 | bsz 1 | num_updates 4962 | best_loss 8.238
2022-03-06 18:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4962 updates
2022-03-06 18:40:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:40:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:40:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 102 @ 4962 updates, score 12.242) (writing took 3.1765265744179487 seconds)
2022-03-06 18:40:12 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 18:40:12 | INFO | train | epoch 102 | loss 1.791 | nll_loss 1.501 | ppl 2.83 | wps 19775.2 | ups 0.3 | wpb 64858.2 | bsz 126.7 | num_updates 4962 | lr 0.000448923 | gnorm 1.298 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 20287
2022-03-06 18:40:12 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 18:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:41:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:42:13 | INFO | train_inner | epoch 103:     39 / 49 loss=1.78, nll_loss=1.49, ppl=2.81, wps=19701.9, ups=0.3, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.274, loss_scale=32, train_wall=281, gb_free=8.8, wall=20408
2022-03-06 18:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:42:48 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.314 | nll_loss 12.144 | ppl 4524.85 | wps 35339.9 | wpb 510.9 | bsz 1 | num_updates 5010 | best_loss 8.238
2022-03-06 18:42:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5010 updates
2022-03-06 18:42:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:42:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:42:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 103 @ 5010 updates, score 12.314) (writing took 3.0689285192638636 seconds)
2022-03-06 18:42:51 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 18:42:51 | INFO | train | epoch 103 | loss 1.749 | nll_loss 1.458 | ppl 2.75 | wps 19585.2 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5010 | lr 0.000446767 | gnorm 1.244 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 20446
2022-03-06 18:42:51 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 18:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:45:27 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.314 | nll_loss 12.141 | ppl 4516.81 | wps 35235.8 | wpb 510.9 | bsz 1 | num_updates 5059 | best_loss 8.238
2022-03-06 18:45:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5059 updates
2022-03-06 18:45:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:45:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:45:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 104 @ 5059 updates, score 12.314) (writing took 2.8024405874311924 seconds)
2022-03-06 18:45:30 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 18:45:30 | INFO | train | epoch 104 | loss 1.721 | nll_loss 1.428 | ppl 2.69 | wps 20007.2 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5059 | lr 0.000444598 | gnorm 1.275 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 20605
2022-03-06 18:45:30 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 18:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:47:37 | INFO | train_inner | epoch 105:     41 / 49 loss=1.71, nll_loss=1.416, ppl=2.67, wps=20017.8, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.261, loss_scale=32, train_wall=277, gb_free=8.8, wall=20732
2022-03-06 18:48:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:48:06 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.466 | nll_loss 12.295 | ppl 5023.71 | wps 35189.9 | wpb 510.9 | bsz 1 | num_updates 5108 | best_loss 8.238
2022-03-06 18:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5108 updates
2022-03-06 18:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 105 @ 5108 updates, score 12.466) (writing took 2.761233700439334 seconds)
2022-03-06 18:48:09 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 18:48:09 | INFO | train | epoch 105 | loss 1.685 | nll_loss 1.391 | ppl 2.62 | wps 19999.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5108 | lr 0.000442461 | gnorm 1.252 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 20764
2022-03-06 18:48:09 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 18:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:48:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:50:45 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.509 | nll_loss 12.336 | ppl 5170.27 | wps 35100.1 | wpb 510.9 | bsz 1 | num_updates 5156 | best_loss 8.238
2022-03-06 18:50:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5156 updates
2022-03-06 18:50:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:50:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:50:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 106 @ 5156 updates, score 12.509) (writing took 2.759592991322279 seconds)
2022-03-06 18:50:48 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 18:50:48 | INFO | train | epoch 106 | loss 1.651 | nll_loss 1.356 | ppl 2.56 | wps 19584.6 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5156 | lr 0.000440396 | gnorm 1.229 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 20923
2022-03-06 18:50:48 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 18:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:53:04 | INFO | train_inner | epoch 107:     44 / 49 loss=1.642, nll_loss=1.346, ppl=2.54, wps=19833.1, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.229, loss_scale=32, train_wall=280, gb_free=8.8, wall=21059
2022-03-06 18:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:53:24 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.599 | nll_loss 12.428 | ppl 5511.81 | wps 34420.1 | wpb 510.9 | bsz 1 | num_updates 5205 | best_loss 8.238
2022-03-06 18:53:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5205 updates
2022-03-06 18:53:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:53:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 107 @ 5205 updates, score 12.599) (writing took 3.190120652318001 seconds)
2022-03-06 18:53:27 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 18:53:27 | INFO | train | epoch 107 | loss 1.621 | nll_loss 1.324 | ppl 2.5 | wps 19934.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5205 | lr 0.000438318 | gnorm 1.222 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 21082
2022-03-06 18:53:27 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 18:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:56:03 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.706 | nll_loss 12.539 | ppl 5951.87 | wps 34241.4 | wpb 510.9 | bsz 1 | num_updates 5254 | best_loss 8.238
2022-03-06 18:56:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5254 updates
2022-03-06 18:56:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:56:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 108 @ 5254 updates, score 12.706) (writing took 3.3235086742788553 seconds)
2022-03-06 18:56:06 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 18:56:06 | INFO | train | epoch 108 | loss 1.589 | nll_loss 1.29 | ppl 2.45 | wps 20030.9 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5254 | lr 0.00043627 | gnorm 1.191 | loss_scale 64 | train_wall 135 | gb_free 8.8 | wall 21241
2022-03-06 18:56:06 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 18:56:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:56:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 18:58:32 | INFO | train_inner | epoch 109:     47 / 49 loss=1.58, nll_loss=1.281, ppl=2.43, wps=19775.2, ups=0.3, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.21, loss_scale=32, train_wall=280, gb_free=8.8, wall=21387
2022-03-06 18:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:58:43 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.718 | nll_loss 12.544 | ppl 5970.75 | wps 34749.1 | wpb 510.9 | bsz 1 | num_updates 5302 | best_loss 8.238
2022-03-06 18:58:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5302 updates
2022-03-06 18:58:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 18:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 109 @ 5302 updates, score 12.718) (writing took 2.9557804595679045 seconds)
2022-03-06 18:58:46 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 18:58:46 | INFO | train | epoch 109 | loss 1.564 | nll_loss 1.264 | ppl 2.4 | wps 19458.4 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5302 | lr 0.00043429 | gnorm 1.218 | loss_scale 32 | train_wall 137 | gb_free 8.8 | wall 21401
2022-03-06 18:58:46 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 18:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:01:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:01:22 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.855 | nll_loss 12.687 | ppl 6595.16 | wps 35246.1 | wpb 510.9 | bsz 1 | num_updates 5351 | best_loss 8.238
2022-03-06 19:01:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5351 updates
2022-03-06 19:01:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:01:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:01:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 110 @ 5351 updates, score 12.855) (writing took 2.8980211913585663 seconds)
2022-03-06 19:01:25 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 19:01:25 | INFO | train | epoch 110 | loss 1.532 | nll_loss 1.231 | ppl 2.35 | wps 19915.4 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5351 | lr 0.000432297 | gnorm 1.18 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 21561
2022-03-06 19:01:25 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 19:01:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:03:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:04:01 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.951 | nll_loss 12.781 | ppl 7036.16 | wps 35197.8 | wpb 510.9 | bsz 1 | num_updates 5399 | best_loss 8.238
2022-03-06 19:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5399 updates
2022-03-06 19:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:04:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 111 @ 5399 updates, score 12.951) (writing took 2.797078335657716 seconds)
2022-03-06 19:04:04 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 19:04:04 | INFO | train | epoch 111 | loss 1.506 | nll_loss 1.204 | ppl 2.3 | wps 19597.4 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5399 | lr 0.000430371 | gnorm 1.194 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 21719
2022-03-06 19:04:04 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 19:04:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:04:07 | INFO | train_inner | epoch 112:      1 / 49 loss=1.52, nll_loss=1.218, ppl=2.33, wps=19231.2, ups=0.3, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.19, loss_scale=32, train_wall=279, gb_free=8.8, wall=21723
2022-03-06 19:06:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:06:40 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.984 | nll_loss 12.816 | ppl 7211.84 | wps 35197.9 | wpb 510.9 | bsz 1 | num_updates 5448 | best_loss 8.238
2022-03-06 19:06:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5448 updates
2022-03-06 19:06:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 112 @ 5448 updates, score 12.984) (writing took 2.7933594845235348 seconds)
2022-03-06 19:06:43 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 19:06:43 | INFO | train | epoch 112 | loss 1.482 | nll_loss 1.178 | ppl 2.26 | wps 20011.1 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5448 | lr 0.000428432 | gnorm 1.187 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 21878
2022-03-06 19:06:43 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 19:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:09:19 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.013 | nll_loss 12.843 | ppl 7347.51 | wps 35225.8 | wpb 510.9 | bsz 1 | num_updates 5497 | best_loss 8.238
2022-03-06 19:09:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5497 updates
2022-03-06 19:09:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:09:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 113 @ 5497 updates, score 13.013) (writing took 2.790201475843787 seconds)
2022-03-06 19:09:22 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 19:09:22 | INFO | train | epoch 113 | loss 1.455 | nll_loss 1.149 | ppl 2.22 | wps 20007.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5497 | lr 0.000426518 | gnorm 1.156 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 22037
2022-03-06 19:09:22 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 19:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:09:31 | INFO | train_inner | epoch 114:      3 / 49 loss=1.466, nll_loss=1.162, ppl=2.24, wps=20030.7, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=1.17, loss_scale=32, train_wall=277, gb_free=8.8, wall=22046
2022-03-06 19:10:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:11:58 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.066 | nll_loss 12.894 | ppl 7611.4 | wps 34967.5 | wpb 510.9 | bsz 1 | num_updates 5545 | best_loss 8.238
2022-03-06 19:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5545 updates
2022-03-06 19:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:12:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:12:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 114 @ 5545 updates, score 13.066) (writing took 2.7425610814243555 seconds)
2022-03-06 19:12:01 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 19:12:01 | INFO | train | epoch 114 | loss 1.429 | nll_loss 1.123 | ppl 2.18 | wps 19602.1 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5545 | lr 0.000424668 | gnorm 1.156 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 22196
2022-03-06 19:12:01 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 19:12:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:14:37 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.168 | nll_loss 12.998 | ppl 8178.26 | wps 34978.6 | wpb 510.9 | bsz 1 | num_updates 5594 | best_loss 8.238
2022-03-06 19:14:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5594 updates
2022-03-06 19:14:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:14:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 115 @ 5594 updates, score 13.168) (writing took 2.8704603891819715 seconds)
2022-03-06 19:14:40 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 19:14:40 | INFO | train | epoch 115 | loss 1.411 | nll_loss 1.104 | ppl 2.15 | wps 19979.5 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5594 | lr 0.000422804 | gnorm 1.156 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 22355
2022-03-06 19:14:40 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 19:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:14:58 | INFO | train_inner | epoch 116:      6 / 49 loss=1.417, nll_loss=1.11, ppl=2.16, wps=19838, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.151, loss_scale=32, train_wall=280, gb_free=8.8, wall=22373
2022-03-06 19:17:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:16 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.213 | nll_loss 13.043 | ppl 8442.67 | wps 34938 | wpb 510.9 | bsz 1 | num_updates 5643 | best_loss 8.238
2022-03-06 19:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5643 updates
2022-03-06 19:17:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:17:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:17:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 116 @ 5643 updates, score 13.213) (writing took 2.7478574216365814 seconds)
2022-03-06 19:17:18 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 19:17:18 | INFO | train | epoch 116 | loss 1.386 | nll_loss 1.077 | ppl 2.11 | wps 20040.3 | ups 0.31 | wpb 64858.2 | bsz 126.7 | num_updates 5643 | lr 0.000420964 | gnorm 1.114 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 22513
2022-03-06 19:17:18 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 19:17:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:17:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:19:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:19:55 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.287 | nll_loss 13.119 | ppl 8898.37 | wps 36555.8 | wpb 510.9 | bsz 1 | num_updates 5691 | best_loss 8.238
2022-03-06 19:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5691 updates
2022-03-06 19:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:19:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:19:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 117 @ 5691 updates, score 13.287) (writing took 2.6667108722031116 seconds)
2022-03-06 19:19:57 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 19:19:57 | INFO | train | epoch 117 | loss 1.365 | nll_loss 1.055 | ppl 2.08 | wps 19562.9 | ups 0.3 | wpb 64844.1 | bsz 126.7 | num_updates 5691 | lr 0.000419185 | gnorm 1.126 | loss_scale 32 | train_wall 136 | gb_free 8.8 | wall 22673
2022-03-06 19:19:57 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 19:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:20:24 | INFO | train_inner | epoch 118:      9 / 49 loss=1.371, nll_loss=1.061, ppl=2.09, wps=19894.2, ups=0.31, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.123, loss_scale=32, train_wall=280, gb_free=8.8, wall=22700
2022-03-06 19:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:29 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.342 | nll_loss 13.168 | ppl 9203 | wps 36729.9 | wpb 510.9 | bsz 1 | num_updates 5740 | best_loss 8.238
2022-03-06 19:22:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5740 updates
2022-03-06 19:22:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:22:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 118 @ 5740 updates, score 13.342) (writing took 2.7177969440817833 seconds)
2022-03-06 19:22:32 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 19:22:32 | INFO | train | epoch 118 | loss 1.346 | nll_loss 1.035 | ppl 2.05 | wps 20623.1 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 5740 | lr 0.000417392 | gnorm 1.127 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 22827
2022-03-06 19:22:32 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 19:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:24:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:25:03 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.379 | nll_loss 13.208 | ppl 9460.66 | wps 35826 | wpb 510.9 | bsz 1 | num_updates 5788 | best_loss 8.238
2022-03-06 19:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5788 updates
2022-03-06 19:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:25:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:25:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 119 @ 5788 updates, score 13.379) (writing took 2.7313843201845884 seconds)
2022-03-06 19:25:05 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 19:25:05 | INFO | train | epoch 119 | loss 1.322 | nll_loss 1.01 | ppl 2.01 | wps 20219 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 5788 | lr 0.000415658 | gnorm 1.093 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 22981
2022-03-06 19:25:05 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 19:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:25:41 | INFO | train_inner | epoch 120:     12 / 49 loss=1.329, nll_loss=1.017, ppl=2.02, wps=20458.4, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.103, loss_scale=32, train_wall=272, gb_free=8.8, wall=23017
2022-03-06 19:27:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:27:37 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.494 | nll_loss 13.322 | ppl 10240.8 | wps 36492.7 | wpb 510.9 | bsz 1 | num_updates 5837 | best_loss 8.238
2022-03-06 19:27:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5837 updates
2022-03-06 19:27:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:27:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:27:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 120 @ 5837 updates, score 13.494) (writing took 2.700854066759348 seconds)
2022-03-06 19:27:39 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 19:27:39 | INFO | train | epoch 120 | loss 1.305 | nll_loss 0.992 | ppl 1.99 | wps 20656 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 5837 | lr 0.000413909 | gnorm 1.087 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 23134
2022-03-06 19:27:39 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 19:27:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:30:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:30:11 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.458 | nll_loss 13.288 | ppl 10001.7 | wps 36315.9 | wpb 510.9 | bsz 1 | num_updates 5886 | best_loss 8.238
2022-03-06 19:30:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5886 updates
2022-03-06 19:30:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:30:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:30:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 121 @ 5886 updates, score 13.458) (writing took 2.705875426530838 seconds)
2022-03-06 19:30:13 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 19:30:13 | INFO | train | epoch 121 | loss 1.287 | nll_loss 0.972 | ppl 1.96 | wps 20638.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 5886 | lr 0.000412183 | gnorm 1.084 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 23288
2022-03-06 19:30:13 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 19:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:30:55 | INFO | train_inner | epoch 122:     14 / 49 loss=1.291, nll_loss=0.977, ppl=1.97, wps=20677.9, ups=0.32, wpb=64867.4, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.086, loss_scale=32, train_wall=269, gb_free=8.8, wall=23330
2022-03-06 19:31:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:32:44 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.555 | nll_loss 13.387 | ppl 10708.9 | wps 36426.2 | wpb 510.9 | bsz 1 | num_updates 5934 | best_loss 8.238
2022-03-06 19:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5934 updates
2022-03-06 19:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 122 @ 5934 updates, score 13.555) (writing took 2.6915507167577744 seconds)
2022-03-06 19:32:47 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 19:32:47 | INFO | train | epoch 122 | loss 1.268 | nll_loss 0.952 | ppl 1.93 | wps 20263.1 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 5934 | lr 0.000410512 | gnorm 1.08 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 23442
2022-03-06 19:32:47 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 19:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:35:17 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.567 | nll_loss 13.397 | ppl 10787.3 | wps 36866.8 | wpb 510.9 | bsz 1 | num_updates 5983 | best_loss 8.238
2022-03-06 19:35:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5983 updates
2022-03-06 19:35:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:35:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 123 @ 5983 updates, score 13.567) (writing took 2.6591191831976175 seconds)
2022-03-06 19:35:19 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 19:35:19 | INFO | train | epoch 123 | loss 1.253 | nll_loss 0.937 | ppl 1.91 | wps 20848.1 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 5983 | lr 0.000408828 | gnorm 1.093 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 23594
2022-03-06 19:35:19 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 19:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:36:10 | INFO | train_inner | epoch 124:     17 / 49 loss=1.254, nll_loss=0.938, ppl=1.92, wps=20636.4, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.081, loss_scale=32, train_wall=270, gb_free=8.8, wall=23645
2022-03-06 19:37:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:37:48 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.592 | nll_loss 13.424 | ppl 10991 | wps 36743.5 | wpb 510.9 | bsz 1 | num_updates 6032 | best_loss 8.238
2022-03-06 19:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6032 updates
2022-03-06 19:37:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 124 @ 6032 updates, score 13.592) (writing took 2.6601442135870457 seconds)
2022-03-06 19:37:51 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 19:37:51 | INFO | train | epoch 124 | loss 1.231 | nll_loss 0.914 | ppl 1.88 | wps 20944.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6032 | lr 0.000407164 | gnorm 1.047 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 23746
2022-03-06 19:37:51 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 19:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:38:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:40:20 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.71 | nll_loss 13.538 | ppl 11893.4 | wps 36447.6 | wpb 510.9 | bsz 1 | num_updates 6080 | best_loss 8.238
2022-03-06 19:40:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6080 updates
2022-03-06 19:40:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 125 @ 6080 updates, score 13.71) (writing took 2.6984409391880035 seconds)
2022-03-06 19:40:23 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 19:40:23 | INFO | train | epoch 125 | loss 1.218 | nll_loss 0.9 | ppl 1.87 | wps 20490.4 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 6080 | lr 0.000405554 | gnorm 1.053 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 23898
2022-03-06 19:40:23 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 19:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:41:22 | INFO | train_inner | epoch 126:     20 / 49 loss=1.219, nll_loss=0.901, ppl=1.87, wps=20755.6, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.041, loss_scale=32, train_wall=268, gb_free=8.8, wall=23957
2022-03-06 19:42:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:42:52 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.749 | nll_loss 13.58 | ppl 12247.1 | wps 36920.3 | wpb 510.9 | bsz 1 | num_updates 6129 | best_loss 8.238
2022-03-06 19:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6129 updates
2022-03-06 19:42:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:42:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:42:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 126 @ 6129 updates, score 13.749) (writing took 2.6317530497908592 seconds)
2022-03-06 19:42:55 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 19:42:55 | INFO | train | epoch 126 | loss 1.202 | nll_loss 0.883 | ppl 1.84 | wps 20951.2 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6129 | lr 0.000403929 | gnorm 1.047 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 24050
2022-03-06 19:42:55 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 19:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:45:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:45:24 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.864 | nll_loss 13.696 | ppl 13269 | wps 36427 | wpb 510.9 | bsz 1 | num_updates 6177 | best_loss 8.238
2022-03-06 19:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6177 updates
2022-03-06 19:45:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 127 @ 6177 updates, score 13.864) (writing took 2.808434847742319 seconds)
2022-03-06 19:45:27 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 19:45:27 | INFO | train | epoch 127 | loss 1.188 | nll_loss 0.868 | ppl 1.83 | wps 20473.9 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 6177 | lr 0.000402357 | gnorm 1.037 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 24202
2022-03-06 19:45:27 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 19:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:46:35 | INFO | train_inner | epoch 128:     23 / 49 loss=1.188, nll_loss=0.868, ppl=1.83, wps=20704.8, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=1.042, loss_scale=32, train_wall=269, gb_free=8.8, wall=24271
2022-03-06 19:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:47:58 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.822 | nll_loss 13.653 | ppl 12880.6 | wps 36416.4 | wpb 510.9 | bsz 1 | num_updates 6226 | best_loss 8.238
2022-03-06 19:47:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6226 updates
2022-03-06 19:47:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:48:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:48:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 128 @ 6226 updates, score 13.822) (writing took 2.7738337200134993 seconds)
2022-03-06 19:48:00 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 19:48:00 | INFO | train | epoch 128 | loss 1.174 | nll_loss 0.854 | ppl 1.81 | wps 20674.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6226 | lr 0.00040077 | gnorm 1.035 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 24356
2022-03-06 19:48:00 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 19:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:50:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:50:31 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.887 | nll_loss 13.717 | ppl 13463.9 | wps 36390.8 | wpb 510.9 | bsz 1 | num_updates 6275 | best_loss 8.238
2022-03-06 19:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6275 updates
2022-03-06 19:50:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:50:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 129 @ 6275 updates, score 13.887) (writing took 2.657058132812381 seconds)
2022-03-06 19:50:34 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 19:50:34 | INFO | train | epoch 129 | loss 1.158 | nll_loss 0.837 | ppl 1.79 | wps 20712.2 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6275 | lr 0.000399202 | gnorm 1.009 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 24509
2022-03-06 19:50:34 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 19:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:49 | INFO | train_inner | epoch 130:     25 / 49 loss=1.16, nll_loss=0.839, ppl=1.79, wps=20707.3, ups=0.32, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=1.021, loss_scale=32, train_wall=269, gb_free=8.8, wall=24584
2022-03-06 19:52:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:53:05 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.858 | nll_loss 13.688 | ppl 13200.8 | wps 36459.2 | wpb 510.9 | bsz 1 | num_updates 6324 | best_loss 8.238
2022-03-06 19:53:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6324 updates
2022-03-06 19:53:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:53:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:53:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 130 @ 6324 updates, score 13.858) (writing took 2.5603384394198656 seconds)
2022-03-06 19:53:07 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 19:53:07 | INFO | train | epoch 130 | loss 1.147 | nll_loss 0.825 | ppl 1.77 | wps 20742.3 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6324 | lr 0.000397653 | gnorm 1.018 | loss_scale 64 | train_wall 131 | gb_free 8.8 | wall 24662
2022-03-06 19:53:07 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 19:53:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:54:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 19:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:55:38 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.999 | nll_loss 13.835 | ppl 14615.4 | wps 36465.1 | wpb 510.9 | bsz 1 | num_updates 6372 | best_loss 8.238
2022-03-06 19:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6372 updates
2022-03-06 19:55:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:55:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:55:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 131 @ 6372 updates, score 13.999) (writing took 2.6449441853910685 seconds)
2022-03-06 19:55:40 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 19:55:40 | INFO | train | epoch 131 | loss 1.131 | nll_loss 0.808 | ppl 1.75 | wps 20325.3 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 6372 | lr 0.000396152 | gnorm 1.013 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 24815
2022-03-06 19:55:40 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 19:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:57:04 | INFO | train_inner | epoch 132:     28 / 49 loss=1.131, nll_loss=0.808, ppl=1.75, wps=20577.9, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=1.007, loss_scale=32, train_wall=270, gb_free=8.8, wall=24899
2022-03-06 19:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:58:11 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 14.034 | nll_loss 13.866 | ppl 14934.8 | wps 36582 | wpb 510.9 | bsz 1 | num_updates 6421 | best_loss 8.238
2022-03-06 19:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6421 updates
2022-03-06 19:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 19:58:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 132 @ 6421 updates, score 14.034) (writing took 2.665626421570778 seconds)
2022-03-06 19:58:14 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 19:58:14 | INFO | train | epoch 132 | loss 1.117 | nll_loss 0.794 | ppl 1.73 | wps 20724.9 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6421 | lr 0.000394638 | gnorm 0.977 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 24969
2022-03-06 19:58:14 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 19:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:00:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:44 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 14.065 | nll_loss 13.896 | ppl 15246 | wps 36407.9 | wpb 510.9 | bsz 1 | num_updates 6470 | best_loss 8.238
2022-03-06 20:00:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6470 updates
2022-03-06 20:00:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 133 @ 6470 updates, score 14.065) (writing took 2.7329279389232397 seconds)
2022-03-06 20:00:47 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 20:00:47 | INFO | train | epoch 133 | loss 1.107 | nll_loss 0.783 | ppl 1.72 | wps 20711.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6470 | lr 0.000393141 | gnorm 0.979 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 25122
2022-03-06 20:00:47 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 20:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:02:20 | INFO | train_inner | epoch 134:     31 / 49 loss=1.107, nll_loss=0.783, ppl=1.72, wps=20537.2, ups=0.32, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.987, loss_scale=32, train_wall=271, gb_free=8.8, wall=25215
2022-03-06 20:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:03:18 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 14.118 | nll_loss 13.95 | ppl 15829.2 | wps 36325.9 | wpb 510.9 | bsz 1 | num_updates 6518 | best_loss 8.238
2022-03-06 20:03:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6518 updates
2022-03-06 20:03:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:03:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:03:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 134 @ 6518 updates, score 14.118) (writing took 2.5988811310380697 seconds)
2022-03-06 20:03:21 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 20:03:21 | INFO | train | epoch 134 | loss 1.099 | nll_loss 0.774 | ppl 1.71 | wps 20270.5 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 6518 | lr 0.00039169 | gnorm 1.015 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 25276
2022-03-06 20:03:21 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 20:03:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:05:51 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 14.088 | nll_loss 13.921 | ppl 15507.3 | wps 36418.1 | wpb 510.9 | bsz 1 | num_updates 6567 | best_loss 8.238
2022-03-06 20:05:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6567 updates
2022-03-06 20:05:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:05:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:05:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 135 @ 6567 updates, score 14.088) (writing took 2.5477685630321503 seconds)
2022-03-06 20:05:53 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 20:05:53 | INFO | train | epoch 135 | loss 1.085 | nll_loss 0.759 | ppl 1.69 | wps 20788.7 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6567 | lr 0.000390226 | gnorm 0.968 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 25429
2022-03-06 20:05:53 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 20:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:07:32 | INFO | train_inner | epoch 136:     33 / 49 loss=1.083, nll_loss=0.757, ppl=1.69, wps=20775.7, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.977, loss_scale=32, train_wall=268, gb_free=8.8, wall=25527
2022-03-06 20:08:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:08:25 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 14.176 | nll_loss 14.007 | ppl 16467.2 | wps 36411 | wpb 510.9 | bsz 1 | num_updates 6615 | best_loss 8.238
2022-03-06 20:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6615 updates
2022-03-06 20:08:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 136 @ 6615 updates, score 14.176) (writing took 2.6071820221841335 seconds)
2022-03-06 20:08:27 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 20:08:27 | INFO | train | epoch 136 | loss 1.073 | nll_loss 0.746 | ppl 1.68 | wps 20240.1 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 6615 | lr 0.000388808 | gnorm 0.972 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 25582
2022-03-06 20:08:27 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 20:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:10:59 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 14.143 | nll_loss 13.974 | ppl 16089 | wps 36380.7 | wpb 510.9 | bsz 1 | num_updates 6664 | best_loss 8.238
2022-03-06 20:10:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6664 updates
2022-03-06 20:10:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:11:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:11:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 137 @ 6664 updates, score 14.143) (writing took 2.5350987147539854 seconds)
2022-03-06 20:11:02 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 20:11:02 | INFO | train | epoch 137 | loss 1.061 | nll_loss 0.734 | ppl 1.66 | wps 20569.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6664 | lr 0.000387376 | gnorm 0.964 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 25737
2022-03-06 20:11:02 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 20:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:12:49 | INFO | train_inner | epoch 138:     36 / 49 loss=1.059, nll_loss=0.732, ppl=1.66, wps=20447.4, ups=0.32, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.961, loss_scale=32, train_wall=272, gb_free=8.8, wall=25844
2022-03-06 20:13:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:13:33 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 14.182 | nll_loss 14.015 | ppl 16549.7 | wps 36499.7 | wpb 510.9 | bsz 1 | num_updates 6713 | best_loss 8.238
2022-03-06 20:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6713 updates
2022-03-06 20:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 138 @ 6713 updates, score 14.182) (writing took 2.8998509123921394 seconds)
2022-03-06 20:13:36 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 20:13:36 | INFO | train | epoch 138 | loss 1.049 | nll_loss 0.722 | ppl 1.65 | wps 20642.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6713 | lr 0.000385959 | gnorm 0.941 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 25891
2022-03-06 20:13:36 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 20:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:15:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:16:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:16:06 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 14.297 | nll_loss 14.13 | ppl 17934.7 | wps 36467.5 | wpb 510.9 | bsz 1 | num_updates 6761 | best_loss 8.238
2022-03-06 20:16:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6761 updates
2022-03-06 20:16:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:16:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 139 @ 6761 updates, score 14.297) (writing took 3.1606365758925676 seconds)
2022-03-06 20:16:10 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 20:16:10 | INFO | train | epoch 139 | loss 1.038 | nll_loss 0.71 | ppl 1.64 | wps 20221.5 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 6761 | lr 0.000384587 | gnorm 0.942 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 26045
2022-03-06 20:16:10 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 20:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:18:06 | INFO | train_inner | epoch 140:     39 / 49 loss=1.037, nll_loss=0.709, ppl=1.63, wps=20491.9, ups=0.32, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.935, loss_scale=32, train_wall=271, gb_free=8.8, wall=26161
2022-03-06 20:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:18:40 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 14.332 | nll_loss 14.166 | ppl 18387.2 | wps 35953.2 | wpb 510.9 | bsz 1 | num_updates 6810 | best_loss 8.238
2022-03-06 20:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6810 updates
2022-03-06 20:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 140 @ 6810 updates, score 14.332) (writing took 3.261287685483694 seconds)
2022-03-06 20:18:44 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 20:18:44 | INFO | train | epoch 140 | loss 1.03 | nll_loss 0.702 | ppl 1.63 | wps 20637.3 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6810 | lr 0.000383201 | gnorm 0.929 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 26199
2022-03-06 20:18:44 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 20:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:21:15 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 14.352 | nll_loss 14.186 | ppl 18636 | wps 35234.9 | wpb 510.9 | bsz 1 | num_updates 6859 | best_loss 8.238
2022-03-06 20:21:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6859 updates
2022-03-06 20:21:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:21:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 141 @ 6859 updates, score 14.352) (writing took 3.345761176198721 seconds)
2022-03-06 20:21:18 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-06 20:21:18 | INFO | train | epoch 141 | loss 1.023 | nll_loss 0.694 | ppl 1.62 | wps 20560.1 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6859 | lr 0.00038183 | gnorm 0.93 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 26353
2022-03-06 20:21:18 | INFO | fairseq.trainer | begin training epoch 142
2022-03-06 20:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:22:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:23:24 | INFO | train_inner | epoch 142:     42 / 49 loss=1.019, nll_loss=0.69, ppl=1.61, wps=20418.5, ups=0.31, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.923, loss_scale=32, train_wall=271, gb_free=8.8, wall=26479
2022-03-06 20:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:23:49 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 14.466 | nll_loss 14.299 | ppl 20150.9 | wps 35259.6 | wpb 510.9 | bsz 1 | num_updates 6907 | best_loss 8.238
2022-03-06 20:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6907 updates
2022-03-06 20:23:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:23:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 142 @ 6907 updates, score 14.466) (writing took 3.210689961910248 seconds)
2022-03-06 20:23:52 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-06 20:23:52 | INFO | train | epoch 142 | loss 1.011 | nll_loss 0.682 | ppl 1.6 | wps 20170.8 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 6907 | lr 0.000380501 | gnorm 0.922 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 26508
2022-03-06 20:23:52 | INFO | fairseq.trainer | begin training epoch 143
2022-03-06 20:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:26:24 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 14.443 | nll_loss 14.275 | ppl 19828.5 | wps 35066.2 | wpb 510.9 | bsz 1 | num_updates 6956 | best_loss 8.238
2022-03-06 20:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6956 updates
2022-03-06 20:26:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 143 @ 6956 updates, score 14.443) (writing took 3.16274600289762 seconds)
2022-03-06 20:26:28 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-06 20:26:28 | INFO | train | epoch 143 | loss 1.002 | nll_loss 0.672 | ppl 1.59 | wps 20479.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 6956 | lr 0.000379158 | gnorm 0.906 | loss_scale 32 | train_wall 132 | gb_free 8.8 | wall 26663
2022-03-06 20:26:28 | INFO | fairseq.trainer | begin training epoch 144
2022-03-06 20:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:28:38 | INFO | train_inner | epoch 144:     44 / 49 loss=0.999, nll_loss=0.669, ppl=1.59, wps=20611.6, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.91, loss_scale=32, train_wall=268, gb_free=8.8, wall=26793
2022-03-06 20:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:28:58 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 14.449 | nll_loss 14.284 | ppl 19948.7 | wps 36272 | wpb 510.9 | bsz 1 | num_updates 7005 | best_loss 8.238
2022-03-06 20:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7005 updates
2022-03-06 20:28:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:29:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:29:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 144 @ 7005 updates, score 14.449) (writing took 2.9178155940026045 seconds)
2022-03-06 20:29:00 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-06 20:29:00 | INFO | train | epoch 144 | loss 0.994 | nll_loss 0.663 | ppl 1.58 | wps 20800.4 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7005 | lr 0.00037783 | gnorm 0.908 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 26816
2022-03-06 20:29:00 | INFO | fairseq.trainer | begin training epoch 145
2022-03-06 20:29:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:31:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:31:28 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 14.484 | nll_loss 14.318 | ppl 20428.7 | wps 37170.4 | wpb 510.9 | bsz 1 | num_updates 7053 | best_loss 8.238
2022-03-06 20:31:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7053 updates
2022-03-06 20:31:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:31:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:31:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 145 @ 7053 updates, score 14.484) (writing took 2.829360628500581 seconds)
2022-03-06 20:31:30 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-06 20:31:30 | INFO | train | epoch 145 | loss 0.985 | nll_loss 0.654 | ppl 1.57 | wps 20764.2 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 7053 | lr 0.000376542 | gnorm 0.908 | loss_scale 32 | train_wall 128 | gb_free 8.8 | wall 26965
2022-03-06 20:31:30 | INFO | fairseq.trainer | begin training epoch 146
2022-03-06 20:31:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:33:47 | INFO | train_inner | epoch 146:     47 / 49 loss=0.983, nll_loss=0.652, ppl=1.57, wps=20983.9, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.905, loss_scale=32, train_wall=264, gb_free=8.8, wall=27103
2022-03-06 20:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:33:58 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 14.518 | nll_loss 14.354 | ppl 20938.7 | wps 37257.5 | wpb 510.9 | bsz 1 | num_updates 7102 | best_loss 8.238
2022-03-06 20:33:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7102 updates
2022-03-06 20:33:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:34:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:34:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 146 @ 7102 updates, score 14.518) (writing took 3.2099020145833492 seconds)
2022-03-06 20:34:01 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-06 20:34:01 | INFO | train | epoch 146 | loss 0.978 | nll_loss 0.646 | ppl 1.57 | wps 21097.3 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 7102 | lr 0.00037524 | gnorm 0.899 | loss_scale 32 | train_wall 129 | gb_free 8.8 | wall 27116
2022-03-06 20:34:01 | INFO | fairseq.trainer | begin training epoch 147
2022-03-06 20:34:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:35:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:36:28 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 14.547 | nll_loss 14.383 | ppl 21362.1 | wps 36501.3 | wpb 510.9 | bsz 1 | num_updates 7150 | best_loss 8.238
2022-03-06 20:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7150 updates
2022-03-06 20:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 147 @ 7150 updates, score 14.547) (writing took 3.3272980712354183 seconds)
2022-03-06 20:36:31 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-06 20:36:31 | INFO | train | epoch 147 | loss 0.965 | nll_loss 0.634 | ppl 1.55 | wps 20720.5 | ups 0.32 | wpb 64844.1 | bsz 126.7 | num_updates 7150 | lr 0.000373979 | gnorm 0.871 | loss_scale 32 | train_wall 128 | gb_free 8.8 | wall 27266
2022-03-06 20:36:31 | INFO | fairseq.trainer | begin training epoch 148
2022-03-06 20:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:38:59 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 14.597 | nll_loss 14.432 | ppl 22097.6 | wps 36318.5 | wpb 510.9 | bsz 1 | num_updates 7199 | best_loss 8.238
2022-03-06 20:38:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7199 updates
2022-03-06 20:38:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 148 @ 7199 updates, score 14.597) (writing took 3.378427892923355 seconds)
2022-03-06 20:39:02 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-06 20:39:02 | INFO | train | epoch 148 | loss 0.961 | nll_loss 0.63 | ppl 1.55 | wps 21022.6 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7199 | lr 0.000372704 | gnorm 0.889 | loss_scale 32 | train_wall 129 | gb_free 8.8 | wall 27418
2022-03-06 20:39:02 | INFO | fairseq.trainer | begin training epoch 149
2022-03-06 20:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:39:05 | INFO | train_inner | epoch 149:      1 / 49 loss=0.964, nll_loss=0.632, ppl=1.55, wps=20300.8, ups=0.31, wpb=64544.1, bsz=126.1, num_updates=7200, lr=0.000372678, gnorm=0.884, loss_scale=32, train_wall=263, gb_free=8.8, wall=27421
2022-03-06 20:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:41:32 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 14.584 | nll_loss 14.418 | ppl 21897.1 | wps 35443.7 | wpb 510.9 | bsz 1 | num_updates 7248 | best_loss 8.238
2022-03-06 20:41:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7248 updates
2022-03-06 20:41:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:41:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 149 @ 7248 updates, score 14.584) (writing took 3.162574315443635 seconds)
2022-03-06 20:41:35 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-06 20:41:35 | INFO | train | epoch 149 | loss 0.956 | nll_loss 0.624 | ppl 1.54 | wps 20849.6 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7248 | lr 0.000371442 | gnorm 0.906 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 27570
2022-03-06 20:41:35 | INFO | fairseq.trainer | begin training epoch 150
2022-03-06 20:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:42:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:44:04 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 14.69 | nll_loss 14.526 | ppl 23589.3 | wps 36732.1 | wpb 510.9 | bsz 1 | num_updates 7296 | best_loss 8.238
2022-03-06 20:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7296 updates
2022-03-06 20:44:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:44:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 150 @ 7296 updates, score 14.69) (writing took 3.4336749147623777 seconds)
2022-03-06 20:44:08 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-06 20:44:08 | INFO | train | epoch 150 | loss 0.943 | nll_loss 0.61 | ppl 1.53 | wps 20372.8 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 7296 | lr 0.000370218 | gnorm 0.868 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 27723
2022-03-06 20:44:08 | INFO | fairseq.trainer | begin training epoch 151
2022-03-06 20:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:44:20 | INFO | train_inner | epoch 151:      4 / 49 loss=0.948, nll_loss=0.615, ppl=1.53, wps=20642.5, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7300, lr=0.000370117, gnorm=0.887, loss_scale=32, train_wall=268, gb_free=8.8, wall=27735
2022-03-06 20:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:46:38 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 14.602 | nll_loss 14.438 | ppl 22194.7 | wps 35994.4 | wpb 510.9 | bsz 1 | num_updates 7345 | best_loss 8.238
2022-03-06 20:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7345 updates
2022-03-06 20:46:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:46:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 151 @ 7345 updates, score 14.602) (writing took 2.958552185446024 seconds)
2022-03-06 20:46:41 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-06 20:46:41 | INFO | train | epoch 151 | loss 0.938 | nll_loss 0.605 | ppl 1.52 | wps 20723.5 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7345 | lr 0.000368981 | gnorm 0.878 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 27876
2022-03-06 20:46:41 | INFO | fairseq.trainer | begin training epoch 152
2022-03-06 20:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:49:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:49:11 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 14.68 | nll_loss 14.518 | ppl 23460.5 | wps 35588 | wpb 510.9 | bsz 1 | num_updates 7394 | best_loss 8.238
2022-03-06 20:49:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7394 updates
2022-03-06 20:49:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:49:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:49:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 152 @ 7394 updates, score 14.68) (writing took 3.281969813629985 seconds)
2022-03-06 20:49:14 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-06 20:49:14 | INFO | train | epoch 152 | loss 0.93 | nll_loss 0.597 | ppl 1.51 | wps 20719 | ups 0.32 | wpb 64858.2 | bsz 126.7 | num_updates 7394 | lr 0.000367756 | gnorm 0.857 | loss_scale 32 | train_wall 130 | gb_free 8.8 | wall 28029
2022-03-06 20:49:14 | INFO | fairseq.trainer | begin training epoch 153
2022-03-06 20:49:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:49:32 | INFO | train_inner | epoch 153:      6 / 49 loss=0.933, nll_loss=0.6, ppl=1.52, wps=20753.6, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.864, loss_scale=64, train_wall=267, gb_free=8.8, wall=28047
2022-03-06 20:50:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:51:44 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 14.698 | nll_loss 14.535 | ppl 23742 | wps 37146.7 | wpb 510.9 | bsz 1 | num_updates 7442 | best_loss 8.238
2022-03-06 20:51:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7442 updates
2022-03-06 20:51:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:51:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:51:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 153 @ 7442 updates, score 14.698) (writing took 3.0278981402516365 seconds)
2022-03-06 20:51:47 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-06 20:51:47 | INFO | train | epoch 153 | loss 0.922 | nll_loss 0.588 | ppl 1.5 | wps 20342 | ups 0.31 | wpb 64844.1 | bsz 126.7 | num_updates 7442 | lr 0.000366569 | gnorm 0.842 | loss_scale 32 | train_wall 131 | gb_free 8.8 | wall 28182
2022-03-06 20:51:47 | INFO | fairseq.trainer | begin training epoch 154
2022-03-06 20:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:54:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:54:14 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 14.753 | nll_loss 14.588 | ppl 24619.3 | wps 36222.2 | wpb 510.9 | bsz 1 | num_updates 7491 | best_loss 8.238
2022-03-06 20:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7491 updates
2022-03-06 20:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:54:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:54:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 154 @ 7491 updates, score 14.753) (writing took 2.833508500829339 seconds)
2022-03-06 20:54:17 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-06 20:54:17 | INFO | train | epoch 154 | loss 0.916 | nll_loss 0.582 | ppl 1.5 | wps 21214.4 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 7491 | lr 0.000365368 | gnorm 0.831 | loss_scale 32 | train_wall 128 | gb_free 8.8 | wall 28332
2022-03-06 20:54:17 | INFO | fairseq.trainer | begin training epoch 155
2022-03-06 20:54:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:54:43 | INFO | train_inner | epoch 155:      9 / 49 loss=0.918, nll_loss=0.584, ppl=1.5, wps=20850.4, ups=0.32, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.843, loss_scale=32, train_wall=266, gb_free=8.8, wall=28359
2022-03-06 20:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:56:43 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 14.752 | nll_loss 14.592 | ppl 24695 | wps 38362.8 | wpb 510.9 | bsz 1 | num_updates 7540 | best_loss 8.238
2022-03-06 20:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7540 updates
2022-03-06 20:56:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:56:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 155 @ 7540 updates, score 14.752) (writing took 2.5867459159344435 seconds)
2022-03-06 20:56:46 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-06 20:56:46 | INFO | train | epoch 155 | loss 0.914 | nll_loss 0.58 | ppl 1.49 | wps 21346.9 | ups 0.33 | wpb 64858.2 | bsz 126.7 | num_updates 7540 | lr 0.000364179 | gnorm 0.849 | loss_scale 32 | train_wall 128 | gb_free 8.8 | wall 28481
2022-03-06 20:56:46 | INFO | fairseq.trainer | begin training epoch 156
2022-03-06 20:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:57:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:59:09 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 14.712 | nll_loss 14.549 | ppl 23965.6 | wps 38146.4 | wpb 510.9 | bsz 1 | num_updates 7588 | best_loss 8.238
2022-03-06 20:59:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7588 updates
2022-03-06 20:59:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:59:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 20:59:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 156 @ 7588 updates, score 14.712) (writing took 2.674896277487278 seconds)
2022-03-06 20:59:12 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-06 20:59:12 | INFO | train | epoch 156 | loss 0.904 | nll_loss 0.569 | ppl 1.48 | wps 21302.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7588 | lr 0.000363025 | gnorm 0.838 | loss_scale 32 | train_wall 125 | gb_free 8.8 | wall 28627
2022-03-06 20:59:12 | INFO | fairseq.trainer | begin training epoch 157
2022-03-06 20:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:46 | INFO | train_inner | epoch 157:     12 / 49 loss=0.906, nll_loss=0.571, ppl=1.49, wps=21427.6, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.835, loss_scale=32, train_wall=259, gb_free=8.8, wall=28661
2022-03-06 21:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:01:35 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 14.796 | nll_loss 14.634 | ppl 25428.1 | wps 37573.4 | wpb 510.9 | bsz 1 | num_updates 7637 | best_loss 8.238
2022-03-06 21:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7637 updates
2022-03-06 21:01:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:01:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 157 @ 7637 updates, score 14.796) (writing took 2.6425452828407288 seconds)
2022-03-06 21:01:38 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-06 21:01:38 | INFO | train | epoch 157 | loss 0.897 | nll_loss 0.563 | ppl 1.48 | wps 21764.9 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7637 | lr 0.000361858 | gnorm 0.831 | loss_scale 32 | train_wall 125 | gb_free 8.8 | wall 28773
2022-03-06 21:01:38 | INFO | fairseq.trainer | begin training epoch 158
2022-03-06 21:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:01 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 14.717 | nll_loss 14.555 | ppl 24075.1 | wps 38455.3 | wpb 510.9 | bsz 1 | num_updates 7686 | best_loss 8.238
2022-03-06 21:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7686 updates
2022-03-06 21:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 158 @ 7686 updates, score 14.717) (writing took 2.596233667805791 seconds)
2022-03-06 21:04:03 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-06 21:04:03 | INFO | train | epoch 158 | loss 0.891 | nll_loss 0.556 | ppl 1.47 | wps 21889.6 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7686 | lr 0.000360703 | gnorm 0.83 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 28918
2022-03-06 21:04:03 | INFO | fairseq.trainer | begin training epoch 159
2022-03-06 21:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:04:46 | INFO | train_inner | epoch 159:     15 / 49 loss=0.893, nll_loss=0.558, ppl=1.47, wps=21652, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.83, loss_scale=32, train_wall=256, gb_free=8.8, wall=28961
2022-03-06 21:06:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:06:26 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 14.796 | nll_loss 14.635 | ppl 25448.6 | wps 38449.5 | wpb 510.9 | bsz 1 | num_updates 7734 | best_loss 8.238
2022-03-06 21:06:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7734 updates
2022-03-06 21:06:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:06:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:06:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 159 @ 7734 updates, score 14.796) (writing took 2.6975392773747444 seconds)
2022-03-06 21:06:29 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-06 21:06:29 | INFO | train | epoch 159 | loss 0.885 | nll_loss 0.55 | ppl 1.46 | wps 21364.3 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7734 | lr 0.000359582 | gnorm 0.828 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 29064
2022-03-06 21:06:29 | INFO | fairseq.trainer | begin training epoch 160
2022-03-06 21:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:08:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:08:52 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 14.81 | nll_loss 14.65 | ppl 25700.9 | wps 38146.2 | wpb 510.9 | bsz 1 | num_updates 7783 | best_loss 8.238
2022-03-06 21:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7783 updates
2022-03-06 21:08:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:08:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:08:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 160 @ 7783 updates, score 14.81) (writing took 2.5727664679288864 seconds)
2022-03-06 21:08:54 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-06 21:08:54 | INFO | train | epoch 160 | loss 0.878 | nll_loss 0.543 | ppl 1.46 | wps 21858.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7783 | lr 0.000358448 | gnorm 0.81 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 29210
2022-03-06 21:08:54 | INFO | fairseq.trainer | begin training epoch 161
2022-03-06 21:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:09:42 | INFO | train_inner | epoch 161:     17 / 49 loss=0.879, nll_loss=0.544, ppl=1.46, wps=21864, ups=0.34, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.821, loss_scale=32, train_wall=254, gb_free=8.8, wall=29258
2022-03-06 21:10:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:11:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:11:17 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 14.869 | nll_loss 14.707 | ppl 26748 | wps 38483.2 | wpb 510.9 | bsz 1 | num_updates 7831 | best_loss 8.238
2022-03-06 21:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7831 updates
2022-03-06 21:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 161 @ 7831 updates, score 14.869) (writing took 2.5278578586876392 seconds)
2022-03-06 21:11:20 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-06 21:11:20 | INFO | train | epoch 161 | loss 0.874 | nll_loss 0.538 | ppl 1.45 | wps 21425.7 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7831 | lr 0.000357348 | gnorm 0.828 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 29355
2022-03-06 21:11:20 | INFO | fairseq.trainer | begin training epoch 162
2022-03-06 21:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:13:43 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 14.857 | nll_loss 14.696 | ppl 26540 | wps 38263.5 | wpb 510.9 | bsz 1 | num_updates 7880 | best_loss 8.238
2022-03-06 21:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7880 updates
2022-03-06 21:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 162 @ 7880 updates, score 14.857) (writing took 2.582097979262471 seconds)
2022-03-06 21:13:45 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-06 21:13:45 | INFO | train | epoch 162 | loss 0.865 | nll_loss 0.53 | ppl 1.44 | wps 21829.1 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7880 | lr 0.000356235 | gnorm 0.791 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 29500
2022-03-06 21:13:45 | INFO | fairseq.trainer | begin training epoch 163
2022-03-06 21:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:14:42 | INFO | train_inner | epoch 163:     20 / 49 loss=0.868, nll_loss=0.532, ppl=1.45, wps=21659.9, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.802, loss_scale=32, train_wall=257, gb_free=8.8, wall=29557
2022-03-06 21:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:16:08 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 14.897 | nll_loss 14.738 | ppl 27320.7 | wps 38231.9 | wpb 510.9 | bsz 1 | num_updates 7929 | best_loss 8.238
2022-03-06 21:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7929 updates
2022-03-06 21:16:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 163 @ 7929 updates, score 14.897) (writing took 2.5773833487182856 seconds)
2022-03-06 21:16:11 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-06 21:16:11 | INFO | train | epoch 163 | loss 0.864 | nll_loss 0.528 | ppl 1.44 | wps 21800.2 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 7929 | lr 0.000355133 | gnorm 0.811 | loss_scale 32 | train_wall 125 | gb_free 8.8 | wall 29646
2022-03-06 21:16:11 | INFO | fairseq.trainer | begin training epoch 164
2022-03-06 21:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:17:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:18:34 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 14.916 | nll_loss 14.756 | ppl 27664.9 | wps 38044.7 | wpb 510.9 | bsz 1 | num_updates 7977 | best_loss 8.238
2022-03-06 21:18:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7977 updates
2022-03-06 21:18:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:18:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 164 @ 7977 updates, score 14.916) (writing took 2.6884840298444033 seconds)
2022-03-06 21:18:37 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-06 21:18:37 | INFO | train | epoch 164 | loss 0.856 | nll_loss 0.52 | ppl 1.43 | wps 21357.2 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 7977 | lr 0.000354063 | gnorm 0.791 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 29792
2022-03-06 21:18:37 | INFO | fairseq.trainer | begin training epoch 165
2022-03-06 21:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:19:42 | INFO | train_inner | epoch 165:     23 / 49 loss=0.857, nll_loss=0.521, ppl=1.44, wps=21643.5, ups=0.33, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.794, loss_scale=32, train_wall=257, gb_free=8.8, wall=29857
2022-03-06 21:20:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:20:59 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 15.074 | nll_loss 14.914 | ppl 30881.5 | wps 38440.3 | wpb 510.9 | bsz 1 | num_updates 8026 | best_loss 8.238
2022-03-06 21:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8026 updates
2022-03-06 21:20:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:21:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:21:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 165 @ 8026 updates, score 15.074) (writing took 2.720377739518881 seconds)
2022-03-06 21:21:02 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-06 21:21:02 | INFO | train | epoch 165 | loss 0.85 | nll_loss 0.514 | ppl 1.43 | wps 21871 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8026 | lr 0.00035298 | gnorm 0.783 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 29937
2022-03-06 21:21:02 | INFO | fairseq.trainer | begin training epoch 166
2022-03-06 21:21:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:23:25 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 15.018 | nll_loss 14.859 | ppl 29724.2 | wps 38461.2 | wpb 510.9 | bsz 1 | num_updates 8075 | best_loss 8.238
2022-03-06 21:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8075 updates
2022-03-06 21:23:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:23:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:23:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 166 @ 8075 updates, score 15.018) (writing took 2.6294210962951183 seconds)
2022-03-06 21:23:27 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-06 21:23:27 | INFO | train | epoch 166 | loss 0.848 | nll_loss 0.512 | ppl 1.43 | wps 21870 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8075 | lr 0.000351908 | gnorm 0.793 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 30083
2022-03-06 21:23:27 | INFO | fairseq.trainer | begin training epoch 167
2022-03-06 21:23:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:24:38 | INFO | train_inner | epoch 167:     25 / 49 loss=0.847, nll_loss=0.51, ppl=1.42, wps=21870.2, ups=0.34, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.787, loss_scale=64, train_wall=254, gb_free=8.8, wall=30153
2022-03-06 21:25:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:25:50 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 14.931 | nll_loss 14.773 | ppl 27998.9 | wps 38409.4 | wpb 510.9 | bsz 1 | num_updates 8123 | best_loss 8.238
2022-03-06 21:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8123 updates
2022-03-06 21:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 167 @ 8123 updates, score 14.931) (writing took 2.5597179494798183 seconds)
2022-03-06 21:25:53 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-06 21:25:53 | INFO | train | epoch 167 | loss 0.84 | nll_loss 0.504 | ppl 1.42 | wps 21413.5 | ups 0.33 | wpb 64844.1 | bsz 126.7 | num_updates 8123 | lr 0.000350866 | gnorm 0.769 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 30228
2022-03-06 21:25:53 | INFO | fairseq.trainer | begin training epoch 168
2022-03-06 21:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:28:16 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 14.993 | nll_loss 14.835 | ppl 29229.1 | wps 38276.2 | wpb 510.9 | bsz 1 | num_updates 8172 | best_loss 8.238
2022-03-06 21:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8172 updates
2022-03-06 21:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 168 @ 8172 updates, score 14.993) (writing took 2.5338502191007137 seconds)
2022-03-06 21:28:18 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-06 21:28:18 | INFO | train | epoch 168 | loss 0.836 | nll_loss 0.5 | ppl 1.41 | wps 21852 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8172 | lr 0.000349813 | gnorm 0.779 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 30373
2022-03-06 21:28:18 | INFO | fairseq.trainer | begin training epoch 169
2022-03-06 21:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:37 | INFO | train_inner | epoch 169:     28 / 49 loss=0.835, nll_loss=0.499, ppl=1.41, wps=21693.3, ups=0.33, wpb=64867.4, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.777, loss_scale=32, train_wall=256, gb_free=8.8, wall=30452
2022-03-06 21:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:30:41 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 15.016 | nll_loss 14.857 | ppl 29681.8 | wps 38238.1 | wpb 510.9 | bsz 1 | num_updates 8221 | best_loss 8.238
2022-03-06 21:30:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8221 updates
2022-03-06 21:30:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:30:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:30:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 169 @ 8221 updates, score 15.016) (writing took 2.5492373313754797 seconds)
2022-03-06 21:30:43 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-06 21:30:43 | INFO | train | epoch 169 | loss 0.832 | nll_loss 0.495 | ppl 1.41 | wps 21886.8 | ups 0.34 | wpb 64858.2 | bsz 126.7 | num_updates 8221 | lr 0.000348769 | gnorm 0.777 | loss_scale 32 | train_wall 124 | gb_free 8.8 | wall 30519
2022-03-06 21:30:43 | INFO | fairseq.trainer | begin training epoch 170
2022-03-06 21:30:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:31:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:33:01 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 15.005 | nll_loss 14.85 | ppl 29525.3 | wps 42185 | wpb 510.9 | bsz 1 | num_updates 8269 | best_loss 8.238
2022-03-06 21:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8269 updates
2022-03-06 21:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:33:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:33:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 170 @ 8269 updates, score 15.005) (writing took 2.4336547758430243 seconds)
2022-03-06 21:33:03 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-06 21:33:03 | INFO | train | epoch 170 | loss 0.826 | nll_loss 0.49 | ppl 1.4 | wps 22302.4 | ups 0.34 | wpb 64844.1 | bsz 126.7 | num_updates 8269 | lr 0.000347755 | gnorm 0.763 | loss_scale 32 | train_wall 119 | gb_free 8.8 | wall 30658
2022-03-06 21:33:03 | INFO | fairseq.trainer | begin training epoch 171
2022-03-06 21:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:25 | INFO | train_inner | epoch 171:     31 / 49 loss=0.826, nll_loss=0.489, ppl=1.4, wps=22563.2, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.763, loss_scale=32, train_wall=246, gb_free=8.8, wall=30740
2022-03-06 21:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:35:16 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 15.09 | nll_loss 14.934 | ppl 31300 | wps 43507.5 | wpb 510.9 | bsz 1 | num_updates 8318 | best_loss 8.238
2022-03-06 21:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8318 updates
2022-03-06 21:35:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:35:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 171 @ 8318 updates, score 15.09) (writing took 2.504803927615285 seconds)
2022-03-06 21:35:18 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-06 21:35:18 | INFO | train | epoch 171 | loss 0.822 | nll_loss 0.485 | ppl 1.4 | wps 23500 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8318 | lr 0.000346729 | gnorm 0.766 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 30793
2022-03-06 21:35:18 | INFO | fairseq.trainer | begin training epoch 172
2022-03-06 21:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:37:24 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 15.033 | nll_loss 14.878 | ppl 30113.1 | wps 46905.5 | wpb 510.9 | bsz 1 | num_updates 8367 | best_loss 8.238
2022-03-06 21:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8367 updates
2022-03-06 21:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 172 @ 8367 updates, score 15.033) (writing took 2.5273292250931263 seconds)
2022-03-06 21:37:26 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-06 21:37:26 | INFO | train | epoch 172 | loss 0.817 | nll_loss 0.48 | ppl 1.4 | wps 24810.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8367 | lr 0.000345713 | gnorm 0.757 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 30921
2022-03-06 21:37:26 | INFO | fairseq.trainer | begin training epoch 173
2022-03-06 21:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:37:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:38:51 | INFO | train_inner | epoch 173:     34 / 49 loss=0.817, nll_loss=0.48, ppl=1.39, wps=24396.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.756, loss_scale=32, train_wall=227, gb_free=8.8, wall=31006
2022-03-06 21:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:39:31 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 15.102 | nll_loss 14.948 | ppl 31600.8 | wps 46939 | wpb 510.9 | bsz 1 | num_updates 8415 | best_loss 8.238
2022-03-06 21:39:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8415 updates
2022-03-06 21:39:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:39:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 173 @ 8415 updates, score 15.102) (writing took 2.533319564536214 seconds)
2022-03-06 21:39:34 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-06 21:39:34 | INFO | train | epoch 173 | loss 0.81 | nll_loss 0.473 | ppl 1.39 | wps 24383.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8415 | lr 0.000344725 | gnorm 0.739 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 31049
2022-03-06 21:39:34 | INFO | fairseq.trainer | begin training epoch 174
2022-03-06 21:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:41:39 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 15.047 | nll_loss 14.89 | ppl 30364 | wps 46799.6 | wpb 510.9 | bsz 1 | num_updates 8464 | best_loss 8.238
2022-03-06 21:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8464 updates
2022-03-06 21:41:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 174 @ 8464 updates, score 15.047) (writing took 2.5338334068655968 seconds)
2022-03-06 21:41:42 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-06 21:41:42 | INFO | train | epoch 174 | loss 0.809 | nll_loss 0.471 | ppl 1.39 | wps 24893.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8464 | lr 0.000343726 | gnorm 0.747 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 31177
2022-03-06 21:41:42 | INFO | fairseq.trainer | begin training epoch 175
2022-03-06 21:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:11 | INFO | train_inner | epoch 175:     36 / 49 loss=0.807, nll_loss=0.47, ppl=1.38, wps=24924.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.74, loss_scale=32, train_wall=222, gb_free=8.8, wall=31266
2022-03-06 21:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:43:47 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 15.193 | nll_loss 15.04 | ppl 33697.4 | wps 46989 | wpb 510.9 | bsz 1 | num_updates 8513 | best_loss 8.238
2022-03-06 21:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8513 updates
2022-03-06 21:43:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:43:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 175 @ 8513 updates, score 15.193) (writing took 2.522587163373828 seconds)
2022-03-06 21:43:49 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-06 21:43:49 | INFO | train | epoch 175 | loss 0.803 | nll_loss 0.466 | ppl 1.38 | wps 24891.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8513 | lr 0.000342735 | gnorm 0.729 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 31304
2022-03-06 21:43:49 | INFO | fairseq.trainer | begin training epoch 176
2022-03-06 21:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:54 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 15.099 | nll_loss 14.943 | ppl 31499.7 | wps 47006.1 | wpb 510.9 | bsz 1 | num_updates 8561 | best_loss 8.238
2022-03-06 21:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8561 updates
2022-03-06 21:45:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 176 @ 8561 updates, score 15.099) (writing took 2.5347067452967167 seconds)
2022-03-06 21:45:57 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-06 21:45:57 | INFO | train | epoch 176 | loss 0.799 | nll_loss 0.461 | ppl 1.38 | wps 24404.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8561 | lr 0.000341773 | gnorm 0.746 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 31432
2022-03-06 21:45:57 | INFO | fairseq.trainer | begin training epoch 177
2022-03-06 21:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:47:34 | INFO | train_inner | epoch 177:     39 / 49 loss=0.798, nll_loss=0.461, ppl=1.38, wps=24715.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.738, loss_scale=32, train_wall=224, gb_free=8.8, wall=31529
2022-03-06 21:47:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:48:02 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 15.128 | nll_loss 14.975 | ppl 32206.7 | wps 47426.4 | wpb 510.9 | bsz 1 | num_updates 8610 | best_loss 8.238
2022-03-06 21:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8610 updates
2022-03-06 21:48:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 177 @ 8610 updates, score 15.128) (writing took 2.5526731945574284 seconds)
2022-03-06 21:48:04 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-06 21:48:04 | INFO | train | epoch 177 | loss 0.795 | nll_loss 0.457 | ppl 1.37 | wps 24915.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8610 | lr 0.000340799 | gnorm 0.733 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 31560
2022-03-06 21:48:04 | INFO | fairseq.trainer | begin training epoch 178
2022-03-06 21:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:49:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:50:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:09 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 15.115 | nll_loss 14.96 | ppl 31876.7 | wps 47036.6 | wpb 510.9 | bsz 1 | num_updates 8658 | best_loss 8.238
2022-03-06 21:50:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8658 updates
2022-03-06 21:50:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 178 @ 8658 updates, score 15.115) (writing took 2.5457381810992956 seconds)
2022-03-06 21:50:12 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-06 21:50:12 | INFO | train | epoch 178 | loss 0.792 | nll_loss 0.455 | ppl 1.37 | wps 24404.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8658 | lr 0.000339853 | gnorm 0.734 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 31687
2022-03-06 21:50:12 | INFO | fairseq.trainer | begin training epoch 179
2022-03-06 21:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:51:56 | INFO | train_inner | epoch 179:     42 / 49 loss=0.79, nll_loss=0.453, ppl=1.37, wps=24697.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.727, loss_scale=32, train_wall=224, gb_free=8.8, wall=31791
2022-03-06 21:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:17 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 15.227 | nll_loss 15.069 | ppl 34382.5 | wps 46894.9 | wpb 510.9 | bsz 1 | num_updates 8707 | best_loss 8.238
2022-03-06 21:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8707 updates
2022-03-06 21:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:52:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 179 @ 8707 updates, score 15.227) (writing took 2.562003493309021 seconds)
2022-03-06 21:52:20 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-06 21:52:20 | INFO | train | epoch 179 | loss 0.786 | nll_loss 0.449 | ppl 1.36 | wps 24883 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8707 | lr 0.000338895 | gnorm 0.718 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 31815
2022-03-06 21:52:20 | INFO | fairseq.trainer | begin training epoch 180
2022-03-06 21:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:54:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:25 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 15.158 | nll_loss 15.002 | ppl 32816.2 | wps 47425.3 | wpb 510.9 | bsz 1 | num_updates 8756 | best_loss 8.238
2022-03-06 21:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8756 updates
2022-03-06 21:54:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 180 @ 8756 updates, score 15.158) (writing took 2.5482214372605085 seconds)
2022-03-06 21:54:27 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-06 21:54:27 | INFO | train | epoch 180 | loss 0.783 | nll_loss 0.446 | ppl 1.36 | wps 24932.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8756 | lr 0.000337946 | gnorm 0.717 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 31942
2022-03-06 21:54:27 | INFO | fairseq.trainer | begin training epoch 181
2022-03-06 21:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:55:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:56:19 | INFO | train_inner | epoch 181:     45 / 49 loss=0.781, nll_loss=0.444, ppl=1.36, wps=24697.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.716, loss_scale=32, train_wall=224, gb_free=8.8, wall=32054
2022-03-06 21:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:56:32 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 15.24 | nll_loss 15.089 | ppl 34847.1 | wps 46912.2 | wpb 510.9 | bsz 1 | num_updates 8804 | best_loss 8.238
2022-03-06 21:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8804 updates
2022-03-06 21:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:56:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 181 @ 8804 updates, score 15.24) (writing took 2.5689334478229284 seconds)
2022-03-06 21:56:35 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-06 21:56:35 | INFO | train | epoch 181 | loss 0.778 | nll_loss 0.44 | ppl 1.36 | wps 24374.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 8804 | lr 0.000337023 | gnorm 0.714 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32070
2022-03-06 21:56:35 | INFO | fairseq.trainer | begin training epoch 182
2022-03-06 21:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:58:40 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 15.14 | nll_loss 14.987 | ppl 32483.9 | wps 46679.7 | wpb 510.9 | bsz 1 | num_updates 8853 | best_loss 8.238
2022-03-06 21:58:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8853 updates
2022-03-06 21:58:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:58:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 21:58:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 182 @ 8853 updates, score 15.14) (writing took 2.5415370520204306 seconds)
2022-03-06 21:58:43 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-06 21:58:43 | INFO | train | epoch 182 | loss 0.776 | nll_loss 0.439 | ppl 1.36 | wps 24844.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8853 | lr 0.000336089 | gnorm 0.708 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32198
2022-03-06 21:58:43 | INFO | fairseq.trainer | begin training epoch 183
2022-03-06 21:58:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:00:39 | INFO | train_inner | epoch 183:     47 / 49 loss=0.774, nll_loss=0.437, ppl=1.35, wps=24890.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.709, loss_scale=32, train_wall=222, gb_free=8.8, wall=32315
2022-03-06 22:00:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:00:48 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 15.15 | nll_loss 14.999 | ppl 32736.2 | wps 47158.5 | wpb 510.9 | bsz 1 | num_updates 8902 | best_loss 8.238
2022-03-06 22:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8902 updates
2022-03-06 22:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 183 @ 8902 updates, score 15.15) (writing took 2.565701687708497 seconds)
2022-03-06 22:00:50 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-06 22:00:50 | INFO | train | epoch 183 | loss 0.772 | nll_loss 0.434 | ppl 1.35 | wps 24876.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8902 | lr 0.000335163 | gnorm 0.71 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32326
2022-03-06 22:00:50 | INFO | fairseq.trainer | begin training epoch 184
2022-03-06 22:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:02:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:02:56 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 15.138 | nll_loss 14.984 | ppl 32410.9 | wps 46284.7 | wpb 510.9 | bsz 1 | num_updates 8950 | best_loss 8.238
2022-03-06 22:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8950 updates
2022-03-06 22:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 184 @ 8950 updates, score 15.138) (writing took 2.5762680675834417 seconds)
2022-03-06 22:02:58 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-06 22:02:58 | INFO | train | epoch 184 | loss 0.768 | nll_loss 0.431 | ppl 1.35 | wps 24314.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 8950 | lr 0.000334263 | gnorm 0.705 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32454
2022-03-06 22:02:58 | INFO | fairseq.trainer | begin training epoch 185
2022-03-06 22:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:05:04 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 15.234 | nll_loss 15.082 | ppl 34676.2 | wps 46945 | wpb 510.9 | bsz 1 | num_updates 8999 | best_loss 8.238
2022-03-06 22:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 8999 updates
2022-03-06 22:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 185 @ 8999 updates, score 15.234) (writing took 2.558809693902731 seconds)
2022-03-06 22:05:06 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-06 22:05:06 | INFO | train | epoch 185 | loss 0.764 | nll_loss 0.427 | ppl 1.34 | wps 24873.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 8999 | lr 0.000333352 | gnorm 0.7 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32581
2022-03-06 22:05:06 | INFO | fairseq.trainer | begin training epoch 186
2022-03-06 22:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:05:09 | INFO | train_inner | epoch 186:      1 / 49 loss=0.766, nll_loss=0.429, ppl=1.35, wps=23962.8, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=9000, lr=0.000333333, gnorm=0.705, loss_scale=32, train_wall=223, gb_free=8.8, wall=32584
2022-03-06 22:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:07:11 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 15.347 | nll_loss 15.199 | ppl 37612.5 | wps 47048.4 | wpb 510.9 | bsz 1 | num_updates 9048 | best_loss 8.238
2022-03-06 22:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9048 updates
2022-03-06 22:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 186 @ 9048 updates, score 15.347) (writing took 2.5373025313019753 seconds)
2022-03-06 22:07:14 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-06 22:07:14 | INFO | train | epoch 186 | loss 0.761 | nll_loss 0.423 | ppl 1.34 | wps 24915.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9048 | lr 0.000332448 | gnorm 0.698 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32709
2022-03-06 22:07:14 | INFO | fairseq.trainer | begin training epoch 187
2022-03-06 22:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:09:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:09:19 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 15.19 | nll_loss 15.039 | ppl 33666 | wps 47025.2 | wpb 510.9 | bsz 1 | num_updates 9096 | best_loss 8.238
2022-03-06 22:09:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9096 updates
2022-03-06 22:09:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:09:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:09:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 187 @ 9096 updates, score 15.19) (writing took 2.5720189195126295 seconds)
2022-03-06 22:09:21 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-06 22:09:21 | INFO | train | epoch 187 | loss 0.757 | nll_loss 0.42 | ppl 1.34 | wps 24376.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 9096 | lr 0.00033157 | gnorm 0.702 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32837
2022-03-06 22:09:22 | INFO | fairseq.trainer | begin training epoch 188
2022-03-06 22:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:09:32 | INFO | train_inner | epoch 188:      4 / 49 loss=0.759, nll_loss=0.421, ppl=1.34, wps=24693.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.701, loss_scale=32, train_wall=224, gb_free=8.8, wall=32847
2022-03-06 22:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:11:27 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 15.209 | nll_loss 15.058 | ppl 34104.1 | wps 46710.2 | wpb 510.9 | bsz 1 | num_updates 9145 | best_loss 8.238
2022-03-06 22:11:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9145 updates
2022-03-06 22:11:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:11:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 188 @ 9145 updates, score 15.209) (writing took 2.4362670313566923 seconds)
2022-03-06 22:11:29 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-06 22:11:29 | INFO | train | epoch 188 | loss 0.753 | nll_loss 0.416 | ppl 1.33 | wps 24876.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9145 | lr 0.00033068 | gnorm 0.693 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 32964
2022-03-06 22:11:29 | INFO | fairseq.trainer | begin training epoch 189
2022-03-06 22:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:13:35 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 15.273 | nll_loss 15.123 | ppl 35679.5 | wps 45829.3 | wpb 510.9 | bsz 1 | num_updates 9194 | best_loss 8.238
2022-03-06 22:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9194 updates
2022-03-06 22:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 189 @ 9194 updates, score 15.273) (writing took 2.5587349478155375 seconds)
2022-03-06 22:13:38 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-06 22:13:38 | INFO | train | epoch 189 | loss 0.749 | nll_loss 0.411 | ppl 1.33 | wps 24683.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9194 | lr 0.000329798 | gnorm 0.681 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33093
2022-03-06 22:13:38 | INFO | fairseq.trainer | begin training epoch 190
2022-03-06 22:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:53 | INFO | train_inner | epoch 190:      6 / 49 loss=0.75, nll_loss=0.412, ppl=1.33, wps=24799.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.684, loss_scale=32, train_wall=223, gb_free=8.8, wall=33108
2022-03-06 22:15:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:15:44 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 15.215 | nll_loss 15.064 | ppl 34246.8 | wps 46532.6 | wpb 510.9 | bsz 1 | num_updates 9242 | best_loss 8.238
2022-03-06 22:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9242 updates
2022-03-06 22:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 190 @ 9242 updates, score 15.215) (writing took 2.4861165937036276 seconds)
2022-03-06 22:15:46 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-06 22:15:46 | INFO | train | epoch 190 | loss 0.746 | nll_loss 0.409 | ppl 1.33 | wps 24248.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9242 | lr 0.00032894 | gnorm 0.686 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33221
2022-03-06 22:15:46 | INFO | fairseq.trainer | begin training epoch 191
2022-03-06 22:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:52 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 15.281 | nll_loss 15.132 | ppl 35902.8 | wps 46313.7 | wpb 510.9 | bsz 1 | num_updates 9291 | best_loss 8.238
2022-03-06 22:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9291 updates
2022-03-06 22:17:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:17:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:17:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 191 @ 9291 updates, score 15.281) (writing took 2.519034245982766 seconds)
2022-03-06 22:17:55 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-06 22:17:55 | INFO | train | epoch 191 | loss 0.743 | nll_loss 0.406 | ppl 1.33 | wps 24715.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9291 | lr 0.000328072 | gnorm 0.684 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33350
2022-03-06 22:17:55 | INFO | fairseq.trainer | begin training epoch 192
2022-03-06 22:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:18:18 | INFO | train_inner | epoch 192:      9 / 49 loss=0.744, nll_loss=0.407, ppl=1.33, wps=24536.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.684, loss_scale=32, train_wall=225, gb_free=8.8, wall=33373
2022-03-06 22:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:20:01 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 15.202 | nll_loss 15.052 | ppl 33975.2 | wps 46439.8 | wpb 510.9 | bsz 1 | num_updates 9340 | best_loss 8.238
2022-03-06 22:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9340 updates
2022-03-06 22:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 192 @ 9340 updates, score 15.202) (writing took 2.56268816255033 seconds)
2022-03-06 22:20:04 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-06 22:20:04 | INFO | train | epoch 192 | loss 0.741 | nll_loss 0.404 | ppl 1.32 | wps 24711.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9340 | lr 0.00032721 | gnorm 0.689 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33479
2022-03-06 22:20:04 | INFO | fairseq.trainer | begin training epoch 193
2022-03-06 22:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:21:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:22:10 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 15.261 | nll_loss 15.109 | ppl 35337.5 | wps 46421.3 | wpb 510.9 | bsz 1 | num_updates 9388 | best_loss 8.238
2022-03-06 22:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9388 updates
2022-03-06 22:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 193 @ 9388 updates, score 15.261) (writing took 2.503682492300868 seconds)
2022-03-06 22:22:12 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-06 22:22:12 | INFO | train | epoch 193 | loss 0.737 | nll_loss 0.399 | ppl 1.32 | wps 24205.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9388 | lr 0.000326372 | gnorm 0.677 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33607
2022-03-06 22:22:12 | INFO | fairseq.trainer | begin training epoch 194
2022-03-06 22:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:22:42 | INFO | train_inner | epoch 194:     12 / 49 loss=0.738, nll_loss=0.401, ppl=1.32, wps=24504.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.68, loss_scale=32, train_wall=226, gb_free=8.8, wall=33637
2022-03-06 22:24:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:24:18 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 15.229 | nll_loss 15.079 | ppl 34618.7 | wps 46683.8 | wpb 510.9 | bsz 1 | num_updates 9437 | best_loss 8.238
2022-03-06 22:24:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9437 updates
2022-03-06 22:24:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 194 @ 9437 updates, score 15.229) (writing took 2.5461324583739042 seconds)
2022-03-06 22:24:21 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-06 22:24:21 | INFO | train | epoch 194 | loss 0.733 | nll_loss 0.396 | ppl 1.32 | wps 24703.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9437 | lr 0.000325524 | gnorm 0.656 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33736
2022-03-06 22:24:21 | INFO | fairseq.trainer | begin training epoch 195
2022-03-06 22:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:27 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 15.249 | nll_loss 15.102 | ppl 35178.3 | wps 46424.1 | wpb 510.9 | bsz 1 | num_updates 9486 | best_loss 8.238
2022-03-06 22:26:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9486 updates
2022-03-06 22:26:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:26:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:26:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 195 @ 9486 updates, score 15.249) (writing took 2.53356084600091 seconds)
2022-03-06 22:26:29 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-06 22:26:29 | INFO | train | epoch 195 | loss 0.731 | nll_loss 0.393 | ppl 1.31 | wps 24696.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9486 | lr 0.000324682 | gnorm 0.665 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33865
2022-03-06 22:26:29 | INFO | fairseq.trainer | begin training epoch 196
2022-03-06 22:26:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:27:04 | INFO | train_inner | epoch 196:     14 / 49 loss=0.732, nll_loss=0.394, ppl=1.31, wps=24737, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.663, loss_scale=64, train_wall=223, gb_free=8.8, wall=33900
2022-03-06 22:27:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:35 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 15.289 | nll_loss 15.141 | ppl 36144 | wps 45798.8 | wpb 510.9 | bsz 1 | num_updates 9534 | best_loss 8.238
2022-03-06 22:28:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9534 updates
2022-03-06 22:28:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:28:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:28:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 196 @ 9534 updates, score 15.289) (writing took 2.5102872028946877 seconds)
2022-03-06 22:28:38 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-06 22:28:38 | INFO | train | epoch 196 | loss 0.728 | nll_loss 0.391 | ppl 1.31 | wps 24235.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9534 | lr 0.000323864 | gnorm 0.668 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 33993
2022-03-06 22:28:38 | INFO | fairseq.trainer | begin training epoch 197
2022-03-06 22:28:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:30:44 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 15.248 | nll_loss 15.097 | ppl 35052.4 | wps 46561.7 | wpb 510.9 | bsz 1 | num_updates 9583 | best_loss 8.238
2022-03-06 22:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9583 updates
2022-03-06 22:30:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 197 @ 9583 updates, score 15.248) (writing took 2.557291716337204 seconds)
2022-03-06 22:30:47 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-06 22:30:47 | INFO | train | epoch 197 | loss 0.725 | nll_loss 0.387 | ppl 1.31 | wps 24698.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9583 | lr 0.000323035 | gnorm 0.668 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34122
2022-03-06 22:30:47 | INFO | fairseq.trainer | begin training epoch 198
2022-03-06 22:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:31:29 | INFO | train_inner | epoch 198:     17 / 49 loss=0.725, nll_loss=0.387, ppl=1.31, wps=24507.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.666, loss_scale=32, train_wall=225, gb_free=8.8, wall=34164
2022-03-06 22:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:32:53 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 15.242 | nll_loss 15.093 | ppl 34957.8 | wps 46021.1 | wpb 510.9 | bsz 1 | num_updates 9632 | best_loss 8.238
2022-03-06 22:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9632 updates
2022-03-06 22:32:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:32:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 198 @ 9632 updates, score 15.242) (writing took 2.539220107719302 seconds)
2022-03-06 22:32:55 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-06 22:32:55 | INFO | train | epoch 198 | loss 0.722 | nll_loss 0.384 | ppl 1.31 | wps 24684 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9632 | lr 0.000322212 | gnorm 0.663 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 34250
2022-03-06 22:32:55 | INFO | fairseq.trainer | begin training epoch 199
2022-03-06 22:32:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:32:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:35:01 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 15.326 | nll_loss 15.176 | ppl 37015.4 | wps 46398.3 | wpb 510.9 | bsz 1 | num_updates 9680 | best_loss 8.238
2022-03-06 22:35:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9680 updates
2022-03-06 22:35:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:35:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:35:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 199 @ 9680 updates, score 15.326) (writing took 2.5378861986100674 seconds)
2022-03-06 22:35:04 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-06 22:35:04 | INFO | train | epoch 199 | loss 0.718 | nll_loss 0.381 | ppl 1.3 | wps 24222.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9680 | lr 0.000321412 | gnorm 0.652 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34379
2022-03-06 22:35:04 | INFO | fairseq.trainer | begin training epoch 200
2022-03-06 22:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:35:54 | INFO | train_inner | epoch 200:     20 / 49 loss=0.719, nll_loss=0.382, ppl=1.3, wps=24499.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.652, loss_scale=32, train_wall=225, gb_free=8.8, wall=34429
2022-03-06 22:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:37:10 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 15.313 | nll_loss 15.167 | ppl 36783 | wps 46346.1 | wpb 510.9 | bsz 1 | num_updates 9729 | best_loss 8.238
2022-03-06 22:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9729 updates
2022-03-06 22:37:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:37:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 200 @ 9729 updates, score 15.313) (writing took 2.5454128831624985 seconds)
2022-03-06 22:37:12 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-06 22:37:12 | INFO | train | epoch 200 | loss 0.715 | nll_loss 0.378 | ppl 1.3 | wps 24701.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9729 | lr 0.000320602 | gnorm 0.64 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34508
2022-03-06 22:37:12 | INFO | fairseq.trainer | begin training epoch 201
2022-03-06 22:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:38:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:39:19 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 15.235 | nll_loss 15.086 | ppl 34790.3 | wps 46462.7 | wpb 510.9 | bsz 1 | num_updates 9777 | best_loss 8.238
2022-03-06 22:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9777 updates
2022-03-06 22:39:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:39:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:39:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 201 @ 9777 updates, score 15.235) (writing took 2.5596230048686266 seconds)
2022-03-06 22:39:21 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-06 22:39:21 | INFO | train | epoch 201 | loss 0.713 | nll_loss 0.376 | ppl 1.3 | wps 24200.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9777 | lr 0.000319814 | gnorm 0.652 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34636
2022-03-06 22:39:21 | INFO | fairseq.trainer | begin training epoch 202
2022-03-06 22:39:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:40:19 | INFO | train_inner | epoch 202:     23 / 49 loss=0.713, nll_loss=0.376, ppl=1.3, wps=24515.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.649, loss_scale=32, train_wall=225, gb_free=8.8, wall=34694
2022-03-06 22:41:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:41:27 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 15.333 | nll_loss 15.187 | ppl 37300.9 | wps 46248.2 | wpb 510.9 | bsz 1 | num_updates 9826 | best_loss 8.238
2022-03-06 22:41:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9826 updates
2022-03-06 22:41:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:41:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 202 @ 9826 updates, score 15.333) (writing took 2.5490424148738384 seconds)
2022-03-06 22:41:30 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-06 22:41:30 | INFO | train | epoch 202 | loss 0.711 | nll_loss 0.374 | ppl 1.3 | wps 24714 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9826 | lr 0.000319015 | gnorm 0.652 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34765
2022-03-06 22:41:30 | INFO | fairseq.trainer | begin training epoch 203
2022-03-06 22:41:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:43:36 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 15.379 | nll_loss 15.234 | ppl 38539.5 | wps 46085.4 | wpb 510.9 | bsz 1 | num_updates 9875 | best_loss 8.238
2022-03-06 22:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9875 updates
2022-03-06 22:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:43:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:43:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 203 @ 9875 updates, score 15.379) (writing took 2.5943254623562098 seconds)
2022-03-06 22:43:38 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-06 22:43:38 | INFO | train | epoch 203 | loss 0.708 | nll_loss 0.371 | ppl 1.29 | wps 24694.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9875 | lr 0.000318223 | gnorm 0.641 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 34894
2022-03-06 22:43:38 | INFO | fairseq.trainer | begin training epoch 204
2022-03-06 22:43:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:44:41 | INFO | train_inner | epoch 204:     25 / 49 loss=0.708, nll_loss=0.371, ppl=1.29, wps=24718, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.645, loss_scale=64, train_wall=223, gb_free=8.8, wall=34956
2022-03-06 22:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:45:44 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 15.376 | nll_loss 15.228 | ppl 38374.9 | wps 46465.2 | wpb 510.9 | bsz 1 | num_updates 9924 | best_loss 8.238
2022-03-06 22:45:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9924 updates
2022-03-06 22:45:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 204 @ 9924 updates, score 15.376) (writing took 2.509992817416787 seconds)
2022-03-06 22:45:47 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-06 22:45:47 | INFO | train | epoch 204 | loss 0.706 | nll_loss 0.369 | ppl 1.29 | wps 24721 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 9924 | lr 0.000317436 | gnorm 0.647 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 35022
2022-03-06 22:45:47 | INFO | fairseq.trainer | begin training epoch 205
2022-03-06 22:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:47:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:47:53 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 15.362 | nll_loss 15.214 | ppl 38001.5 | wps 46495.2 | wpb 510.9 | bsz 1 | num_updates 9972 | best_loss 8.238
2022-03-06 22:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9972 updates
2022-03-06 22:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 205 @ 9972 updates, score 15.362) (writing took 2.545011604204774 seconds)
2022-03-06 22:47:55 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-06 22:47:55 | INFO | train | epoch 205 | loss 0.702 | nll_loss 0.365 | ppl 1.29 | wps 24252.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 9972 | lr 0.000316671 | gnorm 0.64 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35150
2022-03-06 22:47:55 | INFO | fairseq.trainer | begin training epoch 206
2022-03-06 22:47:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:49:06 | INFO | train_inner | epoch 206:     28 / 49 loss=0.702, nll_loss=0.365, ppl=1.29, wps=24529.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.641, loss_scale=32, train_wall=225, gb_free=8.8, wall=35221
2022-03-06 22:49:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:50:01 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 15.353 | nll_loss 15.207 | ppl 37824.3 | wps 46486.5 | wpb 510.9 | bsz 1 | num_updates 10021 | best_loss 8.238
2022-03-06 22:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10021 updates
2022-03-06 22:50:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 206 @ 10021 updates, score 15.353) (writing took 2.5168626196682453 seconds)
2022-03-06 22:50:04 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-06 22:50:04 | INFO | train | epoch 206 | loss 0.699 | nll_loss 0.362 | ppl 1.29 | wps 24701.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10021 | lr 0.000315896 | gnorm 0.63 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35279
2022-03-06 22:50:04 | INFO | fairseq.trainer | begin training epoch 207
2022-03-06 22:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:52:10 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 15.343 | nll_loss 15.199 | ppl 37613.6 | wps 46469.7 | wpb 510.9 | bsz 1 | num_updates 10070 | best_loss 8.238
2022-03-06 22:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10070 updates
2022-03-06 22:52:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:52:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 207 @ 10070 updates, score 15.343) (writing took 2.4969556629657745 seconds)
2022-03-06 22:52:13 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-06 22:52:13 | INFO | train | epoch 207 | loss 0.698 | nll_loss 0.361 | ppl 1.28 | wps 24718.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10070 | lr 0.000315127 | gnorm 0.637 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35408
2022-03-06 22:52:13 | INFO | fairseq.trainer | begin training epoch 208
2022-03-06 22:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:53:30 | INFO | train_inner | epoch 208:     31 / 49 loss=0.697, nll_loss=0.36, ppl=1.28, wps=24511.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.631, loss_scale=32, train_wall=226, gb_free=8.8, wall=35485
2022-03-06 22:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:54:19 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 15.321 | nll_loss 15.175 | ppl 37001.4 | wps 46445.1 | wpb 510.9 | bsz 1 | num_updates 10118 | best_loss 8.238
2022-03-06 22:54:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10118 updates
2022-03-06 22:54:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 208 @ 10118 updates, score 15.321) (writing took 2.507540723308921 seconds)
2022-03-06 22:54:21 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-06 22:54:21 | INFO | train | epoch 208 | loss 0.693 | nll_loss 0.357 | ppl 1.28 | wps 24168.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10118 | lr 0.000314378 | gnorm 0.62 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 35536
2022-03-06 22:54:21 | INFO | fairseq.trainer | begin training epoch 209
2022-03-06 22:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:56:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:56:27 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 15.247 | nll_loss 15.103 | ppl 35182.7 | wps 46466.4 | wpb 510.9 | bsz 1 | num_updates 10167 | best_loss 8.238
2022-03-06 22:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10167 updates
2022-03-06 22:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:56:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 209 @ 10167 updates, score 15.247) (writing took 2.5073035713285208 seconds)
2022-03-06 22:56:30 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-06 22:56:30 | INFO | train | epoch 209 | loss 0.692 | nll_loss 0.355 | ppl 1.28 | wps 24712.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10167 | lr 0.00031362 | gnorm 0.634 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 35665
2022-03-06 22:56:30 | INFO | fairseq.trainer | begin training epoch 210
2022-03-06 22:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:57:53 | INFO | train_inner | epoch 210:     33 / 49 loss=0.691, nll_loss=0.355, ppl=1.28, wps=24716.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.627, loss_scale=32, train_wall=224, gb_free=8.8, wall=35748
2022-03-06 22:58:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:58:36 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 15.424 | nll_loss 15.28 | ppl 39795.1 | wps 46406.3 | wpb 510.9 | bsz 1 | num_updates 10215 | best_loss 8.238
2022-03-06 22:58:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10215 updates
2022-03-06 22:58:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 22:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 210 @ 10215 updates, score 15.424) (writing took 2.496146284043789 seconds)
2022-03-06 22:58:39 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-06 22:58:39 | INFO | train | epoch 210 | loss 0.69 | nll_loss 0.354 | ppl 1.28 | wps 24184.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10215 | lr 0.000312882 | gnorm 0.63 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 35794
2022-03-06 22:58:39 | INFO | fairseq.trainer | begin training epoch 211
2022-03-06 22:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:00:45 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 15.432 | nll_loss 15.289 | ppl 40031.2 | wps 46348.4 | wpb 510.9 | bsz 1 | num_updates 10264 | best_loss 8.238
2022-03-06 23:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10264 updates
2022-03-06 23:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 211 @ 10264 updates, score 15.432) (writing took 2.503419628366828 seconds)
2022-03-06 23:00:47 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-06 23:00:47 | INFO | train | epoch 211 | loss 0.689 | nll_loss 0.353 | ppl 1.28 | wps 24662.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10264 | lr 0.000312134 | gnorm 0.632 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 35923
2022-03-06 23:00:47 | INFO | fairseq.trainer | begin training epoch 212
2022-03-06 23:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:02:17 | INFO | train_inner | epoch 212:     36 / 49 loss=0.687, nll_loss=0.351, ppl=1.28, wps=24494.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.625, loss_scale=32, train_wall=226, gb_free=8.8, wall=36013
2022-03-06 23:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:54 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 15.366 | nll_loss 15.223 | ppl 38254.9 | wps 46365.2 | wpb 510.9 | bsz 1 | num_updates 10313 | best_loss 8.238
2022-03-06 23:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10313 updates
2022-03-06 23:02:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 212 @ 10313 updates, score 15.366) (writing took 2.487191464751959 seconds)
2022-03-06 23:02:56 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-06 23:02:56 | INFO | train | epoch 212 | loss 0.683 | nll_loss 0.347 | ppl 1.27 | wps 24724.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10313 | lr 0.000311392 | gnorm 0.614 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36051
2022-03-06 23:02:56 | INFO | fairseq.trainer | begin training epoch 213
2022-03-06 23:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:05:02 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 15.328 | nll_loss 15.185 | ppl 37252.1 | wps 45716.5 | wpb 510.9 | bsz 1 | num_updates 10362 | best_loss 8.238
2022-03-06 23:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10362 updates
2022-03-06 23:05:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 213 @ 10362 updates, score 15.328) (writing took 2.4894942548125982 seconds)
2022-03-06 23:05:05 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-06 23:05:05 | INFO | train | epoch 213 | loss 0.682 | nll_loss 0.346 | ppl 1.27 | wps 24673 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10362 | lr 0.000310655 | gnorm 0.615 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 36180
2022-03-06 23:05:05 | INFO | fairseq.trainer | begin training epoch 214
2022-03-06 23:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:06:40 | INFO | train_inner | epoch 214:     38 / 49 loss=0.681, nll_loss=0.345, ppl=1.27, wps=24717.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.612, loss_scale=64, train_wall=223, gb_free=8.8, wall=36275
2022-03-06 23:07:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:07:11 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 15.403 | nll_loss 15.261 | ppl 39252.7 | wps 45995.6 | wpb 510.9 | bsz 1 | num_updates 10410 | best_loss 8.238
2022-03-06 23:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10410 updates
2022-03-06 23:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 214 @ 10410 updates, score 15.403) (writing took 2.5350975040346384 seconds)
2022-03-06 23:07:13 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-06 23:07:13 | INFO | train | epoch 214 | loss 0.679 | nll_loss 0.343 | ppl 1.27 | wps 24191.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10410 | lr 0.000309938 | gnorm 0.607 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36309
2022-03-06 23:07:13 | INFO | fairseq.trainer | begin training epoch 215
2022-03-06 23:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:09:20 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 15.386 | nll_loss 15.242 | ppl 38757.7 | wps 45857.9 | wpb 510.9 | bsz 1 | num_updates 10459 | best_loss 8.238
2022-03-06 23:09:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10459 updates
2022-03-06 23:09:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:09:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 215 @ 10459 updates, score 15.386) (writing took 2.5299545861780643 seconds)
2022-03-06 23:09:22 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-06 23:09:22 | INFO | train | epoch 215 | loss 0.679 | nll_loss 0.343 | ppl 1.27 | wps 24688.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10459 | lr 0.000309211 | gnorm 0.61 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36437
2022-03-06 23:09:22 | INFO | fairseq.trainer | begin training epoch 216
2022-03-06 23:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:11:05 | INFO | train_inner | epoch 216:     41 / 49 loss=0.678, nll_loss=0.342, ppl=1.27, wps=24491.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.608, loss_scale=32, train_wall=226, gb_free=8.8, wall=36540
2022-03-06 23:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:11:28 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 15.368 | nll_loss 15.225 | ppl 38294 | wps 45552.6 | wpb 510.9 | bsz 1 | num_updates 10508 | best_loss 8.238
2022-03-06 23:11:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10508 updates
2022-03-06 23:11:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 216 @ 10508 updates, score 15.368) (writing took 2.5072944555431604 seconds)
2022-03-06 23:11:31 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-06 23:11:31 | INFO | train | epoch 216 | loss 0.675 | nll_loss 0.339 | ppl 1.27 | wps 24692.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10508 | lr 0.000308489 | gnorm 0.605 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36566
2022-03-06 23:11:31 | INFO | fairseq.trainer | begin training epoch 217
2022-03-06 23:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:12:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:37 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 15.301 | nll_loss 15.157 | ppl 36542.4 | wps 45750.9 | wpb 510.9 | bsz 1 | num_updates 10556 | best_loss 8.238
2022-03-06 23:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10556 updates
2022-03-06 23:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 217 @ 10556 updates, score 15.301) (writing took 2.542613059282303 seconds)
2022-03-06 23:13:40 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-06 23:13:40 | INFO | train | epoch 217 | loss 0.675 | nll_loss 0.339 | ppl 1.26 | wps 24179 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10556 | lr 0.000307787 | gnorm 0.61 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36695
2022-03-06 23:13:40 | INFO | fairseq.trainer | begin training epoch 218
2022-03-06 23:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:15:30 | INFO | train_inner | epoch 218:     44 / 49 loss=0.673, nll_loss=0.338, ppl=1.26, wps=24494.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.61, loss_scale=32, train_wall=226, gb_free=8.8, wall=36805
2022-03-06 23:15:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:15:46 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 15.327 | nll_loss 15.185 | ppl 37256.4 | wps 45848.2 | wpb 510.9 | bsz 1 | num_updates 10605 | best_loss 8.238
2022-03-06 23:15:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10605 updates
2022-03-06 23:15:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:15:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:15:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 218 @ 10605 updates, score 15.327) (writing took 2.533350069075823 seconds)
2022-03-06 23:15:48 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-06 23:15:48 | INFO | train | epoch 218 | loss 0.671 | nll_loss 0.335 | ppl 1.26 | wps 24707.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10605 | lr 0.000307075 | gnorm 0.606 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36823
2022-03-06 23:15:48 | INFO | fairseq.trainer | begin training epoch 219
2022-03-06 23:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:17:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:17:54 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 15.374 | nll_loss 15.231 | ppl 38466.5 | wps 45940.5 | wpb 510.9 | bsz 1 | num_updates 10654 | best_loss 8.238
2022-03-06 23:17:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10654 updates
2022-03-06 23:17:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:17:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:17:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 219 @ 10654 updates, score 15.374) (writing took 2.5120928902179003 seconds)
2022-03-06 23:17:57 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-06 23:17:57 | INFO | train | epoch 219 | loss 0.668 | nll_loss 0.333 | ppl 1.26 | wps 24725 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10654 | lr 0.000306368 | gnorm 0.597 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 36952
2022-03-06 23:17:57 | INFO | fairseq.trainer | begin training epoch 220
2022-03-06 23:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:18:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:19:54 | INFO | train_inner | epoch 220:     47 / 49 loss=0.668, nll_loss=0.332, ppl=1.26, wps=24513.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.597, loss_scale=32, train_wall=225, gb_free=8.8, wall=37069
2022-03-06 23:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:20:03 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 15.317 | nll_loss 15.176 | ppl 37013.7 | wps 45823 | wpb 510.9 | bsz 1 | num_updates 10702 | best_loss 8.238
2022-03-06 23:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10702 updates
2022-03-06 23:20:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:20:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 220 @ 10702 updates, score 15.317) (writing took 2.5070829540491104 seconds)
2022-03-06 23:20:05 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-06 23:20:05 | INFO | train | epoch 220 | loss 0.665 | nll_loss 0.33 | ppl 1.26 | wps 24202.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10702 | lr 0.00030568 | gnorm 0.596 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37081
2022-03-06 23:20:05 | INFO | fairseq.trainer | begin training epoch 221
2022-03-06 23:20:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:22:12 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 15.306 | nll_loss 15.165 | ppl 36729.9 | wps 45219.4 | wpb 510.9 | bsz 1 | num_updates 10751 | best_loss 8.238
2022-03-06 23:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10751 updates
2022-03-06 23:22:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:22:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 221 @ 10751 updates, score 15.306) (writing took 2.509564310312271 seconds)
2022-03-06 23:22:14 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-06 23:22:14 | INFO | train | epoch 221 | loss 0.666 | nll_loss 0.33 | ppl 1.26 | wps 24699.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10751 | lr 0.000304983 | gnorm 0.598 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37209
2022-03-06 23:22:14 | INFO | fairseq.trainer | begin training epoch 222
2022-03-06 23:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:24:20 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 15.351 | nll_loss 15.211 | ppl 37935.1 | wps 46091.2 | wpb 510.9 | bsz 1 | num_updates 10799 | best_loss 8.238
2022-03-06 23:24:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10799 updates
2022-03-06 23:24:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:24:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 222 @ 10799 updates, score 15.351) (writing took 2.5515426620841026 seconds)
2022-03-06 23:24:23 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-06 23:24:23 | INFO | train | epoch 222 | loss 0.662 | nll_loss 0.327 | ppl 1.25 | wps 24215.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10799 | lr 0.000304304 | gnorm 0.593 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37338
2022-03-06 23:24:23 | INFO | fairseq.trainer | begin training epoch 223
2022-03-06 23:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:24:25 | INFO | train_inner | epoch 223:      1 / 49 loss=0.664, nll_loss=0.329, ppl=1.26, wps=23826.5, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=10800, lr=0.00030429, gnorm=0.597, loss_scale=32, train_wall=224, gb_free=8.8, wall=37340
2022-03-06 23:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:26:29 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 15.373 | nll_loss 15.231 | ppl 38466 | wps 46178 | wpb 510.9 | bsz 1 | num_updates 10848 | best_loss 8.238
2022-03-06 23:26:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10848 updates
2022-03-06 23:26:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:26:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:26:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 223 @ 10848 updates, score 15.373) (writing took 2.569909241050482 seconds)
2022-03-06 23:26:31 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-06 23:26:31 | INFO | train | epoch 223 | loss 0.661 | nll_loss 0.326 | ppl 1.25 | wps 24697.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10848 | lr 0.000303616 | gnorm 0.602 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37466
2022-03-06 23:26:31 | INFO | fairseq.trainer | begin training epoch 224
2022-03-06 23:26:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:28:37 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 15.313 | nll_loss 15.172 | ppl 36912.5 | wps 46304 | wpb 510.9 | bsz 1 | num_updates 10897 | best_loss 8.238
2022-03-06 23:28:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10897 updates
2022-03-06 23:28:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:28:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:28:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 224 @ 10897 updates, score 15.313) (writing took 2.516209002584219 seconds)
2022-03-06 23:28:40 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-06 23:28:40 | INFO | train | epoch 224 | loss 0.658 | nll_loss 0.323 | ppl 1.25 | wps 24706.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10897 | lr 0.000302933 | gnorm 0.59 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37595
2022-03-06 23:28:40 | INFO | fairseq.trainer | begin training epoch 225
2022-03-06 23:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:28:47 | INFO | train_inner | epoch 225:      3 / 49 loss=0.659, nll_loss=0.324, ppl=1.25, wps=24732.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.596, loss_scale=32, train_wall=223, gb_free=8.8, wall=37603
2022-03-06 23:30:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:30:46 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 15.375 | nll_loss 15.233 | ppl 38523.3 | wps 46446.7 | wpb 510.9 | bsz 1 | num_updates 10946 | best_loss 8.238
2022-03-06 23:30:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10946 updates
2022-03-06 23:30:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:30:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:30:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 225 @ 10946 updates, score 15.375) (writing took 2.532699529081583 seconds)
2022-03-06 23:30:48 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-06 23:30:48 | INFO | train | epoch 225 | loss 0.655 | nll_loss 0.32 | ppl 1.25 | wps 24734 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 10946 | lr 0.000302254 | gnorm 0.577 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 37724
2022-03-06 23:30:48 | INFO | fairseq.trainer | begin training epoch 226
2022-03-06 23:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:31:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:54 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 15.472 | nll_loss 15.335 | ppl 41325.7 | wps 46518.3 | wpb 510.9 | bsz 1 | num_updates 10994 | best_loss 8.238
2022-03-06 23:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10994 updates
2022-03-06 23:32:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:32:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:32:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 226 @ 10994 updates, score 15.472) (writing took 2.53735170327127 seconds)
2022-03-06 23:32:57 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-06 23:32:57 | INFO | train | epoch 226 | loss 0.655 | nll_loss 0.32 | ppl 1.25 | wps 24201 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 10994 | lr 0.000301594 | gnorm 0.589 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37852
2022-03-06 23:32:57 | INFO | fairseq.trainer | begin training epoch 227
2022-03-06 23:32:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:33:12 | INFO | train_inner | epoch 227:      6 / 49 loss=0.655, nll_loss=0.32, ppl=1.25, wps=24514.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.583, loss_scale=32, train_wall=225, gb_free=8.8, wall=37867
2022-03-06 23:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:35:03 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 15.417 | nll_loss 15.279 | ppl 39753.8 | wps 46602.4 | wpb 510.9 | bsz 1 | num_updates 11043 | best_loss 8.238
2022-03-06 23:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11043 updates
2022-03-06 23:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 227 @ 11043 updates, score 15.417) (writing took 2.5264150090515614 seconds)
2022-03-06 23:35:06 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-06 23:35:06 | INFO | train | epoch 227 | loss 0.653 | nll_loss 0.318 | ppl 1.25 | wps 24710.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11043 | lr 0.000300924 | gnorm 0.583 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 37981
2022-03-06 23:35:06 | INFO | fairseq.trainer | begin training epoch 228
2022-03-06 23:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:12 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 15.432 | nll_loss 15.293 | ppl 40158.7 | wps 46792.4 | wpb 510.9 | bsz 1 | num_updates 11092 | best_loss 8.238
2022-03-06 23:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11092 updates
2022-03-06 23:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:37:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 228 @ 11092 updates, score 15.432) (writing took 2.532391060143709 seconds)
2022-03-06 23:37:14 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-06 23:37:14 | INFO | train | epoch 228 | loss 0.65 | nll_loss 0.316 | ppl 1.24 | wps 24727.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11092 | lr 0.000300258 | gnorm 0.576 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 38109
2022-03-06 23:37:14 | INFO | fairseq.trainer | begin training epoch 229
2022-03-06 23:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:37:34 | INFO | train_inner | epoch 229:      8 / 49 loss=0.651, nll_loss=0.316, ppl=1.25, wps=24749.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.578, loss_scale=64, train_wall=223, gb_free=8.8, wall=38129
2022-03-06 23:37:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:39:20 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 15.442 | nll_loss 15.306 | ppl 40521.3 | wps 46217 | wpb 510.9 | bsz 1 | num_updates 11140 | best_loss 8.238
2022-03-06 23:39:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11140 updates
2022-03-06 23:39:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:39:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 229 @ 11140 updates, score 15.442) (writing took 2.5126847121864557 seconds)
2022-03-06 23:39:23 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-06 23:39:23 | INFO | train | epoch 229 | loss 0.649 | nll_loss 0.314 | ppl 1.24 | wps 24194.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11140 | lr 0.000299611 | gnorm 0.577 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38238
2022-03-06 23:39:23 | INFO | fairseq.trainer | begin training epoch 230
2022-03-06 23:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:41:29 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 15.388 | nll_loss 15.249 | ppl 38934.1 | wps 46364.1 | wpb 510.9 | bsz 1 | num_updates 11189 | best_loss 8.238
2022-03-06 23:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11189 updates
2022-03-06 23:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:41:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 230 @ 11189 updates, score 15.388) (writing took 2.5255124624818563 seconds)
2022-03-06 23:41:31 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-06 23:41:31 | INFO | train | epoch 230 | loss 0.646 | nll_loss 0.312 | ppl 1.24 | wps 24736.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11189 | lr 0.000298954 | gnorm 0.583 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38366
2022-03-06 23:41:31 | INFO | fairseq.trainer | begin training epoch 231
2022-03-06 23:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:41:59 | INFO | train_inner | epoch 231:     11 / 49 loss=0.647, nll_loss=0.313, ppl=1.24, wps=24513.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.58, loss_scale=32, train_wall=225, gb_free=8.8, wall=38394
2022-03-06 23:43:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:43:37 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 15.424 | nll_loss 15.287 | ppl 39993.9 | wps 46497.2 | wpb 510.9 | bsz 1 | num_updates 11237 | best_loss 8.238
2022-03-06 23:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11237 updates
2022-03-06 23:43:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:43:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 231 @ 11237 updates, score 15.424) (writing took 2.5043514985591173 seconds)
2022-03-06 23:43:40 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-06 23:43:40 | INFO | train | epoch 231 | loss 0.644 | nll_loss 0.31 | ppl 1.24 | wps 24212 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11237 | lr 0.000298315 | gnorm 0.579 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38495
2022-03-06 23:43:40 | INFO | fairseq.trainer | begin training epoch 232
2022-03-06 23:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:45:46 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 15.396 | nll_loss 15.257 | ppl 39149.6 | wps 46398.9 | wpb 510.9 | bsz 1 | num_updates 11286 | best_loss 8.238
2022-03-06 23:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11286 updates
2022-03-06 23:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:45:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:45:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 232 @ 11286 updates, score 15.396) (writing took 2.535206701606512 seconds)
2022-03-06 23:45:49 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-06 23:45:49 | INFO | train | epoch 232 | loss 0.643 | nll_loss 0.31 | ppl 1.24 | wps 24665.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11286 | lr 0.000297667 | gnorm 0.577 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 38624
2022-03-06 23:45:49 | INFO | fairseq.trainer | begin training epoch 233
2022-03-06 23:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:46:24 | INFO | train_inner | epoch 233:     14 / 49 loss=0.643, nll_loss=0.309, ppl=1.24, wps=24495.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.576, loss_scale=32, train_wall=226, gb_free=8.8, wall=38659
2022-03-06 23:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:47:55 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 15.385 | nll_loss 15.247 | ppl 38899.6 | wps 46353.9 | wpb 510.9 | bsz 1 | num_updates 11335 | best_loss 8.238
2022-03-06 23:47:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11335 updates
2022-03-06 23:47:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 233 @ 11335 updates, score 15.385) (writing took 2.496454259380698 seconds)
2022-03-06 23:47:57 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-06 23:47:57 | INFO | train | epoch 233 | loss 0.64 | nll_loss 0.306 | ppl 1.24 | wps 24705.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11335 | lr 0.000297022 | gnorm 0.564 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38752
2022-03-06 23:47:57 | INFO | fairseq.trainer | begin training epoch 234
2022-03-06 23:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:49:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:49:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:50:03 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 15.459 | nll_loss 15.321 | ppl 40943.8 | wps 46355.3 | wpb 510.9 | bsz 1 | num_updates 11383 | best_loss 8.238
2022-03-06 23:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11383 updates
2022-03-06 23:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:50:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:50:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 234 @ 11383 updates, score 15.459) (writing took 2.5242689717561007 seconds)
2022-03-06 23:50:06 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-06 23:50:06 | INFO | train | epoch 234 | loss 0.638 | nll_loss 0.304 | ppl 1.23 | wps 24220.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11383 | lr 0.000296396 | gnorm 0.564 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 38881
2022-03-06 23:50:06 | INFO | fairseq.trainer | begin training epoch 235
2022-03-06 23:50:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:50:48 | INFO | train_inner | epoch 235:     17 / 49 loss=0.639, nll_loss=0.305, ppl=1.24, wps=24515.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.565, loss_scale=32, train_wall=225, gb_free=8.8, wall=38923
2022-03-06 23:52:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:12 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 15.395 | nll_loss 15.261 | ppl 39256.4 | wps 46515.3 | wpb 510.9 | bsz 1 | num_updates 11432 | best_loss 8.238
2022-03-06 23:52:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11432 updates
2022-03-06 23:52:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 235 @ 11432 updates, score 15.395) (writing took 2.510406143963337 seconds)
2022-03-06 23:52:14 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-06 23:52:14 | INFO | train | epoch 235 | loss 0.637 | nll_loss 0.304 | ppl 1.23 | wps 24771.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11432 | lr 0.00029576 | gnorm 0.567 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 39009
2022-03-06 23:52:14 | INFO | fairseq.trainer | begin training epoch 236
2022-03-06 23:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:54:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:20 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 15.383 | nll_loss 15.247 | ppl 38883.6 | wps 46087.8 | wpb 510.9 | bsz 1 | num_updates 11480 | best_loss 8.238
2022-03-06 23:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11480 updates
2022-03-06 23:54:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:54:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 236 @ 11480 updates, score 15.383) (writing took 2.5192149560898542 seconds)
2022-03-06 23:54:23 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-06 23:54:23 | INFO | train | epoch 236 | loss 0.636 | nll_loss 0.302 | ppl 1.23 | wps 24212 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11480 | lr 0.000295141 | gnorm 0.563 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39138
2022-03-06 23:54:23 | INFO | fairseq.trainer | begin training epoch 237
2022-03-06 23:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:55:13 | INFO | train_inner | epoch 237:     20 / 49 loss=0.636, nll_loss=0.302, ppl=1.23, wps=24536.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.564, loss_scale=16, train_wall=225, gb_free=8.8, wall=39188
2022-03-06 23:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:29 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 15.498 | nll_loss 15.363 | ppl 42139.3 | wps 46533.4 | wpb 510.9 | bsz 1 | num_updates 11529 | best_loss 8.238
2022-03-06 23:56:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11529 updates
2022-03-06 23:56:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:56:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 237 @ 11529 updates, score 15.498) (writing took 2.520878391340375 seconds)
2022-03-06 23:56:31 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-06 23:56:31 | INFO | train | epoch 237 | loss 0.634 | nll_loss 0.3 | ppl 1.23 | wps 24716.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11529 | lr 0.000294513 | gnorm 0.567 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39266
2022-03-06 23:56:31 | INFO | fairseq.trainer | begin training epoch 238
2022-03-06 23:56:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:58:37 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 15.411 | nll_loss 15.277 | ppl 39705.1 | wps 46251.3 | wpb 510.9 | bsz 1 | num_updates 11578 | best_loss 8.238
2022-03-06 23:58:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11578 updates
2022-03-06 23:58:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:58:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-06 23:58:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 238 @ 11578 updates, score 15.411) (writing took 2.505965184420347 seconds)
2022-03-06 23:58:40 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-06 23:58:40 | INFO | train | epoch 238 | loss 0.63 | nll_loss 0.297 | ppl 1.23 | wps 24749.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11578 | lr 0.000293889 | gnorm 0.55 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 39395
2022-03-06 23:58:40 | INFO | fairseq.trainer | begin training epoch 239
2022-03-06 23:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:59:35 | INFO | train_inner | epoch 239:     22 / 49 loss=0.631, nll_loss=0.298, ppl=1.23, wps=24758.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.558, loss_scale=32, train_wall=223, gb_free=8.8, wall=39450
2022-03-07 00:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:00:46 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 15.402 | nll_loss 15.266 | ppl 39396 | wps 46525.4 | wpb 510.9 | bsz 1 | num_updates 11627 | best_loss 8.238
2022-03-07 00:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11627 updates
2022-03-07 00:00:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:00:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 239 @ 11627 updates, score 15.402) (writing took 2.5340221356600523 seconds)
2022-03-07 00:00:48 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 00:00:48 | INFO | train | epoch 239 | loss 0.63 | nll_loss 0.297 | ppl 1.23 | wps 24687.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11627 | lr 0.000293269 | gnorm 0.564 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 39524
2022-03-07 00:00:48 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 00:00:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:02:55 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 15.452 | nll_loss 15.317 | ppl 40823.8 | wps 46620.8 | wpb 510.9 | bsz 1 | num_updates 11676 | best_loss 8.238
2022-03-07 00:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11676 updates
2022-03-07 00:02:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:02:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 240 @ 11676 updates, score 15.452) (writing took 2.506753470748663 seconds)
2022-03-07 00:02:57 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 00:02:57 | INFO | train | epoch 240 | loss 0.628 | nll_loss 0.295 | ppl 1.23 | wps 24680.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11676 | lr 0.000292653 | gnorm 0.556 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 39652
2022-03-07 00:02:57 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 00:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:03:57 | INFO | train_inner | epoch 241:     24 / 49 loss=0.628, nll_loss=0.295, ppl=1.23, wps=24711, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.558, loss_scale=32, train_wall=224, gb_free=8.8, wall=39712
2022-03-07 00:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:05:03 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 15.345 | nll_loss 15.209 | ppl 37882.8 | wps 46497.3 | wpb 510.9 | bsz 1 | num_updates 11725 | best_loss 8.238
2022-03-07 00:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11725 updates
2022-03-07 00:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 241 @ 11725 updates, score 15.345) (writing took 2.524541424587369 seconds)
2022-03-07 00:05:06 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 00:05:06 | INFO | train | epoch 241 | loss 0.627 | nll_loss 0.294 | ppl 1.23 | wps 24704.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11725 | lr 0.000292041 | gnorm 0.552 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 39781
2022-03-07 00:05:06 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 00:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:07:12 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 15.393 | nll_loss 15.257 | ppl 39154.8 | wps 46549.2 | wpb 510.9 | bsz 1 | num_updates 11773 | best_loss 8.238
2022-03-07 00:07:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11773 updates
2022-03-07 00:07:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 242 @ 11773 updates, score 15.393) (writing took 2.5286411475390196 seconds)
2022-03-07 00:07:14 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 00:07:14 | INFO | train | epoch 242 | loss 0.626 | nll_loss 0.293 | ppl 1.23 | wps 24201.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11773 | lr 0.000291445 | gnorm 0.551 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 39910
2022-03-07 00:07:14 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 00:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:08:22 | INFO | train_inner | epoch 243:     27 / 49 loss=0.626, nll_loss=0.293, ppl=1.23, wps=24510.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.548, loss_scale=32, train_wall=226, gb_free=8.8, wall=39977
2022-03-07 00:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:09:20 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 15.416 | nll_loss 15.282 | ppl 39836.6 | wps 46431.2 | wpb 510.9 | bsz 1 | num_updates 11822 | best_loss 8.238
2022-03-07 00:09:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11822 updates
2022-03-07 00:09:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:09:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:09:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 243 @ 11822 updates, score 15.416) (writing took 2.5389302149415016 seconds)
2022-03-07 00:09:23 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 00:09:23 | INFO | train | epoch 243 | loss 0.623 | nll_loss 0.291 | ppl 1.22 | wps 24710.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11822 | lr 0.00029084 | gnorm 0.547 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40038
2022-03-07 00:09:23 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 00:09:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:11:29 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 15.401 | nll_loss 15.269 | ppl 39476.5 | wps 46479.8 | wpb 510.9 | bsz 1 | num_updates 11871 | best_loss 8.238
2022-03-07 00:11:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11871 updates
2022-03-07 00:11:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 244 @ 11871 updates, score 15.401) (writing took 2.5210245586931705 seconds)
2022-03-07 00:11:32 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 00:11:32 | INFO | train | epoch 244 | loss 0.622 | nll_loss 0.289 | ppl 1.22 | wps 24725.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11871 | lr 0.000290239 | gnorm 0.547 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 40167
2022-03-07 00:11:32 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 00:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:12:46 | INFO | train_inner | epoch 245:     30 / 49 loss=0.621, nll_loss=0.289, ppl=1.22, wps=24517.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.547, loss_scale=32, train_wall=225, gb_free=8.8, wall=40242
2022-03-07 00:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:37 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 15.415 | nll_loss 15.282 | ppl 39854.4 | wps 46620.4 | wpb 510.9 | bsz 1 | num_updates 11919 | best_loss 8.238
2022-03-07 00:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11919 updates
2022-03-07 00:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 245 @ 11919 updates, score 15.415) (writing took 2.532364124432206 seconds)
2022-03-07 00:13:40 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 00:13:40 | INFO | train | epoch 245 | loss 0.619 | nll_loss 0.287 | ppl 1.22 | wps 24239.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 11919 | lr 0.000289654 | gnorm 0.537 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40295
2022-03-07 00:13:40 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 00:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:46 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 15.373 | nll_loss 15.24 | ppl 38691.4 | wps 46462.7 | wpb 510.9 | bsz 1 | num_updates 11968 | best_loss 8.238
2022-03-07 00:15:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11968 updates
2022-03-07 00:15:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:15:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:15:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 246 @ 11968 updates, score 15.373) (writing took 2.5308676287531853 seconds)
2022-03-07 00:15:48 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 00:15:48 | INFO | train | epoch 246 | loss 0.617 | nll_loss 0.285 | ppl 1.22 | wps 24725.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 11968 | lr 0.000289061 | gnorm 0.536 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40424
2022-03-07 00:15:48 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 00:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:17:09 | INFO | train_inner | epoch 247:     32 / 49 loss=0.617, nll_loss=0.285, ppl=1.22, wps=24756.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.535, loss_scale=32, train_wall=223, gb_free=8.8, wall=40504
2022-03-07 00:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:55 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 15.328 | nll_loss 15.195 | ppl 37509.5 | wps 46309.5 | wpb 510.9 | bsz 1 | num_updates 12017 | best_loss 8.238
2022-03-07 00:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12017 updates
2022-03-07 00:17:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:17:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:17:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 247 @ 12017 updates, score 15.328) (writing took 2.5320475324988365 seconds)
2022-03-07 00:17:57 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 00:17:57 | INFO | train | epoch 247 | loss 0.617 | nll_loss 0.285 | ppl 1.22 | wps 24684.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12017 | lr 0.000288471 | gnorm 0.535 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 40552
2022-03-07 00:17:57 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 00:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:18:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:20:03 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 15.383 | nll_loss 15.248 | ppl 38926.2 | wps 46424.8 | wpb 510.9 | bsz 1 | num_updates 12065 | best_loss 8.238
2022-03-07 00:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12065 updates
2022-03-07 00:20:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 248 @ 12065 updates, score 15.383) (writing took 2.528217965736985 seconds)
2022-03-07 00:20:06 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 00:20:06 | INFO | train | epoch 248 | loss 0.615 | nll_loss 0.283 | ppl 1.22 | wps 24177.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12065 | lr 0.000287896 | gnorm 0.542 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40681
2022-03-07 00:20:06 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 00:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:21:34 | INFO | train_inner | epoch 249:     35 / 49 loss=0.614, nll_loss=0.283, ppl=1.22, wps=24476.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.537, loss_scale=32, train_wall=226, gb_free=8.8, wall=40769
2022-03-07 00:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:22:12 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 15.358 | nll_loss 15.225 | ppl 38301.1 | wps 46407.3 | wpb 510.9 | bsz 1 | num_updates 12114 | best_loss 8.238
2022-03-07 00:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12114 updates
2022-03-07 00:22:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:22:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:22:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 249 @ 12114 updates, score 15.358) (writing took 2.5328411236405373 seconds)
2022-03-07 00:22:15 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 00:22:15 | INFO | train | epoch 249 | loss 0.613 | nll_loss 0.281 | ppl 1.21 | wps 24702.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12114 | lr 0.000287314 | gnorm 0.534 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 40810
2022-03-07 00:22:15 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 00:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:20 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 15.431 | nll_loss 15.298 | ppl 40272.6 | wps 46740.4 | wpb 510.9 | bsz 1 | num_updates 12163 | best_loss 8.238
2022-03-07 00:24:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12163 updates
2022-03-07 00:24:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:24:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 250 @ 12163 updates, score 15.431) (writing took 2.5073376782238483 seconds)
2022-03-07 00:24:23 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 00:24:23 | INFO | train | epoch 250 | loss 0.613 | nll_loss 0.281 | ppl 1.22 | wps 24780.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12163 | lr 0.000286734 | gnorm 0.54 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 40938
2022-03-07 00:24:23 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 00:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:25:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:25:58 | INFO | train_inner | epoch 251:     38 / 49 loss=0.612, nll_loss=0.281, ppl=1.21, wps=24544.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.535, loss_scale=32, train_wall=225, gb_free=8.8, wall=41033
2022-03-07 00:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:29 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 15.417 | nll_loss 15.286 | ppl 39944.7 | wps 46466.5 | wpb 510.9 | bsz 1 | num_updates 12211 | best_loss 8.238
2022-03-07 00:26:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12211 updates
2022-03-07 00:26:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:26:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:26:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 251 @ 12211 updates, score 15.417) (writing took 2.5215734485536814 seconds)
2022-03-07 00:26:31 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 00:26:31 | INFO | train | epoch 251 | loss 0.611 | nll_loss 0.279 | ppl 1.21 | wps 24214.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12211 | lr 0.00028617 | gnorm 0.532 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41067
2022-03-07 00:26:31 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 00:26:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:28:38 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 15.401 | nll_loss 15.269 | ppl 39481.6 | wps 46462.4 | wpb 510.9 | bsz 1 | num_updates 12260 | best_loss 8.238
2022-03-07 00:28:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12260 updates
2022-03-07 00:28:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:28:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:28:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 252 @ 12260 updates, score 15.401) (writing took 2.51950547657907 seconds)
2022-03-07 00:28:40 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 00:28:40 | INFO | train | epoch 252 | loss 0.609 | nll_loss 0.278 | ppl 1.21 | wps 24703 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12260 | lr 0.000285598 | gnorm 0.533 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41195
2022-03-07 00:28:40 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 00:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:30:20 | INFO | train_inner | epoch 253:     40 / 49 loss=0.609, nll_loss=0.278, ppl=1.21, wps=24734, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.535, loss_scale=32, train_wall=223, gb_free=8.8, wall=41295
2022-03-07 00:30:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:30:46 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 15.419 | nll_loss 15.286 | ppl 39947.2 | wps 45884.9 | wpb 510.9 | bsz 1 | num_updates 12309 | best_loss 8.238
2022-03-07 00:30:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12309 updates
2022-03-07 00:30:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 253 @ 12309 updates, score 15.419) (writing took 2.566837230697274 seconds)
2022-03-07 00:30:49 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 00:30:49 | INFO | train | epoch 253 | loss 0.608 | nll_loss 0.277 | ppl 1.21 | wps 24674.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12309 | lr 0.000285029 | gnorm 0.533 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 41324
2022-03-07 00:30:49 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 00:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:32:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:32:55 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 15.357 | nll_loss 15.224 | ppl 38283.4 | wps 45905.3 | wpb 510.9 | bsz 1 | num_updates 12357 | best_loss 8.238
2022-03-07 00:32:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12357 updates
2022-03-07 00:32:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:32:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:32:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 254 @ 12357 updates, score 15.357) (writing took 2.5090048499405384 seconds)
2022-03-07 00:32:58 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 00:32:58 | INFO | train | epoch 254 | loss 0.606 | nll_loss 0.275 | ppl 1.21 | wps 24184.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12357 | lr 0.000284475 | gnorm 0.53 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41453
2022-03-07 00:32:58 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 00:32:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:33:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:34:48 | INFO | train_inner | epoch 255:     44 / 49 loss=0.606, nll_loss=0.275, ppl=1.21, wps=24254, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.53, loss_scale=16, train_wall=228, gb_free=8.8, wall=41563
2022-03-07 00:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:35:04 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 15.302 | nll_loss 15.17 | ppl 36860.6 | wps 46454.4 | wpb 510.9 | bsz 1 | num_updates 12405 | best_loss 8.238
2022-03-07 00:35:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12405 updates
2022-03-07 00:35:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 255 @ 12405 updates, score 15.302) (writing took 2.5272748060524464 seconds)
2022-03-07 00:35:06 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 00:35:06 | INFO | train | epoch 255 | loss 0.605 | nll_loss 0.274 | ppl 1.21 | wps 24206.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12405 | lr 0.000283924 | gnorm 0.531 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 41581
2022-03-07 00:35:06 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 00:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:37:12 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 15.39 | nll_loss 15.259 | ppl 39213.4 | wps 46455.6 | wpb 510.9 | bsz 1 | num_updates 12454 | best_loss 8.238
2022-03-07 00:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12454 updates
2022-03-07 00:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:37:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 256 @ 12454 updates, score 15.39) (writing took 2.509392339736223 seconds)
2022-03-07 00:37:15 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 00:37:15 | INFO | train | epoch 256 | loss 0.603 | nll_loss 0.273 | ppl 1.21 | wps 24751.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12454 | lr 0.000283365 | gnorm 0.527 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 41710
2022-03-07 00:37:15 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 00:37:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:39:10 | INFO | train_inner | epoch 257:     46 / 49 loss=0.603, nll_loss=0.273, ppl=1.21, wps=24770.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.528, loss_scale=16, train_wall=223, gb_free=8.8, wall=41825
2022-03-07 00:39:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:39:20 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 15.382 | nll_loss 15.251 | ppl 38987.4 | wps 46591.4 | wpb 510.9 | bsz 1 | num_updates 12503 | best_loss 8.238
2022-03-07 00:39:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12503 updates
2022-03-07 00:39:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:39:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 257 @ 12503 updates, score 15.382) (writing took 2.5293711833655834 seconds)
2022-03-07 00:39:23 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 00:39:23 | INFO | train | epoch 257 | loss 0.603 | nll_loss 0.272 | ppl 1.21 | wps 24734.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12503 | lr 0.000282809 | gnorm 0.529 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 41838
2022-03-07 00:39:23 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 00:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:41:29 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 15.38 | nll_loss 15.25 | ppl 38967.7 | wps 46504.9 | wpb 510.9 | bsz 1 | num_updates 12552 | best_loss 8.238
2022-03-07 00:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12552 updates
2022-03-07 00:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 258 @ 12552 updates, score 15.38) (writing took 2.517125165089965 seconds)
2022-03-07 00:41:32 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 00:41:32 | INFO | train | epoch 258 | loss 0.599 | nll_loss 0.269 | ppl 1.2 | wps 24714.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12552 | lr 0.000282256 | gnorm 0.514 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 41967
2022-03-07 00:41:32 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 00:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:43:32 | INFO | train_inner | epoch 259:     48 / 49 loss=0.6, nll_loss=0.27, ppl=1.21, wps=24756.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.523, loss_scale=32, train_wall=223, gb_free=8.8, wall=42087
2022-03-07 00:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:43:38 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 15.348 | nll_loss 15.218 | ppl 38110.4 | wps 46347.4 | wpb 510.9 | bsz 1 | num_updates 12601 | best_loss 8.238
2022-03-07 00:43:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12601 updates
2022-03-07 00:43:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:43:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 259 @ 12601 updates, score 15.348) (writing took 2.536228770390153 seconds)
2022-03-07 00:43:40 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 00:43:40 | INFO | train | epoch 259 | loss 0.6 | nll_loss 0.269 | ppl 1.21 | wps 24732.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12601 | lr 0.000281707 | gnorm 0.531 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42095
2022-03-07 00:43:40 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 00:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:45:46 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 15.362 | nll_loss 15.233 | ppl 38510.8 | wps 46442.8 | wpb 510.9 | bsz 1 | num_updates 12650 | best_loss 8.238
2022-03-07 00:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12650 updates
2022-03-07 00:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:45:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:45:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 260 @ 12650 updates, score 15.362) (writing took 2.5106779038906097 seconds)
2022-03-07 00:45:49 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 00:45:49 | INFO | train | epoch 260 | loss 0.596 | nll_loss 0.266 | ppl 1.2 | wps 24745.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12650 | lr 0.000281161 | gnorm 0.509 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 42224
2022-03-07 00:45:49 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 00:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:47:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:47:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:47:55 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 15.284 | nll_loss 15.154 | ppl 36450 | wps 46401.7 | wpb 510.9 | bsz 1 | num_updates 12697 | best_loss 8.238
2022-03-07 00:47:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12697 updates
2022-03-07 00:47:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 261 @ 12697 updates, score 15.284) (writing took 2.569889610633254 seconds)
2022-03-07 00:47:57 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 00:47:57 | INFO | train | epoch 261 | loss 0.596 | nll_loss 0.266 | ppl 1.2 | wps 23701.5 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 12697 | lr 0.00028064 | gnorm 0.516 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 42352
2022-03-07 00:47:57 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 00:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:48:05 | INFO | train_inner | epoch 262:      3 / 49 loss=0.595, nll_loss=0.265, ppl=1.2, wps=23632.3, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=12700, lr=0.000280607, gnorm=0.515, loss_scale=16, train_wall=226, gb_free=8.8, wall=42360
2022-03-07 00:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:50:03 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 15.423 | nll_loss 15.294 | ppl 40178.7 | wps 46807.2 | wpb 510.9 | bsz 1 | num_updates 12746 | best_loss 8.238
2022-03-07 00:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12746 updates
2022-03-07 00:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:50:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 262 @ 12746 updates, score 15.423) (writing took 2.547483630478382 seconds)
2022-03-07 00:50:06 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 00:50:06 | INFO | train | epoch 262 | loss 0.594 | nll_loss 0.264 | ppl 1.2 | wps 24751 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12746 | lr 0.0002801 | gnorm 0.515 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 42481
2022-03-07 00:50:06 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 00:50:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:52:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:52:11 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 15.366 | nll_loss 15.237 | ppl 38608.2 | wps 46607.4 | wpb 510.9 | bsz 1 | num_updates 12795 | best_loss 8.238
2022-03-07 00:52:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12795 updates
2022-03-07 00:52:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 263 @ 12795 updates, score 15.366) (writing took 2.5184149127453566 seconds)
2022-03-07 00:52:14 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 00:52:14 | INFO | train | epoch 263 | loss 0.594 | nll_loss 0.264 | ppl 1.2 | wps 24740.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12795 | lr 0.000279563 | gnorm 0.517 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 42609
2022-03-07 00:52:14 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 00:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:52:27 | INFO | train_inner | epoch 264:      5 / 49 loss=0.594, nll_loss=0.264, ppl=1.2, wps=24774.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.516, loss_scale=16, train_wall=223, gb_free=8.8, wall=42622
2022-03-07 00:54:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:54:20 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 15.304 | nll_loss 15.171 | ppl 36902.8 | wps 46475.6 | wpb 510.9 | bsz 1 | num_updates 12844 | best_loss 8.238
2022-03-07 00:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12844 updates
2022-03-07 00:54:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:54:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:54:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 264 @ 12844 updates, score 15.304) (writing took 2.5295014400035143 seconds)
2022-03-07 00:54:23 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 00:54:23 | INFO | train | epoch 264 | loss 0.592 | nll_loss 0.262 | ppl 1.2 | wps 24719.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12844 | lr 0.000279029 | gnorm 0.509 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42738
2022-03-07 00:54:23 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 00:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:56:28 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 15.434 | nll_loss 15.303 | ppl 40424 | wps 46503.6 | wpb 510.9 | bsz 1 | num_updates 12893 | best_loss 8.238
2022-03-07 00:56:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12893 updates
2022-03-07 00:56:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:56:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 265 @ 12893 updates, score 15.434) (writing took 2.534978613257408 seconds)
2022-03-07 00:56:31 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 00:56:31 | INFO | train | epoch 265 | loss 0.591 | nll_loss 0.262 | ppl 1.2 | wps 24758.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12893 | lr 0.000278499 | gnorm 0.507 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42866
2022-03-07 00:56:31 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 00:56:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:56:49 | INFO | train_inner | epoch 266:      7 / 49 loss=0.591, nll_loss=0.262, ppl=1.2, wps=24759.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.507, loss_scale=32, train_wall=223, gb_free=8.8, wall=42884
2022-03-07 00:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:58:37 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 15.345 | nll_loss 15.215 | ppl 38028.6 | wps 46378.1 | wpb 510.9 | bsz 1 | num_updates 12942 | best_loss 8.238
2022-03-07 00:58:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12942 updates
2022-03-07 00:58:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 00:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 266 @ 12942 updates, score 15.345) (writing took 2.516583764925599 seconds)
2022-03-07 00:58:39 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 00:58:39 | INFO | train | epoch 266 | loss 0.59 | nll_loss 0.26 | ppl 1.2 | wps 24724.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 12942 | lr 0.000277971 | gnorm 0.512 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 42995
2022-03-07 00:58:39 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 00:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:59:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:45 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 15.309 | nll_loss 15.181 | ppl 37135.5 | wps 46627.3 | wpb 510.9 | bsz 1 | num_updates 12990 | best_loss 8.238
2022-03-07 01:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12990 updates
2022-03-07 01:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:00:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 267 @ 12990 updates, score 15.309) (writing took 2.537381649017334 seconds)
2022-03-07 01:00:48 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 01:00:48 | INFO | train | epoch 267 | loss 0.587 | nll_loss 0.258 | ppl 1.2 | wps 24217 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 12990 | lr 0.000277457 | gnorm 0.505 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43123
2022-03-07 01:00:48 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 01:00:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:01:13 | INFO | train_inner | epoch 268:     10 / 49 loss=0.588, nll_loss=0.259, ppl=1.2, wps=24527.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.508, loss_scale=32, train_wall=225, gb_free=8.8, wall=43148
2022-03-07 01:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:54 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 15.319 | nll_loss 15.19 | ppl 37391.8 | wps 46561.9 | wpb 510.9 | bsz 1 | num_updates 13039 | best_loss 8.238
2022-03-07 01:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13039 updates
2022-03-07 01:02:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 268 @ 13039 updates, score 15.319) (writing took 2.5203632209450006 seconds)
2022-03-07 01:02:56 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 01:02:56 | INFO | train | epoch 268 | loss 0.587 | nll_loss 0.258 | ppl 1.2 | wps 24724.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13039 | lr 0.000276935 | gnorm 0.501 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43252
2022-03-07 01:02:57 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 01:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:04:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:05:02 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 15.371 | nll_loss 15.243 | ppl 38784.3 | wps 46895.1 | wpb 510.9 | bsz 1 | num_updates 13087 | best_loss 8.238
2022-03-07 01:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13087 updates
2022-03-07 01:05:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 269 @ 13087 updates, score 15.371) (writing took 2.5589144360274076 seconds)
2022-03-07 01:05:05 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 01:05:05 | INFO | train | epoch 269 | loss 0.586 | nll_loss 0.257 | ppl 1.19 | wps 24228.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13087 | lr 0.000276427 | gnorm 0.507 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43380
2022-03-07 01:05:05 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 01:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:05:38 | INFO | train_inner | epoch 270:     13 / 49 loss=0.586, nll_loss=0.257, ppl=1.2, wps=24524.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.502, loss_scale=32, train_wall=225, gb_free=8.8, wall=43413
2022-03-07 01:07:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:07:11 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 15.367 | nll_loss 15.238 | ppl 38637.8 | wps 46682.4 | wpb 510.9 | bsz 1 | num_updates 13135 | best_loss 8.238
2022-03-07 01:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13135 updates
2022-03-07 01:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 270 @ 13135 updates, score 15.367) (writing took 2.5323619674891233 seconds)
2022-03-07 01:07:13 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 01:07:13 | INFO | train | epoch 270 | loss 0.584 | nll_loss 0.255 | ppl 1.19 | wps 24234.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13135 | lr 0.000275921 | gnorm 0.499 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 43509
2022-03-07 01:07:13 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 01:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:09:19 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 15.405 | nll_loss 15.277 | ppl 39706.6 | wps 46583.9 | wpb 510.9 | bsz 1 | num_updates 13184 | best_loss 8.238
2022-03-07 01:09:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13184 updates
2022-03-07 01:09:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:09:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 271 @ 13184 updates, score 15.405) (writing took 2.5116760171949863 seconds)
2022-03-07 01:09:22 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 01:09:22 | INFO | train | epoch 271 | loss 0.583 | nll_loss 0.254 | ppl 1.19 | wps 24730.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13184 | lr 0.000275408 | gnorm 0.497 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 43637
2022-03-07 01:09:22 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 01:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:10:02 | INFO | train_inner | epoch 272:     16 / 49 loss=0.583, nll_loss=0.254, ppl=1.19, wps=24543.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.498, loss_scale=16, train_wall=225, gb_free=8.8, wall=43677
2022-03-07 01:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:11:28 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 15.4 | nll_loss 15.273 | ppl 39593.3 | wps 46471.3 | wpb 510.9 | bsz 1 | num_updates 13233 | best_loss 8.238
2022-03-07 01:11:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13233 updates
2022-03-07 01:11:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:11:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:11:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 272 @ 13233 updates, score 15.4) (writing took 2.5300575587898493 seconds)
2022-03-07 01:11:30 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 01:11:30 | INFO | train | epoch 272 | loss 0.582 | nll_loss 0.253 | ppl 1.19 | wps 24777.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13233 | lr 0.000274898 | gnorm 0.502 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 43765
2022-03-07 01:11:30 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 01:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:13:36 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 15.451 | nll_loss 15.324 | ppl 41028.6 | wps 46439.1 | wpb 510.9 | bsz 1 | num_updates 13282 | best_loss 8.238
2022-03-07 01:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13282 updates
2022-03-07 01:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 273 @ 13282 updates, score 15.451) (writing took 2.5117453280836344 seconds)
2022-03-07 01:13:39 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 01:13:39 | INFO | train | epoch 273 | loss 0.581 | nll_loss 0.253 | ppl 1.19 | wps 24711.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13282 | lr 0.00027439 | gnorm 0.503 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 43894
2022-03-07 01:13:39 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 01:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:14:24 | INFO | train_inner | epoch 274:     18 / 49 loss=0.582, nll_loss=0.253, ppl=1.19, wps=24762.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.502, loss_scale=32, train_wall=223, gb_free=8.8, wall=43939
2022-03-07 01:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:15:45 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 15.363 | nll_loss 15.235 | ppl 38555.1 | wps 46549.6 | wpb 510.9 | bsz 1 | num_updates 13331 | best_loss 8.238
2022-03-07 01:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13331 updates
2022-03-07 01:15:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 274 @ 13331 updates, score 15.363) (writing took 2.5229532439261675 seconds)
2022-03-07 01:15:47 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 01:15:47 | INFO | train | epoch 274 | loss 0.58 | nll_loss 0.252 | ppl 1.19 | wps 24735.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13331 | lr 0.000273885 | gnorm 0.495 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44022
2022-03-07 01:15:47 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 01:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:17:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:17:54 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 15.295 | nll_loss 15.168 | ppl 36809.1 | wps 45921.3 | wpb 510.9 | bsz 1 | num_updates 13380 | best_loss 8.238
2022-03-07 01:17:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13380 updates
2022-03-07 01:17:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 275 @ 13380 updates, score 15.295) (writing took 2.530923428013921 seconds)
2022-03-07 01:17:56 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 01:17:56 | INFO | train | epoch 275 | loss 0.578 | nll_loss 0.25 | ppl 1.19 | wps 24666.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13380 | lr 0.000273383 | gnorm 0.487 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 44151
2022-03-07 01:17:56 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 01:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:18:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:18:49 | INFO | train_inner | epoch 276:     21 / 49 loss=0.578, nll_loss=0.25, ppl=1.19, wps=24500.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.489, loss_scale=32, train_wall=226, gb_free=8.8, wall=44204
2022-03-07 01:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:02 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 15.398 | nll_loss 15.273 | ppl 39588.3 | wps 46249.9 | wpb 510.9 | bsz 1 | num_updates 13428 | best_loss 8.238
2022-03-07 01:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13428 updates
2022-03-07 01:20:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:20:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 276 @ 13428 updates, score 15.398) (writing took 2.527624972164631 seconds)
2022-03-07 01:20:05 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 01:20:05 | INFO | train | epoch 276 | loss 0.577 | nll_loss 0.249 | ppl 1.19 | wps 24171.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13428 | lr 0.000272894 | gnorm 0.495 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 44280
2022-03-07 01:20:05 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 01:20:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:22:11 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 15.401 | nll_loss 15.276 | ppl 39681.4 | wps 46809.8 | wpb 510.9 | bsz 1 | num_updates 13477 | best_loss 8.238
2022-03-07 01:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13477 updates
2022-03-07 01:22:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:22:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:22:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 277 @ 13477 updates, score 15.401) (writing took 2.5252197962254286 seconds)
2022-03-07 01:22:13 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 01:22:13 | INFO | train | epoch 277 | loss 0.576 | nll_loss 0.248 | ppl 1.19 | wps 24742.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13477 | lr 0.000272398 | gnorm 0.491 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44408
2022-03-07 01:22:13 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 01:22:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:23:11 | INFO | train_inner | epoch 278:     23 / 49 loss=0.576, nll_loss=0.248, ppl=1.19, wps=24723.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.495, loss_scale=32, train_wall=224, gb_free=8.8, wall=44466
2022-03-07 01:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:24:19 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 15.451 | nll_loss 15.325 | ppl 41050.5 | wps 46585.4 | wpb 510.9 | bsz 1 | num_updates 13525 | best_loss 8.238
2022-03-07 01:24:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13525 updates
2022-03-07 01:24:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:24:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:24:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 278 @ 13525 updates, score 15.451) (writing took 2.493444150313735 seconds)
2022-03-07 01:24:22 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 01:24:22 | INFO | train | epoch 278 | loss 0.575 | nll_loss 0.247 | ppl 1.19 | wps 24203.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13525 | lr 0.000271914 | gnorm 0.493 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44537
2022-03-07 01:24:22 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 01:24:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:26:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:26:28 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 15.379 | nll_loss 15.253 | ppl 39060.8 | wps 46524.6 | wpb 510.9 | bsz 1 | num_updates 13574 | best_loss 8.238
2022-03-07 01:26:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13574 updates
2022-03-07 01:26:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:26:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:26:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 279 @ 13574 updates, score 15.379) (writing took 2.5120110735297203 seconds)
2022-03-07 01:26:30 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 01:26:30 | INFO | train | epoch 279 | loss 0.574 | nll_loss 0.247 | ppl 1.19 | wps 24731.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13574 | lr 0.000271423 | gnorm 0.491 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 44666
2022-03-07 01:26:30 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 01:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:27:36 | INFO | train_inner | epoch 280:     26 / 49 loss=0.574, nll_loss=0.246, ppl=1.19, wps=24522.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.489, loss_scale=32, train_wall=225, gb_free=8.8, wall=44731
2022-03-07 01:27:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:28:37 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 15.371 | nll_loss 15.245 | ppl 38830.6 | wps 45195.5 | wpb 510.9 | bsz 1 | num_updates 13622 | best_loss 8.238
2022-03-07 01:28:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13622 updates
2022-03-07 01:28:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 280 @ 13622 updates, score 15.371) (writing took 2.5109602194279432 seconds)
2022-03-07 01:28:39 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 01:28:39 | INFO | train | epoch 280 | loss 0.573 | nll_loss 0.246 | ppl 1.19 | wps 24177.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13622 | lr 0.000270944 | gnorm 0.495 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 44794
2022-03-07 01:28:39 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 01:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:45 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 15.41 | nll_loss 15.284 | ppl 39897.6 | wps 46405 | wpb 510.9 | bsz 1 | num_updates 13671 | best_loss 8.238
2022-03-07 01:30:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13671 updates
2022-03-07 01:30:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:30:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:30:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 281 @ 13671 updates, score 15.41) (writing took 2.5676211062818766 seconds)
2022-03-07 01:30:48 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 01:30:48 | INFO | train | epoch 281 | loss 0.571 | nll_loss 0.244 | ppl 1.18 | wps 24707.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13671 | lr 0.000270458 | gnorm 0.491 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 44923
2022-03-07 01:30:48 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 01:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:00 | INFO | train_inner | epoch 282:     29 / 49 loss=0.572, nll_loss=0.245, ppl=1.18, wps=24513.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.493, loss_scale=16, train_wall=225, gb_free=8.8, wall=44995
2022-03-07 01:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:32:54 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 15.39 | nll_loss 15.264 | ppl 39335.9 | wps 46516.1 | wpb 510.9 | bsz 1 | num_updates 13720 | best_loss 8.238
2022-03-07 01:32:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13720 updates
2022-03-07 01:32:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:32:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 282 @ 13720 updates, score 15.39) (writing took 2.519339231774211 seconds)
2022-03-07 01:32:56 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 01:32:56 | INFO | train | epoch 282 | loss 0.569 | nll_loss 0.242 | ppl 1.18 | wps 24771.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13720 | lr 0.000269975 | gnorm 0.486 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 45051
2022-03-07 01:32:56 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 01:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:35:02 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 15.437 | nll_loss 15.313 | ppl 40708.7 | wps 46476.8 | wpb 510.9 | bsz 1 | num_updates 13769 | best_loss 8.238
2022-03-07 01:35:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13769 updates
2022-03-07 01:35:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:35:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:35:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 283 @ 13769 updates, score 15.437) (writing took 2.474529702216387 seconds)
2022-03-07 01:35:04 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 01:35:04 | INFO | train | epoch 283 | loss 0.569 | nll_loss 0.242 | ppl 1.18 | wps 24778.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13769 | lr 0.000269494 | gnorm 0.482 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45179
2022-03-07 01:35:04 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 01:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:36:22 | INFO | train_inner | epoch 284:     31 / 49 loss=0.569, nll_loss=0.242, ppl=1.18, wps=24789.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.484, loss_scale=32, train_wall=223, gb_free=8.8, wall=45257
2022-03-07 01:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:37:10 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 15.36 | nll_loss 15.236 | ppl 38581 | wps 46494.8 | wpb 510.9 | bsz 1 | num_updates 13818 | best_loss 8.238
2022-03-07 01:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13818 updates
2022-03-07 01:37:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 284 @ 13818 updates, score 15.36) (writing took 2.5411164946854115 seconds)
2022-03-07 01:37:13 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 01:37:13 | INFO | train | epoch 284 | loss 0.568 | nll_loss 0.241 | ppl 1.18 | wps 24704 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13818 | lr 0.000269016 | gnorm 0.484 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45308
2022-03-07 01:37:13 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 01:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:39:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:39:19 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 15.334 | nll_loss 15.209 | ppl 37882.9 | wps 46005.9 | wpb 510.9 | bsz 1 | num_updates 13866 | best_loss 8.238
2022-03-07 01:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13866 updates
2022-03-07 01:39:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:39:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:39:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 285 @ 13866 updates, score 15.334) (writing took 2.4872118961066008 seconds)
2022-03-07 01:39:21 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 01:39:21 | INFO | train | epoch 285 | loss 0.566 | nll_loss 0.239 | ppl 1.18 | wps 24230.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 13866 | lr 0.00026855 | gnorm 0.481 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45437
2022-03-07 01:39:21 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 01:39:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:40:46 | INFO | train_inner | epoch 286:     34 / 49 loss=0.566, nll_loss=0.239, ppl=1.18, wps=24534.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.482, loss_scale=32, train_wall=225, gb_free=8.8, wall=45521
2022-03-07 01:41:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:41:27 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 15.404 | nll_loss 15.28 | ppl 39795.4 | wps 46536.7 | wpb 510.9 | bsz 1 | num_updates 13915 | best_loss 8.238
2022-03-07 01:41:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13915 updates
2022-03-07 01:41:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:41:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 286 @ 13915 updates, score 15.404) (writing took 2.5080279409885406 seconds)
2022-03-07 01:41:30 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 01:41:30 | INFO | train | epoch 286 | loss 0.566 | nll_loss 0.24 | ppl 1.18 | wps 24766.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13915 | lr 0.000268076 | gnorm 0.481 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45565
2022-03-07 01:41:30 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 01:41:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:43:36 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 15.41 | nll_loss 15.286 | ppl 39945.3 | wps 46677.2 | wpb 510.9 | bsz 1 | num_updates 13964 | best_loss 8.238
2022-03-07 01:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13964 updates
2022-03-07 01:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:43:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:43:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 287 @ 13964 updates, score 15.41) (writing took 2.536404252052307 seconds)
2022-03-07 01:43:38 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 01:43:38 | INFO | train | epoch 287 | loss 0.565 | nll_loss 0.239 | ppl 1.18 | wps 24742.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 13964 | lr 0.000267606 | gnorm 0.482 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45693
2022-03-07 01:43:38 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 01:43:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:45:08 | INFO | train_inner | epoch 288:     36 / 49 loss=0.565, nll_loss=0.239, ppl=1.18, wps=24771.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.479, loss_scale=64, train_wall=223, gb_free=8.8, wall=45783
2022-03-07 01:45:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:44 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 15.297 | nll_loss 15.173 | ppl 36937.2 | wps 46511 | wpb 510.9 | bsz 1 | num_updates 14012 | best_loss 8.238
2022-03-07 01:45:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14012 updates
2022-03-07 01:45:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 288 @ 14012 updates, score 15.297) (writing took 2.5070142596960068 seconds)
2022-03-07 01:45:47 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 01:45:47 | INFO | train | epoch 288 | loss 0.563 | nll_loss 0.237 | ppl 1.18 | wps 24229.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14012 | lr 0.000267147 | gnorm 0.475 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45822
2022-03-07 01:45:47 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 01:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:47:52 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 15.384 | nll_loss 15.259 | ppl 39217.4 | wps 45790.5 | wpb 510.9 | bsz 1 | num_updates 14061 | best_loss 8.238
2022-03-07 01:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14061 updates
2022-03-07 01:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 289 @ 14061 updates, score 15.384) (writing took 2.4944641571491957 seconds)
2022-03-07 01:47:55 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 01:47:55 | INFO | train | epoch 289 | loss 0.562 | nll_loss 0.236 | ppl 1.18 | wps 24763 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14061 | lr 0.000266681 | gnorm 0.48 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 45950
2022-03-07 01:47:55 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 01:47:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:49:33 | INFO | train_inner | epoch 290:     39 / 49 loss=0.562, nll_loss=0.236, ppl=1.18, wps=24538.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.476, loss_scale=32, train_wall=225, gb_free=8.8, wall=46048
2022-03-07 01:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:50:01 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 15.355 | nll_loss 15.231 | ppl 38457.1 | wps 46627 | wpb 510.9 | bsz 1 | num_updates 14110 | best_loss 8.238
2022-03-07 01:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14110 updates
2022-03-07 01:50:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 290 @ 14110 updates, score 15.355) (writing took 2.485997097566724 seconds)
2022-03-07 01:50:03 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 01:50:03 | INFO | train | epoch 290 | loss 0.561 | nll_loss 0.235 | ppl 1.18 | wps 24739.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14110 | lr 0.000266217 | gnorm 0.474 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46079
2022-03-07 01:50:03 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 01:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:52:09 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 15.404 | nll_loss 15.281 | ppl 39803.2 | wps 46647.5 | wpb 510.9 | bsz 1 | num_updates 14159 | best_loss 8.238
2022-03-07 01:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14159 updates
2022-03-07 01:52:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 291 @ 14159 updates, score 15.404) (writing took 2.547443026676774 seconds)
2022-03-07 01:52:12 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 01:52:12 | INFO | train | epoch 291 | loss 0.56 | nll_loss 0.234 | ppl 1.18 | wps 24716.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14159 | lr 0.000265756 | gnorm 0.473 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 46207
2022-03-07 01:52:12 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 01:52:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:52:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:53:57 | INFO | train_inner | epoch 292:     42 / 49 loss=0.56, nll_loss=0.234, ppl=1.18, wps=24516.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.472, loss_scale=32, train_wall=226, gb_free=8.8, wall=46312
2022-03-07 01:54:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:54:18 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 15.406 | nll_loss 15.283 | ppl 39859.4 | wps 46753.3 | wpb 510.9 | bsz 1 | num_updates 14207 | best_loss 8.238
2022-03-07 01:54:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14207 updates
2022-03-07 01:54:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:54:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 292 @ 14207 updates, score 15.406) (writing took 2.4856882002204657 seconds)
2022-03-07 01:54:21 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 01:54:21 | INFO | train | epoch 292 | loss 0.559 | nll_loss 0.233 | ppl 1.18 | wps 24219.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14207 | lr 0.000265307 | gnorm 0.467 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46336
2022-03-07 01:54:21 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 01:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:56:26 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 15.466 | nll_loss 15.344 | ppl 41581.2 | wps 46642.4 | wpb 510.9 | bsz 1 | num_updates 14256 | best_loss 8.238
2022-03-07 01:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14256 updates
2022-03-07 01:56:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 293 @ 14256 updates, score 15.466) (writing took 2.5198671482503414 seconds)
2022-03-07 01:56:29 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 01:56:29 | INFO | train | epoch 293 | loss 0.559 | nll_loss 0.233 | ppl 1.18 | wps 24741 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14256 | lr 0.000264851 | gnorm 0.472 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46464
2022-03-07 01:56:29 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 01:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:58:19 | INFO | train_inner | epoch 294:     44 / 49 loss=0.558, nll_loss=0.232, ppl=1.17, wps=24779.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.47, loss_scale=64, train_wall=223, gb_free=8.8, wall=46574
2022-03-07 01:58:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:58:35 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 15.405 | nll_loss 15.284 | ppl 39892.3 | wps 45188.3 | wpb 510.9 | bsz 1 | num_updates 14305 | best_loss 8.238
2022-03-07 01:58:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14305 updates
2022-03-07 01:58:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:58:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 01:58:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 294 @ 14305 updates, score 15.405) (writing took 2.531778806820512 seconds)
2022-03-07 01:58:38 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 01:58:38 | INFO | train | epoch 294 | loss 0.557 | nll_loss 0.231 | ppl 1.17 | wps 24716.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14305 | lr 0.000264397 | gnorm 0.467 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 46593
2022-03-07 01:58:38 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 01:58:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:00:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:00:44 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 15.358 | nll_loss 15.234 | ppl 38546.4 | wps 46086.7 | wpb 510.9 | bsz 1 | num_updates 14353 | best_loss 8.238
2022-03-07 02:00:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14353 updates
2022-03-07 02:00:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:00:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:00:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 295 @ 14353 updates, score 15.358) (writing took 2.497795708477497 seconds)
2022-03-07 02:00:46 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 02:00:46 | INFO | train | epoch 295 | loss 0.557 | nll_loss 0.232 | ppl 1.17 | wps 24228.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14353 | lr 0.000263954 | gnorm 0.474 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46721
2022-03-07 02:00:46 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 02:00:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:02:44 | INFO | train_inner | epoch 296:     47 / 49 loss=0.557, nll_loss=0.231, ppl=1.17, wps=24502.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.469, loss_scale=32, train_wall=225, gb_free=8.8, wall=46839
2022-03-07 02:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:02:52 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 15.424 | nll_loss 15.301 | ppl 40382.9 | wps 45916.4 | wpb 510.9 | bsz 1 | num_updates 14402 | best_loss 8.238
2022-03-07 02:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14402 updates
2022-03-07 02:02:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 296 @ 14402 updates, score 15.424) (writing took 2.5895186755806208 seconds)
2022-03-07 02:02:55 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 02:02:55 | INFO | train | epoch 296 | loss 0.556 | nll_loss 0.231 | ppl 1.17 | wps 24674.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14402 | lr 0.000263505 | gnorm 0.464 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46850
2022-03-07 02:02:55 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 02:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:05:01 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 15.351 | nll_loss 15.228 | ppl 38385.8 | wps 46538.5 | wpb 510.9 | bsz 1 | num_updates 14451 | best_loss 8.238
2022-03-07 02:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14451 updates
2022-03-07 02:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 297 @ 14451 updates, score 15.351) (writing took 2.4724178705364466 seconds)
2022-03-07 02:05:03 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 02:05:03 | INFO | train | epoch 297 | loss 0.555 | nll_loss 0.23 | ppl 1.17 | wps 24706.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14451 | lr 0.000263058 | gnorm 0.471 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 46979
2022-03-07 02:05:03 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 02:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:07:05 | INFO | train_inner | epoch 298:     49 / 49 loss=0.554, nll_loss=0.229, ppl=1.17, wps=24735.2, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=14500, lr=0.000262613, gnorm=0.472, loss_scale=64, train_wall=222, gb_free=8.8, wall=47100
2022-03-07 02:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:07:09 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 15.339 | nll_loss 15.217 | ppl 38078 | wps 46582.3 | wpb 510.9 | bsz 1 | num_updates 14500 | best_loss 8.238
2022-03-07 02:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14500 updates
2022-03-07 02:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 298 @ 14500 updates, score 15.339) (writing took 2.4831748846918344 seconds)
2022-03-07 02:07:12 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 02:07:12 | INFO | train | epoch 298 | loss 0.553 | nll_loss 0.228 | ppl 1.17 | wps 24756.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14500 | lr 0.000262613 | gnorm 0.47 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 47107
2022-03-07 02:07:12 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 02:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:09:18 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 15.297 | nll_loss 15.175 | ppl 36999.3 | wps 46584.1 | wpb 510.9 | bsz 1 | num_updates 14548 | best_loss 8.238
2022-03-07 02:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14548 updates
2022-03-07 02:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 299 @ 14548 updates, score 15.297) (writing took 2.5684626679867506 seconds)
2022-03-07 02:09:20 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 02:09:20 | INFO | train | epoch 299 | loss 0.551 | nll_loss 0.227 | ppl 1.17 | wps 24228.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14548 | lr 0.000262179 | gnorm 0.463 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47235
2022-03-07 02:09:20 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 02:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:11:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:11:26 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 15.372 | nll_loss 15.251 | ppl 38983 | wps 46543.7 | wpb 510.9 | bsz 1 | num_updates 14597 | best_loss 8.238
2022-03-07 02:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14597 updates
2022-03-07 02:11:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:11:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 300 @ 14597 updates, score 15.372) (writing took 2.513389181345701 seconds)
2022-03-07 02:11:29 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 02:11:29 | INFO | train | epoch 300 | loss 0.551 | nll_loss 0.226 | ppl 1.17 | wps 24722.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14597 | lr 0.000261739 | gnorm 0.464 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47364
2022-03-07 02:11:29 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 02:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:11:36 | INFO | train_inner | epoch 301:      3 / 49 loss=0.551, nll_loss=0.226, ppl=1.17, wps=23864.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.463, loss_scale=32, train_wall=225, gb_free=8.8, wall=47372
2022-03-07 02:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:35 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 15.301 | nll_loss 15.179 | ppl 37098.1 | wps 46591.5 | wpb 510.9 | bsz 1 | num_updates 14646 | best_loss 8.238
2022-03-07 02:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14646 updates
2022-03-07 02:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 301 @ 14646 updates, score 15.301) (writing took 2.4993971325457096 seconds)
2022-03-07 02:13:37 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 02:13:37 | INFO | train | epoch 301 | loss 0.55 | nll_loss 0.225 | ppl 1.17 | wps 24768.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14646 | lr 0.000261301 | gnorm 0.461 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47492
2022-03-07 02:13:37 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 02:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:15:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:15:43 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 15.345 | nll_loss 15.224 | ppl 38273.6 | wps 46605.7 | wpb 510.9 | bsz 1 | num_updates 14694 | best_loss 8.238
2022-03-07 02:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14694 updates
2022-03-07 02:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 302 @ 14694 updates, score 15.345) (writing took 2.5708154011517763 seconds)
2022-03-07 02:15:46 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 02:15:46 | INFO | train | epoch 302 | loss 0.549 | nll_loss 0.225 | ppl 1.17 | wps 24191.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14694 | lr 0.000260874 | gnorm 0.462 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47621
2022-03-07 02:15:46 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 02:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:16:01 | INFO | train_inner | epoch 303:      6 / 49 loss=0.549, nll_loss=0.225, ppl=1.17, wps=24529.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=14700, lr=0.00026082, gnorm=0.461, loss_scale=32, train_wall=225, gb_free=8.8, wall=47636
2022-03-07 02:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:52 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 15.243 | nll_loss 15.12 | ppl 35611.2 | wps 45239.9 | wpb 510.9 | bsz 1 | num_updates 14743 | best_loss 8.238
2022-03-07 02:17:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14743 updates
2022-03-07 02:17:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:17:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:17:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 303 @ 14743 updates, score 15.243) (writing took 2.4991160798817873 seconds)
2022-03-07 02:17:55 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 02:17:55 | INFO | train | epoch 303 | loss 0.548 | nll_loss 0.224 | ppl 1.17 | wps 24698.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14743 | lr 0.00026044 | gnorm 0.457 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47750
2022-03-07 02:17:55 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 02:17:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:20:00 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 15.397 | nll_loss 15.279 | ppl 39760.4 | wps 46616.7 | wpb 510.9 | bsz 1 | num_updates 14792 | best_loss 8.238
2022-03-07 02:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14792 updates
2022-03-07 02:20:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 304 @ 14792 updates, score 15.397) (writing took 2.510976556688547 seconds)
2022-03-07 02:20:03 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 02:20:03 | INFO | train | epoch 304 | loss 0.547 | nll_loss 0.223 | ppl 1.17 | wps 24734 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14792 | lr 0.000260008 | gnorm 0.458 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 47878
2022-03-07 02:20:03 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 02:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:20:23 | INFO | train_inner | epoch 305:      8 / 49 loss=0.547, nll_loss=0.223, ppl=1.17, wps=24744.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.457, loss_scale=32, train_wall=223, gb_free=8.8, wall=47898
2022-03-07 02:22:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:09 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 15.388 | nll_loss 15.268 | ppl 39452.5 | wps 46539 | wpb 510.9 | bsz 1 | num_updates 14841 | best_loss 8.238
2022-03-07 02:22:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14841 updates
2022-03-07 02:22:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 305 @ 14841 updates, score 15.388) (writing took 2.525454381480813 seconds)
2022-03-07 02:22:11 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 02:22:11 | INFO | train | epoch 305 | loss 0.546 | nll_loss 0.222 | ppl 1.17 | wps 24731.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14841 | lr 0.000259578 | gnorm 0.452 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 48007
2022-03-07 02:22:12 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 02:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:22:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:17 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 15.411 | nll_loss 15.288 | ppl 40014.1 | wps 46543 | wpb 510.9 | bsz 1 | num_updates 14889 | best_loss 8.238
2022-03-07 02:24:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14889 updates
2022-03-07 02:24:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:24:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:24:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 306 @ 14889 updates, score 15.411) (writing took 2.569780521094799 seconds)
2022-03-07 02:24:20 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 02:24:20 | INFO | train | epoch 306 | loss 0.545 | nll_loss 0.221 | ppl 1.17 | wps 24213.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14889 | lr 0.00025916 | gnorm 0.455 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48135
2022-03-07 02:24:20 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 02:24:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:24:48 | INFO | train_inner | epoch 307:     11 / 49 loss=0.545, nll_loss=0.221, ppl=1.17, wps=24529, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.453, loss_scale=32, train_wall=225, gb_free=8.8, wall=48163
2022-03-07 02:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:26 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 15.33 | nll_loss 15.21 | ppl 37896.5 | wps 46574.4 | wpb 510.9 | bsz 1 | num_updates 14938 | best_loss 8.238
2022-03-07 02:26:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14938 updates
2022-03-07 02:26:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 307 @ 14938 updates, score 15.33) (writing took 2.5158850885927677 seconds)
2022-03-07 02:26:28 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 02:26:28 | INFO | train | epoch 307 | loss 0.545 | nll_loss 0.222 | ppl 1.17 | wps 24763.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 14938 | lr 0.000258734 | gnorm 0.459 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48264
2022-03-07 02:26:28 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 02:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:28:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:28:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:28:35 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 15.317 | nll_loss 15.197 | ppl 37571.6 | wps 45626.4 | wpb 510.9 | bsz 1 | num_updates 14986 | best_loss 8.238
2022-03-07 02:28:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14986 updates
2022-03-07 02:28:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:28:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 308 @ 14986 updates, score 15.317) (writing took 2.5298986919224262 seconds)
2022-03-07 02:28:37 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 02:28:37 | INFO | train | epoch 308 | loss 0.545 | nll_loss 0.221 | ppl 1.17 | wps 24187.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 14986 | lr 0.000258319 | gnorm 0.462 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48392
2022-03-07 02:28:37 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 02:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:29:12 | INFO | train_inner | epoch 309:     14 / 49 loss=0.545, nll_loss=0.221, ppl=1.17, wps=24516.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.458, loss_scale=32, train_wall=225, gb_free=8.8, wall=48427
2022-03-07 02:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:30:43 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 15.375 | nll_loss 15.254 | ppl 39083.1 | wps 46075.1 | wpb 510.9 | bsz 1 | num_updates 15035 | best_loss 8.238
2022-03-07 02:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15035 updates
2022-03-07 02:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 309 @ 15035 updates, score 15.375) (writing took 2.4986128117889166 seconds)
2022-03-07 02:30:46 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 02:30:46 | INFO | train | epoch 309 | loss 0.543 | nll_loss 0.22 | ppl 1.16 | wps 24710.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15035 | lr 0.000257898 | gnorm 0.456 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48521
2022-03-07 02:30:46 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 02:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:32:52 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 15.345 | nll_loss 15.224 | ppl 38280.4 | wps 46205.5 | wpb 510.9 | bsz 1 | num_updates 15084 | best_loss 8.238
2022-03-07 02:32:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15084 updates
2022-03-07 02:32:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:32:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:32:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 310 @ 15084 updates, score 15.345) (writing took 2.5141266118735075 seconds)
2022-03-07 02:32:54 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 02:32:54 | INFO | train | epoch 310 | loss 0.542 | nll_loss 0.219 | ppl 1.16 | wps 24685.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15084 | lr 0.000257479 | gnorm 0.448 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 48650
2022-03-07 02:32:54 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 02:32:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:33:34 | INFO | train_inner | epoch 311:     16 / 49 loss=0.543, nll_loss=0.219, ppl=1.16, wps=24743.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.453, loss_scale=32, train_wall=223, gb_free=8.8, wall=48689
2022-03-07 02:34:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:35:00 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 15.345 | nll_loss 15.226 | ppl 38322 | wps 46475.4 | wpb 510.9 | bsz 1 | num_updates 15133 | best_loss 8.238
2022-03-07 02:35:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15133 updates
2022-03-07 02:35:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 311 @ 15133 updates, score 15.345) (writing took 2.5353733245283365 seconds)
2022-03-07 02:35:03 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 02:35:03 | INFO | train | epoch 311 | loss 0.541 | nll_loss 0.218 | ppl 1.16 | wps 24761.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15133 | lr 0.000257062 | gnorm 0.449 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 48778
2022-03-07 02:35:03 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 02:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:35:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:37:09 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 15.368 | nll_loss 15.248 | ppl 38915.2 | wps 45943.9 | wpb 510.9 | bsz 1 | num_updates 15181 | best_loss 8.238
2022-03-07 02:37:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15181 updates
2022-03-07 02:37:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:37:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:37:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 312 @ 15181 updates, score 15.368) (writing took 2.5092919319868088 seconds)
2022-03-07 02:37:11 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 02:37:11 | INFO | train | epoch 312 | loss 0.54 | nll_loss 0.217 | ppl 1.16 | wps 24212.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15181 | lr 0.000256655 | gnorm 0.445 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 48906
2022-03-07 02:37:11 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 02:37:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:37:59 | INFO | train_inner | epoch 313:     19 / 49 loss=0.54, nll_loss=0.217, ppl=1.16, wps=24523.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.447, loss_scale=32, train_wall=225, gb_free=8.8, wall=48954
2022-03-07 02:39:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:39:17 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 15.423 | nll_loss 15.304 | ppl 40444.5 | wps 46543.3 | wpb 510.9 | bsz 1 | num_updates 15230 | best_loss 8.238
2022-03-07 02:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15230 updates
2022-03-07 02:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 313 @ 15230 updates, score 15.423) (writing took 2.5757878199219704 seconds)
2022-03-07 02:39:20 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 02:39:20 | INFO | train | epoch 313 | loss 0.54 | nll_loss 0.217 | ppl 1.16 | wps 24716.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15230 | lr 0.000256242 | gnorm 0.452 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 49035
2022-03-07 02:39:20 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 02:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:41:29 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 15.384 | nll_loss 15.265 | ppl 39375.9 | wps 38951.3 | wpb 510.9 | bsz 1 | num_updates 15279 | best_loss 8.238
2022-03-07 02:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15279 updates
2022-03-07 02:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 314 @ 15279 updates, score 15.384) (writing took 2.581168055534363 seconds)
2022-03-07 02:41:32 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 02:41:32 | INFO | train | epoch 314 | loss 0.538 | nll_loss 0.215 | ppl 1.16 | wps 24092.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15279 | lr 0.000255831 | gnorm 0.448 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 49167
2022-03-07 02:41:32 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 02:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:42:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:42:28 | INFO | train_inner | epoch 315:     22 / 49 loss=0.539, nll_loss=0.216, ppl=1.16, wps=24141.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.45, loss_scale=32, train_wall=229, gb_free=8.8, wall=49223
2022-03-07 02:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:43:38 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 15.349 | nll_loss 15.231 | ppl 38454.7 | wps 47181.8 | wpb 510.9 | bsz 1 | num_updates 15327 | best_loss 8.238
2022-03-07 02:43:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15327 updates
2022-03-07 02:43:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:43:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 315 @ 15327 updates, score 15.349) (writing took 2.4461743533611298 seconds)
2022-03-07 02:43:40 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 02:43:40 | INFO | train | epoch 315 | loss 0.539 | nll_loss 0.216 | ppl 1.16 | wps 24207.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15327 | lr 0.00025543 | gnorm 0.451 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 49296
2022-03-07 02:43:40 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 02:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:45:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:45:48 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 15.291 | nll_loss 15.171 | ppl 36889.7 | wps 46736.3 | wpb 510.9 | bsz 1 | num_updates 15376 | best_loss 8.238
2022-03-07 02:45:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15376 updates
2022-03-07 02:45:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:45:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 316 @ 15376 updates, score 15.291) (writing took 2.469384850934148 seconds)
2022-03-07 02:45:51 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 02:45:51 | INFO | train | epoch 316 | loss 0.537 | nll_loss 0.214 | ppl 1.16 | wps 24403.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15376 | lr 0.000255022 | gnorm 0.442 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49426
2022-03-07 02:45:51 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 02:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:46:50 | INFO | train_inner | epoch 317:     24 / 49 loss=0.537, nll_loss=0.214, ppl=1.16, wps=24705.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.445, loss_scale=32, train_wall=224, gb_free=8.8, wall=49485
2022-03-07 02:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:47:58 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 15.379 | nll_loss 15.26 | ppl 39248.3 | wps 39252.2 | wpb 510.9 | bsz 1 | num_updates 15425 | best_loss 8.238
2022-03-07 02:47:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15425 updates
2022-03-07 02:47:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:48:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:48:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 317 @ 15425 updates, score 15.379) (writing took 2.493553753942251 seconds)
2022-03-07 02:48:01 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 02:48:01 | INFO | train | epoch 317 | loss 0.537 | nll_loss 0.214 | ppl 1.16 | wps 24410.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15425 | lr 0.000254617 | gnorm 0.447 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 49556
2022-03-07 02:48:01 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 02:48:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:50:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:50:06 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 15.29 | nll_loss 15.169 | ppl 36842.2 | wps 47151.6 | wpb 510.9 | bsz 1 | num_updates 15474 | best_loss 8.238
2022-03-07 02:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15474 updates
2022-03-07 02:50:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:50:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:50:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 318 @ 15474 updates, score 15.29) (writing took 2.479590157046914 seconds)
2022-03-07 02:50:08 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 02:50:08 | INFO | train | epoch 318 | loss 0.535 | nll_loss 0.212 | ppl 1.16 | wps 24904.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15474 | lr 0.000254214 | gnorm 0.443 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 49684
2022-03-07 02:50:08 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 02:50:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:51:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:51:18 | INFO | train_inner | epoch 319:     27 / 49 loss=0.535, nll_loss=0.213, ppl=1.16, wps=24233.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.445, loss_scale=32, train_wall=228, gb_free=8.8, wall=49753
2022-03-07 02:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:52:16 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 15.314 | nll_loss 15.194 | ppl 37484.1 | wps 46995 | wpb 510.9 | bsz 1 | num_updates 15522 | best_loss 8.238
2022-03-07 02:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15522 updates
2022-03-07 02:52:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:52:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 319 @ 15522 updates, score 15.314) (writing took 2.497311882674694 seconds)
2022-03-07 02:52:18 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 02:52:18 | INFO | train | epoch 319 | loss 0.535 | nll_loss 0.212 | ppl 1.16 | wps 23948.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 15522 | lr 0.00025382 | gnorm 0.45 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49814
2022-03-07 02:52:18 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 02:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:54:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:54:26 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 15.255 | nll_loss 15.137 | ppl 36037.4 | wps 46936.1 | wpb 510.9 | bsz 1 | num_updates 15571 | best_loss 8.238
2022-03-07 02:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15571 updates
2022-03-07 02:54:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 320 @ 15571 updates, score 15.255) (writing took 2.4702678211033344 seconds)
2022-03-07 02:54:29 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 02:54:29 | INFO | train | epoch 320 | loss 0.534 | nll_loss 0.211 | ppl 1.16 | wps 24394.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15571 | lr 0.000253421 | gnorm 0.44 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 49944
2022-03-07 02:54:29 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 02:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:55:41 | INFO | train_inner | epoch 321:     29 / 49 loss=0.534, nll_loss=0.211, ppl=1.16, wps=24697.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.445, loss_scale=32, train_wall=224, gb_free=8.8, wall=50016
2022-03-07 02:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:56:34 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 15.294 | nll_loss 15.175 | ppl 36998.6 | wps 46733.4 | wpb 510.9 | bsz 1 | num_updates 15620 | best_loss 8.238
2022-03-07 02:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15620 updates
2022-03-07 02:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:56:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 321 @ 15620 updates, score 15.294) (writing took 2.4767704010009766 seconds)
2022-03-07 02:56:36 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 02:56:36 | INFO | train | epoch 321 | loss 0.532 | nll_loss 0.21 | ppl 1.16 | wps 24934.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15620 | lr 0.000253023 | gnorm 0.44 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 50071
2022-03-07 02:56:36 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 02:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:58:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:58:44 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 15.369 | nll_loss 15.251 | ppl 38984.4 | wps 47484.5 | wpb 510.9 | bsz 1 | num_updates 15669 | best_loss 8.238
2022-03-07 02:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15669 updates
2022-03-07 02:58:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:58:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 02:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 322 @ 15669 updates, score 15.369) (writing took 2.509654924273491 seconds)
2022-03-07 02:58:46 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 02:58:46 | INFO | train | epoch 322 | loss 0.532 | nll_loss 0.21 | ppl 1.16 | wps 24437.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15669 | lr 0.000252627 | gnorm 0.442 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 50201
2022-03-07 02:58:46 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 02:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:00:03 | INFO | train_inner | epoch 323:     31 / 49 loss=0.531, nll_loss=0.209, ppl=1.16, wps=24708.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.438, loss_scale=64, train_wall=224, gb_free=8.8, wall=50278
2022-03-07 03:00:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:54 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 15.28 | nll_loss 15.16 | ppl 36623.8 | wps 46570.2 | wpb 510.9 | bsz 1 | num_updates 15718 | best_loss 8.238
2022-03-07 03:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15718 updates
2022-03-07 03:00:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 323 @ 15718 updates, score 15.28) (writing took 2.46777430921793 seconds)
2022-03-07 03:00:56 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 03:00:56 | INFO | train | epoch 323 | loss 0.531 | nll_loss 0.209 | ppl 1.16 | wps 24451.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15718 | lr 0.000252233 | gnorm 0.437 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 50331
2022-03-07 03:00:56 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 03:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 03:02:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:03:01 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 15.305 | nll_loss 15.187 | ppl 37313 | wps 47021.6 | wpb 510.9 | bsz 1 | num_updates 15765 | best_loss 8.238
2022-03-07 03:03:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15765 updates
2022-03-07 03:03:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:03:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:03:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 324 @ 15765 updates, score 15.305) (writing took 2.5806079246103764 seconds)
2022-03-07 03:03:04 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 03:03:04 | INFO | train | epoch 324 | loss 0.53 | nll_loss 0.208 | ppl 1.16 | wps 23893.7 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 15765 | lr 0.000251856 | gnorm 0.44 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 50459
2022-03-07 03:03:04 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 03:03:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:04:33 | INFO | train_inner | epoch 325:     35 / 49 loss=0.531, nll_loss=0.209, ppl=1.16, wps=24042.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.439, loss_scale=32, train_wall=231, gb_free=8.8, wall=50548
2022-03-07 03:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:11 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 15.208 | nll_loss 15.09 | ppl 34876.9 | wps 47432.9 | wpb 510.9 | bsz 1 | num_updates 15814 | best_loss 8.238
2022-03-07 03:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15814 updates
2022-03-07 03:05:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:05:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 325 @ 15814 updates, score 15.208) (writing took 2.4663728550076485 seconds)
2022-03-07 03:05:13 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 03:05:13 | INFO | train | epoch 325 | loss 0.53 | nll_loss 0.209 | ppl 1.16 | wps 24478.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15814 | lr 0.000251466 | gnorm 0.438 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 50589
2022-03-07 03:05:13 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 03:05:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:07:21 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 15.276 | nll_loss 15.157 | ppl 36539.7 | wps 47147.6 | wpb 510.9 | bsz 1 | num_updates 15863 | best_loss 8.238
2022-03-07 03:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15863 updates
2022-03-07 03:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 326 @ 15863 updates, score 15.276) (writing took 2.475817061960697 seconds)
2022-03-07 03:07:23 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 03:07:23 | INFO | train | epoch 326 | loss 0.529 | nll_loss 0.207 | ppl 1.15 | wps 24448.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15863 | lr 0.000251077 | gnorm 0.437 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 50719
2022-03-07 03:07:23 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 03:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:08:55 | INFO | train_inner | epoch 327:     37 / 49 loss=0.529, nll_loss=0.207, ppl=1.15, wps=24717, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.434, loss_scale=64, train_wall=224, gb_free=8.8, wall=50810
2022-03-07 03:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:09:29 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 15.323 | nll_loss 15.204 | ppl 37732.7 | wps 47515.4 | wpb 510.9 | bsz 1 | num_updates 15912 | best_loss 8.238
2022-03-07 03:09:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15912 updates
2022-03-07 03:09:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 327 @ 15912 updates, score 15.323) (writing took 2.8042749240994453 seconds)
2022-03-07 03:09:31 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 03:09:31 | INFO | train | epoch 327 | loss 0.528 | nll_loss 0.206 | ppl 1.15 | wps 24860 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15912 | lr 0.00025069 | gnorm 0.429 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 50846
2022-03-07 03:09:31 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 03:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:11:39 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 15.218 | nll_loss 15.101 | ppl 35138.1 | wps 46853.9 | wpb 510.9 | bsz 1 | num_updates 15961 | best_loss 8.238
2022-03-07 03:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15961 updates
2022-03-07 03:11:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:11:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 328 @ 15961 updates, score 15.218) (writing took 2.4581795632839203 seconds)
2022-03-07 03:11:41 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 03:11:41 | INFO | train | epoch 328 | loss 0.527 | nll_loss 0.206 | ppl 1.15 | wps 24454.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 15961 | lr 0.000250305 | gnorm 0.432 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 50976
2022-03-07 03:11:41 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 03:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:12:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:13:23 | INFO | train_inner | epoch 329:     40 / 49 loss=0.527, nll_loss=0.206, ppl=1.15, wps=24236.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.434, loss_scale=32, train_wall=228, gb_free=8.8, wall=51078
2022-03-07 03:13:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:13:49 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 15.304 | nll_loss 15.187 | ppl 37294.6 | wps 47033.8 | wpb 510.9 | bsz 1 | num_updates 16009 | best_loss 8.238
2022-03-07 03:13:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16009 updates
2022-03-07 03:13:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:13:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:13:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 329 @ 16009 updates, score 15.304) (writing took 2.485404781997204 seconds)
2022-03-07 03:13:51 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 03:13:51 | INFO | train | epoch 329 | loss 0.526 | nll_loss 0.205 | ppl 1.15 | wps 23955.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16009 | lr 0.00024993 | gnorm 0.437 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 51106
2022-03-07 03:13:51 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 03:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:15:58 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 15.325 | nll_loss 15.207 | ppl 37825 | wps 38757.2 | wpb 510.9 | bsz 1 | num_updates 16058 | best_loss 8.238
2022-03-07 03:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16058 updates
2022-03-07 03:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:16:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 330 @ 16058 updates, score 15.325) (writing took 2.669499794021249 seconds)
2022-03-07 03:16:01 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 03:16:01 | INFO | train | epoch 330 | loss 0.525 | nll_loss 0.204 | ppl 1.15 | wps 24508.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16058 | lr 0.000249548 | gnorm 0.436 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 51236
2022-03-07 03:16:01 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 03:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:17:46 | INFO | train_inner | epoch 331:     42 / 49 loss=0.526, nll_loss=0.205, ppl=1.15, wps=24666.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.436, loss_scale=64, train_wall=223, gb_free=8.8, wall=51341
2022-03-07 03:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:18:07 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 15.336 | nll_loss 15.218 | ppl 38103.7 | wps 46958.9 | wpb 510.9 | bsz 1 | num_updates 16107 | best_loss 8.238
2022-03-07 03:18:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16107 updates
2022-03-07 03:18:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:18:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:18:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 331 @ 16107 updates, score 15.336) (writing took 2.4691735859960318 seconds)
2022-03-07 03:18:09 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 03:18:09 | INFO | train | epoch 331 | loss 0.525 | nll_loss 0.204 | ppl 1.15 | wps 24745.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16107 | lr 0.000249168 | gnorm 0.435 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 51364
2022-03-07 03:18:09 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 03:18:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:20:17 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 15.361 | nll_loss 15.244 | ppl 38795.4 | wps 47454.4 | wpb 510.9 | bsz 1 | num_updates 16155 | best_loss 8.238
2022-03-07 03:20:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16155 updates
2022-03-07 03:20:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:20:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 332 @ 16155 updates, score 15.361) (writing took 2.5497916396707296 seconds)
2022-03-07 03:20:20 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 03:20:20 | INFO | train | epoch 332 | loss 0.523 | nll_loss 0.202 | ppl 1.15 | wps 23890.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16155 | lr 0.000248798 | gnorm 0.43 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 51495
2022-03-07 03:20:20 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 03:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:22:13 | INFO | train_inner | epoch 333:     45 / 49 loss=0.524, nll_loss=0.203, ppl=1.15, wps=24326.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.431, loss_scale=32, train_wall=228, gb_free=8.8, wall=51608
2022-03-07 03:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:22:27 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 15.284 | nll_loss 15.166 | ppl 36767.8 | wps 44025.1 | wpb 510.9 | bsz 1 | num_updates 16204 | best_loss 8.238
2022-03-07 03:22:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16204 updates
2022-03-07 03:22:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:22:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 333 @ 16204 updates, score 15.284) (writing took 2.4485762529075146 seconds)
2022-03-07 03:22:30 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 03:22:30 | INFO | train | epoch 333 | loss 0.524 | nll_loss 0.204 | ppl 1.15 | wps 24385.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16204 | lr 0.000248421 | gnorm 0.432 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 51625
2022-03-07 03:22:30 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 03:22:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:24:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:24:35 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 15.32 | nll_loss 15.203 | ppl 37726.9 | wps 47278.7 | wpb 510.9 | bsz 1 | num_updates 16253 | best_loss 8.238
2022-03-07 03:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16253 updates
2022-03-07 03:24:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:24:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:24:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 334 @ 16253 updates, score 15.32) (writing took 2.4909301698207855 seconds)
2022-03-07 03:24:37 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 03:24:37 | INFO | train | epoch 334 | loss 0.522 | nll_loss 0.202 | ppl 1.15 | wps 24944.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16253 | lr 0.000248047 | gnorm 0.431 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 51752
2022-03-07 03:24:37 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 03:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:26:36 | INFO | train_inner | epoch 335:     47 / 49 loss=0.523, nll_loss=0.202, ppl=1.15, wps=24608.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.431, loss_scale=64, train_wall=225, gb_free=8.8, wall=51871
2022-03-07 03:26:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:26:45 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 15.356 | nll_loss 15.24 | ppl 38705.4 | wps 47108.6 | wpb 510.9 | bsz 1 | num_updates 16301 | best_loss 8.238
2022-03-07 03:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16301 updates
2022-03-07 03:26:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:26:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:26:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 335 @ 16301 updates, score 15.356) (writing took 2.539564622566104 seconds)
2022-03-07 03:26:47 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 03:26:47 | INFO | train | epoch 335 | loss 0.523 | nll_loss 0.202 | ppl 1.15 | wps 23962.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16301 | lr 0.000247681 | gnorm 0.43 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 51882
2022-03-07 03:26:47 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 03:26:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:28:55 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 15.345 | nll_loss 15.229 | ppl 38392.5 | wps 47021.7 | wpb 510.9 | bsz 1 | num_updates 16350 | best_loss 8.238
2022-03-07 03:28:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16350 updates
2022-03-07 03:28:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:28:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:28:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 336 @ 16350 updates, score 15.345) (writing took 2.54419719055295 seconds)
2022-03-07 03:28:57 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 03:28:57 | INFO | train | epoch 336 | loss 0.521 | nll_loss 0.201 | ppl 1.15 | wps 24440.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16350 | lr 0.00024731 | gnorm 0.422 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 52012
2022-03-07 03:28:57 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 03:28:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:31:02 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 15.411 | nll_loss 15.297 | ppl 40251.4 | wps 47111 | wpb 510.9 | bsz 1 | num_updates 16399 | best_loss 8.238
2022-03-07 03:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16399 updates
2022-03-07 03:31:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 337 @ 16399 updates, score 15.411) (writing took 2.5405276343226433 seconds)
2022-03-07 03:31:05 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 03:31:05 | INFO | train | epoch 337 | loss 0.521 | nll_loss 0.201 | ppl 1.15 | wps 24898.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16399 | lr 0.00024694 | gnorm 0.43 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 52140
2022-03-07 03:31:05 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 03:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:31:07 | INFO | train_inner | epoch 338:      1 / 49 loss=0.521, nll_loss=0.201, ppl=1.15, wps=23801.5, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=16400, lr=0.000246932, gnorm=0.428, loss_scale=32, train_wall=225, gb_free=8.8, wall=52143
2022-03-07 03:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:33:12 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 15.349 | nll_loss 15.232 | ppl 38485.3 | wps 47145.9 | wpb 510.9 | bsz 1 | num_updates 16448 | best_loss 8.238
2022-03-07 03:33:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16448 updates
2022-03-07 03:33:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:33:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 338 @ 16448 updates, score 15.349) (writing took 2.4381285570561886 seconds)
2022-03-07 03:33:15 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 03:33:15 | INFO | train | epoch 338 | loss 0.52 | nll_loss 0.2 | ppl 1.15 | wps 24485.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16448 | lr 0.000246572 | gnorm 0.422 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 52270
2022-03-07 03:33:15 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 03:33:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:35:22 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 15.319 | nll_loss 15.204 | ppl 37755 | wps 47251.6 | wpb 510.9 | bsz 1 | num_updates 16497 | best_loss 8.238
2022-03-07 03:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16497 updates
2022-03-07 03:35:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 339 @ 16497 updates, score 15.319) (writing took 2.52716301754117 seconds)
2022-03-07 03:35:25 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 03:35:25 | INFO | train | epoch 339 | loss 0.519 | nll_loss 0.199 | ppl 1.15 | wps 24436.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16497 | lr 0.000246205 | gnorm 0.425 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 52400
2022-03-07 03:35:25 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 03:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:35:32 | INFO | train_inner | epoch 340:      3 / 49 loss=0.519, nll_loss=0.199, ppl=1.15, wps=24496.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.423, loss_scale=64, train_wall=226, gb_free=8.8, wall=52407
2022-03-07 03:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:37:30 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 15.295 | nll_loss 15.178 | ppl 37072.9 | wps 47040.9 | wpb 510.9 | bsz 1 | num_updates 16546 | best_loss 8.238
2022-03-07 03:37:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16546 updates
2022-03-07 03:37:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:37:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:37:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 340 @ 16546 updates, score 15.295) (writing took 2.476145789027214 seconds)
2022-03-07 03:37:32 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 03:37:32 | INFO | train | epoch 340 | loss 0.519 | nll_loss 0.199 | ppl 1.15 | wps 24927 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16546 | lr 0.000245841 | gnorm 0.424 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 52527
2022-03-07 03:37:32 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 03:37:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 03:38:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:39:40 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 15.25 | nll_loss 15.133 | ppl 35942.4 | wps 47427 | wpb 510.9 | bsz 1 | num_updates 16593 | best_loss 8.238
2022-03-07 03:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16593 updates
2022-03-07 03:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 341 @ 16593 updates, score 15.25) (writing took 2.4835940580815077 seconds)
2022-03-07 03:39:42 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 03:39:42 | INFO | train | epoch 341 | loss 0.518 | nll_loss 0.198 | ppl 1.15 | wps 23412 | ups 0.36 | wpb 64829.4 | bsz 126.6 | num_updates 16593 | lr 0.000245492 | gnorm 0.424 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 52658
2022-03-07 03:39:42 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 03:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:40:00 | INFO | train_inner | epoch 342:      7 / 49 loss=0.518, nll_loss=0.198, ppl=1.15, wps=24248.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.424, loss_scale=32, train_wall=229, gb_free=8.8, wall=52675
2022-03-07 03:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:41:50 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 15.279 | nll_loss 15.165 | ppl 36729.1 | wps 46932.6 | wpb 510.9 | bsz 1 | num_updates 16642 | best_loss 8.238
2022-03-07 03:41:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16642 updates
2022-03-07 03:41:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:41:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:41:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 342 @ 16642 updates, score 15.279) (writing took 2.5215018671005964 seconds)
2022-03-07 03:41:53 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 03:41:53 | INFO | train | epoch 342 | loss 0.518 | nll_loss 0.198 | ppl 1.15 | wps 24386.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16642 | lr 0.00024513 | gnorm 0.423 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 52788
2022-03-07 03:41:53 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 03:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:58 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 15.355 | nll_loss 15.241 | ppl 38724.4 | wps 47072.2 | wpb 510.9 | bsz 1 | num_updates 16691 | best_loss 8.238
2022-03-07 03:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16691 updates
2022-03-07 03:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:44:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:44:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 343 @ 16691 updates, score 15.355) (writing took 2.499985186383128 seconds)
2022-03-07 03:44:00 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 03:44:00 | INFO | train | epoch 343 | loss 0.517 | nll_loss 0.197 | ppl 1.15 | wps 24903.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16691 | lr 0.00024477 | gnorm 0.427 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 52915
2022-03-07 03:44:00 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 03:44:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:44:25 | INFO | train_inner | epoch 344:      9 / 49 loss=0.517, nll_loss=0.197, ppl=1.15, wps=24446.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.424, loss_scale=64, train_wall=227, gb_free=8.8, wall=52940
2022-03-07 03:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:46:08 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 15.298 | nll_loss 15.182 | ppl 37182.3 | wps 47053.3 | wpb 510.9 | bsz 1 | num_updates 16739 | best_loss 8.238
2022-03-07 03:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16739 updates
2022-03-07 03:46:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:46:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 344 @ 16739 updates, score 15.298) (writing took 2.5449001602828503 seconds)
2022-03-07 03:46:11 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 03:46:11 | INFO | train | epoch 344 | loss 0.515 | nll_loss 0.195 | ppl 1.14 | wps 23883.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16739 | lr 0.000244419 | gnorm 0.415 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 53046
2022-03-07 03:46:11 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 03:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:18 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 15.353 | nll_loss 15.237 | ppl 38616.5 | wps 47340.9 | wpb 510.9 | bsz 1 | num_updates 16788 | best_loss 8.238
2022-03-07 03:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16788 updates
2022-03-07 03:48:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 345 @ 16788 updates, score 15.353) (writing took 2.4614772461354733 seconds)
2022-03-07 03:48:21 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 03:48:21 | INFO | train | epoch 345 | loss 0.515 | nll_loss 0.196 | ppl 1.15 | wps 24433.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16788 | lr 0.000244062 | gnorm 0.419 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 53176
2022-03-07 03:48:21 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 03:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:48:51 | INFO | train_inner | epoch 346:     12 / 49 loss=0.515, nll_loss=0.195, ppl=1.14, wps=24432.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.419, loss_scale=32, train_wall=227, gb_free=8.8, wall=53206
2022-03-07 03:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:50:27 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 15.394 | nll_loss 15.279 | ppl 39755.8 | wps 40194.7 | wpb 510.9 | bsz 1 | num_updates 16837 | best_loss 8.238
2022-03-07 03:50:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16837 updates
2022-03-07 03:50:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:50:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 346 @ 16837 updates, score 15.394) (writing took 2.5863118208944798 seconds)
2022-03-07 03:50:30 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 03:50:30 | INFO | train | epoch 346 | loss 0.515 | nll_loss 0.195 | ppl 1.15 | wps 24631.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16837 | lr 0.000243707 | gnorm 0.424 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 53305
2022-03-07 03:50:30 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 03:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:37 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 15.309 | nll_loss 15.194 | ppl 37478.5 | wps 46739.3 | wpb 510.9 | bsz 1 | num_updates 16886 | best_loss 8.238
2022-03-07 03:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16886 updates
2022-03-07 03:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:52:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 347 @ 16886 updates, score 15.309) (writing took 2.4424875397235155 seconds)
2022-03-07 03:52:40 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 03:52:40 | INFO | train | epoch 347 | loss 0.514 | nll_loss 0.194 | ppl 1.14 | wps 24473 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16886 | lr 0.000243353 | gnorm 0.415 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 53435
2022-03-07 03:52:40 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 03:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:53:15 | INFO | train_inner | epoch 348:     14 / 49 loss=0.514, nll_loss=0.194, ppl=1.14, wps=24586.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.416, loss_scale=64, train_wall=224, gb_free=8.8, wall=53470
2022-03-07 03:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:54:48 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 15.256 | nll_loss 15.139 | ppl 36089.1 | wps 46626.5 | wpb 510.9 | bsz 1 | num_updates 16935 | best_loss 8.238
2022-03-07 03:54:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16935 updates
2022-03-07 03:54:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:54:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 348 @ 16935 updates, score 15.256) (writing took 2.4621281567960978 seconds)
2022-03-07 03:54:50 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 03:54:50 | INFO | train | epoch 348 | loss 0.513 | nll_loss 0.193 | ppl 1.14 | wps 24323.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 16935 | lr 0.000243001 | gnorm 0.412 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 53565
2022-03-07 03:54:50 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 03:54:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:55:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 03:56:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:56:58 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 15.225 | nll_loss 15.109 | ppl 35342 | wps 38622.4 | wpb 510.9 | bsz 1 | num_updates 16983 | best_loss 8.238
2022-03-07 03:56:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16983 updates
2022-03-07 03:56:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:57:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:57:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 349 @ 16983 updates, score 15.225) (writing took 2.5977189484983683 seconds)
2022-03-07 03:57:00 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 03:57:00 | INFO | train | epoch 349 | loss 0.512 | nll_loss 0.193 | ppl 1.14 | wps 23916.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 16983 | lr 0.000242657 | gnorm 0.416 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 53696
2022-03-07 03:57:00 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 03:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:57:44 | INFO | train_inner | epoch 350:     17 / 49 loss=0.512, nll_loss=0.193, ppl=1.14, wps=24115.5, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.416, loss_scale=64, train_wall=229, gb_free=8.8, wall=53739
2022-03-07 03:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:59:07 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 15.262 | nll_loss 15.147 | ppl 36275.2 | wps 46834 | wpb 510.9 | bsz 1 | num_updates 17032 | best_loss 8.238
2022-03-07 03:59:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17032 updates
2022-03-07 03:59:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:59:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 03:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 350 @ 17032 updates, score 15.262) (writing took 2.417470410466194 seconds)
2022-03-07 03:59:09 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 03:59:09 | INFO | train | epoch 350 | loss 0.513 | nll_loss 0.194 | ppl 1.14 | wps 24704.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17032 | lr 0.000242308 | gnorm 0.419 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 53824
2022-03-07 03:59:09 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 03:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:01:17 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 15.286 | nll_loss 15.171 | ppl 36897.6 | wps 47089.6 | wpb 510.9 | bsz 1 | num_updates 17081 | best_loss 8.238
2022-03-07 04:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17081 updates
2022-03-07 04:01:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:01:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 351 @ 17081 updates, score 15.286) (writing took 2.465075731277466 seconds)
2022-03-07 04:01:19 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 04:01:20 | INFO | train | epoch 351 | loss 0.511 | nll_loss 0.192 | ppl 1.14 | wps 24357.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17081 | lr 0.00024196 | gnorm 0.411 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 53955
2022-03-07 04:01:20 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 04:01:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:02:09 | INFO | train_inner | epoch 352:     20 / 49 loss=0.511, nll_loss=0.192, ppl=1.14, wps=24401.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.414, loss_scale=64, train_wall=227, gb_free=8.8, wall=54005
2022-03-07 04:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:03:28 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 15.262 | nll_loss 15.147 | ppl 36281 | wps 38536.8 | wpb 510.9 | bsz 1 | num_updates 17129 | best_loss 8.238
2022-03-07 04:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17129 updates
2022-03-07 04:03:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:03:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 352 @ 17129 updates, score 15.262) (writing took 2.5921849962323904 seconds)
2022-03-07 04:03:30 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 04:03:30 | INFO | train | epoch 352 | loss 0.511 | nll_loss 0.192 | ppl 1.14 | wps 23815.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17129 | lr 0.000241621 | gnorm 0.413 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 54085
2022-03-07 04:03:30 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 04:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:05:36 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 15.204 | nll_loss 15.089 | ppl 34850.4 | wps 46207.9 | wpb 510.9 | bsz 1 | num_updates 17178 | best_loss 8.238
2022-03-07 04:05:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17178 updates
2022-03-07 04:05:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:05:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:05:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 353 @ 17178 updates, score 15.204) (writing took 2.4677040595561266 seconds)
2022-03-07 04:05:38 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 04:05:38 | INFO | train | epoch 353 | loss 0.511 | nll_loss 0.192 | ppl 1.14 | wps 24806.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17178 | lr 0.000241276 | gnorm 0.416 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 54213
2022-03-07 04:05:38 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 04:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:06:35 | INFO | train_inner | epoch 354:     22 / 49 loss=0.511, nll_loss=0.192, ppl=1.14, wps=24453, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.416, loss_scale=64, train_wall=225, gb_free=8.8, wall=54270
2022-03-07 04:07:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:07:46 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 15.221 | nll_loss 15.105 | ppl 35230.6 | wps 46950.1 | wpb 510.9 | bsz 1 | num_updates 17226 | best_loss 8.238
2022-03-07 04:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17226 updates
2022-03-07 04:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 354 @ 17226 updates, score 15.221) (writing took 2.465143973007798 seconds)
2022-03-07 04:07:49 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 04:07:49 | INFO | train | epoch 354 | loss 0.509 | nll_loss 0.191 | ppl 1.14 | wps 23882.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17226 | lr 0.000240939 | gnorm 0.415 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 54344
2022-03-07 04:07:49 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 04:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:09:57 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 15.329 | nll_loss 15.214 | ppl 38002.2 | wps 46094.6 | wpb 510.9 | bsz 1 | num_updates 17275 | best_loss 8.238
2022-03-07 04:09:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17275 updates
2022-03-07 04:09:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:09:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:09:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 355 @ 17275 updates, score 15.329) (writing took 2.4506488144397736 seconds)
2022-03-07 04:09:59 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 04:09:59 | INFO | train | epoch 355 | loss 0.509 | nll_loss 0.19 | ppl 1.14 | wps 24383.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17275 | lr 0.000240597 | gnorm 0.411 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 54474
2022-03-07 04:09:59 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 04:09:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:11:01 | INFO | train_inner | epoch 356:     25 / 49 loss=0.508, nll_loss=0.19, ppl=1.14, wps=24353.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.412, loss_scale=64, train_wall=227, gb_free=8.8, wall=54536
2022-03-07 04:11:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:11:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:12:04 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 15.259 | nll_loss 15.143 | ppl 36193.7 | wps 46978.2 | wpb 510.9 | bsz 1 | num_updates 17323 | best_loss 8.238
2022-03-07 04:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17323 updates
2022-03-07 04:12:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:12:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:12:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 356 @ 17323 updates, score 15.259) (writing took 2.498935617506504 seconds)
2022-03-07 04:12:07 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 04:12:07 | INFO | train | epoch 356 | loss 0.508 | nll_loss 0.189 | ppl 1.14 | wps 24381.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17323 | lr 0.000240264 | gnorm 0.416 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 54602
2022-03-07 04:12:07 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 04:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:14:14 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 15.323 | nll_loss 15.209 | ppl 37874.2 | wps 47378.9 | wpb 510.9 | bsz 1 | num_updates 17372 | best_loss 8.238
2022-03-07 04:14:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17372 updates
2022-03-07 04:14:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:14:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:14:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 357 @ 17372 updates, score 15.323) (writing took 2.426878122612834 seconds)
2022-03-07 04:14:17 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 04:14:17 | INFO | train | epoch 357 | loss 0.507 | nll_loss 0.189 | ppl 1.14 | wps 24394.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17372 | lr 0.000239925 | gnorm 0.412 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54732
2022-03-07 04:14:17 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 04:14:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:15:27 | INFO | train_inner | epoch 358:     28 / 49 loss=0.507, nll_loss=0.189, ppl=1.14, wps=24418.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.414, loss_scale=32, train_wall=227, gb_free=8.8, wall=54802
2022-03-07 04:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:16:25 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 15.208 | nll_loss 15.093 | ppl 34954.4 | wps 46937.9 | wpb 510.9 | bsz 1 | num_updates 17421 | best_loss 8.238
2022-03-07 04:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17421 updates
2022-03-07 04:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 358 @ 17421 updates, score 15.208) (writing took 2.448511453345418 seconds)
2022-03-07 04:16:27 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 04:16:27 | INFO | train | epoch 358 | loss 0.506 | nll_loss 0.188 | ppl 1.14 | wps 24341 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17421 | lr 0.000239587 | gnorm 0.413 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 54863
2022-03-07 04:16:27 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 04:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:18:33 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 15.198 | nll_loss 15.081 | ppl 34658.9 | wps 46519.1 | wpb 510.9 | bsz 1 | num_updates 17470 | best_loss 8.238
2022-03-07 04:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17470 updates
2022-03-07 04:18:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 359 @ 17470 updates, score 15.198) (writing took 2.500075563788414 seconds)
2022-03-07 04:18:35 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 04:18:35 | INFO | train | epoch 359 | loss 0.506 | nll_loss 0.188 | ppl 1.14 | wps 24878.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17470 | lr 0.000239251 | gnorm 0.41 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 54990
2022-03-07 04:18:35 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 04:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:19:52 | INFO | train_inner | epoch 360:     30 / 49 loss=0.506, nll_loss=0.188, ppl=1.14, wps=24410.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.411, loss_scale=64, train_wall=227, gb_free=8.8, wall=55068
2022-03-07 04:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:20:43 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 15.3 | nll_loss 15.187 | ppl 37314.9 | wps 47304.9 | wpb 510.9 | bsz 1 | num_updates 17519 | best_loss 8.238
2022-03-07 04:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17519 updates
2022-03-07 04:20:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 360 @ 17519 updates, score 15.3) (writing took 2.419410727918148 seconds)
2022-03-07 04:20:45 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 04:20:45 | INFO | train | epoch 360 | loss 0.505 | nll_loss 0.187 | ppl 1.14 | wps 24418.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17519 | lr 0.000238916 | gnorm 0.41 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 55121
2022-03-07 04:20:45 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 04:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:22:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:22:53 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 15.34 | nll_loss 15.227 | ppl 38353.8 | wps 46750.7 | wpb 510.9 | bsz 1 | num_updates 17567 | best_loss 8.238
2022-03-07 04:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17567 updates
2022-03-07 04:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:22:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 361 @ 17567 updates, score 15.34) (writing took 2.503498924896121 seconds)
2022-03-07 04:22:56 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 04:22:56 | INFO | train | epoch 361 | loss 0.504 | nll_loss 0.186 | ppl 1.14 | wps 23894.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17567 | lr 0.000238589 | gnorm 0.408 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 55251
2022-03-07 04:22:56 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 04:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:24:18 | INFO | train_inner | epoch 362:     33 / 49 loss=0.504, nll_loss=0.186, ppl=1.14, wps=24464.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.404, loss_scale=64, train_wall=226, gb_free=8.8, wall=55333
2022-03-07 04:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:25:01 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 15.247 | nll_loss 15.131 | ppl 35893.2 | wps 46872.9 | wpb 510.9 | bsz 1 | num_updates 17616 | best_loss 8.238
2022-03-07 04:25:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17616 updates
2022-03-07 04:25:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:25:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 362 @ 17616 updates, score 15.247) (writing took 2.4293515477329493 seconds)
2022-03-07 04:25:03 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 04:25:03 | INFO | train | epoch 362 | loss 0.504 | nll_loss 0.186 | ppl 1.14 | wps 24864.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17616 | lr 0.000238257 | gnorm 0.4 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 55379
2022-03-07 04:25:03 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 04:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:27:11 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 15.318 | nll_loss 15.204 | ppl 37755.6 | wps 46716.8 | wpb 510.9 | bsz 1 | num_updates 17665 | best_loss 8.238
2022-03-07 04:27:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17665 updates
2022-03-07 04:27:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:27:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 363 @ 17665 updates, score 15.318) (writing took 2.4399210903793573 seconds)
2022-03-07 04:27:14 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 04:27:14 | INFO | train | epoch 363 | loss 0.504 | nll_loss 0.186 | ppl 1.14 | wps 24420.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17665 | lr 0.000237927 | gnorm 0.405 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 55509
2022-03-07 04:27:14 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 04:27:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:28:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:28:44 | INFO | train_inner | epoch 364:     36 / 49 loss=0.504, nll_loss=0.186, ppl=1.14, wps=24346, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.405, loss_scale=64, train_wall=228, gb_free=8.8, wall=55599
2022-03-07 04:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:29:21 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 15.218 | nll_loss 15.105 | ppl 35234.3 | wps 47414 | wpb 510.9 | bsz 1 | num_updates 17713 | best_loss 8.238
2022-03-07 04:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17713 updates
2022-03-07 04:29:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:29:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 364 @ 17713 updates, score 15.218) (writing took 2.5180802531540394 seconds)
2022-03-07 04:29:24 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 04:29:24 | INFO | train | epoch 364 | loss 0.504 | nll_loss 0.186 | ppl 1.14 | wps 23909.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 17713 | lr 0.000237604 | gnorm 0.405 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 55639
2022-03-07 04:29:24 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 04:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:31:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:31:29 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 15.304 | nll_loss 15.191 | ppl 37399.6 | wps 47490.5 | wpb 510.9 | bsz 1 | num_updates 17761 | best_loss 8.238
2022-03-07 04:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17761 updates
2022-03-07 04:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:31:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:31:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 365 @ 17761 updates, score 15.304) (writing took 2.4279986638575792 seconds)
2022-03-07 04:31:31 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 04:31:31 | INFO | train | epoch 365 | loss 0.502 | nll_loss 0.184 | ppl 1.14 | wps 24444 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 17761 | lr 0.000237283 | gnorm 0.401 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 55766
2022-03-07 04:31:31 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 04:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:33:10 | INFO | train_inner | epoch 366:     39 / 49 loss=0.502, nll_loss=0.184, ppl=1.14, wps=24380, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.401, loss_scale=32, train_wall=227, gb_free=8.8, wall=55865
2022-03-07 04:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:33:38 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 15.309 | nll_loss 15.196 | ppl 37544.5 | wps 47194.3 | wpb 510.9 | bsz 1 | num_updates 17810 | best_loss 8.238
2022-03-07 04:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17810 updates
2022-03-07 04:33:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:33:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:33:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 366 @ 17810 updates, score 15.309) (writing took 2.4055418223142624 seconds)
2022-03-07 04:33:41 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 04:33:41 | INFO | train | epoch 366 | loss 0.501 | nll_loss 0.184 | ppl 1.14 | wps 24503.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17810 | lr 0.000236956 | gnorm 0.402 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 55896
2022-03-07 04:33:41 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 04:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:35:48 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 15.35 | nll_loss 15.237 | ppl 38617.3 | wps 46915.5 | wpb 510.9 | bsz 1 | num_updates 17859 | best_loss 8.238
2022-03-07 04:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17859 updates
2022-03-07 04:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 367 @ 17859 updates, score 15.35) (writing took 2.5056121218949556 seconds)
2022-03-07 04:35:51 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 04:35:51 | INFO | train | epoch 367 | loss 0.501 | nll_loss 0.183 | ppl 1.14 | wps 24477.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17859 | lr 0.000236631 | gnorm 0.402 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 56026
2022-03-07 04:35:51 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 04:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:37:32 | INFO | train_inner | epoch 368:     41 / 49 loss=0.501, nll_loss=0.184, ppl=1.14, wps=24749.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.405, loss_scale=64, train_wall=224, gb_free=8.8, wall=56127
2022-03-07 04:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:37:56 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 15.328 | nll_loss 15.215 | ppl 38039.3 | wps 41476.8 | wpb 510.9 | bsz 1 | num_updates 17908 | best_loss 8.238
2022-03-07 04:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17908 updates
2022-03-07 04:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:37:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 368 @ 17908 updates, score 15.328) (writing took 2.5945035722106695 seconds)
2022-03-07 04:37:59 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 04:37:59 | INFO | train | epoch 368 | loss 0.501 | nll_loss 0.184 | ppl 1.14 | wps 24796.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17908 | lr 0.000236307 | gnorm 0.408 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 56154
2022-03-07 04:37:59 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 04:37:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:40:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:06 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 15.251 | nll_loss 15.135 | ppl 35993.4 | wps 47064.8 | wpb 510.9 | bsz 1 | num_updates 17957 | best_loss 8.238
2022-03-07 04:40:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17957 updates
2022-03-07 04:40:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:40:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:40:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 369 @ 17957 updates, score 15.251) (writing took 2.4758917652070522 seconds)
2022-03-07 04:40:08 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 04:40:08 | INFO | train | epoch 369 | loss 0.5 | nll_loss 0.183 | ppl 1.14 | wps 24590.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 17957 | lr 0.000235984 | gnorm 0.401 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 56283
2022-03-07 04:40:08 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 04:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:41:57 | INFO | train_inner | epoch 370:     43 / 49 loss=0.5, nll_loss=0.183, ppl=1.13, wps=24500.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.401, loss_scale=64, train_wall=225, gb_free=8.8, wall=56392
2022-03-07 04:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:42:15 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 15.192 | nll_loss 15.078 | ppl 34585.3 | wps 47517.5 | wpb 510.9 | bsz 1 | num_updates 18006 | best_loss 8.238
2022-03-07 04:42:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18006 updates
2022-03-07 04:42:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:42:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:42:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 370 @ 18006 updates, score 15.192) (writing took 2.4346798080950975 seconds)
2022-03-07 04:42:18 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 04:42:18 | INFO | train | epoch 370 | loss 0.499 | nll_loss 0.182 | ppl 1.13 | wps 24501.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18006 | lr 0.000235663 | gnorm 0.4 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 56413
2022-03-07 04:42:18 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 04:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:42:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:44:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:44:25 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 15.196 | nll_loss 15.082 | ppl 34679.4 | wps 46584.7 | wpb 510.9 | bsz 1 | num_updates 18054 | best_loss 8.238
2022-03-07 04:44:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18054 updates
2022-03-07 04:44:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 371 @ 18054 updates, score 15.196) (writing took 2.4124064836651087 seconds)
2022-03-07 04:44:28 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 04:44:28 | INFO | train | epoch 371 | loss 0.499 | nll_loss 0.182 | ppl 1.13 | wps 23972.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18054 | lr 0.00023535 | gnorm 0.404 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 56543
2022-03-07 04:44:28 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 04:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:46:22 | INFO | train_inner | epoch 372:     46 / 49 loss=0.499, nll_loss=0.182, ppl=1.13, wps=24502.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.404, loss_scale=64, train_wall=226, gb_free=8.8, wall=56657
2022-03-07 04:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:46:33 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 15.197 | nll_loss 15.082 | ppl 34679.9 | wps 46920.5 | wpb 510.9 | bsz 1 | num_updates 18103 | best_loss 8.238
2022-03-07 04:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18103 updates
2022-03-07 04:46:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:46:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 372 @ 18103 updates, score 15.197) (writing took 2.477325500920415 seconds)
2022-03-07 04:46:35 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 04:46:35 | INFO | train | epoch 372 | loss 0.498 | nll_loss 0.181 | ppl 1.13 | wps 24897.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18103 | lr 0.000235031 | gnorm 0.405 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 56670
2022-03-07 04:46:35 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 04:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:48:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:48:43 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 15.308 | nll_loss 15.195 | ppl 37508.9 | wps 46746.9 | wpb 510.9 | bsz 1 | num_updates 18151 | best_loss 8.238
2022-03-07 04:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18151 updates
2022-03-07 04:48:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:48:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 373 @ 18151 updates, score 15.308) (writing took 2.4357947036623955 seconds)
2022-03-07 04:48:45 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 04:48:45 | INFO | train | epoch 373 | loss 0.497 | nll_loss 0.18 | ppl 1.13 | wps 23966.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18151 | lr 0.00023472 | gnorm 0.395 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 56800
2022-03-07 04:48:45 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 04:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:50:48 | INFO | train_inner | epoch 374:     49 / 49 loss=0.497, nll_loss=0.18, ppl=1.13, wps=24260.8, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=18200, lr=0.000234404, gnorm=0.398, loss_scale=64, train_wall=227, gb_free=8.8, wall=56923
2022-03-07 04:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:50:53 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 15.273 | nll_loss 15.16 | ppl 36607.3 | wps 46811.7 | wpb 510.9 | bsz 1 | num_updates 18200 | best_loss 8.238
2022-03-07 04:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18200 updates
2022-03-07 04:50:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 374 @ 18200 updates, score 15.273) (writing took 2.478587305173278 seconds)
2022-03-07 04:50:55 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 04:50:55 | INFO | train | epoch 374 | loss 0.497 | nll_loss 0.18 | ppl 1.13 | wps 24448.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18200 | lr 0.000234404 | gnorm 0.398 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 56930
2022-03-07 04:50:55 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 04:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:53:00 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 15.324 | nll_loss 15.211 | ppl 37930.5 | wps 47029.7 | wpb 510.9 | bsz 1 | num_updates 18249 | best_loss 8.238
2022-03-07 04:53:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18249 updates
2022-03-07 04:53:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:53:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:53:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 375 @ 18249 updates, score 15.324) (writing took 2.491545181721449 seconds)
2022-03-07 04:53:03 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 04:53:03 | INFO | train | epoch 375 | loss 0.496 | nll_loss 0.179 | ppl 1.13 | wps 24909.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18249 | lr 0.000234089 | gnorm 0.392 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 57058
2022-03-07 04:53:03 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 04:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:54:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 04:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:55:10 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 15.326 | nll_loss 15.213 | ppl 37979.9 | wps 47033.2 | wpb 510.9 | bsz 1 | num_updates 18297 | best_loss 8.238
2022-03-07 04:55:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18297 updates
2022-03-07 04:55:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:55:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:55:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 376 @ 18297 updates, score 15.326) (writing took 2.4667723793536425 seconds)
2022-03-07 04:55:12 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 04:55:12 | INFO | train | epoch 376 | loss 0.497 | nll_loss 0.18 | ppl 1.13 | wps 23985 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18297 | lr 0.000233781 | gnorm 0.399 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 57188
2022-03-07 04:55:12 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 04:55:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:55:20 | INFO | train_inner | epoch 377:      3 / 49 loss=0.496, nll_loss=0.18, ppl=1.13, wps=23842.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.395, loss_scale=64, train_wall=226, gb_free=8.8, wall=57195
2022-03-07 04:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:57:20 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 15.252 | nll_loss 15.139 | ppl 36079.8 | wps 47189.9 | wpb 510.9 | bsz 1 | num_updates 18346 | best_loss 8.238
2022-03-07 04:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18346 updates
2022-03-07 04:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 377 @ 18346 updates, score 15.252) (writing took 2.503770340234041 seconds)
2022-03-07 04:57:22 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 04:57:22 | INFO | train | epoch 377 | loss 0.496 | nll_loss 0.18 | ppl 1.13 | wps 24499.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18346 | lr 0.000233469 | gnorm 0.397 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 57317
2022-03-07 04:57:22 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 04:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:59:29 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 15.246 | nll_loss 15.133 | ppl 35938.3 | wps 38547.2 | wpb 510.9 | bsz 1 | num_updates 18395 | best_loss 8.238
2022-03-07 04:59:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18395 updates
2022-03-07 04:59:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 04:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 378 @ 18395 updates, score 15.246) (writing took 2.6918176896870136 seconds)
2022-03-07 04:59:31 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 04:59:31 | INFO | train | epoch 378 | loss 0.495 | nll_loss 0.178 | ppl 1.13 | wps 24611.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18395 | lr 0.000233158 | gnorm 0.395 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 57446
2022-03-07 04:59:31 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 04:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:59:45 | INFO | train_inner | epoch 379:      5 / 49 loss=0.495, nll_loss=0.179, ppl=1.13, wps=24501.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.395, loss_scale=128, train_wall=225, gb_free=8.8, wall=57460
2022-03-07 04:59:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:01:37 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 15.242 | nll_loss 15.13 | ppl 35861.7 | wps 46683.3 | wpb 510.9 | bsz 1 | num_updates 18443 | best_loss 8.238
2022-03-07 05:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18443 updates
2022-03-07 05:01:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:01:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:01:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 379 @ 18443 updates, score 15.242) (writing took 2.4820588883012533 seconds)
2022-03-07 05:01:40 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 05:01:40 | INFO | train | epoch 379 | loss 0.495 | nll_loss 0.178 | ppl 1.13 | wps 24231.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18443 | lr 0.000232854 | gnorm 0.397 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 57575
2022-03-07 05:01:40 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 05:01:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:03:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:03:47 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 15.344 | nll_loss 15.231 | ppl 38467.5 | wps 47003.5 | wpb 510.9 | bsz 1 | num_updates 18492 | best_loss 8.238
2022-03-07 05:03:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18492 updates
2022-03-07 05:03:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:03:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:03:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 380 @ 18492 updates, score 15.344) (writing took 2.4991306886076927 seconds)
2022-03-07 05:03:50 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 05:03:50 | INFO | train | epoch 380 | loss 0.493 | nll_loss 0.177 | ppl 1.13 | wps 24458 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18492 | lr 0.000232546 | gnorm 0.394 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 57705
2022-03-07 05:03:50 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 05:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:04:09 | INFO | train_inner | epoch 381:      8 / 49 loss=0.494, nll_loss=0.177, ppl=1.13, wps=24502.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.395, loss_scale=64, train_wall=226, gb_free=8.8, wall=57725
2022-03-07 05:05:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:05:57 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 15.282 | nll_loss 15.169 | ppl 36840.7 | wps 46195.7 | wpb 510.9 | bsz 1 | num_updates 18540 | best_loss 8.238
2022-03-07 05:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18540 updates
2022-03-07 05:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 381 @ 18540 updates, score 15.282) (writing took 2.4960491955280304 seconds)
2022-03-07 05:05:59 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 05:05:59 | INFO | train | epoch 381 | loss 0.493 | nll_loss 0.177 | ppl 1.13 | wps 23994.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18540 | lr 0.000232244 | gnorm 0.39 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 57835
2022-03-07 05:05:59 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 05:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:08:04 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 15.239 | nll_loss 15.126 | ppl 35762.7 | wps 47090.4 | wpb 510.9 | bsz 1 | num_updates 18589 | best_loss 8.238
2022-03-07 05:08:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18589 updates
2022-03-07 05:08:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:08:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:08:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 382 @ 18589 updates, score 15.239) (writing took 2.463206982240081 seconds)
2022-03-07 05:08:07 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 05:08:07 | INFO | train | epoch 382 | loss 0.493 | nll_loss 0.177 | ppl 1.13 | wps 24930.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18589 | lr 0.000231938 | gnorm 0.392 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 57962
2022-03-07 05:08:07 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 05:08:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:36 | INFO | train_inner | epoch 383:     11 / 49 loss=0.493, nll_loss=0.177, ppl=1.13, wps=24385.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.392, loss_scale=64, train_wall=227, gb_free=8.8, wall=57991
2022-03-07 05:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:10:14 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 15.287 | nll_loss 15.173 | ppl 36938.3 | wps 47064.3 | wpb 510.9 | bsz 1 | num_updates 18638 | best_loss 8.238
2022-03-07 05:10:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18638 updates
2022-03-07 05:10:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:10:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 383 @ 18638 updates, score 15.287) (writing took 2.5159554164856672 seconds)
2022-03-07 05:10:17 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 05:10:17 | INFO | train | epoch 383 | loss 0.493 | nll_loss 0.177 | ppl 1.13 | wps 24440.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18638 | lr 0.000231633 | gnorm 0.394 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 58092
2022-03-07 05:10:17 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 05:10:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:12:24 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 15.329 | nll_loss 15.217 | ppl 38098.6 | wps 47556.3 | wpb 510.9 | bsz 1 | num_updates 18686 | best_loss 8.238
2022-03-07 05:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18686 updates
2022-03-07 05:12:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 384 @ 18686 updates, score 15.329) (writing took 2.511125246062875 seconds)
2022-03-07 05:12:27 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 05:12:27 | INFO | train | epoch 384 | loss 0.492 | nll_loss 0.176 | ppl 1.13 | wps 23987.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 18686 | lr 0.000231335 | gnorm 0.391 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 58222
2022-03-07 05:12:27 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 05:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:13:01 | INFO | train_inner | epoch 385:     14 / 49 loss=0.492, nll_loss=0.176, ppl=1.13, wps=24391.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.392, loss_scale=64, train_wall=227, gb_free=8.8, wall=58257
2022-03-07 05:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:14:33 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 15.273 | nll_loss 15.161 | ppl 36626.4 | wps 38920.7 | wpb 510.9 | bsz 1 | num_updates 18735 | best_loss 8.238
2022-03-07 05:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18735 updates
2022-03-07 05:14:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:14:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 385 @ 18735 updates, score 15.273) (writing took 2.6302418150007725 seconds)
2022-03-07 05:14:36 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 05:14:36 | INFO | train | epoch 385 | loss 0.49 | nll_loss 0.175 | ppl 1.13 | wps 24651.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18735 | lr 0.000231033 | gnorm 0.391 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 58351
2022-03-07 05:14:36 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 05:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:16:41 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 15.303 | nll_loss 15.192 | ppl 37424.2 | wps 47437.4 | wpb 510.9 | bsz 1 | num_updates 18784 | best_loss 8.238
2022-03-07 05:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18784 updates
2022-03-07 05:16:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 386 @ 18784 updates, score 15.303) (writing took 2.4975084383040667 seconds)
2022-03-07 05:16:44 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 05:16:44 | INFO | train | epoch 386 | loss 0.492 | nll_loss 0.176 | ppl 1.13 | wps 24754.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18784 | lr 0.000230731 | gnorm 0.393 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 58479
2022-03-07 05:16:44 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 05:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:17:26 | INFO | train_inner | epoch 387:     17 / 49 loss=0.491, nll_loss=0.175, ppl=1.13, wps=24491.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.392, loss_scale=64, train_wall=225, gb_free=8.8, wall=58521
2022-03-07 05:18:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:18:51 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 15.142 | nll_loss 15.029 | ppl 33427.3 | wps 47094.8 | wpb 510.9 | bsz 1 | num_updates 18831 | best_loss 8.238
2022-03-07 05:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18831 updates
2022-03-07 05:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:18:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:18:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 387 @ 18831 updates, score 15.142) (writing took 2.491620250046253 seconds)
2022-03-07 05:18:54 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 05:18:54 | INFO | train | epoch 387 | loss 0.49 | nll_loss 0.174 | ppl 1.13 | wps 23470.2 | ups 0.36 | wpb 64829.4 | bsz 126.6 | num_updates 18831 | lr 0.000230443 | gnorm 0.387 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58609
2022-03-07 05:18:54 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 05:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:20:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:21:01 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 15.196 | nll_loss 15.084 | ppl 34737.3 | wps 47257.2 | wpb 510.9 | bsz 1 | num_updates 18880 | best_loss 8.238
2022-03-07 05:21:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18880 updates
2022-03-07 05:21:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:21:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:21:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 388 @ 18880 updates, score 15.196) (writing took 2.4843180794268847 seconds)
2022-03-07 05:21:04 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 05:21:04 | INFO | train | epoch 388 | loss 0.49 | nll_loss 0.174 | ppl 1.13 | wps 24491.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18880 | lr 0.000230144 | gnorm 0.388 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 58739
2022-03-07 05:21:04 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 05:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:53 | INFO | train_inner | epoch 389:     20 / 49 loss=0.49, nll_loss=0.174, ppl=1.13, wps=24318, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.388, loss_scale=32, train_wall=228, gb_free=8.8, wall=58788
2022-03-07 05:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:23:08 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 15.294 | nll_loss 15.184 | ppl 37214.5 | wps 47248.9 | wpb 510.9 | bsz 1 | num_updates 18929 | best_loss 8.238
2022-03-07 05:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18929 updates
2022-03-07 05:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:23:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 389 @ 18929 updates, score 15.294) (writing took 2.4817948285490274 seconds)
2022-03-07 05:23:11 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 05:23:11 | INFO | train | epoch 389 | loss 0.489 | nll_loss 0.174 | ppl 1.13 | wps 24981.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 18929 | lr 0.000229846 | gnorm 0.388 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 58866
2022-03-07 05:23:11 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 05:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:25:18 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 15.193 | nll_loss 15.082 | ppl 34680.7 | wps 47106.3 | wpb 510.9 | bsz 1 | num_updates 18978 | best_loss 8.238
2022-03-07 05:25:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18978 updates
2022-03-07 05:25:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 390 @ 18978 updates, score 15.193) (writing took 2.452332464978099 seconds)
2022-03-07 05:25:20 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 05:25:20 | INFO | train | epoch 390 | loss 0.488 | nll_loss 0.173 | ppl 1.13 | wps 24503.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 18978 | lr 0.000229549 | gnorm 0.385 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 58996
2022-03-07 05:25:20 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 05:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:26:15 | INFO | train_inner | epoch 391:     22 / 49 loss=0.488, nll_loss=0.173, ppl=1.13, wps=24776.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.386, loss_scale=64, train_wall=223, gb_free=8.8, wall=59050
2022-03-07 05:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:27:27 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 15.344 | nll_loss 15.234 | ppl 38550 | wps 47045.1 | wpb 510.9 | bsz 1 | num_updates 19027 | best_loss 8.238
2022-03-07 05:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19027 updates
2022-03-07 05:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 391 @ 19027 updates, score 15.344) (writing took 2.4623687379062176 seconds)
2022-03-07 05:27:30 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 05:27:30 | INFO | train | epoch 391 | loss 0.488 | nll_loss 0.173 | ppl 1.13 | wps 24544.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19027 | lr 0.000229253 | gnorm 0.387 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 59125
2022-03-07 05:27:30 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 05:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:29:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:29:37 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 15.34 | nll_loss 15.229 | ppl 38401.7 | wps 38734.6 | wpb 510.9 | bsz 1 | num_updates 19075 | best_loss 8.238
2022-03-07 05:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19075 updates
2022-03-07 05:29:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:29:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:29:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 392 @ 19075 updates, score 15.34) (writing took 2.647083267569542 seconds)
2022-03-07 05:29:40 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 05:29:40 | INFO | train | epoch 392 | loss 0.488 | nll_loss 0.173 | ppl 1.13 | wps 23990 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19075 | lr 0.000228964 | gnorm 0.389 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 59255
2022-03-07 05:29:40 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 05:29:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:30:43 | INFO | train_inner | epoch 393:     25 / 49 loss=0.487, nll_loss=0.172, ppl=1.13, wps=24239, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.386, loss_scale=64, train_wall=228, gb_free=8.8, wall=59318
2022-03-07 05:31:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:31:46 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 15.223 | nll_loss 15.112 | ppl 35417.9 | wps 47188 | wpb 510.9 | bsz 1 | num_updates 19124 | best_loss 8.238
2022-03-07 05:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19124 updates
2022-03-07 05:31:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:31:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 393 @ 19124 updates, score 15.223) (writing took 2.470622606575489 seconds)
2022-03-07 05:31:48 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 05:31:48 | INFO | train | epoch 393 | loss 0.487 | nll_loss 0.171 | ppl 1.13 | wps 24756.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19124 | lr 0.000228671 | gnorm 0.384 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 59383
2022-03-07 05:31:48 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 05:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:33:55 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 15.304 | nll_loss 15.192 | ppl 37434.2 | wps 46882.8 | wpb 510.9 | bsz 1 | num_updates 19173 | best_loss 8.238
2022-03-07 05:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19173 updates
2022-03-07 05:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:33:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 394 @ 19173 updates, score 15.304) (writing took 2.4833084009587765 seconds)
2022-03-07 05:33:58 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 05:33:58 | INFO | train | epoch 394 | loss 0.487 | nll_loss 0.172 | ppl 1.13 | wps 24483.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19173 | lr 0.000228378 | gnorm 0.388 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59513
2022-03-07 05:33:58 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 05:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:35:07 | INFO | train_inner | epoch 395:     28 / 49 loss=0.487, nll_loss=0.172, ppl=1.13, wps=24503.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.386, loss_scale=64, train_wall=226, gb_free=8.8, wall=59582
2022-03-07 05:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:36:05 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 15.341 | nll_loss 15.23 | ppl 38425.4 | wps 47244.6 | wpb 510.9 | bsz 1 | num_updates 19221 | best_loss 8.238
2022-03-07 05:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19221 updates
2022-03-07 05:36:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 395 @ 19221 updates, score 15.341) (writing took 2.4958635587245226 seconds)
2022-03-07 05:36:08 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 05:36:08 | INFO | train | epoch 395 | loss 0.486 | nll_loss 0.171 | ppl 1.13 | wps 23992.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19221 | lr 0.000228093 | gnorm 0.382 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59643
2022-03-07 05:36:08 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 05:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:38:12 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 15.232 | nll_loss 15.121 | ppl 35629.9 | wps 47194.8 | wpb 510.9 | bsz 1 | num_updates 19270 | best_loss 8.238
2022-03-07 05:38:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19270 updates
2022-03-07 05:38:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:38:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:38:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 396 @ 19270 updates, score 15.232) (writing took 2.4749192353338003 seconds)
2022-03-07 05:38:15 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 05:38:15 | INFO | train | epoch 396 | loss 0.486 | nll_loss 0.171 | ppl 1.13 | wps 24954.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19270 | lr 0.000227803 | gnorm 0.389 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 59770
2022-03-07 05:38:15 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 05:38:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:39:32 | INFO | train_inner | epoch 397:     30 / 49 loss=0.486, nll_loss=0.171, ppl=1.13, wps=24539.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.386, loss_scale=64, train_wall=226, gb_free=8.8, wall=59847
2022-03-07 05:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:40:22 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 15.306 | nll_loss 15.195 | ppl 37514.2 | wps 47100.6 | wpb 510.9 | bsz 1 | num_updates 19319 | best_loss 8.238
2022-03-07 05:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19319 updates
2022-03-07 05:40:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:40:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:40:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 397 @ 19319 updates, score 15.306) (writing took 2.5306639317423105 seconds)
2022-03-07 05:40:25 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 05:40:25 | INFO | train | epoch 397 | loss 0.485 | nll_loss 0.17 | ppl 1.13 | wps 24494.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19319 | lr 0.000227514 | gnorm 0.382 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 59900
2022-03-07 05:40:25 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 05:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:42:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:42:32 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 15.173 | nll_loss 15.059 | ppl 34137.5 | wps 46976.9 | wpb 510.9 | bsz 1 | num_updates 19367 | best_loss 8.238
2022-03-07 05:42:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19367 updates
2022-03-07 05:42:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:42:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:42:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 398 @ 19367 updates, score 15.173) (writing took 2.4469792935997248 seconds)
2022-03-07 05:42:34 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 05:42:34 | INFO | train | epoch 398 | loss 0.484 | nll_loss 0.17 | ppl 1.12 | wps 23994.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19367 | lr 0.000227232 | gnorm 0.379 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60030
2022-03-07 05:42:34 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 05:42:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:43:56 | INFO | train_inner | epoch 399:     33 / 49 loss=0.484, nll_loss=0.169, ppl=1.12, wps=24514.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.379, loss_scale=64, train_wall=226, gb_free=8.8, wall=60111
2022-03-07 05:44:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:44:41 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 15.324 | nll_loss 15.213 | ppl 37971.1 | wps 38917.1 | wpb 510.9 | bsz 1 | num_updates 19416 | best_loss 8.238
2022-03-07 05:44:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19416 updates
2022-03-07 05:44:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:44:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:44:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 399 @ 19416 updates, score 15.324) (writing took 2.685410561040044 seconds)
2022-03-07 05:44:44 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 05:44:44 | INFO | train | epoch 399 | loss 0.484 | nll_loss 0.17 | ppl 1.12 | wps 24495.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19416 | lr 0.000226945 | gnorm 0.381 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 60159
2022-03-07 05:44:44 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 05:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:46:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:46:49 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 15.328 | nll_loss 15.218 | ppl 38106.7 | wps 46910.9 | wpb 510.9 | bsz 1 | num_updates 19464 | best_loss 8.238
2022-03-07 05:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19464 updates
2022-03-07 05:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 400 @ 19464 updates, score 15.328) (writing took 2.495116863399744 seconds)
2022-03-07 05:46:52 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 05:46:52 | INFO | train | epoch 400 | loss 0.484 | nll_loss 0.17 | ppl 1.12 | wps 24432.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19464 | lr 0.000226665 | gnorm 0.386 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 60287
2022-03-07 05:46:52 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 05:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:48:23 | INFO | train_inner | epoch 401:     36 / 49 loss=0.484, nll_loss=0.169, ppl=1.12, wps=24307.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.382, loss_scale=64, train_wall=227, gb_free=8.8, wall=60378
2022-03-07 05:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:48:59 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 15.379 | nll_loss 15.268 | ppl 39463.5 | wps 47040.9 | wpb 510.9 | bsz 1 | num_updates 19513 | best_loss 8.238
2022-03-07 05:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19513 updates
2022-03-07 05:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:49:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:49:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 401 @ 19513 updates, score 15.379) (writing took 2.4622137881815434 seconds)
2022-03-07 05:49:01 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 05:49:01 | INFO | train | epoch 401 | loss 0.482 | nll_loss 0.168 | ppl 1.12 | wps 24504.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19513 | lr 0.00022638 | gnorm 0.377 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60416
2022-03-07 05:49:01 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 05:49:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:51:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:51:09 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 15.298 | nll_loss 15.189 | ppl 37359.8 | wps 47189 | wpb 510.9 | bsz 1 | num_updates 19562 | best_loss 8.238
2022-03-07 05:51:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19562 updates
2022-03-07 05:51:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:51:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:51:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 402 @ 19562 updates, score 15.298) (writing took 2.4845998156815767 seconds)
2022-03-07 05:51:11 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 05:51:11 | INFO | train | epoch 402 | loss 0.482 | nll_loss 0.168 | ppl 1.12 | wps 24459.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19562 | lr 0.000226096 | gnorm 0.379 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60546
2022-03-07 05:51:11 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 05:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:52:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:52:48 | INFO | train_inner | epoch 403:     39 / 49 loss=0.483, nll_loss=0.168, ppl=1.12, wps=24499.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.381, loss_scale=64, train_wall=226, gb_free=8.8, wall=60643
2022-03-07 05:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:53:16 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 15.175 | nll_loss 15.064 | ppl 34261.8 | wps 47392.7 | wpb 510.9 | bsz 1 | num_updates 19610 | best_loss 8.238
2022-03-07 05:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19610 updates
2022-03-07 05:53:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:53:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 403 @ 19610 updates, score 15.175) (writing took 2.4976679123938084 seconds)
2022-03-07 05:53:19 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 05:53:19 | INFO | train | epoch 403 | loss 0.483 | nll_loss 0.168 | ppl 1.12 | wps 24408.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 19610 | lr 0.000225819 | gnorm 0.381 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 60674
2022-03-07 05:53:19 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 05:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:55:26 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 15.33 | nll_loss 15.22 | ppl 38156.7 | wps 47043.8 | wpb 510.9 | bsz 1 | num_updates 19659 | best_loss 8.238
2022-03-07 05:55:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19659 updates
2022-03-07 05:55:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:55:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 404 @ 19659 updates, score 15.33) (writing took 2.509153066202998 seconds)
2022-03-07 05:55:28 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 05:55:28 | INFO | train | epoch 404 | loss 0.482 | nll_loss 0.168 | ppl 1.12 | wps 24519.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19659 | lr 0.000225538 | gnorm 0.378 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60803
2022-03-07 05:55:28 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 05:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:12 | INFO | train_inner | epoch 405:     41 / 49 loss=0.481, nll_loss=0.167, ppl=1.12, wps=24524.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.377, loss_scale=64, train_wall=226, gb_free=8.8, wall=60908
2022-03-07 05:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:57:36 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 15.313 | nll_loss 15.203 | ppl 37731.5 | wps 47034.5 | wpb 510.9 | bsz 1 | num_updates 19708 | best_loss 8.238
2022-03-07 05:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19708 updates
2022-03-07 05:57:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 405 @ 19708 updates, score 15.313) (writing took 2.4579527974128723 seconds)
2022-03-07 05:57:38 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 05:57:38 | INFO | train | epoch 405 | loss 0.481 | nll_loss 0.167 | ppl 1.12 | wps 24455.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19708 | lr 0.000225257 | gnorm 0.376 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 60933
2022-03-07 05:57:38 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 05:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:57:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 05:59:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:59:46 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 15.231 | nll_loss 15.122 | ppl 35660.5 | wps 39597.6 | wpb 510.9 | bsz 1 | num_updates 19756 | best_loss 8.238
2022-03-07 05:59:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19756 updates
2022-03-07 05:59:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:59:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 05:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 406 @ 19756 updates, score 15.231) (writing took 2.483774345368147 seconds)
2022-03-07 05:59:48 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 05:59:48 | INFO | train | epoch 406 | loss 0.482 | nll_loss 0.168 | ppl 1.12 | wps 23935.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19756 | lr 0.000224983 | gnorm 0.381 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 61063
2022-03-07 05:59:48 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 05:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:01:37 | INFO | train_inner | epoch 407:     44 / 49 loss=0.481, nll_loss=0.167, ppl=1.12, wps=24487.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.381, loss_scale=64, train_wall=225, gb_free=8.8, wall=61173
2022-03-07 06:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:01:53 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 15.157 | nll_loss 15.045 | ppl 33817.2 | wps 46607.8 | wpb 510.9 | bsz 1 | num_updates 19805 | best_loss 8.238
2022-03-07 06:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19805 updates
2022-03-07 06:01:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:01:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 407 @ 19805 updates, score 15.157) (writing took 2.49737111851573 seconds)
2022-03-07 06:01:56 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 06:01:56 | INFO | train | epoch 407 | loss 0.481 | nll_loss 0.167 | ppl 1.12 | wps 24930.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19805 | lr 0.000224705 | gnorm 0.381 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 61191
2022-03-07 06:01:56 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 06:01:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:03:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:04:03 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 15.241 | nll_loss 15.131 | ppl 35873.1 | wps 47360.6 | wpb 510.9 | bsz 1 | num_updates 19853 | best_loss 8.238
2022-03-07 06:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19853 updates
2022-03-07 06:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 408 @ 19853 updates, score 15.241) (writing took 2.456919338554144 seconds)
2022-03-07 06:04:05 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 06:04:05 | INFO | train | epoch 408 | loss 0.48 | nll_loss 0.166 | ppl 1.12 | wps 24004.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19853 | lr 0.000224433 | gnorm 0.376 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 61321
2022-03-07 06:04:05 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 06:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:06:04 | INFO | train_inner | epoch 409:     47 / 49 loss=0.48, nll_loss=0.166, ppl=1.12, wps=24303.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.377, loss_scale=64, train_wall=228, gb_free=8.8, wall=61439
2022-03-07 06:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:06:13 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 15.235 | nll_loss 15.125 | ppl 35735.9 | wps 47352.6 | wpb 510.9 | bsz 1 | num_updates 19902 | best_loss 8.238
2022-03-07 06:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19902 updates
2022-03-07 06:06:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:06:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:06:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 409 @ 19902 updates, score 15.235) (writing took 2.4761769119650126 seconds)
2022-03-07 06:06:15 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 06:06:15 | INFO | train | epoch 409 | loss 0.48 | nll_loss 0.166 | ppl 1.12 | wps 24498.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19902 | lr 0.000224157 | gnorm 0.378 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 61450
2022-03-07 06:06:15 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 06:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:08:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:08:20 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 15.246 | nll_loss 15.136 | ppl 36002.7 | wps 46971.4 | wpb 510.9 | bsz 1 | num_updates 19951 | best_loss 8.238
2022-03-07 06:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19951 updates
2022-03-07 06:08:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:08:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 410 @ 19951 updates, score 15.246) (writing took 2.5038376078009605 seconds)
2022-03-07 06:08:23 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 06:08:23 | INFO | train | epoch 410 | loss 0.479 | nll_loss 0.165 | ppl 1.12 | wps 24904.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 19951 | lr 0.000223881 | gnorm 0.376 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 61578
2022-03-07 06:08:23 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 06:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:09:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:10:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:10:30 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 15.085 | nll_loss 14.974 | ppl 32179.2 | wps 47128.1 | wpb 510.9 | bsz 1 | num_updates 19999 | best_loss 8.238
2022-03-07 06:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 19999 updates
2022-03-07 06:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:10:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:10:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 411 @ 19999 updates, score 15.085) (writing took 2.487376255914569 seconds)
2022-03-07 06:10:32 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 06:10:32 | INFO | train | epoch 411 | loss 0.479 | nll_loss 0.165 | ppl 1.12 | wps 24022.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 19999 | lr 0.000223612 | gnorm 0.377 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 61707
2022-03-07 06:10:32 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 06:10:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:10:35 | INFO | train_inner | epoch 412:      1 / 49 loss=0.479, nll_loss=0.165, ppl=1.12, wps=23851.7, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=20000, lr=0.000223607, gnorm=0.378, loss_scale=64, train_wall=225, gb_free=8.8, wall=61710
2022-03-07 06:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:12:40 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 15.173 | nll_loss 15.061 | ppl 34188.5 | wps 47122.5 | wpb 510.9 | bsz 1 | num_updates 20048 | best_loss 8.238
2022-03-07 06:12:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20048 updates
2022-03-07 06:12:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 412 @ 20048 updates, score 15.173) (writing took 2.460512612015009 seconds)
2022-03-07 06:12:42 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 06:12:42 | INFO | train | epoch 412 | loss 0.479 | nll_loss 0.165 | ppl 1.12 | wps 24467.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20048 | lr 0.000223339 | gnorm 0.377 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 61837
2022-03-07 06:12:42 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 06:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:49 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 15.234 | nll_loss 15.124 | ppl 35715.7 | wps 46032.2 | wpb 510.9 | bsz 1 | num_updates 20097 | best_loss 8.238
2022-03-07 06:14:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20097 updates
2022-03-07 06:14:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 413 @ 20097 updates, score 15.234) (writing took 2.5312593057751656 seconds)
2022-03-07 06:14:52 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 06:14:52 | INFO | train | epoch 413 | loss 0.479 | nll_loss 0.165 | ppl 1.12 | wps 24484 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20097 | lr 0.000223067 | gnorm 0.378 | loss_scale 128 | train_wall 111 | gb_free 8.8 | wall 61967
2022-03-07 06:14:52 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 06:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:14:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:15:02 | INFO | train_inner | epoch 414:      4 / 49 loss=0.479, nll_loss=0.165, ppl=1.12, wps=24286.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.378, loss_scale=64, train_wall=228, gb_free=8.8, wall=61977
2022-03-07 06:15:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:16:57 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 15.249 | nll_loss 15.139 | ppl 36079.4 | wps 47076.6 | wpb 510.9 | bsz 1 | num_updates 20144 | best_loss 8.238
2022-03-07 06:16:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20144 updates
2022-03-07 06:16:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:16:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 414 @ 20144 updates, score 15.249) (writing took 2.447020808234811 seconds)
2022-03-07 06:16:59 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 06:16:59 | INFO | train | epoch 414 | loss 0.477 | nll_loss 0.164 | ppl 1.12 | wps 23941.2 | ups 0.37 | wpb 64829.4 | bsz 126.6 | num_updates 20144 | lr 0.000222806 | gnorm 0.377 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62094
2022-03-07 06:16:59 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 06:16:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:19:06 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 15.271 | nll_loss 15.162 | ppl 36673.9 | wps 47302 | wpb 510.9 | bsz 1 | num_updates 20193 | best_loss 8.238
2022-03-07 06:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20193 updates
2022-03-07 06:19:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 415 @ 20193 updates, score 15.271) (writing took 2.4857491590082645 seconds)
2022-03-07 06:19:09 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 06:19:09 | INFO | train | epoch 415 | loss 0.476 | nll_loss 0.162 | ppl 1.12 | wps 24515.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20193 | lr 0.000222536 | gnorm 0.368 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 62224
2022-03-07 06:19:09 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 06:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:19:26 | INFO | train_inner | epoch 416:      7 / 49 loss=0.476, nll_loss=0.163, ppl=1.12, wps=24538.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.371, loss_scale=32, train_wall=226, gb_free=8.8, wall=62242
2022-03-07 06:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:21:16 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 15.258 | nll_loss 15.148 | ppl 36314.6 | wps 47125.5 | wpb 510.9 | bsz 1 | num_updates 20242 | best_loss 8.238
2022-03-07 06:21:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20242 updates
2022-03-07 06:21:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:21:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 416 @ 20242 updates, score 15.258) (writing took 2.498254468664527 seconds)
2022-03-07 06:21:19 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 06:21:19 | INFO | train | epoch 416 | loss 0.476 | nll_loss 0.162 | ppl 1.12 | wps 24444.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20242 | lr 0.000222266 | gnorm 0.372 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 62354
2022-03-07 06:21:19 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 06:21:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:23:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:23:24 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 15.28 | nll_loss 15.17 | ppl 36877.2 | wps 47030 | wpb 510.9 | bsz 1 | num_updates 20290 | best_loss 8.238
2022-03-07 06:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20290 updates
2022-03-07 06:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 417 @ 20290 updates, score 15.28) (writing took 2.6398352179676294 seconds)
2022-03-07 06:23:26 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 06:23:26 | INFO | train | epoch 417 | loss 0.476 | nll_loss 0.163 | ppl 1.12 | wps 24418.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20290 | lr 0.000222003 | gnorm 0.373 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 62482
2022-03-07 06:23:26 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 06:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:23:53 | INFO | train_inner | epoch 418:     10 / 49 loss=0.476, nll_loss=0.162, ppl=1.12, wps=24303.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.374, loss_scale=32, train_wall=228, gb_free=8.8, wall=62508
2022-03-07 06:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:25:33 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 15.236 | nll_loss 15.126 | ppl 35762.9 | wps 46872.2 | wpb 510.9 | bsz 1 | num_updates 20339 | best_loss 8.238
2022-03-07 06:25:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20339 updates
2022-03-07 06:25:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:25:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 418 @ 20339 updates, score 15.236) (writing took 2.520643889904022 seconds)
2022-03-07 06:25:36 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 06:25:36 | INFO | train | epoch 418 | loss 0.475 | nll_loss 0.162 | ppl 1.12 | wps 24541.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20339 | lr 0.000221735 | gnorm 0.372 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 62611
2022-03-07 06:25:36 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 06:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:27:43 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 15.244 | nll_loss 15.135 | ppl 35979.7 | wps 47379.8 | wpb 510.9 | bsz 1 | num_updates 20388 | best_loss 8.238
2022-03-07 06:27:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20388 updates
2022-03-07 06:27:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:27:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:27:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 419 @ 20388 updates, score 15.244) (writing took 2.4415633864700794 seconds)
2022-03-07 06:27:45 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 06:27:45 | INFO | train | epoch 419 | loss 0.475 | nll_loss 0.162 | ppl 1.12 | wps 24530.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20388 | lr 0.000221469 | gnorm 0.37 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 62741
2022-03-07 06:27:45 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 06:27:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:15 | INFO | train_inner | epoch 420:     12 / 49 loss=0.475, nll_loss=0.162, ppl=1.12, wps=24760.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.37, loss_scale=32, train_wall=224, gb_free=8.8, wall=62770
2022-03-07 06:29:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:29:53 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 15.299 | nll_loss 15.19 | ppl 37386.1 | wps 46584 | wpb 510.9 | bsz 1 | num_updates 20437 | best_loss 8.238
2022-03-07 06:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20437 updates
2022-03-07 06:29:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:29:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:29:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 420 @ 20437 updates, score 15.299) (writing took 2.434901963919401 seconds)
2022-03-07 06:29:55 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 06:29:55 | INFO | train | epoch 420 | loss 0.475 | nll_loss 0.162 | ppl 1.12 | wps 24455.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20437 | lr 0.000221203 | gnorm 0.369 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 62871
2022-03-07 06:29:55 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 06:29:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:31:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:32:00 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 15.269 | nll_loss 15.159 | ppl 36587.3 | wps 47093.4 | wpb 510.9 | bsz 1 | num_updates 20486 | best_loss 8.238
2022-03-07 06:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20486 updates
2022-03-07 06:32:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:32:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 421 @ 20486 updates, score 15.269) (writing took 2.5261130668222904 seconds)
2022-03-07 06:32:03 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 06:32:03 | INFO | train | epoch 421 | loss 0.474 | nll_loss 0.162 | ppl 1.12 | wps 24984.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 20486 | lr 0.000220939 | gnorm 0.369 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 62998
2022-03-07 06:32:03 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 06:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:32:39 | INFO | train_inner | epoch 422:     14 / 49 loss=0.475, nll_loss=0.162, ppl=1.12, wps=24586.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.369, loss_scale=64, train_wall=225, gb_free=8.8, wall=63034
2022-03-07 06:34:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:34:10 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 15.22 | nll_loss 15.111 | ppl 35385.5 | wps 47105.8 | wpb 510.9 | bsz 1 | num_updates 20535 | best_loss 8.238
2022-03-07 06:34:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20535 updates
2022-03-07 06:34:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:34:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:34:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 422 @ 20535 updates, score 15.22) (writing took 2.505169350653887 seconds)
2022-03-07 06:34:12 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 06:34:12 | INFO | train | epoch 422 | loss 0.475 | nll_loss 0.162 | ppl 1.12 | wps 24466.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20535 | lr 0.000220675 | gnorm 0.372 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63128
2022-03-07 06:34:13 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 06:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:34:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:36:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:36:20 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 15.297 | nll_loss 15.189 | ppl 37342.3 | wps 47096.8 | wpb 510.9 | bsz 1 | num_updates 20583 | best_loss 8.238
2022-03-07 06:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20583 updates
2022-03-07 06:36:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:36:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 423 @ 20583 updates, score 15.297) (writing took 3.142153352499008 seconds)
2022-03-07 06:36:23 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 06:36:23 | INFO | train | epoch 423 | loss 0.473 | nll_loss 0.16 | ppl 1.12 | wps 23855.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20583 | lr 0.000220417 | gnorm 0.367 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63258
2022-03-07 06:36:23 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 06:36:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:37:05 | INFO | train_inner | epoch 424:     17 / 49 loss=0.473, nll_loss=0.16, ppl=1.12, wps=24373.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.369, loss_scale=64, train_wall=227, gb_free=8.8, wall=63300
2022-03-07 06:38:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:38:28 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 15.252 | nll_loss 15.145 | ppl 36235.5 | wps 47071.7 | wpb 510.9 | bsz 1 | num_updates 20632 | best_loss 8.238
2022-03-07 06:38:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20632 updates
2022-03-07 06:38:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:38:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 424 @ 20632 updates, score 15.252) (writing took 2.6226804330945015 seconds)
2022-03-07 06:38:31 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 06:38:31 | INFO | train | epoch 424 | loss 0.474 | nll_loss 0.161 | ppl 1.12 | wps 24893.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20632 | lr 0.000220155 | gnorm 0.372 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 63386
2022-03-07 06:38:31 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 06:38:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:40:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:40:38 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 15.203 | nll_loss 15.093 | ppl 34950 | wps 46874.6 | wpb 510.9 | bsz 1 | num_updates 20680 | best_loss 8.238
2022-03-07 06:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20680 updates
2022-03-07 06:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 425 @ 20680 updates, score 15.203) (writing took 2.4687771555036306 seconds)
2022-03-07 06:40:40 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 06:40:40 | INFO | train | epoch 425 | loss 0.472 | nll_loss 0.16 | ppl 1.12 | wps 24025.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20680 | lr 0.0002199 | gnorm 0.368 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 63515
2022-03-07 06:40:40 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 06:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:41:30 | INFO | train_inner | epoch 426:     20 / 49 loss=0.473, nll_loss=0.16, ppl=1.12, wps=24495.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.368, loss_scale=64, train_wall=226, gb_free=8.8, wall=63565
2022-03-07 06:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:42:48 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 15.155 | nll_loss 15.044 | ppl 33786.3 | wps 46923.1 | wpb 510.9 | bsz 1 | num_updates 20729 | best_loss 8.238
2022-03-07 06:42:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20729 updates
2022-03-07 06:42:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:42:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:42:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 426 @ 20729 updates, score 15.155) (writing took 2.4957560040056705 seconds)
2022-03-07 06:42:50 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 06:42:50 | INFO | train | epoch 426 | loss 0.472 | nll_loss 0.16 | ppl 1.12 | wps 24482.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20729 | lr 0.00021964 | gnorm 0.367 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63645
2022-03-07 06:42:50 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 06:42:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:44:57 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 15.263 | nll_loss 15.155 | ppl 36479.6 | wps 46528.1 | wpb 510.9 | bsz 1 | num_updates 20778 | best_loss 8.238
2022-03-07 06:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20778 updates
2022-03-07 06:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:45:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 427 @ 20778 updates, score 15.263) (writing took 2.5102597773075104 seconds)
2022-03-07 06:45:00 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 06:45:00 | INFO | train | epoch 427 | loss 0.472 | nll_loss 0.159 | ppl 1.12 | wps 24448.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20778 | lr 0.000219381 | gnorm 0.37 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 63775
2022-03-07 06:45:00 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 06:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:45:55 | INFO | train_inner | epoch 428:     22 / 49 loss=0.472, nll_loss=0.159, ppl=1.12, wps=24530.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.37, loss_scale=64, train_wall=226, gb_free=8.8, wall=63830
2022-03-07 06:46:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:05 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 15.251 | nll_loss 15.142 | ppl 36148.3 | wps 47003.1 | wpb 510.9 | bsz 1 | num_updates 20826 | best_loss 8.238
2022-03-07 06:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20826 updates
2022-03-07 06:47:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:47:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:47:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 428 @ 20826 updates, score 15.251) (writing took 2.455266945064068 seconds)
2022-03-07 06:47:07 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 06:47:07 | INFO | train | epoch 428 | loss 0.472 | nll_loss 0.159 | ppl 1.12 | wps 24431.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 20826 | lr 0.000219128 | gnorm 0.37 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 63903
2022-03-07 06:47:07 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 06:47:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:49:15 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 15.243 | nll_loss 15.134 | ppl 35951 | wps 47121.6 | wpb 510.9 | bsz 1 | num_updates 20875 | best_loss 8.238
2022-03-07 06:49:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20875 updates
2022-03-07 06:49:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:49:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 429 @ 20875 updates, score 15.243) (writing took 2.481056872755289 seconds)
2022-03-07 06:49:17 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 06:49:17 | INFO | train | epoch 429 | loss 0.47 | nll_loss 0.158 | ppl 1.12 | wps 24516.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20875 | lr 0.00021887 | gnorm 0.364 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64032
2022-03-07 06:49:17 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 06:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:50:19 | INFO | train_inner | epoch 430:     25 / 49 loss=0.471, nll_loss=0.159, ppl=1.12, wps=24528.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.366, loss_scale=64, train_wall=226, gb_free=8.8, wall=64094
2022-03-07 06:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:51:24 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 15.273 | nll_loss 15.163 | ppl 36677.5 | wps 47114.7 | wpb 510.9 | bsz 1 | num_updates 20924 | best_loss 8.238
2022-03-07 06:51:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20924 updates
2022-03-07 06:51:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 430 @ 20924 updates, score 15.273) (writing took 2.4920538384467363 seconds)
2022-03-07 06:51:27 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 06:51:27 | INFO | train | epoch 430 | loss 0.47 | nll_loss 0.158 | ppl 1.12 | wps 24489.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 20924 | lr 0.000218614 | gnorm 0.364 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64162
2022-03-07 06:51:27 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 06:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:53:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:53:32 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 15.244 | nll_loss 15.135 | ppl 35990.8 | wps 40925.2 | wpb 510.9 | bsz 1 | num_updates 20972 | best_loss 8.238
2022-03-07 06:53:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20972 updates
2022-03-07 06:53:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 431 @ 20972 updates, score 15.244) (writing took 2.652361646294594 seconds)
2022-03-07 06:53:35 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 06:53:35 | INFO | train | epoch 431 | loss 0.471 | nll_loss 0.158 | ppl 1.12 | wps 24273.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 20972 | lr 0.000218364 | gnorm 0.37 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 64290
2022-03-07 06:53:35 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 06:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:46 | INFO | train_inner | epoch 432:     28 / 49 loss=0.47, nll_loss=0.158, ppl=1.12, wps=24299.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.367, loss_scale=64, train_wall=227, gb_free=8.8, wall=64361
2022-03-07 06:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:55:42 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 15.152 | nll_loss 15.042 | ppl 33740 | wps 47197 | wpb 510.9 | bsz 1 | num_updates 21021 | best_loss 8.238
2022-03-07 06:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21021 updates
2022-03-07 06:55:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:55:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 432 @ 21021 updates, score 15.152) (writing took 2.5316447373479605 seconds)
2022-03-07 06:55:44 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 06:55:44 | INFO | train | epoch 432 | loss 0.469 | nll_loss 0.157 | ppl 1.11 | wps 24621.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21021 | lr 0.000218109 | gnorm 0.364 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 64419
2022-03-07 06:55:44 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 06:55:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:57:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 06:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:57:51 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 15.215 | nll_loss 15.106 | ppl 35275.1 | wps 46823.8 | wpb 510.9 | bsz 1 | num_updates 21069 | best_loss 8.238
2022-03-07 06:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21069 updates
2022-03-07 06:57:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 06:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 433 @ 21069 updates, score 15.215) (writing took 2.46823706664145 seconds)
2022-03-07 06:57:54 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 06:57:54 | INFO | train | epoch 433 | loss 0.469 | nll_loss 0.157 | ppl 1.11 | wps 24030.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21069 | lr 0.00021786 | gnorm 0.363 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64549
2022-03-07 06:57:54 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 06:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:59:11 | INFO | train_inner | epoch 434:     31 / 49 loss=0.469, nll_loss=0.157, ppl=1.11, wps=24503.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.362, loss_scale=64, train_wall=226, gb_free=8.8, wall=64626
2022-03-07 06:59:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:00:01 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 15.155 | nll_loss 15.046 | ppl 33833.7 | wps 47092.8 | wpb 510.9 | bsz 1 | num_updates 21118 | best_loss 8.238
2022-03-07 07:00:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21118 updates
2022-03-07 07:00:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 434 @ 21118 updates, score 15.155) (writing took 2.4492831770330667 seconds)
2022-03-07 07:00:03 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 07:00:03 | INFO | train | epoch 434 | loss 0.469 | nll_loss 0.157 | ppl 1.12 | wps 24473 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21118 | lr 0.000217607 | gnorm 0.361 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64679
2022-03-07 07:00:03 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 07:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:02:08 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 15.188 | nll_loss 15.079 | ppl 34612.7 | wps 47144.4 | wpb 510.9 | bsz 1 | num_updates 21167 | best_loss 8.238
2022-03-07 07:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21167 updates
2022-03-07 07:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:02:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 435 @ 21167 updates, score 15.188) (writing took 2.4724090695381165 seconds)
2022-03-07 07:02:11 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 07:02:11 | INFO | train | epoch 435 | loss 0.469 | nll_loss 0.157 | ppl 1.11 | wps 24942.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21167 | lr 0.000217355 | gnorm 0.361 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 64806
2022-03-07 07:02:11 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 07:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:03:37 | INFO | train_inner | epoch 436:     34 / 49 loss=0.468, nll_loss=0.157, ppl=1.11, wps=24329.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.361, loss_scale=64, train_wall=228, gb_free=8.8, wall=64893
2022-03-07 07:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:04:18 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 15.301 | nll_loss 15.194 | ppl 37488.7 | wps 47083.9 | wpb 510.9 | bsz 1 | num_updates 21215 | best_loss 8.238
2022-03-07 07:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21215 updates
2022-03-07 07:04:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:04:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:04:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 436 @ 21215 updates, score 15.301) (writing took 2.4972970988601446 seconds)
2022-03-07 07:04:20 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 07:04:20 | INFO | train | epoch 436 | loss 0.468 | nll_loss 0.156 | ppl 1.11 | wps 24021.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21215 | lr 0.000217109 | gnorm 0.363 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 64936
2022-03-07 07:04:20 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 07:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:06:28 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 15.302 | nll_loss 15.193 | ppl 37469.7 | wps 47169.4 | wpb 510.9 | bsz 1 | num_updates 21264 | best_loss 8.238
2022-03-07 07:06:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21264 updates
2022-03-07 07:06:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:06:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:06:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 437 @ 21264 updates, score 15.302) (writing took 2.4821276143193245 seconds)
2022-03-07 07:06:30 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 07:06:30 | INFO | train | epoch 437 | loss 0.468 | nll_loss 0.156 | ppl 1.11 | wps 24502.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21264 | lr 0.000216859 | gnorm 0.36 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 65065
2022-03-07 07:06:30 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 07:06:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:07:59 | INFO | train_inner | epoch 438:     36 / 49 loss=0.468, nll_loss=0.156, ppl=1.11, wps=24756.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.36, loss_scale=64, train_wall=224, gb_free=8.8, wall=65155
2022-03-07 07:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:08:36 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 15.251 | nll_loss 15.142 | ppl 36167.6 | wps 38504.5 | wpb 510.9 | bsz 1 | num_updates 21313 | best_loss 8.238
2022-03-07 07:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21313 updates
2022-03-07 07:08:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:08:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:08:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 438 @ 21313 updates, score 15.251) (writing took 2.662810690701008 seconds)
2022-03-07 07:08:39 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 07:08:39 | INFO | train | epoch 438 | loss 0.467 | nll_loss 0.155 | ppl 1.11 | wps 24673.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21313 | lr 0.00021661 | gnorm 0.359 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 65194
2022-03-07 07:08:39 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 07:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:08:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:10:45 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 15.264 | nll_loss 15.154 | ppl 36460.8 | wps 47541.7 | wpb 510.9 | bsz 1 | num_updates 21361 | best_loss 8.238
2022-03-07 07:10:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21361 updates
2022-03-07 07:10:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 439 @ 21361 updates, score 15.264) (writing took 2.4723565746098757 seconds)
2022-03-07 07:10:47 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 07:10:47 | INFO | train | epoch 439 | loss 0.467 | nll_loss 0.156 | ppl 1.11 | wps 24257.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21361 | lr 0.000216366 | gnorm 0.362 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 65322
2022-03-07 07:10:47 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 07:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:12:26 | INFO | train_inner | epoch 440:     39 / 49 loss=0.467, nll_loss=0.156, ppl=1.11, wps=24305.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.361, loss_scale=64, train_wall=227, gb_free=8.8, wall=65422
2022-03-07 07:12:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:12:55 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 15.134 | nll_loss 15.025 | ppl 33334.5 | wps 47316.6 | wpb 510.9 | bsz 1 | num_updates 21410 | best_loss 8.238
2022-03-07 07:12:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21410 updates
2022-03-07 07:12:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 440 @ 21410 updates, score 15.134) (writing took 2.4642685502767563 seconds)
2022-03-07 07:12:57 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 07:12:57 | INFO | train | epoch 440 | loss 0.467 | nll_loss 0.156 | ppl 1.11 | wps 24496.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21410 | lr 0.000216118 | gnorm 0.362 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 65452
2022-03-07 07:12:57 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 07:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:14:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:15:05 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 15.219 | nll_loss 15.111 | ppl 35392.9 | wps 46921 | wpb 510.9 | bsz 1 | num_updates 21458 | best_loss 8.238
2022-03-07 07:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21458 updates
2022-03-07 07:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 441 @ 21458 updates, score 15.219) (writing took 2.461910782381892 seconds)
2022-03-07 07:15:07 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 07:15:07 | INFO | train | epoch 441 | loss 0.466 | nll_loss 0.154 | ppl 1.11 | wps 23943.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21458 | lr 0.000215877 | gnorm 0.361 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 65582
2022-03-07 07:15:07 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 07:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:16:51 | INFO | train_inner | epoch 442:     42 / 49 loss=0.466, nll_loss=0.155, ppl=1.11, wps=24476.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.361, loss_scale=64, train_wall=226, gb_free=8.8, wall=65687
2022-03-07 07:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:12 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 15.245 | nll_loss 15.137 | ppl 36043.4 | wps 46143.2 | wpb 510.9 | bsz 1 | num_updates 21507 | best_loss 8.238
2022-03-07 07:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21507 updates
2022-03-07 07:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:17:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 442 @ 21507 updates, score 15.245) (writing took 2.478213094174862 seconds)
2022-03-07 07:17:15 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 07:17:15 | INFO | train | epoch 442 | loss 0.466 | nll_loss 0.155 | ppl 1.11 | wps 24866.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21507 | lr 0.00021563 | gnorm 0.361 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 65710
2022-03-07 07:17:15 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 07:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:19:23 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 15.16 | nll_loss 15.051 | ppl 33951.7 | wps 46746.6 | wpb 510.9 | bsz 1 | num_updates 21556 | best_loss 8.238
2022-03-07 07:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21556 updates
2022-03-07 07:19:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:19:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:19:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 443 @ 21556 updates, score 15.16) (writing took 2.448667736724019 seconds)
2022-03-07 07:19:25 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 07:19:25 | INFO | train | epoch 443 | loss 0.465 | nll_loss 0.154 | ppl 1.11 | wps 24374.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21556 | lr 0.000215385 | gnorm 0.358 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 65840
2022-03-07 07:19:25 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 07:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:20:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:21:20 | INFO | train_inner | epoch 444:     45 / 49 loss=0.465, nll_loss=0.154, ppl=1.11, wps=24174.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.36, loss_scale=64, train_wall=229, gb_free=8.8, wall=65955
2022-03-07 07:21:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:21:33 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 15.382 | nll_loss 15.275 | ppl 39641.4 | wps 45998.7 | wpb 510.9 | bsz 1 | num_updates 21604 | best_loss 8.238
2022-03-07 07:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21604 updates
2022-03-07 07:21:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 444 @ 21604 updates, score 15.382) (writing took 2.4714726246893406 seconds)
2022-03-07 07:21:36 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 07:21:36 | INFO | train | epoch 444 | loss 0.465 | nll_loss 0.154 | ppl 1.11 | wps 23838.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21604 | lr 0.000215146 | gnorm 0.362 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 65971
2022-03-07 07:21:36 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 07:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:23:41 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 15.283 | nll_loss 15.176 | ppl 37009.1 | wps 46893.4 | wpb 510.9 | bsz 1 | num_updates 21653 | best_loss 8.238
2022-03-07 07:23:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21653 updates
2022-03-07 07:23:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:23:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:23:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 445 @ 21653 updates, score 15.283) (writing took 2.4678207878023386 seconds)
2022-03-07 07:23:44 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 07:23:44 | INFO | train | epoch 445 | loss 0.464 | nll_loss 0.153 | ppl 1.11 | wps 24854.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21653 | lr 0.000214902 | gnorm 0.358 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 66099
2022-03-07 07:23:44 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 07:23:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:25:43 | INFO | train_inner | epoch 446:     47 / 49 loss=0.465, nll_loss=0.154, ppl=1.11, wps=24645.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.359, loss_scale=64, train_wall=224, gb_free=8.8, wall=66218
2022-03-07 07:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:25:51 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 15.262 | nll_loss 15.155 | ppl 36478.9 | wps 47271 | wpb 510.9 | bsz 1 | num_updates 21702 | best_loss 8.238
2022-03-07 07:25:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21702 updates
2022-03-07 07:25:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 446 @ 21702 updates, score 15.262) (writing took 2.444174487143755 seconds)
2022-03-07 07:25:54 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 07:25:54 | INFO | train | epoch 446 | loss 0.465 | nll_loss 0.154 | ppl 1.11 | wps 24410.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21702 | lr 0.00021466 | gnorm 0.359 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66229
2022-03-07 07:25:54 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 07:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:25:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:28:02 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 15.185 | nll_loss 15.078 | ppl 34584.8 | wps 47320.2 | wpb 510.9 | bsz 1 | num_updates 21750 | best_loss 8.238
2022-03-07 07:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21750 updates
2022-03-07 07:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:28:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 447 @ 21750 updates, score 15.185) (writing took 2.4505904465913773 seconds)
2022-03-07 07:28:04 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 07:28:04 | INFO | train | epoch 447 | loss 0.464 | nll_loss 0.153 | ppl 1.11 | wps 23909 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 21750 | lr 0.000214423 | gnorm 0.355 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66359
2022-03-07 07:28:04 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 07:28:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:30:12 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 15.181 | nll_loss 15.072 | ppl 34450.2 | wps 39546.5 | wpb 510.9 | bsz 1 | num_updates 21799 | best_loss 8.238
2022-03-07 07:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21799 updates
2022-03-07 07:30:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:30:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:30:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 448 @ 21799 updates, score 15.181) (writing took 2.4929225090891123 seconds)
2022-03-07 07:30:15 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 07:30:15 | INFO | train | epoch 448 | loss 0.463 | nll_loss 0.152 | ppl 1.11 | wps 24313.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21799 | lr 0.000214181 | gnorm 0.356 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66490
2022-03-07 07:30:15 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 07:30:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:30:17 | INFO | train_inner | epoch 449:      1 / 49 loss=0.463, nll_loss=0.153, ppl=1.11, wps=23528.7, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.357, loss_scale=64, train_wall=227, gb_free=8.8, wall=66492
2022-03-07 07:31:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:32:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:32:20 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 15.229 | nll_loss 15.12 | ppl 35616.3 | wps 46663.2 | wpb 510.9 | bsz 1 | num_updates 21847 | best_loss 8.238
2022-03-07 07:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21847 updates
2022-03-07 07:32:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:32:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:32:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 449 @ 21847 updates, score 15.229) (writing took 2.4562162328511477 seconds)
2022-03-07 07:32:22 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 07:32:22 | INFO | train | epoch 449 | loss 0.462 | nll_loss 0.152 | ppl 1.11 | wps 24358.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 21847 | lr 0.000213946 | gnorm 0.356 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 66618
2022-03-07 07:32:23 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 07:32:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:34:31 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 15.158 | nll_loss 15.049 | ppl 33906.6 | wps 46599.6 | wpb 510.9 | bsz 1 | num_updates 21896 | best_loss 8.238
2022-03-07 07:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21896 updates
2022-03-07 07:34:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 450 @ 21896 updates, score 15.158) (writing took 2.4504174701869488 seconds)
2022-03-07 07:34:33 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 07:34:33 | INFO | train | epoch 450 | loss 0.463 | nll_loss 0.152 | ppl 1.11 | wps 24335.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21896 | lr 0.000213706 | gnorm 0.356 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66748
2022-03-07 07:34:33 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 07:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:34:43 | INFO | train_inner | epoch 451:      4 / 49 loss=0.463, nll_loss=0.152, ppl=1.11, wps=24403.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.356, loss_scale=64, train_wall=227, gb_free=8.8, wall=66758
2022-03-07 07:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:36:41 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 15.127 | nll_loss 15.018 | ppl 33178.3 | wps 46840.2 | wpb 510.9 | bsz 1 | num_updates 21945 | best_loss 8.238
2022-03-07 07:36:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21945 updates
2022-03-07 07:36:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:36:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:36:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 451 @ 21945 updates, score 15.127) (writing took 2.506999723613262 seconds)
2022-03-07 07:36:43 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 07:36:43 | INFO | train | epoch 451 | loss 0.462 | nll_loss 0.152 | ppl 1.11 | wps 24378.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 21945 | lr 0.000213468 | gnorm 0.354 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 66879
2022-03-07 07:36:43 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 07:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:37:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:38:49 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 15.216 | nll_loss 15.108 | ppl 35309.6 | wps 46731.5 | wpb 510.9 | bsz 1 | num_updates 21993 | best_loss 8.238
2022-03-07 07:38:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21993 updates
2022-03-07 07:38:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:38:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 452 @ 21993 updates, score 15.216) (writing took 2.472078612074256 seconds)
2022-03-07 07:38:51 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 07:38:51 | INFO | train | epoch 452 | loss 0.461 | nll_loss 0.151 | ppl 1.11 | wps 24313.8 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 21993 | lr 0.000213235 | gnorm 0.351 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 67007
2022-03-07 07:38:51 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 07:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:39:10 | INFO | train_inner | epoch 453:      7 / 49 loss=0.462, nll_loss=0.151, ppl=1.11, wps=24331.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.352, loss_scale=64, train_wall=228, gb_free=8.8, wall=67025
2022-03-07 07:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:41:00 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 15.232 | nll_loss 15.124 | ppl 35699.3 | wps 46833.3 | wpb 510.9 | bsz 1 | num_updates 22042 | best_loss 8.238
2022-03-07 07:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22042 updates
2022-03-07 07:41:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:41:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:41:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 453 @ 22042 updates, score 15.232) (writing took 2.455105535686016 seconds)
2022-03-07 07:41:02 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 07:41:02 | INFO | train | epoch 453 | loss 0.462 | nll_loss 0.151 | ppl 1.11 | wps 24344.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22042 | lr 0.000212997 | gnorm 0.351 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67137
2022-03-07 07:41:02 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 07:41:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:43:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:43:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:43:10 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 15.223 | nll_loss 15.116 | ppl 35504.9 | wps 47031.6 | wpb 510.9 | bsz 1 | num_updates 22090 | best_loss 8.238
2022-03-07 07:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22090 updates
2022-03-07 07:43:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:43:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:43:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 454 @ 22090 updates, score 15.223) (writing took 2.517072230577469 seconds)
2022-03-07 07:43:13 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 07:43:13 | INFO | train | epoch 454 | loss 0.462 | nll_loss 0.152 | ppl 1.11 | wps 23851.6 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 22090 | lr 0.000212766 | gnorm 0.355 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67268
2022-03-07 07:43:13 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 07:43:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:43:38 | INFO | train_inner | epoch 455:     10 / 49 loss=0.462, nll_loss=0.151, ppl=1.11, wps=24226, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.354, loss_scale=64, train_wall=229, gb_free=8.8, wall=67293
2022-03-07 07:45:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:19 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 15.312 | nll_loss 15.206 | ppl 37790.7 | wps 38557.8 | wpb 510.9 | bsz 1 | num_updates 22139 | best_loss 8.238
2022-03-07 07:45:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22139 updates
2022-03-07 07:45:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:45:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 455 @ 22139 updates, score 15.312) (writing took 2.605019275099039 seconds)
2022-03-07 07:45:22 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 07:45:22 | INFO | train | epoch 455 | loss 0.462 | nll_loss 0.152 | ppl 1.11 | wps 24534.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22139 | lr 0.00021253 | gnorm 0.355 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 67397
2022-03-07 07:45:22 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 07:45:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:47:29 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 15.264 | nll_loss 15.158 | ppl 36553.3 | wps 46769.2 | wpb 510.9 | bsz 1 | num_updates 22188 | best_loss 8.238
2022-03-07 07:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22188 updates
2022-03-07 07:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 456 @ 22188 updates, score 15.264) (writing took 2.478998478502035 seconds)
2022-03-07 07:47:31 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 07:47:31 | INFO | train | epoch 456 | loss 0.461 | nll_loss 0.15 | ppl 1.11 | wps 24605.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22188 | lr 0.000212296 | gnorm 0.352 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 67526
2022-03-07 07:47:31 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 07:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:48:01 | INFO | train_inner | epoch 457:     12 / 49 loss=0.461, nll_loss=0.151, ppl=1.11, wps=24592.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.352, loss_scale=64, train_wall=224, gb_free=8.8, wall=67557
2022-03-07 07:48:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:49:39 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 15.369 | nll_loss 15.265 | ppl 39376.1 | wps 46862 | wpb 510.9 | bsz 1 | num_updates 22236 | best_loss 8.238
2022-03-07 07:49:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22236 updates
2022-03-07 07:49:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:49:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 457 @ 22236 updates, score 15.369) (writing took 2.4810159113258123 seconds)
2022-03-07 07:49:42 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 07:49:42 | INFO | train | epoch 457 | loss 0.461 | nll_loss 0.15 | ppl 1.11 | wps 23854.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22236 | lr 0.000212066 | gnorm 0.356 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67657
2022-03-07 07:49:42 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 07:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:51:50 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 15.231 | nll_loss 15.124 | ppl 35716 | wps 46517.4 | wpb 510.9 | bsz 1 | num_updates 22285 | best_loss 8.238
2022-03-07 07:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22285 updates
2022-03-07 07:51:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:51:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:51:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 458 @ 22285 updates, score 15.231) (writing took 2.5188602451235056 seconds)
2022-03-07 07:51:52 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 07:51:52 | INFO | train | epoch 458 | loss 0.459 | nll_loss 0.149 | ppl 1.11 | wps 24327.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22285 | lr 0.000211833 | gnorm 0.349 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 67788
2022-03-07 07:51:52 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 07:51:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:52:30 | INFO | train_inner | epoch 459:     15 / 49 loss=0.46, nll_loss=0.15, ppl=1.11, wps=24164.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.353, loss_scale=64, train_wall=229, gb_free=8.8, wall=67825
2022-03-07 07:53:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:53:58 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 15.279 | nll_loss 15.17 | ppl 36872.5 | wps 46879.1 | wpb 510.9 | bsz 1 | num_updates 22334 | best_loss 8.238
2022-03-07 07:53:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22334 updates
2022-03-07 07:53:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:54:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:54:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 459 @ 22334 updates, score 15.279) (writing took 2.445738710463047 seconds)
2022-03-07 07:54:00 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 07:54:00 | INFO | train | epoch 459 | loss 0.46 | nll_loss 0.15 | ppl 1.11 | wps 24817.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22334 | lr 0.000211601 | gnorm 0.353 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 67916
2022-03-07 07:54:00 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 07:54:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 07:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:56:08 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 15.176 | nll_loss 15.068 | ppl 34341.9 | wps 46861.9 | wpb 510.9 | bsz 1 | num_updates 22382 | best_loss 8.238
2022-03-07 07:56:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22382 updates
2022-03-07 07:56:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:56:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:56:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 460 @ 22382 updates, score 15.176) (writing took 2.484877245500684 seconds)
2022-03-07 07:56:11 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 07:56:11 | INFO | train | epoch 460 | loss 0.459 | nll_loss 0.149 | ppl 1.11 | wps 23839.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22382 | lr 0.000211374 | gnorm 0.355 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68046
2022-03-07 07:56:11 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 07:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:56:56 | INFO | train_inner | epoch 461:     18 / 49 loss=0.459, nll_loss=0.15, ppl=1.11, wps=24374.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.355, loss_scale=64, train_wall=227, gb_free=8.8, wall=68091
2022-03-07 07:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:19 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 15.27 | nll_loss 15.164 | ppl 36714.1 | wps 47110.8 | wpb 510.9 | bsz 1 | num_updates 22431 | best_loss 8.238
2022-03-07 07:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22431 updates
2022-03-07 07:58:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:58:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 07:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 461 @ 22431 updates, score 15.27) (writing took 2.5102739557623863 seconds)
2022-03-07 07:58:21 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 07:58:21 | INFO | train | epoch 461 | loss 0.459 | nll_loss 0.149 | ppl 1.11 | wps 24361.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22431 | lr 0.000211143 | gnorm 0.352 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68177
2022-03-07 07:58:21 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 07:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:00:27 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 15.191 | nll_loss 15.083 | ppl 34716.8 | wps 46499.4 | wpb 510.9 | bsz 1 | num_updates 22479 | best_loss 8.238
2022-03-07 08:00:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22479 updates
2022-03-07 08:00:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:00:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:00:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 462 @ 22479 updates, score 15.191) (writing took 2.5480102598667145 seconds)
2022-03-07 08:00:29 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 08:00:29 | INFO | train | epoch 462 | loss 0.459 | nll_loss 0.149 | ppl 1.11 | wps 24303.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22479 | lr 0.000210917 | gnorm 0.354 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 68305
2022-03-07 08:00:30 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 08:00:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:01:24 | INFO | train_inner | epoch 463:     21 / 49 loss=0.459, nll_loss=0.149, ppl=1.11, wps=24186.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.352, loss_scale=64, train_wall=229, gb_free=8.8, wall=68359
2022-03-07 08:02:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:02:38 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 15.212 | nll_loss 15.104 | ppl 35226.5 | wps 46542.5 | wpb 510.9 | bsz 1 | num_updates 22528 | best_loss 8.238
2022-03-07 08:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22528 updates
2022-03-07 08:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 463 @ 22528 updates, score 15.212) (writing took 2.4974058475345373 seconds)
2022-03-07 08:02:40 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 08:02:40 | INFO | train | epoch 463 | loss 0.458 | nll_loss 0.149 | ppl 1.11 | wps 24346.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22528 | lr 0.000210687 | gnorm 0.35 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68435
2022-03-07 08:02:40 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 08:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:04:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:04:48 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 15.233 | nll_loss 15.126 | ppl 35748.2 | wps 46940.3 | wpb 510.9 | bsz 1 | num_updates 22576 | best_loss 8.238
2022-03-07 08:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22576 updates
2022-03-07 08:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:04:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 464 @ 22576 updates, score 15.233) (writing took 2.4763166308403015 seconds)
2022-03-07 08:04:50 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 08:04:50 | INFO | train | epoch 464 | loss 0.457 | nll_loss 0.147 | ppl 1.11 | wps 23920 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22576 | lr 0.000210463 | gnorm 0.349 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68565
2022-03-07 08:04:50 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 08:04:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:05:50 | INFO | train_inner | epoch 465:     24 / 49 loss=0.458, nll_loss=0.148, ppl=1.11, wps=24404.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.35, loss_scale=32, train_wall=227, gb_free=8.8, wall=68625
2022-03-07 08:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:06:58 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 15.184 | nll_loss 15.077 | ppl 34570.1 | wps 39985.8 | wpb 510.9 | bsz 1 | num_updates 22625 | best_loss 8.238
2022-03-07 08:06:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22625 updates
2022-03-07 08:06:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 465 @ 22625 updates, score 15.184) (writing took 2.499195698648691 seconds)
2022-03-07 08:07:01 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 08:07:01 | INFO | train | epoch 465 | loss 0.458 | nll_loss 0.148 | ppl 1.11 | wps 24340.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22625 | lr 0.000210235 | gnorm 0.349 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 68696
2022-03-07 08:07:01 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 08:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:09:06 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 15.265 | nll_loss 15.16 | ppl 36600.9 | wps 46907.2 | wpb 510.9 | bsz 1 | num_updates 22674 | best_loss 8.238
2022-03-07 08:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22674 updates
2022-03-07 08:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 466 @ 22674 updates, score 15.265) (writing took 2.477563874796033 seconds)
2022-03-07 08:09:09 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 08:09:09 | INFO | train | epoch 466 | loss 0.458 | nll_loss 0.148 | ppl 1.11 | wps 24843.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22674 | lr 0.000210008 | gnorm 0.349 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 68824
2022-03-07 08:09:09 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 08:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:10:16 | INFO | train_inner | epoch 467:     26 / 49 loss=0.458, nll_loss=0.148, ppl=1.11, wps=24404, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.349, loss_scale=64, train_wall=226, gb_free=8.8, wall=68891
2022-03-07 08:11:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:11:17 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 15.169 | nll_loss 15.062 | ppl 34206 | wps 46847 | wpb 510.9 | bsz 1 | num_updates 22723 | best_loss 8.238
2022-03-07 08:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22723 updates
2022-03-07 08:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:11:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 467 @ 22723 updates, score 15.169) (writing took 2.454582255333662 seconds)
2022-03-07 08:11:19 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 08:11:19 | INFO | train | epoch 467 | loss 0.457 | nll_loss 0.147 | ppl 1.11 | wps 24380.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22723 | lr 0.000209781 | gnorm 0.349 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 68954
2022-03-07 08:11:19 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 08:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:13:27 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 15.208 | nll_loss 15.101 | ppl 35155.4 | wps 47074.7 | wpb 510.9 | bsz 1 | num_updates 22772 | best_loss 8.238
2022-03-07 08:13:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22772 updates
2022-03-07 08:13:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:13:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 468 @ 22772 updates, score 15.208) (writing took 2.5048583541065454 seconds)
2022-03-07 08:13:29 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 08:13:29 | INFO | train | epoch 468 | loss 0.457 | nll_loss 0.147 | ppl 1.11 | wps 24358.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22772 | lr 0.000209556 | gnorm 0.348 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69085
2022-03-07 08:13:29 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 08:13:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:14:39 | INFO | train_inner | epoch 469:     28 / 49 loss=0.457, nll_loss=0.147, ppl=1.11, wps=24622.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.348, loss_scale=64, train_wall=225, gb_free=8.8, wall=69154
2022-03-07 08:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:15:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:15:35 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 15.1 | nll_loss 14.993 | ppl 32611.1 | wps 46141.9 | wpb 510.9 | bsz 1 | num_updates 22820 | best_loss 8.238
2022-03-07 08:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22820 updates
2022-03-07 08:15:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:15:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 469 @ 22820 updates, score 15.1) (writing took 2.49837077409029 seconds)
2022-03-07 08:15:38 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 08:15:38 | INFO | train | epoch 469 | loss 0.456 | nll_loss 0.147 | ppl 1.11 | wps 24293.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22820 | lr 0.000209335 | gnorm 0.348 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 69213
2022-03-07 08:15:38 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 08:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:17:46 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 15.292 | nll_loss 15.185 | ppl 37255.1 | wps 46784.4 | wpb 510.9 | bsz 1 | num_updates 22869 | best_loss 8.238
2022-03-07 08:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22869 updates
2022-03-07 08:17:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:17:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:17:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 470 @ 22869 updates, score 15.292) (writing took 2.5103173423558474 seconds)
2022-03-07 08:17:48 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 08:17:48 | INFO | train | epoch 470 | loss 0.456 | nll_loss 0.146 | ppl 1.11 | wps 24363.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22869 | lr 0.000209111 | gnorm 0.346 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69343
2022-03-07 08:17:48 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 08:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:19:07 | INFO | train_inner | epoch 471:     31 / 49 loss=0.456, nll_loss=0.146, ppl=1.11, wps=24246.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.346, loss_scale=64, train_wall=228, gb_free=8.8, wall=69422
2022-03-07 08:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:19:56 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 15.179 | nll_loss 15.072 | ppl 34447.2 | wps 46247.5 | wpb 510.9 | bsz 1 | num_updates 22918 | best_loss 8.238
2022-03-07 08:19:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22918 updates
2022-03-07 08:19:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 471 @ 22918 updates, score 15.179) (writing took 2.4648067746311426 seconds)
2022-03-07 08:19:58 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 08:19:58 | INFO | train | epoch 471 | loss 0.455 | nll_loss 0.146 | ppl 1.11 | wps 24398.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 22918 | lr 0.000208887 | gnorm 0.346 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69473
2022-03-07 08:19:58 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 08:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:20:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:22:05 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 15.286 | nll_loss 15.18 | ppl 37133.2 | wps 38790.4 | wpb 510.9 | bsz 1 | num_updates 22966 | best_loss 8.238
2022-03-07 08:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22966 updates
2022-03-07 08:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 472 @ 22966 updates, score 15.286) (writing took 2.6825206205248833 seconds)
2022-03-07 08:22:08 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 08:22:08 | INFO | train | epoch 472 | loss 0.456 | nll_loss 0.146 | ppl 1.11 | wps 24009.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 22966 | lr 0.000208669 | gnorm 0.346 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 69603
2022-03-07 08:22:08 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 08:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:23:34 | INFO | train_inner | epoch 473:     34 / 49 loss=0.455, nll_loss=0.146, ppl=1.11, wps=24315.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.345, loss_scale=32, train_wall=227, gb_free=8.8, wall=69689
2022-03-07 08:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:24:14 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 15.214 | nll_loss 15.109 | ppl 35332.3 | wps 47428.7 | wpb 510.9 | bsz 1 | num_updates 23015 | best_loss 8.238
2022-03-07 08:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23015 updates
2022-03-07 08:24:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:24:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 473 @ 23015 updates, score 15.214) (writing took 2.470552684739232 seconds)
2022-03-07 08:24:17 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 08:24:17 | INFO | train | epoch 473 | loss 0.454 | nll_loss 0.145 | ppl 1.11 | wps 24655.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23015 | lr 0.000208446 | gnorm 0.344 | loss_scale 32 | train_wall 110 | gb_free 8.8 | wall 69732
2022-03-07 08:24:17 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 08:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:26:24 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 15.053 | nll_loss 14.945 | ppl 31537.4 | wps 46958 | wpb 510.9 | bsz 1 | num_updates 23064 | best_loss 8.238
2022-03-07 08:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23064 updates
2022-03-07 08:26:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:26:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 474 @ 23064 updates, score 15.053) (writing took 2.4543333295732737 seconds)
2022-03-07 08:26:27 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 08:26:27 | INFO | train | epoch 474 | loss 0.454 | nll_loss 0.145 | ppl 1.11 | wps 24453.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23064 | lr 0.000208225 | gnorm 0.346 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69862
2022-03-07 08:26:27 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 08:26:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:27:57 | INFO | train_inner | epoch 475:     36 / 49 loss=0.454, nll_loss=0.145, ppl=1.11, wps=24674.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.346, loss_scale=64, train_wall=224, gb_free=8.8, wall=69952
2022-03-07 08:28:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:28:35 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 15.23 | nll_loss 15.125 | ppl 35736.1 | wps 46211.5 | wpb 510.9 | bsz 1 | num_updates 23113 | best_loss 8.238
2022-03-07 08:28:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23113 updates
2022-03-07 08:28:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:28:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 475 @ 23113 updates, score 15.23) (writing took 2.4690526593476534 seconds)
2022-03-07 08:28:37 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 08:28:37 | INFO | train | epoch 475 | loss 0.455 | nll_loss 0.146 | ppl 1.11 | wps 24387.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23113 | lr 0.000208004 | gnorm 0.348 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 69992
2022-03-07 08:28:37 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 08:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:30:43 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 15.242 | nll_loss 15.137 | ppl 36027.9 | wps 46569.3 | wpb 510.9 | bsz 1 | num_updates 23162 | best_loss 8.238
2022-03-07 08:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23162 updates
2022-03-07 08:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 476 @ 23162 updates, score 15.242) (writing took 2.4784797579050064 seconds)
2022-03-07 08:30:45 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 08:30:45 | INFO | train | epoch 476 | loss 0.454 | nll_loss 0.145 | ppl 1.11 | wps 24790.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23162 | lr 0.000207784 | gnorm 0.346 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 70120
2022-03-07 08:30:45 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 08:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:31:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:32:25 | INFO | train_inner | epoch 477:     39 / 49 loss=0.453, nll_loss=0.144, ppl=1.11, wps=24201.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.344, loss_scale=64, train_wall=229, gb_free=8.8, wall=70220
2022-03-07 08:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:32:53 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 15.113 | nll_loss 15.007 | ppl 32917.3 | wps 46358.3 | wpb 510.9 | bsz 1 | num_updates 23210 | best_loss 8.238
2022-03-07 08:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23210 updates
2022-03-07 08:32:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:32:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 477 @ 23210 updates, score 15.113) (writing took 2.4926329404115677 seconds)
2022-03-07 08:32:56 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 08:32:56 | INFO | train | epoch 477 | loss 0.452 | nll_loss 0.143 | ppl 1.1 | wps 23903.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23210 | lr 0.000207569 | gnorm 0.34 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70251
2022-03-07 08:32:56 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 08:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:35:03 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 15.205 | nll_loss 15.1 | ppl 35111.6 | wps 47036.9 | wpb 510.9 | bsz 1 | num_updates 23259 | best_loss 8.238
2022-03-07 08:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23259 updates
2022-03-07 08:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 478 @ 23259 updates, score 15.205) (writing took 2.4440848268568516 seconds)
2022-03-07 08:35:06 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 08:35:06 | INFO | train | epoch 478 | loss 0.454 | nll_loss 0.145 | ppl 1.11 | wps 24412.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23259 | lr 0.00020735 | gnorm 0.346 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70381
2022-03-07 08:35:06 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 08:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:36:48 | INFO | train_inner | epoch 479:     41 / 49 loss=0.453, nll_loss=0.145, ppl=1.11, wps=24624.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.346, loss_scale=64, train_wall=225, gb_free=8.8, wall=70483
2022-03-07 08:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:11 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 15.186 | nll_loss 15.08 | ppl 34643.2 | wps 46981.6 | wpb 510.9 | bsz 1 | num_updates 23308 | best_loss 8.238
2022-03-07 08:37:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23308 updates
2022-03-07 08:37:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:37:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 479 @ 23308 updates, score 15.186) (writing took 2.4613875951617956 seconds)
2022-03-07 08:37:14 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 08:37:14 | INFO | train | epoch 479 | loss 0.453 | nll_loss 0.144 | ppl 1.11 | wps 24788.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23308 | lr 0.000207132 | gnorm 0.347 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 70509
2022-03-07 08:37:14 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 08:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:37:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:39:22 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 15.179 | nll_loss 15.071 | ppl 34430 | wps 46213.9 | wpb 510.9 | bsz 1 | num_updates 23356 | best_loss 8.238
2022-03-07 08:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23356 updates
2022-03-07 08:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 480 @ 23356 updates, score 15.179) (writing took 2.493775926530361 seconds)
2022-03-07 08:39:24 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 08:39:24 | INFO | train | epoch 480 | loss 0.453 | nll_loss 0.144 | ppl 1.11 | wps 23905.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23356 | lr 0.000206919 | gnorm 0.345 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70639
2022-03-07 08:39:24 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 08:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:16 | INFO | train_inner | epoch 481:     44 / 49 loss=0.452, nll_loss=0.144, ppl=1.1, wps=24200.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.343, loss_scale=64, train_wall=229, gb_free=8.8, wall=70751
2022-03-07 08:41:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:41:32 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 15.263 | nll_loss 15.157 | ppl 36536.6 | wps 46728.7 | wpb 510.9 | bsz 1 | num_updates 23405 | best_loss 8.238
2022-03-07 08:41:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23405 updates
2022-03-07 08:41:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:41:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 481 @ 23405 updates, score 15.263) (writing took 2.458393931388855 seconds)
2022-03-07 08:41:35 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 08:41:35 | INFO | train | epoch 481 | loss 0.452 | nll_loss 0.143 | ppl 1.1 | wps 24367.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23405 | lr 0.000206702 | gnorm 0.341 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 70770
2022-03-07 08:41:35 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 08:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:43:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:43:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:43:42 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 15.263 | nll_loss 15.159 | ppl 36574 | wps 38346.7 | wpb 510.9 | bsz 1 | num_updates 23453 | best_loss 8.238
2022-03-07 08:43:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23453 updates
2022-03-07 08:43:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 482 @ 23453 updates, score 15.263) (writing took 2.6826599035412073 seconds)
2022-03-07 08:43:45 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 08:43:45 | INFO | train | epoch 482 | loss 0.452 | nll_loss 0.143 | ppl 1.1 | wps 23870 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23453 | lr 0.000206491 | gnorm 0.344 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 70900
2022-03-07 08:43:45 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 08:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:45:42 | INFO | train_inner | epoch 483:     47 / 49 loss=0.452, nll_loss=0.143, ppl=1.1, wps=24407.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.342, loss_scale=64, train_wall=226, gb_free=8.8, wall=71017
2022-03-07 08:45:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:45:50 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 15.254 | nll_loss 15.149 | ppl 36333.3 | wps 46719.1 | wpb 510.9 | bsz 1 | num_updates 23502 | best_loss 8.238
2022-03-07 08:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23502 updates
2022-03-07 08:45:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:45:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:45:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 483 @ 23502 updates, score 15.254) (writing took 2.566691489890218 seconds)
2022-03-07 08:45:53 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 08:45:53 | INFO | train | epoch 483 | loss 0.451 | nll_loss 0.143 | ppl 1.1 | wps 24826.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23502 | lr 0.000206275 | gnorm 0.339 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 71028
2022-03-07 08:45:53 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 08:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:47:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:48:01 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 15.252 | nll_loss 15.147 | ppl 36271.9 | wps 46827.1 | wpb 510.9 | bsz 1 | num_updates 23551 | best_loss 8.238
2022-03-07 08:48:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23551 updates
2022-03-07 08:48:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:48:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:48:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 484 @ 23551 updates, score 15.252) (writing took 2.503790320828557 seconds)
2022-03-07 08:48:03 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 08:48:03 | INFO | train | epoch 484 | loss 0.451 | nll_loss 0.143 | ppl 1.1 | wps 24386.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23551 | lr 0.000206061 | gnorm 0.339 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 71158
2022-03-07 08:48:03 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 08:48:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:50:11 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 15.223 | nll_loss 15.116 | ppl 35523.4 | wps 46962.3 | wpb 510.9 | bsz 1 | num_updates 23599 | best_loss 8.238
2022-03-07 08:50:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23599 updates
2022-03-07 08:50:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:50:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 485 @ 23599 updates, score 15.223) (writing took 2.5775797944515944 seconds)
2022-03-07 08:50:14 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 08:50:14 | INFO | train | epoch 485 | loss 0.451 | nll_loss 0.143 | ppl 1.1 | wps 23876.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23599 | lr 0.000205851 | gnorm 0.342 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 71289
2022-03-07 08:50:14 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 08:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:50:16 | INFO | train_inner | epoch 486:      1 / 49 loss=0.451, nll_loss=0.143, ppl=1.1, wps=23527.5, ups=0.36, wpb=64539.7, bsz=126.1, num_updates=23600, lr=0.000205847, gnorm=0.341, loss_scale=64, train_wall=228, gb_free=8.8, wall=71291
2022-03-07 08:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:19 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 15.241 | nll_loss 15.136 | ppl 35998.3 | wps 47171.3 | wpb 510.9 | bsz 1 | num_updates 23648 | best_loss 8.238
2022-03-07 08:52:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23648 updates
2022-03-07 08:52:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:52:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 486 @ 23648 updates, score 15.241) (writing took 2.490064237266779 seconds)
2022-03-07 08:52:21 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 08:52:22 | INFO | train | epoch 486 | loss 0.451 | nll_loss 0.143 | ppl 1.1 | wps 24849.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23648 | lr 0.000205638 | gnorm 0.341 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 71417
2022-03-07 08:52:22 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 08:52:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:54:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:54:29 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 15.291 | nll_loss 15.186 | ppl 37264.5 | wps 46793 | wpb 510.9 | bsz 1 | num_updates 23697 | best_loss 8.238
2022-03-07 08:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23697 updates
2022-03-07 08:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:54:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:54:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 487 @ 23697 updates, score 15.291) (writing took 2.4917083773761988 seconds)
2022-03-07 08:54:32 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 08:54:32 | INFO | train | epoch 487 | loss 0.45 | nll_loss 0.142 | ppl 1.1 | wps 24359.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23697 | lr 0.000205425 | gnorm 0.34 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 71547
2022-03-07 08:54:32 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 08:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:54:40 | INFO | train_inner | epoch 488:      3 / 49 loss=0.45, nll_loss=0.142, ppl=1.1, wps=24634.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.341, loss_scale=64, train_wall=225, gb_free=8.8, wall=71555
2022-03-07 08:54:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 08:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:40 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 15.368 | nll_loss 15.264 | ppl 39347.7 | wps 46527.4 | wpb 510.9 | bsz 1 | num_updates 23745 | best_loss 8.238
2022-03-07 08:56:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23745 updates
2022-03-07 08:56:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 488 @ 23745 updates, score 15.368) (writing took 2.559252928942442 seconds)
2022-03-07 08:56:42 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 08:56:42 | INFO | train | epoch 488 | loss 0.45 | nll_loss 0.142 | ppl 1.1 | wps 23865.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23745 | lr 0.000205217 | gnorm 0.34 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 71678
2022-03-07 08:56:42 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 08:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:58:49 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 15.187 | nll_loss 15.08 | ppl 34633.7 | wps 41296.1 | wpb 510.9 | bsz 1 | num_updates 23794 | best_loss 8.238
2022-03-07 08:58:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23794 updates
2022-03-07 08:58:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 08:58:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 489 @ 23794 updates, score 15.187) (writing took 2.642713824287057 seconds)
2022-03-07 08:58:51 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 08:58:51 | INFO | train | epoch 489 | loss 0.45 | nll_loss 0.142 | ppl 1.1 | wps 24668.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23794 | lr 0.000205006 | gnorm 0.342 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 71806
2022-03-07 08:58:51 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 08:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:59:08 | INFO | train_inner | epoch 490:      6 / 49 loss=0.45, nll_loss=0.142, ppl=1.1, wps=24183, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.34, loss_scale=64, train_wall=228, gb_free=8.8, wall=71823
2022-03-07 09:00:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:00:58 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 15.184 | nll_loss 15.079 | ppl 34606.7 | wps 46887.2 | wpb 510.9 | bsz 1 | num_updates 23842 | best_loss 8.238
2022-03-07 09:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23842 updates
2022-03-07 09:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:01:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:01:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 490 @ 23842 updates, score 15.184) (writing took 2.4590040650218725 seconds)
2022-03-07 09:01:01 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 09:01:01 | INFO | train | epoch 490 | loss 0.449 | nll_loss 0.141 | ppl 1.1 | wps 24019.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 23842 | lr 0.000204799 | gnorm 0.336 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 71936
2022-03-07 09:01:01 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 09:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:03:09 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 15.236 | nll_loss 15.132 | ppl 35900.5 | wps 46787.5 | wpb 510.9 | bsz 1 | num_updates 23891 | best_loss 8.238
2022-03-07 09:03:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23891 updates
2022-03-07 09:03:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:03:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:03:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 491 @ 23891 updates, score 15.236) (writing took 2.536977220326662 seconds)
2022-03-07 09:03:11 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 09:03:11 | INFO | train | epoch 491 | loss 0.449 | nll_loss 0.141 | ppl 1.1 | wps 24400.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23891 | lr 0.000204589 | gnorm 0.338 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 72066
2022-03-07 09:03:11 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 09:03:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:03:34 | INFO | train_inner | epoch 492:      9 / 49 loss=0.449, nll_loss=0.141, ppl=1.1, wps=24413.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.337, loss_scale=64, train_wall=227, gb_free=8.8, wall=72089
2022-03-07 09:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:05:19 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 15.257 | nll_loss 15.152 | ppl 36417.6 | wps 46767.8 | wpb 510.9 | bsz 1 | num_updates 23940 | best_loss 8.238
2022-03-07 09:05:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23940 updates
2022-03-07 09:05:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:05:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:05:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 492 @ 23940 updates, score 15.257) (writing took 2.489238752052188 seconds)
2022-03-07 09:05:21 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 09:05:21 | INFO | train | epoch 492 | loss 0.448 | nll_loss 0.14 | ppl 1.1 | wps 24377.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 23940 | lr 0.00020438 | gnorm 0.337 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 72197
2022-03-07 09:05:21 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 09:05:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:06:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:07:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:07:27 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 15.298 | nll_loss 15.194 | ppl 37495.2 | wps 46800 | wpb 510.9 | bsz 1 | num_updates 23988 | best_loss 8.238
2022-03-07 09:07:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23988 updates
2022-03-07 09:07:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:07:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:07:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 493 @ 23988 updates, score 15.298) (writing took 2.494890758767724 seconds)
2022-03-07 09:07:29 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 09:07:29 | INFO | train | epoch 493 | loss 0.448 | nll_loss 0.14 | ppl 1.1 | wps 24331.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 23988 | lr 0.000204175 | gnorm 0.338 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 72324
2022-03-07 09:07:29 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 09:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:08:00 | INFO | train_inner | epoch 494:     12 / 49 loss=0.448, nll_loss=0.14, ppl=1.1, wps=24368.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.337, loss_scale=64, train_wall=227, gb_free=8.8, wall=72355
2022-03-07 09:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:09:37 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 15.223 | nll_loss 15.119 | ppl 35573.3 | wps 46643.7 | wpb 510.9 | bsz 1 | num_updates 24037 | best_loss 8.238
2022-03-07 09:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24037 updates
2022-03-07 09:09:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:09:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:09:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 494 @ 24037 updates, score 15.223) (writing took 2.5122784189879894 seconds)
2022-03-07 09:09:40 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 09:09:40 | INFO | train | epoch 494 | loss 0.449 | nll_loss 0.141 | ppl 1.1 | wps 24366.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24037 | lr 0.000203967 | gnorm 0.341 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 72455
2022-03-07 09:09:40 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 09:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:11:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:11:48 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 15.011 | nll_loss 14.904 | ppl 30653.5 | wps 46821 | wpb 510.9 | bsz 1 | num_updates 24086 | best_loss 8.238
2022-03-07 09:11:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24086 updates
2022-03-07 09:11:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:11:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 495 @ 24086 updates, score 15.011) (writing took 2.472775347530842 seconds)
2022-03-07 09:11:50 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 09:11:50 | INFO | train | epoch 495 | loss 0.448 | nll_loss 0.14 | ppl 1.1 | wps 24387.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24086 | lr 0.000203759 | gnorm 0.338 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 72585
2022-03-07 09:11:50 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 09:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:12:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:12:28 | INFO | train_inner | epoch 496:     15 / 49 loss=0.448, nll_loss=0.141, ppl=1.1, wps=24225.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.339, loss_scale=64, train_wall=229, gb_free=8.8, wall=72623
2022-03-07 09:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:13:56 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 15.227 | nll_loss 15.122 | ppl 35670 | wps 46565.1 | wpb 510.9 | bsz 1 | num_updates 24134 | best_loss 8.238
2022-03-07 09:13:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24134 updates
2022-03-07 09:13:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:13:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 496 @ 24134 updates, score 15.227) (writing took 2.4974334184080362 seconds)
2022-03-07 09:13:58 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 09:13:58 | INFO | train | epoch 496 | loss 0.447 | nll_loss 0.139 | ppl 1.1 | wps 24268.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24134 | lr 0.000203557 | gnorm 0.332 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 72713
2022-03-07 09:13:58 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 09:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:16:06 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 15.199 | nll_loss 15.093 | ppl 34941 | wps 46761 | wpb 510.9 | bsz 1 | num_updates 24183 | best_loss 8.238
2022-03-07 09:16:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24183 updates
2022-03-07 09:16:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 497 @ 24183 updates, score 15.199) (writing took 2.54364675283432 seconds)
2022-03-07 09:16:09 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 09:16:09 | INFO | train | epoch 497 | loss 0.447 | nll_loss 0.14 | ppl 1.1 | wps 24344 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24183 | lr 0.00020335 | gnorm 0.334 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 72844
2022-03-07 09:16:09 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 09:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:16:51 | INFO | train_inner | epoch 498:     17 / 49 loss=0.447, nll_loss=0.14, ppl=1.1, wps=24600.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.333, loss_scale=64, train_wall=225, gb_free=8.8, wall=72886
2022-03-07 09:17:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:18:17 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 15.189 | nll_loss 15.084 | ppl 34732.6 | wps 47054.4 | wpb 510.9 | bsz 1 | num_updates 24231 | best_loss 8.238
2022-03-07 09:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24231 updates
2022-03-07 09:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 498 @ 24231 updates, score 15.189) (writing took 2.474298434332013 seconds)
2022-03-07 09:18:19 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 09:18:19 | INFO | train | epoch 498 | loss 0.447 | nll_loss 0.14 | ppl 1.1 | wps 23908.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24231 | lr 0.000203149 | gnorm 0.335 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 72974
2022-03-07 09:18:19 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 09:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:27 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 15.17 | nll_loss 15.064 | ppl 34263.8 | wps 38600.4 | wpb 510.9 | bsz 1 | num_updates 24280 | best_loss 8.238
2022-03-07 09:20:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24280 updates
2022-03-07 09:20:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:20:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 499 @ 24280 updates, score 15.17) (writing took 2.647659931331873 seconds)
2022-03-07 09:20:29 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 09:20:29 | INFO | train | epoch 499 | loss 0.447 | nll_loss 0.14 | ppl 1.1 | wps 24383.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24280 | lr 0.000202944 | gnorm 0.341 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 73105
2022-03-07 09:20:29 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 09:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:21:20 | INFO | train_inner | epoch 500:     20 / 49 loss=0.447, nll_loss=0.14, ppl=1.1, wps=24155.7, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.338, loss_scale=64, train_wall=228, gb_free=8.8, wall=73155
2022-03-07 09:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:22:35 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 15.211 | nll_loss 15.105 | ppl 35238.7 | wps 46962.2 | wpb 510.9 | bsz 1 | num_updates 24329 | best_loss 8.238
2022-03-07 09:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24329 updates
2022-03-07 09:22:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:22:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:22:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 500 @ 24329 updates, score 15.211) (writing took 2.5335251837968826 seconds)
2022-03-07 09:22:38 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 09:22:38 | INFO | train | epoch 500 | loss 0.447 | nll_loss 0.14 | ppl 1.1 | wps 24724.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24329 | lr 0.000202739 | gnorm 0.336 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 73233
2022-03-07 09:22:38 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 09:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:23:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:46 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 15.217 | nll_loss 15.111 | ppl 35382 | wps 46809.4 | wpb 510.9 | bsz 1 | num_updates 24377 | best_loss 8.238
2022-03-07 09:24:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24377 updates
2022-03-07 09:24:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 501 @ 24377 updates, score 15.217) (writing took 2.529415614902973 seconds)
2022-03-07 09:24:48 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 09:24:48 | INFO | train | epoch 501 | loss 0.446 | nll_loss 0.139 | ppl 1.1 | wps 23851.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24377 | lr 0.00020254 | gnorm 0.335 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 73364
2022-03-07 09:24:48 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 09:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:25:46 | INFO | train_inner | epoch 502:     23 / 49 loss=0.447, nll_loss=0.139, ppl=1.1, wps=24386.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.336, loss_scale=64, train_wall=227, gb_free=8.8, wall=73421
2022-03-07 09:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:26:56 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 15.173 | nll_loss 15.069 | ppl 34364.7 | wps 46915.4 | wpb 510.9 | bsz 1 | num_updates 24426 | best_loss 8.238
2022-03-07 09:26:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24426 updates
2022-03-07 09:26:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 502 @ 24426 updates, score 15.173) (writing took 2.446716897189617 seconds)
2022-03-07 09:26:59 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 09:26:59 | INFO | train | epoch 502 | loss 0.446 | nll_loss 0.139 | ppl 1.1 | wps 24405.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24426 | lr 0.000202336 | gnorm 0.335 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 73494
2022-03-07 09:26:59 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 09:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:28:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:29:04 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 15.136 | nll_loss 15.031 | ppl 33479.8 | wps 46701.3 | wpb 510.9 | bsz 1 | num_updates 24475 | best_loss 8.238
2022-03-07 09:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24475 updates
2022-03-07 09:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:29:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:29:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 503 @ 24475 updates, score 15.136) (writing took 2.4730001743882895 seconds)
2022-03-07 09:29:07 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 09:29:07 | INFO | train | epoch 503 | loss 0.446 | nll_loss 0.138 | ppl 1.1 | wps 24830.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24475 | lr 0.000202134 | gnorm 0.336 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 73622
2022-03-07 09:29:07 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 09:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:29:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:30:14 | INFO | train_inner | epoch 504:     26 / 49 loss=0.445, nll_loss=0.138, ppl=1.1, wps=24207.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.334, loss_scale=64, train_wall=229, gb_free=8.8, wall=73689
2022-03-07 09:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:31:14 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 15.13 | nll_loss 15.025 | ppl 33338.6 | wps 46969.1 | wpb 510.9 | bsz 1 | num_updates 24523 | best_loss 8.238
2022-03-07 09:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24523 updates
2022-03-07 09:31:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:31:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:31:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 504 @ 24523 updates, score 15.13) (writing took 2.5436878204345703 seconds)
2022-03-07 09:31:17 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 09:31:17 | INFO | train | epoch 504 | loss 0.445 | nll_loss 0.138 | ppl 1.1 | wps 23893.7 | ups 0.37 | wpb 64853.3 | bsz 126.7 | num_updates 24523 | lr 0.000201936 | gnorm 0.332 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 73752
2022-03-07 09:31:17 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 09:31:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:33:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:33:25 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 15.177 | nll_loss 15.072 | ppl 34437.8 | wps 46713.5 | wpb 510.9 | bsz 1 | num_updates 24572 | best_loss 8.238
2022-03-07 09:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24572 updates
2022-03-07 09:33:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:33:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:33:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 505 @ 24572 updates, score 15.177) (writing took 2.469360599294305 seconds)
2022-03-07 09:33:27 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 09:33:27 | INFO | train | epoch 505 | loss 0.445 | nll_loss 0.138 | ppl 1.1 | wps 24379 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24572 | lr 0.000201734 | gnorm 0.336 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 73882
2022-03-07 09:33:27 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 09:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:34:37 | INFO | train_inner | epoch 506:     28 / 49 loss=0.445, nll_loss=0.138, ppl=1.1, wps=24628.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.333, loss_scale=64, train_wall=225, gb_free=8.8, wall=73952
2022-03-07 09:35:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:35:33 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 15.188 | nll_loss 15.082 | ppl 34694.6 | wps 46394.8 | wpb 510.9 | bsz 1 | num_updates 24620 | best_loss 8.238
2022-03-07 09:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24620 updates
2022-03-07 09:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:35:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 506 @ 24620 updates, score 15.188) (writing took 2.642544200643897 seconds)
2022-03-07 09:35:36 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 09:35:36 | INFO | train | epoch 506 | loss 0.444 | nll_loss 0.137 | ppl 1.1 | wps 24256.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24620 | lr 0.000201538 | gnorm 0.329 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 74011
2022-03-07 09:35:36 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 09:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:37:43 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 15.19 | nll_loss 15.084 | ppl 34742.3 | wps 46709.5 | wpb 510.9 | bsz 1 | num_updates 24669 | best_loss 8.238
2022-03-07 09:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24669 updates
2022-03-07 09:37:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:37:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 507 @ 24669 updates, score 15.19) (writing took 2.5259369742125273 seconds)
2022-03-07 09:37:46 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 09:37:46 | INFO | train | epoch 507 | loss 0.445 | nll_loss 0.138 | ppl 1.1 | wps 24431.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24669 | lr 0.000201337 | gnorm 0.333 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 74141
2022-03-07 09:37:46 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 09:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:39:05 | INFO | train_inner | epoch 508:     31 / 49 loss=0.445, nll_loss=0.138, ppl=1.1, wps=24200.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.333, loss_scale=64, train_wall=229, gb_free=8.8, wall=74220
2022-03-07 09:39:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:39:53 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 15.225 | nll_loss 15.12 | ppl 35610 | wps 46861.2 | wpb 510.9 | bsz 1 | num_updates 24718 | best_loss 8.238
2022-03-07 09:39:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24718 updates
2022-03-07 09:39:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:39:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 508 @ 24718 updates, score 15.225) (writing took 2.473686497658491 seconds)
2022-03-07 09:39:56 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 09:39:56 | INFO | train | epoch 508 | loss 0.445 | nll_loss 0.138 | ppl 1.1 | wps 24396.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24718 | lr 0.000201138 | gnorm 0.334 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 74271
2022-03-07 09:39:56 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 09:39:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:42:04 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 15.205 | nll_loss 15.1 | ppl 35130.1 | wps 45196.6 | wpb 510.9 | bsz 1 | num_updates 24766 | best_loss 8.238
2022-03-07 09:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24766 updates
2022-03-07 09:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 509 @ 24766 updates, score 15.205) (writing took 2.473928313702345 seconds)
2022-03-07 09:42:06 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 09:42:06 | INFO | train | epoch 509 | loss 0.444 | nll_loss 0.137 | ppl 1.1 | wps 23855.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24766 | lr 0.000200943 | gnorm 0.329 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 74402
2022-03-07 09:42:06 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 09:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:43:31 | INFO | train_inner | epoch 510:     34 / 49 loss=0.444, nll_loss=0.137, ppl=1.1, wps=24400.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.33, loss_scale=64, train_wall=227, gb_free=8.8, wall=74486
2022-03-07 09:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:44:12 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 15.116 | nll_loss 15.01 | ppl 32994.7 | wps 46967.1 | wpb 510.9 | bsz 1 | num_updates 24815 | best_loss 8.238
2022-03-07 09:44:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24815 updates
2022-03-07 09:44:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 510 @ 24815 updates, score 15.116) (writing took 2.4964453987777233 seconds)
2022-03-07 09:44:14 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 09:44:14 | INFO | train | epoch 510 | loss 0.443 | nll_loss 0.137 | ppl 1.1 | wps 24850.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24815 | lr 0.000200744 | gnorm 0.33 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 74529
2022-03-07 09:44:14 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 09:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:46:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:46:22 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 15.011 | nll_loss 14.905 | ppl 30671.6 | wps 46797.2 | wpb 510.9 | bsz 1 | num_updates 24864 | best_loss 8.238
2022-03-07 09:46:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24864 updates
2022-03-07 09:46:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:46:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:46:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 511 @ 24864 updates, score 15.011) (writing took 2.4999338164925575 seconds)
2022-03-07 09:46:25 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 09:46:25 | INFO | train | epoch 511 | loss 0.444 | nll_loss 0.137 | ppl 1.1 | wps 24395.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24864 | lr 0.000200546 | gnorm 0.336 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 74660
2022-03-07 09:46:25 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 09:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:46:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:47:58 | INFO | train_inner | epoch 512:     37 / 49 loss=0.443, nll_loss=0.137, ppl=1.1, wps=24328.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.334, loss_scale=64, train_wall=228, gb_free=8.8, wall=74753
2022-03-07 09:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:32 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 15.172 | nll_loss 15.066 | ppl 34308.4 | wps 46687.3 | wpb 510.9 | bsz 1 | num_updates 24912 | best_loss 8.238
2022-03-07 09:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24912 updates
2022-03-07 09:48:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:48:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:48:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 512 @ 24912 updates, score 15.172) (writing took 2.5167563408613205 seconds)
2022-03-07 09:48:35 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 09:48:35 | INFO | train | epoch 512 | loss 0.443 | nll_loss 0.136 | ppl 1.1 | wps 23889.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 24912 | lr 0.000200353 | gnorm 0.332 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 74790
2022-03-07 09:48:35 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 09:48:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:50:41 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 15.196 | nll_loss 15.092 | ppl 34922 | wps 46558.3 | wpb 510.9 | bsz 1 | num_updates 24961 | best_loss 8.238
2022-03-07 09:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24961 updates
2022-03-07 09:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 513 @ 24961 updates, score 15.196) (writing took 2.534288138151169 seconds)
2022-03-07 09:50:43 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 09:50:43 | INFO | train | epoch 513 | loss 0.443 | nll_loss 0.137 | ppl 1.1 | wps 24779.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 24961 | lr 0.000200156 | gnorm 0.333 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 74918
2022-03-07 09:50:43 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 09:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:52:25 | INFO | train_inner | epoch 514:     40 / 49 loss=0.443, nll_loss=0.136, ppl=1.1, wps=24267.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.332, loss_scale=64, train_wall=228, gb_free=8.8, wall=75020
2022-03-07 09:52:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:52:51 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 15.206 | nll_loss 15.103 | ppl 35181.8 | wps 46687.3 | wpb 510.9 | bsz 1 | num_updates 25009 | best_loss 8.238
2022-03-07 09:52:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25009 updates
2022-03-07 09:52:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:52:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:52:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 514 @ 25009 updates, score 15.206) (writing took 2.5209330450743437 seconds)
2022-03-07 09:52:53 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 09:52:53 | INFO | train | epoch 514 | loss 0.443 | nll_loss 0.136 | ppl 1.1 | wps 23875.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25009 | lr 0.000199964 | gnorm 0.332 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 75049
2022-03-07 09:52:53 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 09:52:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:55:01 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 15.12 | nll_loss 15.015 | ppl 33112 | wps 46828.5 | wpb 510.9 | bsz 1 | num_updates 25058 | best_loss 8.238
2022-03-07 09:55:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25058 updates
2022-03-07 09:55:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 515 @ 25058 updates, score 15.12) (writing took 2.481843151152134 seconds)
2022-03-07 09:55:04 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 09:55:04 | INFO | train | epoch 515 | loss 0.443 | nll_loss 0.136 | ppl 1.1 | wps 24377.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25058 | lr 0.000199768 | gnorm 0.332 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 75179
2022-03-07 09:55:04 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 09:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:56:49 | INFO | train_inner | epoch 516:     42 / 49 loss=0.443, nll_loss=0.136, ppl=1.1, wps=24609.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.331, loss_scale=64, train_wall=225, gb_free=8.8, wall=75284
2022-03-07 09:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:57:11 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 15.212 | nll_loss 15.108 | ppl 35307.3 | wps 38208.9 | wpb 510.9 | bsz 1 | num_updates 25107 | best_loss 8.238
2022-03-07 09:57:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25107 updates
2022-03-07 09:57:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:57:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 516 @ 25107 updates, score 15.212) (writing took 2.701289862394333 seconds)
2022-03-07 09:57:14 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 09:57:14 | INFO | train | epoch 516 | loss 0.442 | nll_loss 0.136 | ppl 1.1 | wps 24491.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25107 | lr 0.000199573 | gnorm 0.329 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 75309
2022-03-07 09:57:14 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 09:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:58:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 09:59:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:59:20 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 15.2 | nll_loss 15.096 | ppl 35029.4 | wps 46657.9 | wpb 510.9 | bsz 1 | num_updates 25155 | best_loss 8.238
2022-03-07 09:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25155 updates
2022-03-07 09:59:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:59:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 09:59:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 517 @ 25155 updates, score 15.2) (writing took 2.4706697650253773 seconds)
2022-03-07 09:59:23 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 09:59:23 | INFO | train | epoch 517 | loss 0.441 | nll_loss 0.135 | ppl 1.1 | wps 24104.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25155 | lr 0.000199383 | gnorm 0.328 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 75438
2022-03-07 09:59:23 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 09:59:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:01:17 | INFO | train_inner | epoch 518:     45 / 49 loss=0.442, nll_loss=0.136, ppl=1.1, wps=24158.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.331, loss_scale=64, train_wall=228, gb_free=8.8, wall=75552
2022-03-07 10:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:01:31 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 15.167 | nll_loss 15.063 | ppl 34232.8 | wps 46911.1 | wpb 510.9 | bsz 1 | num_updates 25204 | best_loss 8.238
2022-03-07 10:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25204 updates
2022-03-07 10:01:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 518 @ 25204 updates, score 15.167) (writing took 2.4949377719312906 seconds)
2022-03-07 10:01:33 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 10:01:33 | INFO | train | epoch 518 | loss 0.442 | nll_loss 0.136 | ppl 1.1 | wps 24381.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25204 | lr 0.000199189 | gnorm 0.334 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 75568
2022-03-07 10:01:33 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 10:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:03:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:03:41 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 15.235 | nll_loss 15.133 | ppl 35922.6 | wps 46763.2 | wpb 510.9 | bsz 1 | num_updates 25253 | best_loss 8.238
2022-03-07 10:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25253 updates
2022-03-07 10:03:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 519 @ 25253 updates, score 15.235) (writing took 2.5316798221319914 seconds)
2022-03-07 10:03:44 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 10:03:44 | INFO | train | epoch 519 | loss 0.441 | nll_loss 0.135 | ppl 1.1 | wps 24335.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25253 | lr 0.000198996 | gnorm 0.329 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 75699
2022-03-07 10:03:44 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 10:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:03:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:05:43 | INFO | train_inner | epoch 520:     48 / 49 loss=0.441, nll_loss=0.135, ppl=1.1, wps=24394.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.329, loss_scale=64, train_wall=227, gb_free=8.8, wall=75818
2022-03-07 10:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:05:49 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 15.136 | nll_loss 15.032 | ppl 33492.3 | wps 46727.8 | wpb 510.9 | bsz 1 | num_updates 25301 | best_loss 8.238
2022-03-07 10:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25301 updates
2022-03-07 10:05:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:05:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 520 @ 25301 updates, score 15.136) (writing took 2.4797983337193727 seconds)
2022-03-07 10:05:52 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 10:05:52 | INFO | train | epoch 520 | loss 0.44 | nll_loss 0.134 | ppl 1.1 | wps 24334.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25301 | lr 0.000198807 | gnorm 0.328 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 75827
2022-03-07 10:05:52 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 10:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:00 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 15.131 | nll_loss 15.025 | ppl 33350.2 | wps 46972.6 | wpb 510.9 | bsz 1 | num_updates 25350 | best_loss 8.238
2022-03-07 10:08:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25350 updates
2022-03-07 10:08:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 521 @ 25350 updates, score 15.131) (writing took 2.4966749511659145 seconds)
2022-03-07 10:08:02 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 10:08:02 | INFO | train | epoch 521 | loss 0.441 | nll_loss 0.135 | ppl 1.1 | wps 24359.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25350 | lr 0.000198615 | gnorm 0.328 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 75957
2022-03-07 10:08:02 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 10:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:10:10 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 15.188 | nll_loss 15.085 | ppl 34751.6 | wps 46695.9 | wpb 510.9 | bsz 1 | num_updates 25398 | best_loss 8.238
2022-03-07 10:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25398 updates
2022-03-07 10:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:10:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 522 @ 25398 updates, score 15.188) (writing took 2.552403524518013 seconds)
2022-03-07 10:10:13 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 10:10:13 | INFO | train | epoch 522 | loss 0.44 | nll_loss 0.134 | ppl 1.1 | wps 23855.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25398 | lr 0.000198427 | gnorm 0.328 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 76088
2022-03-07 10:10:13 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 10:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:10:18 | INFO | train_inner | epoch 523:      2 / 49 loss=0.44, nll_loss=0.134, ppl=1.1, wps=23512.6, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=25400, lr=0.000198419, gnorm=0.329, loss_scale=64, train_wall=228, gb_free=8.8, wall=76093
2022-03-07 10:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:18 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 15.124 | nll_loss 15.02 | ppl 33214.8 | wps 46751.4 | wpb 510.9 | bsz 1 | num_updates 25447 | best_loss 8.238
2022-03-07 10:12:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25447 updates
2022-03-07 10:12:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:12:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:12:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 523 @ 25447 updates, score 15.124) (writing took 2.4588917959481478 seconds)
2022-03-07 10:12:21 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 10:12:21 | INFO | train | epoch 523 | loss 0.44 | nll_loss 0.134 | ppl 1.1 | wps 24800.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25447 | lr 0.000198236 | gnorm 0.328 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 76216
2022-03-07 10:12:21 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 10:12:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:14:28 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 15.131 | nll_loss 15.027 | ppl 33388.9 | wps 47162.9 | wpb 510.9 | bsz 1 | num_updates 25496 | best_loss 8.238
2022-03-07 10:14:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25496 updates
2022-03-07 10:14:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:14:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:14:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 524 @ 25496 updates, score 15.131) (writing took 2.5014326609671116 seconds)
2022-03-07 10:14:31 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 10:14:31 | INFO | train | epoch 524 | loss 0.44 | nll_loss 0.134 | ppl 1.1 | wps 24391.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25496 | lr 0.000198045 | gnorm 0.328 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 76346
2022-03-07 10:14:31 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 10:14:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:14:41 | INFO | train_inner | epoch 525:      4 / 49 loss=0.44, nll_loss=0.134, ppl=1.1, wps=24630.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.328, loss_scale=64, train_wall=225, gb_free=8.8, wall=76356
2022-03-07 10:15:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:16:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:16:38 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 15.153 | nll_loss 15.047 | ppl 33862.7 | wps 46945 | wpb 510.9 | bsz 1 | num_updates 25544 | best_loss 8.238
2022-03-07 10:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25544 updates
2022-03-07 10:16:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:16:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 525 @ 25544 updates, score 15.153) (writing took 2.500534700229764 seconds)
2022-03-07 10:16:41 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 10:16:41 | INFO | train | epoch 525 | loss 0.44 | nll_loss 0.134 | ppl 1.1 | wps 23977.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25544 | lr 0.000197859 | gnorm 0.328 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 76476
2022-03-07 10:16:41 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 10:16:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:18:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:18:48 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 15.223 | nll_loss 15.119 | ppl 35593.7 | wps 44527.3 | wpb 510.9 | bsz 1 | num_updates 25593 | best_loss 8.238
2022-03-07 10:18:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25593 updates
2022-03-07 10:18:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:18:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:18:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 526 @ 25593 updates, score 15.223) (writing took 2.55129262059927 seconds)
2022-03-07 10:18:51 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 10:18:51 | INFO | train | epoch 526 | loss 0.439 | nll_loss 0.134 | ppl 1.1 | wps 24465 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25593 | lr 0.000197669 | gnorm 0.325 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 76606
2022-03-07 10:18:51 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 10:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:19:08 | INFO | train_inner | epoch 527:      7 / 49 loss=0.439, nll_loss=0.134, ppl=1.1, wps=24275.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.326, loss_scale=64, train_wall=228, gb_free=8.8, wall=76623
2022-03-07 10:20:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:20:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:20:56 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 15.208 | nll_loss 15.105 | ppl 35239.1 | wps 46713 | wpb 510.9 | bsz 1 | num_updates 25641 | best_loss 8.238
2022-03-07 10:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25641 updates
2022-03-07 10:20:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 527 @ 25641 updates, score 15.208) (writing took 2.464722815901041 seconds)
2022-03-07 10:20:58 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 10:20:58 | INFO | train | epoch 527 | loss 0.439 | nll_loss 0.133 | ppl 1.1 | wps 24393.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25641 | lr 0.000197484 | gnorm 0.326 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 76733
2022-03-07 10:20:58 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 10:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:23:06 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 15.167 | nll_loss 15.063 | ppl 34232.6 | wps 46837.3 | wpb 510.9 | bsz 1 | num_updates 25690 | best_loss 8.238
2022-03-07 10:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25690 updates
2022-03-07 10:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:23:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 528 @ 25690 updates, score 15.167) (writing took 2.4938722159713507 seconds)
2022-03-07 10:23:08 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 10:23:08 | INFO | train | epoch 528 | loss 0.439 | nll_loss 0.133 | ppl 1.1 | wps 24430.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25690 | lr 0.000197296 | gnorm 0.326 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 76864
2022-03-07 10:23:08 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 10:23:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:23:33 | INFO | train_inner | epoch 529:     10 / 49 loss=0.439, nll_loss=0.133, ppl=1.1, wps=24466.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.326, loss_scale=64, train_wall=226, gb_free=8.8, wall=76889
2022-03-07 10:25:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:25:16 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 15.126 | nll_loss 15.023 | ppl 33286.9 | wps 46778.1 | wpb 510.9 | bsz 1 | num_updates 25739 | best_loss 8.238
2022-03-07 10:25:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25739 updates
2022-03-07 10:25:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:25:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:25:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 529 @ 25739 updates, score 15.126) (writing took 2.5355275701731443 seconds)
2022-03-07 10:25:19 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 10:25:19 | INFO | train | epoch 529 | loss 0.439 | nll_loss 0.133 | ppl 1.1 | wps 24363.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25739 | lr 0.000197108 | gnorm 0.324 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 76994
2022-03-07 10:25:19 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 10:25:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:26:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:24 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 15.04 | nll_loss 14.935 | ppl 31327.1 | wps 46759.8 | wpb 510.9 | bsz 1 | num_updates 25787 | best_loss 8.238
2022-03-07 10:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25787 updates
2022-03-07 10:27:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:27:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:27:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 530 @ 25787 updates, score 15.04) (writing took 2.527899542823434 seconds)
2022-03-07 10:27:27 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 10:27:27 | INFO | train | epoch 530 | loss 0.438 | nll_loss 0.132 | ppl 1.1 | wps 24342.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 25787 | lr 0.000196924 | gnorm 0.324 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 77122
2022-03-07 10:27:27 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 10:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:28:01 | INFO | train_inner | epoch 531:     13 / 49 loss=0.438, nll_loss=0.132, ppl=1.1, wps=24200.7, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.324, loss_scale=64, train_wall=229, gb_free=8.8, wall=77157
2022-03-07 10:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:29:35 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 15.086 | nll_loss 14.981 | ppl 32341.7 | wps 46597.1 | wpb 510.9 | bsz 1 | num_updates 25836 | best_loss 8.238
2022-03-07 10:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25836 updates
2022-03-07 10:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 531 @ 25836 updates, score 15.086) (writing took 2.5172590892761946 seconds)
2022-03-07 10:29:37 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 10:29:37 | INFO | train | epoch 531 | loss 0.438 | nll_loss 0.132 | ppl 1.1 | wps 24379 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25836 | lr 0.000196738 | gnorm 0.325 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 77252
2022-03-07 10:29:37 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 10:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:45 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 15.129 | nll_loss 15.024 | ppl 33310.6 | wps 46760.2 | wpb 510.9 | bsz 1 | num_updates 25885 | best_loss 8.238
2022-03-07 10:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25885 updates
2022-03-07 10:31:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:31:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:31:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 532 @ 25885 updates, score 15.129) (writing took 2.5281370785087347 seconds)
2022-03-07 10:31:47 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 10:31:47 | INFO | train | epoch 532 | loss 0.438 | nll_loss 0.132 | ppl 1.1 | wps 24387.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25885 | lr 0.000196551 | gnorm 0.322 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 77382
2022-03-07 10:31:47 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 10:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:32:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:32:27 | INFO | train_inner | epoch 533:     16 / 49 loss=0.438, nll_loss=0.132, ppl=1.1, wps=24395.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.323, loss_scale=64, train_wall=227, gb_free=8.8, wall=77423
2022-03-07 10:33:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:33:55 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 15.14 | nll_loss 15.036 | ppl 33600.8 | wps 38647.5 | wpb 510.9 | bsz 1 | num_updates 25933 | best_loss 8.238
2022-03-07 10:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25933 updates
2022-03-07 10:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 533 @ 25933 updates, score 15.14) (writing took 2.7381492014974356 seconds)
2022-03-07 10:33:57 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 10:33:57 | INFO | train | epoch 533 | loss 0.438 | nll_loss 0.132 | ppl 1.1 | wps 23952.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 25933 | lr 0.000196369 | gnorm 0.323 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 77512
2022-03-07 10:33:57 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 10:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:36:04 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 15.184 | nll_loss 15.081 | ppl 34671.4 | wps 46718.1 | wpb 510.9 | bsz 1 | num_updates 25982 | best_loss 8.238
2022-03-07 10:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25982 updates
2022-03-07 10:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 534 @ 25982 updates, score 15.184) (writing took 2.5283284336328506 seconds)
2022-03-07 10:36:06 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 10:36:06 | INFO | train | epoch 534 | loss 0.437 | nll_loss 0.132 | ppl 1.1 | wps 24664.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 25982 | lr 0.000196184 | gnorm 0.326 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 77641
2022-03-07 10:36:06 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 10:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:36:51 | INFO | train_inner | epoch 535:     18 / 49 loss=0.437, nll_loss=0.132, ppl=1.1, wps=24570.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.324, loss_scale=64, train_wall=224, gb_free=8.8, wall=77687
2022-03-07 10:37:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:38:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:38:14 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 15.139 | nll_loss 15.034 | ppl 33548.9 | wps 46864.8 | wpb 510.9 | bsz 1 | num_updates 26030 | best_loss 8.238
2022-03-07 10:38:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26030 updates
2022-03-07 10:38:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 535 @ 26030 updates, score 15.139) (writing took 2.46734588034451 seconds)
2022-03-07 10:38:16 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 10:38:16 | INFO | train | epoch 535 | loss 0.437 | nll_loss 0.132 | ppl 1.1 | wps 23903.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26030 | lr 0.000196003 | gnorm 0.321 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 77772
2022-03-07 10:38:16 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 10:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:40:24 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 15.129 | nll_loss 15.025 | ppl 33347.8 | wps 46667 | wpb 510.9 | bsz 1 | num_updates 26079 | best_loss 8.238
2022-03-07 10:40:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26079 updates
2022-03-07 10:40:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:40:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:40:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 536 @ 26079 updates, score 15.129) (writing took 2.483753602951765 seconds)
2022-03-07 10:40:27 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 10:40:27 | INFO | train | epoch 536 | loss 0.437 | nll_loss 0.132 | ppl 1.1 | wps 24382.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26079 | lr 0.000195819 | gnorm 0.323 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 77902
2022-03-07 10:40:27 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 10:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:41:19 | INFO | train_inner | epoch 537:     21 / 49 loss=0.437, nll_loss=0.132, ppl=1.1, wps=24236.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.323, loss_scale=64, train_wall=229, gb_free=8.8, wall=77954
2022-03-07 10:42:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:42:32 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 15.151 | nll_loss 15.045 | ppl 33815.8 | wps 46451.4 | wpb 510.9 | bsz 1 | num_updates 26128 | best_loss 8.238
2022-03-07 10:42:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26128 updates
2022-03-07 10:42:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:42:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:42:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 537 @ 26128 updates, score 15.151) (writing took 2.49721372500062 seconds)
2022-03-07 10:42:34 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 10:42:34 | INFO | train | epoch 537 | loss 0.437 | nll_loss 0.132 | ppl 1.1 | wps 24873.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26128 | lr 0.000195635 | gnorm 0.324 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 78030
2022-03-07 10:42:34 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 10:42:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:43:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:44:42 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 15.123 | nll_loss 15.019 | ppl 33197.3 | wps 46704.5 | wpb 510.9 | bsz 1 | num_updates 26176 | best_loss 8.238
2022-03-07 10:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26176 updates
2022-03-07 10:44:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:44:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 538 @ 26176 updates, score 15.123) (writing took 2.4611827824264765 seconds)
2022-03-07 10:44:45 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 10:44:45 | INFO | train | epoch 538 | loss 0.436 | nll_loss 0.131 | ppl 1.09 | wps 23867.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26176 | lr 0.000195456 | gnorm 0.319 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 78160
2022-03-07 10:44:45 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 10:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:45:45 | INFO | train_inner | epoch 539:     24 / 49 loss=0.436, nll_loss=0.131, ppl=1.1, wps=24423.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.321, loss_scale=64, train_wall=227, gb_free=8.8, wall=78220
2022-03-07 10:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:46:53 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 15.194 | nll_loss 15.089 | ppl 34855.7 | wps 46479.5 | wpb 510.9 | bsz 1 | num_updates 26225 | best_loss 8.238
2022-03-07 10:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26225 updates
2022-03-07 10:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 539 @ 26225 updates, score 15.194) (writing took 2.490854687988758 seconds)
2022-03-07 10:46:55 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 10:46:55 | INFO | train | epoch 539 | loss 0.436 | nll_loss 0.131 | ppl 1.09 | wps 24369.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26225 | lr 0.000195273 | gnorm 0.32 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 78290
2022-03-07 10:46:55 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 10:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:48:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:49:01 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 15.084 | nll_loss 14.98 | ppl 32325 | wps 47137.1 | wpb 510.9 | bsz 1 | num_updates 26274 | best_loss 8.238
2022-03-07 10:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26274 updates
2022-03-07 10:49:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 540 @ 26274 updates, score 15.084) (writing took 2.5765497758984566 seconds)
2022-03-07 10:49:03 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 10:49:03 | INFO | train | epoch 540 | loss 0.436 | nll_loss 0.13 | ppl 1.09 | wps 24823.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26274 | lr 0.000195091 | gnorm 0.324 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 78418
2022-03-07 10:49:03 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 10:49:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:49:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:50:13 | INFO | train_inner | epoch 541:     27 / 49 loss=0.436, nll_loss=0.131, ppl=1.09, wps=24207, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.322, loss_scale=64, train_wall=229, gb_free=8.8, wall=78488
2022-03-07 10:51:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:51:11 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 15.157 | nll_loss 15.053 | ppl 33999.9 | wps 46831.9 | wpb 510.9 | bsz 1 | num_updates 26322 | best_loss 8.238
2022-03-07 10:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26322 updates
2022-03-07 10:51:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:51:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:51:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 541 @ 26322 updates, score 15.157) (writing took 2.4976628739386797 seconds)
2022-03-07 10:51:13 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 10:51:13 | INFO | train | epoch 541 | loss 0.436 | nll_loss 0.131 | ppl 1.09 | wps 23944.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26322 | lr 0.000194913 | gnorm 0.321 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 78548
2022-03-07 10:51:13 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 10:51:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:53:21 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 15.152 | nll_loss 15.049 | ppl 33895.4 | wps 46772.5 | wpb 510.9 | bsz 1 | num_updates 26371 | best_loss 8.238
2022-03-07 10:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26371 updates
2022-03-07 10:53:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 542 @ 26371 updates, score 15.152) (writing took 2.50252509303391 seconds)
2022-03-07 10:53:23 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 10:53:23 | INFO | train | epoch 542 | loss 0.435 | nll_loss 0.13 | ppl 1.09 | wps 24414.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26371 | lr 0.000194732 | gnorm 0.318 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 78679
2022-03-07 10:53:23 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 10:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:54:36 | INFO | train_inner | epoch 543:     29 / 49 loss=0.435, nll_loss=0.13, ppl=1.09, wps=24667.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.319, loss_scale=64, train_wall=224, gb_free=8.8, wall=78751
2022-03-07 10:55:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 10:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:31 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 15.085 | nll_loss 14.981 | ppl 32331.8 | wps 41830 | wpb 510.9 | bsz 1 | num_updates 26419 | best_loss 8.238
2022-03-07 10:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26419 updates
2022-03-07 10:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 543 @ 26419 updates, score 15.085) (writing took 2.487897824496031 seconds)
2022-03-07 10:55:34 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 10:55:34 | INFO | train | epoch 543 | loss 0.435 | nll_loss 0.131 | ppl 1.09 | wps 23862.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26419 | lr 0.000194555 | gnorm 0.321 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 78809
2022-03-07 10:55:34 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 10:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:57:39 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 15.227 | nll_loss 15.124 | ppl 35702.2 | wps 46426.4 | wpb 510.9 | bsz 1 | num_updates 26468 | best_loss 8.238
2022-03-07 10:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26468 updates
2022-03-07 10:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 544 @ 26468 updates, score 15.227) (writing took 2.4855635426938534 seconds)
2022-03-07 10:57:42 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 10:57:42 | INFO | train | epoch 544 | loss 0.435 | nll_loss 0.13 | ppl 1.09 | wps 24842.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26468 | lr 0.000194375 | gnorm 0.323 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 78937
2022-03-07 10:57:42 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 10:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:59:04 | INFO | train_inner | epoch 545:     32 / 49 loss=0.435, nll_loss=0.131, ppl=1.09, wps=24189, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.322, loss_scale=64, train_wall=229, gb_free=8.8, wall=79019
2022-03-07 10:59:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:59:50 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 15.172 | nll_loss 15.069 | ppl 34380 | wps 45854.4 | wpb 510.9 | bsz 1 | num_updates 26517 | best_loss 8.238
2022-03-07 10:59:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26517 updates
2022-03-07 10:59:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:59:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 10:59:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 545 @ 26517 updates, score 15.172) (writing took 2.4791138004511595 seconds)
2022-03-07 10:59:52 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 10:59:52 | INFO | train | epoch 545 | loss 0.435 | nll_loss 0.131 | ppl 1.09 | wps 24377.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26517 | lr 0.000194195 | gnorm 0.322 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79067
2022-03-07 10:59:52 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 10:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:00:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:01:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:02:00 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 15.106 | nll_loss 15.003 | ppl 32839.3 | wps 46390 | wpb 510.9 | bsz 1 | num_updates 26565 | best_loss 8.238
2022-03-07 11:02:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26565 updates
2022-03-07 11:02:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:02:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:02:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 546 @ 26565 updates, score 15.106) (writing took 2.458089657127857 seconds)
2022-03-07 11:02:02 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 11:02:02 | INFO | train | epoch 546 | loss 0.435 | nll_loss 0.13 | ppl 1.09 | wps 23921.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26565 | lr 0.000194019 | gnorm 0.321 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79197
2022-03-07 11:02:02 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 11:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:03:29 | INFO | train_inner | epoch 547:     35 / 49 loss=0.435, nll_loss=0.13, ppl=1.09, wps=24426.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.321, loss_scale=64, train_wall=227, gb_free=8.8, wall=79285
2022-03-07 11:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:04:08 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 15.253 | nll_loss 15.149 | ppl 36336 | wps 46164.4 | wpb 510.9 | bsz 1 | num_updates 26614 | best_loss 8.238
2022-03-07 11:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26614 updates
2022-03-07 11:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:04:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 547 @ 26614 updates, score 15.253) (writing took 2.5326341316103935 seconds)
2022-03-07 11:04:10 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 11:04:10 | INFO | train | epoch 547 | loss 0.434 | nll_loss 0.13 | ppl 1.09 | wps 24811.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26614 | lr 0.000193841 | gnorm 0.319 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 79326
2022-03-07 11:04:10 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 11:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:06:18 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 15.151 | nll_loss 15.048 | ppl 33881.9 | wps 46221 | wpb 510.9 | bsz 1 | num_updates 26663 | best_loss 8.238
2022-03-07 11:06:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26663 updates
2022-03-07 11:06:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:06:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:06:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 548 @ 26663 updates, score 15.151) (writing took 2.5068014692515135 seconds)
2022-03-07 11:06:21 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 11:06:21 | INFO | train | epoch 548 | loss 0.434 | nll_loss 0.129 | ppl 1.09 | wps 24373.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26663 | lr 0.000193662 | gnorm 0.316 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79456
2022-03-07 11:06:21 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 11:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:06:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:07:58 | INFO | train_inner | epoch 549:     38 / 49 loss=0.434, nll_loss=0.129, ppl=1.09, wps=24178.2, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.317, loss_scale=64, train_wall=229, gb_free=8.8, wall=79553
2022-03-07 11:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:08:29 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 15.201 | nll_loss 15.098 | ppl 35078.7 | wps 46264.8 | wpb 510.9 | bsz 1 | num_updates 26711 | best_loss 8.238
2022-03-07 11:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26711 updates
2022-03-07 11:08:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 549 @ 26711 updates, score 15.201) (writing took 2.538604898378253 seconds)
2022-03-07 11:08:31 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 11:08:31 | INFO | train | epoch 549 | loss 0.434 | nll_loss 0.129 | ppl 1.09 | wps 23883.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26711 | lr 0.000193488 | gnorm 0.319 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79586
2022-03-07 11:08:31 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 11:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:10:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:10:38 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 15.086 | nll_loss 14.982 | ppl 32362.2 | wps 38695.4 | wpb 510.9 | bsz 1 | num_updates 26760 | best_loss 8.238
2022-03-07 11:10:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26760 updates
2022-03-07 11:10:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:10:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 550 @ 26760 updates, score 15.086) (writing took 2.6732288394123316 seconds)
2022-03-07 11:10:41 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 11:10:41 | INFO | train | epoch 550 | loss 0.434 | nll_loss 0.129 | ppl 1.09 | wps 24519.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26760 | lr 0.000193311 | gnorm 0.319 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 79716
2022-03-07 11:10:41 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 11:10:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:12:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:12:24 | INFO | train_inner | epoch 551:     41 / 49 loss=0.433, nll_loss=0.129, ppl=1.09, wps=24394.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.318, loss_scale=64, train_wall=226, gb_free=8.8, wall=79819
2022-03-07 11:12:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:12:47 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 15.205 | nll_loss 15.102 | ppl 35165.1 | wps 46341.9 | wpb 510.9 | bsz 1 | num_updates 26808 | best_loss 8.238
2022-03-07 11:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26808 updates
2022-03-07 11:12:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:12:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:12:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 551 @ 26808 updates, score 15.205) (writing took 2.4901360906660557 seconds)
2022-03-07 11:12:50 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 11:12:50 | INFO | train | epoch 551 | loss 0.433 | nll_loss 0.129 | ppl 1.09 | wps 24164.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26808 | lr 0.000193138 | gnorm 0.317 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 79845
2022-03-07 11:12:50 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 11:12:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:14:57 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 15.148 | nll_loss 15.046 | ppl 33820.9 | wps 46108.5 | wpb 510.9 | bsz 1 | num_updates 26857 | best_loss 8.238
2022-03-07 11:14:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26857 updates
2022-03-07 11:14:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 552 @ 26857 updates, score 15.148) (writing took 2.589211555197835 seconds)
2022-03-07 11:15:00 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 11:15:00 | INFO | train | epoch 552 | loss 0.433 | nll_loss 0.129 | ppl 1.09 | wps 24369.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26857 | lr 0.000192962 | gnorm 0.318 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 79975
2022-03-07 11:15:00 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 11:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:16:49 | INFO | train_inner | epoch 553:     43 / 49 loss=0.433, nll_loss=0.129, ppl=1.09, wps=24486.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.318, loss_scale=64, train_wall=226, gb_free=8.8, wall=80084
2022-03-07 11:17:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:17:08 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 15.065 | nll_loss 14.962 | ppl 31912 | wps 46217.7 | wpb 510.9 | bsz 1 | num_updates 26906 | best_loss 8.238
2022-03-07 11:17:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26906 updates
2022-03-07 11:17:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:17:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 553 @ 26906 updates, score 15.065) (writing took 2.5122215896844864 seconds)
2022-03-07 11:17:10 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 11:17:10 | INFO | train | epoch 553 | loss 0.433 | nll_loss 0.129 | ppl 1.09 | wps 24346.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 26906 | lr 0.000192786 | gnorm 0.318 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80106
2022-03-07 11:17:10 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 11:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:18:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:19:16 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 15.17 | nll_loss 15.068 | ppl 34338.4 | wps 46227.2 | wpb 510.9 | bsz 1 | num_updates 26954 | best_loss 8.238
2022-03-07 11:19:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26954 updates
2022-03-07 11:19:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 554 @ 26954 updates, score 15.17) (writing took 2.60793742723763 seconds)
2022-03-07 11:19:19 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 11:19:19 | INFO | train | epoch 554 | loss 0.432 | nll_loss 0.128 | ppl 1.09 | wps 24264.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 26954 | lr 0.000192614 | gnorm 0.317 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 80234
2022-03-07 11:19:19 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 11:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:16 | INFO | train_inner | epoch 555:     46 / 49 loss=0.433, nll_loss=0.129, ppl=1.09, wps=24300.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.32, loss_scale=64, train_wall=228, gb_free=8.8, wall=80351
2022-03-07 11:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:21:27 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 15.158 | nll_loss 15.054 | ppl 34015.9 | wps 46287.7 | wpb 510.9 | bsz 1 | num_updates 27003 | best_loss 8.238
2022-03-07 11:21:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27003 updates
2022-03-07 11:21:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:21:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 555 @ 27003 updates, score 15.158) (writing took 2.478209961205721 seconds)
2022-03-07 11:21:29 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 11:21:29 | INFO | train | epoch 555 | loss 0.433 | nll_loss 0.129 | ppl 1.09 | wps 24402.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27003 | lr 0.000192439 | gnorm 0.324 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80364
2022-03-07 11:21:29 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 11:21:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:23:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:23:37 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 15.165 | nll_loss 15.062 | ppl 34206.2 | wps 46822.5 | wpb 510.9 | bsz 1 | num_updates 27052 | best_loss 8.238
2022-03-07 11:23:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27052 updates
2022-03-07 11:23:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:23:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:23:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 556 @ 27052 updates, score 15.165) (writing took 2.531063862144947 seconds)
2022-03-07 11:23:39 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 11:23:39 | INFO | train | epoch 556 | loss 0.432 | nll_loss 0.128 | ppl 1.09 | wps 24362.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27052 | lr 0.000192265 | gnorm 0.319 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80495
2022-03-07 11:23:39 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 11:23:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:23:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:25:40 | INFO | train_inner | epoch 557:     49 / 49 loss=0.432, nll_loss=0.128, ppl=1.09, wps=24404.6, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=27100, lr=0.000192095, gnorm=0.32, loss_scale=64, train_wall=226, gb_free=8.8, wall=80615
2022-03-07 11:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:25:45 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 15.096 | nll_loss 14.994 | ppl 32637.2 | wps 46661.4 | wpb 510.9 | bsz 1 | num_updates 27100 | best_loss 8.238
2022-03-07 11:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27100 updates
2022-03-07 11:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 557 @ 27100 updates, score 15.096) (writing took 2.4833010975271463 seconds)
2022-03-07 11:25:47 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 11:25:47 | INFO | train | epoch 557 | loss 0.432 | nll_loss 0.128 | ppl 1.09 | wps 24357.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 27100 | lr 0.000192095 | gnorm 0.317 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 80622
2022-03-07 11:25:47 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 11:25:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:27:55 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 15.324 | nll_loss 15.222 | ppl 38222.8 | wps 46881.6 | wpb 510.9 | bsz 1 | num_updates 27149 | best_loss 8.238
2022-03-07 11:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27149 updates
2022-03-07 11:27:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:27:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:27:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 558 @ 27149 updates, score 15.324) (writing took 2.5201834104955196 seconds)
2022-03-07 11:27:58 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 11:27:58 | INFO | train | epoch 558 | loss 0.431 | nll_loss 0.127 | ppl 1.09 | wps 24341.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27149 | lr 0.000191921 | gnorm 0.316 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 80753
2022-03-07 11:27:58 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 11:27:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:30:06 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 15.138 | nll_loss 15.035 | ppl 33562.3 | wps 46429.5 | wpb 510.9 | bsz 1 | num_updates 27198 | best_loss 8.238
2022-03-07 11:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27198 updates
2022-03-07 11:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 559 @ 27198 updates, score 15.138) (writing took 2.5345304161310196 seconds)
2022-03-07 11:30:08 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 11:30:08 | INFO | train | epoch 559 | loss 0.431 | nll_loss 0.127 | ppl 1.09 | wps 24314.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27198 | lr 0.000191748 | gnorm 0.317 | loss_scale 128 | train_wall 111 | gb_free 8.8 | wall 80884
2022-03-07 11:30:09 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 11:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:30:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:30:16 | INFO | train_inner | epoch 560:      3 / 49 loss=0.431, nll_loss=0.127, ppl=1.09, wps=23497.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.316, loss_scale=64, train_wall=230, gb_free=8.8, wall=80891
2022-03-07 11:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:32:17 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 15.137 | nll_loss 15.034 | ppl 33549.8 | wps 38702.2 | wpb 510.9 | bsz 1 | num_updates 27246 | best_loss 8.238
2022-03-07 11:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27246 updates
2022-03-07 11:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 560 @ 27246 updates, score 15.137) (writing took 2.4914608746767044 seconds)
2022-03-07 11:32:19 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 11:32:19 | INFO | train | epoch 560 | loss 0.431 | nll_loss 0.127 | ppl 1.09 | wps 23836 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27246 | lr 0.000191579 | gnorm 0.315 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 81014
2022-03-07 11:32:19 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 11:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:34:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:24 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 15.15 | nll_loss 15.048 | ppl 33867.2 | wps 46987.5 | wpb 510.9 | bsz 1 | num_updates 27295 | best_loss 8.238
2022-03-07 11:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27295 updates
2022-03-07 11:34:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:34:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:34:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 561 @ 27295 updates, score 15.15) (writing took 2.48023440875113 seconds)
2022-03-07 11:34:27 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 11:34:27 | INFO | train | epoch 561 | loss 0.431 | nll_loss 0.128 | ppl 1.09 | wps 24859.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27295 | lr 0.000191407 | gnorm 0.318 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 81142
2022-03-07 11:34:27 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 11:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:34:39 | INFO | train_inner | epoch 562:      5 / 49 loss=0.431, nll_loss=0.127, ppl=1.09, wps=24627.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.316, loss_scale=64, train_wall=224, gb_free=8.8, wall=81155
2022-03-07 11:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:36:35 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 15.233 | nll_loss 15.131 | ppl 35886.6 | wps 46729 | wpb 510.9 | bsz 1 | num_updates 27343 | best_loss 8.238
2022-03-07 11:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27343 updates
2022-03-07 11:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 562 @ 27343 updates, score 15.233) (writing took 2.484568001702428 seconds)
2022-03-07 11:36:37 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 11:36:37 | INFO | train | epoch 562 | loss 0.431 | nll_loss 0.127 | ppl 1.09 | wps 23874.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27343 | lr 0.000191239 | gnorm 0.319 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81272
2022-03-07 11:36:37 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 11:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:38:45 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 15.204 | nll_loss 15.102 | ppl 35168.9 | wps 46850.9 | wpb 510.9 | bsz 1 | num_updates 27392 | best_loss 8.238
2022-03-07 11:38:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27392 updates
2022-03-07 11:38:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:38:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 563 @ 27392 updates, score 15.204) (writing took 2.5058923810720444 seconds)
2022-03-07 11:38:47 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 11:38:47 | INFO | train | epoch 563 | loss 0.431 | nll_loss 0.127 | ppl 1.09 | wps 24417.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27392 | lr 0.000191068 | gnorm 0.318 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 81403
2022-03-07 11:38:47 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 11:38:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:39:07 | INFO | train_inner | epoch 564:      8 / 49 loss=0.43, nll_loss=0.127, ppl=1.09, wps=24214.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.319, loss_scale=32, train_wall=229, gb_free=8.8, wall=81423
2022-03-07 11:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:40:53 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 15.128 | nll_loss 15.025 | ppl 33344.6 | wps 47011.8 | wpb 510.9 | bsz 1 | num_updates 27441 | best_loss 8.238
2022-03-07 11:40:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27441 updates
2022-03-07 11:40:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:40:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:40:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 564 @ 27441 updates, score 15.128) (writing took 2.4876849688589573 seconds)
2022-03-07 11:40:55 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 11:40:55 | INFO | train | epoch 564 | loss 0.43 | nll_loss 0.126 | ppl 1.09 | wps 24842.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27441 | lr 0.000190897 | gnorm 0.313 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 81531
2022-03-07 11:40:55 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 11:40:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:42:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:03 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 15.103 | nll_loss 14.999 | ppl 32754 | wps 47027.5 | wpb 510.9 | bsz 1 | num_updates 27490 | best_loss 8.238
2022-03-07 11:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27490 updates
2022-03-07 11:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:43:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 565 @ 27490 updates, score 15.103) (writing took 2.475114958360791 seconds)
2022-03-07 11:43:06 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 11:43:06 | INFO | train | epoch 565 | loss 0.429 | nll_loss 0.126 | ppl 1.09 | wps 24407 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27490 | lr 0.000190727 | gnorm 0.311 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 81661
2022-03-07 11:43:06 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 11:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:43:31 | INFO | train_inner | epoch 566:     10 / 49 loss=0.43, nll_loss=0.126, ppl=1.09, wps=24652.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.312, loss_scale=64, train_wall=224, gb_free=8.8, wall=81686
2022-03-07 11:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:45:14 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 15.13 | nll_loss 15.028 | ppl 33412.9 | wps 46763 | wpb 510.9 | bsz 1 | num_updates 27539 | best_loss 8.238
2022-03-07 11:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27539 updates
2022-03-07 11:45:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 566 @ 27539 updates, score 15.13) (writing took 2.532527767121792 seconds)
2022-03-07 11:45:16 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 11:45:16 | INFO | train | epoch 566 | loss 0.43 | nll_loss 0.127 | ppl 1.09 | wps 24344.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27539 | lr 0.000190557 | gnorm 0.316 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 81791
2022-03-07 11:45:16 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 11:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:47:22 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 15.046 | nll_loss 14.943 | ppl 31490.2 | wps 41822.6 | wpb 510.9 | bsz 1 | num_updates 27587 | best_loss 8.238
2022-03-07 11:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27587 updates
2022-03-07 11:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:47:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 567 @ 27587 updates, score 15.046) (writing took 2.668998459354043 seconds)
2022-03-07 11:47:25 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 11:47:25 | INFO | train | epoch 567 | loss 0.429 | nll_loss 0.126 | ppl 1.09 | wps 24204.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27587 | lr 0.000190392 | gnorm 0.311 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 81920
2022-03-07 11:47:25 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 11:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:47:59 | INFO | train_inner | epoch 568:     13 / 49 loss=0.429, nll_loss=0.126, ppl=1.09, wps=24181.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.313, loss_scale=64, train_wall=228, gb_free=8.8, wall=81954
2022-03-07 11:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:49:32 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 15.13 | nll_loss 15.027 | ppl 33380.4 | wps 46612 | wpb 510.9 | bsz 1 | num_updates 27636 | best_loss 8.238
2022-03-07 11:49:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27636 updates
2022-03-07 11:49:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:49:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 568 @ 27636 updates, score 15.13) (writing took 2.4832761865109205 seconds)
2022-03-07 11:49:34 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 11:49:34 | INFO | train | epoch 568 | loss 0.429 | nll_loss 0.126 | ppl 1.09 | wps 24516.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27636 | lr 0.000190223 | gnorm 0.314 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 82049
2022-03-07 11:49:34 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 11:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:51:42 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 15.219 | nll_loss 15.118 | ppl 35564.8 | wps 46741.5 | wpb 510.9 | bsz 1 | num_updates 27685 | best_loss 8.238
2022-03-07 11:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27685 updates
2022-03-07 11:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:51:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:51:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 569 @ 27685 updates, score 15.219) (writing took 2.531582711264491 seconds)
2022-03-07 11:51:45 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 11:51:45 | INFO | train | epoch 569 | loss 0.429 | nll_loss 0.126 | ppl 1.09 | wps 24405.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27685 | lr 0.000190054 | gnorm 0.315 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 82180
2022-03-07 11:51:45 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 11:51:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:52:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:52:24 | INFO | train_inner | epoch 570:     16 / 49 loss=0.429, nll_loss=0.126, ppl=1.09, wps=24416.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.315, loss_scale=64, train_wall=227, gb_free=8.8, wall=82220
2022-03-07 11:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:53:52 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 15.142 | nll_loss 15.039 | ppl 33674.9 | wps 46550.1 | wpb 510.9 | bsz 1 | num_updates 27733 | best_loss 8.238
2022-03-07 11:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27733 updates
2022-03-07 11:53:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:53:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:53:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 570 @ 27733 updates, score 15.142) (writing took 2.4757059048861265 seconds)
2022-03-07 11:53:55 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 11:53:55 | INFO | train | epoch 570 | loss 0.429 | nll_loss 0.126 | ppl 1.09 | wps 23884 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27733 | lr 0.00018989 | gnorm 0.314 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 82310
2022-03-07 11:53:55 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 11:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:56:00 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 15.12 | nll_loss 15.017 | ppl 33155.1 | wps 46742.2 | wpb 510.9 | bsz 1 | num_updates 27782 | best_loss 8.238
2022-03-07 11:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27782 updates
2022-03-07 11:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:56:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 571 @ 27782 updates, score 15.12) (writing took 2.495528858155012 seconds)
2022-03-07 11:56:03 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 11:56:03 | INFO | train | epoch 571 | loss 0.428 | nll_loss 0.125 | ppl 1.09 | wps 24894.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27782 | lr 0.000189722 | gnorm 0.312 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 82438
2022-03-07 11:56:03 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 11:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:56:50 | INFO | train_inner | epoch 572:     18 / 49 loss=0.429, nll_loss=0.125, ppl=1.09, wps=24467.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.313, loss_scale=64, train_wall=226, gb_free=8.8, wall=82485
2022-03-07 11:57:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 11:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:58:10 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 15.102 | nll_loss 14.999 | ppl 32734 | wps 46821.9 | wpb 510.9 | bsz 1 | num_updates 27830 | best_loss 8.238
2022-03-07 11:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27830 updates
2022-03-07 11:58:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 11:58:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 572 @ 27830 updates, score 15.102) (writing took 2.5363308172672987 seconds)
2022-03-07 11:58:13 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 11:58:13 | INFO | train | epoch 572 | loss 0.429 | nll_loss 0.125 | ppl 1.09 | wps 23908.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27830 | lr 0.000189559 | gnorm 0.313 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 82568
2022-03-07 11:58:13 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 11:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:21 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 15.146 | nll_loss 15.045 | ppl 33795.6 | wps 46711.5 | wpb 510.9 | bsz 1 | num_updates 27879 | best_loss 8.238
2022-03-07 12:00:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27879 updates
2022-03-07 12:00:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:00:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 573 @ 27879 updates, score 15.146) (writing took 2.468128127977252 seconds)
2022-03-07 12:00:23 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 12:00:23 | INFO | train | epoch 573 | loss 0.428 | nll_loss 0.125 | ppl 1.09 | wps 24393.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27879 | lr 0.000189392 | gnorm 0.312 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 82698
2022-03-07 12:00:23 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 12:00:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:01:15 | INFO | train_inner | epoch 574:     21 / 49 loss=0.428, nll_loss=0.125, ppl=1.09, wps=24410.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.313, loss_scale=64, train_wall=227, gb_free=8.8, wall=82751
2022-03-07 12:02:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:02:29 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 15.023 | nll_loss 14.92 | ppl 30992.9 | wps 46848.2 | wpb 510.9 | bsz 1 | num_updates 27928 | best_loss 8.238
2022-03-07 12:02:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27928 updates
2022-03-07 12:02:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:02:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 574 @ 27928 updates, score 15.023) (writing took 2.4678531400859356 seconds)
2022-03-07 12:02:31 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 12:02:31 | INFO | train | epoch 574 | loss 0.428 | nll_loss 0.125 | ppl 1.09 | wps 24823.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 27928 | lr 0.000189226 | gnorm 0.313 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 82826
2022-03-07 12:02:31 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 12:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:03:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:04:38 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 15.109 | nll_loss 15.008 | ppl 32944.6 | wps 46463.6 | wpb 510.9 | bsz 1 | num_updates 27976 | best_loss 8.238
2022-03-07 12:04:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27976 updates
2022-03-07 12:04:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:04:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:04:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 575 @ 27976 updates, score 15.109) (writing took 2.529435385018587 seconds)
2022-03-07 12:04:41 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 12:04:41 | INFO | train | epoch 575 | loss 0.428 | nll_loss 0.124 | ppl 1.09 | wps 23953.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 27976 | lr 0.000189063 | gnorm 0.312 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 82956
2022-03-07 12:04:41 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 12:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:41 | INFO | train_inner | epoch 576:     24 / 49 loss=0.428, nll_loss=0.124, ppl=1.09, wps=24402.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.312, loss_scale=64, train_wall=227, gb_free=8.8, wall=83016
2022-03-07 12:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:06:49 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 15.147 | nll_loss 15.045 | ppl 33813.6 | wps 46960.8 | wpb 510.9 | bsz 1 | num_updates 28025 | best_loss 8.238
2022-03-07 12:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28025 updates
2022-03-07 12:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:06:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 576 @ 28025 updates, score 15.147) (writing took 2.485168172046542 seconds)
2022-03-07 12:06:51 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 12:06:51 | INFO | train | epoch 576 | loss 0.428 | nll_loss 0.125 | ppl 1.09 | wps 24416.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28025 | lr 0.000188898 | gnorm 0.315 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 83086
2022-03-07 12:06:51 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 12:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:08:59 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 15.083 | nll_loss 14.98 | ppl 32313.5 | wps 38493.1 | wpb 510.9 | bsz 1 | num_updates 28074 | best_loss 8.238
2022-03-07 12:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28074 updates
2022-03-07 12:08:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:09:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 577 @ 28074 updates, score 15.083) (writing took 2.5159502644091845 seconds)
2022-03-07 12:09:02 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 12:09:02 | INFO | train | epoch 577 | loss 0.427 | nll_loss 0.124 | ppl 1.09 | wps 24362.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28074 | lr 0.000188733 | gnorm 0.31 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 83217
2022-03-07 12:09:02 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 12:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:09:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:10:09 | INFO | train_inner | epoch 578:     27 / 49 loss=0.428, nll_loss=0.125, ppl=1.09, wps=24238.2, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.311, loss_scale=64, train_wall=228, gb_free=8.8, wall=83284
2022-03-07 12:11:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:11:07 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 15.172 | nll_loss 15.071 | ppl 34428.8 | wps 46789.7 | wpb 510.9 | bsz 1 | num_updates 28122 | best_loss 8.238
2022-03-07 12:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28122 updates
2022-03-07 12:11:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:11:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 578 @ 28122 updates, score 15.172) (writing took 2.518179703503847 seconds)
2022-03-07 12:11:10 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 12:11:10 | INFO | train | epoch 578 | loss 0.427 | nll_loss 0.124 | ppl 1.09 | wps 24332 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 28122 | lr 0.000188572 | gnorm 0.309 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 83345
2022-03-07 12:11:10 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 12:11:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:13:17 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 15.158 | nll_loss 15.056 | ppl 34057.3 | wps 46638.3 | wpb 510.9 | bsz 1 | num_updates 28171 | best_loss 8.238
2022-03-07 12:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28171 updates
2022-03-07 12:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 579 @ 28171 updates, score 15.158) (writing took 2.4875223767012358 seconds)
2022-03-07 12:13:20 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 12:13:20 | INFO | train | epoch 579 | loss 0.427 | nll_loss 0.124 | ppl 1.09 | wps 24392.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28171 | lr 0.000188408 | gnorm 0.312 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 83475
2022-03-07 12:13:20 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 12:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:14:32 | INFO | train_inner | epoch 580:     29 / 49 loss=0.427, nll_loss=0.124, ppl=1.09, wps=24624.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.311, loss_scale=64, train_wall=225, gb_free=8.8, wall=83547
2022-03-07 12:15:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:28 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 15.094 | nll_loss 14.991 | ppl 32565.5 | wps 46921 | wpb 510.9 | bsz 1 | num_updates 28219 | best_loss 8.238
2022-03-07 12:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28219 updates
2022-03-07 12:15:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 580 @ 28219 updates, score 15.094) (writing took 2.4755784943699837 seconds)
2022-03-07 12:15:30 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 12:15:30 | INFO | train | epoch 580 | loss 0.427 | nll_loss 0.124 | ppl 1.09 | wps 23849 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28219 | lr 0.000188247 | gnorm 0.314 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 83605
2022-03-07 12:15:30 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 12:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:17:36 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 15.121 | nll_loss 15.017 | ppl 33163.9 | wps 46466.3 | wpb 510.9 | bsz 1 | num_updates 28268 | best_loss 8.238
2022-03-07 12:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28268 updates
2022-03-07 12:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 581 @ 28268 updates, score 15.121) (writing took 2.5391405411064625 seconds)
2022-03-07 12:17:39 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 12:17:39 | INFO | train | epoch 581 | loss 0.427 | nll_loss 0.124 | ppl 1.09 | wps 24749.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28268 | lr 0.000188084 | gnorm 0.311 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 83734
2022-03-07 12:17:39 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 12:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:01 | INFO | train_inner | epoch 582:     32 / 49 loss=0.427, nll_loss=0.124, ppl=1.09, wps=24173.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.311, loss_scale=64, train_wall=229, gb_free=8.8, wall=83816
2022-03-07 12:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:46 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 15.008 | nll_loss 14.905 | ppl 30672 | wps 46827.5 | wpb 510.9 | bsz 1 | num_updates 28317 | best_loss 8.238
2022-03-07 12:19:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28317 updates
2022-03-07 12:19:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:19:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:19:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 582 @ 28317 updates, score 15.008) (writing took 2.4790880419313908 seconds)
2022-03-07 12:19:49 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 12:19:49 | INFO | train | epoch 582 | loss 0.427 | nll_loss 0.124 | ppl 1.09 | wps 24410.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28317 | lr 0.000187921 | gnorm 0.31 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 83864
2022-03-07 12:19:49 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 12:19:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:20:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:57 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 15.126 | nll_loss 15.023 | ppl 33294.8 | wps 46740.7 | wpb 510.9 | bsz 1 | num_updates 28365 | best_loss 8.238
2022-03-07 12:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28365 updates
2022-03-07 12:21:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 583 @ 28365 updates, score 15.126) (writing took 2.4919792767614126 seconds)
2022-03-07 12:21:59 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 12:21:59 | INFO | train | epoch 583 | loss 0.426 | nll_loss 0.123 | ppl 1.09 | wps 23854.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28365 | lr 0.000187762 | gnorm 0.312 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 83995
2022-03-07 12:21:59 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 12:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:23:27 | INFO | train_inner | epoch 584:     35 / 49 loss=0.427, nll_loss=0.124, ppl=1.09, wps=24391.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.312, loss_scale=64, train_wall=227, gb_free=8.8, wall=84082
2022-03-07 12:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:06 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 15.148 | nll_loss 15.045 | ppl 33812.8 | wps 39273.7 | wpb 510.9 | bsz 1 | num_updates 28414 | best_loss 8.238
2022-03-07 12:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28414 updates
2022-03-07 12:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:24:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:24:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 584 @ 28414 updates, score 15.148) (writing took 2.7057280894368887 seconds)
2022-03-07 12:24:09 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 12:24:09 | INFO | train | epoch 584 | loss 0.426 | nll_loss 0.124 | ppl 1.09 | wps 24572.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28414 | lr 0.0001876 | gnorm 0.31 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 84124
2022-03-07 12:24:09 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 12:24:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:26:16 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 15.151 | nll_loss 15.048 | ppl 33883.7 | wps 46858.7 | wpb 510.9 | bsz 1 | num_updates 28463 | best_loss 8.238
2022-03-07 12:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28463 updates
2022-03-07 12:26:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:26:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 585 @ 28463 updates, score 15.151) (writing took 2.4739250652492046 seconds)
2022-03-07 12:26:18 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 12:26:18 | INFO | train | epoch 585 | loss 0.425 | nll_loss 0.123 | ppl 1.09 | wps 24556.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28463 | lr 0.000187439 | gnorm 0.305 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 84253
2022-03-07 12:26:18 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 12:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:26:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:27:55 | INFO | train_inner | epoch 586:     38 / 49 loss=0.426, nll_loss=0.123, ppl=1.09, wps=24163, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.308, loss_scale=64, train_wall=228, gb_free=8.8, wall=84350
2022-03-07 12:28:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:28:26 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 15.06 | nll_loss 14.958 | ppl 31823.1 | wps 47121.4 | wpb 510.9 | bsz 1 | num_updates 28510 | best_loss 8.238
2022-03-07 12:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28510 updates
2022-03-07 12:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 586 @ 28510 updates, score 15.06) (writing took 2.4602683018893003 seconds)
2022-03-07 12:28:28 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 12:28:28 | INFO | train | epoch 586 | loss 0.426 | nll_loss 0.123 | ppl 1.09 | wps 23394.4 | ups 0.36 | wpb 64829.4 | bsz 126.6 | num_updates 28510 | lr 0.000187284 | gnorm 0.313 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 84384
2022-03-07 12:28:28 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 12:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:30:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:30:36 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 15.173 | nll_loss 15.071 | ppl 34427.3 | wps 46601.6 | wpb 510.9 | bsz 1 | num_updates 28559 | best_loss 8.238
2022-03-07 12:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28559 updates
2022-03-07 12:30:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:30:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 587 @ 28559 updates, score 15.173) (writing took 2.5700761433690786 seconds)
2022-03-07 12:30:39 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 12:30:39 | INFO | train | epoch 587 | loss 0.426 | nll_loss 0.123 | ppl 1.09 | wps 24415.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28559 | lr 0.000187124 | gnorm 0.31 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 84514
2022-03-07 12:30:39 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 12:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:32:21 | INFO | train_inner | epoch 588:     41 / 49 loss=0.426, nll_loss=0.123, ppl=1.09, wps=24435.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.31, loss_scale=32, train_wall=227, gb_free=8.8, wall=84616
2022-03-07 12:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:32:44 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 15.19 | nll_loss 15.088 | ppl 34834.2 | wps 46579.3 | wpb 510.9 | bsz 1 | num_updates 28608 | best_loss 8.238
2022-03-07 12:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28608 updates
2022-03-07 12:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 588 @ 28608 updates, score 15.19) (writing took 2.5071407090872526 seconds)
2022-03-07 12:32:47 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 12:32:47 | INFO | train | epoch 588 | loss 0.425 | nll_loss 0.122 | ppl 1.09 | wps 24820.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28608 | lr 0.000186963 | gnorm 0.307 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 84642
2022-03-07 12:32:47 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 12:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:55 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 15.107 | nll_loss 15.004 | ppl 32852.8 | wps 46752 | wpb 510.9 | bsz 1 | num_updates 28657 | best_loss 8.238
2022-03-07 12:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28657 updates
2022-03-07 12:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:34:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 589 @ 28657 updates, score 15.107) (writing took 2.4882492627948523 seconds)
2022-03-07 12:34:57 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 12:34:57 | INFO | train | epoch 589 | loss 0.425 | nll_loss 0.122 | ppl 1.09 | wps 24351.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28657 | lr 0.000186803 | gnorm 0.308 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 84772
2022-03-07 12:34:57 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 12:34:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:36:46 | INFO | train_inner | epoch 590:     43 / 49 loss=0.425, nll_loss=0.122, ppl=1.09, wps=24406.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.307, loss_scale=64, train_wall=227, gb_free=8.8, wall=84882
2022-03-07 12:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:37:05 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 15.027 | nll_loss 14.923 | ppl 31069.5 | wps 47193 | wpb 510.9 | bsz 1 | num_updates 28706 | best_loss 8.238
2022-03-07 12:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28706 updates
2022-03-07 12:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 590 @ 28706 updates, score 15.027) (writing took 2.5088579822331667 seconds)
2022-03-07 12:37:07 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 12:37:07 | INFO | train | epoch 590 | loss 0.424 | nll_loss 0.122 | ppl 1.09 | wps 24414.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28706 | lr 0.000186644 | gnorm 0.306 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 84902
2022-03-07 12:37:07 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 12:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:39:13 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 15.096 | nll_loss 14.995 | ppl 32653.7 | wps 46760.6 | wpb 510.9 | bsz 1 | num_updates 28755 | best_loss 8.238
2022-03-07 12:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28755 updates
2022-03-07 12:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:39:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 591 @ 28755 updates, score 15.096) (writing took 2.531995104625821 seconds)
2022-03-07 12:39:15 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 12:39:15 | INFO | train | epoch 591 | loss 0.425 | nll_loss 0.122 | ppl 1.09 | wps 24811 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28755 | lr 0.000186485 | gnorm 0.308 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85031
2022-03-07 12:39:15 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 12:39:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:39:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:41:13 | INFO | train_inner | epoch 592:     46 / 49 loss=0.424, nll_loss=0.122, ppl=1.09, wps=24377.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.308, loss_scale=64, train_wall=227, gb_free=8.8, wall=85148
2022-03-07 12:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:41:23 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 15.177 | nll_loss 15.076 | ppl 34547 | wps 46413.4 | wpb 510.9 | bsz 1 | num_updates 28803 | best_loss 8.238
2022-03-07 12:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28803 updates
2022-03-07 12:41:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 592 @ 28803 updates, score 15.177) (writing took 2.4521334916353226 seconds)
2022-03-07 12:41:26 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 12:41:26 | INFO | train | epoch 592 | loss 0.424 | nll_loss 0.121 | ppl 1.09 | wps 23835.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28803 | lr 0.000186329 | gnorm 0.307 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 85161
2022-03-07 12:41:26 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 12:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:34 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 15.227 | nll_loss 15.125 | ppl 35741.5 | wps 46572.7 | wpb 510.9 | bsz 1 | num_updates 28852 | best_loss 8.238
2022-03-07 12:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28852 updates
2022-03-07 12:43:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 593 @ 28852 updates, score 15.227) (writing took 2.5532024782150984 seconds)
2022-03-07 12:43:36 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 12:43:36 | INFO | train | epoch 593 | loss 0.424 | nll_loss 0.122 | ppl 1.09 | wps 24414.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28852 | lr 0.000186171 | gnorm 0.307 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 85291
2022-03-07 12:43:36 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 12:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:45:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:45:38 | INFO | train_inner | epoch 594:     49 / 49 loss=0.424, nll_loss=0.122, ppl=1.09, wps=24264.9, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=28900, lr=0.000186016, gnorm=0.308, loss_scale=64, train_wall=227, gb_free=8.8, wall=85414
2022-03-07 12:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:45:44 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 15.07 | nll_loss 14.967 | ppl 32022.4 | wps 38454 | wpb 510.9 | bsz 1 | num_updates 28900 | best_loss 8.238
2022-03-07 12:45:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28900 updates
2022-03-07 12:45:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 594 @ 28900 updates, score 15.07) (writing took 2.549362424761057 seconds)
2022-03-07 12:45:47 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 12:45:47 | INFO | train | epoch 594 | loss 0.424 | nll_loss 0.122 | ppl 1.09 | wps 23816.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 28900 | lr 0.000186016 | gnorm 0.306 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 85422
2022-03-07 12:45:47 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 12:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:47:52 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 15.165 | nll_loss 15.063 | ppl 34236.3 | wps 46144.4 | wpb 510.9 | bsz 1 | num_updates 28949 | best_loss 8.238
2022-03-07 12:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28949 updates
2022-03-07 12:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 595 @ 28949 updates, score 15.165) (writing took 2.456591984257102 seconds)
2022-03-07 12:47:55 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 12:47:55 | INFO | train | epoch 595 | loss 0.424 | nll_loss 0.122 | ppl 1.09 | wps 24839.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28949 | lr 0.000185859 | gnorm 0.31 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85550
2022-03-07 12:47:55 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 12:47:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:50:03 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 15.164 | nll_loss 15.064 | ppl 34263.8 | wps 46984.7 | wpb 510.9 | bsz 1 | num_updates 28998 | best_loss 8.238
2022-03-07 12:50:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 28998 updates
2022-03-07 12:50:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:50:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 596 @ 28998 updates, score 15.164) (writing took 2.486254919320345 seconds)
2022-03-07 12:50:05 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 12:50:05 | INFO | train | epoch 596 | loss 0.424 | nll_loss 0.121 | ppl 1.09 | wps 24393.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 28998 | lr 0.000185702 | gnorm 0.306 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 85680
2022-03-07 12:50:05 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 12:50:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:10 | INFO | train_inner | epoch 597:      2 / 49 loss=0.424, nll_loss=0.122, ppl=1.09, wps=23884, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.308, loss_scale=64, train_wall=225, gb_free=8.8, wall=85685
2022-03-07 12:50:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:52:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:52:13 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 15.096 | nll_loss 14.994 | ppl 32627.7 | wps 47071.4 | wpb 510.9 | bsz 1 | num_updates 29046 | best_loss 8.238
2022-03-07 12:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29046 updates
2022-03-07 12:52:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:52:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:52:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 597 @ 29046 updates, score 15.096) (writing took 2.5652494616806507 seconds)
2022-03-07 12:52:16 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 12:52:16 | INFO | train | epoch 597 | loss 0.423 | nll_loss 0.121 | ppl 1.09 | wps 23852.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29046 | lr 0.000185548 | gnorm 0.305 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 85811
2022-03-07 12:52:16 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 12:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:54:21 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 15.063 | nll_loss 14.96 | ppl 31866.6 | wps 46779.1 | wpb 510.9 | bsz 1 | num_updates 29095 | best_loss 8.238
2022-03-07 12:54:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29095 updates
2022-03-07 12:54:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:54:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:54:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 598 @ 29095 updates, score 15.063) (writing took 2.4366782419383526 seconds)
2022-03-07 12:54:24 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 12:54:24 | INFO | train | epoch 598 | loss 0.424 | nll_loss 0.122 | ppl 1.09 | wps 24810.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29095 | lr 0.000185392 | gnorm 0.308 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 85939
2022-03-07 12:54:24 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 12:54:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:54:36 | INFO | train_inner | epoch 599:      5 / 49 loss=0.423, nll_loss=0.121, ppl=1.09, wps=24370.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.307, loss_scale=64, train_wall=227, gb_free=8.8, wall=85951
2022-03-07 12:56:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 12:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:56:32 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 15.262 | nll_loss 15.162 | ppl 36657.8 | wps 46413.2 | wpb 510.9 | bsz 1 | num_updates 29143 | best_loss 8.238
2022-03-07 12:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29143 updates
2022-03-07 12:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:56:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 599 @ 29143 updates, score 15.262) (writing took 2.4821536280214787 seconds)
2022-03-07 12:56:34 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 12:56:34 | INFO | train | epoch 599 | loss 0.423 | nll_loss 0.121 | ppl 1.09 | wps 23856.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29143 | lr 0.000185239 | gnorm 0.304 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 86069
2022-03-07 12:56:34 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 12:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:58:42 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 15.068 | nll_loss 14.966 | ppl 32014.3 | wps 46833.4 | wpb 510.9 | bsz 1 | num_updates 29192 | best_loss 8.238
2022-03-07 12:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29192 updates
2022-03-07 12:58:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:58:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 12:58:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 600 @ 29192 updates, score 15.068) (writing took 2.443518441170454 seconds)
2022-03-07 12:58:44 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 12:58:44 | INFO | train | epoch 600 | loss 0.423 | nll_loss 0.121 | ppl 1.09 | wps 24383.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29192 | lr 0.000185084 | gnorm 0.305 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 86200
2022-03-07 12:58:44 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 12:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:05 | INFO | train_inner | epoch 601:      8 / 49 loss=0.423, nll_loss=0.121, ppl=1.09, wps=24186.1, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.305, loss_scale=64, train_wall=229, gb_free=8.8, wall=86220
2022-03-07 13:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:00:52 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 15.172 | nll_loss 15.071 | ppl 34423.2 | wps 38150.1 | wpb 510.9 | bsz 1 | num_updates 29241 | best_loss 8.238
2022-03-07 13:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29241 updates
2022-03-07 13:00:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:00:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:00:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 601 @ 29241 updates, score 15.172) (writing took 2.7131185699254274 seconds)
2022-03-07 13:00:54 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 13:00:54 | INFO | train | epoch 601 | loss 0.423 | nll_loss 0.121 | ppl 1.09 | wps 24465.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29241 | lr 0.000184929 | gnorm 0.307 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 86329
2022-03-07 13:00:54 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 13:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:03:01 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 15.215 | nll_loss 15.114 | ppl 35467.9 | wps 46790.6 | wpb 510.9 | bsz 1 | num_updates 29289 | best_loss 8.238
2022-03-07 13:03:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29289 updates
2022-03-07 13:03:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:03:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:03:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 602 @ 29289 updates, score 15.215) (writing took 2.467273185029626 seconds)
2022-03-07 13:03:03 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 13:03:03 | INFO | train | epoch 602 | loss 0.422 | nll_loss 0.12 | ppl 1.09 | wps 24157.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29289 | lr 0.000184777 | gnorm 0.302 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 86458
2022-03-07 13:03:03 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 13:03:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:03:31 | INFO | train_inner | epoch 603:     11 / 49 loss=0.422, nll_loss=0.12, ppl=1.09, wps=24372, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.303, loss_scale=64, train_wall=226, gb_free=8.8, wall=86486
2022-03-07 13:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:05:11 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 15.21 | nll_loss 15.109 | ppl 35332.4 | wps 46389 | wpb 510.9 | bsz 1 | num_updates 29338 | best_loss 8.238
2022-03-07 13:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29338 updates
2022-03-07 13:05:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:05:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 603 @ 29338 updates, score 15.21) (writing took 2.5184124689549208 seconds)
2022-03-07 13:05:13 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 13:05:13 | INFO | train | epoch 603 | loss 0.422 | nll_loss 0.12 | ppl 1.09 | wps 24411.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29338 | lr 0.000184623 | gnorm 0.302 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 86588
2022-03-07 13:05:13 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 13:05:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:07:21 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 15.237 | nll_loss 15.137 | ppl 36042.3 | wps 46720.3 | wpb 510.9 | bsz 1 | num_updates 29387 | best_loss 8.238
2022-03-07 13:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29387 updates
2022-03-07 13:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 604 @ 29387 updates, score 15.237) (writing took 2.522652320563793 seconds)
2022-03-07 13:07:23 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 13:07:23 | INFO | train | epoch 604 | loss 0.422 | nll_loss 0.12 | ppl 1.09 | wps 24427 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29387 | lr 0.000184469 | gnorm 0.305 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 86719
2022-03-07 13:07:23 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 13:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:07:56 | INFO | train_inner | epoch 605:     13 / 49 loss=0.422, nll_loss=0.12, ppl=1.09, wps=24460.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.303, loss_scale=128, train_wall=226, gb_free=8.8, wall=86751
2022-03-07 13:08:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:09:29 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 15.027 | nll_loss 14.924 | ppl 31092.7 | wps 46895 | wpb 510.9 | bsz 1 | num_updates 29435 | best_loss 8.238
2022-03-07 13:09:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29435 updates
2022-03-07 13:09:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 605 @ 29435 updates, score 15.027) (writing took 2.553836515173316 seconds)
2022-03-07 13:09:31 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 13:09:31 | INFO | train | epoch 605 | loss 0.422 | nll_loss 0.12 | ppl 1.09 | wps 24312.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29435 | lr 0.000184318 | gnorm 0.303 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 86847
2022-03-07 13:09:31 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 13:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:11:39 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 15.057 | nll_loss 14.956 | ppl 31773.5 | wps 46802.8 | wpb 510.9 | bsz 1 | num_updates 29484 | best_loss 8.238
2022-03-07 13:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29484 updates
2022-03-07 13:11:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 606 @ 29484 updates, score 15.057) (writing took 2.4580924455076456 seconds)
2022-03-07 13:11:42 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 13:11:42 | INFO | train | epoch 606 | loss 0.422 | nll_loss 0.12 | ppl 1.09 | wps 24382.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29484 | lr 0.000184165 | gnorm 0.302 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 86977
2022-03-07 13:11:42 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 13:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:22 | INFO | train_inner | epoch 607:     16 / 49 loss=0.422, nll_loss=0.12, ppl=1.09, wps=24404.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.303, loss_scale=64, train_wall=227, gb_free=8.8, wall=87017
2022-03-07 13:13:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:13:50 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 15.128 | nll_loss 15.026 | ppl 33367.1 | wps 45796.4 | wpb 510.9 | bsz 1 | num_updates 29532 | best_loss 8.238
2022-03-07 13:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29532 updates
2022-03-07 13:13:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:13:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:13:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 607 @ 29532 updates, score 15.128) (writing took 2.54727515950799 seconds)
2022-03-07 13:13:52 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 13:13:52 | INFO | train | epoch 607 | loss 0.421 | nll_loss 0.12 | ppl 1.09 | wps 23892.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29532 | lr 0.000184015 | gnorm 0.305 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 87107
2022-03-07 13:13:52 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 13:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:15:57 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 15.084 | nll_loss 14.983 | ppl 32377.3 | wps 47493.6 | wpb 510.9 | bsz 1 | num_updates 29581 | best_loss 8.238
2022-03-07 13:15:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29581 updates
2022-03-07 13:15:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:16:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:16:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 608 @ 29581 updates, score 15.084) (writing took 2.5265834890305996 seconds)
2022-03-07 13:16:00 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 13:16:00 | INFO | train | epoch 608 | loss 0.421 | nll_loss 0.12 | ppl 1.09 | wps 24842.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29581 | lr 0.000183863 | gnorm 0.306 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 87235
2022-03-07 13:16:00 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 13:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:16:50 | INFO | train_inner | epoch 609:     19 / 49 loss=0.421, nll_loss=0.119, ppl=1.09, wps=24201.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.306, loss_scale=64, train_wall=229, gb_free=8.8, wall=87285
2022-03-07 13:17:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:18:08 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 15.186 | nll_loss 15.087 | ppl 34800.1 | wps 46570.9 | wpb 510.9 | bsz 1 | num_updates 29629 | best_loss 8.238
2022-03-07 13:18:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29629 updates
2022-03-07 13:18:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:18:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 609 @ 29629 updates, score 15.186) (writing took 2.4687700290232897 seconds)
2022-03-07 13:18:10 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 13:18:10 | INFO | train | epoch 609 | loss 0.421 | nll_loss 0.119 | ppl 1.09 | wps 23869 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 29629 | lr 0.000183714 | gnorm 0.304 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 87366
2022-03-07 13:18:10 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 13:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:20:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:20:18 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 15.21 | nll_loss 15.109 | ppl 35342.2 | wps 47092 | wpb 510.9 | bsz 1 | num_updates 29678 | best_loss 8.238
2022-03-07 13:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29678 updates
2022-03-07 13:20:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 610 @ 29678 updates, score 15.21) (writing took 2.5088617838919163 seconds)
2022-03-07 13:20:20 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 13:20:20 | INFO | train | epoch 610 | loss 0.42 | nll_loss 0.119 | ppl 1.09 | wps 24452.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29678 | lr 0.000183562 | gnorm 0.3 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 87496
2022-03-07 13:20:20 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 13:20:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:21:15 | INFO | train_inner | epoch 611:     22 / 49 loss=0.42, nll_loss=0.119, ppl=1.09, wps=24436.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.301, loss_scale=32, train_wall=227, gb_free=8.8, wall=87550
2022-03-07 13:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:22:28 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 15.147 | nll_loss 15.046 | ppl 33828.9 | wps 44776.5 | wpb 510.9 | bsz 1 | num_updates 29727 | best_loss 8.238
2022-03-07 13:22:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29727 updates
2022-03-07 13:22:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:22:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:22:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 611 @ 29727 updates, score 15.147) (writing took 2.5122620090842247 seconds)
2022-03-07 13:22:31 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 13:22:31 | INFO | train | epoch 611 | loss 0.42 | nll_loss 0.119 | ppl 1.09 | wps 24388.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29727 | lr 0.000183411 | gnorm 0.298 | loss_scale 32 | train_wall 111 | gb_free 8.8 | wall 87626
2022-03-07 13:22:31 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 13:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:24:36 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 15.112 | nll_loss 15.01 | ppl 32995.8 | wps 46581.8 | wpb 510.9 | bsz 1 | num_updates 29776 | best_loss 8.238
2022-03-07 13:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29776 updates
2022-03-07 13:24:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:24:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 612 @ 29776 updates, score 15.112) (writing took 2.4990182891488075 seconds)
2022-03-07 13:24:38 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 13:24:38 | INFO | train | epoch 612 | loss 0.421 | nll_loss 0.119 | ppl 1.09 | wps 24869.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29776 | lr 0.00018326 | gnorm 0.301 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 87754
2022-03-07 13:24:38 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 13:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:25:41 | INFO | train_inner | epoch 613:     24 / 49 loss=0.42, nll_loss=0.119, ppl=1.09, wps=24447.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.3, loss_scale=64, train_wall=226, gb_free=8.8, wall=87816
2022-03-07 13:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:26:46 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 15.087 | nll_loss 14.986 | ppl 32450.2 | wps 47306.8 | wpb 510.9 | bsz 1 | num_updates 29825 | best_loss 8.238
2022-03-07 13:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29825 updates
2022-03-07 13:26:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:26:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:26:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 613 @ 29825 updates, score 15.087) (writing took 2.525976913049817 seconds)
2022-03-07 13:26:49 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 13:26:49 | INFO | train | epoch 613 | loss 0.42 | nll_loss 0.119 | ppl 1.09 | wps 24398.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29825 | lr 0.000183109 | gnorm 0.299 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 87884
2022-03-07 13:26:49 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 13:26:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:28:57 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 15.168 | nll_loss 15.067 | ppl 34317.9 | wps 46862.4 | wpb 510.9 | bsz 1 | num_updates 29874 | best_loss 8.238
2022-03-07 13:28:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29874 updates
2022-03-07 13:28:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 614 @ 29874 updates, score 15.168) (writing took 2.4669806845486164 seconds)
2022-03-07 13:28:59 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 13:28:59 | INFO | train | epoch 614 | loss 0.42 | nll_loss 0.119 | ppl 1.09 | wps 24402.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29874 | lr 0.000182959 | gnorm 0.304 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 88014
2022-03-07 13:28:59 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 13:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:29:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:30:06 | INFO | train_inner | epoch 615:     27 / 49 loss=0.42, nll_loss=0.119, ppl=1.09, wps=24417.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.301, loss_scale=64, train_wall=227, gb_free=8.8, wall=88081
2022-03-07 13:31:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:31:04 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 15.076 | nll_loss 14.973 | ppl 32161.1 | wps 46752.5 | wpb 510.9 | bsz 1 | num_updates 29922 | best_loss 8.238
2022-03-07 13:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29922 updates
2022-03-07 13:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:31:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 615 @ 29922 updates, score 15.076) (writing took 2.486824555322528 seconds)
2022-03-07 13:31:07 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 13:31:07 | INFO | train | epoch 615 | loss 0.42 | nll_loss 0.119 | ppl 1.09 | wps 24323.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 29922 | lr 0.000182812 | gnorm 0.299 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88142
2022-03-07 13:31:07 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 13:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:33:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:33:15 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 15.104 | nll_loss 15.003 | ppl 32829.1 | wps 46814.9 | wpb 510.9 | bsz 1 | num_updates 29971 | best_loss 8.238
2022-03-07 13:33:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29971 updates
2022-03-07 13:33:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 616 @ 29971 updates, score 15.104) (writing took 2.5529013238847256 seconds)
2022-03-07 13:33:17 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 13:33:17 | INFO | train | epoch 616 | loss 0.42 | nll_loss 0.118 | ppl 1.09 | wps 24350.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 29971 | lr 0.000182662 | gnorm 0.3 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 88273
2022-03-07 13:33:17 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 13:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:34:31 | INFO | train_inner | epoch 617:     29 / 49 loss=0.42, nll_loss=0.118, ppl=1.09, wps=24498.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.3, loss_scale=64, train_wall=226, gb_free=8.8, wall=88346
2022-03-07 13:34:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:35:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:25 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 15.11 | nll_loss 15.008 | ppl 32950.8 | wps 47349.9 | wpb 510.9 | bsz 1 | num_updates 30019 | best_loss 8.238
2022-03-07 13:35:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30019 updates
2022-03-07 13:35:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 617 @ 30019 updates, score 15.11) (writing took 2.5015445835888386 seconds)
2022-03-07 13:35:28 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 13:35:28 | INFO | train | epoch 617 | loss 0.42 | nll_loss 0.119 | ppl 1.09 | wps 23920.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30019 | lr 0.000182516 | gnorm 0.301 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 88403
2022-03-07 13:35:28 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 13:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:35 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 15.058 | nll_loss 14.957 | ppl 31799.7 | wps 38344.8 | wpb 510.9 | bsz 1 | num_updates 30068 | best_loss 8.238
2022-03-07 13:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30068 updates
2022-03-07 13:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:37:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:37:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 618 @ 30068 updates, score 15.058) (writing took 2.6554643735289574 seconds)
2022-03-07 13:37:38 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 13:37:38 | INFO | train | epoch 618 | loss 0.419 | nll_loss 0.118 | ppl 1.09 | wps 24451.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30068 | lr 0.000182368 | gnorm 0.3 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 88533
2022-03-07 13:37:38 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 13:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:38:57 | INFO | train_inner | epoch 619:     32 / 49 loss=0.42, nll_loss=0.118, ppl=1.09, wps=24368.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.302, loss_scale=64, train_wall=226, gb_free=8.8, wall=88612
2022-03-07 13:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:39:43 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 15.071 | nll_loss 14.969 | ppl 32076.2 | wps 47187.7 | wpb 510.9 | bsz 1 | num_updates 30117 | best_loss 8.238
2022-03-07 13:39:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30117 updates
2022-03-07 13:39:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:39:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:39:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 619 @ 30117 updates, score 15.071) (writing took 2.5102640967816114 seconds)
2022-03-07 13:39:45 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 13:39:45 | INFO | train | epoch 619 | loss 0.42 | nll_loss 0.118 | ppl 1.09 | wps 24882.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30117 | lr 0.000182219 | gnorm 0.301 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 88660
2022-03-07 13:39:45 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 13:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:40:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:53 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 15.057 | nll_loss 14.955 | ppl 31766.4 | wps 47087.5 | wpb 510.9 | bsz 1 | num_updates 30165 | best_loss 8.238
2022-03-07 13:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30165 updates
2022-03-07 13:41:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 620 @ 30165 updates, score 15.057) (writing took 2.496682520955801 seconds)
2022-03-07 13:41:55 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 13:41:55 | INFO | train | epoch 620 | loss 0.419 | nll_loss 0.118 | ppl 1.09 | wps 23992 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30165 | lr 0.000182074 | gnorm 0.298 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 88790
2022-03-07 13:41:55 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 13:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:43:22 | INFO | train_inner | epoch 621:     35 / 49 loss=0.419, nll_loss=0.118, ppl=1.09, wps=24534.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.299, loss_scale=64, train_wall=226, gb_free=8.8, wall=88877
2022-03-07 13:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:44:02 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 15.045 | nll_loss 14.944 | ppl 31512.8 | wps 47121 | wpb 510.9 | bsz 1 | num_updates 30214 | best_loss 8.238
2022-03-07 13:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30214 updates
2022-03-07 13:44:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 621 @ 30214 updates, score 15.045) (writing took 2.5157210994511843 seconds)
2022-03-07 13:44:05 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 13:44:05 | INFO | train | epoch 621 | loss 0.419 | nll_loss 0.118 | ppl 1.09 | wps 24512.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30214 | lr 0.000181926 | gnorm 0.299 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 88920
2022-03-07 13:44:05 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 13:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:09 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 15.049 | nll_loss 14.948 | ppl 31597 | wps 47517 | wpb 510.9 | bsz 1 | num_updates 30263 | best_loss 8.238
2022-03-07 13:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30263 updates
2022-03-07 13:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 622 @ 30263 updates, score 15.049) (writing took 2.4445959702134132 seconds)
2022-03-07 13:46:12 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 13:46:12 | INFO | train | epoch 622 | loss 0.418 | nll_loss 0.117 | ppl 1.08 | wps 24971.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 30263 | lr 0.000181779 | gnorm 0.3 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89047
2022-03-07 13:46:12 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 13:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:47:48 | INFO | train_inner | epoch 623:     38 / 49 loss=0.418, nll_loss=0.117, ppl=1.08, wps=24316.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.3, loss_scale=64, train_wall=228, gb_free=8.8, wall=89144
2022-03-07 13:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:48:19 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 15.112 | nll_loss 15.013 | ppl 33058.5 | wps 47379.6 | wpb 510.9 | bsz 1 | num_updates 30311 | best_loss 8.238
2022-03-07 13:48:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30311 updates
2022-03-07 13:48:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:48:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 623 @ 30311 updates, score 15.112) (writing took 2.516281422227621 seconds)
2022-03-07 13:48:22 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 13:48:22 | INFO | train | epoch 623 | loss 0.419 | nll_loss 0.118 | ppl 1.08 | wps 23991.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30311 | lr 0.000181635 | gnorm 0.301 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 89177
2022-03-07 13:48:22 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 13:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:29 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 15.028 | nll_loss 14.927 | ppl 31156.7 | wps 47457.2 | wpb 510.9 | bsz 1 | num_updates 30360 | best_loss 8.238
2022-03-07 13:50:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30360 updates
2022-03-07 13:50:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:50:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:50:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 624 @ 30360 updates, score 15.028) (writing took 2.5028181560337543 seconds)
2022-03-07 13:50:31 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 13:50:31 | INFO | train | epoch 624 | loss 0.419 | nll_loss 0.118 | ppl 1.08 | wps 24535.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30360 | lr 0.000181489 | gnorm 0.3 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 89306
2022-03-07 13:50:31 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 13:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:51:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:52:13 | INFO | train_inner | epoch 625:     41 / 49 loss=0.418, nll_loss=0.117, ppl=1.08, wps=24548.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.3, loss_scale=64, train_wall=226, gb_free=8.8, wall=89408
2022-03-07 13:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:52:39 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 15.119 | nll_loss 15.018 | ppl 33175 | wps 38923.4 | wpb 510.9 | bsz 1 | num_updates 30408 | best_loss 8.238
2022-03-07 13:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30408 updates
2022-03-07 13:52:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 625 @ 30408 updates, score 15.119) (writing took 2.483426220715046 seconds)
2022-03-07 13:52:41 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 13:52:41 | INFO | train | epoch 625 | loss 0.418 | nll_loss 0.117 | ppl 1.08 | wps 23957 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30408 | lr 0.000181345 | gnorm 0.3 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 89436
2022-03-07 13:52:41 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 13:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:54:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:54:46 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 15.081 | nll_loss 14.979 | ppl 32298 | wps 46907.9 | wpb 510.9 | bsz 1 | num_updates 30457 | best_loss 8.238
2022-03-07 13:54:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30457 updates
2022-03-07 13:54:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:54:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:54:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 626 @ 30457 updates, score 15.081) (writing took 2.534042241051793 seconds)
2022-03-07 13:54:49 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 13:54:49 | INFO | train | epoch 626 | loss 0.418 | nll_loss 0.117 | ppl 1.08 | wps 24874.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30457 | lr 0.000181199 | gnorm 0.3 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89564
2022-03-07 13:54:49 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 13:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:56:38 | INFO | train_inner | epoch 627:     43 / 49 loss=0.418, nll_loss=0.117, ppl=1.08, wps=24447.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.299, loss_scale=64, train_wall=226, gb_free=8.8, wall=89673
2022-03-07 13:56:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:56:56 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 15.071 | nll_loss 14.97 | ppl 32103.4 | wps 47110.3 | wpb 510.9 | bsz 1 | num_updates 30506 | best_loss 8.238
2022-03-07 13:56:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30506 updates
2022-03-07 13:56:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:56:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:56:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 627 @ 30506 updates, score 15.071) (writing took 2.5147509407252073 seconds)
2022-03-07 13:56:59 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 13:56:59 | INFO | train | epoch 627 | loss 0.417 | nll_loss 0.116 | ppl 1.08 | wps 24444.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30506 | lr 0.000181054 | gnorm 0.296 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 89694
2022-03-07 13:56:59 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 13:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 13:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:59:06 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 15.07 | nll_loss 14.969 | ppl 32065.9 | wps 47271.4 | wpb 510.9 | bsz 1 | num_updates 30554 | best_loss 8.238
2022-03-07 13:59:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30554 updates
2022-03-07 13:59:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:59:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 13:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 628 @ 30554 updates, score 15.07) (writing took 2.5201620385050774 seconds)
2022-03-07 13:59:09 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 13:59:09 | INFO | train | epoch 628 | loss 0.418 | nll_loss 0.117 | ppl 1.08 | wps 23973.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30554 | lr 0.000180911 | gnorm 0.297 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 89824
2022-03-07 13:59:09 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 13:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:01:03 | INFO | train_inner | epoch 629:     46 / 49 loss=0.417, nll_loss=0.117, ppl=1.08, wps=24486.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.297, loss_scale=64, train_wall=226, gb_free=8.8, wall=89938
2022-03-07 14:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:01:14 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 15.143 | nll_loss 15.042 | ppl 33746 | wps 47013.7 | wpb 510.9 | bsz 1 | num_updates 30603 | best_loss 8.238
2022-03-07 14:01:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30603 updates
2022-03-07 14:01:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:01:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:01:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 629 @ 30603 updates, score 15.143) (writing took 2.47881793230772 seconds)
2022-03-07 14:01:16 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 14:01:16 | INFO | train | epoch 629 | loss 0.417 | nll_loss 0.117 | ppl 1.08 | wps 24888.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30603 | lr 0.000180767 | gnorm 0.296 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 89952
2022-03-07 14:01:16 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 14:01:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:03:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:03:24 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 15.076 | nll_loss 14.975 | ppl 32194.9 | wps 46826.9 | wpb 510.9 | bsz 1 | num_updates 30651 | best_loss 8.238
2022-03-07 14:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30651 updates
2022-03-07 14:03:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:03:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 630 @ 30651 updates, score 15.076) (writing took 2.4904725067317486 seconds)
2022-03-07 14:03:27 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 14:03:27 | INFO | train | epoch 630 | loss 0.417 | nll_loss 0.116 | ppl 1.08 | wps 23898.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30651 | lr 0.000180625 | gnorm 0.299 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 90082
2022-03-07 14:03:27 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 14:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:05:30 | INFO | train_inner | epoch 631:     49 / 49 loss=0.417, nll_loss=0.117, ppl=1.08, wps=24213.2, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=30700, lr=0.000180481, gnorm=0.299, loss_scale=64, train_wall=228, gb_free=8.8, wall=90205
2022-03-07 14:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:05:34 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 15.068 | nll_loss 14.967 | ppl 32028 | wps 46562.3 | wpb 510.9 | bsz 1 | num_updates 30700 | best_loss 8.238
2022-03-07 14:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30700 updates
2022-03-07 14:05:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:05:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 631 @ 30700 updates, score 15.068) (writing took 2.5341737251728773 seconds)
2022-03-07 14:05:37 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 14:05:37 | INFO | train | epoch 631 | loss 0.417 | nll_loss 0.117 | ppl 1.08 | wps 24407 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30700 | lr 0.000180481 | gnorm 0.297 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 90212
2022-03-07 14:05:37 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 14:05:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:07:44 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 15.147 | nll_loss 15.047 | ppl 33859.3 | wps 38112.6 | wpb 510.9 | bsz 1 | num_updates 30749 | best_loss 8.238
2022-03-07 14:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30749 updates
2022-03-07 14:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 632 @ 30749 updates, score 15.147) (writing took 2.648755047470331 seconds)
2022-03-07 14:07:46 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 14:07:46 | INFO | train | epoch 632 | loss 0.417 | nll_loss 0.116 | ppl 1.08 | wps 24557.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30749 | lr 0.000180337 | gnorm 0.299 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 90341
2022-03-07 14:07:46 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 14:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:08:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:09:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:09:52 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 15.02 | nll_loss 14.918 | ppl 30950.5 | wps 46687.6 | wpb 510.9 | bsz 1 | num_updates 30797 | best_loss 8.238
2022-03-07 14:09:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30797 updates
2022-03-07 14:09:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 633 @ 30797 updates, score 15.02) (writing took 2.5582578163594007 seconds)
2022-03-07 14:09:55 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 14:09:55 | INFO | train | epoch 633 | loss 0.417 | nll_loss 0.116 | ppl 1.08 | wps 24213.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 30797 | lr 0.000180196 | gnorm 0.298 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 90470
2022-03-07 14:09:55 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 14:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:10:02 | INFO | train_inner | epoch 634:      3 / 49 loss=0.417, nll_loss=0.116, ppl=1.08, wps=23783.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.298, loss_scale=64, train_wall=225, gb_free=8.8, wall=90477
2022-03-07 14:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:12:02 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 15.128 | nll_loss 15.028 | ppl 33403.4 | wps 47278.4 | wpb 510.9 | bsz 1 | num_updates 30846 | best_loss 8.238
2022-03-07 14:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30846 updates
2022-03-07 14:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:12:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 634 @ 30846 updates, score 15.128) (writing took 2.449755545705557 seconds)
2022-03-07 14:12:05 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 14:12:05 | INFO | train | epoch 634 | loss 0.417 | nll_loss 0.116 | ppl 1.08 | wps 24459.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30846 | lr 0.000180053 | gnorm 0.298 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 90600
2022-03-07 14:12:05 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 14:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:14:12 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 15.087 | nll_loss 14.986 | ppl 32452.5 | wps 46967.1 | wpb 510.9 | bsz 1 | num_updates 30895 | best_loss 8.238
2022-03-07 14:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30895 updates
2022-03-07 14:14:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:14:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:14:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 635 @ 30895 updates, score 15.087) (writing took 2.4707237109541893 seconds)
2022-03-07 14:14:14 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 14:14:14 | INFO | train | epoch 635 | loss 0.417 | nll_loss 0.116 | ppl 1.08 | wps 24504.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30895 | lr 0.00017991 | gnorm 0.295 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 90730
2022-03-07 14:14:14 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 14:14:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:14:27 | INFO | train_inner | epoch 636:      5 / 49 loss=0.417, nll_loss=0.116, ppl=1.08, wps=24515.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=30900, lr=0.000179896, gnorm=0.296, loss_scale=64, train_wall=226, gb_free=8.8, wall=90742
2022-03-07 14:14:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:16:20 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 15.135 | nll_loss 15.034 | ppl 33539.2 | wps 47278 | wpb 510.9 | bsz 1 | num_updates 30943 | best_loss 8.238
2022-03-07 14:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30943 updates
2022-03-07 14:16:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:16:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:16:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 636 @ 30943 updates, score 15.135) (writing took 2.5311280582100153 seconds)
2022-03-07 14:16:22 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 14:16:22 | INFO | train | epoch 636 | loss 0.416 | nll_loss 0.116 | ppl 1.08 | wps 24376.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 30943 | lr 0.000179771 | gnorm 0.297 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 90857
2022-03-07 14:16:22 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 14:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:18:30 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 15.088 | nll_loss 14.987 | ppl 32482.7 | wps 47031.1 | wpb 510.9 | bsz 1 | num_updates 30992 | best_loss 8.238
2022-03-07 14:18:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 30992 updates
2022-03-07 14:18:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:18:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 637 @ 30992 updates, score 15.088) (writing took 2.4767455384135246 seconds)
2022-03-07 14:18:32 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 14:18:32 | INFO | train | epoch 637 | loss 0.416 | nll_loss 0.115 | ppl 1.08 | wps 24468.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 30992 | lr 0.000179628 | gnorm 0.296 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 90987
2022-03-07 14:18:32 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 14:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:18:52 | INFO | train_inner | epoch 638:      8 / 49 loss=0.416, nll_loss=0.116, ppl=1.08, wps=24479, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.296, loss_scale=64, train_wall=226, gb_free=8.8, wall=91007
2022-03-07 14:20:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:20:39 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 15.176 | nll_loss 15.076 | ppl 34542.2 | wps 46486.4 | wpb 510.9 | bsz 1 | num_updates 31040 | best_loss 8.238
2022-03-07 14:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31040 updates
2022-03-07 14:20:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 638 @ 31040 updates, score 15.176) (writing took 2.4860079679638147 seconds)
2022-03-07 14:20:42 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 14:20:42 | INFO | train | epoch 638 | loss 0.416 | nll_loss 0.115 | ppl 1.08 | wps 23950.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31040 | lr 0.00017949 | gnorm 0.299 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 91117
2022-03-07 14:20:42 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 14:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:47 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 15.161 | nll_loss 15.06 | ppl 34162.7 | wps 45291.2 | wpb 510.9 | bsz 1 | num_updates 31089 | best_loss 8.238
2022-03-07 14:22:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31089 updates
2022-03-07 14:22:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:22:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 639 @ 31089 updates, score 15.161) (writing took 2.716912854462862 seconds)
2022-03-07 14:22:50 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 14:22:50 | INFO | train | epoch 639 | loss 0.416 | nll_loss 0.116 | ppl 1.08 | wps 24820.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31089 | lr 0.000179348 | gnorm 0.297 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 91245
2022-03-07 14:22:50 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 14:22:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:23:19 | INFO | train_inner | epoch 640:     11 / 49 loss=0.416, nll_loss=0.116, ppl=1.08, wps=24282.7, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.298, loss_scale=64, train_wall=228, gb_free=8.8, wall=91274
2022-03-07 14:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:57 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 15.054 | nll_loss 14.953 | ppl 31723.3 | wps 46707.9 | wpb 510.9 | bsz 1 | num_updates 31138 | best_loss 8.238
2022-03-07 14:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31138 updates
2022-03-07 14:24:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 640 @ 31138 updates, score 15.054) (writing took 2.481858743354678 seconds)
2022-03-07 14:24:59 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 14:24:59 | INFO | train | epoch 640 | loss 0.415 | nll_loss 0.115 | ppl 1.08 | wps 24584.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31138 | lr 0.000179207 | gnorm 0.296 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 91374
2022-03-07 14:24:59 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 14:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:26:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:27:07 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 15.079 | nll_loss 14.978 | ppl 32277.7 | wps 46787.5 | wpb 510.9 | bsz 1 | num_updates 31186 | best_loss 8.238
2022-03-07 14:27:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31186 updates
2022-03-07 14:27:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:27:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:27:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 641 @ 31186 updates, score 15.079) (writing took 2.466522404924035 seconds)
2022-03-07 14:27:10 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 14:27:10 | INFO | train | epoch 641 | loss 0.415 | nll_loss 0.115 | ppl 1.08 | wps 23890.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31186 | lr 0.000179069 | gnorm 0.294 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 91505
2022-03-07 14:27:10 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 14:27:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:45 | INFO | train_inner | epoch 642:     14 / 49 loss=0.415, nll_loss=0.115, ppl=1.08, wps=24440.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.295, loss_scale=64, train_wall=227, gb_free=8.8, wall=91540
2022-03-07 14:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:29:18 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 15.133 | nll_loss 15.032 | ppl 33513.9 | wps 46407.3 | wpb 510.9 | bsz 1 | num_updates 31235 | best_loss 8.238
2022-03-07 14:29:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31235 updates
2022-03-07 14:29:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 642 @ 31235 updates, score 15.133) (writing took 2.5125336684286594 seconds)
2022-03-07 14:29:20 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 14:29:20 | INFO | train | epoch 642 | loss 0.415 | nll_loss 0.115 | ppl 1.08 | wps 24346.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31235 | lr 0.000178928 | gnorm 0.296 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 91635
2022-03-07 14:29:20 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 14:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:31:26 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 15.168 | nll_loss 15.067 | ppl 34331.9 | wps 46881 | wpb 510.9 | bsz 1 | num_updates 31284 | best_loss 8.238
2022-03-07 14:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31284 updates
2022-03-07 14:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 643 @ 31284 updates, score 15.168) (writing took 2.48150154389441 seconds)
2022-03-07 14:31:28 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 14:31:28 | INFO | train | epoch 643 | loss 0.415 | nll_loss 0.115 | ppl 1.08 | wps 24782.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31284 | lr 0.000178788 | gnorm 0.293 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 91763
2022-03-07 14:31:28 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 14:31:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:32:13 | INFO | train_inner | epoch 644:     17 / 49 loss=0.415, nll_loss=0.115, ppl=1.08, wps=24202.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=31300, lr=0.000178743, gnorm=0.293, loss_scale=64, train_wall=229, gb_free=8.8, wall=91808
2022-03-07 14:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:33:36 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 15.138 | nll_loss 15.037 | ppl 33627.8 | wps 46297 | wpb 510.9 | bsz 1 | num_updates 31332 | best_loss 8.238
2022-03-07 14:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31332 updates
2022-03-07 14:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 644 @ 31332 updates, score 15.138) (writing took 2.4866322837769985 seconds)
2022-03-07 14:33:39 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 14:33:39 | INFO | train | epoch 644 | loss 0.415 | nll_loss 0.115 | ppl 1.08 | wps 23900.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31332 | lr 0.000178651 | gnorm 0.294 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 91894
2022-03-07 14:33:39 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 14:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:35:47 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 15.145 | nll_loss 15.044 | ppl 33788.7 | wps 46961.7 | wpb 510.9 | bsz 1 | num_updates 31381 | best_loss 8.238
2022-03-07 14:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31381 updates
2022-03-07 14:35:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:35:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 645 @ 31381 updates, score 15.145) (writing took 2.563445568084717 seconds)
2022-03-07 14:35:49 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 14:35:49 | INFO | train | epoch 645 | loss 0.415 | nll_loss 0.115 | ppl 1.08 | wps 24342.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31381 | lr 0.000178512 | gnorm 0.298 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 92024
2022-03-07 14:35:49 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 14:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:36 | INFO | train_inner | epoch 646:     19 / 49 loss=0.415, nll_loss=0.115, ppl=1.08, wps=24582.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.296, loss_scale=64, train_wall=225, gb_free=8.8, wall=92072
2022-03-07 14:37:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:37:54 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 15.169 | nll_loss 15.068 | ppl 34344.7 | wps 46667.9 | wpb 510.9 | bsz 1 | num_updates 31429 | best_loss 8.238
2022-03-07 14:37:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31429 updates
2022-03-07 14:37:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:37:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 646 @ 31429 updates, score 15.169) (writing took 2.4937152601778507 seconds)
2022-03-07 14:37:57 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 14:37:57 | INFO | train | epoch 646 | loss 0.414 | nll_loss 0.114 | ppl 1.08 | wps 24345.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31429 | lr 0.000178375 | gnorm 0.293 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 92152
2022-03-07 14:37:57 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 14:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:40:05 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 15.146 | nll_loss 15.046 | ppl 33826.4 | wps 46341 | wpb 510.9 | bsz 1 | num_updates 31478 | best_loss 8.238
2022-03-07 14:40:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31478 updates
2022-03-07 14:40:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:40:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:40:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 647 @ 31478 updates, score 15.146) (writing took 2.560958681628108 seconds)
2022-03-07 14:40:08 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 14:40:08 | INFO | train | epoch 647 | loss 0.414 | nll_loss 0.114 | ppl 1.08 | wps 24345 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31478 | lr 0.000178236 | gnorm 0.296 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 92283
2022-03-07 14:40:08 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 14:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:02 | INFO | train_inner | epoch 648:     22 / 49 loss=0.414, nll_loss=0.114, ppl=1.08, wps=24388.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.295, loss_scale=64, train_wall=227, gb_free=8.8, wall=92338
2022-03-07 14:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:42:15 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 15.086 | nll_loss 14.985 | ppl 32435.1 | wps 47238.9 | wpb 510.9 | bsz 1 | num_updates 31527 | best_loss 8.238
2022-03-07 14:42:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31527 updates
2022-03-07 14:42:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:42:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:42:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 648 @ 31527 updates, score 15.086) (writing took 2.540544217452407 seconds)
2022-03-07 14:42:18 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 14:42:18 | INFO | train | epoch 648 | loss 0.414 | nll_loss 0.114 | ppl 1.08 | wps 24369.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31527 | lr 0.000178098 | gnorm 0.292 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 92413
2022-03-07 14:42:18 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 14:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:43:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:44:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:44:25 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 15.184 | nll_loss 15.084 | ppl 34731.5 | wps 38956.8 | wpb 510.9 | bsz 1 | num_updates 31575 | best_loss 8.238
2022-03-07 14:44:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31575 updates
2022-03-07 14:44:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 649 @ 31575 updates, score 15.184) (writing took 2.6500383000820875 seconds)
2022-03-07 14:44:28 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 14:44:28 | INFO | train | epoch 649 | loss 0.414 | nll_loss 0.114 | ppl 1.08 | wps 23921.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31575 | lr 0.000177962 | gnorm 0.293 | loss_scale 64 | train_wall 110 | gb_free 8.8 | wall 92543
2022-03-07 14:44:28 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 14:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:45:31 | INFO | train_inner | epoch 650:     25 / 49 loss=0.414, nll_loss=0.114, ppl=1.08, wps=24180.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.293, loss_scale=64, train_wall=228, gb_free=8.8, wall=92606
2022-03-07 14:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:34 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 15.132 | nll_loss 15.032 | ppl 33504.4 | wps 46462 | wpb 510.9 | bsz 1 | num_updates 31624 | best_loss 8.238
2022-03-07 14:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31624 updates
2022-03-07 14:46:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:46:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:46:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 650 @ 31624 updates, score 15.132) (writing took 2.4682743307203054 seconds)
2022-03-07 14:46:36 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 14:46:36 | INFO | train | epoch 650 | loss 0.414 | nll_loss 0.114 | ppl 1.08 | wps 24752 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31624 | lr 0.000177825 | gnorm 0.293 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 92672
2022-03-07 14:46:36 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 14:46:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:48:44 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 15.181 | nll_loss 15.081 | ppl 34671.9 | wps 46860.3 | wpb 510.9 | bsz 1 | num_updates 31673 | best_loss 8.238
2022-03-07 14:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31673 updates
2022-03-07 14:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 651 @ 31673 updates, score 15.181) (writing took 2.552591096609831 seconds)
2022-03-07 14:48:47 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 14:48:47 | INFO | train | epoch 651 | loss 0.414 | nll_loss 0.114 | ppl 1.08 | wps 24423.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31673 | lr 0.000177687 | gnorm 0.296 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 92802
2022-03-07 14:48:47 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 14:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:49:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:49:56 | INFO | train_inner | epoch 652:     28 / 49 loss=0.413, nll_loss=0.114, ppl=1.08, wps=24419.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.294, loss_scale=64, train_wall=227, gb_free=8.8, wall=92872
2022-03-07 14:50:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:50:54 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 15.081 | nll_loss 14.98 | ppl 32320.4 | wps 47012.2 | wpb 510.9 | bsz 1 | num_updates 31721 | best_loss 8.238
2022-03-07 14:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31721 updates
2022-03-07 14:50:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:50:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:50:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 652 @ 31721 updates, score 15.081) (writing took 2.445803912356496 seconds)
2022-03-07 14:50:57 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 14:50:57 | INFO | train | epoch 652 | loss 0.413 | nll_loss 0.113 | ppl 1.08 | wps 23905.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31721 | lr 0.000177552 | gnorm 0.294 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 92932
2022-03-07 14:50:57 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 14:50:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:53:02 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 15.135 | nll_loss 15.034 | ppl 33561 | wps 47226.3 | wpb 510.9 | bsz 1 | num_updates 31770 | best_loss 8.238
2022-03-07 14:53:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31770 updates
2022-03-07 14:53:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:53:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 653 @ 31770 updates, score 15.135) (writing took 2.480094088241458 seconds)
2022-03-07 14:53:05 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 14:53:05 | INFO | train | epoch 653 | loss 0.413 | nll_loss 0.114 | ppl 1.08 | wps 24865 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31770 | lr 0.000177415 | gnorm 0.291 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 93060
2022-03-07 14:53:05 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 14:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:22 | INFO | train_inner | epoch 654:     30 / 49 loss=0.413, nll_loss=0.114, ppl=1.08, wps=24464.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.292, loss_scale=64, train_wall=226, gb_free=8.8, wall=93137
2022-03-07 14:54:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 14:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:55:12 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 15.041 | nll_loss 14.94 | ppl 31431.6 | wps 47215.8 | wpb 510.9 | bsz 1 | num_updates 31818 | best_loss 8.238
2022-03-07 14:55:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31818 updates
2022-03-07 14:55:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:55:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:55:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 654 @ 31818 updates, score 15.041) (writing took 2.5472402926534414 seconds)
2022-03-07 14:55:15 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 14:55:15 | INFO | train | epoch 654 | loss 0.413 | nll_loss 0.113 | ppl 1.08 | wps 23913.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 31818 | lr 0.000177282 | gnorm 0.292 | loss_scale 64 | train_wall 111 | gb_free 8.8 | wall 93190
2022-03-07 14:55:15 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 14:55:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:57:20 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 15.072 | nll_loss 14.972 | ppl 32131.8 | wps 47214.4 | wpb 510.9 | bsz 1 | num_updates 31867 | best_loss 8.238
2022-03-07 14:57:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31867 updates
2022-03-07 14:57:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:57:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 655 @ 31867 updates, score 15.072) (writing took 2.530836172401905 seconds)
2022-03-07 14:57:22 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 14:57:22 | INFO | train | epoch 655 | loss 0.413 | nll_loss 0.113 | ppl 1.08 | wps 24960.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31867 | lr 0.000177145 | gnorm 0.291 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93317
2022-03-07 14:57:22 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 14:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:58:44 | INFO | train_inner | epoch 656:     33 / 49 loss=0.413, nll_loss=0.113, ppl=1.08, wps=24728.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.291, loss_scale=64, train_wall=224, gb_free=8.8, wall=93399
2022-03-07 14:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:59:27 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 15.152 | nll_loss 15.053 | ppl 34002.6 | wps 47554.2 | wpb 510.9 | bsz 1 | num_updates 31916 | best_loss 8.238
2022-03-07 14:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31916 updates
2022-03-07 14:59:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:59:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 14:59:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 656 @ 31916 updates, score 15.152) (writing took 2.507695844396949 seconds)
2022-03-07 14:59:29 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 14:59:29 | INFO | train | epoch 656 | loss 0.413 | nll_loss 0.113 | ppl 1.08 | wps 24948.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 31916 | lr 0.000177009 | gnorm 0.291 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93445
2022-03-07 14:59:29 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 14:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:00:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:01:34 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 15.129 | nll_loss 15.029 | ppl 33426.1 | wps 46855.3 | wpb 510.9 | bsz 1 | num_updates 31964 | best_loss 8.238
2022-03-07 15:01:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31964 updates
2022-03-07 15:01:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:01:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:01:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 657 @ 31964 updates, score 15.129) (writing took 2.5509468261152506 seconds)
2022-03-07 15:01:37 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 15:01:37 | INFO | train | epoch 657 | loss 0.413 | nll_loss 0.113 | ppl 1.08 | wps 24427 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 31964 | lr 0.000176876 | gnorm 0.29 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93572
2022-03-07 15:01:37 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 15:01:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:03:06 | INFO | train_inner | epoch 658:     36 / 49 loss=0.413, nll_loss=0.113, ppl=1.08, wps=24747.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.291, loss_scale=64, train_wall=224, gb_free=8.8, wall=93661
2022-03-07 15:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:03:42 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 15.158 | nll_loss 15.06 | ppl 34150.2 | wps 46697.6 | wpb 510.9 | bsz 1 | num_updates 32013 | best_loss 8.238
2022-03-07 15:03:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32013 updates
2022-03-07 15:03:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 658 @ 32013 updates, score 15.158) (writing took 2.525167364627123 seconds)
2022-03-07 15:03:44 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 15:03:44 | INFO | train | epoch 658 | loss 0.413 | nll_loss 0.113 | ppl 1.08 | wps 24940.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32013 | lr 0.000176741 | gnorm 0.293 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93699
2022-03-07 15:03:44 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 15:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:05:49 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 15.113 | nll_loss 15.014 | ppl 33092.8 | wps 46543.7 | wpb 510.9 | bsz 1 | num_updates 32062 | best_loss 8.238
2022-03-07 15:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32062 updates
2022-03-07 15:05:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 659 @ 32062 updates, score 15.113) (writing took 2.5264971870929003 seconds)
2022-03-07 15:05:52 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 15:05:52 | INFO | train | epoch 659 | loss 0.412 | nll_loss 0.113 | ppl 1.08 | wps 24906.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32062 | lr 0.000176606 | gnorm 0.294 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 93827
2022-03-07 15:05:52 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 15:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:07:28 | INFO | train_inner | epoch 660:     39 / 49 loss=0.412, nll_loss=0.113, ppl=1.08, wps=24738.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.293, loss_scale=64, train_wall=224, gb_free=8.8, wall=93923
2022-03-07 15:07:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:07:56 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 15.187 | nll_loss 15.088 | ppl 34835.2 | wps 47148.7 | wpb 510.9 | bsz 1 | num_updates 32110 | best_loss 8.238
2022-03-07 15:07:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32110 updates
2022-03-07 15:07:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 660 @ 32110 updates, score 15.187) (writing took 2.537441598251462 seconds)
2022-03-07 15:07:59 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 15:07:59 | INFO | train | epoch 660 | loss 0.412 | nll_loss 0.112 | ppl 1.08 | wps 24489 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32110 | lr 0.000176474 | gnorm 0.291 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 93954
2022-03-07 15:07:59 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 15:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:10:04 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 15.202 | nll_loss 15.102 | ppl 35170.1 | wps 47105.3 | wpb 510.9 | bsz 1 | num_updates 32159 | best_loss 8.238
2022-03-07 15:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32159 updates
2022-03-07 15:10:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:10:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:10:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 661 @ 32159 updates, score 15.202) (writing took 2.562459262087941 seconds)
2022-03-07 15:10:06 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 15:10:06 | INFO | train | epoch 661 | loss 0.412 | nll_loss 0.113 | ppl 1.08 | wps 24975.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32159 | lr 0.000176339 | gnorm 0.292 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94081
2022-03-07 15:10:06 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 15:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:48 | INFO | train_inner | epoch 662:     41 / 49 loss=0.412, nll_loss=0.113, ppl=1.08, wps=25000.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.291, loss_scale=64, train_wall=221, gb_free=8.8, wall=94183
2022-03-07 15:12:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:12:11 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 15.089 | nll_loss 14.99 | ppl 32531.8 | wps 47168.5 | wpb 510.9 | bsz 1 | num_updates 32208 | best_loss 8.238
2022-03-07 15:12:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32208 updates
2022-03-07 15:12:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:12:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:12:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 662 @ 32208 updates, score 15.089) (writing took 2.530665758997202 seconds)
2022-03-07 15:12:14 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 15:12:14 | INFO | train | epoch 662 | loss 0.412 | nll_loss 0.113 | ppl 1.08 | wps 24966.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32208 | lr 0.000176205 | gnorm 0.291 | loss_scale 128 | train_wall 108 | gb_free 8.8 | wall 94209
2022-03-07 15:12:14 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 15:12:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:12:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:14:18 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 15.114 | nll_loss 15.015 | ppl 33106.5 | wps 47065.5 | wpb 510.9 | bsz 1 | num_updates 32256 | best_loss 8.238
2022-03-07 15:14:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32256 updates
2022-03-07 15:14:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 663 @ 32256 updates, score 15.114) (writing took 2.54347918368876 seconds)
2022-03-07 15:14:21 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 15:14:21 | INFO | train | epoch 663 | loss 0.412 | nll_loss 0.113 | ppl 1.08 | wps 24472.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32256 | lr 0.000176074 | gnorm 0.293 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94336
2022-03-07 15:14:21 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 15:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:16:10 | INFO | train_inner | epoch 664:     44 / 49 loss=0.412, nll_loss=0.113, ppl=1.08, wps=24764, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.293, loss_scale=64, train_wall=223, gb_free=8.8, wall=94445
2022-03-07 15:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:16:26 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 15.029 | nll_loss 14.929 | ppl 31184.9 | wps 47123.6 | wpb 510.9 | bsz 1 | num_updates 32305 | best_loss 8.238
2022-03-07 15:16:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32305 updates
2022-03-07 15:16:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 664 @ 32305 updates, score 15.029) (writing took 2.5139489080756903 seconds)
2022-03-07 15:16:28 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 15:16:28 | INFO | train | epoch 664 | loss 0.412 | nll_loss 0.113 | ppl 1.08 | wps 24958.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32305 | lr 0.00017594 | gnorm 0.293 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94463
2022-03-07 15:16:28 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 15:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:17:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:18:33 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 15.13 | nll_loss 15.03 | ppl 33457.4 | wps 47087.9 | wpb 510.9 | bsz 1 | num_updates 32353 | best_loss 8.238
2022-03-07 15:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32353 updates
2022-03-07 15:18:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 665 @ 32353 updates, score 15.13) (writing took 2.5278573650866747 seconds)
2022-03-07 15:18:35 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 15:18:35 | INFO | train | epoch 665 | loss 0.412 | nll_loss 0.113 | ppl 1.08 | wps 24444.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32353 | lr 0.00017581 | gnorm 0.294 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94591
2022-03-07 15:18:35 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 15:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:32 | INFO | train_inner | epoch 666:     47 / 49 loss=0.412, nll_loss=0.112, ppl=1.08, wps=24764.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.291, loss_scale=64, train_wall=223, gb_free=8.8, wall=94707
2022-03-07 15:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:20:40 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 15.16 | nll_loss 15.06 | ppl 34156.7 | wps 47227.8 | wpb 510.9 | bsz 1 | num_updates 32402 | best_loss 8.238
2022-03-07 15:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32402 updates
2022-03-07 15:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:20:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:20:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 666 @ 32402 updates, score 15.16) (writing took 2.543669844046235 seconds)
2022-03-07 15:20:43 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 15:20:43 | INFO | train | epoch 666 | loss 0.411 | nll_loss 0.112 | ppl 1.08 | wps 24975.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32402 | lr 0.000175677 | gnorm 0.288 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94718
2022-03-07 15:20:43 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 15:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:22:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:22:47 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 15.081 | nll_loss 14.982 | ppl 32359.2 | wps 47187.4 | wpb 510.9 | bsz 1 | num_updates 32451 | best_loss 8.238
2022-03-07 15:22:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32451 updates
2022-03-07 15:22:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:22:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 667 @ 32451 updates, score 15.081) (writing took 2.5345695577561855 seconds)
2022-03-07 15:22:50 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 15:22:50 | INFO | train | epoch 667 | loss 0.411 | nll_loss 0.112 | ppl 1.08 | wps 24979 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32451 | lr 0.000175544 | gnorm 0.29 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94845
2022-03-07 15:22:50 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 15:22:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:23:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:55 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 15.166 | nll_loss 15.067 | ppl 34328.8 | wps 47211.6 | wpb 510.9 | bsz 1 | num_updates 32499 | best_loss 8.238
2022-03-07 15:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32499 updates
2022-03-07 15:24:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:24:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:24:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 668 @ 32499 updates, score 15.166) (writing took 2.5278980378061533 seconds)
2022-03-07 15:24:57 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 15:24:57 | INFO | train | epoch 668 | loss 0.411 | nll_loss 0.112 | ppl 1.08 | wps 24462.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32499 | lr 0.000175414 | gnorm 0.29 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 94972
2022-03-07 15:24:57 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 15:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:25:00 | INFO | train_inner | epoch 669:      1 / 49 loss=0.411, nll_loss=0.112, ppl=1.08, wps=24082.4, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=32500, lr=0.000175412, gnorm=0.291, loss_scale=64, train_wall=222, gb_free=8.8, wall=94975
2022-03-07 15:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:27:02 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 15.149 | nll_loss 15.049 | ppl 33897.2 | wps 47161.4 | wpb 510.9 | bsz 1 | num_updates 32548 | best_loss 8.238
2022-03-07 15:27:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32548 updates
2022-03-07 15:27:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:27:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 669 @ 32548 updates, score 15.149) (writing took 2.5605276748538017 seconds)
2022-03-07 15:27:05 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 15:27:05 | INFO | train | epoch 669 | loss 0.411 | nll_loss 0.112 | ppl 1.08 | wps 24929.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32548 | lr 0.000175282 | gnorm 0.29 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95100
2022-03-07 15:27:05 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 15:27:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:29:09 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 15.137 | nll_loss 15.037 | ppl 33620.9 | wps 47243.1 | wpb 510.9 | bsz 1 | num_updates 32597 | best_loss 8.238
2022-03-07 15:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32597 updates
2022-03-07 15:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:29:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:29:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 670 @ 32597 updates, score 15.137) (writing took 2.5536826476454735 seconds)
2022-03-07 15:29:12 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 15:29:12 | INFO | train | epoch 670 | loss 0.411 | nll_loss 0.112 | ppl 1.08 | wps 24956.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32597 | lr 0.00017515 | gnorm 0.289 | loss_scale 128 | train_wall 108 | gb_free 8.8 | wall 95227
2022-03-07 15:29:12 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 15:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:29:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:29:22 | INFO | train_inner | epoch 671:      4 / 49 loss=0.411, nll_loss=0.112, ppl=1.08, wps=24734.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.289, loss_scale=64, train_wall=224, gb_free=8.8, wall=95237
2022-03-07 15:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:31:17 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 15.116 | nll_loss 15.016 | ppl 33141.6 | wps 47441.3 | wpb 510.9 | bsz 1 | num_updates 32645 | best_loss 8.238
2022-03-07 15:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32645 updates
2022-03-07 15:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:31:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:31:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 671 @ 32645 updates, score 15.116) (writing took 2.538367845118046 seconds)
2022-03-07 15:31:19 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 15:31:19 | INFO | train | epoch 671 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24441.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32645 | lr 0.000175022 | gnorm 0.288 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95354
2022-03-07 15:31:19 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 15:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:33:24 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 15.191 | nll_loss 15.093 | ppl 34950.8 | wps 47092 | wpb 510.9 | bsz 1 | num_updates 32694 | best_loss 8.238
2022-03-07 15:33:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32694 updates
2022-03-07 15:33:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:33:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:33:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 672 @ 32694 updates, score 15.191) (writing took 2.540743600577116 seconds)
2022-03-07 15:33:27 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 15:33:27 | INFO | train | epoch 672 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24962.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32694 | lr 0.00017489 | gnorm 0.286 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95482
2022-03-07 15:33:27 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 15:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:33:42 | INFO | train_inner | epoch 673:      6 / 49 loss=0.41, nll_loss=0.111, ppl=1.08, wps=24992.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=32700, lr=0.000174874, gnorm=0.287, loss_scale=64, train_wall=221, gb_free=8.8, wall=95497
2022-03-07 15:34:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:35:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:35:31 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 15.109 | nll_loss 15.01 | ppl 33003.2 | wps 47139.2 | wpb 510.9 | bsz 1 | num_updates 32742 | best_loss 8.238
2022-03-07 15:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32742 updates
2022-03-07 15:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 673 @ 32742 updates, score 15.109) (writing took 2.53568054176867 seconds)
2022-03-07 15:35:34 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 15:35:34 | INFO | train | epoch 673 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24465.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32742 | lr 0.000174762 | gnorm 0.287 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95609
2022-03-07 15:35:34 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 15:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:37:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:37:39 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 15.11 | nll_loss 15.011 | ppl 33010.4 | wps 47018.1 | wpb 510.9 | bsz 1 | num_updates 32791 | best_loss 8.238
2022-03-07 15:37:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32791 updates
2022-03-07 15:37:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 674 @ 32791 updates, score 15.11) (writing took 2.5560376811772585 seconds)
2022-03-07 15:37:41 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 15:37:41 | INFO | train | epoch 674 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24959.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32791 | lr 0.000174632 | gnorm 0.286 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95736
2022-03-07 15:37:41 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 15:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:38:03 | INFO | train_inner | epoch 675:      9 / 49 loss=0.41, nll_loss=0.111, ppl=1.08, wps=24768, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.287, loss_scale=64, train_wall=223, gb_free=8.8, wall=95759
2022-03-07 15:39:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:39:46 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 15.194 | nll_loss 15.095 | ppl 35002.4 | wps 47224.7 | wpb 510.9 | bsz 1 | num_updates 32840 | best_loss 8.238
2022-03-07 15:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32840 updates
2022-03-07 15:39:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 675 @ 32840 updates, score 15.194) (writing took 2.5276176799088717 seconds)
2022-03-07 15:39:48 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 15:39:48 | INFO | train | epoch 675 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24966 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32840 | lr 0.000174501 | gnorm 0.288 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95864
2022-03-07 15:39:48 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 15:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:41:53 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 15.078 | nll_loss 14.978 | ppl 32282.4 | wps 47157.7 | wpb 510.9 | bsz 1 | num_updates 32888 | best_loss 8.238
2022-03-07 15:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32888 updates
2022-03-07 15:41:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:41:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:41:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 676 @ 32888 updates, score 15.078) (writing took 2.5231331288814545 seconds)
2022-03-07 15:41:56 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 15:41:56 | INFO | train | epoch 676 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24474.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 32888 | lr 0.000174374 | gnorm 0.287 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 95991
2022-03-07 15:41:56 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 15:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:42:25 | INFO | train_inner | epoch 677:     12 / 49 loss=0.41, nll_loss=0.111, ppl=1.08, wps=24768, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.287, loss_scale=64, train_wall=223, gb_free=8.8, wall=96020
2022-03-07 15:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:44:00 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 15.109 | nll_loss 15.01 | ppl 33000.7 | wps 47090.9 | wpb 510.9 | bsz 1 | num_updates 32937 | best_loss 8.238
2022-03-07 15:44:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32937 updates
2022-03-07 15:44:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:44:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:44:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 677 @ 32937 updates, score 15.109) (writing took 2.514454735442996 seconds)
2022-03-07 15:44:03 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 15:44:03 | INFO | train | epoch 677 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24975.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 32937 | lr 0.000174244 | gnorm 0.287 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96118
2022-03-07 15:44:03 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 15:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:46:08 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 15.079 | nll_loss 14.979 | ppl 32285.9 | wps 47175.7 | wpb 510.9 | bsz 1 | num_updates 32986 | best_loss 8.238
2022-03-07 15:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 32986 updates
2022-03-07 15:46:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:46:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 678 @ 32986 updates, score 15.079) (writing took 2.536298166960478 seconds)
2022-03-07 15:46:10 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 15:46:10 | INFO | train | epoch 678 | loss 0.41 | nll_loss 0.111 | ppl 1.08 | wps 24952.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 32986 | lr 0.000174115 | gnorm 0.29 | loss_scale 128 | train_wall 108 | gb_free 8.8 | wall 96245
2022-03-07 15:46:10 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 15:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:46:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:46:47 | INFO | train_inner | epoch 679:     15 / 49 loss=0.409, nll_loss=0.111, ppl=1.08, wps=24759, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.288, loss_scale=64, train_wall=223, gb_free=8.8, wall=96283
2022-03-07 15:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:48:15 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 15.178 | nll_loss 15.077 | ppl 34572.3 | wps 47217.4 | wpb 510.9 | bsz 1 | num_updates 33034 | best_loss 8.238
2022-03-07 15:48:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33034 updates
2022-03-07 15:48:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:48:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 679 @ 33034 updates, score 15.178) (writing took 2.544356409460306 seconds)
2022-03-07 15:48:18 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 15:48:18 | INFO | train | epoch 679 | loss 0.409 | nll_loss 0.11 | ppl 1.08 | wps 24436.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33034 | lr 0.000173988 | gnorm 0.289 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96373
2022-03-07 15:48:18 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 15:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:50:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:50:22 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 15.074 | nll_loss 14.973 | ppl 32166.5 | wps 47670.2 | wpb 510.9 | bsz 1 | num_updates 33083 | best_loss 8.238
2022-03-07 15:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33083 updates
2022-03-07 15:50:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:50:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 680 @ 33083 updates, score 15.074) (writing took 2.5242159329354763 seconds)
2022-03-07 15:50:25 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 15:50:25 | INFO | train | epoch 680 | loss 0.409 | nll_loss 0.11 | ppl 1.08 | wps 24951.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33083 | lr 0.000173859 | gnorm 0.286 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96500
2022-03-07 15:50:25 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 15:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:51:07 | INFO | train_inner | epoch 681:     17 / 49 loss=0.409, nll_loss=0.11, ppl=1.08, wps=24978.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.287, loss_scale=64, train_wall=221, gb_free=8.8, wall=96542
2022-03-07 15:51:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:52:30 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 15.099 | nll_loss 14.999 | ppl 32753.8 | wps 46778.9 | wpb 510.9 | bsz 1 | num_updates 33131 | best_loss 8.238
2022-03-07 15:52:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33131 updates
2022-03-07 15:52:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:52:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:52:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 681 @ 33131 updates, score 15.099) (writing took 2.5746749360114336 seconds)
2022-03-07 15:52:32 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-07 15:52:32 | INFO | train | epoch 681 | loss 0.409 | nll_loss 0.111 | ppl 1.08 | wps 24424.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33131 | lr 0.000173733 | gnorm 0.286 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96628
2022-03-07 15:52:32 | INFO | fairseq.trainer | begin training epoch 682
2022-03-07 15:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:54:37 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 15.092 | nll_loss 14.991 | ppl 32566.8 | wps 46419 | wpb 510.9 | bsz 1 | num_updates 33180 | best_loss 8.238
2022-03-07 15:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33180 updates
2022-03-07 15:54:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:54:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 682 @ 33180 updates, score 15.092) (writing took 2.511028315871954 seconds)
2022-03-07 15:54:40 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-07 15:54:40 | INFO | train | epoch 682 | loss 0.409 | nll_loss 0.11 | ppl 1.08 | wps 24948.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33180 | lr 0.000173605 | gnorm 0.286 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96755
2022-03-07 15:54:40 | INFO | fairseq.trainer | begin training epoch 683
2022-03-07 15:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:55:29 | INFO | train_inner | epoch 683:     20 / 49 loss=0.409, nll_loss=0.11, ppl=1.08, wps=24736.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.286, loss_scale=64, train_wall=224, gb_free=8.8, wall=96804
2022-03-07 15:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:56:44 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 15.138 | nll_loss 15.04 | ppl 33686.4 | wps 47495.1 | wpb 510.9 | bsz 1 | num_updates 33229 | best_loss 8.238
2022-03-07 15:56:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33229 updates
2022-03-07 15:56:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:56:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:56:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 683 @ 33229 updates, score 15.138) (writing took 2.530948171392083 seconds)
2022-03-07 15:56:47 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-07 15:56:47 | INFO | train | epoch 683 | loss 0.409 | nll_loss 0.11 | ppl 1.08 | wps 24974.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33229 | lr 0.000173477 | gnorm 0.287 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 96882
2022-03-07 15:56:47 | INFO | fairseq.trainer | begin training epoch 684
2022-03-07 15:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 15:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:58:52 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 15.19 | nll_loss 15.091 | ppl 34912.8 | wps 47093.7 | wpb 510.9 | bsz 1 | num_updates 33277 | best_loss 8.238
2022-03-07 15:58:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33277 updates
2022-03-07 15:58:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:58:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 15:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 684 @ 33277 updates, score 15.19) (writing took 2.5570362340658903 seconds)
2022-03-07 15:58:54 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-07 15:58:54 | INFO | train | epoch 684 | loss 0.409 | nll_loss 0.11 | ppl 1.08 | wps 24448.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33277 | lr 0.000173352 | gnorm 0.285 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 97009
2022-03-07 15:58:54 | INFO | fairseq.trainer | begin training epoch 685
2022-03-07 15:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:59:51 | INFO | train_inner | epoch 685:     23 / 49 loss=0.408, nll_loss=0.11, ppl=1.08, wps=24755.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.286, loss_scale=64, train_wall=223, gb_free=8.8, wall=97067
2022-03-07 16:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:00:59 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 15.089 | nll_loss 14.99 | ppl 32536.2 | wps 47273.8 | wpb 510.9 | bsz 1 | num_updates 33326 | best_loss 8.238
2022-03-07 16:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33326 updates
2022-03-07 16:00:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 685 @ 33326 updates, score 15.089) (writing took 2.5379688404500484 seconds)
2022-03-07 16:01:02 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-07 16:01:02 | INFO | train | epoch 685 | loss 0.408 | nll_loss 0.11 | ppl 1.08 | wps 24949.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33326 | lr 0.000173224 | gnorm 0.287 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 97137
2022-03-07 16:01:02 | INFO | fairseq.trainer | begin training epoch 686
2022-03-07 16:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:03:06 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 15.155 | nll_loss 15.056 | ppl 34054 | wps 47197.7 | wpb 510.9 | bsz 1 | num_updates 33375 | best_loss 8.238
2022-03-07 16:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33375 updates
2022-03-07 16:03:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:03:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:03:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 686 @ 33375 updates, score 15.155) (writing took 2.528683179989457 seconds)
2022-03-07 16:03:09 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-07 16:03:09 | INFO | train | epoch 686 | loss 0.408 | nll_loss 0.11 | ppl 1.08 | wps 24993.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33375 | lr 0.000173097 | gnorm 0.287 | loss_scale 128 | train_wall 108 | gb_free 8.8 | wall 97264
2022-03-07 16:03:09 | INFO | fairseq.trainer | begin training epoch 687
2022-03-07 16:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:04:13 | INFO | train_inner | epoch 687:     26 / 49 loss=0.408, nll_loss=0.11, ppl=1.08, wps=24774.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.287, loss_scale=64, train_wall=223, gb_free=8.8, wall=97328
2022-03-07 16:05:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:05:14 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 15.046 | nll_loss 14.946 | ppl 31564.4 | wps 47194.1 | wpb 510.9 | bsz 1 | num_updates 33423 | best_loss 8.238
2022-03-07 16:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33423 updates
2022-03-07 16:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:05:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:05:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 687 @ 33423 updates, score 15.046) (writing took 2.5655345637351274 seconds)
2022-03-07 16:05:16 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-07 16:05:16 | INFO | train | epoch 687 | loss 0.408 | nll_loss 0.109 | ppl 1.08 | wps 24463.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33423 | lr 0.000172973 | gnorm 0.284 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 97391
2022-03-07 16:05:16 | INFO | fairseq.trainer | begin training epoch 688
2022-03-07 16:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:07:21 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 15.102 | nll_loss 15.003 | ppl 32846 | wps 46986.7 | wpb 510.9 | bsz 1 | num_updates 33472 | best_loss 8.238
2022-03-07 16:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33472 updates
2022-03-07 16:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 688 @ 33472 updates, score 15.102) (writing took 2.5251074973493814 seconds)
2022-03-07 16:07:23 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-07 16:07:23 | INFO | train | epoch 688 | loss 0.408 | nll_loss 0.11 | ppl 1.08 | wps 24982.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33472 | lr 0.000172846 | gnorm 0.287 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 97518
2022-03-07 16:07:23 | INFO | fairseq.trainer | begin training epoch 689
2022-03-07 16:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:08:33 | INFO | train_inner | epoch 689:     28 / 49 loss=0.408, nll_loss=0.11, ppl=1.08, wps=25004.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.285, loss_scale=64, train_wall=221, gb_free=8.8, wall=97588
2022-03-07 16:08:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:09:28 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 15.083 | nll_loss 14.984 | ppl 32398 | wps 47177.7 | wpb 510.9 | bsz 1 | num_updates 33520 | best_loss 8.238
2022-03-07 16:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33520 updates
2022-03-07 16:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 689 @ 33520 updates, score 15.083) (writing took 2.5140879824757576 seconds)
2022-03-07 16:09:31 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-07 16:09:31 | INFO | train | epoch 689 | loss 0.408 | nll_loss 0.109 | ppl 1.08 | wps 24447.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33520 | lr 0.000172722 | gnorm 0.284 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 97646
2022-03-07 16:09:31 | INFO | fairseq.trainer | begin training epoch 690
2022-03-07 16:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:11:35 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 15.087 | nll_loss 14.987 | ppl 32476.4 | wps 46569.6 | wpb 510.9 | bsz 1 | num_updates 33569 | best_loss 8.238
2022-03-07 16:11:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33569 updates
2022-03-07 16:11:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:11:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:11:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 690 @ 33569 updates, score 15.087) (writing took 2.5540343187749386 seconds)
2022-03-07 16:11:38 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-07 16:11:38 | INFO | train | epoch 690 | loss 0.408 | nll_loss 0.11 | ppl 1.08 | wps 24947.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33569 | lr 0.000172596 | gnorm 0.284 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 97773
2022-03-07 16:11:38 | INFO | fairseq.trainer | begin training epoch 691
2022-03-07 16:11:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:12:55 | INFO | train_inner | epoch 691:     31 / 49 loss=0.408, nll_loss=0.11, ppl=1.08, wps=24746, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.284, loss_scale=64, train_wall=223, gb_free=8.8, wall=97850
2022-03-07 16:13:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:13:43 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 15.055 | nll_loss 14.956 | ppl 31787.7 | wps 47203.5 | wpb 510.9 | bsz 1 | num_updates 33618 | best_loss 8.238
2022-03-07 16:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33618 updates
2022-03-07 16:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 691 @ 33618 updates, score 15.055) (writing took 2.5270097721368074 seconds)
2022-03-07 16:13:45 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-07 16:13:45 | INFO | train | epoch 691 | loss 0.408 | nll_loss 0.11 | ppl 1.08 | wps 24961.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33618 | lr 0.00017247 | gnorm 0.286 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 97900
2022-03-07 16:13:45 | INFO | fairseq.trainer | begin training epoch 692
2022-03-07 16:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:15:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:15:50 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 15.14 | nll_loss 15.041 | ppl 33703.4 | wps 46806.5 | wpb 510.9 | bsz 1 | num_updates 33666 | best_loss 8.238
2022-03-07 16:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33666 updates
2022-03-07 16:15:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:15:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 692 @ 33666 updates, score 15.14) (writing took 2.52163852378726 seconds)
2022-03-07 16:15:53 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-07 16:15:53 | INFO | train | epoch 692 | loss 0.408 | nll_loss 0.109 | ppl 1.08 | wps 24458.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33666 | lr 0.000172347 | gnorm 0.284 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 98028
2022-03-07 16:15:53 | INFO | fairseq.trainer | begin training epoch 693
2022-03-07 16:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:17:17 | INFO | train_inner | epoch 693:     34 / 49 loss=0.408, nll_loss=0.109, ppl=1.08, wps=24753.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.285, loss_scale=64, train_wall=223, gb_free=8.8, wall=98112
2022-03-07 16:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:17:57 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 15.05 | nll_loss 14.951 | ppl 31673.9 | wps 47561.1 | wpb 510.9 | bsz 1 | num_updates 33715 | best_loss 8.238
2022-03-07 16:17:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33715 updates
2022-03-07 16:17:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 693 @ 33715 updates, score 15.05) (writing took 2.540797872468829 seconds)
2022-03-07 16:18:00 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-07 16:18:00 | INFO | train | epoch 693 | loss 0.407 | nll_loss 0.109 | ppl 1.08 | wps 24952.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33715 | lr 0.000172222 | gnorm 0.288 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 98155
2022-03-07 16:18:00 | INFO | fairseq.trainer | begin training epoch 694
2022-03-07 16:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:20:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:20:05 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 15.092 | nll_loss 14.993 | ppl 32600.1 | wps 47494.7 | wpb 510.9 | bsz 1 | num_updates 33764 | best_loss 8.238
2022-03-07 16:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33764 updates
2022-03-07 16:20:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 694 @ 33764 updates, score 15.092) (writing took 2.5259319078177214 seconds)
2022-03-07 16:20:07 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-07 16:20:07 | INFO | train | epoch 694 | loss 0.408 | nll_loss 0.109 | ppl 1.08 | wps 24972.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 33764 | lr 0.000172097 | gnorm 0.286 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 98282
2022-03-07 16:20:07 | INFO | fairseq.trainer | begin training epoch 695
2022-03-07 16:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:20:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:21:39 | INFO | train_inner | epoch 695:     37 / 49 loss=0.407, nll_loss=0.109, ppl=1.08, wps=24761.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.285, loss_scale=64, train_wall=224, gb_free=8.8, wall=98374
2022-03-07 16:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:22:12 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 15.062 | nll_loss 14.963 | ppl 31929.6 | wps 47264.2 | wpb 510.9 | bsz 1 | num_updates 33812 | best_loss 8.238
2022-03-07 16:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33812 updates
2022-03-07 16:22:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:22:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:22:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 695 @ 33812 updates, score 15.062) (writing took 2.548763979226351 seconds)
2022-03-07 16:22:15 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-07 16:22:15 | INFO | train | epoch 695 | loss 0.407 | nll_loss 0.109 | ppl 1.08 | wps 24428.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33812 | lr 0.000171975 | gnorm 0.283 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 98410
2022-03-07 16:22:15 | INFO | fairseq.trainer | begin training epoch 696
2022-03-07 16:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:24:19 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 15.067 | nll_loss 14.967 | ppl 32024.1 | wps 47526.2 | wpb 510.9 | bsz 1 | num_updates 33861 | best_loss 8.238
2022-03-07 16:24:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33861 updates
2022-03-07 16:24:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:24:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:24:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 696 @ 33861 updates, score 15.067) (writing took 2.5929877776652575 seconds)
2022-03-07 16:24:22 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-07 16:24:22 | INFO | train | epoch 696 | loss 0.407 | nll_loss 0.109 | ppl 1.08 | wps 24959.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33861 | lr 0.00017185 | gnorm 0.284 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 98537
2022-03-07 16:24:22 | INFO | fairseq.trainer | begin training epoch 697
2022-03-07 16:24:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:59 | INFO | train_inner | epoch 697:     39 / 49 loss=0.407, nll_loss=0.109, ppl=1.08, wps=24950.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.283, loss_scale=64, train_wall=222, gb_free=8.8, wall=98634
2022-03-07 16:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:26:27 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 15.121 | nll_loss 15.023 | ppl 33289.5 | wps 47439.5 | wpb 510.9 | bsz 1 | num_updates 33910 | best_loss 8.238
2022-03-07 16:26:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33910 updates
2022-03-07 16:26:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:26:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:26:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 697 @ 33910 updates, score 15.121) (writing took 2.5489471461623907 seconds)
2022-03-07 16:26:30 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-07 16:26:30 | INFO | train | epoch 697 | loss 0.406 | nll_loss 0.108 | ppl 1.08 | wps 24901.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 33910 | lr 0.000171726 | gnorm 0.28 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 98665
2022-03-07 16:26:30 | INFO | fairseq.trainer | begin training epoch 698
2022-03-07 16:26:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:26:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:28:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:28:34 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 15.116 | nll_loss 15.017 | ppl 33158.4 | wps 47007.8 | wpb 510.9 | bsz 1 | num_updates 33958 | best_loss 8.238
2022-03-07 16:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33958 updates
2022-03-07 16:28:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:28:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 698 @ 33958 updates, score 15.116) (writing took 2.508315557613969 seconds)
2022-03-07 16:28:37 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-07 16:28:37 | INFO | train | epoch 698 | loss 0.406 | nll_loss 0.109 | ppl 1.08 | wps 24429 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 33958 | lr 0.000171605 | gnorm 0.285 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 98792
2022-03-07 16:28:37 | INFO | fairseq.trainer | begin training epoch 699
2022-03-07 16:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:21 | INFO | train_inner | epoch 699:     42 / 49 loss=0.407, nll_loss=0.109, ppl=1.08, wps=24728.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.284, loss_scale=64, train_wall=224, gb_free=8.8, wall=98896
2022-03-07 16:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:30:42 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 15.09 | nll_loss 14.991 | ppl 32572 | wps 47130.1 | wpb 510.9 | bsz 1 | num_updates 34007 | best_loss 8.238
2022-03-07 16:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34007 updates
2022-03-07 16:30:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 699 @ 34007 updates, score 15.09) (writing took 2.5237838327884674 seconds)
2022-03-07 16:30:45 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-07 16:30:45 | INFO | train | epoch 699 | loss 0.406 | nll_loss 0.109 | ppl 1.08 | wps 24911.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34007 | lr 0.000171481 | gnorm 0.284 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 98920
2022-03-07 16:30:45 | INFO | fairseq.trainer | begin training epoch 700
2022-03-07 16:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:32:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:32:50 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 14.987 | nll_loss 14.887 | ppl 30300.3 | wps 46901.8 | wpb 510.9 | bsz 1 | num_updates 34055 | best_loss 8.238
2022-03-07 16:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34055 updates
2022-03-07 16:32:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 700 @ 34055 updates, score 14.987) (writing took 2.5336512941867113 seconds)
2022-03-07 16:32:52 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-07 16:32:52 | INFO | train | epoch 700 | loss 0.406 | nll_loss 0.108 | ppl 1.08 | wps 24398.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34055 | lr 0.00017136 | gnorm 0.283 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 99047
2022-03-07 16:32:52 | INFO | fairseq.trainer | begin training epoch 701
2022-03-07 16:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:34:44 | INFO | train_inner | epoch 701:     45 / 49 loss=0.406, nll_loss=0.108, ppl=1.08, wps=24676.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.284, loss_scale=64, train_wall=224, gb_free=8.8, wall=99159
2022-03-07 16:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:34:58 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 15.009 | nll_loss 14.909 | ppl 30754.7 | wps 46904.5 | wpb 510.9 | bsz 1 | num_updates 34104 | best_loss 8.238
2022-03-07 16:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34104 updates
2022-03-07 16:34:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:35:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:35:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 701 @ 34104 updates, score 15.009) (writing took 2.4208288211375475 seconds)
2022-03-07 16:35:00 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-07 16:35:00 | INFO | train | epoch 701 | loss 0.406 | nll_loss 0.108 | ppl 1.08 | wps 24864.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34104 | lr 0.000171237 | gnorm 0.285 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 99175
2022-03-07 16:35:00 | INFO | fairseq.trainer | begin training epoch 702
2022-03-07 16:35:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:05 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 15.02 | nll_loss 14.919 | ppl 30982.1 | wps 46938.8 | wpb 510.9 | bsz 1 | num_updates 34153 | best_loss 8.238
2022-03-07 16:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34153 updates
2022-03-07 16:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 702 @ 34153 updates, score 15.02) (writing took 2.4481039959937334 seconds)
2022-03-07 16:37:07 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-07 16:37:07 | INFO | train | epoch 702 | loss 0.406 | nll_loss 0.108 | ppl 1.08 | wps 24915.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34153 | lr 0.000171114 | gnorm 0.283 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 99303
2022-03-07 16:37:08 | INFO | fairseq.trainer | begin training epoch 703
2022-03-07 16:37:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:39:07 | INFO | train_inner | epoch 703:     48 / 49 loss=0.406, nll_loss=0.108, ppl=1.08, wps=24715, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.283, loss_scale=64, train_wall=224, gb_free=8.8, wall=99422
2022-03-07 16:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:13 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 15.204 | nll_loss 15.106 | ppl 35259.3 | wps 46893.8 | wpb 510.9 | bsz 1 | num_updates 34201 | best_loss 8.238
2022-03-07 16:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34201 updates
2022-03-07 16:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:39:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 703 @ 34201 updates, score 15.204) (writing took 2.5160252563655376 seconds)
2022-03-07 16:39:15 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-07 16:39:15 | INFO | train | epoch 703 | loss 0.406 | nll_loss 0.108 | ppl 1.08 | wps 24400.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34201 | lr 0.000170994 | gnorm 0.283 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 99430
2022-03-07 16:39:15 | INFO | fairseq.trainer | begin training epoch 704
2022-03-07 16:39:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:41:20 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 15.08 | nll_loss 14.981 | ppl 32338 | wps 47283.8 | wpb 510.9 | bsz 1 | num_updates 34250 | best_loss 8.238
2022-03-07 16:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34250 updates
2022-03-07 16:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:41:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 704 @ 34250 updates, score 15.08) (writing took 2.4685687329620123 seconds)
2022-03-07 16:41:23 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-07 16:41:23 | INFO | train | epoch 704 | loss 0.406 | nll_loss 0.108 | ppl 1.08 | wps 24925.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34250 | lr 0.000170872 | gnorm 0.28 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 99558
2022-03-07 16:41:23 | INFO | fairseq.trainer | begin training epoch 705
2022-03-07 16:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:43:28 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 15.099 | nll_loss 14.999 | ppl 32752.6 | wps 47151.7 | wpb 510.9 | bsz 1 | num_updates 34299 | best_loss 8.238
2022-03-07 16:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34299 updates
2022-03-07 16:43:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 705 @ 34299 updates, score 15.099) (writing took 2.4931444078683853 seconds)
2022-03-07 16:43:30 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-07 16:43:30 | INFO | train | epoch 705 | loss 0.406 | nll_loss 0.108 | ppl 1.08 | wps 24884.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34299 | lr 0.000170749 | gnorm 0.281 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 99685
2022-03-07 16:43:30 | INFO | fairseq.trainer | begin training epoch 706
2022-03-07 16:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:33 | INFO | train_inner | epoch 706:      1 / 49 loss=0.406, nll_loss=0.108, ppl=1.08, wps=24232.2, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=34300, lr=0.000170747, gnorm=0.282, loss_scale=128, train_wall=221, gb_free=8.8, wall=99688
2022-03-07 16:43:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:45:35 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 15.002 | nll_loss 14.903 | ppl 30631.7 | wps 46095.9 | wpb 510.9 | bsz 1 | num_updates 34347 | best_loss 8.238
2022-03-07 16:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34347 updates
2022-03-07 16:45:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 706 @ 34347 updates, score 15.002) (writing took 2.53527007997036 seconds)
2022-03-07 16:45:38 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-07 16:45:38 | INFO | train | epoch 706 | loss 0.405 | nll_loss 0.108 | ppl 1.08 | wps 24370.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34347 | lr 0.00017063 | gnorm 0.282 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 99813
2022-03-07 16:45:38 | INFO | fairseq.trainer | begin training epoch 707
2022-03-07 16:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:47:43 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 15.026 | nll_loss 14.928 | ppl 31179 | wps 47317.1 | wpb 510.9 | bsz 1 | num_updates 34396 | best_loss 8.238
2022-03-07 16:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34396 updates
2022-03-07 16:47:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:47:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 707 @ 34396 updates, score 15.026) (writing took 2.418369708582759 seconds)
2022-03-07 16:47:45 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-07 16:47:45 | INFO | train | epoch 707 | loss 0.405 | nll_loss 0.107 | ppl 1.08 | wps 24944.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34396 | lr 0.000170508 | gnorm 0.281 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 99941
2022-03-07 16:47:45 | INFO | fairseq.trainer | begin training epoch 708
2022-03-07 16:47:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:55 | INFO | train_inner | epoch 708:      4 / 49 loss=0.405, nll_loss=0.108, ppl=1.08, wps=24719.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.281, loss_scale=64, train_wall=224, gb_free=8.8, wall=99951
2022-03-07 16:49:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:50 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 15.061 | nll_loss 14.963 | ppl 31928.2 | wps 47289.7 | wpb 510.9 | bsz 1 | num_updates 34444 | best_loss 8.238
2022-03-07 16:49:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34444 updates
2022-03-07 16:49:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:49:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:49:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 708 @ 34444 updates, score 15.061) (writing took 2.470238510519266 seconds)
2022-03-07 16:49:53 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-07 16:49:53 | INFO | train | epoch 708 | loss 0.405 | nll_loss 0.107 | ppl 1.08 | wps 24404.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34444 | lr 0.00017039 | gnorm 0.28 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100068
2022-03-07 16:49:53 | INFO | fairseq.trainer | begin training epoch 709
2022-03-07 16:49:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:58 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 14.99 | nll_loss 14.891 | ppl 30376 | wps 46924 | wpb 510.9 | bsz 1 | num_updates 34493 | best_loss 8.238
2022-03-07 16:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34493 updates
2022-03-07 16:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:52:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 709 @ 34493 updates, score 14.99) (writing took 2.4979832135140896 seconds)
2022-03-07 16:52:01 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-07 16:52:01 | INFO | train | epoch 709 | loss 0.405 | nll_loss 0.107 | ppl 1.08 | wps 24888.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34493 | lr 0.000170269 | gnorm 0.281 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100196
2022-03-07 16:52:01 | INFO | fairseq.trainer | begin training epoch 710
2022-03-07 16:52:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:52:18 | INFO | train_inner | epoch 710:      7 / 49 loss=0.405, nll_loss=0.107, ppl=1.08, wps=24695.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34500, lr=0.000170251, gnorm=0.281, loss_scale=64, train_wall=224, gb_free=8.8, wall=100213
2022-03-07 16:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:54:06 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 15.064 | nll_loss 14.964 | ppl 31969.8 | wps 46954.2 | wpb 510.9 | bsz 1 | num_updates 34542 | best_loss 8.238
2022-03-07 16:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34542 updates
2022-03-07 16:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:54:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 710 @ 34542 updates, score 15.064) (writing took 2.4697400350123644 seconds)
2022-03-07 16:54:08 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-07 16:54:08 | INFO | train | epoch 710 | loss 0.405 | nll_loss 0.107 | ppl 1.08 | wps 24895.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34542 | lr 0.000170148 | gnorm 0.282 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100323
2022-03-07 16:54:08 | INFO | fairseq.trainer | begin training epoch 711
2022-03-07 16:54:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 16:56:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:13 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 15.048 | nll_loss 14.95 | ppl 31650 | wps 46788.5 | wpb 510.9 | bsz 1 | num_updates 34590 | best_loss 8.238
2022-03-07 16:56:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34590 updates
2022-03-07 16:56:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:56:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:56:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 711 @ 34590 updates, score 15.048) (writing took 2.5363444667309523 seconds)
2022-03-07 16:56:16 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-07 16:56:16 | INFO | train | epoch 711 | loss 0.404 | nll_loss 0.107 | ppl 1.08 | wps 24403.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34590 | lr 0.00017003 | gnorm 0.28 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100451
2022-03-07 16:56:16 | INFO | fairseq.trainer | begin training epoch 712
2022-03-07 16:56:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:56:41 | INFO | train_inner | epoch 712:     10 / 49 loss=0.404, nll_loss=0.107, ppl=1.08, wps=24693.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.281, loss_scale=64, train_wall=224, gb_free=8.8, wall=100476
2022-03-07 16:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:21 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 15.099 | nll_loss 15 | ppl 32776.8 | wps 46779.9 | wpb 510.9 | bsz 1 | num_updates 34639 | best_loss 8.238
2022-03-07 16:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34639 updates
2022-03-07 16:58:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 16:58:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 712 @ 34639 updates, score 15.099) (writing took 2.3576627243310213 seconds)
2022-03-07 16:58:23 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-07 16:58:23 | INFO | train | epoch 712 | loss 0.404 | nll_loss 0.107 | ppl 1.08 | wps 24899.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34639 | lr 0.000169909 | gnorm 0.28 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100579
2022-03-07 16:58:23 | INFO | fairseq.trainer | begin training epoch 713
2022-03-07 16:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:00:29 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 15.036 | nll_loss 14.937 | ppl 31358.3 | wps 46999.3 | wpb 510.9 | bsz 1 | num_updates 34688 | best_loss 8.238
2022-03-07 17:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34688 updates
2022-03-07 17:00:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:00:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:00:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 713 @ 34688 updates, score 15.036) (writing took 2.506007818505168 seconds)
2022-03-07 17:00:31 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-07 17:00:31 | INFO | train | epoch 713 | loss 0.405 | nll_loss 0.107 | ppl 1.08 | wps 24897.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34688 | lr 0.000169789 | gnorm 0.281 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100706
2022-03-07 17:00:31 | INFO | fairseq.trainer | begin training epoch 714
2022-03-07 17:00:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:01:03 | INFO | train_inner | epoch 714:     13 / 49 loss=0.405, nll_loss=0.107, ppl=1.08, wps=24696.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.282, loss_scale=64, train_wall=224, gb_free=8.8, wall=100739
2022-03-07 17:02:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:02:36 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 14.996 | nll_loss 14.896 | ppl 30491.9 | wps 47062.5 | wpb 510.9 | bsz 1 | num_updates 34736 | best_loss 8.238
2022-03-07 17:02:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34736 updates
2022-03-07 17:02:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:02:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 714 @ 34736 updates, score 14.996) (writing took 2.4671387653797865 seconds)
2022-03-07 17:02:39 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-07 17:02:39 | INFO | train | epoch 714 | loss 0.404 | nll_loss 0.107 | ppl 1.08 | wps 24386.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34736 | lr 0.000169672 | gnorm 0.285 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100834
2022-03-07 17:02:39 | INFO | fairseq.trainer | begin training epoch 715
2022-03-07 17:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:04:44 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 15.087 | nll_loss 14.989 | ppl 32521.9 | wps 46964.2 | wpb 510.9 | bsz 1 | num_updates 34785 | best_loss 8.238
2022-03-07 17:04:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34785 updates
2022-03-07 17:04:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:04:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:04:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 715 @ 34785 updates, score 15.087) (writing took 2.49185729585588 seconds)
2022-03-07 17:04:46 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-07 17:04:46 | INFO | train | epoch 715 | loss 0.404 | nll_loss 0.107 | ppl 1.08 | wps 24914.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34785 | lr 0.000169552 | gnorm 0.283 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 100961
2022-03-07 17:04:46 | INFO | fairseq.trainer | begin training epoch 716
2022-03-07 17:04:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:05:24 | INFO | train_inner | epoch 716:     15 / 49 loss=0.404, nll_loss=0.107, ppl=1.08, wps=24936.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.283, loss_scale=64, train_wall=222, gb_free=8.8, wall=100999
2022-03-07 17:06:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:06:52 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 15.02 | nll_loss 14.921 | ppl 31021.9 | wps 46903.9 | wpb 510.9 | bsz 1 | num_updates 34833 | best_loss 8.238
2022-03-07 17:06:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34833 updates
2022-03-07 17:06:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:06:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:06:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 716 @ 34833 updates, score 15.02) (writing took 2.4869549237191677 seconds)
2022-03-07 17:06:54 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-07 17:06:54 | INFO | train | epoch 716 | loss 0.404 | nll_loss 0.106 | ppl 1.08 | wps 24373.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34833 | lr 0.000169436 | gnorm 0.278 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 101089
2022-03-07 17:06:54 | INFO | fairseq.trainer | begin training epoch 717
2022-03-07 17:06:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:08:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:08:59 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 15.193 | nll_loss 15.096 | ppl 35022.9 | wps 46963.9 | wpb 510.9 | bsz 1 | num_updates 34882 | best_loss 8.238
2022-03-07 17:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34882 updates
2022-03-07 17:08:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:09:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 717 @ 34882 updates, score 15.193) (writing took 2.5425494723021984 seconds)
2022-03-07 17:09:02 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-07 17:09:02 | INFO | train | epoch 717 | loss 0.404 | nll_loss 0.107 | ppl 1.08 | wps 24914.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34882 | lr 0.000169317 | gnorm 0.28 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 101217
2022-03-07 17:09:02 | INFO | fairseq.trainer | begin training epoch 718
2022-03-07 17:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:46 | INFO | train_inner | epoch 718:     18 / 49 loss=0.404, nll_loss=0.107, ppl=1.08, wps=24697.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.279, loss_scale=64, train_wall=224, gb_free=8.8, wall=101261
2022-03-07 17:11:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:11:07 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 15.149 | nll_loss 15.05 | ppl 33928.8 | wps 47208.3 | wpb 510.9 | bsz 1 | num_updates 34931 | best_loss 8.238
2022-03-07 17:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34931 updates
2022-03-07 17:11:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 718 @ 34931 updates, score 15.149) (writing took 2.527886312454939 seconds)
2022-03-07 17:11:09 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-07 17:11:09 | INFO | train | epoch 718 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24911.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 34931 | lr 0.000169198 | gnorm 0.278 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 101344
2022-03-07 17:11:09 | INFO | fairseq.trainer | begin training epoch 719
2022-03-07 17:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:12:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:13:14 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 15.084 | nll_loss 14.985 | ppl 32418.9 | wps 47173.2 | wpb 510.9 | bsz 1 | num_updates 34979 | best_loss 8.238
2022-03-07 17:13:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 34979 updates
2022-03-07 17:13:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:13:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:13:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 719 @ 34979 updates, score 15.084) (writing took 2.504464313387871 seconds)
2022-03-07 17:13:17 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-07 17:13:17 | INFO | train | epoch 719 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24425.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 34979 | lr 0.000169082 | gnorm 0.279 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 101472
2022-03-07 17:13:17 | INFO | fairseq.trainer | begin training epoch 720
2022-03-07 17:13:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:14:09 | INFO | train_inner | epoch 720:     21 / 49 loss=0.403, nll_loss=0.106, ppl=1.08, wps=24719.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.279, loss_scale=64, train_wall=224, gb_free=8.8, wall=101524
2022-03-07 17:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:15:21 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 15.078 | nll_loss 14.98 | ppl 32314.8 | wps 47138.5 | wpb 510.9 | bsz 1 | num_updates 35028 | best_loss 8.238
2022-03-07 17:15:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35028 updates
2022-03-07 17:15:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:15:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:15:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 720 @ 35028 updates, score 15.078) (writing took 2.5443610325455666 seconds)
2022-03-07 17:15:24 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-07 17:15:24 | INFO | train | epoch 720 | loss 0.404 | nll_loss 0.106 | ppl 1.08 | wps 24935.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35028 | lr 0.000168963 | gnorm 0.281 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 101599
2022-03-07 17:15:24 | INFO | fairseq.trainer | begin training epoch 721
2022-03-07 17:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:17:29 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 15.011 | nll_loss 14.912 | ppl 30826.8 | wps 46718.9 | wpb 510.9 | bsz 1 | num_updates 35077 | best_loss 8.238
2022-03-07 17:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35077 updates
2022-03-07 17:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:17:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 721 @ 35077 updates, score 15.011) (writing took 2.5445154905319214 seconds)
2022-03-07 17:17:32 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-07 17:17:32 | INFO | train | epoch 721 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24906 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35077 | lr 0.000168845 | gnorm 0.281 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 101727
2022-03-07 17:17:32 | INFO | fairseq.trainer | begin training epoch 722
2022-03-07 17:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:18:31 | INFO | train_inner | epoch 722:     24 / 49 loss=0.403, nll_loss=0.106, ppl=1.08, wps=24721.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.279, loss_scale=64, train_wall=224, gb_free=8.8, wall=101786
2022-03-07 17:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:19:36 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 15.123 | nll_loss 15.025 | ppl 33337.6 | wps 46970.6 | wpb 510.9 | bsz 1 | num_updates 35125 | best_loss 8.238
2022-03-07 17:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35125 updates
2022-03-07 17:19:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:19:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 722 @ 35125 updates, score 15.123) (writing took 2.5885046515613794 seconds)
2022-03-07 17:19:39 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-07 17:19:39 | INFO | train | epoch 722 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24420.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35125 | lr 0.00016873 | gnorm 0.279 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 101854
2022-03-07 17:19:39 | INFO | fairseq.trainer | begin training epoch 723
2022-03-07 17:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:21:44 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 15.069 | nll_loss 14.971 | ppl 32117.8 | wps 47163.8 | wpb 510.9 | bsz 1 | num_updates 35174 | best_loss 8.238
2022-03-07 17:21:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35174 updates
2022-03-07 17:21:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:21:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 723 @ 35174 updates, score 15.069) (writing took 2.521052038297057 seconds)
2022-03-07 17:21:47 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-07 17:21:47 | INFO | train | epoch 723 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24919.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35174 | lr 0.000168612 | gnorm 0.278 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 101982
2022-03-07 17:21:47 | INFO | fairseq.trainer | begin training epoch 724
2022-03-07 17:21:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:22:51 | INFO | train_inner | epoch 724:     26 / 49 loss=0.403, nll_loss=0.106, ppl=1.08, wps=24956.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.28, loss_scale=64, train_wall=222, gb_free=8.8, wall=102046
2022-03-07 17:23:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:23:51 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 15.075 | nll_loss 14.977 | ppl 32250 | wps 47065.6 | wpb 510.9 | bsz 1 | num_updates 35222 | best_loss 8.238
2022-03-07 17:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35222 updates
2022-03-07 17:23:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 724 @ 35222 updates, score 15.075) (writing took 2.5448727905750275 seconds)
2022-03-07 17:23:54 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-07 17:23:54 | INFO | train | epoch 724 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24433.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35222 | lr 0.000168497 | gnorm 0.282 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 102109
2022-03-07 17:23:54 | INFO | fairseq.trainer | begin training epoch 725
2022-03-07 17:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:25:59 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 15.042 | nll_loss 14.943 | ppl 31489.2 | wps 47001.1 | wpb 510.9 | bsz 1 | num_updates 35271 | best_loss 8.238
2022-03-07 17:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35271 updates
2022-03-07 17:25:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 725 @ 35271 updates, score 15.042) (writing took 2.5257322192192078 seconds)
2022-03-07 17:26:02 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-07 17:26:02 | INFO | train | epoch 725 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24921.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35271 | lr 0.00016838 | gnorm 0.28 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 102237
2022-03-07 17:26:02 | INFO | fairseq.trainer | begin training epoch 726
2022-03-07 17:26:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:27:14 | INFO | train_inner | epoch 726:     29 / 49 loss=0.403, nll_loss=0.106, ppl=1.08, wps=24713.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.28, loss_scale=64, train_wall=224, gb_free=8.8, wall=102309
2022-03-07 17:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:28:07 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 15.113 | nll_loss 15.015 | ppl 33115.2 | wps 47212.4 | wpb 510.9 | bsz 1 | num_updates 35320 | best_loss 8.238
2022-03-07 17:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35320 updates
2022-03-07 17:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:28:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 726 @ 35320 updates, score 15.113) (writing took 2.517783086746931 seconds)
2022-03-07 17:28:09 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-07 17:28:09 | INFO | train | epoch 726 | loss 0.403 | nll_loss 0.106 | ppl 1.08 | wps 24919.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35320 | lr 0.000168263 | gnorm 0.278 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 102364
2022-03-07 17:28:09 | INFO | fairseq.trainer | begin training epoch 727
2022-03-07 17:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:29:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:30:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:30:14 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 15.112 | nll_loss 15.014 | ppl 33090.6 | wps 47122.9 | wpb 510.9 | bsz 1 | num_updates 35368 | best_loss 8.238
2022-03-07 17:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35368 updates
2022-03-07 17:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 727 @ 35368 updates, score 15.112) (writing took 2.5319781843572855 seconds)
2022-03-07 17:30:16 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-07 17:30:16 | INFO | train | epoch 727 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24442.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35368 | lr 0.000168149 | gnorm 0.28 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 102492
2022-03-07 17:30:16 | INFO | fairseq.trainer | begin training epoch 728
2022-03-07 17:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:31:36 | INFO | train_inner | epoch 728:     32 / 49 loss=0.402, nll_loss=0.105, ppl=1.08, wps=24735.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.279, loss_scale=64, train_wall=224, gb_free=8.8, wall=102571
2022-03-07 17:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:32:21 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 14.987 | nll_loss 14.888 | ppl 30315.8 | wps 47234.2 | wpb 510.9 | bsz 1 | num_updates 35417 | best_loss 8.238
2022-03-07 17:32:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35417 updates
2022-03-07 17:32:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 728 @ 35417 updates, score 14.987) (writing took 2.5044920817017555 seconds)
2022-03-07 17:32:24 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-07 17:32:24 | INFO | train | epoch 728 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24936.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35417 | lr 0.000168033 | gnorm 0.279 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 102619
2022-03-07 17:32:24 | INFO | fairseq.trainer | begin training epoch 729
2022-03-07 17:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:34:29 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 15.089 | nll_loss 14.991 | ppl 32570.9 | wps 47128.8 | wpb 510.9 | bsz 1 | num_updates 35466 | best_loss 8.238
2022-03-07 17:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35466 updates
2022-03-07 17:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 729 @ 35466 updates, score 15.089) (writing took 2.571030706167221 seconds)
2022-03-07 17:34:31 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-07 17:34:31 | INFO | train | epoch 729 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24946.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35466 | lr 0.000167917 | gnorm 0.278 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 102746
2022-03-07 17:34:31 | INFO | fairseq.trainer | begin training epoch 730
2022-03-07 17:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:34:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:35:58 | INFO | train_inner | epoch 730:     35 / 49 loss=0.402, nll_loss=0.105, ppl=1.08, wps=24757.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.278, loss_scale=64, train_wall=223, gb_free=8.8, wall=102833
2022-03-07 17:36:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:36:36 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 15.032 | nll_loss 14.934 | ppl 31294.3 | wps 47040.8 | wpb 510.9 | bsz 1 | num_updates 35514 | best_loss 8.238
2022-03-07 17:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35514 updates
2022-03-07 17:36:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 730 @ 35514 updates, score 15.032) (writing took 2.548222029581666 seconds)
2022-03-07 17:36:38 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-07 17:36:38 | INFO | train | epoch 730 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24476.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35514 | lr 0.000167803 | gnorm 0.277 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 102874
2022-03-07 17:36:38 | INFO | fairseq.trainer | begin training epoch 731
2022-03-07 17:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:38:43 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 15.078 | nll_loss 14.979 | ppl 32297.2 | wps 47582.5 | wpb 510.9 | bsz 1 | num_updates 35563 | best_loss 8.238
2022-03-07 17:38:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35563 updates
2022-03-07 17:38:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 731 @ 35563 updates, score 15.078) (writing took 2.5250641349703074 seconds)
2022-03-07 17:38:46 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-07 17:38:46 | INFO | train | epoch 731 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24960.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35563 | lr 0.000167688 | gnorm 0.279 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 103001
2022-03-07 17:38:46 | INFO | fairseq.trainer | begin training epoch 732
2022-03-07 17:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:40:18 | INFO | train_inner | epoch 732:     37 / 49 loss=0.402, nll_loss=0.105, ppl=1.08, wps=24976.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.279, loss_scale=128, train_wall=221, gb_free=8.8, wall=103093
2022-03-07 17:40:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:40:51 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 15.046 | nll_loss 14.948 | ppl 31601 | wps 47145.5 | wpb 510.9 | bsz 1 | num_updates 35611 | best_loss 8.238
2022-03-07 17:40:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35611 updates
2022-03-07 17:40:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:40:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:40:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 732 @ 35611 updates, score 15.046) (writing took 2.5238341484218836 seconds)
2022-03-07 17:40:53 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-07 17:40:53 | INFO | train | epoch 732 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24408.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35611 | lr 0.000167574 | gnorm 0.278 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 103128
2022-03-07 17:40:53 | INFO | fairseq.trainer | begin training epoch 733
2022-03-07 17:40:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:42:58 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 15.112 | nll_loss 15.014 | ppl 33082.8 | wps 47034.6 | wpb 510.9 | bsz 1 | num_updates 35660 | best_loss 8.238
2022-03-07 17:42:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35660 updates
2022-03-07 17:42:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:43:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:43:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 733 @ 35660 updates, score 15.112) (writing took 2.5520487632602453 seconds)
2022-03-07 17:43:01 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-07 17:43:01 | INFO | train | epoch 733 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24905.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35660 | lr 0.000167459 | gnorm 0.279 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 103256
2022-03-07 17:43:01 | INFO | fairseq.trainer | begin training epoch 734
2022-03-07 17:43:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:44:40 | INFO | train_inner | epoch 734:     40 / 49 loss=0.402, nll_loss=0.105, ppl=1.08, wps=24719.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.279, loss_scale=64, train_wall=224, gb_free=8.8, wall=103355
2022-03-07 17:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:06 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 14.994 | nll_loss 14.896 | ppl 30489.6 | wps 47128.8 | wpb 510.9 | bsz 1 | num_updates 35709 | best_loss 8.238
2022-03-07 17:45:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35709 updates
2022-03-07 17:45:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:45:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 734 @ 35709 updates, score 14.994) (writing took 2.5478133764117956 seconds)
2022-03-07 17:45:08 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-07 17:45:08 | INFO | train | epoch 734 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24936.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35709 | lr 0.000167344 | gnorm 0.279 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 103383
2022-03-07 17:45:08 | INFO | fairseq.trainer | begin training epoch 735
2022-03-07 17:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:46:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:47:13 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 15.089 | nll_loss 14.991 | ppl 32565.9 | wps 47165.4 | wpb 510.9 | bsz 1 | num_updates 35757 | best_loss 8.238
2022-03-07 17:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35757 updates
2022-03-07 17:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:47:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:47:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 735 @ 35757 updates, score 15.089) (writing took 2.5103848725557327 seconds)
2022-03-07 17:47:16 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-07 17:47:16 | INFO | train | epoch 735 | loss 0.401 | nll_loss 0.105 | ppl 1.08 | wps 24406.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35757 | lr 0.000167232 | gnorm 0.277 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 103511
2022-03-07 17:47:16 | INFO | fairseq.trainer | begin training epoch 736
2022-03-07 17:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:49:02 | INFO | train_inner | epoch 736:     43 / 49 loss=0.402, nll_loss=0.105, ppl=1.08, wps=24728.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.278, loss_scale=64, train_wall=224, gb_free=8.8, wall=103617
2022-03-07 17:49:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:49:21 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 15.042 | nll_loss 14.943 | ppl 31493.2 | wps 47113 | wpb 510.9 | bsz 1 | num_updates 35806 | best_loss 8.238
2022-03-07 17:49:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35806 updates
2022-03-07 17:49:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 736 @ 35806 updates, score 15.042) (writing took 2.5874522514641285 seconds)
2022-03-07 17:49:23 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-07 17:49:23 | INFO | train | epoch 736 | loss 0.402 | nll_loss 0.105 | ppl 1.08 | wps 24956.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35806 | lr 0.000167118 | gnorm 0.281 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 103638
2022-03-07 17:49:23 | INFO | fairseq.trainer | begin training epoch 737
2022-03-07 17:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:51:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:51:28 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 15.04 | nll_loss 14.941 | ppl 31449.3 | wps 45427.8 | wpb 510.9 | bsz 1 | num_updates 35855 | best_loss 8.238
2022-03-07 17:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35855 updates
2022-03-07 17:51:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 737 @ 35855 updates, score 15.04) (writing took 2.423695385456085 seconds)
2022-03-07 17:51:31 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-07 17:51:31 | INFO | train | epoch 737 | loss 0.401 | nll_loss 0.104 | ppl 1.07 | wps 24911.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35855 | lr 0.000167003 | gnorm 0.277 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 103766
2022-03-07 17:51:31 | INFO | fairseq.trainer | begin training epoch 738
2022-03-07 17:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:52:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:53:25 | INFO | train_inner | epoch 738:     46 / 49 loss=0.401, nll_loss=0.105, ppl=1.08, wps=24661.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.277, loss_scale=64, train_wall=224, gb_free=8.8, wall=103881
2022-03-07 17:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:53:36 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 15.169 | nll_loss 15.071 | ppl 34417.8 | wps 46352.2 | wpb 510.9 | bsz 1 | num_updates 35903 | best_loss 8.238
2022-03-07 17:53:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35903 updates
2022-03-07 17:53:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:53:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 738 @ 35903 updates, score 15.169) (writing took 2.53979872725904 seconds)
2022-03-07 17:53:39 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-07 17:53:39 | INFO | train | epoch 738 | loss 0.401 | nll_loss 0.105 | ppl 1.08 | wps 24279.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 35903 | lr 0.000166892 | gnorm 0.275 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 103894
2022-03-07 17:53:39 | INFO | fairseq.trainer | begin training epoch 739
2022-03-07 17:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:55:44 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 15.157 | nll_loss 15.06 | ppl 34157.4 | wps 47223.9 | wpb 510.9 | bsz 1 | num_updates 35952 | best_loss 8.238
2022-03-07 17:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35952 updates
2022-03-07 17:55:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:55:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 739 @ 35952 updates, score 15.157) (writing took 2.5286184325814247 seconds)
2022-03-07 17:55:47 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-07 17:55:47 | INFO | train | epoch 739 | loss 0.401 | nll_loss 0.105 | ppl 1.08 | wps 24844.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 35952 | lr 0.000166778 | gnorm 0.279 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 104022
2022-03-07 17:55:47 | INFO | fairseq.trainer | begin training epoch 740
2022-03-07 17:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:57:46 | INFO | train_inner | epoch 740:     48 / 49 loss=0.401, nll_loss=0.105, ppl=1.08, wps=24926.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.278, loss_scale=128, train_wall=222, gb_free=8.8, wall=104141
2022-03-07 17:57:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:57:52 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 15.151 | nll_loss 15.055 | ppl 34033.1 | wps 47256.7 | wpb 510.9 | bsz 1 | num_updates 36001 | best_loss 8.238
2022-03-07 17:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36001 updates
2022-03-07 17:57:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 17:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 740 @ 36001 updates, score 15.151) (writing took 2.4676538202911615 seconds)
2022-03-07 17:57:54 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-07 17:57:54 | INFO | train | epoch 740 | loss 0.401 | nll_loss 0.105 | ppl 1.08 | wps 24995.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36001 | lr 0.000166664 | gnorm 0.278 | loss_scale 128 | train_wall 108 | gb_free 8.8 | wall 104149
2022-03-07 17:57:54 | INFO | fairseq.trainer | begin training epoch 741
2022-03-07 17:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:57:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 17:59:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:59 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 15.082 | nll_loss 14.985 | ppl 32435 | wps 47201.4 | wpb 510.9 | bsz 1 | num_updates 36049 | best_loss 8.238
2022-03-07 17:59:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36049 updates
2022-03-07 17:59:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:00:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:00:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 741 @ 36049 updates, score 15.082) (writing took 2.4948015864938498 seconds)
2022-03-07 18:00:01 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-07 18:00:01 | INFO | train | epoch 741 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24477.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36049 | lr 0.000166553 | gnorm 0.273 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104276
2022-03-07 18:00:01 | INFO | fairseq.trainer | begin training epoch 742
2022-03-07 18:00:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:02:06 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 15.116 | nll_loss 15.019 | ppl 33195.5 | wps 46881.2 | wpb 510.9 | bsz 1 | num_updates 36098 | best_loss 8.238
2022-03-07 18:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36098 updates
2022-03-07 18:02:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 742 @ 36098 updates, score 15.116) (writing took 2.5207721535116434 seconds)
2022-03-07 18:02:09 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-07 18:02:09 | INFO | train | epoch 742 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24905.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36098 | lr 0.00016644 | gnorm 0.275 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 104404
2022-03-07 18:02:09 | INFO | fairseq.trainer | begin training epoch 743
2022-03-07 18:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:14 | INFO | train_inner | epoch 743:      2 / 49 loss=0.4, nll_loss=0.104, ppl=1.07, wps=24066.1, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=36100, lr=0.000166436, gnorm=0.275, loss_scale=64, train_wall=223, gb_free=8.8, wall=104409
2022-03-07 18:03:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:13 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 15.024 | nll_loss 14.926 | ppl 31129.8 | wps 47417.1 | wpb 510.9 | bsz 1 | num_updates 36146 | best_loss 8.238
2022-03-07 18:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36146 updates
2022-03-07 18:04:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:04:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:04:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 743 @ 36146 updates, score 15.024) (writing took 2.444991609081626 seconds)
2022-03-07 18:04:16 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-07 18:04:16 | INFO | train | epoch 743 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24491.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36146 | lr 0.00016633 | gnorm 0.277 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104531
2022-03-07 18:04:16 | INFO | fairseq.trainer | begin training epoch 744
2022-03-07 18:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:06:21 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 15.043 | nll_loss 14.945 | ppl 31532.8 | wps 47229.2 | wpb 510.9 | bsz 1 | num_updates 36195 | best_loss 8.238
2022-03-07 18:06:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36195 updates
2022-03-07 18:06:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:06:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:06:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 744 @ 36195 updates, score 15.043) (writing took 2.584559164941311 seconds)
2022-03-07 18:06:23 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-07 18:06:23 | INFO | train | epoch 744 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24954.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36195 | lr 0.000166217 | gnorm 0.277 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 104658
2022-03-07 18:06:23 | INFO | fairseq.trainer | begin training epoch 745
2022-03-07 18:06:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:36 | INFO | train_inner | epoch 745:      5 / 49 loss=0.4, nll_loss=0.104, ppl=1.07, wps=24770.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.277, loss_scale=64, train_wall=223, gb_free=8.8, wall=104671
2022-03-07 18:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:08:28 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 15.033 | nll_loss 14.935 | ppl 31331.4 | wps 47168.7 | wpb 510.9 | bsz 1 | num_updates 36244 | best_loss 8.238
2022-03-07 18:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36244 updates
2022-03-07 18:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 745 @ 36244 updates, score 15.033) (writing took 2.5257603973150253 seconds)
2022-03-07 18:08:31 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-07 18:08:31 | INFO | train | epoch 745 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24941.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36244 | lr 0.000166105 | gnorm 0.276 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 104786
2022-03-07 18:08:31 | INFO | fairseq.trainer | begin training epoch 746
2022-03-07 18:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:10:36 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 15.03 | nll_loss 14.932 | ppl 31248.8 | wps 46646.3 | wpb 510.9 | bsz 1 | num_updates 36292 | best_loss 8.238
2022-03-07 18:10:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36292 updates
2022-03-07 18:10:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:10:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:10:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 746 @ 36292 updates, score 15.03) (writing took 2.482001096010208 seconds)
2022-03-07 18:10:38 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-07 18:10:38 | INFO | train | epoch 746 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24397.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36292 | lr 0.000165995 | gnorm 0.277 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 104913
2022-03-07 18:10:38 | INFO | fairseq.trainer | begin training epoch 747
2022-03-07 18:10:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:10:58 | INFO | train_inner | epoch 747:      8 / 49 loss=0.4, nll_loss=0.104, ppl=1.07, wps=24723.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.276, loss_scale=64, train_wall=224, gb_free=8.8, wall=104933
2022-03-07 18:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:12:43 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 14.974 | nll_loss 14.876 | ppl 30067.4 | wps 46935.7 | wpb 510.9 | bsz 1 | num_updates 36341 | best_loss 8.238
2022-03-07 18:12:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36341 updates
2022-03-07 18:12:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 747 @ 36341 updates, score 14.974) (writing took 2.5160928927361965 seconds)
2022-03-07 18:12:46 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-07 18:12:46 | INFO | train | epoch 747 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24961.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36341 | lr 0.000165883 | gnorm 0.277 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 105041
2022-03-07 18:12:46 | INFO | fairseq.trainer | begin training epoch 748
2022-03-07 18:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:14:51 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 15.09 | nll_loss 14.991 | ppl 32558.5 | wps 46932.7 | wpb 510.9 | bsz 1 | num_updates 36390 | best_loss 8.238
2022-03-07 18:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36390 updates
2022-03-07 18:14:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:14:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 748 @ 36390 updates, score 15.09) (writing took 2.494203921407461 seconds)
2022-03-07 18:14:53 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-07 18:14:53 | INFO | train | epoch 748 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24877 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36390 | lr 0.000165771 | gnorm 0.276 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 105168
2022-03-07 18:14:53 | INFO | fairseq.trainer | begin training epoch 749
2022-03-07 18:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:15:18 | INFO | train_inner | epoch 749:     10 / 49 loss=0.4, nll_loss=0.104, ppl=1.07, wps=24952.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.276, loss_scale=128, train_wall=222, gb_free=8.8, wall=105193
2022-03-07 18:15:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:16:58 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 15.084 | nll_loss 14.987 | ppl 32463.8 | wps 46552.7 | wpb 510.9 | bsz 1 | num_updates 36438 | best_loss 8.238
2022-03-07 18:16:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36438 updates
2022-03-07 18:16:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:17:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:17:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 749 @ 36438 updates, score 15.084) (writing took 2.460162216797471 seconds)
2022-03-07 18:17:01 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-07 18:17:01 | INFO | train | epoch 749 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24444.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36438 | lr 0.000165662 | gnorm 0.276 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 105296
2022-03-07 18:17:01 | INFO | fairseq.trainer | begin training epoch 750
2022-03-07 18:17:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:19:06 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 14.976 | nll_loss 14.878 | ppl 30114 | wps 46440.1 | wpb 510.9 | bsz 1 | num_updates 36487 | best_loss 8.238
2022-03-07 18:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36487 updates
2022-03-07 18:19:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 750 @ 36487 updates, score 14.976) (writing took 2.413864605128765 seconds)
2022-03-07 18:19:08 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-07 18:19:08 | INFO | train | epoch 750 | loss 0.4 | nll_loss 0.104 | ppl 1.07 | wps 24909.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36487 | lr 0.000165551 | gnorm 0.277 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 105423
2022-03-07 18:19:08 | INFO | fairseq.trainer | begin training epoch 751
2022-03-07 18:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:19:41 | INFO | train_inner | epoch 751:     13 / 49 loss=0.4, nll_loss=0.104, ppl=1.07, wps=24697.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.278, loss_scale=64, train_wall=224, gb_free=8.8, wall=105456
2022-03-07 18:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:14 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 15.079 | nll_loss 14.98 | ppl 32325.9 | wps 46626.7 | wpb 510.9 | bsz 1 | num_updates 36536 | best_loss 8.238
2022-03-07 18:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36536 updates
2022-03-07 18:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:21:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:21:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 751 @ 36536 updates, score 15.079) (writing took 2.582223741337657 seconds)
2022-03-07 18:21:17 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-07 18:21:17 | INFO | train | epoch 751 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24719.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36536 | lr 0.00016544 | gnorm 0.276 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 105552
2022-03-07 18:21:17 | INFO | fairseq.trainer | begin training epoch 752
2022-03-07 18:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:21:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:22 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 15.019 | nll_loss 14.92 | ppl 30998.6 | wps 47161.6 | wpb 510.9 | bsz 1 | num_updates 36584 | best_loss 8.238
2022-03-07 18:23:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36584 updates
2022-03-07 18:23:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:23:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 752 @ 36584 updates, score 15.019) (writing took 2.5377127900719643 seconds)
2022-03-07 18:23:25 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-07 18:23:25 | INFO | train | epoch 752 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24340.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36584 | lr 0.000165331 | gnorm 0.275 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 105680
2022-03-07 18:23:25 | INFO | fairseq.trainer | begin training epoch 753
2022-03-07 18:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:24:04 | INFO | train_inner | epoch 753:     16 / 49 loss=0.399, nll_loss=0.103, ppl=1.07, wps=24609.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.275, loss_scale=64, train_wall=225, gb_free=8.8, wall=105719
2022-03-07 18:25:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:25:30 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 15.063 | nll_loss 14.965 | ppl 31991.1 | wps 46391.8 | wpb 510.9 | bsz 1 | num_updates 36633 | best_loss 8.238
2022-03-07 18:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36633 updates
2022-03-07 18:25:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:25:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 753 @ 36633 updates, score 15.063) (writing took 2.544660260900855 seconds)
2022-03-07 18:25:32 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-07 18:25:32 | INFO | train | epoch 753 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24914.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36633 | lr 0.00016522 | gnorm 0.274 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 105807
2022-03-07 18:25:32 | INFO | fairseq.trainer | begin training epoch 754
2022-03-07 18:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:27:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:27:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:27:37 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 15.152 | nll_loss 15.055 | ppl 34035.4 | wps 46925.1 | wpb 510.9 | bsz 1 | num_updates 36681 | best_loss 8.238
2022-03-07 18:27:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36681 updates
2022-03-07 18:27:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:27:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:27:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 754 @ 36681 updates, score 15.152) (writing took 2.5493947565555573 seconds)
2022-03-07 18:27:40 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-07 18:27:40 | INFO | train | epoch 754 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24436.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36681 | lr 0.000165112 | gnorm 0.275 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 105935
2022-03-07 18:27:40 | INFO | fairseq.trainer | begin training epoch 755
2022-03-07 18:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:28:27 | INFO | train_inner | epoch 755:     19 / 49 loss=0.399, nll_loss=0.103, ppl=1.07, wps=24738.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.274, loss_scale=64, train_wall=224, gb_free=8.8, wall=105982
2022-03-07 18:29:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:29:44 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 15.101 | nll_loss 15.005 | ppl 32879.9 | wps 46419 | wpb 510.9 | bsz 1 | num_updates 36730 | best_loss 8.238
2022-03-07 18:29:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36730 updates
2022-03-07 18:29:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 755 @ 36730 updates, score 15.101) (writing took 2.39268503151834 seconds)
2022-03-07 18:29:47 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-07 18:29:47 | INFO | train | epoch 755 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24964 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36730 | lr 0.000165002 | gnorm 0.271 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106062
2022-03-07 18:29:47 | INFO | fairseq.trainer | begin training epoch 756
2022-03-07 18:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:31:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:31:52 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 15.133 | nll_loss 15.035 | ppl 33584.1 | wps 47384.6 | wpb 510.9 | bsz 1 | num_updates 36779 | best_loss 8.238
2022-03-07 18:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36779 updates
2022-03-07 18:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 756 @ 36779 updates, score 15.133) (writing took 2.5503062084317207 seconds)
2022-03-07 18:31:54 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-07 18:31:54 | INFO | train | epoch 756 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24965.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36779 | lr 0.000164892 | gnorm 0.275 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106189
2022-03-07 18:31:54 | INFO | fairseq.trainer | begin training epoch 757
2022-03-07 18:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:32:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:32:49 | INFO | train_inner | epoch 757:     22 / 49 loss=0.399, nll_loss=0.103, ppl=1.07, wps=24748.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.275, loss_scale=64, train_wall=224, gb_free=8.8, wall=106244
2022-03-07 18:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:33:59 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 14.983 | nll_loss 14.884 | ppl 30242 | wps 47160.2 | wpb 510.9 | bsz 1 | num_updates 36827 | best_loss 8.238
2022-03-07 18:33:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36827 updates
2022-03-07 18:33:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:34:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:34:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 757 @ 36827 updates, score 14.983) (writing took 2.435717737302184 seconds)
2022-03-07 18:34:01 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-07 18:34:01 | INFO | train | epoch 757 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24484.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36827 | lr 0.000164785 | gnorm 0.277 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106316
2022-03-07 18:34:01 | INFO | fairseq.trainer | begin training epoch 758
2022-03-07 18:34:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:36:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:36:06 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 15.07 | nll_loss 14.973 | ppl 32149.8 | wps 47036.8 | wpb 510.9 | bsz 1 | num_updates 36876 | best_loss 8.238
2022-03-07 18:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36876 updates
2022-03-07 18:36:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:36:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:36:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 758 @ 36876 updates, score 15.07) (writing took 2.5303597543388605 seconds)
2022-03-07 18:36:09 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-07 18:36:09 | INFO | train | epoch 758 | loss 0.398 | nll_loss 0.102 | ppl 1.07 | wps 24917.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36876 | lr 0.000164675 | gnorm 0.273 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 106444
2022-03-07 18:36:09 | INFO | fairseq.trainer | begin training epoch 759
2022-03-07 18:36:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:37:08 | INFO | train_inner | epoch 759:     24 / 49 loss=0.398, nll_loss=0.103, ppl=1.07, wps=24983.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=36900, lr=0.000164622, gnorm=0.274, loss_scale=64, train_wall=221, gb_free=8.8, wall=106504
2022-03-07 18:38:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:38:14 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 15.059 | nll_loss 14.961 | ppl 31900.3 | wps 47002.9 | wpb 510.9 | bsz 1 | num_updates 36925 | best_loss 8.238
2022-03-07 18:38:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36925 updates
2022-03-07 18:38:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 759 @ 36925 updates, score 15.059) (writing took 2.507257055491209 seconds)
2022-03-07 18:38:16 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-07 18:38:16 | INFO | train | epoch 759 | loss 0.398 | nll_loss 0.103 | ppl 1.07 | wps 24942.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 36925 | lr 0.000164566 | gnorm 0.274 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 106571
2022-03-07 18:38:16 | INFO | fairseq.trainer | begin training epoch 760
2022-03-07 18:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:38:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:21 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 15.04 | nll_loss 14.943 | ppl 31496.2 | wps 46617 | wpb 510.9 | bsz 1 | num_updates 36973 | best_loss 8.238
2022-03-07 18:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36973 updates
2022-03-07 18:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:40:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 760 @ 36973 updates, score 15.04) (writing took 2.443164663389325 seconds)
2022-03-07 18:40:24 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-07 18:40:24 | INFO | train | epoch 760 | loss 0.399 | nll_loss 0.103 | ppl 1.07 | wps 24393.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36973 | lr 0.000164459 | gnorm 0.275 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 106699
2022-03-07 18:40:24 | INFO | fairseq.trainer | begin training epoch 761
2022-03-07 18:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:41:31 | INFO | train_inner | epoch 761:     27 / 49 loss=0.399, nll_loss=0.103, ppl=1.07, wps=24691.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.274, loss_scale=64, train_wall=224, gb_free=8.8, wall=106766
2022-03-07 18:42:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:42:29 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 15.002 | nll_loss 14.904 | ppl 30656.3 | wps 46990.4 | wpb 510.9 | bsz 1 | num_updates 37022 | best_loss 8.238
2022-03-07 18:42:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37022 updates
2022-03-07 18:42:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:42:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 761 @ 37022 updates, score 15.002) (writing took 2.4741330556571484 seconds)
2022-03-07 18:42:32 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-07 18:42:32 | INFO | train | epoch 761 | loss 0.398 | nll_loss 0.103 | ppl 1.07 | wps 24878 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37022 | lr 0.00016435 | gnorm 0.275 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 106827
2022-03-07 18:42:32 | INFO | fairseq.trainer | begin training epoch 762
2022-03-07 18:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:44:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:44:37 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 15.026 | nll_loss 14.928 | ppl 31182.7 | wps 46410.1 | wpb 510.9 | bsz 1 | num_updates 37070 | best_loss 8.238
2022-03-07 18:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37070 updates
2022-03-07 18:44:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:44:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:44:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 762 @ 37070 updates, score 15.026) (writing took 2.4337080288678408 seconds)
2022-03-07 18:44:39 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-07 18:44:39 | INFO | train | epoch 762 | loss 0.398 | nll_loss 0.102 | ppl 1.07 | wps 24354.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37070 | lr 0.000164244 | gnorm 0.271 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 106955
2022-03-07 18:44:39 | INFO | fairseq.trainer | begin training epoch 763
2022-03-07 18:44:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:45:54 | INFO | train_inner | epoch 763:     30 / 49 loss=0.398, nll_loss=0.103, ppl=1.07, wps=24688.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.272, loss_scale=64, train_wall=224, gb_free=8.8, wall=107029
2022-03-07 18:46:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:46:44 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 15.077 | nll_loss 14.98 | ppl 32317.2 | wps 47163.3 | wpb 510.9 | bsz 1 | num_updates 37119 | best_loss 8.238
2022-03-07 18:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37119 updates
2022-03-07 18:46:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:46:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:46:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 763 @ 37119 updates, score 15.077) (writing took 2.476940954104066 seconds)
2022-03-07 18:46:47 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-07 18:46:47 | INFO | train | epoch 763 | loss 0.398 | nll_loss 0.102 | ppl 1.07 | wps 24948.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37119 | lr 0.000164135 | gnorm 0.272 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107082
2022-03-07 18:46:47 | INFO | fairseq.trainer | begin training epoch 764
2022-03-07 18:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:48:51 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 15.023 | nll_loss 14.926 | ppl 31124.5 | wps 46514.3 | wpb 510.9 | bsz 1 | num_updates 37168 | best_loss 8.238
2022-03-07 18:48:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37168 updates
2022-03-07 18:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:48:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 764 @ 37168 updates, score 15.023) (writing took 2.5334346182644367 seconds)
2022-03-07 18:48:54 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-07 18:48:54 | INFO | train | epoch 764 | loss 0.398 | nll_loss 0.102 | ppl 1.07 | wps 24972.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37168 | lr 0.000164027 | gnorm 0.273 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107209
2022-03-07 18:48:54 | INFO | fairseq.trainer | begin training epoch 765
2022-03-07 18:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:50:16 | INFO | train_inner | epoch 765:     33 / 49 loss=0.398, nll_loss=0.102, ppl=1.07, wps=24763.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.272, loss_scale=64, train_wall=223, gb_free=8.8, wall=107291
2022-03-07 18:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:50:59 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 15.032 | nll_loss 14.934 | ppl 31297.5 | wps 47551.4 | wpb 510.9 | bsz 1 | num_updates 37216 | best_loss 8.238
2022-03-07 18:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37216 updates
2022-03-07 18:50:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:51:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:51:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 765 @ 37216 updates, score 15.032) (writing took 2.487889740616083 seconds)
2022-03-07 18:51:01 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-07 18:51:01 | INFO | train | epoch 765 | loss 0.398 | nll_loss 0.102 | ppl 1.07 | wps 24428.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37216 | lr 0.000163921 | gnorm 0.273 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107337
2022-03-07 18:51:01 | INFO | fairseq.trainer | begin training epoch 766
2022-03-07 18:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:53:06 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 15.027 | nll_loss 14.929 | ppl 31184.2 | wps 47093.2 | wpb 510.9 | bsz 1 | num_updates 37265 | best_loss 8.238
2022-03-07 18:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37265 updates
2022-03-07 18:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:53:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 766 @ 37265 updates, score 15.027) (writing took 2.484698360785842 seconds)
2022-03-07 18:53:09 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-07 18:53:09 | INFO | train | epoch 766 | loss 0.397 | nll_loss 0.102 | ppl 1.07 | wps 24946.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37265 | lr 0.000163813 | gnorm 0.271 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107464
2022-03-07 18:53:09 | INFO | fairseq.trainer | begin training epoch 767
2022-03-07 18:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:54:36 | INFO | train_inner | epoch 767:     35 / 49 loss=0.397, nll_loss=0.102, ppl=1.07, wps=24951.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.271, loss_scale=64, train_wall=222, gb_free=8.8, wall=107551
2022-03-07 18:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:55:14 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 15.121 | nll_loss 15.024 | ppl 33325.3 | wps 47583.4 | wpb 510.9 | bsz 1 | num_updates 37314 | best_loss 8.238
2022-03-07 18:55:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37314 updates
2022-03-07 18:55:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 767 @ 37314 updates, score 15.121) (writing took 2.522449741140008 seconds)
2022-03-07 18:55:16 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-07 18:55:16 | INFO | train | epoch 767 | loss 0.397 | nll_loss 0.102 | ppl 1.07 | wps 24915.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37314 | lr 0.000163706 | gnorm 0.271 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 107592
2022-03-07 18:55:16 | INFO | fairseq.trainer | begin training epoch 768
2022-03-07 18:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:55:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 18:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:57:21 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 15.073 | nll_loss 14.975 | ppl 32212.1 | wps 46872.9 | wpb 510.9 | bsz 1 | num_updates 37362 | best_loss 8.238
2022-03-07 18:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37362 updates
2022-03-07 18:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 768 @ 37362 updates, score 15.073) (writing took 2.5001796185970306 seconds)
2022-03-07 18:57:24 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-07 18:57:24 | INFO | train | epoch 768 | loss 0.397 | nll_loss 0.101 | ppl 1.07 | wps 24442.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37362 | lr 0.000163601 | gnorm 0.271 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107719
2022-03-07 18:57:24 | INFO | fairseq.trainer | begin training epoch 769
2022-03-07 18:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:58:58 | INFO | train_inner | epoch 769:     38 / 49 loss=0.397, nll_loss=0.102, ppl=1.07, wps=24750.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.272, loss_scale=64, train_wall=224, gb_free=8.8, wall=107813
2022-03-07 18:59:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:29 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 15.091 | nll_loss 14.991 | ppl 32571.1 | wps 45918.6 | wpb 510.9 | bsz 1 | num_updates 37411 | best_loss 8.238
2022-03-07 18:59:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37411 updates
2022-03-07 18:59:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 18:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 769 @ 37411 updates, score 15.091) (writing took 2.387899784371257 seconds)
2022-03-07 18:59:31 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-07 18:59:31 | INFO | train | epoch 769 | loss 0.397 | nll_loss 0.102 | ppl 1.07 | wps 24943.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37411 | lr 0.000163493 | gnorm 0.274 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 107846
2022-03-07 18:59:31 | INFO | fairseq.trainer | begin training epoch 770
2022-03-07 18:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:01:37 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 15.141 | nll_loss 15.045 | ppl 33807 | wps 46182.8 | wpb 510.9 | bsz 1 | num_updates 37460 | best_loss 8.238
2022-03-07 19:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37460 updates
2022-03-07 19:01:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:01:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:01:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 770 @ 37460 updates, score 15.141) (writing took 2.5678060576319695 seconds)
2022-03-07 19:01:40 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-07 19:01:40 | INFO | train | epoch 770 | loss 0.397 | nll_loss 0.101 | ppl 1.07 | wps 24741 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37460 | lr 0.000163386 | gnorm 0.273 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 107975
2022-03-07 19:01:40 | INFO | fairseq.trainer | begin training epoch 771
2022-03-07 19:01:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:01:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:03:22 | INFO | train_inner | epoch 771:     41 / 49 loss=0.397, nll_loss=0.102, ppl=1.07, wps=24586.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.274, loss_scale=64, train_wall=225, gb_free=8.8, wall=108077
2022-03-07 19:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:03:45 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 15.012 | nll_loss 14.915 | ppl 30901.6 | wps 46765 | wpb 510.9 | bsz 1 | num_updates 37508 | best_loss 8.238
2022-03-07 19:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37508 updates
2022-03-07 19:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 771 @ 37508 updates, score 15.012) (writing took 2.5357732102274895 seconds)
2022-03-07 19:03:48 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-07 19:03:48 | INFO | train | epoch 771 | loss 0.397 | nll_loss 0.102 | ppl 1.07 | wps 24299.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37508 | lr 0.000163282 | gnorm 0.275 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108103
2022-03-07 19:03:48 | INFO | fairseq.trainer | begin training epoch 772
2022-03-07 19:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:05:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:05:53 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 15.053 | nll_loss 14.956 | ppl 31788.7 | wps 46384.6 | wpb 510.9 | bsz 1 | num_updates 37557 | best_loss 8.238
2022-03-07 19:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37557 updates
2022-03-07 19:05:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:05:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 772 @ 37557 updates, score 15.053) (writing took 2.55315107293427 seconds)
2022-03-07 19:05:56 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-07 19:05:56 | INFO | train | epoch 772 | loss 0.397 | nll_loss 0.102 | ppl 1.07 | wps 24835.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37557 | lr 0.000163175 | gnorm 0.274 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108231
2022-03-07 19:05:56 | INFO | fairseq.trainer | begin training epoch 773
2022-03-07 19:05:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:07:45 | INFO | train_inner | epoch 773:     44 / 49 loss=0.397, nll_loss=0.102, ppl=1.07, wps=24641.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.273, loss_scale=64, train_wall=224, gb_free=8.8, wall=108340
2022-03-07 19:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:08:01 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 14.999 | nll_loss 14.902 | ppl 30622.9 | wps 46752.3 | wpb 510.9 | bsz 1 | num_updates 37605 | best_loss 8.238
2022-03-07 19:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37605 updates
2022-03-07 19:08:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:08:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:08:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 773 @ 37605 updates, score 14.999) (writing took 2.5849761310964823 seconds)
2022-03-07 19:08:03 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-07 19:08:03 | INFO | train | epoch 773 | loss 0.397 | nll_loss 0.102 | ppl 1.07 | wps 24350.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37605 | lr 0.000163071 | gnorm 0.272 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108359
2022-03-07 19:08:03 | INFO | fairseq.trainer | begin training epoch 774
2022-03-07 19:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:10:09 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 14.919 | nll_loss 14.822 | ppl 28955.8 | wps 46770.6 | wpb 510.9 | bsz 1 | num_updates 37654 | best_loss 8.238
2022-03-07 19:10:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37654 updates
2022-03-07 19:10:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:10:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:10:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 774 @ 37654 updates, score 14.919) (writing took 2.4776084572076797 seconds)
2022-03-07 19:10:11 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-07 19:10:11 | INFO | train | epoch 774 | loss 0.397 | nll_loss 0.101 | ppl 1.07 | wps 24826.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37654 | lr 0.000162965 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108487
2022-03-07 19:10:11 | INFO | fairseq.trainer | begin training epoch 775
2022-03-07 19:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:12:06 | INFO | train_inner | epoch 775:     46 / 49 loss=0.396, nll_loss=0.101, ppl=1.07, wps=24834.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.269, loss_scale=64, train_wall=223, gb_free=8.8, wall=108601
2022-03-07 19:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:12:17 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 14.957 | nll_loss 14.859 | ppl 29715.2 | wps 46658.5 | wpb 510.9 | bsz 1 | num_updates 37703 | best_loss 8.238
2022-03-07 19:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37703 updates
2022-03-07 19:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:12:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 775 @ 37703 updates, score 14.957) (writing took 2.487925475463271 seconds)
2022-03-07 19:12:20 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-07 19:12:20 | INFO | train | epoch 775 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24790.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37703 | lr 0.000162859 | gnorm 0.269 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108615
2022-03-07 19:12:20 | INFO | fairseq.trainer | begin training epoch 776
2022-03-07 19:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:13:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:14:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:14:25 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 15.091 | nll_loss 14.994 | ppl 32627.6 | wps 47137.5 | wpb 510.9 | bsz 1 | num_updates 37751 | best_loss 8.238
2022-03-07 19:14:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37751 updates
2022-03-07 19:14:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:14:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 776 @ 37751 updates, score 15.091) (writing took 2.5470261704176664 seconds)
2022-03-07 19:14:28 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-07 19:14:28 | INFO | train | epoch 776 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24286.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37751 | lr 0.000162756 | gnorm 0.272 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108743
2022-03-07 19:14:28 | INFO | fairseq.trainer | begin training epoch 777
2022-03-07 19:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:16:28 | INFO | train_inner | epoch 777:     49 / 49 loss=0.396, nll_loss=0.101, ppl=1.07, wps=24613.9, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=37800, lr=0.00016265, gnorm=0.273, loss_scale=64, train_wall=224, gb_free=8.8, wall=108864
2022-03-07 19:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:16:33 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 15.043 | nll_loss 14.945 | ppl 31536.6 | wps 46763.3 | wpb 510.9 | bsz 1 | num_updates 37800 | best_loss 8.238
2022-03-07 19:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37800 updates
2022-03-07 19:16:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:16:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:16:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 777 @ 37800 updates, score 15.043) (writing took 2.5297877360135317 seconds)
2022-03-07 19:16:36 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-07 19:16:36 | INFO | train | epoch 777 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24851.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37800 | lr 0.00016265 | gnorm 0.272 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108871
2022-03-07 19:16:36 | INFO | fairseq.trainer | begin training epoch 778
2022-03-07 19:16:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:18:42 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 15.009 | nll_loss 14.912 | ppl 30818.9 | wps 46741.7 | wpb 510.9 | bsz 1 | num_updates 37849 | best_loss 8.238
2022-03-07 19:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37849 updates
2022-03-07 19:18:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 778 @ 37849 updates, score 15.009) (writing took 2.4859191235154867 seconds)
2022-03-07 19:18:44 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-07 19:18:44 | INFO | train | epoch 778 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24755.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37849 | lr 0.000162545 | gnorm 0.271 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 108999
2022-03-07 19:18:44 | INFO | fairseq.trainer | begin training epoch 779
2022-03-07 19:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:19:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:20:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:50 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 15.117 | nll_loss 15.019 | ppl 33208.6 | wps 46203.4 | wpb 510.9 | bsz 1 | num_updates 37897 | best_loss 8.238
2022-03-07 19:20:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37897 updates
2022-03-07 19:20:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:20:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:20:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 779 @ 37897 updates, score 15.117) (writing took 2.582543132826686 seconds)
2022-03-07 19:20:52 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-07 19:20:53 | INFO | train | epoch 779 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24239.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 37897 | lr 0.000162442 | gnorm 0.271 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 109128
2022-03-07 19:20:53 | INFO | fairseq.trainer | begin training epoch 780
2022-03-07 19:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:21:00 | INFO | train_inner | epoch 780:      3 / 49 loss=0.396, nll_loss=0.101, ppl=1.07, wps=23884.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=37900, lr=0.000162435, gnorm=0.271, loss_scale=64, train_wall=225, gb_free=8.8, wall=109135
2022-03-07 19:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:22:58 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 15.013 | nll_loss 14.915 | ppl 30902.5 | wps 46792.2 | wpb 510.9 | bsz 1 | num_updates 37946 | best_loss 8.238
2022-03-07 19:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37946 updates
2022-03-07 19:22:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:23:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:23:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 780 @ 37946 updates, score 15.013) (writing took 2.5126401018351316 seconds)
2022-03-07 19:23:00 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-07 19:23:00 | INFO | train | epoch 780 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24869.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37946 | lr 0.000162337 | gnorm 0.268 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 109255
2022-03-07 19:23:00 | INFO | fairseq.trainer | begin training epoch 781
2022-03-07 19:23:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:24:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:25:05 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 15.084 | nll_loss 14.987 | ppl 32481 | wps 47084.8 | wpb 510.9 | bsz 1 | num_updates 37994 | best_loss 8.238
2022-03-07 19:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 37994 updates
2022-03-07 19:25:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:25:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:25:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 781 @ 37994 updates, score 15.084) (writing took 2.5185071900486946 seconds)
2022-03-07 19:25:08 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-07 19:25:08 | INFO | train | epoch 781 | loss 0.395 | nll_loss 0.1 | ppl 1.07 | wps 24380.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37994 | lr 0.000162234 | gnorm 0.269 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 109383
2022-03-07 19:25:08 | INFO | fairseq.trainer | begin training epoch 782
2022-03-07 19:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:25:23 | INFO | train_inner | epoch 782:      6 / 49 loss=0.396, nll_loss=0.101, ppl=1.07, wps=24675.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.268, loss_scale=64, train_wall=224, gb_free=8.8, wall=109398
2022-03-07 19:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:27:13 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 15.034 | nll_loss 14.937 | ppl 31368 | wps 46676.6 | wpb 510.9 | bsz 1 | num_updates 38043 | best_loss 8.238
2022-03-07 19:27:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38043 updates
2022-03-07 19:27:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:27:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 782 @ 38043 updates, score 15.034) (writing took 2.5381607599556446 seconds)
2022-03-07 19:27:16 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-07 19:27:16 | INFO | train | epoch 782 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24850.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38043 | lr 0.00016213 | gnorm 0.271 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 109511
2022-03-07 19:27:16 | INFO | fairseq.trainer | begin training epoch 783
2022-03-07 19:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:29:21 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 15.131 | nll_loss 15.035 | ppl 33566.1 | wps 46683.4 | wpb 510.9 | bsz 1 | num_updates 38092 | best_loss 8.238
2022-03-07 19:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38092 updates
2022-03-07 19:29:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:29:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 783 @ 38092 updates, score 15.131) (writing took 2.5244420655071735 seconds)
2022-03-07 19:29:24 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-07 19:29:24 | INFO | train | epoch 783 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24835.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38092 | lr 0.000162025 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 109639
2022-03-07 19:29:24 | INFO | fairseq.trainer | begin training epoch 784
2022-03-07 19:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:29:44 | INFO | train_inner | epoch 784:      8 / 49 loss=0.396, nll_loss=0.101, ppl=1.07, wps=24868.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.271, loss_scale=64, train_wall=222, gb_free=8.8, wall=109659
2022-03-07 19:30:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:31:29 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 14.983 | nll_loss 14.886 | ppl 30285.8 | wps 47058.8 | wpb 510.9 | bsz 1 | num_updates 38140 | best_loss 8.238
2022-03-07 19:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38140 updates
2022-03-07 19:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 784 @ 38140 updates, score 14.983) (writing took 2.484077997505665 seconds)
2022-03-07 19:31:32 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-07 19:31:32 | INFO | train | epoch 784 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24325.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38140 | lr 0.000161923 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 109767
2022-03-07 19:31:32 | INFO | fairseq.trainer | begin training epoch 785
2022-03-07 19:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:33:37 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 15.081 | nll_loss 14.985 | ppl 32422 | wps 45642.3 | wpb 510.9 | bsz 1 | num_updates 38189 | best_loss 8.238
2022-03-07 19:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38189 updates
2022-03-07 19:33:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:33:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:33:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 785 @ 38189 updates, score 15.081) (writing took 2.543488522991538 seconds)
2022-03-07 19:33:40 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-07 19:33:40 | INFO | train | epoch 785 | loss 0.395 | nll_loss 0.1 | ppl 1.07 | wps 24801.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38189 | lr 0.00016182 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 109895
2022-03-07 19:33:40 | INFO | fairseq.trainer | begin training epoch 786
2022-03-07 19:33:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:34:07 | INFO | train_inner | epoch 786:     11 / 49 loss=0.395, nll_loss=0.1, ppl=1.07, wps=24612.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.268, loss_scale=64, train_wall=225, gb_free=8.8, wall=109923
2022-03-07 19:35:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:35:45 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 15.062 | nll_loss 14.964 | ppl 31970.6 | wps 46790.6 | wpb 510.9 | bsz 1 | num_updates 38238 | best_loss 8.238
2022-03-07 19:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38238 updates
2022-03-07 19:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:35:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:35:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 786 @ 38238 updates, score 15.062) (writing took 2.5119212195277214 seconds)
2022-03-07 19:35:48 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-07 19:35:48 | INFO | train | epoch 786 | loss 0.396 | nll_loss 0.101 | ppl 1.07 | wps 24838.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38238 | lr 0.000161716 | gnorm 0.269 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110023
2022-03-07 19:35:48 | INFO | fairseq.trainer | begin training epoch 787
2022-03-07 19:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:36:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:37:53 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 15.071 | nll_loss 14.974 | ppl 32179.6 | wps 46402.4 | wpb 510.9 | bsz 1 | num_updates 38286 | best_loss 8.238
2022-03-07 19:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38286 updates
2022-03-07 19:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:37:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 787 @ 38286 updates, score 15.071) (writing took 2.5304999630898237 seconds)
2022-03-07 19:37:56 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-07 19:37:56 | INFO | train | epoch 787 | loss 0.395 | nll_loss 0.1 | ppl 1.07 | wps 24295.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38286 | lr 0.000161614 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110151
2022-03-07 19:37:56 | INFO | fairseq.trainer | begin training epoch 788
2022-03-07 19:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:38:31 | INFO | train_inner | epoch 788:     14 / 49 loss=0.395, nll_loss=0.1, ppl=1.07, wps=24619.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.271, loss_scale=64, train_wall=225, gb_free=8.8, wall=110186
2022-03-07 19:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:40:01 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 15.08 | nll_loss 14.984 | ppl 32411.4 | wps 46485.6 | wpb 510.9 | bsz 1 | num_updates 38335 | best_loss 8.238
2022-03-07 19:40:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38335 updates
2022-03-07 19:40:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 788 @ 38335 updates, score 15.08) (writing took 2.5500056985765696 seconds)
2022-03-07 19:40:04 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-07 19:40:04 | INFO | train | epoch 788 | loss 0.395 | nll_loss 0.101 | ppl 1.07 | wps 24841.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38335 | lr 0.000161511 | gnorm 0.272 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110279
2022-03-07 19:40:04 | INFO | fairseq.trainer | begin training epoch 789
2022-03-07 19:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:42:09 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 15.082 | nll_loss 14.985 | ppl 32424.2 | wps 47159.3 | wpb 510.9 | bsz 1 | num_updates 38384 | best_loss 8.238
2022-03-07 19:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38384 updates
2022-03-07 19:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:42:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 789 @ 38384 updates, score 15.082) (writing took 2.5142679382115602 seconds)
2022-03-07 19:42:12 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-07 19:42:12 | INFO | train | epoch 789 | loss 0.395 | nll_loss 0.101 | ppl 1.07 | wps 24848.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38384 | lr 0.000161408 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110407
2022-03-07 19:42:12 | INFO | fairseq.trainer | begin training epoch 790
2022-03-07 19:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:42:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:42:54 | INFO | train_inner | epoch 790:     17 / 49 loss=0.395, nll_loss=0.1, ppl=1.07, wps=24654.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.27, loss_scale=64, train_wall=224, gb_free=8.8, wall=110449
2022-03-07 19:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:44:17 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 15.062 | nll_loss 14.964 | ppl 31964.2 | wps 47152.4 | wpb 510.9 | bsz 1 | num_updates 38432 | best_loss 8.238
2022-03-07 19:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38432 updates
2022-03-07 19:44:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 790 @ 38432 updates, score 15.062) (writing took 2.537938529625535 seconds)
2022-03-07 19:44:19 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-07 19:44:19 | INFO | train | epoch 790 | loss 0.395 | nll_loss 0.1 | ppl 1.07 | wps 24419.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38432 | lr 0.000161307 | gnorm 0.269 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 110534
2022-03-07 19:44:19 | INFO | fairseq.trainer | begin training epoch 791
2022-03-07 19:44:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:46:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:46:24 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 15.087 | nll_loss 14.99 | ppl 32540.8 | wps 46771 | wpb 510.9 | bsz 1 | num_updates 38481 | best_loss 8.238
2022-03-07 19:46:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38481 updates
2022-03-07 19:46:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:46:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:46:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 791 @ 38481 updates, score 15.087) (writing took 2.4985420145094395 seconds)
2022-03-07 19:46:27 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-07 19:46:27 | INFO | train | epoch 791 | loss 0.395 | nll_loss 0.1 | ppl 1.07 | wps 24921.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38481 | lr 0.000161204 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110662
2022-03-07 19:46:27 | INFO | fairseq.trainer | begin training epoch 792
2022-03-07 19:46:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:47:14 | INFO | train_inner | epoch 792:     19 / 49 loss=0.395, nll_loss=0.1, ppl=1.07, wps=24928.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.268, loss_scale=64, train_wall=222, gb_free=8.8, wall=110709
2022-03-07 19:48:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:48:32 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 15.005 | nll_loss 14.907 | ppl 30732.3 | wps 46656.5 | wpb 510.9 | bsz 1 | num_updates 38529 | best_loss 8.238
2022-03-07 19:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38529 updates
2022-03-07 19:48:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:48:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:48:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 792 @ 38529 updates, score 15.005) (writing took 2.468740940093994 seconds)
2022-03-07 19:48:35 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-07 19:48:35 | INFO | train | epoch 792 | loss 0.395 | nll_loss 0.1 | ppl 1.07 | wps 24290.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38529 | lr 0.000161104 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110790
2022-03-07 19:48:35 | INFO | fairseq.trainer | begin training epoch 793
2022-03-07 19:48:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:50:41 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 14.997 | nll_loss 14.9 | ppl 30572.4 | wps 46654.3 | wpb 510.9 | bsz 1 | num_updates 38578 | best_loss 8.238
2022-03-07 19:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38578 updates
2022-03-07 19:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 793 @ 38578 updates, score 14.997) (writing took 2.472032558172941 seconds)
2022-03-07 19:50:43 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-07 19:50:43 | INFO | train | epoch 793 | loss 0.395 | nll_loss 0.1 | ppl 1.07 | wps 24807 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38578 | lr 0.000161002 | gnorm 0.268 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 110918
2022-03-07 19:50:43 | INFO | fairseq.trainer | begin training epoch 794
2022-03-07 19:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:51:38 | INFO | train_inner | epoch 794:     22 / 49 loss=0.395, nll_loss=0.1, ppl=1.07, wps=24605.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.269, loss_scale=64, train_wall=225, gb_free=8.8, wall=110973
2022-03-07 19:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:52:49 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 14.979 | nll_loss 14.881 | ppl 30178.7 | wps 46696.1 | wpb 510.9 | bsz 1 | num_updates 38627 | best_loss 8.238
2022-03-07 19:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38627 updates
2022-03-07 19:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:52:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:52:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 794 @ 38627 updates, score 14.979) (writing took 2.492712177336216 seconds)
2022-03-07 19:52:51 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-07 19:52:51 | INFO | train | epoch 794 | loss 0.394 | nll_loss 0.1 | ppl 1.07 | wps 24833.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38627 | lr 0.000160899 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111046
2022-03-07 19:52:51 | INFO | fairseq.trainer | begin training epoch 795
2022-03-07 19:52:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:53:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 19:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:54:57 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 15.076 | nll_loss 14.979 | ppl 32298 | wps 46708.2 | wpb 510.9 | bsz 1 | num_updates 38675 | best_loss 8.238
2022-03-07 19:54:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38675 updates
2022-03-07 19:54:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:54:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 795 @ 38675 updates, score 15.076) (writing took 2.4731169044971466 seconds)
2022-03-07 19:54:59 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-07 19:54:59 | INFO | train | epoch 795 | loss 0.394 | nll_loss 0.1 | ppl 1.07 | wps 24306.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38675 | lr 0.0001608 | gnorm 0.273 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111174
2022-03-07 19:54:59 | INFO | fairseq.trainer | begin training epoch 796
2022-03-07 19:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:56:02 | INFO | train_inner | epoch 796:     25 / 49 loss=0.394, nll_loss=0.099, ppl=1.07, wps=24603.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.269, loss_scale=64, train_wall=225, gb_free=8.8, wall=111237
2022-03-07 19:57:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:57:05 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 15.078 | nll_loss 14.981 | ppl 32348 | wps 47081.7 | wpb 510.9 | bsz 1 | num_updates 38724 | best_loss 8.238
2022-03-07 19:57:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38724 updates
2022-03-07 19:57:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 796 @ 38724 updates, score 15.078) (writing took 2.487459661439061 seconds)
2022-03-07 19:57:07 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-07 19:57:07 | INFO | train | epoch 796 | loss 0.394 | nll_loss 0.099 | ppl 1.07 | wps 24759.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38724 | lr 0.000160698 | gnorm 0.268 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111303
2022-03-07 19:57:07 | INFO | fairseq.trainer | begin training epoch 797
2022-03-07 19:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:59:13 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 15.113 | nll_loss 15.017 | ppl 33157.1 | wps 46644.4 | wpb 510.9 | bsz 1 | num_updates 38773 | best_loss 8.238
2022-03-07 19:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38773 updates
2022-03-07 19:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 19:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 797 @ 38773 updates, score 15.113) (writing took 2.490931250154972 seconds)
2022-03-07 19:59:16 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-07 19:59:16 | INFO | train | epoch 797 | loss 0.394 | nll_loss 0.1 | ppl 1.07 | wps 24759.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38773 | lr 0.000160596 | gnorm 0.269 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111431
2022-03-07 19:59:16 | INFO | fairseq.trainer | begin training epoch 798
2022-03-07 19:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:59:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:00:25 | INFO | train_inner | epoch 798:     28 / 49 loss=0.394, nll_loss=0.1, ppl=1.07, wps=24587.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=38800, lr=0.00016054, gnorm=0.269, loss_scale=64, train_wall=225, gb_free=8.8, wall=111501
2022-03-07 20:01:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:01:21 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 15.086 | nll_loss 14.989 | ppl 32515.2 | wps 46929.6 | wpb 510.9 | bsz 1 | num_updates 38821 | best_loss 8.238
2022-03-07 20:01:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38821 updates
2022-03-07 20:01:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:01:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:01:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 798 @ 38821 updates, score 15.086) (writing took 2.4362681228667498 seconds)
2022-03-07 20:01:24 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-07 20:01:24 | INFO | train | epoch 798 | loss 0.394 | nll_loss 0.1 | ppl 1.07 | wps 24365.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38821 | lr 0.000160497 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111559
2022-03-07 20:01:24 | INFO | fairseq.trainer | begin training epoch 799
2022-03-07 20:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:03:29 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 15.058 | nll_loss 14.961 | ppl 31899.7 | wps 47175.1 | wpb 510.9 | bsz 1 | num_updates 38870 | best_loss 8.238
2022-03-07 20:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38870 updates
2022-03-07 20:03:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:03:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 799 @ 38870 updates, score 15.058) (writing took 2.456980152055621 seconds)
2022-03-07 20:03:32 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-07 20:03:32 | INFO | train | epoch 799 | loss 0.394 | nll_loss 0.099 | ppl 1.07 | wps 24816.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38870 | lr 0.000160396 | gnorm 0.268 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111687
2022-03-07 20:03:32 | INFO | fairseq.trainer | begin training epoch 800
2022-03-07 20:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:04:46 | INFO | train_inner | epoch 800:     30 / 49 loss=0.394, nll_loss=0.1, ppl=1.07, wps=24867.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.269, loss_scale=64, train_wall=222, gb_free=8.8, wall=111761
2022-03-07 20:05:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:05:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:05:37 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 15.096 | nll_loss 15 | ppl 32772.5 | wps 46162.7 | wpb 510.9 | bsz 1 | num_updates 38918 | best_loss 8.238
2022-03-07 20:05:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38918 updates
2022-03-07 20:05:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:05:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 800 @ 38918 updates, score 15.096) (writing took 2.494316179305315 seconds)
2022-03-07 20:05:40 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-07 20:05:40 | INFO | train | epoch 800 | loss 0.394 | nll_loss 0.1 | ppl 1.07 | wps 24291.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 38918 | lr 0.000160297 | gnorm 0.27 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111815
2022-03-07 20:05:40 | INFO | fairseq.trainer | begin training epoch 801
2022-03-07 20:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:07:46 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 14.977 | nll_loss 14.879 | ppl 30134.1 | wps 46087 | wpb 510.9 | bsz 1 | num_updates 38967 | best_loss 8.238
2022-03-07 20:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38967 updates
2022-03-07 20:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 801 @ 38967 updates, score 14.977) (writing took 2.521028069779277 seconds)
2022-03-07 20:07:48 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-07 20:07:48 | INFO | train | epoch 801 | loss 0.394 | nll_loss 0.1 | ppl 1.07 | wps 24765.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 38967 | lr 0.000160196 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 111943
2022-03-07 20:07:48 | INFO | fairseq.trainer | begin training epoch 802
2022-03-07 20:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:10 | INFO | train_inner | epoch 802:     33 / 49 loss=0.394, nll_loss=0.099, ppl=1.07, wps=24579, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.268, loss_scale=64, train_wall=225, gb_free=8.8, wall=112025
2022-03-07 20:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:09:54 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 15.047 | nll_loss 14.95 | ppl 31662.2 | wps 45872.5 | wpb 510.9 | bsz 1 | num_updates 39016 | best_loss 8.238
2022-03-07 20:09:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39016 updates
2022-03-07 20:09:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:09:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 802 @ 39016 updates, score 15.047) (writing took 2.4795510694384575 seconds)
2022-03-07 20:09:56 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-07 20:09:56 | INFO | train | epoch 802 | loss 0.394 | nll_loss 0.099 | ppl 1.07 | wps 24819.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39016 | lr 0.000160095 | gnorm 0.268 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112071
2022-03-07 20:09:56 | INFO | fairseq.trainer | begin training epoch 803
2022-03-07 20:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:10:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:12:01 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 15.112 | nll_loss 15.016 | ppl 33125.4 | wps 46862.4 | wpb 510.9 | bsz 1 | num_updates 39064 | best_loss 8.238
2022-03-07 20:12:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39064 updates
2022-03-07 20:12:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:12:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 803 @ 39064 updates, score 15.112) (writing took 2.516778999939561 seconds)
2022-03-07 20:12:04 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-07 20:12:04 | INFO | train | epoch 803 | loss 0.393 | nll_loss 0.099 | ppl 1.07 | wps 24334.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39064 | lr 0.000159997 | gnorm 0.268 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112199
2022-03-07 20:12:04 | INFO | fairseq.trainer | begin training epoch 804
2022-03-07 20:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:13:34 | INFO | train_inner | epoch 804:     36 / 49 loss=0.394, nll_loss=0.099, ppl=1.07, wps=24621.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.269, loss_scale=64, train_wall=225, gb_free=8.8, wall=112289
2022-03-07 20:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:14:10 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 15.034 | nll_loss 14.938 | ppl 31380.1 | wps 46724.5 | wpb 510.9 | bsz 1 | num_updates 39113 | best_loss 8.238
2022-03-07 20:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39113 updates
2022-03-07 20:14:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:14:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:14:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 804 @ 39113 updates, score 15.034) (writing took 2.5243784729391336 seconds)
2022-03-07 20:14:12 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-07 20:14:12 | INFO | train | epoch 804 | loss 0.394 | nll_loss 0.099 | ppl 1.07 | wps 24809.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39113 | lr 0.000159897 | gnorm 0.269 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112327
2022-03-07 20:14:12 | INFO | fairseq.trainer | begin training epoch 805
2022-03-07 20:14:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:16:18 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 14.966 | nll_loss 14.869 | ppl 29914.8 | wps 46624.9 | wpb 510.9 | bsz 1 | num_updates 39162 | best_loss 8.238
2022-03-07 20:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39162 updates
2022-03-07 20:16:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 805 @ 39162 updates, score 14.966) (writing took 2.4450383372604847 seconds)
2022-03-07 20:16:20 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-07 20:16:20 | INFO | train | epoch 805 | loss 0.393 | nll_loss 0.099 | ppl 1.07 | wps 24819.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39162 | lr 0.000159797 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112455
2022-03-07 20:16:20 | INFO | fairseq.trainer | begin training epoch 806
2022-03-07 20:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:16:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:17:57 | INFO | train_inner | epoch 806:     39 / 49 loss=0.393, nll_loss=0.098, ppl=1.07, wps=24601.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.266, loss_scale=64, train_wall=225, gb_free=8.8, wall=112552
2022-03-07 20:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:18:26 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 15.049 | nll_loss 14.952 | ppl 31697 | wps 46685.9 | wpb 510.9 | bsz 1 | num_updates 39210 | best_loss 8.238
2022-03-07 20:18:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39210 updates
2022-03-07 20:18:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:18:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 806 @ 39210 updates, score 15.049) (writing took 2.496578212827444 seconds)
2022-03-07 20:18:28 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-07 20:18:28 | INFO | train | epoch 806 | loss 0.393 | nll_loss 0.098 | ppl 1.07 | wps 24313.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 39210 | lr 0.000159699 | gnorm 0.266 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112583
2022-03-07 20:18:28 | INFO | fairseq.trainer | begin training epoch 807
2022-03-07 20:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:20:34 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 15.066 | nll_loss 14.97 | ppl 32088.8 | wps 46589.8 | wpb 510.9 | bsz 1 | num_updates 39259 | best_loss 8.238
2022-03-07 20:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39259 updates
2022-03-07 20:20:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:20:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 807 @ 39259 updates, score 15.066) (writing took 2.4467140585184097 seconds)
2022-03-07 20:20:36 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-07 20:20:36 | INFO | train | epoch 807 | loss 0.393 | nll_loss 0.099 | ppl 1.07 | wps 24831.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39259 | lr 0.000159599 | gnorm 0.266 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112711
2022-03-07 20:20:36 | INFO | fairseq.trainer | begin training epoch 808
2022-03-07 20:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:22:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:22:21 | INFO | train_inner | epoch 808:     42 / 49 loss=0.393, nll_loss=0.098, ppl=1.07, wps=24642.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.265, loss_scale=64, train_wall=224, gb_free=8.8, wall=112816
2022-03-07 20:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:22:41 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 15.064 | nll_loss 14.967 | ppl 32033.2 | wps 46614.1 | wpb 510.9 | bsz 1 | num_updates 39307 | best_loss 8.238
2022-03-07 20:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39307 updates
2022-03-07 20:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:22:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 808 @ 39307 updates, score 15.064) (writing took 2.5275166798382998 seconds)
2022-03-07 20:22:44 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-07 20:22:44 | INFO | train | epoch 808 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24337.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39307 | lr 0.000159502 | gnorm 0.263 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 112839
2022-03-07 20:22:44 | INFO | fairseq.trainer | begin training epoch 809
2022-03-07 20:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:24:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:24:49 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 15.072 | nll_loss 14.976 | ppl 32230.8 | wps 46930 | wpb 510.9 | bsz 1 | num_updates 39356 | best_loss 8.238
2022-03-07 20:24:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39356 updates
2022-03-07 20:24:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:24:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:24:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 809 @ 39356 updates, score 15.072) (writing took 2.477404771372676 seconds)
2022-03-07 20:24:51 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-07 20:24:51 | INFO | train | epoch 809 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24936.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39356 | lr 0.000159402 | gnorm 0.266 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 112967
2022-03-07 20:24:51 | INFO | fairseq.trainer | begin training epoch 810
2022-03-07 20:24:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:26:41 | INFO | train_inner | epoch 810:     44 / 49 loss=0.393, nll_loss=0.098, ppl=1.07, wps=24948.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.266, loss_scale=64, train_wall=222, gb_free=8.8, wall=113076
2022-03-07 20:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:26:57 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 14.99 | nll_loss 14.893 | ppl 30416.5 | wps 47084.7 | wpb 510.9 | bsz 1 | num_updates 39405 | best_loss 8.238
2022-03-07 20:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39405 updates
2022-03-07 20:26:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 810 @ 39405 updates, score 14.99) (writing took 2.551832176744938 seconds)
2022-03-07 20:26:59 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-07 20:26:59 | INFO | train | epoch 810 | loss 0.393 | nll_loss 0.099 | ppl 1.07 | wps 24908.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39405 | lr 0.000159303 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 113094
2022-03-07 20:26:59 | INFO | fairseq.trainer | begin training epoch 811
2022-03-07 20:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:27:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:28:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:29:04 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 15.107 | nll_loss 15.01 | ppl 33000.8 | wps 47096.2 | wpb 510.9 | bsz 1 | num_updates 39453 | best_loss 8.238
2022-03-07 20:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39453 updates
2022-03-07 20:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 811 @ 39453 updates, score 15.107) (writing took 2.5358971785753965 seconds)
2022-03-07 20:29:06 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-07 20:29:06 | INFO | train | epoch 811 | loss 0.393 | nll_loss 0.099 | ppl 1.07 | wps 24427.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39453 | lr 0.000159206 | gnorm 0.266 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 113222
2022-03-07 20:29:06 | INFO | fairseq.trainer | begin training epoch 812
2022-03-07 20:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:31:03 | INFO | train_inner | epoch 812:     47 / 49 loss=0.392, nll_loss=0.098, ppl=1.07, wps=24728.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.265, loss_scale=64, train_wall=224, gb_free=8.8, wall=113338
2022-03-07 20:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:31:11 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 15.046 | nll_loss 14.949 | ppl 31625.1 | wps 47040.8 | wpb 510.9 | bsz 1 | num_updates 39502 | best_loss 8.238
2022-03-07 20:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39502 updates
2022-03-07 20:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:31:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:31:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 812 @ 39502 updates, score 15.046) (writing took 2.4915388002991676 seconds)
2022-03-07 20:31:14 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-07 20:31:14 | INFO | train | epoch 812 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24947.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39502 | lr 0.000159107 | gnorm 0.265 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 113349
2022-03-07 20:31:14 | INFO | fairseq.trainer | begin training epoch 813
2022-03-07 20:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:33:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:33:20 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 15.043 | nll_loss 14.946 | ppl 31559.4 | wps 46593.1 | wpb 510.9 | bsz 1 | num_updates 39551 | best_loss 8.238
2022-03-07 20:33:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39551 updates
2022-03-07 20:33:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 813 @ 39551 updates, score 15.043) (writing took 2.4356056451797485 seconds)
2022-03-07 20:33:22 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-07 20:33:22 | INFO | train | epoch 813 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24764.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39551 | lr 0.000159009 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 113477
2022-03-07 20:33:22 | INFO | fairseq.trainer | begin training epoch 814
2022-03-07 20:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:33:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:35:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:35:28 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 15.055 | nll_loss 14.959 | ppl 31845.1 | wps 47067.4 | wpb 510.9 | bsz 1 | num_updates 39599 | best_loss 8.238
2022-03-07 20:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39599 updates
2022-03-07 20:35:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:35:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 814 @ 39599 updates, score 15.055) (writing took 2.429607240483165 seconds)
2022-03-07 20:35:30 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-07 20:35:30 | INFO | train | epoch 814 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24319.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39599 | lr 0.000158912 | gnorm 0.268 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 113605
2022-03-07 20:35:30 | INFO | fairseq.trainer | begin training epoch 815
2022-03-07 20:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:35:33 | INFO | train_inner | epoch 815:      1 / 49 loss=0.392, nll_loss=0.098, ppl=1.07, wps=23921.5, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=39600, lr=0.00015891, gnorm=0.268, loss_scale=64, train_wall=224, gb_free=8.8, wall=113608
2022-03-07 20:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:37:35 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 15.042 | nll_loss 14.946 | ppl 31570 | wps 47097.3 | wpb 510.9 | bsz 1 | num_updates 39648 | best_loss 8.238
2022-03-07 20:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39648 updates
2022-03-07 20:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:37:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:37:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 815 @ 39648 updates, score 15.042) (writing took 2.5197294875979424 seconds)
2022-03-07 20:37:38 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-07 20:37:38 | INFO | train | epoch 815 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24881.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39648 | lr 0.000158814 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 113733
2022-03-07 20:37:38 | INFO | fairseq.trainer | begin training epoch 816
2022-03-07 20:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:39:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:39:43 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 15.023 | nll_loss 14.928 | ppl 31176.8 | wps 47527.7 | wpb 510.9 | bsz 1 | num_updates 39696 | best_loss 8.238
2022-03-07 20:39:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39696 updates
2022-03-07 20:39:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:39:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:39:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 816 @ 39696 updates, score 15.023) (writing took 2.537188373506069 seconds)
2022-03-07 20:39:45 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-07 20:39:45 | INFO | train | epoch 816 | loss 0.391 | nll_loss 0.097 | ppl 1.07 | wps 24464.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39696 | lr 0.000158718 | gnorm 0.264 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 113860
2022-03-07 20:39:45 | INFO | fairseq.trainer | begin training epoch 817
2022-03-07 20:39:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:39:55 | INFO | train_inner | epoch 817:      4 / 49 loss=0.392, nll_loss=0.098, ppl=1.07, wps=24727.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39700, lr=0.00015871, gnorm=0.266, loss_scale=64, train_wall=224, gb_free=8.8, wall=113870
2022-03-07 20:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:41:50 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 14.903 | nll_loss 14.806 | ppl 28649.5 | wps 46592.3 | wpb 510.9 | bsz 1 | num_updates 39745 | best_loss 8.238
2022-03-07 20:41:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39745 updates
2022-03-07 20:41:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:41:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:41:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 817 @ 39745 updates, score 14.903) (writing took 2.5139162112027407 seconds)
2022-03-07 20:41:52 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-07 20:41:52 | INFO | train | epoch 817 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24964.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39745 | lr 0.00015862 | gnorm 0.268 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 113988
2022-03-07 20:41:52 | INFO | fairseq.trainer | begin training epoch 818
2022-03-07 20:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:43:58 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 15.019 | nll_loss 14.922 | ppl 31048.8 | wps 46812.7 | wpb 510.9 | bsz 1 | num_updates 39794 | best_loss 8.238
2022-03-07 20:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39794 updates
2022-03-07 20:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:44:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:44:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 818 @ 39794 updates, score 15.019) (writing took 2.5361888352781534 seconds)
2022-03-07 20:44:00 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-07 20:44:00 | INFO | train | epoch 818 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24892.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39794 | lr 0.000158523 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 114115
2022-03-07 20:44:00 | INFO | fairseq.trainer | begin training epoch 819
2022-03-07 20:44:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:44:15 | INFO | train_inner | epoch 819:      6 / 49 loss=0.392, nll_loss=0.098, ppl=1.07, wps=24959.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.266, loss_scale=64, train_wall=221, gb_free=8.8, wall=114130
2022-03-07 20:45:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:46:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:46:05 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 14.944 | nll_loss 14.847 | ppl 29479 | wps 47446.1 | wpb 510.9 | bsz 1 | num_updates 39842 | best_loss 8.238
2022-03-07 20:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39842 updates
2022-03-07 20:46:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:46:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 819 @ 39842 updates, score 14.944) (writing took 2.5589724238961935 seconds)
2022-03-07 20:46:07 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-07 20:46:07 | INFO | train | epoch 819 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24445.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39842 | lr 0.000158427 | gnorm 0.264 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 114243
2022-03-07 20:46:07 | INFO | fairseq.trainer | begin training epoch 820
2022-03-07 20:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:48:12 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 15.152 | nll_loss 15.057 | ppl 34081.3 | wps 47177.5 | wpb 510.9 | bsz 1 | num_updates 39891 | best_loss 8.238
2022-03-07 20:48:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39891 updates
2022-03-07 20:48:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:48:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:48:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 820 @ 39891 updates, score 15.152) (writing took 2.489600706845522 seconds)
2022-03-07 20:48:15 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-07 20:48:15 | INFO | train | epoch 820 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 25000.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39891 | lr 0.00015833 | gnorm 0.265 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 114370
2022-03-07 20:48:15 | INFO | fairseq.trainer | begin training epoch 821
2022-03-07 20:48:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:48:37 | INFO | train_inner | epoch 821:      9 / 49 loss=0.392, nll_loss=0.098, ppl=1.07, wps=24761.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.264, loss_scale=64, train_wall=223, gb_free=8.8, wall=114392
2022-03-07 20:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:50:20 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 14.92 | nll_loss 14.823 | ppl 28983.9 | wps 46960.1 | wpb 510.9 | bsz 1 | num_updates 39940 | best_loss 8.238
2022-03-07 20:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39940 updates
2022-03-07 20:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 821 @ 39940 updates, score 14.92) (writing took 2.5168045852333307 seconds)
2022-03-07 20:50:22 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-07 20:50:22 | INFO | train | epoch 821 | loss 0.391 | nll_loss 0.097 | ppl 1.07 | wps 24889.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39940 | lr 0.000158233 | gnorm 0.266 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 114497
2022-03-07 20:50:22 | INFO | fairseq.trainer | begin training epoch 822
2022-03-07 20:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:50:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:52:28 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 15.066 | nll_loss 14.97 | ppl 32096.6 | wps 46641.6 | wpb 510.9 | bsz 1 | num_updates 39988 | best_loss 8.238
2022-03-07 20:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 39988 updates
2022-03-07 20:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 822 @ 39988 updates, score 15.066) (writing took 2.5278527084738016 seconds)
2022-03-07 20:52:30 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-07 20:52:30 | INFO | train | epoch 822 | loss 0.392 | nll_loss 0.098 | ppl 1.07 | wps 24312.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 39988 | lr 0.000158138 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 114625
2022-03-07 20:52:30 | INFO | fairseq.trainer | begin training epoch 823
2022-03-07 20:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:53:00 | INFO | train_inner | epoch 823:     12 / 49 loss=0.392, nll_loss=0.098, ppl=1.07, wps=24648.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40000, lr=0.000158114, gnorm=0.267, loss_scale=64, train_wall=224, gb_free=8.8, wall=114655
2022-03-07 20:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:54:36 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 14.973 | nll_loss 14.876 | ppl 30077.5 | wps 46790.1 | wpb 510.9 | bsz 1 | num_updates 40037 | best_loss 8.238
2022-03-07 20:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40037 updates
2022-03-07 20:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:54:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 823 @ 40037 updates, score 14.973) (writing took 2.5014970917254686 seconds)
2022-03-07 20:54:38 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-07 20:54:38 | INFO | train | epoch 823 | loss 0.391 | nll_loss 0.097 | ppl 1.07 | wps 24837.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40037 | lr 0.000158041 | gnorm 0.264 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 114753
2022-03-07 20:54:38 | INFO | fairseq.trainer | begin training epoch 824
2022-03-07 20:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:56:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 20:56:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:56:44 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 15.174 | nll_loss 15.079 | ppl 34615 | wps 46556.8 | wpb 510.9 | bsz 1 | num_updates 40085 | best_loss 8.238
2022-03-07 20:56:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40085 updates
2022-03-07 20:56:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:56:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 824 @ 40085 updates, score 15.174) (writing took 2.502844722941518 seconds)
2022-03-07 20:56:46 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-07 20:56:46 | INFO | train | epoch 824 | loss 0.391 | nll_loss 0.098 | ppl 1.07 | wps 24333.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40085 | lr 0.000157946 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 114881
2022-03-07 20:56:46 | INFO | fairseq.trainer | begin training epoch 825
2022-03-07 20:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:57:24 | INFO | train_inner | epoch 825:     15 / 49 loss=0.391, nll_loss=0.097, ppl=1.07, wps=24627.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.265, loss_scale=64, train_wall=225, gb_free=8.8, wall=114919
2022-03-07 20:58:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:58:52 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 15.009 | nll_loss 14.912 | ppl 30838.5 | wps 46393.8 | wpb 510.9 | bsz 1 | num_updates 40134 | best_loss 8.238
2022-03-07 20:58:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40134 updates
2022-03-07 20:58:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:58:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 20:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 825 @ 40134 updates, score 15.009) (writing took 2.5695616975426674 seconds)
2022-03-07 20:58:54 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-07 20:58:54 | INFO | train | epoch 825 | loss 0.391 | nll_loss 0.098 | ppl 1.07 | wps 24783.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40134 | lr 0.00015785 | gnorm 0.267 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115010
2022-03-07 20:58:54 | INFO | fairseq.trainer | begin training epoch 826
2022-03-07 20:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:01:00 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 15.156 | nll_loss 15.06 | ppl 34159.6 | wps 46535.8 | wpb 510.9 | bsz 1 | num_updates 40183 | best_loss 8.238
2022-03-07 21:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40183 updates
2022-03-07 21:01:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:01:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 826 @ 40183 updates, score 15.156) (writing took 2.4957212433218956 seconds)
2022-03-07 21:01:02 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-07 21:01:02 | INFO | train | epoch 826 | loss 0.391 | nll_loss 0.098 | ppl 1.07 | wps 24809.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40183 | lr 0.000157753 | gnorm 0.264 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115138
2022-03-07 21:01:02 | INFO | fairseq.trainer | begin training epoch 827
2022-03-07 21:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:01:45 | INFO | train_inner | epoch 827:     17 / 49 loss=0.391, nll_loss=0.098, ppl=1.07, wps=24831.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.265, loss_scale=64, train_wall=223, gb_free=8.8, wall=115180
2022-03-07 21:02:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:03:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:03:08 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 15.082 | nll_loss 14.986 | ppl 32447.6 | wps 47032.7 | wpb 510.9 | bsz 1 | num_updates 40231 | best_loss 8.238
2022-03-07 21:03:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40231 updates
2022-03-07 21:03:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:03:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:03:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 827 @ 40231 updates, score 15.082) (writing took 2.547363420948386 seconds)
2022-03-07 21:03:11 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-07 21:03:11 | INFO | train | epoch 827 | loss 0.391 | nll_loss 0.097 | ppl 1.07 | wps 24301.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 40231 | lr 0.000157659 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115266
2022-03-07 21:03:11 | INFO | fairseq.trainer | begin training epoch 828
2022-03-07 21:03:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:05:16 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 14.979 | nll_loss 14.882 | ppl 30193.3 | wps 46793 | wpb 510.9 | bsz 1 | num_updates 40280 | best_loss 8.238
2022-03-07 21:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40280 updates
2022-03-07 21:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:05:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:05:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 828 @ 40280 updates, score 14.979) (writing took 2.5448267720639706 seconds)
2022-03-07 21:05:19 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-07 21:05:19 | INFO | train | epoch 828 | loss 0.391 | nll_loss 0.098 | ppl 1.07 | wps 24800.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40280 | lr 0.000157563 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115394
2022-03-07 21:05:19 | INFO | fairseq.trainer | begin training epoch 829
2022-03-07 21:05:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:06:09 | INFO | train_inner | epoch 829:     20 / 49 loss=0.391, nll_loss=0.097, ppl=1.07, wps=24603.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.264, loss_scale=64, train_wall=225, gb_free=8.8, wall=115444
2022-03-07 21:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:07:24 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 15.044 | nll_loss 14.948 | ppl 31598.6 | wps 46609 | wpb 510.9 | bsz 1 | num_updates 40329 | best_loss 8.238
2022-03-07 21:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40329 updates
2022-03-07 21:07:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:07:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 829 @ 40329 updates, score 15.044) (writing took 2.5081644635647535 seconds)
2022-03-07 21:07:27 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-07 21:07:27 | INFO | train | epoch 829 | loss 0.391 | nll_loss 0.097 | ppl 1.07 | wps 24821.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40329 | lr 0.000157468 | gnorm 0.263 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115522
2022-03-07 21:07:27 | INFO | fairseq.trainer | begin training epoch 830
2022-03-07 21:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:07:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:09:32 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 14.942 | nll_loss 14.845 | ppl 29433 | wps 47159 | wpb 510.9 | bsz 1 | num_updates 40377 | best_loss 8.238
2022-03-07 21:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40377 updates
2022-03-07 21:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 830 @ 40377 updates, score 14.942) (writing took 2.525384843349457 seconds)
2022-03-07 21:09:35 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-07 21:09:35 | INFO | train | epoch 830 | loss 0.39 | nll_loss 0.097 | ppl 1.07 | wps 24332.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40377 | lr 0.000157374 | gnorm 0.262 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115650
2022-03-07 21:09:35 | INFO | fairseq.trainer | begin training epoch 831
2022-03-07 21:09:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:10:32 | INFO | train_inner | epoch 831:     23 / 49 loss=0.39, nll_loss=0.097, ppl=1.07, wps=24641.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.262, loss_scale=64, train_wall=224, gb_free=8.8, wall=115707
2022-03-07 21:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:11:40 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 15.037 | nll_loss 14.942 | ppl 31472.2 | wps 46841.8 | wpb 510.9 | bsz 1 | num_updates 40426 | best_loss 8.238
2022-03-07 21:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40426 updates
2022-03-07 21:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 831 @ 40426 updates, score 15.037) (writing took 2.4530400708317757 seconds)
2022-03-07 21:11:42 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-07 21:11:42 | INFO | train | epoch 831 | loss 0.391 | nll_loss 0.097 | ppl 1.07 | wps 24874.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40426 | lr 0.000157279 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115778
2022-03-07 21:11:42 | INFO | fairseq.trainer | begin training epoch 832
2022-03-07 21:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:13:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:13:48 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 15.034 | nll_loss 14.938 | ppl 31379.9 | wps 46588.2 | wpb 510.9 | bsz 1 | num_updates 40474 | best_loss 8.238
2022-03-07 21:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40474 updates
2022-03-07 21:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:13:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:13:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 832 @ 40474 updates, score 15.034) (writing took 2.5255082100629807 seconds)
2022-03-07 21:13:50 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-07 21:13:50 | INFO | train | epoch 832 | loss 0.39 | nll_loss 0.097 | ppl 1.07 | wps 24308.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 40474 | lr 0.000157185 | gnorm 0.263 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 115906
2022-03-07 21:13:50 | INFO | fairseq.trainer | begin training epoch 833
2022-03-07 21:13:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:14:55 | INFO | train_inner | epoch 833:     26 / 49 loss=0.39, nll_loss=0.097, ppl=1.07, wps=24628.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.264, loss_scale=64, train_wall=225, gb_free=8.8, wall=115970
2022-03-07 21:15:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:15:56 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 15.002 | nll_loss 14.905 | ppl 30676.5 | wps 46152.4 | wpb 510.9 | bsz 1 | num_updates 40523 | best_loss 8.238
2022-03-07 21:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40523 updates
2022-03-07 21:15:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:15:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:15:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 833 @ 40523 updates, score 15.002) (writing took 2.4575137570500374 seconds)
2022-03-07 21:15:58 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-07 21:15:58 | INFO | train | epoch 833 | loss 0.39 | nll_loss 0.096 | ppl 1.07 | wps 24840.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40523 | lr 0.00015709 | gnorm 0.264 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116034
2022-03-07 21:15:58 | INFO | fairseq.trainer | begin training epoch 834
2022-03-07 21:15:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:04 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 15.03 | nll_loss 14.934 | ppl 31294.9 | wps 46708.6 | wpb 510.9 | bsz 1 | num_updates 40572 | best_loss 8.238
2022-03-07 21:18:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40572 updates
2022-03-07 21:18:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:18:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:18:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 834 @ 40572 updates, score 15.03) (writing took 2.4106541089713573 seconds)
2022-03-07 21:18:06 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-07 21:18:06 | INFO | train | epoch 834 | loss 0.39 | nll_loss 0.097 | ppl 1.07 | wps 24873.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40572 | lr 0.000156995 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116161
2022-03-07 21:18:06 | INFO | fairseq.trainer | begin training epoch 835
2022-03-07 21:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:19:16 | INFO | train_inner | epoch 835:     28 / 49 loss=0.39, nll_loss=0.097, ppl=1.07, wps=24867, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.265, loss_scale=128, train_wall=222, gb_free=8.8, wall=116231
2022-03-07 21:19:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:12 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 14.944 | nll_loss 14.847 | ppl 29471.5 | wps 46948.6 | wpb 510.9 | bsz 1 | num_updates 40620 | best_loss 8.238
2022-03-07 21:20:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40620 updates
2022-03-07 21:20:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:20:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 835 @ 40620 updates, score 14.944) (writing took 2.464160732924938 seconds)
2022-03-07 21:20:14 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-07 21:20:14 | INFO | train | epoch 835 | loss 0.39 | nll_loss 0.097 | ppl 1.07 | wps 24283.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 40620 | lr 0.000156903 | gnorm 0.265 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116289
2022-03-07 21:20:14 | INFO | fairseq.trainer | begin training epoch 836
2022-03-07 21:20:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:22:20 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 15.091 | nll_loss 14.995 | ppl 32662.2 | wps 46626.3 | wpb 510.9 | bsz 1 | num_updates 40669 | best_loss 8.238
2022-03-07 21:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40669 updates
2022-03-07 21:22:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:22:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 836 @ 40669 updates, score 15.091) (writing took 2.434496132656932 seconds)
2022-03-07 21:22:22 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-07 21:22:22 | INFO | train | epoch 836 | loss 0.39 | nll_loss 0.097 | ppl 1.07 | wps 24847 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40669 | lr 0.000156808 | gnorm 0.262 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116417
2022-03-07 21:22:22 | INFO | fairseq.trainer | begin training epoch 837
2022-03-07 21:22:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:23:39 | INFO | train_inner | epoch 837:     31 / 49 loss=0.39, nll_loss=0.097, ppl=1.07, wps=24631.2, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.263, loss_scale=64, train_wall=225, gb_free=8.8, wall=116495
2022-03-07 21:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:24:28 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 15.024 | nll_loss 14.928 | ppl 31162.9 | wps 47191.7 | wpb 510.9 | bsz 1 | num_updates 40718 | best_loss 8.238
2022-03-07 21:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40718 updates
2022-03-07 21:24:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:24:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 837 @ 40718 updates, score 15.024) (writing took 2.533729726448655 seconds)
2022-03-07 21:24:30 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-07 21:24:30 | INFO | train | epoch 837 | loss 0.39 | nll_loss 0.097 | ppl 1.07 | wps 24863 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40718 | lr 0.000156714 | gnorm 0.262 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116545
2022-03-07 21:24:30 | INFO | fairseq.trainer | begin training epoch 838
2022-03-07 21:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:25:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:26:35 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 14.986 | nll_loss 14.888 | ppl 30328.2 | wps 46432 | wpb 510.9 | bsz 1 | num_updates 40766 | best_loss 8.238
2022-03-07 21:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40766 updates
2022-03-07 21:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:26:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:26:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 838 @ 40766 updates, score 14.986) (writing took 2.4080843161791563 seconds)
2022-03-07 21:26:37 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-07 21:26:37 | INFO | train | epoch 838 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24424.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40766 | lr 0.000156621 | gnorm 0.261 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116673
2022-03-07 21:26:38 | INFO | fairseq.trainer | begin training epoch 839
2022-03-07 21:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:02 | INFO | train_inner | epoch 839:     34 / 49 loss=0.389, nll_loss=0.096, ppl=1.07, wps=24706.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.263, loss_scale=64, train_wall=224, gb_free=8.8, wall=116757
2022-03-07 21:28:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:28:43 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 15.087 | nll_loss 14.991 | ppl 32574.3 | wps 46839.2 | wpb 510.9 | bsz 1 | num_updates 40815 | best_loss 8.238
2022-03-07 21:28:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40815 updates
2022-03-07 21:28:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:28:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:28:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 839 @ 40815 updates, score 15.087) (writing took 2.5239592734724283 seconds)
2022-03-07 21:28:45 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-07 21:28:45 | INFO | train | epoch 839 | loss 0.39 | nll_loss 0.096 | ppl 1.07 | wps 24858.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40815 | lr 0.000156527 | gnorm 0.266 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116800
2022-03-07 21:28:45 | INFO | fairseq.trainer | begin training epoch 840
2022-03-07 21:28:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:30:51 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 14.968 | nll_loss 14.872 | ppl 29977.6 | wps 46786.4 | wpb 510.9 | bsz 1 | num_updates 40864 | best_loss 8.238
2022-03-07 21:30:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 40864 updates
2022-03-07 21:30:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:30:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:30:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 840 @ 40864 updates, score 14.968) (writing took 2.4611493572592735 seconds)
2022-03-07 21:30:53 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2022-03-07 21:30:53 | INFO | train | epoch 840 | loss 0.39 | nll_loss 0.097 | ppl 1.07 | wps 24863.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40864 | lr 0.000156433 | gnorm 0.266 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 116928
2022-03-07 21:30:53 | INFO | fairseq.trainer | begin training epoch 841
2022-03-07 21:30:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:31:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:32:25 | INFO | train_inner | epoch 841:     37 / 49 loss=0.39, nll_loss=0.097, ppl=1.07, wps=24662.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40900, lr=0.000156365, gnorm=0.265, loss_scale=64, train_wall=224, gb_free=8.8, wall=117020
2022-03-07 21:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:32:58 | INFO | valid | epoch 841 | valid on 'valid' subset | loss 15.084 | nll_loss 14.988 | ppl 32493.6 | wps 46966.8 | wpb 510.9 | bsz 1 | num_updates 40912 | best_loss 8.238
2022-03-07 21:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 841 @ 40912 updates
2022-03-07 21:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 841 @ 40912 updates, score 15.084) (writing took 2.5477163828909397 seconds)
2022-03-07 21:33:01 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2022-03-07 21:33:01 | INFO | train | epoch 841 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24358 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40912 | lr 0.000156342 | gnorm 0.262 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 117056
2022-03-07 21:33:01 | INFO | fairseq.trainer | begin training epoch 842
2022-03-07 21:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:35:06 | INFO | valid | epoch 842 | valid on 'valid' subset | loss 15.081 | nll_loss 14.985 | ppl 32432.5 | wps 46799.8 | wpb 510.9 | bsz 1 | num_updates 40961 | best_loss 8.238
2022-03-07 21:35:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 842 @ 40961 updates
2022-03-07 21:35:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 842 @ 40961 updates, score 15.081) (writing took 2.462427143007517 seconds)
2022-03-07 21:35:09 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2022-03-07 21:35:09 | INFO | train | epoch 842 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24853.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40961 | lr 0.000156248 | gnorm 0.263 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 117184
2022-03-07 21:35:09 | INFO | fairseq.trainer | begin training epoch 843
2022-03-07 21:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:36:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:36:48 | INFO | train_inner | epoch 843:     40 / 49 loss=0.39, nll_loss=0.096, ppl=1.07, wps=24648.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41000, lr=0.000156174, gnorm=0.263, loss_scale=64, train_wall=224, gb_free=8.8, wall=117283
2022-03-07 21:37:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:14 | INFO | valid | epoch 843 | valid on 'valid' subset | loss 15.025 | nll_loss 14.929 | ppl 31196.8 | wps 47335.9 | wpb 510.9 | bsz 1 | num_updates 41009 | best_loss 8.238
2022-03-07 21:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 843 @ 41009 updates
2022-03-07 21:37:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:37:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 843 @ 41009 updates, score 15.025) (writing took 2.487955706194043 seconds)
2022-03-07 21:37:17 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2022-03-07 21:37:17 | INFO | train | epoch 843 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24374.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41009 | lr 0.000156157 | gnorm 0.264 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 117312
2022-03-07 21:37:17 | INFO | fairseq.trainer | begin training epoch 844
2022-03-07 21:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:22 | INFO | valid | epoch 844 | valid on 'valid' subset | loss 15.035 | nll_loss 14.938 | ppl 31394.8 | wps 47124.6 | wpb 510.9 | bsz 1 | num_updates 41058 | best_loss 8.238
2022-03-07 21:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 844 @ 41058 updates
2022-03-07 21:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 844 @ 41058 updates, score 15.035) (writing took 2.5667574647814035 seconds)
2022-03-07 21:39:24 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)
2022-03-07 21:39:24 | INFO | train | epoch 844 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24857.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41058 | lr 0.000156063 | gnorm 0.262 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 117440
2022-03-07 21:39:24 | INFO | fairseq.trainer | begin training epoch 845
2022-03-07 21:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:41:08 | INFO | train_inner | epoch 845:     42 / 49 loss=0.389, nll_loss=0.096, ppl=1.07, wps=24934.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41100, lr=0.000155984, gnorm=0.262, loss_scale=64, train_wall=222, gb_free=8.8, wall=117544
2022-03-07 21:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:41:29 | INFO | valid | epoch 845 | valid on 'valid' subset | loss 14.996 | nll_loss 14.899 | ppl 30561.9 | wps 47149.7 | wpb 510.9 | bsz 1 | num_updates 41107 | best_loss 8.238
2022-03-07 21:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 845 @ 41107 updates
2022-03-07 21:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:41:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 845 @ 41107 updates, score 14.996) (writing took 2.492990270256996 seconds)
2022-03-07 21:41:32 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)
2022-03-07 21:41:32 | INFO | train | epoch 845 | loss 0.39 | nll_loss 0.096 | ppl 1.07 | wps 24967.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41107 | lr 0.00015597 | gnorm 0.262 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 117567
2022-03-07 21:41:32 | INFO | fairseq.trainer | begin training epoch 846
2022-03-07 21:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:42:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:43:36 | INFO | valid | epoch 846 | valid on 'valid' subset | loss 15.104 | nll_loss 15.009 | ppl 32975.3 | wps 47212.6 | wpb 510.9 | bsz 1 | num_updates 41155 | best_loss 8.238
2022-03-07 21:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 846 @ 41155 updates
2022-03-07 21:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 846 @ 41155 updates, score 15.104) (writing took 2.5372922383248806 seconds)
2022-03-07 21:43:39 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)
2022-03-07 21:43:39 | INFO | train | epoch 846 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24493.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41155 | lr 0.000155879 | gnorm 0.261 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 117694
2022-03-07 21:43:39 | INFO | fairseq.trainer | begin training epoch 847
2022-03-07 21:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:45:30 | INFO | train_inner | epoch 847:     45 / 49 loss=0.389, nll_loss=0.096, ppl=1.07, wps=24791.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41200, lr=0.000155794, gnorm=0.261, loss_scale=64, train_wall=223, gb_free=8.8, wall=117805
2022-03-07 21:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:45:43 | INFO | valid | epoch 847 | valid on 'valid' subset | loss 14.95 | nll_loss 14.853 | ppl 29592.9 | wps 47188.5 | wpb 510.9 | bsz 1 | num_updates 41204 | best_loss 8.238
2022-03-07 21:45:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 847 @ 41204 updates
2022-03-07 21:45:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 847 @ 41204 updates, score 14.95) (writing took 2.5511040091514587 seconds)
2022-03-07 21:45:46 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)
2022-03-07 21:45:46 | INFO | train | epoch 847 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24975.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41204 | lr 0.000155787 | gnorm 0.261 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 117821
2022-03-07 21:45:46 | INFO | fairseq.trainer | begin training epoch 848
2022-03-07 21:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:47:51 | INFO | valid | epoch 848 | valid on 'valid' subset | loss 15.027 | nll_loss 14.931 | ppl 31245.7 | wps 46783.4 | wpb 510.9 | bsz 1 | num_updates 41253 | best_loss 8.238
2022-03-07 21:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 848 @ 41253 updates
2022-03-07 21:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 848 @ 41253 updates, score 15.027) (writing took 2.524392480030656 seconds)
2022-03-07 21:47:53 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)
2022-03-07 21:47:53 | INFO | train | epoch 848 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24981.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41253 | lr 0.000155694 | gnorm 0.265 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 117948
2022-03-07 21:47:53 | INFO | fairseq.trainer | begin training epoch 849
2022-03-07 21:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:49:52 | INFO | train_inner | epoch 849:     48 / 49 loss=0.389, nll_loss=0.096, ppl=1.07, wps=24778.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41300, lr=0.000155606, gnorm=0.262, loss_scale=64, train_wall=223, gb_free=8.8, wall=118067
2022-03-07 21:49:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:49:58 | INFO | valid | epoch 849 | valid on 'valid' subset | loss 15.009 | nll_loss 14.914 | ppl 30862.4 | wps 46769.6 | wpb 510.9 | bsz 1 | num_updates 41301 | best_loss 8.238
2022-03-07 21:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 849 @ 41301 updates
2022-03-07 21:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 849 @ 41301 updates, score 15.009) (writing took 2.497052386403084 seconds)
2022-03-07 21:50:00 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)
2022-03-07 21:50:00 | INFO | train | epoch 849 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24477.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41301 | lr 0.000155604 | gnorm 0.259 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 118075
2022-03-07 21:50:00 | INFO | fairseq.trainer | begin training epoch 850
2022-03-07 21:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:05 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 15.011 | nll_loss 14.916 | ppl 30908 | wps 47099.2 | wpb 510.9 | bsz 1 | num_updates 41350 | best_loss 8.238
2022-03-07 21:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 41350 updates
2022-03-07 21:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:52:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:52:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 850 @ 41350 updates, score 15.011) (writing took 2.5354488641023636 seconds)
2022-03-07 21:52:08 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)
2022-03-07 21:52:08 | INFO | train | epoch 850 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24946.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41350 | lr 0.000155511 | gnorm 0.262 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 118203
2022-03-07 21:52:08 | INFO | fairseq.trainer | begin training epoch 851
2022-03-07 21:52:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:54:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 21:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:13 | INFO | valid | epoch 851 | valid on 'valid' subset | loss 14.957 | nll_loss 14.859 | ppl 29719.3 | wps 46504.4 | wpb 510.9 | bsz 1 | num_updates 41398 | best_loss 8.238
2022-03-07 21:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 851 @ 41398 updates
2022-03-07 21:54:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:54:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:54:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 851 @ 41398 updates, score 14.957) (writing took 2.473155817016959 seconds)
2022-03-07 21:54:16 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)
2022-03-07 21:54:16 | INFO | train | epoch 851 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24303.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 41398 | lr 0.000155421 | gnorm 0.26 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 118331
2022-03-07 21:54:16 | INFO | fairseq.trainer | begin training epoch 852
2022-03-07 21:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:54:21 | INFO | train_inner | epoch 852:      2 / 49 loss=0.388, nll_loss=0.095, ppl=1.07, wps=23992.9, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=41400, lr=0.000155417, gnorm=0.262, loss_scale=64, train_wall=223, gb_free=8.8, wall=118336
2022-03-07 21:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:21 | INFO | valid | epoch 852 | valid on 'valid' subset | loss 15.041 | nll_loss 14.945 | ppl 31545.7 | wps 47118.5 | wpb 510.9 | bsz 1 | num_updates 41447 | best_loss 8.238
2022-03-07 21:56:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 852 @ 41447 updates
2022-03-07 21:56:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:56:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 852 @ 41447 updates, score 15.041) (writing took 2.536667486652732 seconds)
2022-03-07 21:56:24 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)
2022-03-07 21:56:24 | INFO | train | epoch 852 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24798.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41447 | lr 0.000155329 | gnorm 0.261 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 118459
2022-03-07 21:56:24 | INFO | fairseq.trainer | begin training epoch 853
2022-03-07 21:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:58:29 | INFO | valid | epoch 853 | valid on 'valid' subset | loss 15.091 | nll_loss 14.996 | ppl 32684.7 | wps 47351.4 | wpb 510.9 | bsz 1 | num_updates 41496 | best_loss 8.238
2022-03-07 21:58:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 853 @ 41496 updates
2022-03-07 21:58:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 21:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 853 @ 41496 updates, score 15.091) (writing took 2.530278066173196 seconds)
2022-03-07 21:58:31 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)
2022-03-07 21:58:31 | INFO | train | epoch 853 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24970.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41496 | lr 0.000155238 | gnorm 0.262 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 118586
2022-03-07 21:58:31 | INFO | fairseq.trainer | begin training epoch 854
2022-03-07 21:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:58:41 | INFO | train_inner | epoch 854:      4 / 49 loss=0.389, nll_loss=0.096, ppl=1.07, wps=24919.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41500, lr=0.00015523, gnorm=0.262, loss_scale=64, train_wall=222, gb_free=8.8, wall=118596
2022-03-07 21:59:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:00:36 | INFO | valid | epoch 854 | valid on 'valid' subset | loss 15.052 | nll_loss 14.956 | ppl 31777 | wps 47444.8 | wpb 510.9 | bsz 1 | num_updates 41544 | best_loss 8.238
2022-03-07 22:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 854 @ 41544 updates
2022-03-07 22:00:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:00:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:00:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 854 @ 41544 updates, score 15.052) (writing took 2.5085319988429546 seconds)
2022-03-07 22:00:39 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)
2022-03-07 22:00:39 | INFO | train | epoch 854 | loss 0.389 | nll_loss 0.096 | ppl 1.07 | wps 24409.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41544 | lr 0.000155148 | gnorm 0.263 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 118714
2022-03-07 22:00:39 | INFO | fairseq.trainer | begin training epoch 855
2022-03-07 22:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:02:43 | INFO | valid | epoch 855 | valid on 'valid' subset | loss 15.086 | nll_loss 14.99 | ppl 32533.1 | wps 47180.9 | wpb 510.9 | bsz 1 | num_updates 41593 | best_loss 8.238
2022-03-07 22:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 855 @ 41593 updates
2022-03-07 22:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:02:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 855 @ 41593 updates, score 15.086) (writing took 2.5038510374724865 seconds)
2022-03-07 22:02:46 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)
2022-03-07 22:02:46 | INFO | train | epoch 855 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24976 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41593 | lr 0.000155056 | gnorm 0.259 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 118841
2022-03-07 22:02:46 | INFO | fairseq.trainer | begin training epoch 856
2022-03-07 22:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:03 | INFO | train_inner | epoch 856:      7 / 49 loss=0.388, nll_loss=0.095, ppl=1.07, wps=24738.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41600, lr=0.000155043, gnorm=0.261, loss_scale=64, train_wall=224, gb_free=8.8, wall=118859
2022-03-07 22:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:04:51 | INFO | valid | epoch 856 | valid on 'valid' subset | loss 15.091 | nll_loss 14.996 | ppl 32670.3 | wps 47199 | wpb 510.9 | bsz 1 | num_updates 41642 | best_loss 8.238
2022-03-07 22:04:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 856 @ 41642 updates
2022-03-07 22:04:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:04:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:04:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 856 @ 41642 updates, score 15.091) (writing took 2.5528046246618032 seconds)
2022-03-07 22:04:54 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)
2022-03-07 22:04:54 | INFO | train | epoch 856 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24924.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41642 | lr 0.000154965 | gnorm 0.261 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 118969
2022-03-07 22:04:54 | INFO | fairseq.trainer | begin training epoch 857
2022-03-07 22:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:05:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:06:58 | INFO | valid | epoch 857 | valid on 'valid' subset | loss 15.05 | nll_loss 14.955 | ppl 31752.9 | wps 47230.6 | wpb 510.9 | bsz 1 | num_updates 41690 | best_loss 8.238
2022-03-07 22:06:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 857 @ 41690 updates
2022-03-07 22:06:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 857 @ 41690 updates, score 15.05) (writing took 2.524129882454872 seconds)
2022-03-07 22:07:01 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)
2022-03-07 22:07:01 | INFO | train | epoch 857 | loss 0.387 | nll_loss 0.095 | ppl 1.07 | wps 24449 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41690 | lr 0.000154876 | gnorm 0.259 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 119096
2022-03-07 22:07:01 | INFO | fairseq.trainer | begin training epoch 858
2022-03-07 22:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:07:26 | INFO | train_inner | epoch 858:     10 / 49 loss=0.388, nll_loss=0.095, ppl=1.07, wps=24739.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41700, lr=0.000154857, gnorm=0.26, loss_scale=64, train_wall=224, gb_free=8.8, wall=119121
2022-03-07 22:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:09:06 | INFO | valid | epoch 858 | valid on 'valid' subset | loss 15.126 | nll_loss 15.031 | ppl 33483.6 | wps 46799 | wpb 510.9 | bsz 1 | num_updates 41739 | best_loss 8.238
2022-03-07 22:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 858 @ 41739 updates
2022-03-07 22:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 858 @ 41739 updates, score 15.126) (writing took 2.439097858965397 seconds)
2022-03-07 22:09:09 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)
2022-03-07 22:09:09 | INFO | train | epoch 858 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24807.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41739 | lr 0.000154785 | gnorm 0.262 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 119224
2022-03-07 22:09:09 | INFO | fairseq.trainer | begin training epoch 859
2022-03-07 22:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:11:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:11:14 | INFO | valid | epoch 859 | valid on 'valid' subset | loss 15.035 | nll_loss 14.939 | ppl 31419.9 | wps 46706.5 | wpb 510.9 | bsz 1 | num_updates 41788 | best_loss 8.238
2022-03-07 22:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 859 @ 41788 updates
2022-03-07 22:11:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:11:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 859 @ 41788 updates, score 15.035) (writing took 2.5248018819838762 seconds)
2022-03-07 22:11:17 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)
2022-03-07 22:11:17 | INFO | train | epoch 859 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24823.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41788 | lr 0.000154694 | gnorm 0.261 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 119352
2022-03-07 22:11:17 | INFO | fairseq.trainer | begin training epoch 860
2022-03-07 22:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:11:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:11:49 | INFO | train_inner | epoch 860:     13 / 49 loss=0.388, nll_loss=0.095, ppl=1.07, wps=24609.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41800, lr=0.000154672, gnorm=0.261, loss_scale=64, train_wall=225, gb_free=8.8, wall=119384
2022-03-07 22:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:13:22 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 15.023 | nll_loss 14.927 | ppl 31149.8 | wps 47124.2 | wpb 510.9 | bsz 1 | num_updates 41836 | best_loss 8.238
2022-03-07 22:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 41836 updates
2022-03-07 22:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:13:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 860 @ 41836 updates, score 15.023) (writing took 2.5124227944761515 seconds)
2022-03-07 22:13:24 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)
2022-03-07 22:13:24 | INFO | train | epoch 860 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24459 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41836 | lr 0.000154605 | gnorm 0.259 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 119479
2022-03-07 22:13:24 | INFO | fairseq.trainer | begin training epoch 861
2022-03-07 22:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:15:29 | INFO | valid | epoch 861 | valid on 'valid' subset | loss 15.111 | nll_loss 15.016 | ppl 33140.8 | wps 47145.9 | wpb 510.9 | bsz 1 | num_updates 41885 | best_loss 8.238
2022-03-07 22:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 861 @ 41885 updates
2022-03-07 22:15:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 861 @ 41885 updates, score 15.111) (writing took 2.487445531412959 seconds)
2022-03-07 22:15:32 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)
2022-03-07 22:15:32 | INFO | train | epoch 861 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24901.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41885 | lr 0.000154515 | gnorm 0.259 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 119607
2022-03-07 22:15:32 | INFO | fairseq.trainer | begin training epoch 862
2022-03-07 22:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:16:09 | INFO | train_inner | epoch 862:     15 / 49 loss=0.387, nll_loss=0.095, ppl=1.07, wps=24971.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41900, lr=0.000154487, gnorm=0.258, loss_scale=64, train_wall=221, gb_free=8.8, wall=119644
2022-03-07 22:17:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:17:37 | INFO | valid | epoch 862 | valid on 'valid' subset | loss 15.073 | nll_loss 14.978 | ppl 32269 | wps 47146.3 | wpb 510.9 | bsz 1 | num_updates 41934 | best_loss 8.238
2022-03-07 22:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 862 @ 41934 updates
2022-03-07 22:17:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 862 @ 41934 updates, score 15.073) (writing took 2.514015018939972 seconds)
2022-03-07 22:17:39 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)
2022-03-07 22:17:39 | INFO | train | epoch 862 | loss 0.387 | nll_loss 0.095 | ppl 1.07 | wps 24941.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41934 | lr 0.000154425 | gnorm 0.258 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 119734
2022-03-07 22:17:39 | INFO | fairseq.trainer | begin training epoch 863
2022-03-07 22:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:19:44 | INFO | valid | epoch 863 | valid on 'valid' subset | loss 15.049 | nll_loss 14.952 | ppl 31705.2 | wps 47189.3 | wpb 510.9 | bsz 1 | num_updates 41982 | best_loss 8.238
2022-03-07 22:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 863 @ 41982 updates
2022-03-07 22:19:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:19:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:19:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 863 @ 41982 updates, score 15.049) (writing took 2.562210064381361 seconds)
2022-03-07 22:19:47 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)
2022-03-07 22:19:47 | INFO | train | epoch 863 | loss 0.387 | nll_loss 0.095 | ppl 1.07 | wps 24437.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41982 | lr 0.000154336 | gnorm 0.26 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 119862
2022-03-07 22:19:47 | INFO | fairseq.trainer | begin training epoch 864
2022-03-07 22:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:20:31 | INFO | train_inner | epoch 864:     18 / 49 loss=0.387, nll_loss=0.095, ppl=1.07, wps=24740.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42000, lr=0.000154303, gnorm=0.259, loss_scale=64, train_wall=224, gb_free=8.8, wall=119906
2022-03-07 22:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:21:51 | INFO | valid | epoch 864 | valid on 'valid' subset | loss 15.106 | nll_loss 15.011 | ppl 33019.1 | wps 47026.1 | wpb 510.9 | bsz 1 | num_updates 42031 | best_loss 8.238
2022-03-07 22:21:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 864 @ 42031 updates
2022-03-07 22:21:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:21:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 864 @ 42031 updates, score 15.106) (writing took 2.46225892752409 seconds)
2022-03-07 22:21:54 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)
2022-03-07 22:21:54 | INFO | train | epoch 864 | loss 0.387 | nll_loss 0.094 | ppl 1.07 | wps 24987.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42031 | lr 0.000154246 | gnorm 0.259 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 119989
2022-03-07 22:21:54 | INFO | fairseq.trainer | begin training epoch 865
2022-03-07 22:21:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:23:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:23:59 | INFO | valid | epoch 865 | valid on 'valid' subset | loss 15.05 | nll_loss 14.956 | ppl 31775.1 | wps 46647.3 | wpb 510.9 | bsz 1 | num_updates 42079 | best_loss 8.238
2022-03-07 22:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 865 @ 42079 updates
2022-03-07 22:23:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:24:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:24:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 865 @ 42079 updates, score 15.05) (writing took 2.506578601896763 seconds)
2022-03-07 22:24:01 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)
2022-03-07 22:24:01 | INFO | train | epoch 865 | loss 0.387 | nll_loss 0.094 | ppl 1.07 | wps 24463.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42079 | lr 0.000154158 | gnorm 0.258 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120116
2022-03-07 22:24:01 | INFO | fairseq.trainer | begin training epoch 866
2022-03-07 22:24:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:24:53 | INFO | train_inner | epoch 866:     21 / 49 loss=0.387, nll_loss=0.095, ppl=1.07, wps=24776.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42100, lr=0.00015412, gnorm=0.259, loss_scale=64, train_wall=223, gb_free=8.8, wall=120168
2022-03-07 22:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:26:06 | INFO | valid | epoch 866 | valid on 'valid' subset | loss 15.048 | nll_loss 14.952 | ppl 31706.5 | wps 47159.2 | wpb 510.9 | bsz 1 | num_updates 42128 | best_loss 8.238
2022-03-07 22:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 866 @ 42128 updates
2022-03-07 22:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:26:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:26:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 866 @ 42128 updates, score 15.048) (writing took 2.54885414801538 seconds)
2022-03-07 22:26:08 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)
2022-03-07 22:26:08 | INFO | train | epoch 866 | loss 0.388 | nll_loss 0.095 | ppl 1.07 | wps 24958.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42128 | lr 0.000154069 | gnorm 0.26 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120244
2022-03-07 22:26:08 | INFO | fairseq.trainer | begin training epoch 867
2022-03-07 22:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:28:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:13 | INFO | valid | epoch 867 | valid on 'valid' subset | loss 15.073 | nll_loss 14.978 | ppl 32261.7 | wps 47062.9 | wpb 510.9 | bsz 1 | num_updates 42177 | best_loss 8.238
2022-03-07 22:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 867 @ 42177 updates
2022-03-07 22:28:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:28:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 867 @ 42177 updates, score 15.073) (writing took 2.4599347934126854 seconds)
2022-03-07 22:28:16 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)
2022-03-07 22:28:16 | INFO | train | epoch 867 | loss 0.387 | nll_loss 0.095 | ppl 1.07 | wps 24960.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42177 | lr 0.000153979 | gnorm 0.26 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120371
2022-03-07 22:28:16 | INFO | fairseq.trainer | begin training epoch 868
2022-03-07 22:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:29:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:29:15 | INFO | train_inner | epoch 868:     24 / 49 loss=0.388, nll_loss=0.095, ppl=1.07, wps=24753.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42200, lr=0.000153937, gnorm=0.26, loss_scale=64, train_wall=224, gb_free=8.8, wall=120430
2022-03-07 22:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:30:20 | INFO | valid | epoch 868 | valid on 'valid' subset | loss 15.024 | nll_loss 14.929 | ppl 31198.2 | wps 47074.8 | wpb 510.9 | bsz 1 | num_updates 42225 | best_loss 8.238
2022-03-07 22:30:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 868 @ 42225 updates
2022-03-07 22:30:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:30:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 868 @ 42225 updates, score 15.024) (writing took 2.5279399044811726 seconds)
2022-03-07 22:30:23 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)
2022-03-07 22:30:23 | INFO | train | epoch 868 | loss 0.387 | nll_loss 0.095 | ppl 1.07 | wps 24442.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42225 | lr 0.000153892 | gnorm 0.261 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120498
2022-03-07 22:30:23 | INFO | fairseq.trainer | begin training epoch 869
2022-03-07 22:30:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:32:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:28 | INFO | valid | epoch 869 | valid on 'valid' subset | loss 15.053 | nll_loss 14.957 | ppl 31811.1 | wps 47021.8 | wpb 510.9 | bsz 1 | num_updates 42274 | best_loss 8.238
2022-03-07 22:32:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 869 @ 42274 updates
2022-03-07 22:32:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:32:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:32:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 869 @ 42274 updates, score 15.053) (writing took 2.5546871218830347 seconds)
2022-03-07 22:32:30 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)
2022-03-07 22:32:30 | INFO | train | epoch 869 | loss 0.387 | nll_loss 0.095 | ppl 1.07 | wps 24957.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42274 | lr 0.000153802 | gnorm 0.261 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120626
2022-03-07 22:32:30 | INFO | fairseq.trainer | begin training epoch 870
2022-03-07 22:32:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:33:35 | INFO | train_inner | epoch 870:     26 / 49 loss=0.387, nll_loss=0.094, ppl=1.07, wps=24973, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=42300, lr=0.000153755, gnorm=0.26, loss_scale=64, train_wall=221, gb_free=8.8, wall=120690
2022-03-07 22:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:35 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 15.117 | nll_loss 15.022 | ppl 33278.4 | wps 46983.5 | wpb 510.9 | bsz 1 | num_updates 42323 | best_loss 8.238
2022-03-07 22:34:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 42323 updates
2022-03-07 22:34:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:34:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 870 @ 42323 updates, score 15.117) (writing took 2.48036877065897 seconds)
2022-03-07 22:34:38 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)
2022-03-07 22:34:38 | INFO | train | epoch 870 | loss 0.387 | nll_loss 0.094 | ppl 1.07 | wps 24928.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42323 | lr 0.000153713 | gnorm 0.26 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 120753
2022-03-07 22:34:38 | INFO | fairseq.trainer | begin training epoch 871
2022-03-07 22:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:34:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:36:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:36:43 | INFO | valid | epoch 871 | valid on 'valid' subset | loss 15.078 | nll_loss 14.983 | ppl 32388.4 | wps 47016.1 | wpb 510.9 | bsz 1 | num_updates 42371 | best_loss 8.238
2022-03-07 22:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 871 @ 42371 updates
2022-03-07 22:36:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:36:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:36:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 871 @ 42371 updates, score 15.078) (writing took 2.5351132806390524 seconds)
2022-03-07 22:36:45 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)
2022-03-07 22:36:45 | INFO | train | epoch 871 | loss 0.387 | nll_loss 0.094 | ppl 1.07 | wps 24463 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42371 | lr 0.000153626 | gnorm 0.26 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 120880
2022-03-07 22:36:45 | INFO | fairseq.trainer | begin training epoch 872
2022-03-07 22:36:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:37:57 | INFO | train_inner | epoch 872:     29 / 49 loss=0.387, nll_loss=0.094, ppl=1.07, wps=24752.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42400, lr=0.000153574, gnorm=0.259, loss_scale=64, train_wall=224, gb_free=8.8, wall=120952
2022-03-07 22:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:38:50 | INFO | valid | epoch 872 | valid on 'valid' subset | loss 15.085 | nll_loss 14.989 | ppl 32524.6 | wps 47014.1 | wpb 510.9 | bsz 1 | num_updates 42420 | best_loss 8.238
2022-03-07 22:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 872 @ 42420 updates
2022-03-07 22:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:38:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 872 @ 42420 updates, score 15.085) (writing took 2.52016587741673 seconds)
2022-03-07 22:38:52 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)
2022-03-07 22:38:52 | INFO | train | epoch 872 | loss 0.387 | nll_loss 0.095 | ppl 1.07 | wps 24961.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42420 | lr 0.000153538 | gnorm 0.259 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 121008
2022-03-07 22:38:52 | INFO | fairseq.trainer | begin training epoch 873
2022-03-07 22:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:40:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:40:57 | INFO | valid | epoch 873 | valid on 'valid' subset | loss 15.023 | nll_loss 14.928 | ppl 31173 | wps 47556.5 | wpb 510.9 | bsz 1 | num_updates 42468 | best_loss 8.238
2022-03-07 22:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 873 @ 42468 updates
2022-03-07 22:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:41:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 873 @ 42468 updates, score 15.023) (writing took 2.473177008330822 seconds)
2022-03-07 22:41:00 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)
2022-03-07 22:41:00 | INFO | train | epoch 873 | loss 0.387 | nll_loss 0.094 | ppl 1.07 | wps 24474.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42468 | lr 0.000153451 | gnorm 0.259 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 121135
2022-03-07 22:41:00 | INFO | fairseq.trainer | begin training epoch 874
2022-03-07 22:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:19 | INFO | train_inner | epoch 874:     32 / 49 loss=0.387, nll_loss=0.094, ppl=1.07, wps=24762, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42500, lr=0.000153393, gnorm=0.259, loss_scale=64, train_wall=224, gb_free=8.8, wall=121214
2022-03-07 22:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:43:05 | INFO | valid | epoch 874 | valid on 'valid' subset | loss 15.075 | nll_loss 14.98 | ppl 32308.8 | wps 47190.4 | wpb 510.9 | bsz 1 | num_updates 42517 | best_loss 8.238
2022-03-07 22:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 874 @ 42517 updates
2022-03-07 22:43:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:43:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 874 @ 42517 updates, score 15.075) (writing took 2.509209118783474 seconds)
2022-03-07 22:43:07 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)
2022-03-07 22:43:07 | INFO | train | epoch 874 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24935.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42517 | lr 0.000153362 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 121262
2022-03-07 22:43:07 | INFO | fairseq.trainer | begin training epoch 875
2022-03-07 22:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:45:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:45:12 | INFO | valid | epoch 875 | valid on 'valid' subset | loss 15.031 | nll_loss 14.935 | ppl 31332.4 | wps 47042.9 | wpb 510.9 | bsz 1 | num_updates 42566 | best_loss 8.238
2022-03-07 22:45:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 875 @ 42566 updates
2022-03-07 22:45:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:45:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:45:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 875 @ 42566 updates, score 15.031) (writing took 2.515968907624483 seconds)
2022-03-07 22:45:15 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)
2022-03-07 22:45:15 | INFO | train | epoch 875 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24910.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42566 | lr 0.000153274 | gnorm 0.258 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 121390
2022-03-07 22:45:15 | INFO | fairseq.trainer | begin training epoch 876
2022-03-07 22:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:46:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:46:41 | INFO | train_inner | epoch 876:     35 / 49 loss=0.386, nll_loss=0.094, ppl=1.07, wps=24718.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=42600, lr=0.000153213, gnorm=0.257, loss_scale=64, train_wall=224, gb_free=8.8, wall=121477
2022-03-07 22:47:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:47:20 | INFO | valid | epoch 876 | valid on 'valid' subset | loss 15.06 | nll_loss 14.965 | ppl 31972.3 | wps 47246.6 | wpb 510.9 | bsz 1 | num_updates 42614 | best_loss 8.238
2022-03-07 22:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 876 @ 42614 updates
2022-03-07 22:47:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 876 @ 42614 updates, score 15.06) (writing took 2.4885872807353735 seconds)
2022-03-07 22:47:22 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)
2022-03-07 22:47:22 | INFO | train | epoch 876 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24422.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42614 | lr 0.000153188 | gnorm 0.257 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 121517
2022-03-07 22:47:22 | INFO | fairseq.trainer | begin training epoch 877
2022-03-07 22:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:49:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:49:27 | INFO | valid | epoch 877 | valid on 'valid' subset | loss 15.053 | nll_loss 14.958 | ppl 31828.3 | wps 46775.3 | wpb 510.9 | bsz 1 | num_updates 42663 | best_loss 8.238
2022-03-07 22:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 877 @ 42663 updates
2022-03-07 22:49:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:49:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:49:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 877 @ 42663 updates, score 15.053) (writing took 2.5071796886622906 seconds)
2022-03-07 22:49:30 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)
2022-03-07 22:49:30 | INFO | train | epoch 877 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24910.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42663 | lr 0.0001531 | gnorm 0.258 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 121645
2022-03-07 22:49:30 | INFO | fairseq.trainer | begin training epoch 878
2022-03-07 22:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:51:01 | INFO | train_inner | epoch 878:     37 / 49 loss=0.386, nll_loss=0.094, ppl=1.07, wps=24950.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42700, lr=0.000153033, gnorm=0.257, loss_scale=64, train_wall=222, gb_free=8.8, wall=121737
2022-03-07 22:51:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:51:35 | INFO | valid | epoch 878 | valid on 'valid' subset | loss 15.02 | nll_loss 14.925 | ppl 31098.6 | wps 47037.7 | wpb 510.9 | bsz 1 | num_updates 42712 | best_loss 8.238
2022-03-07 22:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 878 @ 42712 updates
2022-03-07 22:51:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 878 @ 42712 updates, score 15.02) (writing took 2.599078480154276 seconds)
2022-03-07 22:51:37 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)
2022-03-07 22:51:37 | INFO | train | epoch 878 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24912.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42712 | lr 0.000153012 | gnorm 0.257 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 121772
2022-03-07 22:51:37 | INFO | fairseq.trainer | begin training epoch 879
2022-03-07 22:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:52:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:53:42 | INFO | valid | epoch 879 | valid on 'valid' subset | loss 15.092 | nll_loss 14.996 | ppl 32682.2 | wps 47228.9 | wpb 510.9 | bsz 1 | num_updates 42760 | best_loss 8.238
2022-03-07 22:53:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 879 @ 42760 updates
2022-03-07 22:53:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:53:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:53:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 879 @ 42760 updates, score 15.092) (writing took 2.4997692443430424 seconds)
2022-03-07 22:53:45 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)
2022-03-07 22:53:45 | INFO | train | epoch 879 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24416.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42760 | lr 0.000152926 | gnorm 0.258 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 121900
2022-03-07 22:53:45 | INFO | fairseq.trainer | begin training epoch 880
2022-03-07 22:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:55:24 | INFO | train_inner | epoch 880:     40 / 49 loss=0.386, nll_loss=0.094, ppl=1.07, wps=24710.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42800, lr=0.000152854, gnorm=0.258, loss_scale=64, train_wall=224, gb_free=8.8, wall=121999
2022-03-07 22:55:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:55:50 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 15.061 | nll_loss 14.965 | ppl 31993.1 | wps 47077.3 | wpb 510.9 | bsz 1 | num_updates 42809 | best_loss 8.238
2022-03-07 22:55:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 42809 updates
2022-03-07 22:55:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:55:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 880 @ 42809 updates, score 15.061) (writing took 2.512337116524577 seconds)
2022-03-07 22:55:52 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)
2022-03-07 22:55:52 | INFO | train | epoch 880 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24916 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42809 | lr 0.000152838 | gnorm 0.258 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 122027
2022-03-07 22:55:52 | INFO | fairseq.trainer | begin training epoch 881
2022-03-07 22:55:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:57:57 | INFO | valid | epoch 881 | valid on 'valid' subset | loss 14.928 | nll_loss 14.831 | ppl 29146.1 | wps 46559.1 | wpb 510.9 | bsz 1 | num_updates 42858 | best_loss 8.238
2022-03-07 22:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 881 @ 42858 updates
2022-03-07 22:57:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 22:58:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 881 @ 42858 updates, score 14.928) (writing took 2.5406014658510685 seconds)
2022-03-07 22:58:00 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)
2022-03-07 22:58:00 | INFO | train | epoch 881 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24902.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42858 | lr 0.000152751 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 122155
2022-03-07 22:58:00 | INFO | fairseq.trainer | begin training epoch 882
2022-03-07 22:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:58:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 22:59:46 | INFO | train_inner | epoch 882:     43 / 49 loss=0.386, nll_loss=0.094, ppl=1.07, wps=24723.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42900, lr=0.000152676, gnorm=0.257, loss_scale=64, train_wall=224, gb_free=8.8, wall=122261
2022-03-07 23:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:00:05 | INFO | valid | epoch 882 | valid on 'valid' subset | loss 15.021 | nll_loss 14.925 | ppl 31099.4 | wps 47151.1 | wpb 510.9 | bsz 1 | num_updates 42906 | best_loss 8.238
2022-03-07 23:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 882 @ 42906 updates
2022-03-07 23:00:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 882 @ 42906 updates, score 15.021) (writing took 2.48050457239151 seconds)
2022-03-07 23:00:07 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)
2022-03-07 23:00:07 | INFO | train | epoch 882 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24449.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42906 | lr 0.000152666 | gnorm 0.257 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122282
2022-03-07 23:00:07 | INFO | fairseq.trainer | begin training epoch 883
2022-03-07 23:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:02:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:02:12 | INFO | valid | epoch 883 | valid on 'valid' subset | loss 14.932 | nll_loss 14.837 | ppl 29265 | wps 47149.5 | wpb 510.9 | bsz 1 | num_updates 42955 | best_loss 8.238
2022-03-07 23:02:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 883 @ 42955 updates
2022-03-07 23:02:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:02:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:02:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 883 @ 42955 updates, score 14.932) (writing took 2.5313430428504944 seconds)
2022-03-07 23:02:14 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)
2022-03-07 23:02:14 | INFO | train | epoch 883 | loss 0.386 | nll_loss 0.094 | ppl 1.07 | wps 24975.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42955 | lr 0.000152578 | gnorm 0.258 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122410
2022-03-07 23:02:14 | INFO | fairseq.trainer | begin training epoch 884
2022-03-07 23:02:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:03:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:04:08 | INFO | train_inner | epoch 884:     46 / 49 loss=0.386, nll_loss=0.094, ppl=1.07, wps=24755.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43000, lr=0.000152499, gnorm=0.259, loss_scale=64, train_wall=224, gb_free=8.8, wall=122524
2022-03-07 23:04:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:04:19 | INFO | valid | epoch 884 | valid on 'valid' subset | loss 15.1 | nll_loss 15.004 | ppl 32855 | wps 47424.6 | wpb 510.9 | bsz 1 | num_updates 43003 | best_loss 8.238
2022-03-07 23:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 884 @ 43003 updates
2022-03-07 23:04:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:04:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 884 @ 43003 updates, score 15.1) (writing took 2.5235035065561533 seconds)
2022-03-07 23:04:22 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)
2022-03-07 23:04:22 | INFO | train | epoch 884 | loss 0.386 | nll_loss 0.093 | ppl 1.07 | wps 24433.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43003 | lr 0.000152493 | gnorm 0.26 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122537
2022-03-07 23:04:22 | INFO | fairseq.trainer | begin training epoch 885
2022-03-07 23:04:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:06:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:06:27 | INFO | valid | epoch 885 | valid on 'valid' subset | loss 15.056 | nll_loss 14.961 | ppl 31885.5 | wps 47189.9 | wpb 510.9 | bsz 1 | num_updates 43052 | best_loss 8.238
2022-03-07 23:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 885 @ 43052 updates
2022-03-07 23:06:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:06:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:06:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 885 @ 43052 updates, score 15.056) (writing took 2.5009414423257113 seconds)
2022-03-07 23:06:29 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)
2022-03-07 23:06:29 | INFO | train | epoch 885 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24954.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43052 | lr 0.000152406 | gnorm 0.257 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122664
2022-03-07 23:06:29 | INFO | fairseq.trainer | begin training epoch 886
2022-03-07 23:06:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:28 | INFO | train_inner | epoch 886:     48 / 49 loss=0.385, nll_loss=0.093, ppl=1.07, wps=24988.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43100, lr=0.000152322, gnorm=0.256, loss_scale=64, train_wall=221, gb_free=8.8, wall=122783
2022-03-07 23:08:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:08:34 | INFO | valid | epoch 886 | valid on 'valid' subset | loss 15.031 | nll_loss 14.935 | ppl 31332.1 | wps 47092.8 | wpb 510.9 | bsz 1 | num_updates 43101 | best_loss 8.238
2022-03-07 23:08:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 886 @ 43101 updates
2022-03-07 23:08:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 886 @ 43101 updates, score 15.031) (writing took 2.544630041345954 seconds)
2022-03-07 23:08:36 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)
2022-03-07 23:08:36 | INFO | train | epoch 886 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24954.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43101 | lr 0.00015232 | gnorm 0.256 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 122792
2022-03-07 23:08:36 | INFO | fairseq.trainer | begin training epoch 887
2022-03-07 23:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:09:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:10:41 | INFO | valid | epoch 887 | valid on 'valid' subset | loss 15.086 | nll_loss 14.992 | ppl 32597.5 | wps 47187 | wpb 510.9 | bsz 1 | num_updates 43149 | best_loss 8.238
2022-03-07 23:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 887 @ 43149 updates
2022-03-07 23:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 887 @ 43149 updates, score 15.086) (writing took 2.5088495444506407 seconds)
2022-03-07 23:10:44 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)
2022-03-07 23:10:44 | INFO | train | epoch 887 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24423.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43149 | lr 0.000152235 | gnorm 0.258 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 122919
2022-03-07 23:10:44 | INFO | fairseq.trainer | begin training epoch 888
2022-03-07 23:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:49 | INFO | valid | epoch 888 | valid on 'valid' subset | loss 15.048 | nll_loss 14.953 | ppl 31713.2 | wps 46844.2 | wpb 510.9 | bsz 1 | num_updates 43198 | best_loss 8.238
2022-03-07 23:12:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 888 @ 43198 updates
2022-03-07 23:12:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:12:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:12:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 888 @ 43198 updates, score 15.048) (writing took 2.53248343616724 seconds)
2022-03-07 23:12:51 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)
2022-03-07 23:12:51 | INFO | train | epoch 888 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24935.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43198 | lr 0.000152149 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 123047
2022-03-07 23:12:51 | INFO | fairseq.trainer | begin training epoch 889
2022-03-07 23:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:12:56 | INFO | train_inner | epoch 889:      2 / 49 loss=0.385, nll_loss=0.093, ppl=1.07, wps=24041.6, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=43200, lr=0.000152145, gnorm=0.258, loss_scale=64, train_wall=223, gb_free=8.8, wall=123052
2022-03-07 23:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:14:56 | INFO | valid | epoch 889 | valid on 'valid' subset | loss 15.061 | nll_loss 14.966 | ppl 32009.4 | wps 46953.5 | wpb 510.9 | bsz 1 | num_updates 43247 | best_loss 8.238
2022-03-07 23:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 889 @ 43247 updates
2022-03-07 23:14:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 889 @ 43247 updates, score 15.061) (writing took 2.542152648791671 seconds)
2022-03-07 23:14:59 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)
2022-03-07 23:14:59 | INFO | train | epoch 889 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24944 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43247 | lr 0.000152062 | gnorm 0.256 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 123174
2022-03-07 23:14:59 | INFO | fairseq.trainer | begin training epoch 890
2022-03-07 23:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:15:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:16:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:17:04 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 15.013 | nll_loss 14.917 | ppl 30933.2 | wps 47148.8 | wpb 510.9 | bsz 1 | num_updates 43295 | best_loss 8.238
2022-03-07 23:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 43295 updates
2022-03-07 23:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 890 @ 43295 updates, score 15.013) (writing took 2.5050140097737312 seconds)
2022-03-07 23:17:06 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)
2022-03-07 23:17:06 | INFO | train | epoch 890 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24424.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43295 | lr 0.000151978 | gnorm 0.26 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 123301
2022-03-07 23:17:06 | INFO | fairseq.trainer | begin training epoch 891
2022-03-07 23:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:17:19 | INFO | train_inner | epoch 891:      5 / 49 loss=0.385, nll_loss=0.093, ppl=1.07, wps=24737.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43300, lr=0.000151969, gnorm=0.258, loss_scale=64, train_wall=224, gb_free=8.8, wall=123314
2022-03-07 23:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:19:11 | INFO | valid | epoch 891 | valid on 'valid' subset | loss 15.006 | nll_loss 14.911 | ppl 30812.8 | wps 47090.3 | wpb 510.9 | bsz 1 | num_updates 43344 | best_loss 8.238
2022-03-07 23:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 891 @ 43344 updates
2022-03-07 23:19:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:19:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 891 @ 43344 updates, score 15.006) (writing took 2.4955201912671328 seconds)
2022-03-07 23:19:14 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)
2022-03-07 23:19:14 | INFO | train | epoch 891 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24955 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43344 | lr 0.000151892 | gnorm 0.257 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 123429
2022-03-07 23:19:14 | INFO | fairseq.trainer | begin training epoch 892
2022-03-07 23:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:21:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:21:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:21:19 | INFO | valid | epoch 892 | valid on 'valid' subset | loss 14.949 | nll_loss 14.853 | ppl 29596.1 | wps 47160.5 | wpb 510.9 | bsz 1 | num_updates 43392 | best_loss 8.238
2022-03-07 23:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 892 @ 43392 updates
2022-03-07 23:21:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:21:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:21:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 892 @ 43392 updates, score 14.949) (writing took 2.546172469854355 seconds)
2022-03-07 23:21:21 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)
2022-03-07 23:21:21 | INFO | train | epoch 892 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24397.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43392 | lr 0.000151808 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 123556
2022-03-07 23:21:21 | INFO | fairseq.trainer | begin training epoch 893
2022-03-07 23:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:21:41 | INFO | train_inner | epoch 893:      8 / 49 loss=0.385, nll_loss=0.093, ppl=1.07, wps=24729.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43400, lr=0.000151794, gnorm=0.256, loss_scale=64, train_wall=224, gb_free=8.8, wall=123576
2022-03-07 23:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:23:26 | INFO | valid | epoch 893 | valid on 'valid' subset | loss 15.045 | nll_loss 14.95 | ppl 31646.1 | wps 47143.9 | wpb 510.9 | bsz 1 | num_updates 43441 | best_loss 8.238
2022-03-07 23:23:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 893 @ 43441 updates
2022-03-07 23:23:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:23:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 893 @ 43441 updates, score 15.045) (writing took 2.514239851385355 seconds)
2022-03-07 23:23:29 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)
2022-03-07 23:23:29 | INFO | train | epoch 893 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24932.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43441 | lr 0.000151723 | gnorm 0.257 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 123684
2022-03-07 23:23:29 | INFO | fairseq.trainer | begin training epoch 894
2022-03-07 23:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:25:34 | INFO | valid | epoch 894 | valid on 'valid' subset | loss 15.097 | nll_loss 15.003 | ppl 32839.4 | wps 46919.9 | wpb 510.9 | bsz 1 | num_updates 43490 | best_loss 8.238
2022-03-07 23:25:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 894 @ 43490 updates
2022-03-07 23:25:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:25:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 894 @ 43490 updates, score 15.097) (writing took 2.5055010803043842 seconds)
2022-03-07 23:25:36 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)
2022-03-07 23:25:36 | INFO | train | epoch 894 | loss 0.385 | nll_loss 0.093 | ppl 1.07 | wps 24922.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43490 | lr 0.000151637 | gnorm 0.258 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 123811
2022-03-07 23:25:36 | INFO | fairseq.trainer | begin training epoch 895
2022-03-07 23:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:26:01 | INFO | train_inner | epoch 895:     10 / 49 loss=0.384, nll_loss=0.093, ppl=1.07, wps=24950.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43500, lr=0.00015162, gnorm=0.257, loss_scale=64, train_wall=222, gb_free=8.8, wall=123836
2022-03-07 23:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:27:41 | INFO | valid | epoch 895 | valid on 'valid' subset | loss 15.025 | nll_loss 14.929 | ppl 31196.5 | wps 47013.9 | wpb 510.9 | bsz 1 | num_updates 43539 | best_loss 8.238
2022-03-07 23:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 895 @ 43539 updates
2022-03-07 23:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:27:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:27:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 895 @ 43539 updates, score 15.025) (writing took 2.5252105221152306 seconds)
2022-03-07 23:27:44 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)
2022-03-07 23:27:44 | INFO | train | epoch 895 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24950.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43539 | lr 0.000151552 | gnorm 0.254 | loss_scale 128 | train_wall 108 | gb_free 8.8 | wall 123939
2022-03-07 23:27:44 | INFO | fairseq.trainer | begin training epoch 896
2022-03-07 23:27:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:29:48 | INFO | valid | epoch 896 | valid on 'valid' subset | loss 15.01 | nll_loss 14.914 | ppl 30869.1 | wps 47237.9 | wpb 510.9 | bsz 1 | num_updates 43587 | best_loss 8.238
2022-03-07 23:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 896 @ 43587 updates
2022-03-07 23:29:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:29:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:29:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 896 @ 43587 updates, score 15.01) (writing took 2.4788001030683517 seconds)
2022-03-07 23:29:51 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)
2022-03-07 23:29:51 | INFO | train | epoch 896 | loss 0.384 | nll_loss 0.093 | ppl 1.07 | wps 24450.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43587 | lr 0.000151468 | gnorm 0.255 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 124066
2022-03-07 23:29:51 | INFO | fairseq.trainer | begin training epoch 897
2022-03-07 23:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:30:23 | INFO | train_inner | epoch 897:     13 / 49 loss=0.384, nll_loss=0.092, ppl=1.07, wps=24754.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43600, lr=0.000151446, gnorm=0.255, loss_scale=64, train_wall=224, gb_free=8.8, wall=124098
2022-03-07 23:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:31:56 | INFO | valid | epoch 897 | valid on 'valid' subset | loss 15.088 | nll_loss 14.992 | ppl 32593.7 | wps 46547.8 | wpb 510.9 | bsz 1 | num_updates 43636 | best_loss 8.238
2022-03-07 23:31:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 897 @ 43636 updates
2022-03-07 23:31:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:31:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:31:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 897 @ 43636 updates, score 15.088) (writing took 2.555331578478217 seconds)
2022-03-07 23:31:58 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)
2022-03-07 23:31:58 | INFO | train | epoch 897 | loss 0.384 | nll_loss 0.093 | ppl 1.07 | wps 24917 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43636 | lr 0.000151383 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 124193
2022-03-07 23:31:58 | INFO | fairseq.trainer | begin training epoch 898
2022-03-07 23:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:33:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:34:03 | INFO | valid | epoch 898 | valid on 'valid' subset | loss 14.984 | nll_loss 14.888 | ppl 30328.9 | wps 47093 | wpb 510.9 | bsz 1 | num_updates 43684 | best_loss 8.238
2022-03-07 23:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 898 @ 43684 updates
2022-03-07 23:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:34:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:34:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 898 @ 43684 updates, score 14.984) (writing took 2.4762209989130497 seconds)
2022-03-07 23:34:06 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)
2022-03-07 23:34:06 | INFO | train | epoch 898 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24436.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43684 | lr 0.0001513 | gnorm 0.257 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 124321
2022-03-07 23:34:06 | INFO | fairseq.trainer | begin training epoch 899
2022-03-07 23:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:34:45 | INFO | train_inner | epoch 899:     16 / 49 loss=0.384, nll_loss=0.092, ppl=1.07, wps=24733.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43700, lr=0.000151272, gnorm=0.256, loss_scale=64, train_wall=224, gb_free=8.8, wall=124361
2022-03-07 23:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:36:10 | INFO | valid | epoch 899 | valid on 'valid' subset | loss 14.985 | nll_loss 14.889 | ppl 30344.4 | wps 47166.4 | wpb 510.9 | bsz 1 | num_updates 43733 | best_loss 8.238
2022-03-07 23:36:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 899 @ 43733 updates
2022-03-07 23:36:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 899 @ 43733 updates, score 14.985) (writing took 2.514344273135066 seconds)
2022-03-07 23:36:13 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)
2022-03-07 23:36:13 | INFO | train | epoch 899 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 25001.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43733 | lr 0.000151215 | gnorm 0.256 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 124448
2022-03-07 23:36:13 | INFO | fairseq.trainer | begin training epoch 900
2022-03-07 23:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:38:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:38:18 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 15.008 | nll_loss 14.913 | ppl 30843.2 | wps 46971.1 | wpb 510.9 | bsz 1 | num_updates 43782 | best_loss 8.238
2022-03-07 23:38:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 43782 updates
2022-03-07 23:38:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:38:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:38:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 900 @ 43782 updates, score 15.008) (writing took 2.4836836718022823 seconds)
2022-03-07 23:38:20 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)
2022-03-07 23:38:20 | INFO | train | epoch 900 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24949.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43782 | lr 0.000151131 | gnorm 0.253 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 124575
2022-03-07 23:38:20 | INFO | fairseq.trainer | begin training epoch 901
2022-03-07 23:38:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:39:05 | INFO | train_inner | epoch 901:     18 / 49 loss=0.384, nll_loss=0.093, ppl=1.07, wps=24996.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=43800, lr=0.000151099, gnorm=0.256, loss_scale=128, train_wall=221, gb_free=8.8, wall=124620
2022-03-07 23:39:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:40:25 | INFO | valid | epoch 901 | valid on 'valid' subset | loss 15.032 | nll_loss 14.937 | ppl 31364.8 | wps 46830.2 | wpb 510.9 | bsz 1 | num_updates 43830 | best_loss 8.238
2022-03-07 23:40:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 901 @ 43830 updates
2022-03-07 23:40:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:40:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:40:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 901 @ 43830 updates, score 15.032) (writing took 2.4803863279521465 seconds)
2022-03-07 23:40:28 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)
2022-03-07 23:40:28 | INFO | train | epoch 901 | loss 0.384 | nll_loss 0.093 | ppl 1.07 | wps 24432.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43830 | lr 0.000151048 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 124703
2022-03-07 23:40:28 | INFO | fairseq.trainer | begin training epoch 902
2022-03-07 23:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:42:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:42:33 | INFO | valid | epoch 902 | valid on 'valid' subset | loss 15.074 | nll_loss 14.979 | ppl 32296 | wps 46668.1 | wpb 510.9 | bsz 1 | num_updates 43879 | best_loss 8.238
2022-03-07 23:42:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 902 @ 43879 updates
2022-03-07 23:42:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:42:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 902 @ 43879 updates, score 15.074) (writing took 2.5726346112787724 seconds)
2022-03-07 23:42:35 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)
2022-03-07 23:42:35 | INFO | train | epoch 902 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24904.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43879 | lr 0.000150963 | gnorm 0.254 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 124830
2022-03-07 23:42:35 | INFO | fairseq.trainer | begin training epoch 903
2022-03-07 23:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:43:28 | INFO | train_inner | epoch 903:     21 / 49 loss=0.384, nll_loss=0.092, ppl=1.07, wps=24684.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43900, lr=0.000150927, gnorm=0.254, loss_scale=64, train_wall=224, gb_free=8.8, wall=124883
2022-03-07 23:44:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:44:41 | INFO | valid | epoch 903 | valid on 'valid' subset | loss 14.997 | nll_loss 14.902 | ppl 30612.9 | wps 46172.9 | wpb 510.9 | bsz 1 | num_updates 43928 | best_loss 8.238
2022-03-07 23:44:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 903 @ 43928 updates
2022-03-07 23:44:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:44:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:44:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 903 @ 43928 updates, score 14.997) (writing took 2.466745125129819 seconds)
2022-03-07 23:44:43 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)
2022-03-07 23:44:43 | INFO | train | epoch 903 | loss 0.384 | nll_loss 0.093 | ppl 1.07 | wps 24784.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43928 | lr 0.000150879 | gnorm 0.257 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 124959
2022-03-07 23:44:43 | INFO | fairseq.trainer | begin training epoch 904
2022-03-07 23:44:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:45:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:46:49 | INFO | valid | epoch 904 | valid on 'valid' subset | loss 15.033 | nll_loss 14.939 | ppl 31403.5 | wps 46519.4 | wpb 510.9 | bsz 1 | num_updates 43976 | best_loss 8.238
2022-03-07 23:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 904 @ 43976 updates
2022-03-07 23:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 904 @ 43976 updates, score 15.033) (writing took 2.518661407753825 seconds)
2022-03-07 23:46:51 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)
2022-03-07 23:46:51 | INFO | train | epoch 904 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24390.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43976 | lr 0.000150797 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 125086
2022-03-07 23:46:51 | INFO | fairseq.trainer | begin training epoch 905
2022-03-07 23:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:47:51 | INFO | train_inner | epoch 905:     24 / 49 loss=0.384, nll_loss=0.092, ppl=1.07, wps=24677.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44000, lr=0.000150756, gnorm=0.257, loss_scale=64, train_wall=224, gb_free=8.8, wall=125146
2022-03-07 23:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:48:56 | INFO | valid | epoch 905 | valid on 'valid' subset | loss 15.039 | nll_loss 14.944 | ppl 31519.7 | wps 46635.8 | wpb 510.9 | bsz 1 | num_updates 44025 | best_loss 8.238
2022-03-07 23:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 905 @ 44025 updates
2022-03-07 23:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 905 @ 44025 updates, score 15.039) (writing took 2.4689417723566294 seconds)
2022-03-07 23:48:58 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)
2022-03-07 23:48:58 | INFO | train | epoch 905 | loss 0.383 | nll_loss 0.092 | ppl 1.07 | wps 24953 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44025 | lr 0.000150713 | gnorm 0.256 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125214
2022-03-07 23:48:58 | INFO | fairseq.trainer | begin training epoch 906
2022-03-07 23:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:50:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:51:04 | INFO | valid | epoch 906 | valid on 'valid' subset | loss 14.976 | nll_loss 14.88 | ppl 30161.9 | wps 46593.7 | wpb 510.9 | bsz 1 | num_updates 44073 | best_loss 8.238
2022-03-07 23:51:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 906 @ 44073 updates
2022-03-07 23:51:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:51:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:51:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 906 @ 44073 updates, score 14.976) (writing took 2.5148645639419556 seconds)
2022-03-07 23:51:06 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)
2022-03-07 23:51:06 | INFO | train | epoch 906 | loss 0.383 | nll_loss 0.092 | ppl 1.07 | wps 24394 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44073 | lr 0.000150631 | gnorm 0.254 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 125341
2022-03-07 23:51:06 | INFO | fairseq.trainer | begin training epoch 907
2022-03-07 23:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:52:13 | INFO | train_inner | epoch 907:     27 / 49 loss=0.383, nll_loss=0.092, ppl=1.07, wps=24726.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44100, lr=0.000150585, gnorm=0.255, loss_scale=64, train_wall=224, gb_free=8.8, wall=125408
2022-03-07 23:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:53:11 | INFO | valid | epoch 907 | valid on 'valid' subset | loss 15.033 | nll_loss 14.937 | ppl 31372 | wps 46551.3 | wpb 510.9 | bsz 1 | num_updates 44122 | best_loss 8.238
2022-03-07 23:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 907 @ 44122 updates
2022-03-07 23:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:53:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 907 @ 44122 updates, score 15.033) (writing took 2.604974338784814 seconds)
2022-03-07 23:53:14 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)
2022-03-07 23:53:14 | INFO | train | epoch 907 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24916.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44122 | lr 0.000150547 | gnorm 0.257 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125469
2022-03-07 23:53:14 | INFO | fairseq.trainer | begin training epoch 908
2022-03-07 23:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:55:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:55:18 | INFO | valid | epoch 908 | valid on 'valid' subset | loss 15.061 | nll_loss 14.966 | ppl 32003.4 | wps 46639.3 | wpb 510.9 | bsz 1 | num_updates 44171 | best_loss 8.238
2022-03-07 23:55:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 908 @ 44171 updates
2022-03-07 23:55:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:55:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 908 @ 44171 updates, score 15.061) (writing took 2.4972225204110146 seconds)
2022-03-07 23:55:21 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)
2022-03-07 23:55:21 | INFO | train | epoch 908 | loss 0.384 | nll_loss 0.093 | ppl 1.07 | wps 24972.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44171 | lr 0.000150464 | gnorm 0.255 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125596
2022-03-07 23:55:21 | INFO | fairseq.trainer | begin training epoch 909
2022-03-07 23:55:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:56:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-07 23:56:35 | INFO | train_inner | epoch 909:     30 / 49 loss=0.384, nll_loss=0.092, ppl=1.07, wps=24739.9, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=44200, lr=0.000150414, gnorm=0.255, loss_scale=64, train_wall=223, gb_free=8.8, wall=125670
2022-03-07 23:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:57:26 | INFO | valid | epoch 909 | valid on 'valid' subset | loss 15.067 | nll_loss 14.973 | ppl 32155.2 | wps 46625.8 | wpb 510.9 | bsz 1 | num_updates 44219 | best_loss 8.238
2022-03-07 23:57:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 909 @ 44219 updates
2022-03-07 23:57:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:57:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:57:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 909 @ 44219 updates, score 15.067) (writing took 2.547145798802376 seconds)
2022-03-07 23:57:28 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)
2022-03-07 23:57:28 | INFO | train | epoch 909 | loss 0.383 | nll_loss 0.092 | ppl 1.07 | wps 24406.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44219 | lr 0.000150382 | gnorm 0.255 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125723
2022-03-07 23:57:28 | INFO | fairseq.trainer | begin training epoch 910
2022-03-07 23:57:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:59:33 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 14.999 | nll_loss 14.905 | ppl 30672.2 | wps 46567.9 | wpb 510.9 | bsz 1 | num_updates 44268 | best_loss 8.238
2022-03-07 23:59:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 44268 updates
2022-03-07 23:59:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:59:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-07 23:59:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 910 @ 44268 updates, score 14.999) (writing took 2.5975923035293818 seconds)
2022-03-07 23:59:36 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)
2022-03-07 23:59:36 | INFO | train | epoch 910 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24943.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44268 | lr 0.000150299 | gnorm 0.255 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125851
2022-03-07 23:59:36 | INFO | fairseq.trainer | begin training epoch 911
2022-03-07 23:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:00:55 | INFO | train_inner | epoch 911:     32 / 49 loss=0.384, nll_loss=0.092, ppl=1.07, wps=24956.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=44300, lr=0.000150244, gnorm=0.255, loss_scale=64, train_wall=221, gb_free=8.8, wall=125930
2022-03-08 00:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:01:41 | INFO | valid | epoch 911 | valid on 'valid' subset | loss 15.105 | nll_loss 15.011 | ppl 33025 | wps 46757.3 | wpb 510.9 | bsz 1 | num_updates 44317 | best_loss 8.238
2022-03-08 00:01:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 911 @ 44317 updates
2022-03-08 00:01:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 911 @ 44317 updates, score 15.105) (writing took 2.523090183734894 seconds)
2022-03-08 00:01:43 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)
2022-03-08 00:01:43 | INFO | train | epoch 911 | loss 0.384 | nll_loss 0.092 | ppl 1.07 | wps 24942 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44317 | lr 0.000150216 | gnorm 0.256 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 125978
2022-03-08 00:01:43 | INFO | fairseq.trainer | begin training epoch 912
2022-03-08 00:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:03:48 | INFO | valid | epoch 912 | valid on 'valid' subset | loss 15.007 | nll_loss 14.912 | ppl 30834.1 | wps 46940.7 | wpb 510.9 | bsz 1 | num_updates 44365 | best_loss 8.238
2022-03-08 00:03:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 912 @ 44365 updates
2022-03-08 00:03:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 912 @ 44365 updates, score 15.007) (writing took 2.4851102642714977 seconds)
2022-03-08 00:03:51 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)
2022-03-08 00:03:51 | INFO | train | epoch 912 | loss 0.383 | nll_loss 0.092 | ppl 1.07 | wps 24418.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44365 | lr 0.000150134 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 126106
2022-03-08 00:03:51 | INFO | fairseq.trainer | begin training epoch 913
2022-03-08 00:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:05:17 | INFO | train_inner | epoch 913:     35 / 49 loss=0.383, nll_loss=0.092, ppl=1.07, wps=24736.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44400, lr=0.000150075, gnorm=0.255, loss_scale=64, train_wall=224, gb_free=8.8, wall=126192
2022-03-08 00:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:05:56 | INFO | valid | epoch 913 | valid on 'valid' subset | loss 14.931 | nll_loss 14.836 | ppl 29247.5 | wps 47142 | wpb 510.9 | bsz 1 | num_updates 44414 | best_loss 8.238
2022-03-08 00:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 913 @ 44414 updates
2022-03-08 00:05:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:05:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 913 @ 44414 updates, score 14.931) (writing took 2.555927837267518 seconds)
2022-03-08 00:05:58 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)
2022-03-08 00:05:58 | INFO | train | epoch 913 | loss 0.383 | nll_loss 0.092 | ppl 1.07 | wps 24934.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44414 | lr 0.000150051 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 126233
2022-03-08 00:05:58 | INFO | fairseq.trainer | begin training epoch 914
2022-03-08 00:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:07:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:08:03 | INFO | valid | epoch 914 | valid on 'valid' subset | loss 14.979 | nll_loss 14.883 | ppl 30223.3 | wps 47088.6 | wpb 510.9 | bsz 1 | num_updates 44463 | best_loss 8.238
2022-03-08 00:08:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 914 @ 44463 updates
2022-03-08 00:08:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:08:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:08:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 914 @ 44463 updates, score 14.979) (writing took 2.524433922022581 seconds)
2022-03-08 00:08:06 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)
2022-03-08 00:08:06 | INFO | train | epoch 914 | loss 0.383 | nll_loss 0.092 | ppl 1.07 | wps 24939 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44463 | lr 0.000149969 | gnorm 0.255 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 126361
2022-03-08 00:08:06 | INFO | fairseq.trainer | begin training epoch 915
2022-03-08 00:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:08:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:09:40 | INFO | train_inner | epoch 915:     38 / 49 loss=0.383, nll_loss=0.092, ppl=1.07, wps=24731.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44500, lr=0.000149906, gnorm=0.254, loss_scale=64, train_wall=224, gb_free=8.8, wall=126455
2022-03-08 00:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:10:10 | INFO | valid | epoch 915 | valid on 'valid' subset | loss 15.001 | nll_loss 14.905 | ppl 30685.4 | wps 47293.1 | wpb 510.9 | bsz 1 | num_updates 44511 | best_loss 8.238
2022-03-08 00:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 915 @ 44511 updates
2022-03-08 00:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:10:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:10:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 915 @ 44511 updates, score 15.001) (writing took 2.527486175298691 seconds)
2022-03-08 00:10:13 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)
2022-03-08 00:10:13 | INFO | train | epoch 915 | loss 0.383 | nll_loss 0.091 | ppl 1.07 | wps 24436.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44511 | lr 0.000149888 | gnorm 0.254 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 126488
2022-03-08 00:10:13 | INFO | fairseq.trainer | begin training epoch 916
2022-03-08 00:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:12:18 | INFO | valid | epoch 916 | valid on 'valid' subset | loss 15.012 | nll_loss 14.919 | ppl 30971.4 | wps 47394.3 | wpb 510.9 | bsz 1 | num_updates 44560 | best_loss 8.238
2022-03-08 00:12:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 916 @ 44560 updates
2022-03-08 00:12:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:12:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 916 @ 44560 updates, score 15.012) (writing took 2.578563867136836 seconds)
2022-03-08 00:12:20 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)
2022-03-08 00:12:20 | INFO | train | epoch 916 | loss 0.383 | nll_loss 0.091 | ppl 1.07 | wps 24927.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44560 | lr 0.000149805 | gnorm 0.254 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 126616
2022-03-08 00:12:20 | INFO | fairseq.trainer | begin training epoch 917
2022-03-08 00:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:13:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:14:02 | INFO | train_inner | epoch 917:     41 / 49 loss=0.382, nll_loss=0.091, ppl=1.07, wps=24720.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44600, lr=0.000149738, gnorm=0.255, loss_scale=64, train_wall=224, gb_free=8.8, wall=126717
2022-03-08 00:14:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:14:25 | INFO | valid | epoch 917 | valid on 'valid' subset | loss 14.956 | nll_loss 14.861 | ppl 29757.3 | wps 47065.4 | wpb 510.9 | bsz 1 | num_updates 44608 | best_loss 8.238
2022-03-08 00:14:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 917 @ 44608 updates
2022-03-08 00:14:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:14:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 917 @ 44608 updates, score 14.956) (writing took 2.48886489123106 seconds)
2022-03-08 00:14:28 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)
2022-03-08 00:14:28 | INFO | train | epoch 917 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24422.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44608 | lr 0.000149725 | gnorm 0.255 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 126743
2022-03-08 00:14:28 | INFO | fairseq.trainer | begin training epoch 918
2022-03-08 00:14:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:16:33 | INFO | valid | epoch 918 | valid on 'valid' subset | loss 14.968 | nll_loss 14.873 | ppl 30014.5 | wps 46657.2 | wpb 510.9 | bsz 1 | num_updates 44657 | best_loss 8.238
2022-03-08 00:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 918 @ 44657 updates
2022-03-08 00:16:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:16:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:16:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 918 @ 44657 updates, score 14.968) (writing took 2.511920213699341 seconds)
2022-03-08 00:16:35 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)
2022-03-08 00:16:35 | INFO | train | epoch 918 | loss 0.383 | nll_loss 0.092 | ppl 1.07 | wps 24927 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44657 | lr 0.000149643 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 126870
2022-03-08 00:16:35 | INFO | fairseq.trainer | begin training epoch 919
2022-03-08 00:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:18:22 | INFO | train_inner | epoch 919:     43 / 49 loss=0.383, nll_loss=0.092, ppl=1.07, wps=24956, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=44700, lr=0.000149571, gnorm=0.255, loss_scale=64, train_wall=222, gb_free=8.8, wall=126977
2022-03-08 00:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:18:40 | INFO | valid | epoch 919 | valid on 'valid' subset | loss 14.966 | nll_loss 14.871 | ppl 29959.5 | wps 47194.8 | wpb 510.9 | bsz 1 | num_updates 44706 | best_loss 8.238
2022-03-08 00:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 919 @ 44706 updates
2022-03-08 00:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 919 @ 44706 updates, score 14.966) (writing took 2.519300363957882 seconds)
2022-03-08 00:18:43 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)
2022-03-08 00:18:43 | INFO | train | epoch 919 | loss 0.383 | nll_loss 0.091 | ppl 1.07 | wps 24909.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44706 | lr 0.000149561 | gnorm 0.255 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 126998
2022-03-08 00:18:43 | INFO | fairseq.trainer | begin training epoch 920
2022-03-08 00:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:20:48 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 15.041 | nll_loss 14.946 | ppl 31566 | wps 47068.9 | wpb 510.9 | bsz 1 | num_updates 44754 | best_loss 8.238
2022-03-08 00:20:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 44754 updates
2022-03-08 00:20:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:20:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:20:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 920 @ 44754 updates, score 15.041) (writing took 2.5217083171010017 seconds)
2022-03-08 00:20:50 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)
2022-03-08 00:20:50 | INFO | train | epoch 920 | loss 0.383 | nll_loss 0.091 | ppl 1.07 | wps 24439.8 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 44754 | lr 0.00014948 | gnorm 0.253 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 127125
2022-03-08 00:20:50 | INFO | fairseq.trainer | begin training epoch 921
2022-03-08 00:20:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:22:44 | INFO | train_inner | epoch 921:     46 / 49 loss=0.382, nll_loss=0.091, ppl=1.07, wps=24732.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=44800, lr=0.000149404, gnorm=0.253, loss_scale=64, train_wall=224, gb_free=8.8, wall=127239
2022-03-08 00:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:22:55 | INFO | valid | epoch 921 | valid on 'valid' subset | loss 14.951 | nll_loss 14.856 | ppl 29648.5 | wps 46870.4 | wpb 510.9 | bsz 1 | num_updates 44803 | best_loss 8.238
2022-03-08 00:22:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 921 @ 44803 updates
2022-03-08 00:22:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:22:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:22:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 921 @ 44803 updates, score 14.951) (writing took 2.514904310926795 seconds)
2022-03-08 00:22:58 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)
2022-03-08 00:22:58 | INFO | train | epoch 921 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24909.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44803 | lr 0.000149399 | gnorm 0.253 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 127253
2022-03-08 00:22:58 | INFO | fairseq.trainer | begin training epoch 922
2022-03-08 00:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:25:03 | INFO | valid | epoch 922 | valid on 'valid' subset | loss 14.997 | nll_loss 14.901 | ppl 30596.5 | wps 47213.3 | wpb 510.9 | bsz 1 | num_updates 44852 | best_loss 8.238
2022-03-08 00:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 922 @ 44852 updates
2022-03-08 00:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:25:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:25:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 922 @ 44852 updates, score 14.997) (writing took 2.5405976623296738 seconds)
2022-03-08 00:25:05 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)
2022-03-08 00:25:05 | INFO | train | epoch 922 | loss 0.383 | nll_loss 0.091 | ppl 1.07 | wps 24922.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44852 | lr 0.000149317 | gnorm 0.256 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 127381
2022-03-08 00:25:05 | INFO | fairseq.trainer | begin training epoch 923
2022-03-08 00:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:25:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:27:06 | INFO | train_inner | epoch 923:     49 / 49 loss=0.382, nll_loss=0.091, ppl=1.07, wps=24701.7, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=44900, lr=0.000149237, gnorm=0.255, loss_scale=64, train_wall=223, gb_free=8.8, wall=127501
2022-03-08 00:27:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:10 | INFO | valid | epoch 923 | valid on 'valid' subset | loss 14.921 | nll_loss 14.825 | ppl 29028.1 | wps 47210.8 | wpb 510.9 | bsz 1 | num_updates 44900 | best_loss 8.238
2022-03-08 00:27:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 923 @ 44900 updates
2022-03-08 00:27:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:27:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 923 @ 44900 updates, score 14.921) (writing took 2.5231099631637335 seconds)
2022-03-08 00:27:13 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)
2022-03-08 00:27:13 | INFO | train | epoch 923 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24422.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44900 | lr 0.000149237 | gnorm 0.253 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 127508
2022-03-08 00:27:13 | INFO | fairseq.trainer | begin training epoch 924
2022-03-08 00:27:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:29:18 | INFO | valid | epoch 924 | valid on 'valid' subset | loss 14.959 | nll_loss 14.864 | ppl 29825.7 | wps 47036.3 | wpb 510.9 | bsz 1 | num_updates 44949 | best_loss 8.238
2022-03-08 00:29:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 924 @ 44949 updates
2022-03-08 00:29:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 924 @ 44949 updates, score 14.959) (writing took 2.5216242242604494 seconds)
2022-03-08 00:29:20 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)
2022-03-08 00:29:20 | INFO | train | epoch 924 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24924.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 44949 | lr 0.000149156 | gnorm 0.256 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 127635
2022-03-08 00:29:20 | INFO | fairseq.trainer | begin training epoch 925
2022-03-08 00:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:30:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:31:25 | INFO | valid | epoch 925 | valid on 'valid' subset | loss 15.034 | nll_loss 14.94 | ppl 31428.3 | wps 47565.3 | wpb 510.9 | bsz 1 | num_updates 44997 | best_loss 8.238
2022-03-08 00:31:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 925 @ 44997 updates
2022-03-08 00:31:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 925 @ 44997 updates, score 15.034) (writing took 2.5503896102309227 seconds)
2022-03-08 00:31:28 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)
2022-03-08 00:31:28 | INFO | train | epoch 925 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24400.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44997 | lr 0.000149076 | gnorm 0.255 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 127763
2022-03-08 00:31:28 | INFO | fairseq.trainer | begin training epoch 926
2022-03-08 00:31:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:31:35 | INFO | train_inner | epoch 926:      3 / 49 loss=0.382, nll_loss=0.091, ppl=1.07, wps=24039.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=45000, lr=0.000149071, gnorm=0.255, loss_scale=64, train_wall=224, gb_free=8.8, wall=127771
2022-03-08 00:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:33:33 | INFO | valid | epoch 926 | valid on 'valid' subset | loss 14.933 | nll_loss 14.838 | ppl 29292.7 | wps 46925 | wpb 510.9 | bsz 1 | num_updates 45046 | best_loss 8.238
2022-03-08 00:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 926 @ 45046 updates
2022-03-08 00:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 926 @ 45046 updates, score 14.933) (writing took 2.4814191441982985 seconds)
2022-03-08 00:33:35 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)
2022-03-08 00:33:35 | INFO | train | epoch 926 | loss 0.382 | nll_loss 0.091 | ppl 1.06 | wps 24922.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45046 | lr 0.000148995 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 127891
2022-03-08 00:33:35 | INFO | fairseq.trainer | begin training epoch 927
2022-03-08 00:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:35:41 | INFO | valid | epoch 927 | valid on 'valid' subset | loss 15.059 | nll_loss 14.964 | ppl 31970.9 | wps 46595.8 | wpb 510.9 | bsz 1 | num_updates 45095 | best_loss 8.238
2022-03-08 00:35:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 927 @ 45095 updates
2022-03-08 00:35:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:35:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:35:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 927 @ 45095 updates, score 15.059) (writing took 2.5235983822494745 seconds)
2022-03-08 00:35:43 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)
2022-03-08 00:35:43 | INFO | train | epoch 927 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24894.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45095 | lr 0.000148914 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128018
2022-03-08 00:35:43 | INFO | fairseq.trainer | begin training epoch 928
2022-03-08 00:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:56 | INFO | train_inner | epoch 928:      5 / 49 loss=0.382, nll_loss=0.091, ppl=1.06, wps=24939.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45100, lr=0.000148906, gnorm=0.252, loss_scale=64, train_wall=222, gb_free=8.8, wall=128031
2022-03-08 00:36:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:37:48 | INFO | valid | epoch 928 | valid on 'valid' subset | loss 15.074 | nll_loss 14.979 | ppl 32300.2 | wps 46487.8 | wpb 510.9 | bsz 1 | num_updates 45143 | best_loss 8.238
2022-03-08 00:37:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 928 @ 45143 updates
2022-03-08 00:37:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:37:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 928 @ 45143 updates, score 15.074) (writing took 2.5201381128281355 seconds)
2022-03-08 00:37:51 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)
2022-03-08 00:37:51 | INFO | train | epoch 928 | loss 0.382 | nll_loss 0.091 | ppl 1.06 | wps 24420.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45143 | lr 0.000148835 | gnorm 0.254 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 128146
2022-03-08 00:37:51 | INFO | fairseq.trainer | begin training epoch 929
2022-03-08 00:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:39:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:39:56 | INFO | valid | epoch 929 | valid on 'valid' subset | loss 15.011 | nll_loss 14.916 | ppl 30909.9 | wps 47158.2 | wpb 510.9 | bsz 1 | num_updates 45192 | best_loss 8.238
2022-03-08 00:39:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 929 @ 45192 updates
2022-03-08 00:39:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:39:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:39:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 929 @ 45192 updates, score 15.011) (writing took 2.48149786144495 seconds)
2022-03-08 00:39:58 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)
2022-03-08 00:39:58 | INFO | train | epoch 929 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24873 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45192 | lr 0.000148754 | gnorm 0.254 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128273
2022-03-08 00:39:58 | INFO | fairseq.trainer | begin training epoch 930
2022-03-08 00:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:40:18 | INFO | train_inner | epoch 930:      8 / 49 loss=0.382, nll_loss=0.091, ppl=1.06, wps=24704.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45200, lr=0.000148741, gnorm=0.253, loss_scale=64, train_wall=224, gb_free=8.8, wall=128293
2022-03-08 00:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:42:03 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 15.034 | nll_loss 14.939 | ppl 31412.5 | wps 47500.5 | wpb 510.9 | bsz 1 | num_updates 45241 | best_loss 8.238
2022-03-08 00:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 45241 updates
2022-03-08 00:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 930 @ 45241 updates, score 15.034) (writing took 2.5299011692404747 seconds)
2022-03-08 00:42:06 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)
2022-03-08 00:42:06 | INFO | train | epoch 930 | loss 0.382 | nll_loss 0.091 | ppl 1.07 | wps 24942.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45241 | lr 0.000148674 | gnorm 0.252 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 128401
2022-03-08 00:42:06 | INFO | fairseq.trainer | begin training epoch 931
2022-03-08 00:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:42:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:44:11 | INFO | valid | epoch 931 | valid on 'valid' subset | loss 14.962 | nll_loss 14.867 | ppl 29886.4 | wps 46040.7 | wpb 510.9 | bsz 1 | num_updates 45289 | best_loss 8.238
2022-03-08 00:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 931 @ 45289 updates
2022-03-08 00:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 931 @ 45289 updates, score 14.962) (writing took 2.46146073192358 seconds)
2022-03-08 00:44:14 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)
2022-03-08 00:44:14 | INFO | train | epoch 931 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24346.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45289 | lr 0.000148595 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128529
2022-03-08 00:44:14 | INFO | fairseq.trainer | begin training epoch 932
2022-03-08 00:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:44:41 | INFO | train_inner | epoch 932:     11 / 49 loss=0.382, nll_loss=0.091, ppl=1.06, wps=24681.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=45300, lr=0.000148577, gnorm=0.252, loss_scale=64, train_wall=224, gb_free=8.8, wall=128556
2022-03-08 00:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:19 | INFO | valid | epoch 932 | valid on 'valid' subset | loss 15.018 | nll_loss 14.924 | ppl 31076.2 | wps 47092.5 | wpb 510.9 | bsz 1 | num_updates 45338 | best_loss 8.238
2022-03-08 00:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 932 @ 45338 updates
2022-03-08 00:46:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:46:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 932 @ 45338 updates, score 15.018) (writing took 2.5144129041582346 seconds)
2022-03-08 00:46:22 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)
2022-03-08 00:46:22 | INFO | train | epoch 932 | loss 0.382 | nll_loss 0.091 | ppl 1.06 | wps 24827.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45338 | lr 0.000148514 | gnorm 0.253 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128657
2022-03-08 00:46:22 | INFO | fairseq.trainer | begin training epoch 933
2022-03-08 00:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:47:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:48:27 | INFO | valid | epoch 933 | valid on 'valid' subset | loss 14.959 | nll_loss 14.863 | ppl 29808.4 | wps 46084.9 | wpb 510.9 | bsz 1 | num_updates 45386 | best_loss 8.238
2022-03-08 00:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 933 @ 45386 updates
2022-03-08 00:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:48:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:48:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 933 @ 45386 updates, score 14.959) (writing took 2.383856074884534 seconds)
2022-03-08 00:48:29 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)
2022-03-08 00:48:29 | INFO | train | epoch 933 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24412.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45386 | lr 0.000148436 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128784
2022-03-08 00:48:29 | INFO | fairseq.trainer | begin training epoch 934
2022-03-08 00:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:49:04 | INFO | train_inner | epoch 934:     14 / 49 loss=0.381, nll_loss=0.09, ppl=1.06, wps=24663.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45400, lr=0.000148413, gnorm=0.252, loss_scale=64, train_wall=224, gb_free=8.8, wall=128819
2022-03-08 00:50:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:50:35 | INFO | valid | epoch 934 | valid on 'valid' subset | loss 14.954 | nll_loss 14.859 | ppl 29708.4 | wps 46425.4 | wpb 510.9 | bsz 1 | num_updates 45435 | best_loss 8.238
2022-03-08 00:50:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 934 @ 45435 updates
2022-03-08 00:50:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 934 @ 45435 updates, score 14.954) (writing took 2.5577562879770994 seconds)
2022-03-08 00:50:37 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)
2022-03-08 00:50:37 | INFO | train | epoch 934 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24824.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45435 | lr 0.000148356 | gnorm 0.253 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 128912
2022-03-08 00:50:37 | INFO | fairseq.trainer | begin training epoch 935
2022-03-08 00:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:52:43 | INFO | valid | epoch 935 | valid on 'valid' subset | loss 14.907 | nll_loss 14.812 | ppl 28773.9 | wps 46820 | wpb 510.9 | bsz 1 | num_updates 45484 | best_loss 8.238
2022-03-08 00:52:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 935 @ 45484 updates
2022-03-08 00:52:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:52:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:52:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 935 @ 45484 updates, score 14.907) (writing took 5.520220933482051 seconds)
2022-03-08 00:52:48 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)
2022-03-08 00:52:48 | INFO | train | epoch 935 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24247.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 45484 | lr 0.000148276 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 129043
2022-03-08 00:52:48 | INFO | fairseq.trainer | begin training epoch 936
2022-03-08 00:52:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:53:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:53:30 | INFO | train_inner | epoch 936:     17 / 49 loss=0.381, nll_loss=0.09, ppl=1.06, wps=24352.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=45500, lr=0.00014825, gnorm=0.251, loss_scale=64, train_wall=224, gb_free=8.8, wall=129086
2022-03-08 00:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:54:53 | INFO | valid | epoch 936 | valid on 'valid' subset | loss 15.011 | nll_loss 14.917 | ppl 30925.4 | wps 47321.9 | wpb 510.9 | bsz 1 | num_updates 45532 | best_loss 8.238
2022-03-08 00:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 936 @ 45532 updates
2022-03-08 00:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:54:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 936 @ 45532 updates, score 15.011) (writing took 2.4868426881730556 seconds)
2022-03-08 00:54:56 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)
2022-03-08 00:54:56 | INFO | train | epoch 936 | loss 0.381 | nll_loss 0.091 | ppl 1.06 | wps 24400.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45532 | lr 0.000148198 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 129171
2022-03-08 00:54:56 | INFO | fairseq.trainer | begin training epoch 937
2022-03-08 00:54:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:57:01 | INFO | valid | epoch 937 | valid on 'valid' subset | loss 15.032 | nll_loss 14.938 | ppl 31390 | wps 47078.1 | wpb 510.9 | bsz 1 | num_updates 45581 | best_loss 8.238
2022-03-08 00:57:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 937 @ 45581 updates
2022-03-08 00:57:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:57:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:57:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 937 @ 45581 updates, score 15.032) (writing took 2.562860459089279 seconds)
2022-03-08 00:57:03 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)
2022-03-08 00:57:03 | INFO | train | epoch 937 | loss 0.381 | nll_loss 0.091 | ppl 1.06 | wps 24925.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45581 | lr 0.000148118 | gnorm 0.254 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 129298
2022-03-08 00:57:03 | INFO | fairseq.trainer | begin training epoch 938
2022-03-08 00:57:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:57:50 | INFO | train_inner | epoch 938:     19 / 49 loss=0.381, nll_loss=0.09, ppl=1.06, wps=24958.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45600, lr=0.000148087, gnorm=0.253, loss_scale=64, train_wall=221, gb_free=8.8, wall=129346
2022-03-08 00:58:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 00:59:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:59:08 | INFO | valid | epoch 938 | valid on 'valid' subset | loss 14.975 | nll_loss 14.88 | ppl 30156.1 | wps 47576.2 | wpb 510.9 | bsz 1 | num_updates 45629 | best_loss 8.238
2022-03-08 00:59:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 938 @ 45629 updates
2022-03-08 00:59:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:59:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 00:59:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 938 @ 45629 updates, score 14.975) (writing took 2.486837714910507 seconds)
2022-03-08 00:59:11 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)
2022-03-08 00:59:11 | INFO | train | epoch 938 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24450.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45629 | lr 0.00014804 | gnorm 0.251 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 129426
2022-03-08 00:59:11 | INFO | fairseq.trainer | begin training epoch 939
2022-03-08 00:59:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:01:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:01:16 | INFO | valid | epoch 939 | valid on 'valid' subset | loss 15.038 | nll_loss 14.945 | ppl 31542.2 | wps 47056.2 | wpb 510.9 | bsz 1 | num_updates 45678 | best_loss 8.238
2022-03-08 01:01:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 939 @ 45678 updates
2022-03-08 01:01:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:01:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:01:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 939 @ 45678 updates, score 15.038) (writing took 2.5079446975141764 seconds)
2022-03-08 01:01:18 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)
2022-03-08 01:01:18 | INFO | train | epoch 939 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24924.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45678 | lr 0.000147961 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 129553
2022-03-08 01:01:18 | INFO | fairseq.trainer | begin training epoch 940
2022-03-08 01:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:13 | INFO | train_inner | epoch 940:     22 / 49 loss=0.381, nll_loss=0.09, ppl=1.06, wps=24725.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=45700, lr=0.000147925, gnorm=0.252, loss_scale=64, train_wall=224, gb_free=8.8, wall=129608
2022-03-08 01:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:03:23 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 15.003 | nll_loss 14.909 | ppl 30755.7 | wps 47176.6 | wpb 510.9 | bsz 1 | num_updates 45727 | best_loss 8.238
2022-03-08 01:03:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 45727 updates
2022-03-08 01:03:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:03:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:03:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 940 @ 45727 updates, score 15.003) (writing took 2.540877863764763 seconds)
2022-03-08 01:03:26 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)
2022-03-08 01:03:26 | INFO | train | epoch 940 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24903.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45727 | lr 0.000147881 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 129681
2022-03-08 01:03:26 | INFO | fairseq.trainer | begin training epoch 941
2022-03-08 01:03:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:05:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:05:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:31 | INFO | valid | epoch 941 | valid on 'valid' subset | loss 14.966 | nll_loss 14.87 | ppl 29945.4 | wps 47088.2 | wpb 510.9 | bsz 1 | num_updates 45775 | best_loss 8.238
2022-03-08 01:05:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 941 @ 45775 updates
2022-03-08 01:05:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:05:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 941 @ 45775 updates, score 14.966) (writing took 2.5268152002245188 seconds)
2022-03-08 01:05:33 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)
2022-03-08 01:05:33 | INFO | train | epoch 941 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24417.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45775 | lr 0.000147804 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 129808
2022-03-08 01:05:33 | INFO | fairseq.trainer | begin training epoch 942
2022-03-08 01:05:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:06:35 | INFO | train_inner | epoch 942:     25 / 49 loss=0.381, nll_loss=0.09, ppl=1.06, wps=24723.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45800, lr=0.000147764, gnorm=0.251, loss_scale=64, train_wall=224, gb_free=8.8, wall=129870
2022-03-08 01:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:38 | INFO | valid | epoch 942 | valid on 'valid' subset | loss 15.061 | nll_loss 14.966 | ppl 32014.5 | wps 46951.1 | wpb 510.9 | bsz 1 | num_updates 45824 | best_loss 8.238
2022-03-08 01:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 942 @ 45824 updates
2022-03-08 01:07:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:07:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 942 @ 45824 updates, score 15.061) (writing took 2.566593397408724 seconds)
2022-03-08 01:07:41 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)
2022-03-08 01:07:41 | INFO | train | epoch 942 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24927.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45824 | lr 0.000147725 | gnorm 0.253 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 129936
2022-03-08 01:07:41 | INFO | fairseq.trainer | begin training epoch 943
2022-03-08 01:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:09:46 | INFO | valid | epoch 943 | valid on 'valid' subset | loss 15.036 | nll_loss 14.941 | ppl 31458.8 | wps 46866.4 | wpb 510.9 | bsz 1 | num_updates 45873 | best_loss 8.238
2022-03-08 01:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 943 @ 45873 updates
2022-03-08 01:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:09:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 943 @ 45873 updates, score 15.036) (writing took 2.469674838706851 seconds)
2022-03-08 01:09:48 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)
2022-03-08 01:09:48 | INFO | train | epoch 943 | loss 0.381 | nll_loss 0.09 | ppl 1.06 | wps 24883.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45873 | lr 0.000147646 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130063
2022-03-08 01:09:48 | INFO | fairseq.trainer | begin training epoch 944
2022-03-08 01:09:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:10:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:10:58 | INFO | train_inner | epoch 944:     28 / 49 loss=0.381, nll_loss=0.09, ppl=1.06, wps=24694.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45900, lr=0.000147602, gnorm=0.252, loss_scale=64, train_wall=224, gb_free=8.8, wall=130133
2022-03-08 01:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:11:53 | INFO | valid | epoch 944 | valid on 'valid' subset | loss 14.966 | nll_loss 14.872 | ppl 29977 | wps 47162.5 | wpb 510.9 | bsz 1 | num_updates 45921 | best_loss 8.238
2022-03-08 01:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 944 @ 45921 updates
2022-03-08 01:11:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:11:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:11:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 944 @ 45921 updates, score 14.966) (writing took 2.509817883372307 seconds)
2022-03-08 01:11:56 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)
2022-03-08 01:11:56 | INFO | train | epoch 944 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24409.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45921 | lr 0.000147569 | gnorm 0.253 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130191
2022-03-08 01:11:56 | INFO | fairseq.trainer | begin training epoch 945
2022-03-08 01:11:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:14:01 | INFO | valid | epoch 945 | valid on 'valid' subset | loss 15.033 | nll_loss 14.939 | ppl 31408.4 | wps 47077.5 | wpb 510.9 | bsz 1 | num_updates 45970 | best_loss 8.238
2022-03-08 01:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 945 @ 45970 updates
2022-03-08 01:14:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 945 @ 45970 updates, score 15.033) (writing took 2.546685976907611 seconds)
2022-03-08 01:14:03 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)
2022-03-08 01:14:03 | INFO | train | epoch 945 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24909.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 45970 | lr 0.00014749 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130319
2022-03-08 01:14:03 | INFO | fairseq.trainer | begin training epoch 946
2022-03-08 01:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:15:18 | INFO | train_inner | epoch 946:     30 / 49 loss=0.38, nll_loss=0.09, ppl=1.06, wps=24931.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46000, lr=0.000147442, gnorm=0.25, loss_scale=64, train_wall=222, gb_free=8.8, wall=130393
2022-03-08 01:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:16:09 | INFO | valid | epoch 946 | valid on 'valid' subset | loss 15.035 | nll_loss 14.941 | ppl 31452.5 | wps 46476.7 | wpb 510.9 | bsz 1 | num_updates 46019 | best_loss 8.238
2022-03-08 01:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 946 @ 46019 updates
2022-03-08 01:16:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 946 @ 46019 updates, score 15.035) (writing took 2.4900950994342566 seconds)
2022-03-08 01:16:11 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)
2022-03-08 01:16:11 | INFO | train | epoch 946 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24845.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46019 | lr 0.000147412 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130446
2022-03-08 01:16:11 | INFO | fairseq.trainer | begin training epoch 947
2022-03-08 01:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:16:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:18:17 | INFO | valid | epoch 947 | valid on 'valid' subset | loss 14.978 | nll_loss 14.883 | ppl 30210.8 | wps 46850.6 | wpb 510.9 | bsz 1 | num_updates 46067 | best_loss 8.238
2022-03-08 01:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 947 @ 46067 updates
2022-03-08 01:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 947 @ 46067 updates, score 14.978) (writing took 2.467591527849436 seconds)
2022-03-08 01:18:19 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)
2022-03-08 01:18:19 | INFO | train | epoch 947 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24307.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 46067 | lr 0.000147335 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130575
2022-03-08 01:18:19 | INFO | fairseq.trainer | begin training epoch 948
2022-03-08 01:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:19:42 | INFO | train_inner | epoch 948:     33 / 49 loss=0.38, nll_loss=0.09, ppl=1.06, wps=24599, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46100, lr=0.000147282, gnorm=0.25, loss_scale=64, train_wall=225, gb_free=8.8, wall=130657
2022-03-08 01:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:20:25 | INFO | valid | epoch 948 | valid on 'valid' subset | loss 14.976 | nll_loss 14.881 | ppl 30168.5 | wps 46593.5 | wpb 510.9 | bsz 1 | num_updates 46116 | best_loss 8.238
2022-03-08 01:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 948 @ 46116 updates
2022-03-08 01:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:20:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 948 @ 46116 updates, score 14.976) (writing took 2.552411735057831 seconds)
2022-03-08 01:20:28 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)
2022-03-08 01:20:28 | INFO | train | epoch 948 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24774.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46116 | lr 0.000147256 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130703
2022-03-08 01:20:28 | INFO | fairseq.trainer | begin training epoch 949
2022-03-08 01:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:22:33 | INFO | valid | epoch 949 | valid on 'valid' subset | loss 14.944 | nll_loss 14.849 | ppl 29510.2 | wps 46471.8 | wpb 510.9 | bsz 1 | num_updates 46165 | best_loss 8.238
2022-03-08 01:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 949 @ 46165 updates
2022-03-08 01:22:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:22:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:22:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 949 @ 46165 updates, score 14.944) (writing took 2.5253457967191935 seconds)
2022-03-08 01:22:36 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)
2022-03-08 01:22:36 | INFO | train | epoch 949 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24786.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46165 | lr 0.000147178 | gnorm 0.25 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 130831
2022-03-08 01:22:36 | INFO | fairseq.trainer | begin training epoch 950
2022-03-08 01:22:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:22:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:24:06 | INFO | train_inner | epoch 950:     36 / 49 loss=0.38, nll_loss=0.09, ppl=1.06, wps=24586.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46200, lr=0.000147122, gnorm=0.251, loss_scale=64, train_wall=225, gb_free=8.8, wall=130921
2022-03-08 01:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:24:41 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 15.058 | nll_loss 14.964 | ppl 31960.4 | wps 46672.1 | wpb 510.9 | bsz 1 | num_updates 46213 | best_loss 8.238
2022-03-08 01:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 46213 updates
2022-03-08 01:24:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:24:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:24:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 950 @ 46213 updates, score 15.058) (writing took 2.513601439073682 seconds)
2022-03-08 01:24:44 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)
2022-03-08 01:24:44 | INFO | train | epoch 950 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24304.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 46213 | lr 0.000147102 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 130959
2022-03-08 01:24:44 | INFO | fairseq.trainer | begin training epoch 951
2022-03-08 01:24:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:26:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:26:50 | INFO | valid | epoch 951 | valid on 'valid' subset | loss 14.947 | nll_loss 14.852 | ppl 29572.8 | wps 46509.7 | wpb 510.9 | bsz 1 | num_updates 46262 | best_loss 8.238
2022-03-08 01:26:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 951 @ 46262 updates
2022-03-08 01:26:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:26:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:26:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 951 @ 46262 updates, score 14.947) (writing took 2.5724796764552593 seconds)
2022-03-08 01:26:52 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)
2022-03-08 01:26:52 | INFO | train | epoch 951 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24795.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46262 | lr 0.000147024 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131087
2022-03-08 01:26:52 | INFO | fairseq.trainer | begin training epoch 952
2022-03-08 01:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:27 | INFO | train_inner | epoch 952:     38 / 49 loss=0.38, nll_loss=0.09, ppl=1.06, wps=24834.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46300, lr=0.000146964, gnorm=0.251, loss_scale=128, train_wall=222, gb_free=8.8, wall=131182
2022-03-08 01:28:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:28:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:28:58 | INFO | valid | epoch 952 | valid on 'valid' subset | loss 14.947 | nll_loss 14.853 | ppl 29588.2 | wps 46942.3 | wpb 510.9 | bsz 1 | num_updates 46310 | best_loss 8.238
2022-03-08 01:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 952 @ 46310 updates
2022-03-08 01:28:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:29:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:29:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 952 @ 46310 updates, score 14.947) (writing took 2.4863922987133265 seconds)
2022-03-08 01:29:00 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)
2022-03-08 01:29:00 | INFO | train | epoch 952 | loss 0.38 | nll_loss 0.089 | ppl 1.06 | wps 24287.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 46310 | lr 0.000146948 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131215
2022-03-08 01:29:00 | INFO | fairseq.trainer | begin training epoch 953
2022-03-08 01:29:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:31:06 | INFO | valid | epoch 953 | valid on 'valid' subset | loss 15.006 | nll_loss 14.911 | ppl 30813.2 | wps 47005 | wpb 510.9 | bsz 1 | num_updates 46359 | best_loss 8.238
2022-03-08 01:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 953 @ 46359 updates
2022-03-08 01:31:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:31:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:31:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 953 @ 46359 updates, score 15.006) (writing took 2.51802908629179 seconds)
2022-03-08 01:31:08 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)
2022-03-08 01:31:08 | INFO | train | epoch 953 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24801.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46359 | lr 0.00014687 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131344
2022-03-08 01:31:08 | INFO | fairseq.trainer | begin training epoch 954
2022-03-08 01:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:32:51 | INFO | train_inner | epoch 954:     41 / 49 loss=0.38, nll_loss=0.09, ppl=1.06, wps=24579.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46400, lr=0.000146805, gnorm=0.251, loss_scale=64, train_wall=225, gb_free=8.8, wall=131446
2022-03-08 01:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:33:14 | INFO | valid | epoch 954 | valid on 'valid' subset | loss 15.035 | nll_loss 14.941 | ppl 31452.8 | wps 47069.4 | wpb 510.9 | bsz 1 | num_updates 46408 | best_loss 8.238
2022-03-08 01:33:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 954 @ 46408 updates
2022-03-08 01:33:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 954 @ 46408 updates, score 15.035) (writing took 2.5294290222227573 seconds)
2022-03-08 01:33:17 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)
2022-03-08 01:33:17 | INFO | train | epoch 954 | loss 0.38 | nll_loss 0.089 | ppl 1.06 | wps 24789.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46408 | lr 0.000146792 | gnorm 0.252 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131472
2022-03-08 01:33:17 | INFO | fairseq.trainer | begin training epoch 955
2022-03-08 01:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:34:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:35:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:35:22 | INFO | valid | epoch 955 | valid on 'valid' subset | loss 15.005 | nll_loss 14.91 | ppl 30796.2 | wps 46700.6 | wpb 510.9 | bsz 1 | num_updates 46456 | best_loss 8.238
2022-03-08 01:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 955 @ 46456 updates
2022-03-08 01:35:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 955 @ 46456 updates, score 15.005) (writing took 2.502855021506548 seconds)
2022-03-08 01:35:25 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)
2022-03-08 01:35:25 | INFO | train | epoch 955 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24298.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 46456 | lr 0.000146717 | gnorm 0.246 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131600
2022-03-08 01:35:25 | INFO | fairseq.trainer | begin training epoch 956
2022-03-08 01:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:37:14 | INFO | train_inner | epoch 956:     44 / 49 loss=0.379, nll_loss=0.089, ppl=1.06, wps=24601.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46500, lr=0.000146647, gnorm=0.247, loss_scale=64, train_wall=225, gb_free=8.8, wall=131710
2022-03-08 01:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:37:30 | INFO | valid | epoch 956 | valid on 'valid' subset | loss 14.97 | nll_loss 14.876 | ppl 30076.7 | wps 46659.3 | wpb 510.9 | bsz 1 | num_updates 46505 | best_loss 8.238
2022-03-08 01:37:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 956 @ 46505 updates
2022-03-08 01:37:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:37:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 956 @ 46505 updates, score 14.97) (writing took 2.49156348221004 seconds)
2022-03-08 01:37:33 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)
2022-03-08 01:37:33 | INFO | train | epoch 956 | loss 0.38 | nll_loss 0.089 | ppl 1.06 | wps 24802.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46505 | lr 0.000146639 | gnorm 0.247 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131728
2022-03-08 01:37:33 | INFO | fairseq.trainer | begin training epoch 957
2022-03-08 01:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:39 | INFO | valid | epoch 957 | valid on 'valid' subset | loss 15.073 | nll_loss 14.98 | ppl 32317.9 | wps 46217.5 | wpb 510.9 | bsz 1 | num_updates 46554 | best_loss 8.238
2022-03-08 01:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 957 @ 46554 updates
2022-03-08 01:39:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:39:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:39:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 957 @ 46554 updates, score 15.073) (writing took 2.4903174359351397 seconds)
2022-03-08 01:39:41 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)
2022-03-08 01:39:41 | INFO | train | epoch 957 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24786.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46554 | lr 0.000146562 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131856
2022-03-08 01:39:41 | INFO | fairseq.trainer | begin training epoch 958
2022-03-08 01:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:40:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:41:38 | INFO | train_inner | epoch 958:     47 / 49 loss=0.38, nll_loss=0.089, ppl=1.06, wps=24608.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46600, lr=0.00014649, gnorm=0.249, loss_scale=64, train_wall=225, gb_free=8.8, wall=131973
2022-03-08 01:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:41:47 | INFO | valid | epoch 958 | valid on 'valid' subset | loss 15.048 | nll_loss 14.954 | ppl 31735 | wps 46697.9 | wpb 510.9 | bsz 1 | num_updates 46602 | best_loss 8.238
2022-03-08 01:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 958 @ 46602 updates
2022-03-08 01:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:41:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 958 @ 46602 updates, score 15.048) (writing took 2.4996840599924326 seconds)
2022-03-08 01:41:49 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)
2022-03-08 01:41:49 | INFO | train | epoch 958 | loss 0.38 | nll_loss 0.09 | ppl 1.06 | wps 24328.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46602 | lr 0.000146487 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 131984
2022-03-08 01:41:49 | INFO | fairseq.trainer | begin training epoch 959
2022-03-08 01:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:55 | INFO | valid | epoch 959 | valid on 'valid' subset | loss 14.992 | nll_loss 14.898 | ppl 30526.1 | wps 46612.4 | wpb 510.9 | bsz 1 | num_updates 46651 | best_loss 8.238
2022-03-08 01:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 959 @ 46651 updates
2022-03-08 01:43:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:43:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 959 @ 46651 updates, score 14.992) (writing took 2.52814369648695 seconds)
2022-03-08 01:43:57 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)
2022-03-08 01:43:57 | INFO | train | epoch 959 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24778.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46651 | lr 0.00014641 | gnorm 0.251 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132112
2022-03-08 01:43:57 | INFO | fairseq.trainer | begin training epoch 960
2022-03-08 01:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:45:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:46:03 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 14.984 | nll_loss 14.889 | ppl 30332 | wps 46946.8 | wpb 510.9 | bsz 1 | num_updates 46699 | best_loss 8.238
2022-03-08 01:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 46699 updates
2022-03-08 01:46:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 960 @ 46699 updates, score 14.984) (writing took 2.5304957795888186 seconds)
2022-03-08 01:46:06 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)
2022-03-08 01:46:06 | INFO | train | epoch 960 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24272.6 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 46699 | lr 0.000146334 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132241
2022-03-08 01:46:06 | INFO | fairseq.trainer | begin training epoch 961
2022-03-08 01:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:46:08 | INFO | train_inner | epoch 961:      1 / 49 loss=0.379, nll_loss=0.089, ppl=1.06, wps=23898.1, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=46700, lr=0.000146333, gnorm=0.251, loss_scale=64, train_wall=224, gb_free=8.8, wall=132243
2022-03-08 01:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:11 | INFO | valid | epoch 961 | valid on 'valid' subset | loss 15.013 | nll_loss 14.919 | ppl 30971.9 | wps 46740.3 | wpb 510.9 | bsz 1 | num_updates 46748 | best_loss 8.238
2022-03-08 01:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 961 @ 46748 updates
2022-03-08 01:48:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:48:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:48:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 961 @ 46748 updates, score 15.013) (writing took 2.517206085845828 seconds)
2022-03-08 01:48:14 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)
2022-03-08 01:48:14 | INFO | train | epoch 961 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24767.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46748 | lr 0.000146258 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132369
2022-03-08 01:48:14 | INFO | fairseq.trainer | begin training epoch 962
2022-03-08 01:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:50:20 | INFO | valid | epoch 962 | valid on 'valid' subset | loss 15.01 | nll_loss 14.916 | ppl 30922.8 | wps 46573.3 | wpb 510.9 | bsz 1 | num_updates 46797 | best_loss 8.238
2022-03-08 01:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 962 @ 46797 updates
2022-03-08 01:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 962 @ 46797 updates, score 15.01) (writing took 2.5241877362132072 seconds)
2022-03-08 01:50:22 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)
2022-03-08 01:50:22 | INFO | train | epoch 962 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24778.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46797 | lr 0.000146181 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132497
2022-03-08 01:50:22 | INFO | fairseq.trainer | begin training epoch 963
2022-03-08 01:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:50:30 | INFO | train_inner | epoch 963:      3 / 49 loss=0.379, nll_loss=0.089, ppl=1.06, wps=24805.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46800, lr=0.000146176, gnorm=0.249, loss_scale=64, train_wall=223, gb_free=8.8, wall=132505
2022-03-08 01:51:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:52:28 | INFO | valid | epoch 963 | valid on 'valid' subset | loss 14.954 | nll_loss 14.859 | ppl 29720.2 | wps 46613.9 | wpb 510.9 | bsz 1 | num_updates 46845 | best_loss 8.238
2022-03-08 01:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 963 @ 46845 updates
2022-03-08 01:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 963 @ 46845 updates, score 14.954) (writing took 2.5305241383612156 seconds)
2022-03-08 01:52:30 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)
2022-03-08 01:52:30 | INFO | train | epoch 963 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24268.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 46845 | lr 0.000146106 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132625
2022-03-08 01:52:30 | INFO | fairseq.trainer | begin training epoch 964
2022-03-08 01:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:54:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:54:36 | INFO | valid | epoch 964 | valid on 'valid' subset | loss 14.985 | nll_loss 14.89 | ppl 30358.4 | wps 46566.1 | wpb 510.9 | bsz 1 | num_updates 46894 | best_loss 8.238
2022-03-08 01:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 964 @ 46894 updates
2022-03-08 01:54:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:54:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 964 @ 46894 updates, score 14.985) (writing took 2.485009826719761 seconds)
2022-03-08 01:54:39 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)
2022-03-08 01:54:39 | INFO | train | epoch 964 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24780.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46894 | lr 0.00014603 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132754
2022-03-08 01:54:39 | INFO | fairseq.trainer | begin training epoch 965
2022-03-08 01:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:54:54 | INFO | train_inner | epoch 965:      6 / 49 loss=0.379, nll_loss=0.089, ppl=1.06, wps=24561.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=46900, lr=0.00014602, gnorm=0.248, loss_scale=64, train_wall=225, gb_free=8.8, wall=132769
2022-03-08 01:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:56:45 | INFO | valid | epoch 965 | valid on 'valid' subset | loss 15.01 | nll_loss 14.916 | ppl 30920.2 | wps 46687.8 | wpb 510.9 | bsz 1 | num_updates 46943 | best_loss 8.238
2022-03-08 01:56:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 965 @ 46943 updates
2022-03-08 01:56:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:56:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:56:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 965 @ 46943 updates, score 15.01) (writing took 2.4937041439116 seconds)
2022-03-08 01:56:47 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)
2022-03-08 01:56:47 | INFO | train | epoch 965 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24743.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 46943 | lr 0.000145954 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 132882
2022-03-08 01:56:47 | INFO | fairseq.trainer | begin training epoch 966
2022-03-08 01:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:57:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 01:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:58:53 | INFO | valid | epoch 966 | valid on 'valid' subset | loss 14.937 | nll_loss 14.842 | ppl 29373.2 | wps 46381.6 | wpb 510.9 | bsz 1 | num_updates 46991 | best_loss 8.238
2022-03-08 01:58:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 966 @ 46991 updates
2022-03-08 01:58:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:58:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 01:58:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 966 @ 46991 updates, score 14.937) (writing took 2.629794480279088 seconds)
2022-03-08 01:58:55 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)
2022-03-08 01:58:55 | INFO | train | epoch 966 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24254.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 46991 | lr 0.000145879 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133010
2022-03-08 01:58:55 | INFO | fairseq.trainer | begin training epoch 967
2022-03-08 01:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:59:18 | INFO | train_inner | epoch 967:      9 / 49 loss=0.379, nll_loss=0.089, ppl=1.06, wps=24564.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47000, lr=0.000145865, gnorm=0.249, loss_scale=64, train_wall=225, gb_free=8.8, wall=133033
2022-03-08 02:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:01:01 | INFO | valid | epoch 967 | valid on 'valid' subset | loss 14.924 | nll_loss 14.83 | ppl 29116 | wps 46716.5 | wpb 510.9 | bsz 1 | num_updates 47040 | best_loss 8.238
2022-03-08 02:01:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 967 @ 47040 updates
2022-03-08 02:01:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:01:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:01:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 967 @ 47040 updates, score 14.924) (writing took 2.4796632286161184 seconds)
2022-03-08 02:01:04 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)
2022-03-08 02:01:04 | INFO | train | epoch 967 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24791.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47040 | lr 0.000145803 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133139
2022-03-08 02:01:04 | INFO | fairseq.trainer | begin training epoch 968
2022-03-08 02:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:02:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:03:09 | INFO | valid | epoch 968 | valid on 'valid' subset | loss 14.987 | nll_loss 14.893 | ppl 30436 | wps 46802.4 | wpb 510.9 | bsz 1 | num_updates 47088 | best_loss 8.238
2022-03-08 02:03:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 968 @ 47088 updates
2022-03-08 02:03:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:03:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:03:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 968 @ 47088 updates, score 14.987) (writing took 2.5645076278597116 seconds)
2022-03-08 02:03:12 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)
2022-03-08 02:03:12 | INFO | train | epoch 968 | loss 0.379 | nll_loss 0.088 | ppl 1.06 | wps 24299.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47088 | lr 0.000145729 | gnorm 0.247 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133267
2022-03-08 02:03:12 | INFO | fairseq.trainer | begin training epoch 969
2022-03-08 02:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:03:42 | INFO | train_inner | epoch 969:     12 / 49 loss=0.379, nll_loss=0.089, ppl=1.06, wps=24593.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47100, lr=0.00014571, gnorm=0.248, loss_scale=64, train_wall=225, gb_free=8.8, wall=133297
2022-03-08 02:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:05:17 | INFO | valid | epoch 969 | valid on 'valid' subset | loss 14.989 | nll_loss 14.894 | ppl 30452.8 | wps 46896.6 | wpb 510.9 | bsz 1 | num_updates 47137 | best_loss 8.238
2022-03-08 02:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 969 @ 47137 updates
2022-03-08 02:05:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:05:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:05:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 969 @ 47137 updates, score 14.989) (writing took 2.4904776252806187 seconds)
2022-03-08 02:05:20 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)
2022-03-08 02:05:20 | INFO | train | epoch 969 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24789.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47137 | lr 0.000145653 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133395
2022-03-08 02:05:20 | INFO | fairseq.trainer | begin training epoch 970
2022-03-08 02:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:07:26 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 14.954 | nll_loss 14.859 | ppl 29717.4 | wps 46784.3 | wpb 510.9 | bsz 1 | num_updates 47186 | best_loss 8.238
2022-03-08 02:07:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 47186 updates
2022-03-08 02:07:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:07:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 970 @ 47186 updates, score 14.954) (writing took 2.5101120993494987 seconds)
2022-03-08 02:07:28 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)
2022-03-08 02:07:28 | INFO | train | epoch 970 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24787 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47186 | lr 0.000145577 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133523
2022-03-08 02:07:28 | INFO | fairseq.trainer | begin training epoch 971
2022-03-08 02:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:08:03 | INFO | train_inner | epoch 971:     14 / 49 loss=0.379, nll_loss=0.089, ppl=1.06, wps=24815.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47200, lr=0.000145556, gnorm=0.249, loss_scale=64, train_wall=223, gb_free=8.8, wall=133558
2022-03-08 02:09:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:09:34 | INFO | valid | epoch 971 | valid on 'valid' subset | loss 14.964 | nll_loss 14.869 | ppl 29918.4 | wps 45953.2 | wpb 510.9 | bsz 1 | num_updates 47235 | best_loss 8.238
2022-03-08 02:09:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 971 @ 47235 updates
2022-03-08 02:09:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:09:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:09:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 971 @ 47235 updates, score 14.964) (writing took 2.5486853569746017 seconds)
2022-03-08 02:09:36 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)
2022-03-08 02:09:36 | INFO | train | epoch 971 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24767.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47235 | lr 0.000145502 | gnorm 0.247 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 133652
2022-03-08 02:09:36 | INFO | fairseq.trainer | begin training epoch 972
2022-03-08 02:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:09:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:11:42 | INFO | valid | epoch 972 | valid on 'valid' subset | loss 14.953 | nll_loss 14.858 | ppl 29695.1 | wps 46448.4 | wpb 510.9 | bsz 1 | num_updates 47283 | best_loss 8.238
2022-03-08 02:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 972 @ 47283 updates
2022-03-08 02:11:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 972 @ 47283 updates, score 14.953) (writing took 2.4672078546136618 seconds)
2022-03-08 02:11:44 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)
2022-03-08 02:11:44 | INFO | train | epoch 972 | loss 0.379 | nll_loss 0.089 | ppl 1.06 | wps 24302 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47283 | lr 0.000145428 | gnorm 0.253 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133780
2022-03-08 02:11:44 | INFO | fairseq.trainer | begin training epoch 973
2022-03-08 02:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:12:27 | INFO | train_inner | epoch 973:     17 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24593.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47300, lr=0.000145402, gnorm=0.251, loss_scale=64, train_wall=225, gb_free=8.8, wall=133822
2022-03-08 02:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:13:50 | INFO | valid | epoch 973 | valid on 'valid' subset | loss 14.999 | nll_loss 14.905 | ppl 30673.6 | wps 46846.5 | wpb 510.9 | bsz 1 | num_updates 47332 | best_loss 8.238
2022-03-08 02:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 973 @ 47332 updates
2022-03-08 02:13:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:13:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 973 @ 47332 updates, score 14.999) (writing took 2.520056227222085 seconds)
2022-03-08 02:13:53 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)
2022-03-08 02:13:53 | INFO | train | epoch 973 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24799.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47332 | lr 0.000145353 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 133908
2022-03-08 02:13:53 | INFO | fairseq.trainer | begin training epoch 974
2022-03-08 02:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:15:58 | INFO | valid | epoch 974 | valid on 'valid' subset | loss 14.958 | nll_loss 14.862 | ppl 29786.1 | wps 46903.7 | wpb 510.9 | bsz 1 | num_updates 47380 | best_loss 8.238
2022-03-08 02:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 974 @ 47380 updates
2022-03-08 02:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:16:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 974 @ 47380 updates, score 14.958) (writing took 2.531713208183646 seconds)
2022-03-08 02:16:01 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)
2022-03-08 02:16:01 | INFO | train | epoch 974 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24293.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47380 | lr 0.000145279 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134036
2022-03-08 02:16:01 | INFO | fairseq.trainer | begin training epoch 975
2022-03-08 02:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:16:51 | INFO | train_inner | epoch 975:     20 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24585.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47400, lr=0.000145248, gnorm=0.248, loss_scale=64, train_wall=225, gb_free=8.8, wall=134086
2022-03-08 02:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:18:06 | INFO | valid | epoch 975 | valid on 'valid' subset | loss 15 | nll_loss 14.907 | ppl 30725.7 | wps 46614.7 | wpb 510.9 | bsz 1 | num_updates 47429 | best_loss 8.238
2022-03-08 02:18:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 975 @ 47429 updates
2022-03-08 02:18:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:18:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:18:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 975 @ 47429 updates, score 15.0) (writing took 2.490726288408041 seconds)
2022-03-08 02:18:09 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)
2022-03-08 02:18:09 | INFO | train | epoch 975 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24780.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47429 | lr 0.000145204 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134164
2022-03-08 02:18:09 | INFO | fairseq.trainer | begin training epoch 976
2022-03-08 02:18:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:20:15 | INFO | valid | epoch 976 | valid on 'valid' subset | loss 14.955 | nll_loss 14.861 | ppl 29748.9 | wps 46606.7 | wpb 510.9 | bsz 1 | num_updates 47478 | best_loss 8.238
2022-03-08 02:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 976 @ 47478 updates
2022-03-08 02:20:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:20:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 976 @ 47478 updates, score 14.955) (writing took 2.4907237123697996 seconds)
2022-03-08 02:20:17 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)
2022-03-08 02:20:17 | INFO | train | epoch 976 | loss 0.377 | nll_loss 0.088 | ppl 1.06 | wps 24792.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47478 | lr 0.000145129 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134292
2022-03-08 02:20:17 | INFO | fairseq.trainer | begin training epoch 977
2022-03-08 02:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:12 | INFO | train_inner | epoch 977:     22 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24828.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47500, lr=0.000145095, gnorm=0.246, loss_scale=128, train_wall=223, gb_free=8.8, wall=134347
2022-03-08 02:21:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:22:23 | INFO | valid | epoch 977 | valid on 'valid' subset | loss 14.998 | nll_loss 14.904 | ppl 30653 | wps 45941.7 | wpb 510.9 | bsz 1 | num_updates 47526 | best_loss 8.238
2022-03-08 02:22:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 977 @ 47526 updates
2022-03-08 02:22:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:22:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 977 @ 47526 updates, score 14.998) (writing took 2.5245278421789408 seconds)
2022-03-08 02:22:25 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)
2022-03-08 02:22:25 | INFO | train | epoch 977 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24273.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47526 | lr 0.000145056 | gnorm 0.247 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134421
2022-03-08 02:22:25 | INFO | fairseq.trainer | begin training epoch 978
2022-03-08 02:22:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:24:31 | INFO | valid | epoch 978 | valid on 'valid' subset | loss 14.936 | nll_loss 14.842 | ppl 29372.3 | wps 46663.6 | wpb 510.9 | bsz 1 | num_updates 47575 | best_loss 8.238
2022-03-08 02:24:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 978 @ 47575 updates
2022-03-08 02:24:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:24:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 978 @ 47575 updates, score 14.936) (writing took 2.491740096360445 seconds)
2022-03-08 02:24:34 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)
2022-03-08 02:24:34 | INFO | train | epoch 978 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24792.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47575 | lr 0.000144981 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134549
2022-03-08 02:24:34 | INFO | fairseq.trainer | begin training epoch 979
2022-03-08 02:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:25:36 | INFO | train_inner | epoch 979:     25 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24566, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47600, lr=0.000144943, gnorm=0.248, loss_scale=64, train_wall=225, gb_free=8.8, wall=134611
2022-03-08 02:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:26:39 | INFO | valid | epoch 979 | valid on 'valid' subset | loss 14.947 | nll_loss 14.852 | ppl 29577.9 | wps 46732.2 | wpb 510.9 | bsz 1 | num_updates 47624 | best_loss 8.238
2022-03-08 02:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 979 @ 47624 updates
2022-03-08 02:26:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:26:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 979 @ 47624 updates, score 14.947) (writing took 2.4903788436204195 seconds)
2022-03-08 02:26:42 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)
2022-03-08 02:26:42 | INFO | train | epoch 979 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24778.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47624 | lr 0.000144906 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134677
2022-03-08 02:26:42 | INFO | fairseq.trainer | begin training epoch 980
2022-03-08 02:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:26:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:28:48 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 15.04 | nll_loss 14.946 | ppl 31572.3 | wps 46547.9 | wpb 510.9 | bsz 1 | num_updates 47672 | best_loss 8.238
2022-03-08 02:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 47672 updates
2022-03-08 02:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 980 @ 47672 updates, score 15.04) (writing took 2.5084071066230536 seconds)
2022-03-08 02:28:50 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)
2022-03-08 02:28:50 | INFO | train | epoch 980 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24267.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47672 | lr 0.000144833 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134805
2022-03-08 02:28:50 | INFO | fairseq.trainer | begin training epoch 981
2022-03-08 02:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:30:00 | INFO | train_inner | epoch 981:     28 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24577.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47700, lr=0.000144791, gnorm=0.247, loss_scale=64, train_wall=225, gb_free=8.8, wall=134875
2022-03-08 02:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:30:56 | INFO | valid | epoch 981 | valid on 'valid' subset | loss 15.003 | nll_loss 14.909 | ppl 30756 | wps 46802.5 | wpb 510.9 | bsz 1 | num_updates 47721 | best_loss 8.238
2022-03-08 02:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 981 @ 47721 updates
2022-03-08 02:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:30:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 981 @ 47721 updates, score 15.003) (writing took 2.512180656194687 seconds)
2022-03-08 02:30:58 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)
2022-03-08 02:30:58 | INFO | train | epoch 981 | loss 0.378 | nll_loss 0.089 | ppl 1.06 | wps 24761.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47721 | lr 0.000144759 | gnorm 0.249 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 134934
2022-03-08 02:30:58 | INFO | fairseq.trainer | begin training epoch 982
2022-03-08 02:30:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:32:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:33:04 | INFO | valid | epoch 982 | valid on 'valid' subset | loss 14.9 | nll_loss 14.806 | ppl 28649.7 | wps 46525.5 | wpb 510.9 | bsz 1 | num_updates 47769 | best_loss 8.238
2022-03-08 02:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 982 @ 47769 updates
2022-03-08 02:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 982 @ 47769 updates, score 14.9) (writing took 2.513942951336503 seconds)
2022-03-08 02:33:07 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)
2022-03-08 02:33:07 | INFO | train | epoch 982 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24248.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47769 | lr 0.000144686 | gnorm 0.25 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135062
2022-03-08 02:33:07 | INFO | fairseq.trainer | begin training epoch 983
2022-03-08 02:33:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:34:24 | INFO | train_inner | epoch 983:     31 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24568.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47800, lr=0.000144639, gnorm=0.249, loss_scale=64, train_wall=225, gb_free=8.8, wall=135139
2022-03-08 02:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:35:12 | INFO | valid | epoch 983 | valid on 'valid' subset | loss 15.042 | nll_loss 14.949 | ppl 31622 | wps 46649.1 | wpb 510.9 | bsz 1 | num_updates 47818 | best_loss 8.238
2022-03-08 02:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 983 @ 47818 updates
2022-03-08 02:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:35:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:35:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 983 @ 47818 updates, score 15.042) (writing took 2.5443585366010666 seconds)
2022-03-08 02:35:15 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)
2022-03-08 02:35:15 | INFO | train | epoch 983 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24792.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47818 | lr 0.000144612 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135190
2022-03-08 02:35:15 | INFO | fairseq.trainer | begin training epoch 984
2022-03-08 02:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:37:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:37:21 | INFO | valid | epoch 984 | valid on 'valid' subset | loss 14.991 | nll_loss 14.897 | ppl 30512.5 | wps 46385.9 | wpb 510.9 | bsz 1 | num_updates 47867 | best_loss 8.238
2022-03-08 02:37:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 984 @ 47867 updates
2022-03-08 02:37:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:37:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 984 @ 47867 updates, score 14.991) (writing took 2.496413055807352 seconds)
2022-03-08 02:37:23 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)
2022-03-08 02:37:23 | INFO | train | epoch 984 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24819.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47867 | lr 0.000144538 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135318
2022-03-08 02:37:23 | INFO | fairseq.trainer | begin training epoch 985
2022-03-08 02:37:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:38:48 | INFO | train_inner | epoch 985:     34 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24584.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=47900, lr=0.000144488, gnorm=0.248, loss_scale=64, train_wall=225, gb_free=8.8, wall=135403
2022-03-08 02:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:39:29 | INFO | valid | epoch 985 | valid on 'valid' subset | loss 14.975 | nll_loss 14.881 | ppl 30166 | wps 46616.6 | wpb 510.9 | bsz 1 | num_updates 47915 | best_loss 8.238
2022-03-08 02:39:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 985 @ 47915 updates
2022-03-08 02:39:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:39:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:39:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 985 @ 47915 updates, score 14.975) (writing took 2.4766849875450134 seconds)
2022-03-08 02:39:31 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)
2022-03-08 02:39:31 | INFO | train | epoch 985 | loss 0.377 | nll_loss 0.088 | ppl 1.06 | wps 24258.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 47915 | lr 0.000144466 | gnorm 0.247 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135446
2022-03-08 02:39:31 | INFO | fairseq.trainer | begin training epoch 986
2022-03-08 02:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:41:37 | INFO | valid | epoch 986 | valid on 'valid' subset | loss 14.957 | nll_loss 14.863 | ppl 29798.3 | wps 46687.4 | wpb 510.9 | bsz 1 | num_updates 47964 | best_loss 8.238
2022-03-08 02:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 986 @ 47964 updates
2022-03-08 02:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:41:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:41:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 986 @ 47964 updates, score 14.957) (writing took 2.4875186644494534 seconds)
2022-03-08 02:41:40 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)
2022-03-08 02:41:40 | INFO | train | epoch 986 | loss 0.377 | nll_loss 0.088 | ppl 1.06 | wps 24760.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 47964 | lr 0.000144392 | gnorm 0.247 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135575
2022-03-08 02:41:40 | INFO | fairseq.trainer | begin training epoch 987
2022-03-08 02:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:43:09 | INFO | train_inner | epoch 987:     36 / 49 loss=0.377, nll_loss=0.088, ppl=1.06, wps=24803.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48000, lr=0.000144338, gnorm=0.246, loss_scale=64, train_wall=223, gb_free=8.8, wall=135665
2022-03-08 02:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:43:45 | INFO | valid | epoch 987 | valid on 'valid' subset | loss 14.98 | nll_loss 14.886 | ppl 30274.4 | wps 46592.1 | wpb 510.9 | bsz 1 | num_updates 48013 | best_loss 8.238
2022-03-08 02:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 987 @ 48013 updates
2022-03-08 02:43:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:43:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:43:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 987 @ 48013 updates, score 14.98) (writing took 2.480842435732484 seconds)
2022-03-08 02:43:48 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)
2022-03-08 02:43:48 | INFO | train | epoch 987 | loss 0.377 | nll_loss 0.088 | ppl 1.06 | wps 24799.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48013 | lr 0.000144318 | gnorm 0.246 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135703
2022-03-08 02:43:48 | INFO | fairseq.trainer | begin training epoch 988
2022-03-08 02:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:44:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:45:54 | INFO | valid | epoch 988 | valid on 'valid' subset | loss 14.968 | nll_loss 14.874 | ppl 30029.9 | wps 46497.6 | wpb 510.9 | bsz 1 | num_updates 48061 | best_loss 8.238
2022-03-08 02:45:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 988 @ 48061 updates
2022-03-08 02:45:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:45:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:45:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 988 @ 48061 updates, score 14.968) (writing took 2.5174674317240715 seconds)
2022-03-08 02:45:56 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)
2022-03-08 02:45:56 | INFO | train | epoch 988 | loss 0.377 | nll_loss 0.088 | ppl 1.06 | wps 24250.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 48061 | lr 0.000144246 | gnorm 0.248 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135831
2022-03-08 02:45:56 | INFO | fairseq.trainer | begin training epoch 989
2022-03-08 02:45:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:47:34 | INFO | train_inner | epoch 989:     39 / 49 loss=0.378, nll_loss=0.088, ppl=1.06, wps=24569.5, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=48100, lr=0.000144187, gnorm=0.248, loss_scale=64, train_wall=225, gb_free=8.8, wall=135929
2022-03-08 02:47:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:48:02 | INFO | valid | epoch 989 | valid on 'valid' subset | loss 15.028 | nll_loss 14.934 | ppl 31311.5 | wps 46581.4 | wpb 510.9 | bsz 1 | num_updates 48110 | best_loss 8.238
2022-03-08 02:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 989 @ 48110 updates
2022-03-08 02:48:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 989 @ 48110 updates, score 15.028) (writing took 2.5174805875867605 seconds)
2022-03-08 02:48:04 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)
2022-03-08 02:48:04 | INFO | train | epoch 989 | loss 0.378 | nll_loss 0.088 | ppl 1.06 | wps 24771.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48110 | lr 0.000144172 | gnorm 0.247 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 135960
2022-03-08 02:48:04 | INFO | fairseq.trainer | begin training epoch 990
2022-03-08 02:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:49:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:50:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:50:10 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 14.942 | nll_loss 14.847 | ppl 29477.1 | wps 46626.4 | wpb 510.9 | bsz 1 | num_updates 48158 | best_loss 8.238
2022-03-08 02:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 48158 updates
2022-03-08 02:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:50:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:50:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 990 @ 48158 updates, score 14.942) (writing took 2.5416499450802803 seconds)
2022-03-08 02:50:13 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)
2022-03-08 02:50:13 | INFO | train | epoch 990 | loss 0.377 | nll_loss 0.087 | ppl 1.06 | wps 24286.4 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 48158 | lr 0.000144101 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 136088
2022-03-08 02:50:13 | INFO | fairseq.trainer | begin training epoch 991
2022-03-08 02:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:51:57 | INFO | train_inner | epoch 991:     42 / 49 loss=0.377, nll_loss=0.087, ppl=1.06, wps=24577.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48200, lr=0.000144038, gnorm=0.245, loss_scale=64, train_wall=225, gb_free=8.8, wall=136193
2022-03-08 02:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:52:18 | INFO | valid | epoch 991 | valid on 'valid' subset | loss 14.978 | nll_loss 14.884 | ppl 30238.6 | wps 46543.1 | wpb 510.9 | bsz 1 | num_updates 48207 | best_loss 8.238
2022-03-08 02:52:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 991 @ 48207 updates
2022-03-08 02:52:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:52:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 991 @ 48207 updates, score 14.978) (writing took 2.5096340533345938 seconds)
2022-03-08 02:52:21 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)
2022-03-08 02:52:21 | INFO | train | epoch 991 | loss 0.377 | nll_loss 0.087 | ppl 1.06 | wps 24781.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48207 | lr 0.000144027 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 136216
2022-03-08 02:52:21 | INFO | fairseq.trainer | begin training epoch 992
2022-03-08 02:52:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:54:26 | INFO | valid | epoch 992 | valid on 'valid' subset | loss 14.983 | nll_loss 14.889 | ppl 30338 | wps 47024 | wpb 510.9 | bsz 1 | num_updates 48256 | best_loss 8.238
2022-03-08 02:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 992 @ 48256 updates
2022-03-08 02:54:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 992 @ 48256 updates, score 14.983) (writing took 2.599973924458027 seconds)
2022-03-08 02:54:29 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)
2022-03-08 02:54:29 | INFO | train | epoch 992 | loss 0.377 | nll_loss 0.087 | ppl 1.06 | wps 24828.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48256 | lr 0.000143954 | gnorm 0.246 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 136344
2022-03-08 02:54:29 | INFO | fairseq.trainer | begin training epoch 993
2022-03-08 02:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:55:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 02:56:20 | INFO | train_inner | epoch 993:     45 / 49 loss=0.377, nll_loss=0.087, ppl=1.06, wps=24681.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=48300, lr=0.000143889, gnorm=0.246, loss_scale=64, train_wall=224, gb_free=8.8, wall=136455
2022-03-08 02:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:56:34 | INFO | valid | epoch 993 | valid on 'valid' subset | loss 14.999 | nll_loss 14.905 | ppl 30685.6 | wps 46969.3 | wpb 510.9 | bsz 1 | num_updates 48304 | best_loss 8.238
2022-03-08 02:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 993 @ 48304 updates
2022-03-08 02:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:56:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 993 @ 48304 updates, score 14.999) (writing took 2.505022333934903 seconds)
2022-03-08 02:56:36 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)
2022-03-08 02:56:36 | INFO | train | epoch 993 | loss 0.377 | nll_loss 0.087 | ppl 1.06 | wps 24450.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48304 | lr 0.000143883 | gnorm 0.246 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 136471
2022-03-08 02:56:36 | INFO | fairseq.trainer | begin training epoch 994
2022-03-08 02:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:58:41 | INFO | valid | epoch 994 | valid on 'valid' subset | loss 15.048 | nll_loss 14.955 | ppl 31750.8 | wps 47116.5 | wpb 510.9 | bsz 1 | num_updates 48353 | best_loss 8.238
2022-03-08 02:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 994 @ 48353 updates
2022-03-08 02:58:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:58:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 02:58:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 994 @ 48353 updates, score 15.048) (writing took 2.4849328864365816 seconds)
2022-03-08 02:58:44 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)
2022-03-08 02:58:44 | INFO | train | epoch 994 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24959.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48353 | lr 0.00014381 | gnorm 0.245 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 136599
2022-03-08 02:58:44 | INFO | fairseq.trainer | begin training epoch 995
2022-03-08 02:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:00:40 | INFO | train_inner | epoch 995:     47 / 49 loss=0.377, nll_loss=0.087, ppl=1.06, wps=24970.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48400, lr=0.00014374, gnorm=0.246, loss_scale=64, train_wall=222, gb_free=8.8, wall=136715
2022-03-08 03:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:00:48 | INFO | valid | epoch 995 | valid on 'valid' subset | loss 14.986 | nll_loss 14.892 | ppl 30402.6 | wps 46922 | wpb 510.9 | bsz 1 | num_updates 48402 | best_loss 8.238
2022-03-08 03:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 995 @ 48402 updates
2022-03-08 03:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:00:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:00:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 995 @ 48402 updates, score 14.986) (writing took 2.5420080348849297 seconds)
2022-03-08 03:00:51 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)
2022-03-08 03:00:51 | INFO | train | epoch 995 | loss 0.377 | nll_loss 0.087 | ppl 1.06 | wps 24920.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48402 | lr 0.000143737 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 136726
2022-03-08 03:00:51 | INFO | fairseq.trainer | begin training epoch 996
2022-03-08 03:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:01:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:02:56 | INFO | valid | epoch 996 | valid on 'valid' subset | loss 14.932 | nll_loss 14.838 | ppl 29280.9 | wps 47068.3 | wpb 510.9 | bsz 1 | num_updates 48450 | best_loss 8.238
2022-03-08 03:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 996 @ 48450 updates
2022-03-08 03:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 996 @ 48450 updates, score 14.932) (writing took 2.519652558490634 seconds)
2022-03-08 03:02:58 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)
2022-03-08 03:02:58 | INFO | train | epoch 996 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24440.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48450 | lr 0.000143666 | gnorm 0.247 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 136854
2022-03-08 03:02:58 | INFO | fairseq.trainer | begin training epoch 997
2022-03-08 03:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:05:03 | INFO | valid | epoch 997 | valid on 'valid' subset | loss 15.003 | nll_loss 14.909 | ppl 30769.2 | wps 47343.5 | wpb 510.9 | bsz 1 | num_updates 48499 | best_loss 8.238
2022-03-08 03:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 997 @ 48499 updates
2022-03-08 03:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 997 @ 48499 updates, score 15.003) (writing took 2.5152852926403284 seconds)
2022-03-08 03:05:06 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)
2022-03-08 03:05:06 | INFO | train | epoch 997 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24927 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48499 | lr 0.000143593 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 136981
2022-03-08 03:05:06 | INFO | fairseq.trainer | begin training epoch 998
2022-03-08 03:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:05:08 | INFO | train_inner | epoch 998:      1 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24047.8, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=48500, lr=0.000143592, gnorm=0.246, loss_scale=64, train_wall=223, gb_free=8.8, wall=136984
2022-03-08 03:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:07:11 | INFO | valid | epoch 998 | valid on 'valid' subset | loss 14.923 | nll_loss 14.828 | ppl 29091.9 | wps 47142.1 | wpb 510.9 | bsz 1 | num_updates 48548 | best_loss 8.238
2022-03-08 03:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 998 @ 48548 updates
2022-03-08 03:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 998 @ 48548 updates, score 14.923) (writing took 2.5221447963267565 seconds)
2022-03-08 03:07:13 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)
2022-03-08 03:07:13 | INFO | train | epoch 998 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24947.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48548 | lr 0.000143521 | gnorm 0.245 | loss_scale 128 | train_wall 108 | gb_free 8.8 | wall 137108
2022-03-08 03:07:13 | INFO | fairseq.trainer | begin training epoch 999
2022-03-08 03:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:07:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:09:18 | INFO | valid | epoch 999 | valid on 'valid' subset | loss 14.938 | nll_loss 14.844 | ppl 29404 | wps 47188.8 | wpb 510.9 | bsz 1 | num_updates 48596 | best_loss 8.238
2022-03-08 03:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 999 @ 48596 updates
2022-03-08 03:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:09:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:09:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 999 @ 48596 updates, score 14.938) (writing took 2.527094017714262 seconds)
2022-03-08 03:09:21 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)
2022-03-08 03:09:21 | INFO | train | epoch 999 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24433.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48596 | lr 0.00014345 | gnorm 0.245 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137236
2022-03-08 03:09:21 | INFO | fairseq.trainer | begin training epoch 1000
2022-03-08 03:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:09:31 | INFO | train_inner | epoch 1000:      4 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24740.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48600, lr=0.000143444, gnorm=0.245, loss_scale=64, train_wall=224, gb_free=8.8, wall=137246
2022-03-08 03:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:11:26 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 14.97 | nll_loss 14.876 | ppl 30067.8 | wps 47093.5 | wpb 510.9 | bsz 1 | num_updates 48645 | best_loss 8.238
2022-03-08 03:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 48645 updates
2022-03-08 03:11:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:11:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:11:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1000 @ 48645 updates, score 14.97) (writing took 2.521030977368355 seconds)
2022-03-08 03:11:28 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)
2022-03-08 03:11:28 | INFO | train | epoch 1000 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24909.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48645 | lr 0.000143377 | gnorm 0.246 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 137363
2022-03-08 03:11:28 | INFO | fairseq.trainer | begin training epoch 1001
2022-03-08 03:11:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:12:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:13:33 | INFO | valid | epoch 1001 | valid on 'valid' subset | loss 14.853 | nll_loss 14.759 | ppl 27718.6 | wps 46946.7 | wpb 510.9 | bsz 1 | num_updates 48693 | best_loss 8.238
2022-03-08 03:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1001 @ 48693 updates
2022-03-08 03:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1001 @ 48693 updates, score 14.853) (writing took 2.5669596791267395 seconds)
2022-03-08 03:13:36 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)
2022-03-08 03:13:36 | INFO | train | epoch 1001 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24398.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48693 | lr 0.000143307 | gnorm 0.244 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 137491
2022-03-08 03:13:36 | INFO | fairseq.trainer | begin training epoch 1002
2022-03-08 03:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:13:53 | INFO | train_inner | epoch 1002:      7 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24703.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48700, lr=0.000143296, gnorm=0.245, loss_scale=64, train_wall=224, gb_free=8.8, wall=137508
2022-03-08 03:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:15:41 | INFO | valid | epoch 1002 | valid on 'valid' subset | loss 14.924 | nll_loss 14.83 | ppl 29128.1 | wps 47207 | wpb 510.9 | bsz 1 | num_updates 48742 | best_loss 8.238
2022-03-08 03:15:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1002 @ 48742 updates
2022-03-08 03:15:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:15:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:15:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1002 @ 48742 updates, score 14.924) (writing took 2.5374133680015802 seconds)
2022-03-08 03:15:43 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)
2022-03-08 03:15:43 | INFO | train | epoch 1002 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24941.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48742 | lr 0.000143235 | gnorm 0.246 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 137618
2022-03-08 03:15:43 | INFO | fairseq.trainer | begin training epoch 1003
2022-03-08 03:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:17:48 | INFO | valid | epoch 1003 | valid on 'valid' subset | loss 14.972 | nll_loss 14.878 | ppl 30113.6 | wps 46929.1 | wpb 510.9 | bsz 1 | num_updates 48791 | best_loss 8.238
2022-03-08 03:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1003 @ 48791 updates
2022-03-08 03:17:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:17:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:17:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1003 @ 48791 updates, score 14.972) (writing took 2.5317121408879757 seconds)
2022-03-08 03:17:51 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)
2022-03-08 03:17:51 | INFO | train | epoch 1003 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24943.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48791 | lr 0.000143163 | gnorm 0.246 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137746
2022-03-08 03:17:51 | INFO | fairseq.trainer | begin training epoch 1004
2022-03-08 03:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:18:13 | INFO | train_inner | epoch 1004:      9 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24978.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=48800, lr=0.00014315, gnorm=0.247, loss_scale=64, train_wall=221, gb_free=8.8, wall=137768
2022-03-08 03:18:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:19:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:19:55 | INFO | valid | epoch 1004 | valid on 'valid' subset | loss 14.981 | nll_loss 14.887 | ppl 30291.8 | wps 47417.7 | wpb 510.9 | bsz 1 | num_updates 48839 | best_loss 8.238
2022-03-08 03:19:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1004 @ 48839 updates
2022-03-08 03:19:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1004 @ 48839 updates, score 14.981) (writing took 2.5450965873897076 seconds)
2022-03-08 03:19:58 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)
2022-03-08 03:19:58 | INFO | train | epoch 1004 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24457.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48839 | lr 0.000143092 | gnorm 0.246 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 137873
2022-03-08 03:19:58 | INFO | fairseq.trainer | begin training epoch 1005
2022-03-08 03:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:21:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:22:03 | INFO | valid | epoch 1005 | valid on 'valid' subset | loss 14.999 | nll_loss 14.906 | ppl 30695.7 | wps 47117.4 | wpb 510.9 | bsz 1 | num_updates 48888 | best_loss 8.238
2022-03-08 03:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1005 @ 48888 updates
2022-03-08 03:22:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:22:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1005 @ 48888 updates, score 14.999) (writing took 2.517258796840906 seconds)
2022-03-08 03:22:05 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)
2022-03-08 03:22:05 | INFO | train | epoch 1005 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24923 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48888 | lr 0.000143021 | gnorm 0.244 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 138001
2022-03-08 03:22:05 | INFO | fairseq.trainer | begin training epoch 1006
2022-03-08 03:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:22:35 | INFO | train_inner | epoch 1006:     12 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24741.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48900, lr=0.000143003, gnorm=0.245, loss_scale=64, train_wall=224, gb_free=8.8, wall=138030
2022-03-08 03:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:24:10 | INFO | valid | epoch 1006 | valid on 'valid' subset | loss 14.969 | nll_loss 14.875 | ppl 30056.9 | wps 47527.5 | wpb 510.9 | bsz 1 | num_updates 48937 | best_loss 8.238
2022-03-08 03:24:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1006 @ 48937 updates
2022-03-08 03:24:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1006 @ 48937 updates, score 14.969) (writing took 2.530713304877281 seconds)
2022-03-08 03:24:13 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)
2022-03-08 03:24:13 | INFO | train | epoch 1006 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24955.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48937 | lr 0.000142949 | gnorm 0.246 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 138128
2022-03-08 03:24:13 | INFO | fairseq.trainer | begin training epoch 1007
2022-03-08 03:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:24:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:26:18 | INFO | valid | epoch 1007 | valid on 'valid' subset | loss 15.011 | nll_loss 14.916 | ppl 30915.4 | wps 47125.1 | wpb 510.9 | bsz 1 | num_updates 48985 | best_loss 8.238
2022-03-08 03:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1007 @ 48985 updates
2022-03-08 03:26:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:26:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:26:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1007 @ 48985 updates, score 15.011) (writing took 2.536506263539195 seconds)
2022-03-08 03:26:20 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)
2022-03-08 03:26:20 | INFO | train | epoch 1007 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24436.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48985 | lr 0.000142879 | gnorm 0.245 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 138255
2022-03-08 03:26:20 | INFO | fairseq.trainer | begin training epoch 1008
2022-03-08 03:26:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:26:57 | INFO | train_inner | epoch 1008:     15 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24729.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49000, lr=0.000142857, gnorm=0.246, loss_scale=64, train_wall=224, gb_free=8.8, wall=138293
2022-03-08 03:28:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:28:25 | INFO | valid | epoch 1008 | valid on 'valid' subset | loss 15.026 | nll_loss 14.932 | ppl 31269.7 | wps 47188.1 | wpb 510.9 | bsz 1 | num_updates 49034 | best_loss 8.238
2022-03-08 03:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1008 @ 49034 updates
2022-03-08 03:28:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1008 @ 49034 updates, score 15.026) (writing took 2.5160911101847887 seconds)
2022-03-08 03:28:28 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)
2022-03-08 03:28:28 | INFO | train | epoch 1008 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24919.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49034 | lr 0.000142808 | gnorm 0.247 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 138383
2022-03-08 03:28:28 | INFO | fairseq.trainer | begin training epoch 1009
2022-03-08 03:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:30:33 | INFO | valid | epoch 1009 | valid on 'valid' subset | loss 14.954 | nll_loss 14.86 | ppl 29740.4 | wps 47071.3 | wpb 510.9 | bsz 1 | num_updates 49083 | best_loss 8.238
2022-03-08 03:30:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1009 @ 49083 updates
2022-03-08 03:30:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:30:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1009 @ 49083 updates, score 14.954) (writing took 2.524758877232671 seconds)
2022-03-08 03:30:35 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)
2022-03-08 03:30:35 | INFO | train | epoch 1009 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24911.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49083 | lr 0.000142736 | gnorm 0.245 | loss_scale 128 | train_wall 109 | gb_free 8.8 | wall 138510
2022-03-08 03:30:35 | INFO | fairseq.trainer | begin training epoch 1010
2022-03-08 03:30:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:30:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:31:20 | INFO | train_inner | epoch 1010:     18 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24730.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49100, lr=0.000142712, gnorm=0.245, loss_scale=64, train_wall=224, gb_free=8.8, wall=138555
2022-03-08 03:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:32:40 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 14.915 | nll_loss 14.821 | ppl 28942.7 | wps 47078.3 | wpb 510.9 | bsz 1 | num_updates 49131 | best_loss 8.238
2022-03-08 03:32:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 49131 updates
2022-03-08 03:32:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:32:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1010 @ 49131 updates, score 14.915) (writing took 2.530768170952797 seconds)
2022-03-08 03:32:43 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)
2022-03-08 03:32:43 | INFO | train | epoch 1010 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24428.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49131 | lr 0.000142667 | gnorm 0.246 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 138638
2022-03-08 03:32:43 | INFO | fairseq.trainer | begin training epoch 1011
2022-03-08 03:32:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:34:48 | INFO | valid | epoch 1011 | valid on 'valid' subset | loss 14.978 | nll_loss 14.884 | ppl 30227.3 | wps 47096.1 | wpb 510.9 | bsz 1 | num_updates 49180 | best_loss 8.238
2022-03-08 03:34:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1011 @ 49180 updates
2022-03-08 03:34:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:34:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:34:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1011 @ 49180 updates, score 14.978) (writing took 2.503385130316019 seconds)
2022-03-08 03:34:50 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)
2022-03-08 03:34:50 | INFO | train | epoch 1011 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24932.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49180 | lr 0.000142595 | gnorm 0.246 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 138765
2022-03-08 03:34:50 | INFO | fairseq.trainer | begin training epoch 1012
2022-03-08 03:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:35:40 | INFO | train_inner | epoch 1012:     20 / 49 loss=0.376, nll_loss=0.087, ppl=1.06, wps=24973.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49200, lr=0.000142566, gnorm=0.246, loss_scale=64, train_wall=221, gb_free=8.8, wall=138815
2022-03-08 03:36:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:36:55 | INFO | valid | epoch 1012 | valid on 'valid' subset | loss 15.023 | nll_loss 14.93 | ppl 31209.6 | wps 47083.5 | wpb 510.9 | bsz 1 | num_updates 49228 | best_loss 8.238
2022-03-08 03:36:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1012 @ 49228 updates
2022-03-08 03:36:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:36:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:36:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1012 @ 49228 updates, score 15.023) (writing took 2.5409713461995125 seconds)
2022-03-08 03:36:57 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)
2022-03-08 03:36:57 | INFO | train | epoch 1012 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24497.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49228 | lr 0.000142526 | gnorm 0.243 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 138892
2022-03-08 03:36:57 | INFO | fairseq.trainer | begin training epoch 1013
2022-03-08 03:36:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:39:02 | INFO | valid | epoch 1013 | valid on 'valid' subset | loss 15.026 | nll_loss 14.933 | ppl 31272.1 | wps 47571.1 | wpb 510.9 | bsz 1 | num_updates 49277 | best_loss 8.238
2022-03-08 03:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1013 @ 49277 updates
2022-03-08 03:39:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:39:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1013 @ 49277 updates, score 15.026) (writing took 2.5102351494133472 seconds)
2022-03-08 03:39:05 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)
2022-03-08 03:39:05 | INFO | train | epoch 1013 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24929 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49277 | lr 0.000142455 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 139020
2022-03-08 03:39:05 | INFO | fairseq.trainer | begin training epoch 1014
2022-03-08 03:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:40:02 | INFO | train_inner | epoch 1014:     23 / 49 loss=0.375, nll_loss=0.086, ppl=1.06, wps=24741.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49300, lr=0.000142422, gnorm=0.244, loss_scale=64, train_wall=224, gb_free=8.8, wall=139077
2022-03-08 03:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:41:10 | INFO | valid | epoch 1014 | valid on 'valid' subset | loss 14.986 | nll_loss 14.892 | ppl 30401.7 | wps 47222.3 | wpb 510.9 | bsz 1 | num_updates 49326 | best_loss 8.238
2022-03-08 03:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1014 @ 49326 updates
2022-03-08 03:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1014 @ 49326 updates, score 14.986) (writing took 2.5230857636779547 seconds)
2022-03-08 03:41:12 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)
2022-03-08 03:41:12 | INFO | train | epoch 1014 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24926.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49326 | lr 0.000142384 | gnorm 0.244 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 139147
2022-03-08 03:41:12 | INFO | fairseq.trainer | begin training epoch 1015
2022-03-08 03:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:43:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:43:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:43:17 | INFO | valid | epoch 1015 | valid on 'valid' subset | loss 14.914 | nll_loss 14.819 | ppl 28909.3 | wps 47559.8 | wpb 510.9 | bsz 1 | num_updates 49374 | best_loss 8.238
2022-03-08 03:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1015 @ 49374 updates
2022-03-08 03:43:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1015 @ 49374 updates, score 14.914) (writing took 2.5188982617110014 seconds)
2022-03-08 03:43:20 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)
2022-03-08 03:43:20 | INFO | train | epoch 1015 | loss 0.375 | nll_loss 0.087 | ppl 1.06 | wps 24430.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49374 | lr 0.000142315 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 139275
2022-03-08 03:43:20 | INFO | fairseq.trainer | begin training epoch 1016
2022-03-08 03:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:44:24 | INFO | train_inner | epoch 1016:     26 / 49 loss=0.375, nll_loss=0.086, ppl=1.06, wps=24739.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49400, lr=0.000142278, gnorm=0.244, loss_scale=64, train_wall=224, gb_free=8.8, wall=139339
2022-03-08 03:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:45:24 | INFO | valid | epoch 1016 | valid on 'valid' subset | loss 14.979 | nll_loss 14.885 | ppl 30256.5 | wps 47124.6 | wpb 510.9 | bsz 1 | num_updates 49423 | best_loss 8.238
2022-03-08 03:45:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1016 @ 49423 updates
2022-03-08 03:45:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1016 @ 49423 updates, score 14.979) (writing took 2.514864267781377 seconds)
2022-03-08 03:45:27 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)
2022-03-08 03:45:27 | INFO | train | epoch 1016 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24945.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49423 | lr 0.000142244 | gnorm 0.244 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 139402
2022-03-08 03:45:27 | INFO | fairseq.trainer | begin training epoch 1017
2022-03-08 03:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:47:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:47:32 | INFO | valid | epoch 1017 | valid on 'valid' subset | loss 15.001 | nll_loss 14.907 | ppl 30724.6 | wps 46977 | wpb 510.9 | bsz 1 | num_updates 49472 | best_loss 8.238
2022-03-08 03:47:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1017 @ 49472 updates
2022-03-08 03:47:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:47:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:47:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1017 @ 49472 updates, score 15.001) (writing took 2.5319369826465845 seconds)
2022-03-08 03:47:34 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)
2022-03-08 03:47:34 | INFO | train | epoch 1017 | loss 0.376 | nll_loss 0.087 | ppl 1.06 | wps 24926.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49472 | lr 0.000142174 | gnorm 0.246 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 139530
2022-03-08 03:47:34 | INFO | fairseq.trainer | begin training epoch 1018
2022-03-08 03:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:48:44 | INFO | train_inner | epoch 1018:     28 / 49 loss=0.375, nll_loss=0.086, ppl=1.06, wps=24945, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49500, lr=0.000142134, gnorm=0.246, loss_scale=128, train_wall=222, gb_free=8.8, wall=139599
2022-03-08 03:48:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:49:40 | INFO | valid | epoch 1018 | valid on 'valid' subset | loss 15.002 | nll_loss 14.909 | ppl 30758.9 | wps 46972.2 | wpb 510.9 | bsz 1 | num_updates 49520 | best_loss 8.238
2022-03-08 03:49:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1018 @ 49520 updates
2022-03-08 03:49:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:49:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1018 @ 49520 updates, score 15.002) (writing took 2.5260583870112896 seconds)
2022-03-08 03:49:42 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)
2022-03-08 03:49:42 | INFO | train | epoch 1018 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24383.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49520 | lr 0.000142105 | gnorm 0.244 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 139657
2022-03-08 03:49:42 | INFO | fairseq.trainer | begin training epoch 1019
2022-03-08 03:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:51:47 | INFO | valid | epoch 1019 | valid on 'valid' subset | loss 14.942 | nll_loss 14.848 | ppl 29489 | wps 47047.3 | wpb 510.9 | bsz 1 | num_updates 49569 | best_loss 8.238
2022-03-08 03:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1019 @ 49569 updates
2022-03-08 03:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:51:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:51:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1019 @ 49569 updates, score 14.942) (writing took 2.5106546860188246 seconds)
2022-03-08 03:51:50 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)
2022-03-08 03:51:50 | INFO | train | epoch 1019 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24921.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49569 | lr 0.000142035 | gnorm 0.242 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 139785
2022-03-08 03:51:50 | INFO | fairseq.trainer | begin training epoch 1020
2022-03-08 03:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:53:07 | INFO | train_inner | epoch 1020:     31 / 49 loss=0.375, nll_loss=0.086, ppl=1.06, wps=24717.1, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49600, lr=0.00014199, gnorm=0.242, loss_scale=64, train_wall=224, gb_free=8.8, wall=139862
2022-03-08 03:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:53:55 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 15.007 | nll_loss 14.914 | ppl 30870.7 | wps 46506.2 | wpb 510.9 | bsz 1 | num_updates 49618 | best_loss 8.238
2022-03-08 03:53:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 49618 updates
2022-03-08 03:53:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:53:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:53:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1020 @ 49618 updates, score 15.007) (writing took 2.5473522637039423 seconds)
2022-03-08 03:53:57 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)
2022-03-08 03:53:57 | INFO | train | epoch 1020 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24912 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49618 | lr 0.000141965 | gnorm 0.242 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 139912
2022-03-08 03:53:57 | INFO | fairseq.trainer | begin training epoch 1021
2022-03-08 03:53:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:54:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 03:55:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:56:02 | INFO | valid | epoch 1021 | valid on 'valid' subset | loss 14.998 | nll_loss 14.905 | ppl 30670.3 | wps 47151.7 | wpb 510.9 | bsz 1 | num_updates 49666 | best_loss 8.238
2022-03-08 03:56:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1021 @ 49666 updates
2022-03-08 03:56:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:56:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1021 @ 49666 updates, score 14.998) (writing took 2.499823495745659 seconds)
2022-03-08 03:56:05 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)
2022-03-08 03:56:05 | INFO | train | epoch 1021 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24437.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49666 | lr 0.000141896 | gnorm 0.248 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 140040
2022-03-08 03:56:05 | INFO | fairseq.trainer | begin training epoch 1022
2022-03-08 03:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:57:29 | INFO | train_inner | epoch 1022:     34 / 49 loss=0.375, nll_loss=0.086, ppl=1.06, wps=24714.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49700, lr=0.000141848, gnorm=0.246, loss_scale=64, train_wall=224, gb_free=8.8, wall=140124
2022-03-08 03:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:58:10 | INFO | valid | epoch 1022 | valid on 'valid' subset | loss 14.93 | nll_loss 14.836 | ppl 29245 | wps 46991.5 | wpb 510.9 | bsz 1 | num_updates 49715 | best_loss 8.238
2022-03-08 03:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1022 @ 49715 updates
2022-03-08 03:58:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:58:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 03:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1022 @ 49715 updates, score 14.93) (writing took 2.537777289748192 seconds)
2022-03-08 03:58:12 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)
2022-03-08 03:58:12 | INFO | train | epoch 1022 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24908.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49715 | lr 0.000141826 | gnorm 0.245 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 140167
2022-03-08 03:58:12 | INFO | fairseq.trainer | begin training epoch 1023
2022-03-08 03:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:00:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 04:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:00:17 | INFO | valid | epoch 1023 | valid on 'valid' subset | loss 15.013 | nll_loss 14.92 | ppl 31008.3 | wps 46879.4 | wpb 510.9 | bsz 1 | num_updates 49763 | best_loss 8.238
2022-03-08 04:00:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1023 @ 49763 updates
2022-03-08 04:00:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:00:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1023 @ 49763 updates, score 15.013) (writing took 2.506342662498355 seconds)
2022-03-08 04:00:20 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)
2022-03-08 04:00:20 | INFO | train | epoch 1023 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24401.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49763 | lr 0.000141758 | gnorm 0.241 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 140295
2022-03-08 04:00:20 | INFO | fairseq.trainer | begin training epoch 1024
2022-03-08 04:00:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:01:52 | INFO | train_inner | epoch 1024:     37 / 49 loss=0.375, nll_loss=0.086, ppl=1.06, wps=24690.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49800, lr=0.000141705, gnorm=0.242, loss_scale=64, train_wall=224, gb_free=8.8, wall=140387
2022-03-08 04:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:02:25 | INFO | valid | epoch 1024 | valid on 'valid' subset | loss 14.98 | nll_loss 14.885 | ppl 30259.3 | wps 47115.8 | wpb 510.9 | bsz 1 | num_updates 49812 | best_loss 8.238
2022-03-08 04:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1024 @ 49812 updates
2022-03-08 04:02:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:02:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:02:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1024 @ 49812 updates, score 14.98) (writing took 2.49710102006793 seconds)
2022-03-08 04:02:27 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)
2022-03-08 04:02:27 | INFO | train | epoch 1024 | loss 0.374 | nll_loss 0.086 | ppl 1.06 | wps 24888.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49812 | lr 0.000141688 | gnorm 0.242 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 140423
2022-03-08 04:02:27 | INFO | fairseq.trainer | begin training epoch 1025
2022-03-08 04:02:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:04:32 | INFO | valid | epoch 1025 | valid on 'valid' subset | loss 14.949 | nll_loss 14.855 | ppl 29635.7 | wps 46982.2 | wpb 510.9 | bsz 1 | num_updates 49861 | best_loss 8.238
2022-03-08 04:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1025 @ 49861 updates
2022-03-08 04:04:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1025 @ 49861 updates, score 14.949) (writing took 2.5615705009549856 seconds)
2022-03-08 04:04:35 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)
2022-03-08 04:04:35 | INFO | train | epoch 1025 | loss 0.375 | nll_loss 0.086 | ppl 1.06 | wps 24900.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49861 | lr 0.000141618 | gnorm 0.244 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 140550
2022-03-08 04:04:35 | INFO | fairseq.trainer | begin training epoch 1026
2022-03-08 04:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:06:12 | INFO | train_inner | epoch 1026:     39 / 49 loss=0.375, nll_loss=0.086, ppl=1.06, wps=24950.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49900, lr=0.000141563, gnorm=0.243, loss_scale=128, train_wall=222, gb_free=8.8, wall=140647
2022-03-08 04:06:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 04:06:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:06:40 | INFO | valid | epoch 1026 | valid on 'valid' subset | loss 15.017 | nll_loss 14.924 | ppl 31079.8 | wps 47059 | wpb 510.9 | bsz 1 | num_updates 49909 | best_loss 8.238
2022-03-08 04:06:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1026 @ 49909 updates
2022-03-08 04:06:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:06:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1026 @ 49909 updates, score 15.017) (writing took 2.5043064281344414 seconds)
2022-03-08 04:06:42 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)
2022-03-08 04:06:42 | INFO | train | epoch 1026 | loss 0.374 | nll_loss 0.086 | ppl 1.06 | wps 24424.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49909 | lr 0.00014155 | gnorm 0.243 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 140678
2022-03-08 04:06:42 | INFO | fairseq.trainer | begin training epoch 1027
2022-03-08 04:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:08:47 | INFO | valid | epoch 1027 | valid on 'valid' subset | loss 14.971 | nll_loss 14.877 | ppl 30096.1 | wps 46940.5 | wpb 510.9 | bsz 1 | num_updates 49958 | best_loss 8.238
2022-03-08 04:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1027 @ 49958 updates
2022-03-08 04:08:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:08:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:08:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1027 @ 49958 updates, score 14.971) (writing took 2.5119188837707043 seconds)
2022-03-08 04:08:50 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)
2022-03-08 04:08:50 | INFO | train | epoch 1027 | loss 0.374 | nll_loss 0.085 | ppl 1.06 | wps 24937.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49958 | lr 0.000141481 | gnorm 0.24 | loss_scale 64 | train_wall 109 | gb_free 8.8 | wall 140805
2022-03-08 04:08:50 | INFO | fairseq.trainer | begin training epoch 1028
2022-03-08 04:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:10:34 | INFO | train_inner | epoch 1028:     42 / 49 loss=0.374, nll_loss=0.086, ppl=1.06, wps=24729.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=50000, lr=0.000141421, gnorm=0.241, loss_scale=64, train_wall=224, gb_free=8.8, wall=140909
2022-03-08 04:10:34 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 04:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:10:39 | INFO | valid | epoch 1028 | valid on 'valid' subset | loss 14.982 | nll_loss 14.889 | ppl 30334.4 | wps 46978.5 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 8.238
2022-03-08 04:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1028 @ 50000 updates
2022-03-08 04:10:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt
2022-03-08 04:10:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#2/checkpoint_last.pt (epoch 1028 @ 50000 updates, score 14.982) (writing took 2.5434372052550316 seconds)
2022-03-08 04:10:41 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)
2022-03-08 04:10:41 | INFO | train | epoch 1028 | loss 0.374 | nll_loss 0.086 | ppl 1.06 | wps 24700.4 | ups 0.38 | wpb 65525.5 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.241 | loss_scale 64 | train_wall 94 | gb_free 8.8 | wall 140916
2022-03-08 04:10:41 | INFO | fairseq_cli.train | done training in 140916.3 seconds
