Sender: LSF System <lsfadmin@eu-g2-01>
Subject: Job 202625102: <w2_jelinek_0.1_0.0_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#1> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:49:41 2022
Job was executed on host(s) <eu-g2-01>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:50:12 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:50:12 2022
Terminated at Tue Feb  1 04:50:19 2022
Results reported at Tue Feb  1 04:50:19 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72732.00 sec.
    Max Memory :                                 6189 MB
    Average Memory :                             3787.54 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13811.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72007 sec.
    Turnaround time :                            72038 sec.

The output (if any) follows:

2022-01-31 08:50:21 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:50:21 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:50:22 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1265/36718 [00:00<00:02, 12632.09it/s]  7%|▋         | 2529/36718 [00:00<00:02, 11834.56it/s] 11%|█         | 3929/36718 [00:00<00:02, 12786.80it/s] 15%|█▍        | 5348/36718 [00:00<00:02, 13317.43it/s] 18%|█▊        | 6685/36718 [00:00<00:02, 13007.84it/s] 22%|██▏       | 7990/36718 [00:00<00:02, 12813.44it/s] 25%|██▌       | 9274/36718 [00:00<00:02, 12800.67it/s] 29%|██▊       | 10556/36718 [00:00<00:02, 12723.97it/s] 32%|███▏      | 11830/36718 [00:00<00:01, 12555.30it/s] 36%|███▌      | 13179/36718 [00:01<00:01, 12837.29it/s] 39%|███▉      | 14489/36718 [00:01<00:01, 12903.28it/s] 43%|████▎     | 15803/36718 [00:01<00:01, 12973.20it/s] 47%|████▋     | 17102/36718 [00:01<00:01, 12773.72it/s] 50%|█████     | 18381/36718 [00:01<00:01, 12736.23it/s] 54%|█████▍    | 19752/36718 [00:01<00:01, 13022.63it/s] 57%|█████▋    | 21056/36718 [00:01<00:01, 12676.27it/s] 61%|██████    | 22326/36718 [00:01<00:01, 12634.63it/s] 65%|██████▍   | 23722/36718 [00:01<00:00, 13019.28it/s] 69%|██████▉   | 25246/36718 [00:01<00:00, 13674.34it/s] 72%|███████▏  | 26616/36718 [00:02<00:00, 13162.75it/s] 76%|███████▌  | 27938/36718 [00:02<00:00, 12713.32it/s] 80%|███████▉  | 29308/36718 [00:02<00:00, 12980.88it/s] 83%|████████▎ | 30612/36718 [00:02<00:00, 12807.05it/s] 87%|████████▋ | 31897/36718 [00:02<00:00, 12608.21it/s] 90%|█████████ | 33161/36718 [00:02<00:00, 12335.69it/s] 94%|█████████▍| 34488/36718 [00:02<00:00, 12603.64it/s] 97%|█████████▋| 35752/36718 [00:02<00:00, 12595.71it/s]100%|██████████| 36718/36718 [00:02<00:00, 12799.69it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2768/36718 [00:00<00:01, 27646.61it/s] 16%|█▋        | 5979/36718 [00:00<00:01, 30264.31it/s] 25%|██▍       | 9006/36718 [00:00<00:00, 28959.94it/s] 32%|███▏      | 11909/36718 [00:00<00:00, 28836.62it/s] 40%|████      | 14847/36718 [00:00<00:00, 29026.66it/s] 48%|████▊     | 17753/36718 [00:00<00:00, 28872.39it/s] 57%|█████▋    | 20765/36718 [00:00<00:00, 29273.50it/s] 65%|██████▍   | 23748/36718 [00:00<00:00, 29446.62it/s] 73%|███████▎  | 26765/36718 [00:00<00:00, 29664.47it/s] 81%|████████  | 29733/36718 [00:01<00:00, 29481.57it/s] 89%|████████▉ | 32683/36718 [00:01<00:00, 28871.42it/s] 97%|█████████▋| 35574/36718 [00:01<00:00, 28844.83it/s]100%|██████████| 36718/36718 [00:01<00:00, 29090.75it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 78.05it/s]2022-01-31 08:50:35 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:50:35 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:50:35 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:50:35 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:50:35 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:50:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:50:35 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:50:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:50:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:50:35 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:50:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:50:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:50:35 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:50:35 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint_last.pt
2022-01-31 08:50:35 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint_last.pt
2022-01-31 08:50:35 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:50:35 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:50:35 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:50:35 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:50:35 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:57:29 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.699 | ppl 26592.6 | wps 6613.6 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:57:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:57:29 | INFO | train | epoch 001 | loss 16.133 | ppl 71847.7 | wps 5060.8 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.237 | train_wall 379 | gb_free 6.1 | wall 414
KL Stats: Epoch 1 Divergences: Uniform: 0.517208394610612 Unigram: 3.6856011076604216
2022-01-31 08:57:29 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:57:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:01:04 | INFO | train_inner | epoch 002:     36 / 64 loss=15.593, ppl=49417.3, wps=5213.8, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.652, train_wall=593, gb_free=6.1, wall=628
2022-01-31 09:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:04:21 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.698 | ppl 13288.5 | wps 6628.4 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:04:21 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:04:21 | INFO | train | epoch 002 | loss 14.424 | ppl 21986.4 | wps 5069 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.494 | train_wall 378 | gb_free 6.1 | wall 826
KL Stats: Epoch 2 Divergences: Uniform: 0.5345499046738815 Unigram: 2.415997657361054
2022-01-31 09:04:21 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:11:13 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.877 | ppl 7520.44 | wps 6626.4 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:11:13 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:11:13 | INFO | train | epoch 003 | loss 13.522 | ppl 11762.5 | wps 5074.3 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.204 | train_wall 378 | gb_free 6.1 | wall 1237
KL Stats: Epoch 3 Divergences: Uniform: 0.5190752576416564 Unigram: 1.733469657351904
2022-01-31 09:11:13 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:11:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:12:00 | INFO | train_inner | epoch 004:      8 / 64 loss=13.655, ppl=12898.2, wps=4962.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.233, train_wall=590, gb_free=6.1, wall=1285
2022-01-31 09:17:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:18:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.032 | ppl 4186.81 | wps 6592.9 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:18:06 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:18:06 | INFO | train | epoch 004 | loss 12.574 | ppl 6099.57 | wps 5061.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.959 | train_wall 379 | gb_free 6.1 | wall 1650
KL Stats: Epoch 4 Divergences: Uniform: 0.6028876543785803 Unigram: 1.119898046115955
2022-01-31 09:18:06 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:22:28 | INFO | train_inner | epoch 005:     44 / 64 loss=12.226, ppl=4790.33, wps=5208.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.843, train_wall=593, gb_free=6.1, wall=1912
2022-01-31 09:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:24:58 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.513 | ppl 2922.68 | wps 6602.8 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:24:58 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:24:58 | INFO | train | epoch 005 | loss 11.78 | ppl 3516.08 | wps 5057.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.687 | train_wall 379 | gb_free 6.1 | wall 2063
KL Stats: Epoch 5 Divergences: Uniform: 0.8414502514768483 Unigram: 0.6666348311195255
2022-01-31 09:24:58 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:24:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:31:51 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.267 | ppl 2463.98 | wps 6623.8 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:31:51 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:31:51 | INFO | train | epoch 006 | loss 11.348 | ppl 2607.18 | wps 5059.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.584 | train_wall 379 | gb_free 6.1 | wall 2476
KL Stats: Epoch 6 Divergences: Uniform: 1.1381679960636897 Unigram: 0.466223778536306
2022-01-31 09:31:51 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:31:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:33:27 | INFO | train_inner | epoch 007:     16 / 64 loss=11.371, ppl=2648.07, wps=4948.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.582, train_wall=591, gb_free=6.1, wall=2571
2022-01-31 09:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:38:44 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.122 | ppl 2229.25 | wps 6616.3 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:38:44 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:38:44 | INFO | train | epoch 007 | loss 11.147 | ppl 2267.92 | wps 5064 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.524 | train_wall 379 | gb_free 6.1 | wall 2888
KL Stats: Epoch 7 Divergences: Uniform: 1.3621972641625302 Unigram: 0.4759570718658166
2022-01-31 09:38:44 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:43:53 | INFO | train_inner | epoch 008:     52 / 64 loss=11.086, ppl=2173.19, wps=5216.7, ups=0.16, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=592, gb_free=6.1, wall=3198
2022-01-31 09:45:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:45:36 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.017 | ppl 2072.77 | wps 6617.1 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:45:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:45:36 | INFO | train | epoch 008 | loss 11.034 | ppl 2096.41 | wps 5064.1 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 379 | gb_free 6.1 | wall 3301
KL Stats: Epoch 8 Divergences: Uniform: 1.477641246290245 Unigram: 0.55090545782554
2022-01-31 09:45:36 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:51:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:52:29 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.9 | ppl 1910.42 | wps 6610.8 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:52:29 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:52:29 | INFO | train | epoch 009 | loss 10.927 | ppl 1947.19 | wps 5054.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 379 | gb_free 6.1 | wall 3714
KL Stats: Epoch 9 Divergences: Uniform: 1.522980453171203 Unigram: 0.6545921842945029
2022-01-31 09:52:29 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:54:52 | INFO | train_inner | epoch 010:     24 / 64 loss=10.918, ppl=1934.73, wps=4946, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.488, train_wall=592, gb_free=6.1, wall=3857
2022-01-31 09:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:59:22 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.795 | ppl 1776.39 | wps 6613.2 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:59:22 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:59:22 | INFO | train | epoch 010 | loss 10.817 | ppl 1804.08 | wps 5063.4 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 379 | gb_free 6.1 | wall 4127
KL Stats: Epoch 10 Divergences: Uniform: 1.5479367586754715 Unigram: 0.768739755027727
2022-01-31 09:59:22 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:05:22 | INFO | train_inner | epoch 011:     60 / 64 loss=10.74, ppl=1710.71, wps=5192.4, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=595, gb_free=6.1, wall=4486
2022-01-31 10:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:06:17 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.686 | ppl 1647.97 | wps 6629.7 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 10:06:17 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 10:06:17 | INFO | train | epoch 011 | loss 10.7 | ppl 1663.77 | wps 5032.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.498 | train_wall 381 | gb_free 6.1 | wall 4542
KL Stats: Epoch 11 Divergences: Uniform: 1.5662919629482603 Unigram: 0.8823497823434991
2022-01-31 10:06:17 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 10:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:12:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:13:14 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.578 | ppl 1528.88 | wps 6450.8 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 10:13:14 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 10:13:14 | INFO | train | epoch 012 | loss 10.583 | ppl 1533.59 | wps 5008.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.479 | train_wall 382 | gb_free 6.1 | wall 4959
KL Stats: Epoch 12 Divergences: Uniform: 1.5772463506558076 Unigram: 0.9927787941083134
2022-01-31 10:13:14 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 10:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:16:25 | INFO | train_inner | epoch 013:     32 / 64 loss=10.559, ppl=1508.19, wps=4911.9, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.494, train_wall=595, gb_free=6.1, wall=5150
2022-01-31 10:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:20:08 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.488 | ppl 1435.97 | wps 6514.5 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:20:08 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:20:08 | INFO | train | epoch 013 | loss 10.468 | ppl 1416.33 | wps 5049.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.517 | train_wall 379 | gb_free 6.1 | wall 5372
KL Stats: Epoch 13 Divergences: Uniform: 1.6027387457321445 Unigram: 1.089840558810177
2022-01-31 10:20:08 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:20:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:27:01 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.393 | ppl 1344.23 | wps 6632 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:27:01 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:27:01 | INFO | train | epoch 014 | loss 10.357 | ppl 1311.24 | wps 5056.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.557 | train_wall 379 | gb_free 6.1 | wall 5785
KL Stats: Epoch 14 Divergences: Uniform: 1.6292497132864732 Unigram: 1.1795074918034127
2022-01-31 10:27:01 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:27:25 | INFO | train_inner | epoch 015:      4 / 64 loss=10.379, ppl=1332.01, wps=4944.6, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.537, train_wall=591, gb_free=6.1, wall=5809
2022-01-31 10:33:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:33:55 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.323 | ppl 1280.73 | wps 6620.5 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:33:55 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:33:55 | INFO | train | epoch 015 | loss 10.245 | ppl 1213.45 | wps 5034.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.537 | train_wall 381 | gb_free 6.1 | wall 6200
KL Stats: Epoch 15 Divergences: Uniform: 1.6525316768046014 Unigram: 1.2610839664592142
2022-01-31 10:33:55 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:33:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:37:55 | INFO | train_inner | epoch 016:     40 / 64 loss=10.204, ppl=1179.28, wps=5184.7, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.557, train_wall=596, gb_free=6.1, wall=6440
2022-01-31 10:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:40:51 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.243 | ppl 1211.72 | wps 6582.6 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:40:51 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:40:51 | INFO | train | epoch 016 | loss 10.138 | ppl 1127.16 | wps 5030.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.555 | train_wall 381 | gb_free 6.1 | wall 6615
KL Stats: Epoch 16 Divergences: Uniform: 1.6810889769489374 Unigram: 1.3394041445537825
2022-01-31 10:40:51 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:47:50 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.15 | ppl 1136.44 | wps 6563.9 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:47:50 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:47:50 | INFO | train | epoch 017 | loss 10.032 | ppl 1046.81 | wps 4982.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.548 | train_wall 385 | gb_free 6.1 | wall 7034
KL Stats: Epoch 17 Divergences: Uniform: 1.7144411620276798 Unigram: 1.40776968261585
2022-01-31 10:47:50 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:49:02 | INFO | train_inner | epoch 018:     12 / 64 loss=10.046, ppl=1057.12, wps=4888.8, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.55, train_wall=599, gb_free=6.1, wall=7106
2022-01-31 10:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:54:48 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.087 | ppl 1087.63 | wps 6495.6 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:54:48 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:54:48 | INFO | train | epoch 018 | loss 9.932 | ppl 976.59 | wps 4994.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.572 | train_wall 384 | gb_free 6.1 | wall 7453
KL Stats: Epoch 18 Divergences: Uniform: 1.7496488849904026 Unigram: 1.4746713423485551
2022-01-31 10:54:48 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:59:36 | INFO | train_inner | epoch 019:     48 / 64 loss=9.882, ppl=943.63, wps=5151.1, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.543, train_wall=599, gb_free=6.1, wall=7741
2022-01-31 11:01:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:01:44 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.013 | ppl 1033.27 | wps 6595.4 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 11:01:44 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 11:01:44 | INFO | train | epoch 019 | loss 9.828 | ppl 909.12 | wps 5024.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 382 | gb_free 6.1 | wall 7868
KL Stats: Epoch 19 Divergences: Uniform: 1.7792725108540752 Unigram: 1.5414256647434226
2022-01-31 11:01:44 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 11:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:08:39 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.928 | ppl 973.96 | wps 6464.1 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 11:08:39 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 11:08:39 | INFO | train | epoch 020 | loss 9.732 | ppl 850.39 | wps 5035.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.553 | train_wall 380 | gb_free 6.1 | wall 8283
KL Stats: Epoch 20 Divergences: Uniform: 1.810073113896505 Unigram: 1.6018857836352949
2022-01-31 11:08:39 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 11:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:10:39 | INFO | train_inner | epoch 021:     20 / 64 loss=9.727, ppl=847.46, wps=4916.5, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.547, train_wall=595, gb_free=6.1, wall=8404
2022-01-31 11:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:15:35 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.886 | ppl 945.96 | wps 6511.3 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 11:15:35 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 11:15:35 | INFO | train | epoch 021 | loss 9.638 | ppl 796.65 | wps 5014.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.528 | train_wall 382 | gb_free 6.1 | wall 8700
KL Stats: Epoch 21 Divergences: Uniform: 1.8398694904232575 Unigram: 1.6609174339600896
2022-01-31 11:15:35 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 11:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:21:14 | INFO | train_inner | epoch 022:     56 / 64 loss=9.585, ppl=768.17, wps=5149.4, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.536, train_wall=600, gb_free=6.1, wall=9039
2022-01-31 11:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:22:34 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.82 | ppl 903.64 | wps 6578.9 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 11:22:34 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 11:22:34 | INFO | train | epoch 022 | loss 9.549 | ppl 749.04 | wps 4991.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.547 | train_wall 384 | gb_free 6.1 | wall 9118
KL Stats: Epoch 22 Divergences: Uniform: 1.8648498854105915 Unigram: 1.7173722735310575
2022-01-31 11:22:34 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 11:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:29:27 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.761 | ppl 867.89 | wps 6586.9 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:29:27 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:29:27 | INFO | train | epoch 023 | loss 9.462 | ppl 705.38 | wps 5045.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.517 | train_wall 380 | gb_free 6.1 | wall 9532
KL Stats: Epoch 23 Divergences: Uniform: 1.8927516774288877 Unigram: 1.7692917245152893
2022-01-31 11:29:27 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:29:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:32:15 | INFO | train_inner | epoch 024:     28 / 64 loss=9.447, ppl=698.06, wps=4930.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.529, train_wall=593, gb_free=6.1, wall=9700
2022-01-31 11:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:36:22 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.702 | ppl 832.69 | wps 6577.6 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:36:22 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:36:22 | INFO | train | epoch 024 | loss 9.379 | ppl 665.78 | wps 5036.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.551 | train_wall 381 | gb_free 6.1 | wall 9947
KL Stats: Epoch 24 Divergences: Uniform: 1.9145869638355795 Unigram: 1.815088546175561
2022-01-31 11:36:22 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:36:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:42:45 | INFO | train_inner | epoch 025:     64 / 64 loss=9.325, ppl=641.36, wps=5176.7, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.531, train_wall=595, gb_free=6.1, wall=10329
2022-01-31 11:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:43:18 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.67 | ppl 814.62 | wps 6520.3 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:43:18 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:43:18 | INFO | train | epoch 025 | loss 9.297 | ppl 629.17 | wps 5019.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.52 | train_wall 382 | gb_free 6.1 | wall 10363
KL Stats: Epoch 25 Divergences: Uniform: 1.9436216731098985 Unigram: 1.8632243217175344
2022-01-31 11:43:18 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:43:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:50:16 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.619 | ppl 786.47 | wps 6550.6 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:50:16 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:50:16 | INFO | train | epoch 026 | loss 9.217 | ppl 595.05 | wps 5006.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.546 | train_wall 383 | gb_free 6.1 | wall 10780
KL Stats: Epoch 26 Divergences: Uniform: 1.9564830183824116 Unigram: 1.9069174388965078
2022-01-31 11:50:16 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:50:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:53:52 | INFO | train_inner | epoch 027:     36 / 64 loss=9.189, ppl=583.53, wps=4898.1, ups=0.15, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.535, train_wall=599, gb_free=6.1, wall=10997
2022-01-31 11:56:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:57:12 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.589 | ppl 769.97 | wps 6553.5 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:57:12 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:57:12 | INFO | train | epoch 027 | loss 9.136 | ppl 562.48 | wps 5014.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.52 | train_wall 382 | gb_free 6.1 | wall 11197
KL Stats: Epoch 27 Divergences: Uniform: 1.9820231089738016 Unigram: 1.9459831047947016
2022-01-31 11:57:12 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:57:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:04:13 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.564 | ppl 756.84 | wps 6552.2 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 12:04:13 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 12:04:13 | INFO | train | epoch 028 | loss 9.058 | ppl 532.98 | wps 4961.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.525 | train_wall 387 | gb_free 6.1 | wall 11618
KL Stats: Epoch 28 Divergences: Uniform: 2.013568105456356 Unigram: 1.9871563517777484
2022-01-31 12:04:13 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 12:04:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:05:01 | INFO | train_inner | epoch 029:      8 / 64 loss=9.073, ppl=538.73, wps=4872.2, ups=0.15, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.527, train_wall=601, gb_free=6.1, wall=11666
2022-01-31 12:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:11:11 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.532 | ppl 740.08 | wps 6445.6 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 12:11:11 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 12:11:11 | INFO | train | epoch 029 | loss 8.979 | ppl 504.73 | wps 5001 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.527 | train_wall 383 | gb_free 6.1 | wall 12035
KL Stats: Epoch 29 Divergences: Uniform: 2.0329932599294147 Unigram: 2.024818367922089
2022-01-31 12:11:11 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 12:11:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:15:36 | INFO | train_inner | epoch 030:     44 / 64 loss=8.946, ppl=493.36, wps=5146.8, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.519, train_wall=600, gb_free=6.1, wall=12301
2022-01-31 12:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:18:09 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.503 | ppl 725.54 | wps 6434.6 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 12:18:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 12:18:09 | INFO | train | epoch 030 | loss 8.902 | ppl 478.35 | wps 4988.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.522 | train_wall 384 | gb_free 6.1 | wall 12454
KL Stats: Epoch 30 Divergences: Uniform: 2.052228590990245 Unigram: 2.0652157583080077
2022-01-31 12:18:09 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 12:18:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:25:08 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.455 | ppl 701.6 | wps 6385 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 12:25:08 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 12:25:08 | INFO | train | epoch 031 | loss 8.823 | ppl 452.88 | wps 4983.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.495 | train_wall 384 | gb_free 6.1 | wall 12873
KL Stats: Epoch 31 Divergences: Uniform: 2.0699090993621323 Unigram: 2.0991911459540558
2022-01-31 12:25:08 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 12:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:26:45 | INFO | train_inner | epoch 032:     16 / 64 loss=8.824, ppl=453.24, wps=4874.8, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.503, train_wall=599, gb_free=6.1, wall=12969
2022-01-31 12:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:32:05 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.419 | ppl 684.59 | wps 6597.1 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 12:32:05 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 12:32:05 | INFO | train | epoch 032 | loss 8.749 | ppl 430.28 | wps 5011.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.508 | train_wall 383 | gb_free 6.1 | wall 13290
KL Stats: Epoch 32 Divergences: Uniform: 2.0962749504270524 Unigram: 2.136079636775701
2022-01-31 12:32:05 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 12:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:37:16 | INFO | train_inner | epoch 033:     52 / 64 loss=8.712, ppl=419.42, wps=5179.7, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.512, train_wall=596, gb_free=6.1, wall=13600
2022-01-31 12:38:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:38:59 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.404 | ppl 677.58 | wps 6574.6 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:38:59 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:38:59 | INFO | train | epoch 033 | loss 8.675 | ppl 408.64 | wps 5042.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.51 | train_wall 380 | gb_free 6.1 | wall 13704
KL Stats: Epoch 33 Divergences: Uniform: 2.121835613589365 Unigram: 2.1758039922540684
2022-01-31 12:38:59 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:45:57 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.392 | ppl 672.03 | wps 6558 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:45:57 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:45:57 | INFO | train | epoch 034 | loss 8.599 | ppl 387.82 | wps 5000.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.512 | train_wall 383 | gb_free 6.1 | wall 14122
KL Stats: Epoch 34 Divergences: Uniform: 2.141329987124237 Unigram: 2.211969545667456
2022-01-31 12:45:57 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:48:21 | INFO | train_inner | epoch 035:     24 / 64 loss=8.586, ppl=384.4, wps=4901.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.514, train_wall=597, gb_free=6.1, wall=14266
2022-01-31 12:52:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:52:53 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.357 | ppl 655.6 | wps 6521 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:52:53 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:52:53 | INFO | train | epoch 035 | loss 8.527 | ppl 368.88 | wps 5020.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.507 | train_wall 382 | gb_free 6.1 | wall 14538
KL Stats: Epoch 35 Divergences: Uniform: 2.1630275068524356 Unigram: 2.2423064347854256
2022-01-31 12:52:53 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:52:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:58:54 | INFO | train_inner | epoch 036:     60 / 64 loss=8.483, ppl=357.73, wps=5165.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.499, train_wall=598, gb_free=6.1, wall=14898
2022-01-31 12:59:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:59:49 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.331 | ppl 643.93 | wps 6572.1 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:59:49 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:59:49 | INFO | train | epoch 036 | loss 8.453 | ppl 350.43 | wps 5019.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.497 | train_wall 382 | gb_free 6.1 | wall 14954
KL Stats: Epoch 36 Divergences: Uniform: 2.1848241602427367 Unigram: 2.2812232144715994
2022-01-31 12:59:49 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:06:45 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.349 | ppl 652.24 | wps 6584.1 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 13:06:45 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 13:06:45 | INFO | train | epoch 037 | loss 8.384 | ppl 334.07 | wps 5021.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.509 | train_wall 382 | gb_free 6.1 | wall 15370
KL Stats: Epoch 37 Divergences: Uniform: 2.203489617035752 Unigram: 2.316397890322906
2022-01-31 13:06:45 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 13:06:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:09:57 | INFO | train_inner | epoch 038:     32 / 64 loss=8.363, ppl=329.14, wps=4910.4, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.507, train_wall=596, gb_free=6.1, wall=15562
2022-01-31 13:13:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:13:42 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.329 | ppl 643.01 | wps 6564.7 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 13:13:42 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 13:13:42 | INFO | train | epoch 038 | loss 8.315 | ppl 318.58 | wps 5015.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.507 | train_wall 382 | gb_free 6.1 | wall 15786
KL Stats: Epoch 38 Divergences: Uniform: 2.234366494922494 Unigram: 2.3405972583210315
2022-01-31 13:13:42 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 13:13:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:20:38 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.312 | ppl 635.73 | wps 6572.8 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 13:20:38 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 13:20:38 | INFO | train | epoch 039 | loss 8.246 | ppl 303.68 | wps 5020.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.498 | train_wall 382 | gb_free 6.1 | wall 16202
KL Stats: Epoch 39 Divergences: Uniform: 2.24170071921029 Unigram: 2.3802682186199515
2022-01-31 13:20:38 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 13:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:21:02 | INFO | train_inner | epoch 040:      4 / 64 loss=8.268, ppl=308.33, wps=4905.8, ups=0.15, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.504, train_wall=596, gb_free=6.1, wall=16226
2022-01-31 13:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:27:34 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.29 | ppl 625.94 | wps 6545.5 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 13:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 13:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint40.pt
2022-01-31 13:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint40.pt
2022-01-31 13:28:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.29) (writing took 32.276057763025165 seconds)
2022-01-31 13:28:06 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 13:28:06 | INFO | train | epoch 040 | loss 8.178 | ppl 289.55 | wps 4657.8 | ups 0.14 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.501 | train_wall 382 | gb_free 6.1 | wall 16651
KL Stats: Epoch 40 Divergences: Uniform: 2.267977422467878 Unigram: 2.411234622630235
2022-01-31 13:28:06 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 13:28:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:32:06 | INFO | train_inner | epoch 041:     40 / 64 loss=8.154, ppl=284.87, wps=4917.5, ups=0.15, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.499, train_wall=597, gb_free=6.1, wall=16891
2022-01-31 13:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:35:03 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.28 | ppl 621.58 | wps 6541.8 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.28
2022-01-31 13:35:03 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 13:35:03 | INFO | train | epoch 041 | loss 8.114 | ppl 277.01 | wps 5007.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.502 | train_wall 383 | gb_free 6.1 | wall 17068
KL Stats: Epoch 41 Divergences: Uniform: 2.2836917864710187 Unigram: 2.4385710476876574
2022-01-31 13:35:03 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 13:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:41:59 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.258 | ppl 612.46 | wps 6564 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.258
2022-01-31 13:41:59 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 13:41:59 | INFO | train | epoch 042 | loss 8.05 | ppl 264.98 | wps 5023.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.513 | train_wall 382 | gb_free 6.1 | wall 17484
KL Stats: Epoch 42 Divergences: Uniform: 2.300976599368634 Unigram: 2.474831047345943
2022-01-31 13:41:59 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 13:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:43:11 | INFO | train_inner | epoch 043:     12 / 64 loss=8.056, ppl=266.17, wps=4905.4, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.512, train_wall=596, gb_free=6.1, wall=17556
2022-01-31 13:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:48:56 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.288 | ppl 625.11 | wps 6523.2 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.288
2022-01-31 13:48:56 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 13:48:56 | INFO | train | epoch 043 | loss 7.984 | ppl 253.21 | wps 5006.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.497 | train_wall 383 | gb_free 6.1 | wall 17901
KL Stats: Epoch 43 Divergences: Uniform: 2.3226290864516934 Unigram: 2.503865702121564
2022-01-31 13:48:56 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 13:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:53:45 | INFO | train_inner | epoch 044:     48 / 64 loss=7.95, ppl=247.32, wps=5156.8, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.502, train_wall=599, gb_free=6.1, wall=18189
2022-01-31 13:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:55:53 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.295 | ppl 627.97 | wps 6561.4 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.29
2022-01-31 13:55:53 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:55:53 | INFO | train | epoch 044 | loss 7.925 | ppl 243.09 | wps 5012.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.509 | train_wall 382 | gb_free 6.1 | wall 18317
KL Stats: Epoch 44 Divergences: Uniform: 2.341551777314357 Unigram: 2.5316330457442717
2022-01-31 13:55:53 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:55:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:02:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:02:49 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.265 | ppl 615.16 | wps 6565.3 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.265
2022-01-31 14:02:49 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 14:02:49 | INFO | train | epoch 045 | loss 7.861 | ppl 232.52 | wps 5012.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.503 | train_wall 382 | gb_free 6.1 | wall 18734
KL Stats: Epoch 45 Divergences: Uniform: 2.3594785450936633 Unigram: 2.5660223371443935
2022-01-31 14:02:49 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 14:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:04:49 | INFO | train_inner | epoch 046:     20 / 64 loss=7.861, ppl=232.52, wps=4904.7, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.506, train_wall=597, gb_free=6.1, wall=18854
2022-01-31 14:09:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:09:45 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.274 | ppl 619.17 | wps 6548.9 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.274
2022-01-31 14:09:45 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 14:09:45 | INFO | train | epoch 046 | loss 7.803 | ppl 223.28 | wps 5028.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.513 | train_wall 381 | gb_free 6.1 | wall 19149
KL Stats: Epoch 46 Divergences: Uniform: 2.372532614273227 Unigram: 2.5855353878595224
2022-01-31 14:09:45 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 14:09:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:15:21 | INFO | train_inner | epoch 047:     56 / 64 loss=7.772, ppl=218.56, wps=5175.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.503, train_wall=597, gb_free=6.1, wall=19485
2022-01-31 14:16:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:16:41 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.261 | ppl 613.7 | wps 6572.4 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.261
2022-01-31 14:16:41 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 14:16:41 | INFO | train | epoch 047 | loss 7.744 | ppl 214.38 | wps 5024.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.498 | train_wall 382 | gb_free 6.1 | wall 19565
KL Stats: Epoch 47 Divergences: Uniform: 2.3953707973744356 Unigram: 2.6122049747759957
2022-01-31 14:16:41 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 14:16:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:23:36 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.253 | ppl 610.2 | wps 6562.5 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.253
2022-01-31 14:23:36 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 14:23:36 | INFO | train | epoch 048 | loss 7.687 | ppl 206.13 | wps 5027.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.511 | train_wall 381 | gb_free 6.1 | wall 19981
KL Stats: Epoch 48 Divergences: Uniform: 2.4143608979421143 Unigram: 2.642530954947643
2022-01-31 14:23:36 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 14:23:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:26:24 | INFO | train_inner | epoch 049:     28 / 64 loss=7.67, ppl=203.61, wps=4912.3, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.507, train_wall=596, gb_free=6.1, wall=20149
2022-01-31 14:29:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:30:32 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.282 | ppl 622.5 | wps 6498.4 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.282
2022-01-31 14:30:32 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 14:30:32 | INFO | train | epoch 049 | loss 7.63 | ppl 198.12 | wps 5015 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.507 | train_wall 382 | gb_free 6.1 | wall 20397
KL Stats: Epoch 49 Divergences: Uniform: 2.4188905508318213 Unigram: 2.6677853228301935
2022-01-31 14:30:33 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 14:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:36:54 | INFO | train_inner | epoch 050:     64 / 64 loss=7.606, ppl=194.86, wps=5179, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.525, train_wall=594, gb_free=6.1, wall=20778
2022-01-31 14:36:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:37:27 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.295 | ppl 628.08 | wps 6587.7 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.29
2022-01-31 14:37:27 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 14:37:27 | INFO | train | epoch 050 | loss 7.58 | ppl 191.31 | wps 5038 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.532 | train_wall 380 | gb_free 6.1 | wall 20812
KL Stats: Epoch 50 Divergences: Uniform: 2.4357930271031853 Unigram: 2.6851564620898873
2022-01-31 14:37:27 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 14:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:44:22 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.306 | ppl 632.87 | wps 6555.5 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.29
2022-01-31 14:44:22 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 14:44:22 | INFO | train | epoch 051 | loss 7.523 | ppl 183.98 | wps 5029.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.508 | train_wall 381 | gb_free 6.1 | wall 21227
KL Stats: Epoch 51 Divergences: Uniform: 2.4625107206030523 Unigram: 2.7080783075721224
2022-01-31 14:44:22 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 14:44:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:47:58 | INFO | train_inner | epoch 052:     36 / 64 loss=7.5, ppl=180.96, wps=4920.9, ups=0.15, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.509, train_wall=596, gb_free=6.1, wall=21443
2022-01-31 14:50:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:51:18 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.291 | ppl 626.58 | wps 6529.3 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.29
2022-01-31 14:51:18 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 14:51:18 | INFO | train | epoch 052 | loss 7.471 | ppl 177.46 | wps 5021.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.52 | train_wall 382 | gb_free 6.1 | wall 21643
KL Stats: Epoch 52 Divergences: Uniform: 2.473241743594871 Unigram: 2.7419926173095432
2022-01-31 14:51:18 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 14:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:58:14 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.276 | ppl 620.04 | wps 6559.4 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.276
2022-01-31 14:58:14 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 14:58:14 | INFO | train | epoch 053 | loss 7.42 | ppl 171.21 | wps 5020 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.509 | train_wall 382 | gb_free 6.1 | wall 22059
KL Stats: Epoch 53 Divergences: Uniform: 2.4961905188418685 Unigram: 2.7590443627653363
2022-01-31 14:58:14 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 14:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:59:02 | INFO | train_inner | epoch 054:      8 / 64 loss=7.433, ppl=172.79, wps=4907.1, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.52, train_wall=596, gb_free=6.1, wall=22107
2022-01-31 15:04:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:05:10 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.33 | ppl 643.61 | wps 6534.8 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.29
2022-01-31 15:05:10 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 15:05:10 | INFO | train | epoch 054 | loss 7.37 | ppl 165.42 | wps 5022.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.525 | train_wall 381 | gb_free 6.1 | wall 22475
KL Stats: Epoch 54 Divergences: Uniform: 2.497436100146636 Unigram: 2.779324647748518
2022-01-31 15:05:10 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 15:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:09:35 | INFO | train_inner | epoch 055:     44 / 64 loss=7.342, ppl=162.23, wps=5167.1, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.518, train_wall=598, gb_free=6.1, wall=22739
2022-01-31 15:11:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:12:07 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.327 | ppl 642.36 | wps 6552.2 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.29
2022-01-31 15:12:07 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 15:12:07 | INFO | train | epoch 055 | loss 7.322 | ppl 160.05 | wps 5016.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.529 | train_wall 382 | gb_free 6.1 | wall 22891
KL Stats: Epoch 55 Divergences: Uniform: 2.512791394446619 Unigram: 2.808401310438587
2022-01-31 15:12:07 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 15:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:19:02 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.438 | ppl 693.63 | wps 6513.5 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.29
2022-01-31 15:19:02 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 15:19:02 | INFO | train | epoch 056 | loss 7.273 | ppl 154.69 | wps 5021.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.52 | train_wall 381 | gb_free 6.1 | wall 23307
KL Stats: Epoch 56 Divergences: Uniform: 2.51154919936294 Unigram: 2.825248114648947
2022-01-31 15:19:02 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 15:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:20:39 | INFO | train_inner | epoch 057:     16 / 64 loss=7.277, ppl=155.13, wps=4911.8, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.53, train_wall=595, gb_free=6.1, wall=23403
2022-01-31 15:25:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:25:59 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.416 | ppl 683.01 | wps 6544.3 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.29
2022-01-31 15:25:59 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 15:25:59 | INFO | train | epoch 057 | loss 7.226 | ppl 149.71 | wps 5008.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.531 | train_wall 383 | gb_free 6.1 | wall 23724
KL Stats: Epoch 57 Divergences: Uniform: 2.5433143425453415 Unigram: 2.8541784453698913
2022-01-31 15:25:59 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 15:25:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:31:12 | INFO | train_inner | epoch 058:     52 / 64 loss=7.202, ppl=147.19, wps=5156.7, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.527, train_wall=599, gb_free=6.1, wall=24037
2022-01-31 15:32:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:32:56 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.422 | ppl 685.83 | wps 6522.4 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.29
2022-01-31 15:32:56 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 15:32:56 | INFO | train | epoch 058 | loss 7.181 | ppl 145.13 | wps 5008.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.529 | train_wall 383 | gb_free 6.1 | wall 24141
KL Stats: Epoch 58 Divergences: Uniform: 2.5545396036536654 Unigram: 2.8690830763847734
2022-01-31 15:32:56 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 15:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:39:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:39:53 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.487 | ppl 717.77 | wps 6572.6 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.29
2022-01-31 15:39:53 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 15:39:53 | INFO | train | epoch 059 | loss 7.137 | ppl 140.7 | wps 5012.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.536 | train_wall 383 | gb_free 6.1 | wall 24558
KL Stats: Epoch 59 Divergences: Uniform: 2.56783731048286 Unigram: 2.8899126929068535
2022-01-31 15:39:53 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 15:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:42:17 | INFO | train_inner | epoch 060:     24 / 64 loss=7.13, ppl=140.11, wps=4903.6, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.536, train_wall=597, gb_free=6.1, wall=24702
2022-01-31 15:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:46:49 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.44 | ppl 694.49 | wps 6579.9 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.29
2022-01-31 15:46:49 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 15:46:49 | INFO | train | epoch 060 | loss 7.092 | ppl 136.47 | wps 5024.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.542 | train_wall 381 | gb_free 6.1 | wall 24973
KL Stats: Epoch 60 Divergences: Uniform: 2.582392889607815 Unigram: 2.9171904700626756
2022-01-31 15:46:49 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 15:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:52:49 | INFO | train_inner | epoch 061:     60 / 64 loss=7.073, ppl=134.67, wps=5175.3, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.547, train_wall=597, gb_free=6.1, wall=25333
2022-01-31 15:53:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:53:45 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.498 | ppl 722.85 | wps 6504.7 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.29
2022-01-31 15:53:45 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 15:53:45 | INFO | train | epoch 061 | loss 7.05 | ppl 132.51 | wps 5023.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.549 | train_wall 381 | gb_free 6.1 | wall 25389
KL Stats: Epoch 61 Divergences: Uniform: 2.6006211294791353 Unigram: 2.92704817183114
2022-01-31 15:53:45 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 15:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:00:41 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.468 | ppl 708.08 | wps 6565 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.29
2022-01-31 16:00:41 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 16:00:41 | INFO | train | epoch 062 | loss 7.008 | ppl 128.75 | wps 5019.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.551 | train_wall 382 | gb_free 6.1 | wall 25805
KL Stats: Epoch 62 Divergences: Uniform: 2.606305320687258 Unigram: 2.9574455860398685
2022-01-31 16:00:41 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 16:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:03:53 | INFO | train_inner | epoch 063:     32 / 64 loss=6.983, ppl=126.47, wps=4908.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.55, train_wall=596, gb_free=6.1, wall=25997
2022-01-31 16:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:07:36 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.48 | ppl 713.92 | wps 6585.7 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.29
2022-01-31 16:07:36 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 16:07:36 | INFO | train | epoch 063 | loss 6.965 | ppl 124.9 | wps 5028.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.547 | train_wall 381 | gb_free 6.1 | wall 26221
KL Stats: Epoch 63 Divergences: Uniform: 2.618785416238635 Unigram: 2.9738992967448974
2022-01-31 16:07:36 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 16:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:14:32 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.558 | ppl 753.82 | wps 6521.3 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.29
2022-01-31 16:14:32 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 16:14:32 | INFO | train | epoch 064 | loss 6.922 | ppl 121.26 | wps 5025.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.558 | train_wall 381 | gb_free 6.1 | wall 26636
KL Stats: Epoch 64 Divergences: Uniform: 2.628982474525611 Unigram: 2.992738841747211
2022-01-31 16:14:32 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 16:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:14:56 | INFO | train_inner | epoch 065:      4 / 64 loss=6.949, ppl=123.54, wps=4916.4, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.554, train_wall=595, gb_free=6.1, wall=26660
2022-01-31 16:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:21:28 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.565 | ppl 757.63 | wps 6534.7 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.29
2022-01-31 16:21:28 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 16:21:28 | INFO | train | epoch 065 | loss 6.879 | ppl 117.73 | wps 5014.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.555 | train_wall 382 | gb_free 6.1 | wall 27053
KL Stats: Epoch 65 Divergences: Uniform: 2.6387180847112095 Unigram: 3.0134925258143763
2022-01-31 16:21:28 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 16:21:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:25:28 | INFO | train_inner | epoch 066:     40 / 64 loss=6.855, ppl=115.79, wps=5166.6, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.561, train_wall=598, gb_free=6.1, wall=27293
2022-01-31 16:27:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:28:24 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.577 | ppl 763.57 | wps 6547.5 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.29
2022-01-31 16:28:24 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 16:28:24 | INFO | train | epoch 066 | loss 6.839 | ppl 114.52 | wps 5027.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.555 | train_wall 381 | gb_free 6.1 | wall 27468
KL Stats: Epoch 66 Divergences: Uniform: 2.651188497166606 Unigram: 3.0278592977426446
2022-01-31 16:28:24 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 16:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:35:22 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.553 | ppl 751.36 | wps 6430.9 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.29
2022-01-31 16:35:22 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 16:35:22 | INFO | train | epoch 067 | loss 6.798 | ppl 111.25 | wps 4992.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.554 | train_wall 383 | gb_free 6.1 | wall 27887
KL Stats: Epoch 67 Divergences: Uniform: 2.6699556343512065 Unigram: 3.0547058660614717
2022-01-31 16:35:22 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 16:35:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:36:36 | INFO | train_inner | epoch 068:     12 / 64 loss=6.806, ppl=111.93, wps=4884.9, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.551, train_wall=599, gb_free=6.1, wall=27960
2022-01-31 16:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:42:19 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.626 | ppl 789.97 | wps 6553 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.29
2022-01-31 16:42:19 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 16:42:19 | INFO | train | epoch 068 | loss 6.762 | ppl 108.5 | wps 5006.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.578 | train_wall 383 | gb_free 6.1 | wall 28304
KL Stats: Epoch 68 Divergences: Uniform: 2.6794011551594132 Unigram: 3.0733487497051186
2022-01-31 16:42:19 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 16:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:47:07 | INFO | train_inner | epoch 069:     48 / 64 loss=6.743, ppl=107.1, wps=5173.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.566, train_wall=597, gb_free=6.1, wall=28592
2022-01-31 16:48:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:49:15 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.635 | ppl 795.11 | wps 6560.1 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.29
2022-01-31 16:49:15 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 16:49:15 | INFO | train | epoch 069 | loss 6.722 | ppl 105.55 | wps 5023.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.555 | train_wall 382 | gb_free 6.1 | wall 28720
KL Stats: Epoch 69 Divergences: Uniform: 2.692300496289744 Unigram: 3.089894889250788
2022-01-31 16:49:15 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 16:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:55:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:56:12 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.703 | ppl 833.37 | wps 6551.6 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.29
2022-01-31 16:56:12 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 16:56:12 | INFO | train | epoch 070 | loss 6.687 | ppl 103.03 | wps 5011.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.559 | train_wall 382 | gb_free 6.1 | wall 29136
KL Stats: Epoch 70 Divergences: Uniform: 2.697833402813989 Unigram: 3.100456947016811
2022-01-31 16:56:12 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 16:56:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:58:12 | INFO | train_inner | epoch 071:     20 / 64 loss=6.681, ppl=102.63, wps=4902.8, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.563, train_wall=597, gb_free=6.1, wall=29257
2022-01-31 17:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:03:10 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.688 | ppl 824.87 | wps 6447.2 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.29
2022-01-31 17:03:10 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 17:03:10 | INFO | train | epoch 071 | loss 6.654 | ppl 100.68 | wps 4989.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.578 | train_wall 384 | gb_free 6.1 | wall 29555
KL Stats: Epoch 71 Divergences: Uniform: 2.708446192201698 Unigram: 3.123140413180172
2022-01-31 17:03:10 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 17:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:08:48 | INFO | train_inner | epoch 072:     56 / 64 loss=6.638, ppl=99.61, wps=5140.2, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.573, train_wall=600, gb_free=6.1, wall=29893
2022-01-31 17:09:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:10:08 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.641 | ppl 798.24 | wps 6568.6 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.29
2022-01-31 17:10:08 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 17:10:08 | INFO | train | epoch 072 | loss 6.618 | ppl 98.23 | wps 5005.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.57 | train_wall 383 | gb_free 6.1 | wall 29972
KL Stats: Epoch 72 Divergences: Uniform: 2.7257006899600444 Unigram: 3.1415577593031747
2022-01-31 17:10:08 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 17:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:16:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:17:04 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.73 | ppl 849.4 | wps 6478.9 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.29
2022-01-31 17:17:04 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 17:17:04 | INFO | train | epoch 073 | loss 6.586 | ppl 96.04 | wps 5019.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.571 | train_wall 381 | gb_free 6.1 | wall 30388
KL Stats: Epoch 73 Divergences: Uniform: 2.7247781095322745 Unigram: 3.157295048210391
2022-01-31 17:17:04 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 17:17:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:19:53 | INFO | train_inner | epoch 074:     28 / 64 loss=6.575, ppl=95.31, wps=4900.7, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.572, train_wall=597, gb_free=6.1, wall=30558
2022-01-31 17:23:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:24:04 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.626 | ppl 790.1 | wps 6562.4 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.29
2022-01-31 17:24:04 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 17:24:04 | INFO | train | epoch 074 | loss 6.554 | ppl 93.93 | wps 4972.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.586 | train_wall 386 | gb_free 6.1 | wall 30808
KL Stats: Epoch 74 Divergences: Uniform: 2.7385114359950893 Unigram: 3.184915355719623
2022-01-31 17:24:04 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 17:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:30:28 | INFO | train_inner | epoch 075:     64 / 64 loss=6.544, ppl=93.31, wps=5131.3, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.584, train_wall=601, gb_free=6.1, wall=31193
2022-01-31 17:30:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:31:02 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.766 | ppl 870.43 | wps 6562.5 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.29
2022-01-31 17:31:02 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 17:31:02 | INFO | train | epoch 075 | loss 6.523 | ppl 91.96 | wps 4996.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.578 | train_wall 384 | gb_free 6.1 | wall 31226
KL Stats: Epoch 75 Divergences: Uniform: 2.741120185949408 Unigram: 3.1948940729597544
2022-01-31 17:31:02 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 17:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:38:02 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.725 | ppl 846.13 | wps 6474.4 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.29
2022-01-31 17:38:02 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 17:38:02 | INFO | train | epoch 076 | loss 6.494 | ppl 90.12 | wps 4970.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.598 | train_wall 386 | gb_free 6.1 | wall 31647
KL Stats: Epoch 76 Divergences: Uniform: 2.7547274526891528 Unigram: 3.215229785341821
2022-01-31 17:38:02 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 17:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:41:39 | INFO | train_inner | epoch 077:     36 / 64 loss=6.468, ppl=88.54, wps=4875.5, ups=0.15, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.592, train_wall=602, gb_free=6.1, wall=31863
2022-01-31 17:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:44:59 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.766 | ppl 870.59 | wps 6522.5 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.29
2022-01-31 17:44:59 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 17:44:59 | INFO | train | epoch 077 | loss 6.464 | ppl 88.27 | wps 5009.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.597 | train_wall 383 | gb_free 6.1 | wall 32064
KL Stats: Epoch 77 Divergences: Uniform: 2.755473268862782 Unigram: 3.2377440815124308
2022-01-31 17:44:59 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 17:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:51:55 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.73 | ppl 849.26 | wps 6543.8 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.29
2022-01-31 17:51:55 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 17:51:55 | INFO | train | epoch 078 | loss 6.437 | ppl 86.62 | wps 5021 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.601 | train_wall 382 | gb_free 6.1 | wall 32480
KL Stats: Epoch 78 Divergences: Uniform: 2.7689016539416627 Unigram: 3.249212446923897
2022-01-31 17:51:55 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 17:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:52:43 | INFO | train_inner | epoch 079:      8 / 64 loss=6.451, ppl=87.5, wps=4907.8, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.605, train_wall=596, gb_free=6.1, wall=32528
2022-01-31 17:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:58:51 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.827 | ppl 908.13 | wps 6545.6 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.29
2022-01-31 17:58:51 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 17:58:51 | INFO | train | epoch 079 | loss 6.405 | ppl 84.75 | wps 5020.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.588 | train_wall 382 | gb_free 6.1 | wall 32896
KL Stats: Epoch 79 Divergences: Uniform: 2.7718663429399095 Unigram: 3.2610553525788384
2022-01-31 17:58:51 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 17:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:03:15 | INFO | train_inner | epoch 080:     44 / 64 loss=6.389, ppl=83.81, wps=5170.6, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.591, train_wall=597, gb_free=6.1, wall=33160
2022-01-31 18:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:05:47 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.742 | ppl 856.06 | wps 6573.2 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.29
2022-01-31 18:05:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 18:05:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint80.pt
2022-01-31 18:05:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint80.pt
2022-01-31 18:05:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.742) (writing took 3.2600006982684135 seconds)
2022-01-31 18:05:50 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 18:05:50 | INFO | train | epoch 080 | loss 6.381 | ppl 83.32 | wps 4984.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.603 | train_wall 382 | gb_free 6.1 | wall 33315
KL Stats: Epoch 80 Divergences: Uniform: 2.7778181665693977 Unigram: 3.2833505363608273
2022-01-31 18:05:50 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 18:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:12:46 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.814 | ppl 900.02 | wps 6494.3 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.29
2022-01-31 18:12:46 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 18:12:46 | INFO | train | epoch 081 | loss 6.355 | ppl 81.83 | wps 5016.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.615 | train_wall 382 | gb_free 6.1 | wall 33731
KL Stats: Epoch 81 Divergences: Uniform: 2.7978398000934734 Unigram: 3.299518783093557
2022-01-31 18:12:46 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 18:12:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:14:23 | INFO | train_inner | epoch 082:     16 / 64 loss=6.361, ppl=82.2, wps=4882.2, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.62, train_wall=596, gb_free=6.1, wall=33827
2022-01-31 18:19:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:19:42 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.772 | ppl 874.33 | wps 6550.9 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.29
2022-01-31 18:19:42 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 18:19:42 | INFO | train | epoch 082 | loss 6.328 | ppl 80.34 | wps 5021.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.61 | train_wall 382 | gb_free 6.1 | wall 34147
KL Stats: Epoch 82 Divergences: Uniform: 2.7992774490986303 Unigram: 3.322864494797816
2022-01-31 18:19:42 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 18:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:24:55 | INFO | train_inner | epoch 083:     52 / 64 loss=6.314, ppl=79.55, wps=5173.5, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.609, train_wall=597, gb_free=6.1, wall=34459
2022-01-31 18:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:26:38 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.693 | ppl 827.92 | wps 6565.6 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.29
2022-01-31 18:26:38 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 18:26:38 | INFO | train | epoch 083 | loss 6.304 | ppl 78.99 | wps 5018.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.618 | train_wall 382 | gb_free 6.1 | wall 34563
KL Stats: Epoch 83 Divergences: Uniform: 2.8133406032734958 Unigram: 3.33984726680632
2022-01-31 18:26:38 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 18:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:33:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:33:35 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.779 | ppl 878.48 | wps 6487.6 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.29
2022-01-31 18:33:35 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 18:33:35 | INFO | train | epoch 084 | loss 6.279 | ppl 77.63 | wps 5015.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.615 | train_wall 382 | gb_free 6.1 | wall 34979
KL Stats: Epoch 84 Divergences: Uniform: 2.8156578613819674 Unigram: 3.349408390783385
2022-01-31 18:33:35 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 18:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:35:59 | INFO | train_inner | epoch 085:     24 / 64 loss=6.268, ppl=77.06, wps=4904.4, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.615, train_wall=596, gb_free=6.1, wall=35124
2022-01-31 18:39:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:40:32 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.797 | ppl 889.54 | wps 6551.8 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.29
2022-01-31 18:40:32 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 18:40:32 | INFO | train | epoch 085 | loss 6.255 | ppl 76.35 | wps 5004.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.623 | train_wall 383 | gb_free 6.1 | wall 35397
KL Stats: Epoch 85 Divergences: Uniform: 2.8300923714889614 Unigram: 3.3609882021183126
2022-01-31 18:40:32 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 18:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:46:34 | INFO | train_inner | epoch 086:     60 / 64 loss=6.252, ppl=76.21, wps=5149.3, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.629, train_wall=600, gb_free=6.1, wall=35758
2022-01-31 18:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:47:30 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.815 | ppl 900.81 | wps 6465.3 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.29
2022-01-31 18:47:30 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 18:47:30 | INFO | train | epoch 086 | loss 6.231 | ppl 75.11 | wps 4994.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.632 | train_wall 383 | gb_free 6.1 | wall 35815
KL Stats: Epoch 86 Divergences: Uniform: 2.828308306320265 Unigram: 3.385656513217498
2022-01-31 18:47:30 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 18:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:53:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:54:26 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.851 | ppl 923.6 | wps 6614.9 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.29
2022-01-31 18:54:26 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 18:54:26 | INFO | train | epoch 087 | loss 6.209 | ppl 73.97 | wps 5020.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.651 | train_wall 382 | gb_free 6.1 | wall 36231
KL Stats: Epoch 87 Divergences: Uniform: 2.8336558541984913 Unigram: 3.393945844237983
2022-01-31 18:54:26 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 18:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:57:38 | INFO | train_inner | epoch 088:     32 / 64 loss=6.196, ppl=73.32, wps=4907.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.651, train_wall=596, gb_free=6.1, wall=36423
2022-01-31 19:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:01:27 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.815 | ppl 900.84 | wps 6395.1 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.29
2022-01-31 19:01:27 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 19:01:27 | INFO | train | epoch 088 | loss 6.186 | ppl 72.83 | wps 4967.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.648 | train_wall 385 | gb_free 6.1 | wall 36651
KL Stats: Epoch 88 Divergences: Uniform: 2.841669920757512 Unigram: 3.409556756483096
2022-01-31 19:01:27 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 19:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:08:22 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.82 | ppl 904.14 | wps 6620 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.29
2022-01-31 19:08:22 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 19:08:22 | INFO | train | epoch 089 | loss 6.168 | ppl 71.89 | wps 5030 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.661 | train_wall 381 | gb_free 6.1 | wall 37067
KL Stats: Epoch 89 Divergences: Uniform: 2.852255433916887 Unigram: 3.4218323981026466
2022-01-31 19:08:22 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 19:08:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:08:46 | INFO | train_inner | epoch 090:      4 / 64 loss=6.178, ppl=72.41, wps=4881.5, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.657, train_wall=599, gb_free=6.1, wall=37091
2022-01-31 19:14:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:15:15 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.893 | ppl 950.67 | wps 6581.5 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.29
2022-01-31 19:15:15 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 19:15:15 | INFO | train | epoch 090 | loss 6.144 | ppl 70.71 | wps 5053.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.637 | train_wall 379 | gb_free 6.1 | wall 37480
KL Stats: Epoch 90 Divergences: Uniform: 2.8513590447171446 Unigram: 3.431394040505197
2022-01-31 19:15:15 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 19:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:19:14 | INFO | train_inner | epoch 091:     40 / 64 loss=6.125, ppl=69.81, wps=5206.2, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.635, train_wall=593, gb_free=6.1, wall=37718
2022-01-31 19:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:22:10 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.885 | ppl 945.52 | wps 6480.1 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.29
2022-01-31 19:22:10 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 19:22:10 | INFO | train | epoch 091 | loss 6.122 | ppl 69.63 | wps 5043.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.645 | train_wall 379 | gb_free 6.1 | wall 37894
KL Stats: Epoch 91 Divergences: Uniform: 2.8609451318496184 Unigram: 3.457986270169708
2022-01-31 19:22:10 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 19:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:29:05 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.901 | ppl 956 | wps 6596 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.29
2022-01-31 19:29:05 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 19:29:05 | INFO | train | epoch 092 | loss 6.104 | ppl 68.77 | wps 5025.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.666 | train_wall 382 | gb_free 6.1 | wall 38310
KL Stats: Epoch 92 Divergences: Uniform: 2.865546964509086 Unigram: 3.466909888157885
2022-01-31 19:29:05 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 19:29:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:30:17 | INFO | train_inner | epoch 093:     12 / 64 loss=6.113, ppl=69.21, wps=4915.8, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.662, train_wall=595, gb_free=6.1, wall=38381
2022-01-31 19:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:36:06 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.848 | ppl 921.78 | wps 6370.9 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.29
2022-01-31 19:36:06 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 19:36:06 | INFO | train | epoch 093 | loss 6.086 | ppl 67.92 | wps 4962.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.664 | train_wall 386 | gb_free 6.1 | wall 38731
KL Stats: Epoch 93 Divergences: Uniform: 2.8747369600728625 Unigram: 3.4833577734282213
2022-01-31 19:36:06 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 19:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:40:57 | INFO | train_inner | epoch 094:     48 / 64 loss=6.071, ppl=67.24, wps=5103, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.666, train_wall=605, gb_free=6.1, wall=39022
2022-01-31 19:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:43:05 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.927 | ppl 973.76 | wps 6542 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.29
2022-01-31 19:43:05 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 19:43:05 | INFO | train | epoch 094 | loss 6.064 | ppl 66.9 | wps 4986.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.665 | train_wall 384 | gb_free 6.1 | wall 39149
KL Stats: Epoch 94 Divergences: Uniform: 2.877513395115581 Unigram: 3.49938328150797
2022-01-31 19:43:05 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 19:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:50:03 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.937 | ppl 980.42 | wps 6606.1 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.29
2022-01-31 19:50:03 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 19:50:03 | INFO | train | epoch 095 | loss 6.045 | ppl 66.01 | wps 4998.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.661 | train_wall 384 | gb_free 6.1 | wall 39567
KL Stats: Epoch 95 Divergences: Uniform: 2.8821069702168756 Unigram: 3.510813961333822
2022-01-31 19:50:03 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 19:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:52:02 | INFO | train_inner | epoch 096:     20 / 64 loss=6.044, ppl=65.97, wps=4902.7, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.663, train_wall=597, gb_free=6.1, wall=39687
2022-01-31 19:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:56:57 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.858 | ppl 927.75 | wps 6587.1 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.29
2022-01-31 19:56:57 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 19:56:57 | INFO | train | epoch 096 | loss 6.029 | ppl 65.28 | wps 5036.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.675 | train_wall 381 | gb_free 6.1 | wall 39982
KL Stats: Epoch 96 Divergences: Uniform: 2.89185744150977 Unigram: 3.5185268952801025
2022-01-31 19:56:57 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 19:56:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:02:32 | INFO | train_inner | epoch 097:     56 / 64 loss=6.023, ppl=65.03, wps=5192.2, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.686, train_wall=595, gb_free=6.1, wall=40316
2022-01-31 20:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:03:51 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.934 | ppl 977.99 | wps 6581.1 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.29
2022-01-31 20:03:51 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 20:03:51 | INFO | train | epoch 097 | loss 6.012 | ppl 64.52 | wps 5048.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.688 | train_wall 380 | gb_free 6.1 | wall 40396
KL Stats: Epoch 97 Divergences: Uniform: 2.9008521560663865 Unigram: 3.5440895684390825
2022-01-31 20:03:51 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 20:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:10:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:10:46 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.922 | ppl 969.96 | wps 6570.1 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.29
2022-01-31 20:10:46 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 20:10:46 | INFO | train | epoch 098 | loss 5.991 | ppl 63.61 | wps 5036.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.694 | train_wall 381 | gb_free 6.1 | wall 40810
KL Stats: Epoch 98 Divergences: Uniform: 2.898821637305587 Unigram: 3.5435061844200546
2022-01-31 20:10:46 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 20:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:13:34 | INFO | train_inner | epoch 099:     28 / 64 loss=5.982, ppl=63.22, wps=4924.8, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.693, train_wall=594, gb_free=6.1, wall=40978
2022-01-31 20:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:17:41 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.938 | ppl 980.89 | wps 6540.8 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.29
2022-01-31 20:17:41 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 20:17:41 | INFO | train | epoch 099 | loss 5.974 | ppl 62.84 | wps 5031.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.695 | train_wall 381 | gb_free 6.1 | wall 41225
KL Stats: Epoch 99 Divergences: Uniform: 2.9051198747705156 Unigram: 3.5648624337201005
2022-01-31 20:17:41 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 20:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:24:03 | INFO | train_inner | epoch 100:     64 / 64 loss=5.977, ppl=62.99, wps=5179.9, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.705, train_wall=595, gb_free=6.1, wall=41607
2022-01-31 20:24:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:24:36 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.881 | ppl 942.76 | wps 6596.1 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.29
2022-01-31 20:24:36 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 20:24:36 | INFO | train | epoch 100 | loss 5.96 | ppl 62.25 | wps 5030.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.711 | train_wall 381 | gb_free 6.1 | wall 41641
KL Stats: Epoch 100 Divergences: Uniform: 2.9088823478908683 Unigram: 3.573776732324972
2022-01-31 20:24:36 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 20:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:30:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:31:30 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.939 | ppl 981.4 | wps 6584.4 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.29
2022-01-31 20:31:30 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 20:31:30 | INFO | train | epoch 101 | loss 5.939 | ppl 61.35 | wps 5046.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.708 | train_wall 380 | gb_free 6.1 | wall 42054
KL Stats: Epoch 101 Divergences: Uniform: 2.918221504488258 Unigram: 3.5912306227262847
2022-01-31 20:31:30 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 20:31:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:35:05 | INFO | train_inner | epoch 102:     36 / 64 loss=5.926, ppl=60.78, wps=4935.9, ups=0.15, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.717, train_wall=594, gb_free=6.1, wall=42270
2022-01-31 20:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:38:24 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.944 | ppl 985.34 | wps 6593.8 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.29
2022-01-31 20:38:24 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 20:38:24 | INFO | train | epoch 102 | loss 5.926 | ppl 60.79 | wps 5045.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.725 | train_wall 380 | gb_free 6.1 | wall 42468
KL Stats: Epoch 102 Divergences: Uniform: 2.9149174840514838 Unigram: 3.5996971195981176
2022-01-31 20:38:24 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 20:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:45:18 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.942 | ppl 983.48 | wps 6572.9 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.29
2022-01-31 20:45:18 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 20:45:18 | INFO | train | epoch 103 | loss 5.908 | ppl 60.05 | wps 5039.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.712 | train_wall 380 | gb_free 6.1 | wall 42883
KL Stats: Epoch 103 Divergences: Uniform: 2.929068771193835 Unigram: 3.6135491361842385
2022-01-31 20:45:18 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 20:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:46:06 | INFO | train_inner | epoch 104:      8 / 64 loss=5.915, ppl=60.35, wps=4930.3, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.716, train_wall=593, gb_free=6.1, wall=42931
2022-01-31 20:51:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:52:13 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.97 | ppl 1002.85 | wps 6582.3 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.29
2022-01-31 20:52:13 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 20:52:13 | INFO | train | epoch 104 | loss 5.895 | ppl 59.49 | wps 5038.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.723 | train_wall 380 | gb_free 6.1 | wall 43297
KL Stats: Epoch 104 Divergences: Uniform: 2.921846406913788 Unigram: 3.628791090228322
2022-01-31 20:52:13 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 20:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:56:36 | INFO | train_inner | epoch 105:     44 / 64 loss=5.882, ppl=58.97, wps=5189.2, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.724, train_wall=595, gb_free=6.1, wall=43561
2022-01-31 20:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:59:07 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.926 | ppl 972.58 | wps 6608.5 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.29
2022-01-31 20:59:07 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 20:59:07 | INFO | train | epoch 105 | loss 5.877 | ppl 58.79 | wps 5040.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.727 | train_wall 380 | gb_free 6.1 | wall 43712
KL Stats: Epoch 105 Divergences: Uniform: 2.927999191902184 Unigram: 3.6371713334382823
2022-01-31 20:59:07 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 20:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:05:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:06:02 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.952 | ppl 990.24 | wps 6477 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.29
2022-01-31 21:06:02 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 21:06:02 | INFO | train | epoch 106 | loss 5.861 | ppl 58.14 | wps 5035 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.717 | train_wall 380 | gb_free 6.1 | wall 44127
KL Stats: Epoch 106 Divergences: Uniform: 2.933958317510721 Unigram: 3.641976673868673
2022-01-31 21:06:02 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 21:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:07:37 | INFO | train_inner | epoch 107:     16 / 64 loss=5.865, ppl=58.27, wps=4928.5, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.721, train_wall=593, gb_free=6.1, wall=44222
2022-01-31 21:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:12:55 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.959 | ppl 995.17 | wps 6599.8 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.29
2022-01-31 21:12:55 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 21:12:55 | INFO | train | epoch 107 | loss 5.846 | ppl 57.53 | wps 5059.2 | ups 0.16 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.722 | train_wall 379 | gb_free 6.1 | wall 44540
KL Stats: Epoch 107 Divergences: Uniform: 2.944170568341739 Unigram: 3.662934894409383
2022-01-31 21:12:55 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 21:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:18:07 | INFO | train_inner | epoch 108:     52 / 64 loss=5.842, ppl=57.35, wps=5193.3, ups=0.16, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.726, train_wall=595, gb_free=6.1, wall=44851
2022-01-31 21:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:19:51 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.941 | ppl 983.21 | wps 6572.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.29
2022-01-31 21:19:51 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 21:19:51 | INFO | train | epoch 108 | loss 5.835 | ppl 57.09 | wps 5019.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.736 | train_wall 382 | gb_free 6.1 | wall 44956
KL Stats: Epoch 108 Divergences: Uniform: 2.9456544628261834 Unigram: 3.6713233821613227
2022-01-31 21:19:51 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 21:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:26:44 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.963 | ppl 998.24 | wps 6614.1 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.29
2022-01-31 21:26:44 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 21:26:44 | INFO | train | epoch 109 | loss 5.819 | ppl 56.47 | wps 5054.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.742 | train_wall 379 | gb_free 6.1 | wall 45369
KL Stats: Epoch 109 Divergences: Uniform: 2.9469948557816874 Unigram: 3.686066909625802
2022-01-31 21:26:44 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 21:26:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:29:07 | INFO | train_inner | epoch 110:     24 / 64 loss=5.813, ppl=56.23, wps=4935.9, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.747, train_wall=593, gb_free=6.1, wall=45512
2022-01-31 21:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:33:39 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.052 | ppl 1061.29 | wps 6430.5 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.29
2022-01-31 21:33:39 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 21:33:39 | INFO | train | epoch 110 | loss 5.806 | ppl 55.95 | wps 5038.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.748 | train_wall 380 | gb_free 6.1 | wall 45783
KL Stats: Epoch 110 Divergences: Uniform: 2.9529942547645347 Unigram: 3.688917320143949
2022-01-31 21:33:39 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 21:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:39:39 | INFO | train_inner | epoch 111:     60 / 64 loss=5.805, ppl=55.92, wps=5171, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.758, train_wall=597, gb_free=6.1, wall=46144
2022-01-31 21:40:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:40:35 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.997 | ppl 1021.8 | wps 6536.1 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.29
2022-01-31 21:40:35 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 21:40:35 | INFO | train | epoch 111 | loss 5.793 | ppl 55.43 | wps 5016.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.77 | train_wall 382 | gb_free 6.1 | wall 46200
KL Stats: Epoch 111 Divergences: Uniform: 2.958232169144957 Unigram: 3.712586618136471
2022-01-31 21:40:35 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 21:40:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:47:30 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.038 | ppl 1051.03 | wps 6572.1 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.29
2022-01-31 21:47:30 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 21:47:30 | INFO | train | epoch 112 | loss 5.778 | ppl 54.86 | wps 5036.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.748 | train_wall 381 | gb_free 6.1 | wall 46614
KL Stats: Epoch 112 Divergences: Uniform: 2.956651482749292 Unigram: 3.7232129993938203
2022-01-31 21:47:30 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 21:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:50:41 | INFO | train_inner | epoch 113:     32 / 64 loss=5.766, ppl=54.41, wps=4922.3, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.75, train_wall=594, gb_free=6.1, wall=46806
2022-01-31 21:53:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:54:25 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.065 | ppl 1071.18 | wps 6605.3 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.29
2022-01-31 21:54:25 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 21:54:25 | INFO | train | epoch 113 | loss 5.763 | ppl 54.3 | wps 5036.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.76 | train_wall 381 | gb_free 6.1 | wall 47029
KL Stats: Epoch 113 Divergences: Uniform: 2.970154316013673 Unigram: 3.7323132333785125
2022-01-31 21:54:25 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 21:54:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:01:20 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.032 | ppl 1046.72 | wps 6598.3 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.29
2022-01-31 22:01:20 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 22:01:20 | INFO | train | epoch 114 | loss 5.75 | ppl 53.83 | wps 5024.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.772 | train_wall 382 | gb_free 6.1 | wall 47445
KL Stats: Epoch 114 Divergences: Uniform: 2.9633227946014338 Unigram: 3.7364174323879875
2022-01-31 22:01:20 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 22:01:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:01:44 | INFO | train_inner | epoch 115:      4 / 64 loss=5.763, ppl=54.3, wps=4918.5, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.772, train_wall=595, gb_free=6.1, wall=47469
2022-01-31 22:07:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:08:16 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.052 | ppl 1061.8 | wps 6562.9 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.29
2022-01-31 22:08:16 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 22:08:16 | INFO | train | epoch 115 | loss 5.738 | ppl 53.38 | wps 5028.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.781 | train_wall 381 | gb_free 6.1 | wall 47860
KL Stats: Epoch 115 Divergences: Uniform: 2.9710936173829725 Unigram: 3.7451520825405944
2022-01-31 22:08:16 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 22:08:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:12:15 | INFO | train_inner | epoch 116:     40 / 64 loss=5.724, ppl=52.87, wps=5182.5, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.776, train_wall=596, gb_free=6.1, wall=48099
2022-01-31 22:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:15:10 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.013 | ppl 1033.54 | wps 6573 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.29
2022-01-31 22:15:10 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 22:15:10 | INFO | train | epoch 116 | loss 5.725 | ppl 52.89 | wps 5040.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.774 | train_wall 380 | gb_free 6.1 | wall 48275
KL Stats: Epoch 116 Divergences: Uniform: 2.9725005049944664 Unigram: 3.7522981510763427
2022-01-31 22:15:10 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 22:15:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:21:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:22:05 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.074 | ppl 1077.9 | wps 6509.1 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.29
2022-01-31 22:22:05 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 22:22:05 | INFO | train | epoch 117 | loss 5.715 | ppl 52.53 | wps 5037.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.789 | train_wall 380 | gb_free 6.1 | wall 48689
KL Stats: Epoch 117 Divergences: Uniform: 2.9722236854681903 Unigram: 3.771100226900496
2022-01-31 22:22:05 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 22:22:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:23:16 | INFO | train_inner | epoch 118:     12 / 64 loss=5.72, ppl=52.71, wps=4926.8, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.792, train_wall=593, gb_free=6.1, wall=48761
2022-01-31 22:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:28:59 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.103 | ppl 1099.98 | wps 6542.5 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.29
2022-01-31 22:28:59 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 22:28:59 | INFO | train | epoch 118 | loss 5.702 | ppl 52.07 | wps 5034 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.8 | train_wall 381 | gb_free 6.1 | wall 49104
KL Stats: Epoch 118 Divergences: Uniform: 2.984010811334602 Unigram: 3.7770286188409217
2022-01-31 22:28:59 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 22:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:33:47 | INFO | train_inner | epoch 119:     48 / 64 loss=5.691, ppl=51.68, wps=5185.8, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.795, train_wall=595, gb_free=6.1, wall=49391
2022-01-31 22:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:35:54 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.057 | ppl 1065.31 | wps 6552.3 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.29
2022-01-31 22:35:54 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 22:35:54 | INFO | train | epoch 119 | loss 5.688 | ppl 51.56 | wps 5035.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.802 | train_wall 380 | gb_free 6.1 | wall 49519
KL Stats: Epoch 119 Divergences: Uniform: 2.9861449888426623 Unigram: 3.7924699652105027
2022-01-31 22:35:54 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 22:35:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:42:49 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.094 | ppl 1093.28 | wps 6592 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.29
2022-01-31 22:42:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 22:42:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint120.pt
2022-01-31 22:42:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint120.pt
2022-01-31 22:42:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.094) (writing took 3.277533106505871 seconds)
2022-01-31 22:42:52 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 22:42:52 | INFO | train | epoch 120 | loss 5.678 | ppl 51.2 | wps 5000.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.794 | train_wall 380 | gb_free 6.1 | wall 49936
KL Stats: Epoch 120 Divergences: Uniform: 2.989256713001981 Unigram: 3.7992169731096115
2022-01-31 22:42:52 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 22:42:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:44:51 | INFO | train_inner | epoch 121:     20 / 64 loss=5.679, ppl=51.23, wps=4905.5, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.8, train_wall=593, gb_free=6.1, wall=50056
2022-01-31 22:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:49:46 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.088 | ppl 1088.68 | wps 6564.3 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.29
2022-01-31 22:49:46 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 22:49:46 | INFO | train | epoch 121 | loss 5.667 | ppl 50.8 | wps 5038.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.802 | train_wall 380 | gb_free 6.1 | wall 50351
KL Stats: Epoch 121 Divergences: Uniform: 2.9903880911724228 Unigram: 3.807805982421252
2022-01-31 22:49:46 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 22:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:55:20 | INFO | train_inner | epoch 122:     56 / 64 loss=5.665, ppl=50.73, wps=5194.8, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.812, train_wall=594, gb_free=6.1, wall=50685
2022-01-31 22:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:56:40 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.039 | ppl 1052.15 | wps 6585.3 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.29
2022-01-31 22:56:40 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 22:56:40 | INFO | train | epoch 122 | loss 5.657 | ppl 50.44 | wps 5051.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.822 | train_wall 379 | gb_free 6.1 | wall 50764
KL Stats: Epoch 122 Divergences: Uniform: 2.996788647457382 Unigram: 3.8190911733675574
2022-01-31 22:56:40 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 22:56:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:03:34 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.127 | ppl 1118.49 | wps 6556.4 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.29
2022-01-31 23:03:34 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 23:03:34 | INFO | train | epoch 123 | loss 5.643 | ppl 49.99 | wps 5039.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.804 | train_wall 380 | gb_free 6.1 | wall 51179
KL Stats: Epoch 123 Divergences: Uniform: 2.996793557737226 Unigram: 3.8350295237419716
2022-01-31 23:03:34 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 23:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:06:22 | INFO | train_inner | epoch 124:     28 / 64 loss=5.637, ppl=49.76, wps=4930.6, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.806, train_wall=593, gb_free=6.1, wall=51346
2022-01-31 23:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:10:29 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.057 | ppl 1065.51 | wps 6493.5 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.29
2022-01-31 23:10:29 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 23:10:29 | INFO | train | epoch 124 | loss 5.634 | ppl 49.66 | wps 5039.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.828 | train_wall 380 | gb_free 6.1 | wall 51593
KL Stats: Epoch 124 Divergences: Uniform: 2.9909709621629235 Unigram: 3.8277534898841745
2022-01-31 23:10:29 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 23:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:16:50 | INFO | train_inner | epoch 125:     64 / 64 loss=5.637, ppl=49.76, wps=5185, ups=0.16, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.833, train_wall=594, gb_free=6.1, wall=51975
2022-01-31 23:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:17:23 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.106 | ppl 1102.37 | wps 6576.3 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.29
2022-01-31 23:17:23 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 23:17:23 | INFO | train | epoch 125 | loss 5.622 | ppl 49.26 | wps 5036.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.827 | train_wall 381 | gb_free 6.1 | wall 52008
KL Stats: Epoch 125 Divergences: Uniform: 2.998012022288492 Unigram: 3.8434956307629187
2022-01-31 23:17:23 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 23:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:23:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:24:17 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.118 | ppl 1111.02 | wps 6575.2 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.29
2022-01-31 23:24:17 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 23:24:17 | INFO | train | epoch 126 | loss 5.611 | ppl 48.88 | wps 5046.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.814 | train_wall 380 | gb_free 6.1 | wall 52422
KL Stats: Epoch 126 Divergences: Uniform: 3.0052412037737253 Unigram: 3.854848321786839
2022-01-31 23:24:17 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 23:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:27:53 | INFO | train_inner | epoch 127:     36 / 64 loss=5.599, ppl=48.49, wps=4933.7, ups=0.15, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.832, train_wall=594, gb_free=6.1, wall=52637
2022-01-31 23:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:31:12 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.102 | ppl 1098.67 | wps 6576.1 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.29
2022-01-31 23:31:12 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 23:31:12 | INFO | train | epoch 127 | loss 5.602 | ppl 48.57 | wps 5035.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.842 | train_wall 381 | gb_free 6.1 | wall 52837
KL Stats: Epoch 127 Divergences: Uniform: 3.0059959567815424 Unigram: 3.861290193059103
2022-01-31 23:31:12 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 23:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:38:06 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.125 | ppl 1116.66 | wps 6539.8 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.29
2022-01-31 23:38:06 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 23:38:06 | INFO | train | epoch 128 | loss 5.591 | ppl 48.2 | wps 5043.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.844 | train_wall 380 | gb_free 6.1 | wall 53251
KL Stats: Epoch 128 Divergences: Uniform: 3.0055516493145857 Unigram: 3.8689075788285434
2022-01-31 23:38:06 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 23:38:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:38:54 | INFO | train_inner | epoch 129:      8 / 64 loss=5.598, ppl=48.45, wps=4928.4, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.838, train_wall=593, gb_free=6.1, wall=53299
2022-01-31 23:44:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:45:00 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.124 | ppl 1115.58 | wps 6578 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.29
2022-01-31 23:45:00 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 23:45:00 | INFO | train | epoch 129 | loss 5.584 | ppl 47.98 | wps 5044.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.854 | train_wall 380 | gb_free 6.1 | wall 53665
KL Stats: Epoch 129 Divergences: Uniform: 3.002639358222511 Unigram: 3.877890855219435
2022-01-31 23:45:00 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 23:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:49:23 | INFO | train_inner | epoch 130:     44 / 64 loss=5.571, ppl=47.55, wps=5194, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.845, train_wall=595, gb_free=6.1, wall=53928
2022-01-31 23:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:51:55 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.128 | ppl 1118.85 | wps 6575.1 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.29
2022-01-31 23:51:55 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 23:51:55 | INFO | train | epoch 130 | loss 5.571 | ppl 47.53 | wps 5040.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.841 | train_wall 380 | gb_free 6.1 | wall 54079
KL Stats: Epoch 130 Divergences: Uniform: 3.008637856865691 Unigram: 3.888506879184281
2022-01-31 23:51:55 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 23:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:58:49 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.099 | ppl 1096.83 | wps 6558.4 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.29
2022-01-31 23:58:49 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 23:58:49 | INFO | train | epoch 131 | loss 5.563 | ppl 47.27 | wps 5042.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.86 | train_wall 380 | gb_free 6.1 | wall 54493
KL Stats: Epoch 131 Divergences: Uniform: 3.014075638398138 Unigram: 3.892896715503664
2022-01-31 23:58:49 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 23:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:00:24 | INFO | train_inner | epoch 132:     16 / 64 loss=5.566, ppl=47.37, wps=4931.1, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.859, train_wall=593, gb_free=6.1, wall=54589
2022-02-01 00:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:05:43 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.128 | ppl 1119.28 | wps 6565.4 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.29
2022-02-01 00:05:43 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-01 00:05:43 | INFO | train | epoch 132 | loss 5.553 | ppl 46.96 | wps 5042.7 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.872 | train_wall 380 | gb_free 6.1 | wall 54908
KL Stats: Epoch 132 Divergences: Uniform: 3.01276792201581 Unigram: 3.9087337620037164
2022-02-01 00:05:43 | INFO | fairseq.trainer | begin training epoch 133
2022-02-01 00:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:10:54 | INFO | train_inner | epoch 133:     52 / 64 loss=5.547, ppl=46.77, wps=5193.5, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.872, train_wall=595, gb_free=6.1, wall=55218
2022-02-01 00:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:12:37 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.095 | ppl 1093.75 | wps 6598.6 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.29
2022-02-01 00:12:37 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-01 00:12:37 | INFO | train | epoch 133 | loss 5.542 | ppl 46.6 | wps 5047.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.871 | train_wall 380 | gb_free 6.1 | wall 55321
KL Stats: Epoch 133 Divergences: Uniform: 3.0247023631560235 Unigram: 3.9125850140334126
2022-02-01 00:12:37 | INFO | fairseq.trainer | begin training epoch 134
2022-02-01 00:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:19:31 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.213 | ppl 1187.23 | wps 6584.9 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.29
2022-02-01 00:19:31 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-01 00:19:31 | INFO | train | epoch 134 | loss 5.534 | ppl 46.35 | wps 5045.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.901 | train_wall 380 | gb_free 6.1 | wall 55735
KL Stats: Epoch 134 Divergences: Uniform: 3.015347536859965 Unigram: 3.918390897978585
2022-02-01 00:19:31 | INFO | fairseq.trainer | begin training epoch 135
2022-02-01 00:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:21:54 | INFO | train_inner | epoch 135:     24 / 64 loss=5.533, ppl=46.3, wps=4932.7, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.892, train_wall=593, gb_free=6.1, wall=55879
2022-02-01 00:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:26:25 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.154 | ppl 1138.99 | wps 6592.5 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.29
2022-02-01 00:26:25 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-01 00:26:25 | INFO | train | epoch 135 | loss 5.524 | ppl 46.03 | wps 5037.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.879 | train_wall 381 | gb_free 6.1 | wall 56150
KL Stats: Epoch 135 Divergences: Uniform: 3.021054618791427 Unigram: 3.929158523143052
2022-02-01 00:26:25 | INFO | fairseq.trainer | begin training epoch 136
2022-02-01 00:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:32:24 | INFO | train_inner | epoch 136:     60 / 64 loss=5.525, ppl=46.05, wps=5190.8, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.886, train_wall=595, gb_free=6.1, wall=56509
2022-02-01 00:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:33:20 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.168 | ppl 1150.12 | wps 6584.5 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.29
2022-02-01 00:33:20 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-01 00:33:20 | INFO | train | epoch 136 | loss 5.516 | ppl 45.75 | wps 5041.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.889 | train_wall 380 | gb_free 6.1 | wall 56564
KL Stats: Epoch 136 Divergences: Uniform: 3.0212329563118856 Unigram: 3.933462528562313
2022-02-01 00:33:20 | INFO | fairseq.trainer | begin training epoch 137
2022-02-01 00:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:40:15 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.222 | ppl 1194.61 | wps 6540.7 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.29
2022-02-01 00:40:15 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-01 00:40:15 | INFO | train | epoch 137 | loss 5.509 | ppl 45.53 | wps 5026.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.921 | train_wall 381 | gb_free 6.1 | wall 56980
KL Stats: Epoch 137 Divergences: Uniform: 3.023289416453281 Unigram: 3.944449442310223
2022-02-01 00:40:15 | INFO | fairseq.trainer | begin training epoch 138
2022-02-01 00:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:43:26 | INFO | train_inner | epoch 138:     32 / 64 loss=5.499, ppl=45.23, wps=4922.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.903, train_wall=594, gb_free=6.1, wall=57171
2022-02-01 00:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:47:10 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.237 | ppl 1206.99 | wps 6557.9 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.29
2022-02-01 00:47:10 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-01 00:47:10 | INFO | train | epoch 138 | loss 5.497 | ppl 45.16 | wps 5039.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.891 | train_wall 380 | gb_free 6.1 | wall 57394
KL Stats: Epoch 138 Divergences: Uniform: 3.025632021112861 Unigram: 3.946643257903037
2022-02-01 00:47:10 | INFO | fairseq.trainer | begin training epoch 139
2022-02-01 00:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:54:04 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.211 | ppl 1185.54 | wps 6585.4 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.29
2022-02-01 00:54:04 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-01 00:54:04 | INFO | train | epoch 139 | loss 5.488 | ppl 44.88 | wps 5038 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.923 | train_wall 380 | gb_free 6.1 | wall 57809
KL Stats: Epoch 139 Divergences: Uniform: 3.028012962908518 Unigram: 3.9649852330664555
2022-02-01 00:54:04 | INFO | fairseq.trainer | begin training epoch 140
2022-02-01 00:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:54:28 | INFO | train_inner | epoch 140:      4 / 64 loss=5.496, ppl=45.12, wps=4926, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.921, train_wall=594, gb_free=6.1, wall=57833
2022-02-01 01:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:00:59 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.195 | ppl 1171.92 | wps 6542.8 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.29
2022-02-01 01:00:59 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-01 01:00:59 | INFO | train | epoch 140 | loss 5.48 | ppl 44.64 | wps 5042 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.922 | train_wall 380 | gb_free 6.1 | wall 58223
KL Stats: Epoch 140 Divergences: Uniform: 3.027051586497375 Unigram: 3.9706657729675863
2022-02-01 01:00:59 | INFO | fairseq.trainer | begin training epoch 141
2022-02-01 01:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:04:58 | INFO | train_inner | epoch 141:     40 / 64 loss=5.472, ppl=44.39, wps=5190.4, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.924, train_wall=595, gb_free=6.1, wall=58462
2022-02-01 01:07:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:07:53 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.251 | ppl 1218.6 | wps 6597.1 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.29
2022-02-01 01:07:53 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-01 01:07:53 | INFO | train | epoch 141 | loss 5.472 | ppl 44.39 | wps 5043.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.916 | train_wall 380 | gb_free 6.1 | wall 58637
KL Stats: Epoch 141 Divergences: Uniform: 3.033565383459058 Unigram: 3.9799895220949977
2022-02-01 01:07:53 | INFO | fairseq.trainer | begin training epoch 142
2022-02-01 01:07:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:14:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:14:48 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.203 | ppl 1178.51 | wps 6566.9 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.29
2022-02-01 01:14:48 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-01 01:14:48 | INFO | train | epoch 142 | loss 5.464 | ppl 44.14 | wps 5028.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.946 | train_wall 381 | gb_free 6.1 | wall 59053
KL Stats: Epoch 142 Divergences: Uniform: 3.0330811368059276 Unigram: 3.978078231566015
2022-02-01 01:14:48 | INFO | fairseq.trainer | begin training epoch 143
2022-02-01 01:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:16:00 | INFO | train_inner | epoch 143:     12 / 64 loss=5.465, ppl=44.17, wps=4920.7, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.931, train_wall=595, gb_free=6.1, wall=59125
2022-02-01 01:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:21:43 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.191 | ppl 1168.61 | wps 6573 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.29
2022-02-01 01:21:43 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-01 01:21:43 | INFO | train | epoch 143 | loss 5.455 | ppl 43.86 | wps 5028.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.918 | train_wall 381 | gb_free 6.1 | wall 59468
KL Stats: Epoch 143 Divergences: Uniform: 3.04291486221581 Unigram: 3.9888203822397097
2022-02-01 01:21:43 | INFO | fairseq.trainer | begin training epoch 144
2022-02-01 01:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:26:30 | INFO | train_inner | epoch 144:     48 / 64 loss=5.452, ppl=43.79, wps=5187.6, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.915, train_wall=595, gb_free=6.1, wall=59755
2022-02-01 01:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:28:38 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.278 | ppl 1241.81 | wps 6554 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.29
2022-02-01 01:28:38 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-01 01:28:38 | INFO | train | epoch 144 | loss 5.45 | ppl 43.7 | wps 5041.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.917 | train_wall 380 | gb_free 6.1 | wall 59882
KL Stats: Epoch 144 Divergences: Uniform: 3.0339599184814263 Unigram: 3.990451990949594
2022-02-01 01:28:38 | INFO | fairseq.trainer | begin training epoch 145
2022-02-01 01:28:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:35:32 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.215 | ppl 1188.73 | wps 6553.9 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.29
2022-02-01 01:35:32 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-01 01:35:32 | INFO | train | epoch 145 | loss 5.442 | ppl 43.48 | wps 5038.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.945 | train_wall 380 | gb_free 6.1 | wall 60297
KL Stats: Epoch 145 Divergences: Uniform: 3.042607400558072 Unigram: 4.001060286258201
2022-02-01 01:35:32 | INFO | fairseq.trainer | begin training epoch 146
2022-02-01 01:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:37:32 | INFO | train_inner | epoch 146:     20 / 64 loss=5.438, ppl=43.36, wps=4926, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.947, train_wall=594, gb_free=6.1, wall=60417
2022-02-01 01:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:42:27 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.231 | ppl 1201.56 | wps 6561.1 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.29
2022-02-01 01:42:27 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-01 01:42:27 | INFO | train | epoch 146 | loss 5.431 | ppl 43.16 | wps 5038.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.961 | train_wall 380 | gb_free 6.1 | wall 60711
KL Stats: Epoch 146 Divergences: Uniform: 3.03956439491912 Unigram: 4.0042693935602545
2022-02-01 01:42:27 | INFO | fairseq.trainer | begin training epoch 147
2022-02-01 01:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:48:01 | INFO | train_inner | epoch 147:     56 / 64 loss=5.433, ppl=43.21, wps=5197.9, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.969, train_wall=594, gb_free=6.1, wall=61045
2022-02-01 01:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:49:20 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.183 | ppl 1162.53 | wps 6553.8 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.29
2022-02-01 01:49:20 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-01 01:49:20 | INFO | train | epoch 147 | loss 5.424 | ppl 42.94 | wps 5050 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.98 | train_wall 379 | gb_free 6.1 | wall 61125
KL Stats: Epoch 147 Divergences: Uniform: 3.045200730132041 Unigram: 4.01579120177139
2022-02-01 01:49:20 | INFO | fairseq.trainer | begin training epoch 148
2022-02-01 01:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:56:14 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.208 | ppl 1182.65 | wps 6586.7 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.29
2022-02-01 01:56:14 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-01 01:56:14 | INFO | train | epoch 148 | loss 5.417 | ppl 42.71 | wps 5045.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.953 | train_wall 380 | gb_free 6.1 | wall 61539
KL Stats: Epoch 148 Divergences: Uniform: 3.0429937698763845 Unigram: 4.0224635293099595
2022-02-01 01:56:14 | INFO | fairseq.trainer | begin training epoch 149
2022-02-01 01:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:59:02 | INFO | train_inner | epoch 149:     28 / 64 loss=5.412, ppl=42.59, wps=4933, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.957, train_wall=593, gb_free=6.1, wall=61706
2022-02-01 02:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:03:08 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.287 | ppl 1249.06 | wps 6558.4 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.29
2022-02-01 02:03:08 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-01 02:03:08 | INFO | train | epoch 149 | loss 5.411 | ppl 42.55 | wps 5043.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.965 | train_wall 380 | gb_free 6.1 | wall 61953
KL Stats: Epoch 149 Divergences: Uniform: 3.0491225005148572 Unigram: 4.029804365612695
2022-02-01 02:03:08 | INFO | fairseq.trainer | begin training epoch 150
2022-02-01 02:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:09:29 | INFO | train_inner | epoch 150:     64 / 64 loss=5.413, ppl=42.61, wps=5193.7, ups=0.16, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.972, train_wall=593, gb_free=6.1, wall=62334
2022-02-01 02:09:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:10:03 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.286 | ppl 1248.38 | wps 6549.5 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.29
2022-02-01 02:10:03 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-01 02:10:03 | INFO | train | epoch 150 | loss 5.402 | ppl 42.29 | wps 5042.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.97 | train_wall 380 | gb_free 6.1 | wall 62367
KL Stats: Epoch 150 Divergences: Uniform: 3.047466270880227 Unigram: 4.0299796912070125
2022-02-01 02:10:03 | INFO | fairseq.trainer | begin training epoch 151
2022-02-01 02:10:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:16:56 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.223 | ppl 1195.37 | wps 6593.4 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.29
2022-02-01 02:16:56 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-01 02:16:56 | INFO | train | epoch 151 | loss 5.394 | ppl 42.06 | wps 5047.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.997 | train_wall 380 | gb_free 6.1 | wall 62781
KL Stats: Epoch 151 Divergences: Uniform: 3.0434594882418198 Unigram: 4.039476807996849
2022-02-01 02:16:56 | INFO | fairseq.trainer | begin training epoch 152
2022-02-01 02:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:20:32 | INFO | train_inner | epoch 152:     36 / 64 loss=5.381, ppl=41.69, wps=4934.6, ups=0.15, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.995, train_wall=594, gb_free=6.1, wall=62996
2022-02-01 02:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:23:51 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.213 | ppl 1186.53 | wps 6600.8 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.29
2022-02-01 02:23:51 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-01 02:23:51 | INFO | train | epoch 152 | loss 5.388 | ppl 41.86 | wps 5042.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.003 | train_wall 380 | gb_free 6.1 | wall 63195
KL Stats: Epoch 152 Divergences: Uniform: 3.0542965377641687 Unigram: 4.050538004423532
2022-02-01 02:23:51 | INFO | fairseq.trainer | begin training epoch 153
2022-02-01 02:23:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:30:45 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.263 | ppl 1228.88 | wps 6565.4 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.29
2022-02-01 02:30:45 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-01 02:30:45 | INFO | train | epoch 153 | loss 5.379 | ppl 41.62 | wps 5041.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.986 | train_wall 380 | gb_free 6.1 | wall 63609
KL Stats: Epoch 153 Divergences: Uniform: 3.0533656572374936 Unigram: 4.056986386332573
2022-02-01 02:30:45 | INFO | fairseq.trainer | begin training epoch 154
2022-02-01 02:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:31:33 | INFO | train_inner | epoch 154:      8 / 64 loss=5.388, ppl=41.86, wps=4929.4, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.997, train_wall=593, gb_free=6.1, wall=63657
2022-02-01 02:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:37:39 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.282 | ppl 1244.96 | wps 6567.1 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.29
2022-02-01 02:37:39 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-01 02:37:39 | INFO | train | epoch 154 | loss 5.373 | ppl 41.44 | wps 5042.5 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.011 | train_wall 380 | gb_free 6.1 | wall 64024
KL Stats: Epoch 154 Divergences: Uniform: 3.0596152090571267 Unigram: 4.058354967814046
2022-02-01 02:37:39 | INFO | fairseq.trainer | begin training epoch 155
2022-02-01 02:37:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:42:02 | INFO | train_inner | epoch 155:     44 / 64 loss=5.365, ppl=41.2, wps=5195.4, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.994, train_wall=594, gb_free=6.1, wall=64287
2022-02-01 02:44:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:44:33 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.261 | ppl 1226.66 | wps 6553.6 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.29
2022-02-01 02:44:33 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-01 02:44:33 | INFO | train | epoch 155 | loss 5.367 | ppl 41.28 | wps 5044.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.002 | train_wall 380 | gb_free 6.1 | wall 64438
KL Stats: Epoch 155 Divergences: Uniform: 3.0548763614837404 Unigram: 4.070180938448104
2022-02-01 02:44:33 | INFO | fairseq.trainer | begin training epoch 156
2022-02-01 02:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:51:28 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.271 | ppl 1235.58 | wps 6590.2 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.29
2022-02-01 02:51:28 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-01 02:51:28 | INFO | train | epoch 156 | loss 5.36 | ppl 41.06 | wps 5031.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.034 | train_wall 381 | gb_free 6.1 | wall 64853
KL Stats: Epoch 156 Divergences: Uniform: 3.056439922483455 Unigram: 4.069101174672444
2022-02-01 02:51:28 | INFO | fairseq.trainer | begin training epoch 157
2022-02-01 02:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:53:04 | INFO | train_inner | epoch 157:     16 / 64 loss=5.366, ppl=41.24, wps=4923.6, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.036, train_wall=594, gb_free=6.1, wall=64949
2022-02-01 02:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:58:23 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.232 | ppl 1202.85 | wps 6592 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.29
2022-02-01 02:58:23 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-01 02:58:23 | INFO | train | epoch 157 | loss 5.352 | ppl 40.85 | wps 5041.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.022 | train_wall 380 | gb_free 6.1 | wall 65267
KL Stats: Epoch 157 Divergences: Uniform: 3.0608715626910903 Unigram: 4.079767542947836
2022-02-01 02:58:23 | INFO | fairseq.trainer | begin training epoch 158
2022-02-01 02:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:03:34 | INFO | train_inner | epoch 158:     52 / 64 loss=5.346, ppl=40.67, wps=5191.8, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.014, train_wall=595, gb_free=6.1, wall=65578
2022-02-01 03:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:05:17 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.288 | ppl 1250.01 | wps 6576.7 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.29
2022-02-01 03:05:17 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 03:05:17 | INFO | train | epoch 158 | loss 5.346 | ppl 40.68 | wps 5039.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.016 | train_wall 380 | gb_free 6.1 | wall 65682
KL Stats: Epoch 158 Divergences: Uniform: 3.0558533945773583 Unigram: 4.086374289821213
2022-02-01 03:05:17 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 03:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:12:11 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.326 | ppl 1283.23 | wps 6572.5 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.29
2022-02-01 03:12:11 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 03:12:11 | INFO | train | epoch 159 | loss 5.34 | ppl 40.51 | wps 5044.9 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.054 | train_wall 380 | gb_free 6.1 | wall 66096
KL Stats: Epoch 159 Divergences: Uniform: 3.0549733275791513 Unigram: 4.093062282084784
2022-02-01 03:12:11 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 03:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:14:34 | INFO | train_inner | epoch 160:     24 / 64 loss=5.339, ppl=40.48, wps=4932.6, ups=0.15, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.058, train_wall=593, gb_free=6.1, wall=66239
2022-02-01 03:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:19:05 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.269 | ppl 1234.01 | wps 6567 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.29
2022-02-01 03:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 03:19:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint160.pt
2022-02-01 03:19:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint160.pt
2022-02-01 03:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.269) (writing took 3.254254885017872 seconds)
2022-02-01 03:19:08 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 03:19:08 | INFO | train | epoch 160 | loss 5.333 | ppl 40.31 | wps 5005.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.046 | train_wall 380 | gb_free 6.1 | wall 66513
KL Stats: Epoch 160 Divergences: Uniform: 3.0616603969628158 Unigram: 4.100983607626151
2022-02-01 03:19:08 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 03:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:25:07 | INFO | train_inner | epoch 161:     60 / 64 loss=5.334, ppl=40.34, wps=5164.5, ups=0.16, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.04, train_wall=595, gb_free=6.1, wall=66872
2022-02-01 03:25:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:26:03 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.24 | ppl 1209.22 | wps 6554.9 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.29
2022-02-01 03:26:03 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 03:26:03 | INFO | train | epoch 161 | loss 5.327 | ppl 40.14 | wps 5036.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.041 | train_wall 380 | gb_free 6.1 | wall 66928
KL Stats: Epoch 161 Divergences: Uniform: 3.0672003823918232 Unigram: 4.102704337899334
2022-02-01 03:26:03 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 03:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:32:57 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.242 | ppl 1211.15 | wps 6567.6 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.29
2022-02-01 03:32:57 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 03:32:57 | INFO | train | epoch 162 | loss 5.319 | ppl 39.92 | wps 5040.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.039 | train_wall 380 | gb_free 6.1 | wall 67342
KL Stats: Epoch 162 Divergences: Uniform: 3.068637760702473 Unigram: 4.110482323820518
2022-02-01 03:32:57 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 03:32:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:36:08 | INFO | train_inner | epoch 163:     32 / 64 loss=5.306, ppl=39.57, wps=4929.7, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.044, train_wall=593, gb_free=6.1, wall=67533
2022-02-01 03:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:39:51 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.387 | ppl 1338.81 | wps 6600.5 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.29
2022-02-01 03:39:51 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 03:39:51 | INFO | train | epoch 163 | loss 5.316 | ppl 39.83 | wps 5044.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.056 | train_wall 380 | gb_free 6.1 | wall 67756
KL Stats: Epoch 163 Divergences: Uniform: 3.0683272439429246 Unigram: 4.117609959309015
2022-02-01 03:39:51 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 03:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:46:46 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.279 | ppl 1242.12 | wps 6560.8 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.29
2022-02-01 03:46:46 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 03:46:46 | INFO | train | epoch 164 | loss 5.308 | ppl 39.61 | wps 5036.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.07 | train_wall 380 | gb_free 6.1 | wall 68171
KL Stats: Epoch 164 Divergences: Uniform: 3.0633462307138863 Unigram: 4.121737585562999
2022-02-01 03:46:46 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 03:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:47:10 | INFO | train_inner | epoch 165:      4 / 64 loss=5.323, ppl=40.02, wps=4927.2, ups=0.15, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.065, train_wall=594, gb_free=6.1, wall=68195
2022-02-01 03:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:53:40 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.389 | ppl 1340.62 | wps 6592.3 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.29
2022-02-01 03:53:40 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 03:53:40 | INFO | train | epoch 165 | loss 5.3 | ppl 39.39 | wps 5043.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.058 | train_wall 380 | gb_free 6.1 | wall 68585
KL Stats: Epoch 165 Divergences: Uniform: 3.0696356733587122 Unigram: 4.132712199113341
2022-02-01 03:53:40 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 03:53:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:57:39 | INFO | train_inner | epoch 166:     40 / 64 loss=5.293, ppl=39.2, wps=5192.6, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.057, train_wall=595, gb_free=6.1, wall=68824
2022-02-01 04:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:00:35 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.191 | ppl 1168.97 | wps 6585.4 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.29
2022-02-01 04:00:35 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 04:00:35 | INFO | train | epoch 166 | loss 5.295 | ppl 39.27 | wps 5040.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.075 | train_wall 380 | gb_free 6.1 | wall 68999
KL Stats: Epoch 166 Divergences: Uniform: 3.0707235288683488 Unigram: 4.136854159265849
2022-02-01 04:00:35 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 04:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:07:28 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.205 | ppl 1180.29 | wps 6556.6 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.29
2022-02-01 04:07:28 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 04:07:28 | INFO | train | epoch 167 | loss 5.29 | ppl 39.13 | wps 5047 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.092 | train_wall 380 | gb_free 6.1 | wall 69413
KL Stats: Epoch 167 Divergences: Uniform: 3.0688495478310482 Unigram: 4.136527112892242
2022-02-01 04:07:28 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 04:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:08:40 | INFO | train_inner | epoch 168:     12 / 64 loss=5.292, ppl=39.18, wps=4934.9, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.097, train_wall=593, gb_free=6.1, wall=69485
2022-02-01 04:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:14:23 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.294 | ppl 1255.7 | wps 6552.8 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.29
2022-02-01 04:14:23 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 04:14:23 | INFO | train | epoch 168 | loss 5.284 | ppl 38.96 | wps 5043.2 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.11 | train_wall 380 | gb_free 6.1 | wall 69827
KL Stats: Epoch 168 Divergences: Uniform: 3.0764219447659538 Unigram: 4.141364380141867
2022-02-01 04:14:23 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 04:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:19:09 | INFO | train_inner | epoch 169:     48 / 64 loss=5.283, ppl=38.94, wps=5194.6, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.106, train_wall=594, gb_free=6.1, wall=70114
2022-02-01 04:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:21:16 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.264 | ppl 1229.46 | wps 6584.6 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.29
2022-02-01 04:21:16 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 04:21:16 | INFO | train | epoch 169 | loss 5.278 | ppl 38.8 | wps 5046.1 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.091 | train_wall 380 | gb_free 6.1 | wall 70241
KL Stats: Epoch 169 Divergences: Uniform: 3.0743679720933206 Unigram: 4.148062016241189
2022-02-01 04:21:16 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 04:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:27:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:28:11 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.318 | ppl 1276.73 | wps 6561.1 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.29
2022-02-01 04:28:11 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 04:28:11 | INFO | train | epoch 170 | loss 5.272 | ppl 38.64 | wps 5042.6 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.13 | train_wall 380 | gb_free 6.1 | wall 70655
KL Stats: Epoch 170 Divergences: Uniform: 3.076272813574346 Unigram: 4.152342232925544
2022-02-01 04:28:11 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 04:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:30:11 | INFO | train_inner | epoch 171:     20 / 64 loss=5.267, ppl=38.51, wps=4925.1, ups=0.15, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.133, train_wall=594, gb_free=6.1, wall=70776
2022-02-01 04:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:35:06 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.268 | ppl 1233.32 | wps 6560.7 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.29
2022-02-01 04:35:06 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 04:35:06 | INFO | train | epoch 171 | loss 5.268 | ppl 38.52 | wps 5026.3 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.148 | train_wall 381 | gb_free 6.1 | wall 71071
KL Stats: Epoch 171 Divergences: Uniform: 3.07382952283342 Unigram: 4.158352140104088
2022-02-01 04:35:06 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 04:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:40:40 | INFO | train_inner | epoch 172:     56 / 64 loss=5.269, ppl=38.56, wps=5192.1, ups=0.16, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.117, train_wall=595, gb_free=6.1, wall=71405
2022-02-01 04:41:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:42:00 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.295 | ppl 1256.31 | wps 6584.6 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.29
2022-02-01 04:42:00 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 04:42:00 | INFO | train | epoch 172 | loss 5.259 | ppl 38.3 | wps 5048.4 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.111 | train_wall 380 | gb_free 6.1 | wall 71484
KL Stats: Epoch 172 Divergences: Uniform: 3.0753096500291752 Unigram: 4.166689883747262
2022-02-01 04:42:00 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 04:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:48:54 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.232 | ppl 1202.99 | wps 6574 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.29
2022-02-01 04:48:54 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 04:48:54 | INFO | train | epoch 173 | loss 5.256 | ppl 38.22 | wps 5043.8 | ups 0.15 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.162 | train_wall 380 | gb_free 6.1 | wall 71899
KL Stats: Epoch 173 Divergences: Uniform: 3.07695695849138 Unigram: 4.16835253364607
2022-02-01 04:48:54 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 04:48:54 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g2-12>
Subject: Job 202993487: <w2_jelinek_0.1_0.0_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.1_0.0_0.9_#1> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:06:45 2022
Job was executed on host(s) <eu-g2-12>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:07:02 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:07:02 2022
Terminated at Thu Feb  3 02:07:16 2022
Results reported at Thu Feb  3 02:07:16 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.1, 0.0, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 1002 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72919.00 sec.
    Max Memory :                                 5047 MB
    Average Memory :                             2638.61 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14953.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72014 sec.
    Turnaround time :                            72031 sec.

The output (if any) follows:

2022-02-02 06:07:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1002, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1002, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.1, 0.0, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:07:07 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:07:08 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1446/36718 [00:00<00:02, 14445.65it/s]  8%|▊         | 2891/36718 [00:00<00:02, 13841.19it/s] 12%|█▏        | 4490/36718 [00:00<00:02, 14792.40it/s] 17%|█▋        | 6147/36718 [00:00<00:01, 15477.46it/s] 21%|██        | 7698/36718 [00:00<00:01, 14697.49it/s] 25%|██▍       | 9176/36718 [00:00<00:01, 14457.49it/s] 29%|██▉       | 10627/36718 [00:00<00:01, 14407.28it/s] 33%|███▎      | 12125/36718 [00:00<00:01, 14581.06it/s] 37%|███▋      | 13620/36718 [00:00<00:01, 14691.13it/s] 41%|████      | 15098/36718 [00:01<00:01, 14717.92it/s] 45%|████▌     | 16572/36718 [00:01<00:01, 14291.06it/s] 49%|████▉     | 18045/36718 [00:01<00:01, 14419.28it/s] 53%|█████▎    | 19642/36718 [00:01<00:01, 14869.67it/s] 58%|█████▊    | 21132/36718 [00:01<00:01, 14602.39it/s] 62%|██████▏   | 22595/36718 [00:01<00:00, 14514.33it/s] 66%|██████▌   | 24230/36718 [00:01<00:00, 15053.64it/s] 70%|███████   | 25842/36718 [00:01<00:00, 15360.92it/s] 75%|███████▍  | 27381/36718 [00:01<00:00, 14599.04it/s] 79%|███████▊  | 28902/36718 [00:01<00:00, 14768.71it/s] 83%|████████▎ | 30386/36718 [00:02<00:00, 14637.88it/s] 87%|████████▋ | 31855/36718 [00:02<00:00, 14192.82it/s] 91%|█████████ | 33280/36718 [00:02<00:00, 13798.20it/s] 95%|█████████▍| 34855/36718 [00:02<00:00, 14353.37it/s] 99%|█████████▉| 36297/36718 [00:02<00:00, 14200.78it/s]100%|██████████| 36718/36718 [00:02<00:00, 14530.13it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2767/36718 [00:00<00:01, 27666.53it/s] 16%|█▋        | 5984/36718 [00:00<00:01, 30307.69it/s] 25%|██▍       | 9015/36718 [00:00<00:00, 28921.59it/s] 32%|███▏      | 11915/36718 [00:00<00:00, 28751.30it/s] 40%|████      | 14815/36718 [00:00<00:00, 28837.34it/s] 48%|████▊     | 17702/36718 [00:00<00:00, 28534.95it/s] 56%|█████▋    | 20697/36718 [00:00<00:00, 28986.27it/s] 64%|██████▍   | 23622/36718 [00:00<00:00, 29065.30it/s] 73%|███████▎  | 26642/36718 [00:00<00:00, 29411.06it/s] 81%|████████  | 29585/36718 [00:01<00:00, 29043.53it/s] 88%|████████▊ | 32492/36718 [00:01<00:00, 28416.10it/s] 96%|█████████▌| 35338/36718 [00:01<00:00, 28326.62it/s]100%|██████████| 36718/36718 [00:01<00:00, 28744.43it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 206.60it/s]2022-02-02 06:07:16 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:07:16 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:07:16 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:07:16 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:07:16 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:07:16 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:07:16 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:07:16 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:07:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:16 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:07:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:07:16 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:07:16 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:07:16 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint_last.pt
2022-02-02 06:07:16 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint_last.pt
2022-02-02 06:07:16 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:07:16 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:07:16 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:07:16 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:07:16 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:12:45 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.682 | ppl 26282.6 | wps 8771.1 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:12:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:12:45 | INFO | train | epoch 001 | loss 16.036 | ppl 67192.5 | wps 6363.9 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.159 | train_wall 303 | gb_free 6.1 | wall 329
KL Stats: Epoch 1 Divergences: Uniform: 0.5191044836535329 Unigram: 3.623896338492037
2022-02-02 06:12:45 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:15:36 | INFO | train_inner | epoch 002:     36 / 64 loss=15.527, ppl=47203.3, wps=6546.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.608, train_wall=473, gb_free=6.1, wall=500
2022-02-02 06:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:18:13 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.657 | ppl 12915.4 | wps 8755.8 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:18:13 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:18:13 | INFO | train | epoch 002 | loss 14.403 | ppl 21668.4 | wps 6370.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.532 | train_wall 302 | gb_free 6.1 | wall 657
KL Stats: Epoch 2 Divergences: Uniform: 0.5239137664033845 Unigram: 2.401253144422532
2022-02-02 06:18:13 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:23:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:23:41 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.826 | ppl 7263.75 | wps 8740.3 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:23:41 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:23:41 | INFO | train | epoch 003 | loss 13.484 | ppl 11459.5 | wps 6367.8 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.247 | train_wall 302 | gb_free 6.1 | wall 985
KL Stats: Epoch 3 Divergences: Uniform: 0.5101145976287124 Unigram: 1.7072079690678406
2022-02-02 06:23:41 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:24:19 | INFO | train_inner | epoch 004:      8 / 64 loss=13.62, ppl=12592.1, wps=6235.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.28, train_wall=471, gb_free=6.1, wall=1023
2022-02-02 06:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:29:09 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.02 | ppl 4153.01 | wps 8760.6 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:29:09 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:29:09 | INFO | train | epoch 004 | loss 12.544 | ppl 5972.52 | wps 6377.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.943 | train_wall 302 | gb_free 6.1 | wall 1313
KL Stats: Epoch 4 Divergences: Uniform: 0.6111369363689126 Unigram: 1.1014316747625617
2022-02-02 06:29:09 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:32:38 | INFO | train_inner | epoch 005:     44 / 64 loss=12.208, ppl=4730.1, wps=6555.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.827, train_wall=472, gb_free=6.1, wall=1522
2022-02-02 06:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:34:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.499 | ppl 2894.54 | wps 8714.8 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:34:37 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:34:37 | INFO | train | epoch 005 | loss 11.773 | ppl 3500.56 | wps 6367.8 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.682 | train_wall 302 | gb_free 6.1 | wall 1641
KL Stats: Epoch 5 Divergences: Uniform: 0.8478543766329038 Unigram: 0.6674941455952813
2022-02-02 06:34:37 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:40:05 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.27 | ppl 2469.61 | wps 8729.9 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:40:05 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:40:05 | INFO | train | epoch 006 | loss 11.354 | ppl 2617.51 | wps 6361.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.577 | train_wall 302 | gb_free 6.1 | wall 1969
KL Stats: Epoch 6 Divergences: Uniform: 1.1397428587178258 Unigram: 0.46286764504165584
2022-02-02 06:40:05 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:41:21 | INFO | train_inner | epoch 007:     16 / 64 loss=11.373, ppl=2652.5, wps=6228.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.579, train_wall=472, gb_free=6.1, wall=2045
2022-02-02 06:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:45:33 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.132 | ppl 2244.22 | wps 8741.2 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:45:33 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:45:33 | INFO | train | epoch 007 | loss 11.152 | ppl 2276.21 | wps 6367.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.516 | train_wall 302 | gb_free 6.1 | wall 2297
KL Stats: Epoch 7 Divergences: Uniform: 1.364751007733639 Unigram: 0.470278827471041
2022-02-02 06:45:33 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:49:40 | INFO | train_inner | epoch 008:     52 / 64 loss=11.091, ppl=2180.7, wps=6550.4, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.513, train_wall=473, gb_free=6.1, wall=2544
2022-02-02 06:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:51:01 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.023 | ppl 2080.94 | wps 8745.6 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:51:01 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:51:01 | INFO | train | epoch 008 | loss 11.038 | ppl 2102.64 | wps 6372.1 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.515 | train_wall 302 | gb_free 6.1 | wall 2625
KL Stats: Epoch 8 Divergences: Uniform: 1.4772186405225907 Unigram: 0.5482095197683116
2022-02-02 06:51:01 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:56:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:56:29 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.901 | ppl 1912.53 | wps 8732.5 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 06:56:29 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 06:56:29 | INFO | train | epoch 009 | loss 10.934 | ppl 1956.06 | wps 6368.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.527 | train_wall 302 | gb_free 6.1 | wall 2953
KL Stats: Epoch 9 Divergences: Uniform: 1.5272562378943892 Unigram: 0.6473978381658521
2022-02-02 06:56:29 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 06:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:58:23 | INFO | train_inner | epoch 010:     24 / 64 loss=10.92, ppl=1936.9, wps=6235.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.512, train_wall=472, gb_free=6.1, wall=3067
2022-02-02 07:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:01:57 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.802 | ppl 1784.98 | wps 8746.1 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:01:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:01:57 | INFO | train | epoch 010 | loss 10.82 | ppl 1808.13 | wps 6369 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.485 | train_wall 302 | gb_free 6.1 | wall 3281
KL Stats: Epoch 10 Divergences: Uniform: 1.5526197900573149 Unigram: 0.7625852955006728
2022-02-02 07:01:57 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:06:42 | INFO | train_inner | epoch 011:     60 / 64 loss=10.747, ppl=1718.6, wps=6550.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.514, train_wall=473, gb_free=6.1, wall=3566
2022-02-02 07:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:07:25 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.694 | ppl 1657.14 | wps 8746.1 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:07:25 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:07:25 | INFO | train | epoch 011 | loss 10.704 | ppl 1668.56 | wps 6369.9 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.523 | train_wall 302 | gb_free 6.1 | wall 3609
KL Stats: Epoch 11 Divergences: Uniform: 1.5679296251937014 Unigram: 0.8831083943353882
2022-02-02 07:07:25 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:07:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:12:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:12:53 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.581 | ppl 1531.78 | wps 8742.8 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:12:53 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:12:53 | INFO | train | epoch 012 | loss 10.586 | ppl 1536.78 | wps 6367 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.487 | train_wall 302 | gb_free 6.1 | wall 3937
KL Stats: Epoch 12 Divergences: Uniform: 1.5847649293849588 Unigram: 0.9920430283942224
2022-02-02 07:12:53 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:15:25 | INFO | train_inner | epoch 013:     32 / 64 loss=10.559, ppl=1509.05, wps=6230.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.486, train_wall=472, gb_free=6.1, wall=4089
2022-02-02 07:17:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:18:22 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.484 | ppl 1432.36 | wps 8746.8 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:18:22 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:18:22 | INFO | train | epoch 013 | loss 10.47 | ppl 1418.01 | wps 6348.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.492 | train_wall 303 | gb_free 6.1 | wall 4266
KL Stats: Epoch 13 Divergences: Uniform: 1.605927768940932 Unigram: 1.089806741573945
2022-02-02 07:18:22 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:18:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:23:50 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.415 | ppl 1365.64 | wps 8736.9 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:23:50 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:23:50 | INFO | train | epoch 014 | loss 10.356 | ppl 1310.87 | wps 6363 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.526 | train_wall 302 | gb_free 6.1 | wall 4594
KL Stats: Epoch 14 Divergences: Uniform: 1.6329685035304287 Unigram: 1.1814312006281156
2022-02-02 07:23:50 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:24:09 | INFO | train_inner | epoch 015:      4 / 64 loss=10.382, ppl=1334.51, wps=6222.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.516, train_wall=473, gb_free=6.1, wall=4613
2022-02-02 07:28:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:29:18 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.309 | ppl 1268.29 | wps 8738.8 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:29:18 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:29:18 | INFO | train | epoch 015 | loss 10.243 | ppl 1211.5 | wps 6358.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.489 | train_wall 303 | gb_free 6.1 | wall 4922
KL Stats: Epoch 15 Divergences: Uniform: 1.6627660764888081 Unigram: 1.2608443855234004
2022-02-02 07:29:18 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:32:29 | INFO | train_inner | epoch 016:     40 / 64 loss=10.2, ppl=1176.42, wps=6541.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.498, train_wall=473, gb_free=6.1, wall=5113
2022-02-02 07:34:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:34:46 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.227 | ppl 1198.47 | wps 8754.2 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:34:46 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:34:46 | INFO | train | epoch 016 | loss 10.13 | ppl 1120.66 | wps 6367.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.507 | train_wall 302 | gb_free 6.1 | wall 5250
KL Stats: Epoch 16 Divergences: Uniform: 1.6875626977369407 Unigram: 1.3397100243206508
2022-02-02 07:34:46 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:34:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:40:15 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.143 | ppl 1131.09 | wps 8754.8 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:40:15 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:40:15 | INFO | train | epoch 017 | loss 10.023 | ppl 1040.47 | wps 6360.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.531 | train_wall 303 | gb_free 6.1 | wall 5579
KL Stats: Epoch 17 Divergences: Uniform: 1.7211348367065415 Unigram: 1.4146357985850815
2022-02-02 07:40:15 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:41:12 | INFO | train_inner | epoch 018:     12 / 64 loss=10.032, ppl=1047.1, wps=6229.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.525, train_wall=472, gb_free=6.1, wall=5636
2022-02-02 07:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:45:43 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.074 | ppl 1077.53 | wps 8740.4 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:45:43 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:45:43 | INFO | train | epoch 018 | loss 9.92 | ppl 968.47 | wps 6367.6 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.54 | train_wall 302 | gb_free 6.1 | wall 5907
KL Stats: Epoch 18 Divergences: Uniform: 1.7516421968017322 Unigram: 1.4830268475409354
2022-02-02 07:45:43 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:49:31 | INFO | train_inner | epoch 019:     48 / 64 loss=9.869, ppl=934.89, wps=6547.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.534, train_wall=473, gb_free=6.1, wall=6135
2022-02-02 07:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:51:11 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.008 | ppl 1029.39 | wps 8746.1 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 07:51:11 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 07:51:11 | INFO | train | epoch 019 | loss 9.818 | ppl 902.55 | wps 6366.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.536 | train_wall 302 | gb_free 6.1 | wall 6235
KL Stats: Epoch 19 Divergences: Uniform: 1.7834268201471593 Unigram: 1.5469211846312259
2022-02-02 07:51:11 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 07:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:56:39 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.962 | ppl 997.24 | wps 8744.5 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 07:56:39 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 07:56:39 | INFO | train | epoch 020 | loss 9.724 | ppl 845.47 | wps 6366.1 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.513 | train_wall 302 | gb_free 6.1 | wall 6563
KL Stats: Epoch 20 Divergences: Uniform: 1.8082009304696807 Unigram: 1.6115023590330013
2022-02-02 07:56:39 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 07:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:58:14 | INFO | train_inner | epoch 021:     20 / 64 loss=9.725, ppl=846.1, wps=6233.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.529, train_wall=472, gb_free=6.1, wall=6658
2022-02-02 08:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:02:06 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.88 | ppl 942.07 | wps 8777.1 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:02:06 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:02:06 | INFO | train | epoch 021 | loss 9.633 | ppl 793.8 | wps 6382.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.542 | train_wall 302 | gb_free 6.1 | wall 6890
KL Stats: Epoch 21 Divergences: Uniform: 1.8353596636310345 Unigram: 1.6673289696692997
2022-02-02 08:02:06 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:02:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:06:32 | INFO | train_inner | epoch 022:     56 / 64 loss=9.581, ppl=766.06, wps=6559.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.56, train_wall=472, gb_free=6.1, wall=7156
2022-02-02 08:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:07:34 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.845 | ppl 919.48 | wps 8786.9 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:07:34 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:07:34 | INFO | train | epoch 022 | loss 9.545 | ppl 747.15 | wps 6372.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.577 | train_wall 302 | gb_free 6.1 | wall 7218
KL Stats: Epoch 22 Divergences: Uniform: 1.8655905750027457 Unigram: 1.720950329404273
2022-02-02 08:07:34 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:13:01 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.786 | ppl 882.71 | wps 8792.7 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:13:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:13:01 | INFO | train | epoch 023 | loss 9.458 | ppl 703.17 | wps 6379.8 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.52 | train_wall 302 | gb_free 6.1 | wall 7545
KL Stats: Epoch 23 Divergences: Uniform: 1.8942716289931703 Unigram: 1.7700229647738426
2022-02-02 08:13:01 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:15:14 | INFO | train_inner | epoch 024:     28 / 64 loss=9.441, ppl=694.86, wps=6246.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.522, train_wall=471, gb_free=6.1, wall=7678
2022-02-02 08:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:18:28 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.753 | ppl 862.87 | wps 8781.1 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:18:28 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:18:28 | INFO | train | epoch 024 | loss 9.374 | ppl 663.4 | wps 6387.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.525 | train_wall 301 | gb_free 6.1 | wall 7872
KL Stats: Epoch 24 Divergences: Uniform: 1.9148753162389112 Unigram: 1.8177238323399612
2022-02-02 08:18:28 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:23:30 | INFO | train_inner | epoch 025:     64 / 64 loss=9.319, ppl=638.91, wps=6567.1, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.545, train_wall=470, gb_free=6.1, wall=8174
2022-02-02 08:23:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:23:55 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.678 | ppl 819.42 | wps 8769.3 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:23:55 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:23:55 | INFO | train | epoch 025 | loss 9.291 | ppl 626.49 | wps 6386 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.551 | train_wall 301 | gb_free 6.1 | wall 8199
KL Stats: Epoch 25 Divergences: Uniform: 1.9407259937503103 Unigram: 1.860495940770142
2022-02-02 08:23:55 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:29:22 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.628 | ppl 791.14 | wps 8783 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:29:22 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:29:22 | INFO | train | epoch 026 | loss 9.209 | ppl 591.91 | wps 6385.2 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.526 | train_wall 301 | gb_free 6.1 | wall 8526
KL Stats: Epoch 26 Divergences: Uniform: 1.9570207755617497 Unigram: 1.9044786912306013
2022-02-02 08:29:23 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:32:14 | INFO | train_inner | epoch 027:     36 / 64 loss=9.182, ppl=580.74, wps=6247.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.532, train_wall=472, gb_free=6.1, wall=8698
2022-02-02 08:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:34:51 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.588 | ppl 769.44 | wps 8610.6 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:34:51 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:34:51 | INFO | train | epoch 027 | loss 9.13 | ppl 560.22 | wps 6352.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.54 | train_wall 303 | gb_free 6.1 | wall 8855
KL Stats: Epoch 27 Divergences: Uniform: 1.9864738911350621 Unigram: 1.9439160542333598
2022-02-02 08:34:51 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:34:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:40:19 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.56 | ppl 754.68 | wps 8782.6 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:40:19 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:40:19 | INFO | train | epoch 028 | loss 9.049 | ppl 529.69 | wps 6378.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.51 | train_wall 302 | gb_free 6.1 | wall 9183
KL Stats: Epoch 28 Divergences: Uniform: 2.007431909131094 Unigram: 1.9840307805043986
2022-02-02 08:40:19 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:40:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:40:57 | INFO | train_inner | epoch 029:      8 / 64 loss=9.064, ppl=535.39, wps=6231.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.517, train_wall=472, gb_free=6.1, wall=9221
2022-02-02 08:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:45:46 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.508 | ppl 728.14 | wps 8773.2 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:45:46 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:45:46 | INFO | train | epoch 029 | loss 8.972 | ppl 502.26 | wps 6379.8 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.52 | train_wall 302 | gb_free 6.1 | wall 9510
KL Stats: Epoch 29 Divergences: Uniform: 2.030825422120211 Unigram: 2.0217875416311646
2022-02-02 08:45:46 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:49:15 | INFO | train_inner | epoch 030:     44 / 64 loss=8.936, ppl=489.63, wps=6561.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.522, train_wall=472, gb_free=6.1, wall=9719
2022-02-02 08:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:51:13 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.483 | ppl 715.57 | wps 8783.5 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 08:51:13 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 08:51:13 | INFO | train | epoch 030 | loss 8.895 | ppl 475.95 | wps 6384.2 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.53 | train_wall 301 | gb_free 6.1 | wall 9837
KL Stats: Epoch 30 Divergences: Uniform: 2.051123411455421 Unigram: 2.0612728435941343
2022-02-02 08:51:13 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 08:51:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:56:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:56:40 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.449 | ppl 699.1 | wps 8777.9 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 08:56:40 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 08:56:40 | INFO | train | epoch 031 | loss 8.818 | ppl 451.26 | wps 6387.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.508 | train_wall 301 | gb_free 6.1 | wall 10164
KL Stats: Epoch 31 Divergences: Uniform: 2.0719015734808424 Unigram: 2.0958823834955562
2022-02-02 08:56:40 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 08:56:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:57:56 | INFO | train_inner | epoch 032:     16 / 64 loss=8.823, ppl=453.01, wps=6252.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.524, train_wall=470, gb_free=6.1, wall=10240
2022-02-02 09:01:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:02:08 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.43 | ppl 689.83 | wps 8788.8 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:02:08 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:02:08 | INFO | train | epoch 032 | loss 8.743 | ppl 428.59 | wps 6381.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.517 | train_wall 302 | gb_free 6.1 | wall 10492
KL Stats: Epoch 32 Divergences: Uniform: 2.092304484345783 Unigram: 2.1356931132736916
2022-02-02 09:02:08 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:06:14 | INFO | train_inner | epoch 033:     52 / 64 loss=8.702, ppl=416.4, wps=6558.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.508, train_wall=472, gb_free=6.1, wall=10738
2022-02-02 09:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:07:35 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.394 | ppl 672.8 | wps 8791.6 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:07:35 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:07:35 | INFO | train | epoch 033 | loss 8.667 | ppl 406.54 | wps 6376 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.51 | train_wall 302 | gb_free 6.1 | wall 10819
KL Stats: Epoch 33 Divergences: Uniform: 2.1189888490870747 Unigram: 2.1684938631637647
2022-02-02 09:07:35 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:12:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:13:03 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.394 | ppl 672.7 | wps 8781.4 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:13:03 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:13:03 | INFO | train | epoch 034 | loss 8.594 | ppl 386.45 | wps 6377.7 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.509 | train_wall 302 | gb_free 6.1 | wall 11147
KL Stats: Epoch 34 Divergences: Uniform: 2.1386524405523875 Unigram: 2.2095821976820416
2022-02-02 09:13:03 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:14:57 | INFO | train_inner | epoch 035:     24 / 64 loss=8.589, ppl=385.13, wps=6244.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.503, train_wall=471, gb_free=6.1, wall=11261
2022-02-02 09:18:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:18:30 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.373 | ppl 662.91 | wps 8766.6 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:18:30 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:18:30 | INFO | train | epoch 035 | loss 8.52 | ppl 367.19 | wps 6380.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.508 | train_wall 302 | gb_free 6.1 | wall 11474
KL Stats: Epoch 35 Divergences: Uniform: 2.1599327587732144 Unigram: 2.2426042679517044
2022-02-02 09:18:30 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:23:16 | INFO | train_inner | epoch 036:     60 / 64 loss=8.474, ppl=355.64, wps=6542.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.518, train_wall=473, gb_free=6.1, wall=11760
2022-02-02 09:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:23:59 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.339 | ppl 647.74 | wps 8772.3 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:23:59 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:23:59 | INFO | train | epoch 036 | loss 8.451 | ppl 349.95 | wps 6354.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.519 | train_wall 303 | gb_free 6.1 | wall 11803
KL Stats: Epoch 36 Divergences: Uniform: 2.181813406510402 Unigram: 2.277665457511763
2022-02-02 09:23:59 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:29:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:29:26 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.353 | ppl 653.98 | wps 8818.2 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:29:26 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:29:26 | INFO | train | epoch 037 | loss 8.378 | ppl 332.75 | wps 6379.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.51 | train_wall 302 | gb_free 6.1 | wall 12130
KL Stats: Epoch 37 Divergences: Uniform: 2.201295663767585 Unigram: 2.3149142678028416
2022-02-02 09:29:26 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:29:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:31:58 | INFO | train_inner | epoch 038:     32 / 64 loss=8.358, ppl=328.14, wps=6245.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.511, train_wall=471, gb_free=6.1, wall=12282
2022-02-02 09:34:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:34:53 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.296 | ppl 628.39 | wps 8802.6 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:34:53 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:34:53 | INFO | train | epoch 038 | loss 8.308 | ppl 317.03 | wps 6380.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.513 | train_wall 302 | gb_free 6.1 | wall 12457
KL Stats: Epoch 38 Divergences: Uniform: 2.2199574195169314 Unigram: 2.3438120603667225
2022-02-02 09:34:53 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:40:21 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.28 | ppl 621.65 | wps 8789.1 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:40:21 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:40:21 | INFO | train | epoch 039 | loss 8.241 | ppl 302.57 | wps 6380.5 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.511 | train_wall 302 | gb_free 6.1 | wall 12785
KL Stats: Epoch 39 Divergences: Uniform: 2.2496933407959174 Unigram: 2.3785766407060347
2022-02-02 09:40:21 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:40:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:40:40 | INFO | train_inner | epoch 040:      4 / 64 loss=8.263, ppl=307.23, wps=6247.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.511, train_wall=471, gb_free=6.1, wall=12804
2022-02-02 09:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:45:48 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.289 | ppl 625.74 | wps 8811.6 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 09:45:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 09:45:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint40.pt
2022-02-02 09:45:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint40.pt
2022-02-02 09:45:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.289) (writing took 5.298287879995769 seconds)
2022-02-02 09:45:53 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 09:45:53 | INFO | train | epoch 040 | loss 8.173 | ppl 288.56 | wps 6285.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.504 | train_wall 301 | gb_free 6.1 | wall 13117
KL Stats: Epoch 40 Divergences: Uniform: 2.2684353328100375 Unigram: 2.4119936145785856
2022-02-02 09:45:53 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 09:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:49:03 | INFO | train_inner | epoch 041:     40 / 64 loss=8.144, ppl=282.95, wps=6495.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.505, train_wall=472, gb_free=6.1, wall=13307
2022-02-02 09:50:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:51:21 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.268 | ppl 616.47 | wps 8774.8 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.268
2022-02-02 09:51:21 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 09:51:21 | INFO | train | epoch 041 | loss 8.109 | ppl 276.04 | wps 6378.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.503 | train_wall 302 | gb_free 6.1 | wall 13445
KL Stats: Epoch 41 Divergences: Uniform: 2.2785799634546584 Unigram: 2.4426248709572405
2022-02-02 09:51:21 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 09:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:56:49 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.254 | ppl 610.67 | wps 8783.4 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.254
2022-02-02 09:56:49 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 09:56:49 | INFO | train | epoch 042 | loss 8.046 | ppl 264.21 | wps 6356.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.526 | train_wall 303 | gb_free 6.1 | wall 13773
KL Stats: Epoch 42 Divergences: Uniform: 2.306251463866795 Unigram: 2.476348436942272
2022-02-02 09:56:49 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 09:56:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:57:46 | INFO | train_inner | epoch 043:     12 / 64 loss=8.054, ppl=265.73, wps=6230.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.515, train_wall=472, gb_free=6.1, wall=13830
2022-02-02 10:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:02:17 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.262 | ppl 614.17 | wps 8768 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.262
2022-02-02 10:02:17 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:02:17 | INFO | train | epoch 043 | loss 7.983 | ppl 253.08 | wps 6378.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.511 | train_wall 302 | gb_free 6.1 | wall 14101
KL Stats: Epoch 43 Divergences: Uniform: 2.324867123452706 Unigram: 2.5046222434274577
2022-02-02 10:02:17 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:06:04 | INFO | train_inner | epoch 044:     48 / 64 loss=7.952, ppl=247.59, wps=6559.2, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.518, train_wall=472, gb_free=6.1, wall=14328
2022-02-02 10:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:07:44 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.259 | ppl 612.88 | wps 8785.5 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.259
2022-02-02 10:07:44 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:07:44 | INFO | train | epoch 044 | loss 7.921 | ppl 242.37 | wps 6379.1 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.515 | train_wall 302 | gb_free 6.1 | wall 14428
KL Stats: Epoch 44 Divergences: Uniform: 2.338326541995452 Unigram: 2.5368174939382038
2022-02-02 10:07:44 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:13:11 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.271 | ppl 617.71 | wps 8801.8 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.271
2022-02-02 10:13:11 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:13:11 | INFO | train | epoch 045 | loss 7.861 | ppl 232.42 | wps 6386.2 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.511 | train_wall 301 | gb_free 6.1 | wall 14755
KL Stats: Epoch 45 Divergences: Uniform: 2.365229692768109 Unigram: 2.564303556972221
2022-02-02 10:13:11 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:14:46 | INFO | train_inner | epoch 046:     20 / 64 loss=7.858, ppl=232.06, wps=6249, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.511, train_wall=471, gb_free=6.1, wall=14850
2022-02-02 10:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:18:39 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.263 | ppl 614.18 | wps 8783 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.263
2022-02-02 10:18:39 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:18:39 | INFO | train | epoch 046 | loss 7.802 | ppl 223.17 | wps 6377.7 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.507 | train_wall 302 | gb_free 6.1 | wall 15083
KL Stats: Epoch 46 Divergences: Uniform: 2.3875987313876297 Unigram: 2.5918482603944253
2022-02-02 10:18:39 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:18:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:23:04 | INFO | train_inner | epoch 047:     56 / 64 loss=7.771, ppl=218.44, wps=6561.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.503, train_wall=472, gb_free=6.1, wall=15348
2022-02-02 10:23:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:24:06 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.262 | ppl 613.81 | wps 8789.5 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.262
2022-02-02 10:24:06 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:24:06 | INFO | train | epoch 047 | loss 7.745 | ppl 214.46 | wps 6382.9 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.509 | train_wall 302 | gb_free 6.1 | wall 15410
KL Stats: Epoch 47 Divergences: Uniform: 2.392550278598872 Unigram: 2.619388501590165
2022-02-02 10:24:06 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:29:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:29:35 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.241 | ppl 605.27 | wps 8786.4 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.241
2022-02-02 10:29:35 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:29:35 | INFO | train | epoch 048 | loss 7.688 | ppl 206.22 | wps 6350.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.521 | train_wall 303 | gb_free 6.1 | wall 15739
KL Stats: Epoch 48 Divergences: Uniform: 2.4203768831541734 Unigram: 2.6414759054323644
2022-02-02 10:29:35 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:29:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:31:47 | INFO | train_inner | epoch 049:     28 / 64 loss=7.673, ppl=204.05, wps=6229.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.524, train_wall=472, gb_free=6.1, wall=15871
2022-02-02 10:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:35:02 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.266 | ppl 615.48 | wps 8772.9 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.266
2022-02-02 10:35:02 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:35:02 | INFO | train | epoch 049 | loss 7.632 | ppl 198.31 | wps 6383 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.52 | train_wall 301 | gb_free 6.1 | wall 16066
KL Stats: Epoch 49 Divergences: Uniform: 2.4310208444218606 Unigram: 2.665897376686533
2022-02-02 10:35:02 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:35:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:40:04 | INFO | train_inner | epoch 050:     64 / 64 loss=7.601, ppl=194.18, wps=6564.1, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.509, train_wall=470, gb_free=6.1, wall=16368
2022-02-02 10:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:40:29 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.28 | ppl 621.84 | wps 8798.4 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.28
2022-02-02 10:40:29 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:40:29 | INFO | train | epoch 050 | loss 7.576 | ppl 190.84 | wps 6386.3 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.506 | train_wall 301 | gb_free 6.1 | wall 16393
KL Stats: Epoch 50 Divergences: Uniform: 2.4397002189253576 Unigram: 2.6953417149004912
2022-02-02 10:40:29 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:40:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:45:56 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.334 | ppl 645.36 | wps 8795.2 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.289
2022-02-02 10:45:56 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 10:45:56 | INFO | train | epoch 051 | loss 7.524 | ppl 184.05 | wps 6386 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.518 | train_wall 301 | gb_free 6.1 | wall 16720
KL Stats: Epoch 51 Divergences: Uniform: 2.4531787049225366 Unigram: 2.7199113604972696
2022-02-02 10:45:56 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 10:45:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:48:47 | INFO | train_inner | epoch 052:     36 / 64 loss=7.5, ppl=181.04, wps=6254.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.522, train_wall=472, gb_free=6.1, wall=16891
2022-02-02 10:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:51:23 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.357 | ppl 655.68 | wps 8776 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.289
2022-02-02 10:51:23 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 10:51:23 | INFO | train | epoch 052 | loss 7.472 | ppl 177.55 | wps 6387.7 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.525 | train_wall 301 | gb_free 6.1 | wall 17047
KL Stats: Epoch 52 Divergences: Uniform: 2.470392857876239 Unigram: 2.7454221104707814
2022-02-02 10:51:23 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 10:51:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:56:50 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.348 | ppl 651.89 | wps 8777.8 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.289
2022-02-02 10:56:50 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 10:56:50 | INFO | train | epoch 053 | loss 7.42 | ppl 171.26 | wps 6385.4 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.535 | train_wall 301 | gb_free 6.1 | wall 17374
KL Stats: Epoch 53 Divergences: Uniform: 2.4782906594511354 Unigram: 2.7683344486285675
2022-02-02 10:56:50 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 10:56:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:57:28 | INFO | train_inner | epoch 054:      8 / 64 loss=7.432, ppl=172.7, wps=6252.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.53, train_wall=470, gb_free=6.1, wall=17412
2022-02-02 11:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:02:17 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.342 | ppl 648.75 | wps 8784 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.289
2022-02-02 11:02:17 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:02:17 | INFO | train | epoch 054 | loss 7.366 | ppl 164.96 | wps 6383.9 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.509 | train_wall 301 | gb_free 6.1 | wall 17701
KL Stats: Epoch 54 Divergences: Uniform: 2.496846880533935 Unigram: 2.7958492185082164
2022-02-02 11:02:17 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:05:46 | INFO | train_inner | epoch 055:     44 / 64 loss=7.339, ppl=161.9, wps=6565.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.521, train_wall=472, gb_free=6.1, wall=17910
2022-02-02 11:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:07:44 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.377 | ppl 664.99 | wps 8760.2 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.289
2022-02-02 11:07:44 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:07:44 | INFO | train | epoch 055 | loss 7.319 | ppl 159.66 | wps 6384.2 | ups 0.2 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.532 | train_wall 301 | gb_free 6.1 | wall 18028
KL Stats: Epoch 55 Divergences: Uniform: 2.5023970908712294 Unigram: 2.8128195693637865
2022-02-02 11:07:44 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:12:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:13:16 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.401 | ppl 676.05 | wps 8247 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.289
2022-02-02 11:13:16 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:13:16 | INFO | train | epoch 056 | loss 7.27 | ppl 154.34 | wps 6302.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.518 | train_wall 304 | gb_free 6.1 | wall 18360
KL Stats: Epoch 56 Divergences: Uniform: 2.5240384034987717 Unigram: 2.8361403545272967
2022-02-02 11:13:16 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:13:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:14:33 | INFO | train_inner | epoch 057:     16 / 64 loss=7.274, ppl=154.78, wps=6188.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.52, train_wall=474, gb_free=6.1, wall=18436
2022-02-02 11:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:18:47 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.409 | ppl 679.74 | wps 8653.5 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.289
2022-02-02 11:18:47 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:18:47 | INFO | train | epoch 057 | loss 7.226 | ppl 149.71 | wps 6312.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.543 | train_wall 305 | gb_free 6.1 | wall 18691
KL Stats: Epoch 57 Divergences: Uniform: 2.53586725039425 Unigram: 2.8533530578156125
2022-02-02 11:18:47 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:22:55 | INFO | train_inner | epoch 058:     52 / 64 loss=7.202, ppl=147.27, wps=6505, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.545, train_wall=476, gb_free=6.1, wall=18939
2022-02-02 11:23:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:24:16 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.381 | ppl 666.67 | wps 8675.4 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.289
2022-02-02 11:24:16 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:24:16 | INFO | train | epoch 058 | loss 7.177 | ppl 144.76 | wps 6340.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.538 | train_wall 303 | gb_free 6.1 | wall 19020
KL Stats: Epoch 58 Divergences: Uniform: 2.553192989698157 Unigram: 2.880360110198663
2022-02-02 11:24:16 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:29:45 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.426 | ppl 687.64 | wps 8676.1 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.289
2022-02-02 11:29:45 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:29:45 | INFO | train | epoch 059 | loss 7.135 | ppl 140.59 | wps 6342.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.551 | train_wall 303 | gb_free 6.1 | wall 19349
KL Stats: Epoch 59 Divergences: Uniform: 2.5631956755718126 Unigram: 2.9012678072709694
2022-02-02 11:29:45 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:31:40 | INFO | train_inner | epoch 060:     24 / 64 loss=7.122, ppl=139.27, wps=6209.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.542, train_wall=473, gb_free=6.1, wall=19464
2022-02-02 11:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:35:15 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.51 | ppl 728.99 | wps 8663.6 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.289
2022-02-02 11:35:15 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:35:15 | INFO | train | epoch 060 | loss 7.089 | ppl 136.15 | wps 6342.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.541 | train_wall 303 | gb_free 6.1 | wall 19679
KL Stats: Epoch 60 Divergences: Uniform: 2.5724539003317166 Unigram: 2.9168720962839343
2022-02-02 11:35:15 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:40:01 | INFO | train_inner | epoch 061:     60 / 64 loss=7.073, ppl=134.63, wps=6526.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.542, train_wall=474, gb_free=6.1, wall=19965
2022-02-02 11:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:40:44 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.491 | ppl 719.53 | wps 8691.6 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.289
2022-02-02 11:40:44 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 11:40:44 | INFO | train | epoch 061 | loss 7.044 | ppl 131.98 | wps 6349.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.538 | train_wall 303 | gb_free 6.1 | wall 20008
KL Stats: Epoch 61 Divergences: Uniform: 2.5903652365134655 Unigram: 2.9410435652870417
2022-02-02 11:40:44 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 11:40:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:46:14 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.467 | ppl 707.58 | wps 8672.3 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.289
2022-02-02 11:46:14 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 11:46:14 | INFO | train | epoch 062 | loss 7.003 | ppl 128.27 | wps 6330.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.545 | train_wall 304 | gb_free 6.1 | wall 20338
KL Stats: Epoch 62 Divergences: Uniform: 2.6030492148714703 Unigram: 2.9551404793422273
2022-02-02 11:46:14 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 11:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:48:46 | INFO | train_inner | epoch 063:     32 / 64 loss=6.987, ppl=126.89, wps=6203, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.555, train_wall=474, gb_free=6.1, wall=20490
2022-02-02 11:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:51:43 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.615 | ppl 784.13 | wps 8697.6 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.289
2022-02-02 11:51:43 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 11:51:43 | INFO | train | epoch 063 | loss 6.963 | ppl 124.74 | wps 6342.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.557 | train_wall 303 | gb_free 6.1 | wall 20667
KL Stats: Epoch 63 Divergences: Uniform: 2.6038501998132673 Unigram: 2.98022116738534
2022-02-02 11:51:43 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 11:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:57:12 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.613 | ppl 782.86 | wps 8683.7 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.289
2022-02-02 11:57:12 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 11:57:12 | INFO | train | epoch 064 | loss 6.919 | ppl 121.02 | wps 6342.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.561 | train_wall 303 | gb_free 6.1 | wall 20996
KL Stats: Epoch 64 Divergences: Uniform: 2.6253493389869553 Unigram: 3.0084617476541626
2022-02-02 11:57:12 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 11:57:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:57:31 | INFO | train_inner | epoch 065:      4 / 64 loss=6.936, ppl=122.42, wps=6208.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.553, train_wall=473, gb_free=6.1, wall=21015
2022-02-02 12:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:02:43 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.557 | ppl 753.22 | wps 8382.6 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.289
2022-02-02 12:02:43 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:02:43 | INFO | train | epoch 065 | loss 6.878 | ppl 117.6 | wps 6313.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.572 | train_wall 304 | gb_free 6.1 | wall 21327
KL Stats: Epoch 65 Divergences: Uniform: 2.6416745477922747 Unigram: 3.03029462871052
2022-02-02 12:02:43 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:05:56 | INFO | train_inner | epoch 066:     40 / 64 loss=6.852, ppl=115.54, wps=6474.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.567, train_wall=477, gb_free=6.1, wall=21520
2022-02-02 12:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:08:14 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.531 | ppl 739.57 | wps 8673.6 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.289
2022-02-02 12:08:14 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:08:14 | INFO | train | epoch 066 | loss 6.834 | ppl 114.1 | wps 6302.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.552 | train_wall 305 | gb_free 6.1 | wall 21658
KL Stats: Epoch 66 Divergences: Uniform: 2.654560231548704 Unigram: 3.0507606650478194
2022-02-02 12:08:14 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:08:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:13:44 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.573 | ppl 761.82 | wps 8694.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.289
2022-02-02 12:13:44 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:13:44 | INFO | train | epoch 067 | loss 6.795 | ppl 111.07 | wps 6340.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.57 | train_wall 303 | gb_free 6.1 | wall 21988
KL Stats: Epoch 67 Divergences: Uniform: 2.6608040512692805 Unigram: 3.0654176440283396
2022-02-02 12:13:44 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:14:41 | INFO | train_inner | epoch 068:     12 / 64 loss=6.805, ppl=111.82, wps=6207.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.563, train_wall=474, gb_free=6.1, wall=22045
2022-02-02 12:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:19:14 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.653 | ppl 805.05 | wps 8695.9 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.289
2022-02-02 12:19:14 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:19:14 | INFO | train | epoch 068 | loss 6.755 | ppl 107.99 | wps 6331 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.564 | train_wall 304 | gb_free 6.1 | wall 22318
KL Stats: Epoch 68 Divergences: Uniform: 2.676714702230319 Unigram: 3.086910063671209
2022-02-02 12:19:14 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:23:03 | INFO | train_inner | epoch 069:     48 / 64 loss=6.735, ppl=106.54, wps=6512.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.562, train_wall=475, gb_free=6.1, wall=22547
2022-02-02 12:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:24:43 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.645 | ppl 800.46 | wps 8666.1 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.289
2022-02-02 12:24:43 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:24:43 | INFO | train | epoch 069 | loss 6.717 | ppl 105.19 | wps 6334.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.565 | train_wall 304 | gb_free 6.1 | wall 22647
KL Stats: Epoch 69 Divergences: Uniform: 2.6786834011594296 Unigram: 3.109522823222838
2022-02-02 12:24:43 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:29:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:30:13 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.675 | ppl 817.67 | wps 8690.3 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.289
2022-02-02 12:30:13 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:30:13 | INFO | train | epoch 070 | loss 6.68 | ppl 102.56 | wps 6340.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.574 | train_wall 303 | gb_free 6.1 | wall 22977
KL Stats: Epoch 70 Divergences: Uniform: 2.694300521176707 Unigram: 3.129564045907337
2022-02-02 12:30:13 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:31:48 | INFO | train_inner | epoch 071:     20 / 64 loss=6.676, ppl=102.23, wps=6205.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.572, train_wall=474, gb_free=6.1, wall=23072
2022-02-02 12:35:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:35:42 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.625 | ppl 789.65 | wps 8667.7 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.289
2022-02-02 12:35:42 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 12:35:42 | INFO | train | epoch 071 | loss 6.646 | ppl 100.14 | wps 6336.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.572 | train_wall 304 | gb_free 6.1 | wall 23306
KL Stats: Epoch 71 Divergences: Uniform: 2.705022307538584 Unigram: 3.1481117410655557
2022-02-02 12:35:42 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 12:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:40:10 | INFO | train_inner | epoch 072:     56 / 64 loss=6.633, ppl=99.24, wps=6515.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.577, train_wall=475, gb_free=6.1, wall=23574
2022-02-02 12:40:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:41:12 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.703 | ppl 833.62 | wps 8702.5 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.289
2022-02-02 12:41:12 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 12:41:12 | INFO | train | epoch 072 | loss 6.613 | ppl 97.9 | wps 6338 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.578 | train_wall 304 | gb_free 6.1 | wall 23636
KL Stats: Epoch 72 Divergences: Uniform: 2.7194720489207342 Unigram: 3.1622419894879203
2022-02-02 12:41:12 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 12:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:46:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:46:42 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.636 | ppl 795.54 | wps 8665.8 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.289
2022-02-02 12:46:42 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 12:46:42 | INFO | train | epoch 073 | loss 6.577 | ppl 95.49 | wps 6331.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.575 | train_wall 304 | gb_free 6.1 | wall 23966
KL Stats: Epoch 73 Divergences: Uniform: 2.726271172602654 Unigram: 3.182915217284885
2022-02-02 12:46:42 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 12:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:48:56 | INFO | train_inner | epoch 074:     28 / 64 loss=6.562, ppl=94.48, wps=6201, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.575, train_wall=474, gb_free=6.1, wall=24100
2022-02-02 12:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:52:11 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.708 | ppl 836.55 | wps 8694.5 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.289
2022-02-02 12:52:11 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 12:52:11 | INFO | train | epoch 074 | loss 6.547 | ppl 93.49 | wps 6336.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.583 | train_wall 304 | gb_free 6.1 | wall 24295
KL Stats: Epoch 74 Divergences: Uniform: 2.7322061172972982 Unigram: 3.2031091081794507
2022-02-02 12:52:11 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 12:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:57:16 | INFO | train_inner | epoch 075:     64 / 64 loss=6.542, ppl=93.16, wps=6519.3, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.586, train_wall=474, gb_free=6.1, wall=24600
2022-02-02 12:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:57:41 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.696 | ppl 829.25 | wps 8674.5 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.289
2022-02-02 12:57:41 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 12:57:41 | INFO | train | epoch 075 | loss 6.516 | ppl 91.54 | wps 6341.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.581 | train_wall 303 | gb_free 6.1 | wall 24625
KL Stats: Epoch 75 Divergences: Uniform: 2.7459004040670245 Unigram: 3.2325878332733207
2022-02-02 12:57:41 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 12:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:03:10 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.726 | ppl 846.89 | wps 8700.6 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.289
2022-02-02 13:03:10 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:03:10 | INFO | train | epoch 076 | loss 6.484 | ppl 89.52 | wps 6340.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.594 | train_wall 303 | gb_free 6.1 | wall 24954
KL Stats: Epoch 76 Divergences: Uniform: 2.752905133561034 Unigram: 3.2336016022995
2022-02-02 13:03:10 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:06:02 | INFO | train_inner | epoch 077:     36 / 64 loss=6.464, ppl=88.28, wps=6209, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.588, train_wall=475, gb_free=6.1, wall=25126
2022-02-02 13:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:08:40 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.756 | ppl 864.67 | wps 8686.2 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.289
2022-02-02 13:08:40 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:08:40 | INFO | train | epoch 077 | loss 6.452 | ppl 87.54 | wps 6343.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.581 | train_wall 303 | gb_free 6.1 | wall 25283
KL Stats: Epoch 77 Divergences: Uniform: 2.7548320385492278 Unigram: 3.2534139496032473
2022-02-02 13:08:40 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:13:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:14:09 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.786 | ppl 883.11 | wps 8665.7 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.289
2022-02-02 13:14:09 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:14:09 | INFO | train | epoch 078 | loss 6.427 | ppl 86.07 | wps 6339.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.607 | train_wall 303 | gb_free 6.1 | wall 25613
KL Stats: Epoch 78 Divergences: Uniform: 2.781612463437659 Unigram: 3.269273630312375
2022-02-02 13:14:09 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:14:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:14:47 | INFO | train_inner | epoch 079:      8 / 64 loss=6.436, ppl=86.6, wps=6206.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.604, train_wall=473, gb_free=6.1, wall=25651
2022-02-02 13:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:19:39 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.783 | ppl 880.76 | wps 8650.9 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.289
2022-02-02 13:19:39 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:19:39 | INFO | train | epoch 079 | loss 6.399 | ppl 84.39 | wps 6337.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.611 | train_wall 303 | gb_free 6.1 | wall 25943
KL Stats: Epoch 79 Divergences: Uniform: 2.772384085657329 Unigram: 3.2885795288280653
2022-02-02 13:19:39 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:23:09 | INFO | train_inner | epoch 080:     44 / 64 loss=6.382, ppl=83.39, wps=6519.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.611, train_wall=475, gb_free=6.1, wall=26153
2022-02-02 13:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:25:08 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.796 | ppl 888.71 | wps 8685.3 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.289
2022-02-02 13:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:25:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint80.pt
2022-02-02 13:25:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint80.pt
2022-02-02 13:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.796) (writing took 3.889808501000516 seconds)
2022-02-02 13:25:12 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:25:12 | INFO | train | epoch 080 | loss 6.37 | ppl 82.72 | wps 6265.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.611 | train_wall 303 | gb_free 6.1 | wall 26276
KL Stats: Epoch 80 Divergences: Uniform: 2.7873015314856477 Unigram: 3.3121651951281486
2022-02-02 13:25:12 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:30:42 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.845 | ppl 919.56 | wps 8664.2 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.289
2022-02-02 13:30:42 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:30:42 | INFO | train | epoch 081 | loss 6.344 | ppl 81.26 | wps 6336.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.615 | train_wall 304 | gb_free 6.1 | wall 26606
KL Stats: Epoch 81 Divergences: Uniform: 2.797488441903275 Unigram: 3.322350337036546
2022-02-02 13:30:42 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:30:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:31:58 | INFO | train_inner | epoch 082:     16 / 64 loss=6.344, ppl=81.21, wps=6157.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.612, train_wall=474, gb_free=6.1, wall=26682
2022-02-02 13:35:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:36:11 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.884 | ppl 945.01 | wps 8676.7 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.289
2022-02-02 13:36:11 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 13:36:11 | INFO | train | epoch 082 | loss 6.319 | ppl 79.82 | wps 6339.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.622 | train_wall 303 | gb_free 6.1 | wall 26935
KL Stats: Epoch 82 Divergences: Uniform: 2.7945054446227595 Unigram: 3.3462812169308247
2022-02-02 13:36:11 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 13:36:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:40:19 | INFO | train_inner | epoch 083:     52 / 64 loss=6.31, ppl=79.32, wps=6518.4, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.625, train_wall=475, gb_free=6.1, wall=27183
2022-02-02 13:41:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:41:41 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.841 | ppl 917.2 | wps 8680.8 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.289
2022-02-02 13:41:41 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 13:41:41 | INFO | train | epoch 083 | loss 6.293 | ppl 78.41 | wps 6338.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.626 | train_wall 303 | gb_free 6.1 | wall 27264
KL Stats: Epoch 83 Divergences: Uniform: 2.8101903652541647 Unigram: 3.3631416910021663
2022-02-02 13:41:41 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 13:41:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:47:10 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.743 | ppl 857.11 | wps 8682.8 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.289
2022-02-02 13:47:10 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 13:47:10 | INFO | train | epoch 084 | loss 6.27 | ppl 77.17 | wps 6343.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.635 | train_wall 303 | gb_free 6.1 | wall 27594
KL Stats: Epoch 84 Divergences: Uniform: 2.825305195527769 Unigram: 3.379388112678985
2022-02-02 13:47:10 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 13:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:49:05 | INFO | train_inner | epoch 085:     24 / 64 loss=6.262, ppl=76.75, wps=6207.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.632, train_wall=473, gb_free=6.1, wall=27708
2022-02-02 13:52:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:52:40 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.884 | ppl 944.89 | wps 8665.1 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.289
2022-02-02 13:52:40 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 13:52:40 | INFO | train | epoch 085 | loss 6.243 | ppl 75.77 | wps 6328 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.621 | train_wall 304 | gb_free 6.1 | wall 27924
KL Stats: Epoch 85 Divergences: Uniform: 2.831358938602358 Unigram: 3.3944514679263236
2022-02-02 13:52:40 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 13:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:57:26 | INFO | train_inner | epoch 086:     60 / 64 loss=6.237, ppl=75.44, wps=6514.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.622, train_wall=475, gb_free=6.1, wall=28210
2022-02-02 13:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:58:09 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.777 | ppl 877.42 | wps 8691.3 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.289
2022-02-02 13:58:09 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 13:58:09 | INFO | train | epoch 086 | loss 6.221 | ppl 74.59 | wps 6342.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.629 | train_wall 303 | gb_free 6.1 | wall 28253
KL Stats: Epoch 86 Divergences: Uniform: 2.8334714019240352 Unigram: 3.4115318058333925
2022-02-02 13:58:09 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 13:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:03:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:03:38 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.877 | ppl 940.13 | wps 8679.6 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.289
2022-02-02 14:03:38 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:03:38 | INFO | train | epoch 087 | loss 6.2 | ppl 73.52 | wps 6343.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.643 | train_wall 303 | gb_free 6.1 | wall 28582
KL Stats: Epoch 87 Divergences: Uniform: 2.8313151774171508 Unigram: 3.4212947190204726
2022-02-02 14:03:38 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:06:11 | INFO | train_inner | epoch 088:     32 / 64 loss=6.186, ppl=72.82, wps=6210.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.648, train_wall=473, gb_free=6.1, wall=28735
2022-02-02 14:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:09:07 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.828 | ppl 908.93 | wps 8741.8 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.289
2022-02-02 14:09:07 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:09:07 | INFO | train | epoch 088 | loss 6.179 | ppl 72.44 | wps 6347.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.648 | train_wall 303 | gb_free 6.1 | wall 28911
KL Stats: Epoch 88 Divergences: Uniform: 2.8445486489053415 Unigram: 3.435131157867865
2022-02-02 14:09:07 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:14:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:14:37 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.868 | ppl 934.58 | wps 8683.6 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.289
2022-02-02 14:14:37 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:14:37 | INFO | train | epoch 089 | loss 6.154 | ppl 71.21 | wps 6342.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.646 | train_wall 303 | gb_free 6.1 | wall 29241
KL Stats: Epoch 89 Divergences: Uniform: 2.85101063813414 Unigram: 3.4594110742019537
2022-02-02 14:14:37 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:14:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:14:56 | INFO | train_inner | epoch 090:      4 / 64 loss=6.169, ppl=71.94, wps=6211, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.645, train_wall=473, gb_free=6.1, wall=29260
2022-02-02 14:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:20:06 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.801 | ppl 892.16 | wps 8680.9 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.289
2022-02-02 14:20:06 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:20:06 | INFO | train | epoch 090 | loss 6.136 | ppl 70.32 | wps 6341.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.66 | train_wall 303 | gb_free 6.1 | wall 29570
KL Stats: Epoch 90 Divergences: Uniform: 2.8594455325333636 Unigram: 3.4661471465932387
2022-02-02 14:20:06 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:23:17 | INFO | train_inner | epoch 091:     40 / 64 loss=6.117, ppl=69.39, wps=6520, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.662, train_wall=475, gb_free=6.1, wall=29761
2022-02-02 14:25:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:25:36 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.912 | ppl 963.48 | wps 8660.3 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.289
2022-02-02 14:25:36 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:25:36 | INFO | train | epoch 091 | loss 6.114 | ppl 69.27 | wps 6332.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.664 | train_wall 304 | gb_free 6.1 | wall 29900
KL Stats: Epoch 91 Divergences: Uniform: 2.859656979865198 Unigram: 3.4875381118818436
2022-02-02 14:25:36 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:25:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:31:05 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.957 | ppl 993.64 | wps 8683.3 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.289
2022-02-02 14:31:05 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 14:31:05 | INFO | train | epoch 092 | loss 6.092 | ppl 68.21 | wps 6345 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.657 | train_wall 303 | gb_free 6.1 | wall 30229
KL Stats: Epoch 92 Divergences: Uniform: 2.864499048714737 Unigram: 3.492778006416927
2022-02-02 14:31:05 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 14:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:32:02 | INFO | train_inner | epoch 093:     12 / 64 loss=6.097, ppl=68.44, wps=6206.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.657, train_wall=473, gb_free=6.1, wall=30286
2022-02-02 14:36:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:36:35 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.906 | ppl 959.6 | wps 8679.6 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.289
2022-02-02 14:36:35 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 14:36:35 | INFO | train | epoch 093 | loss 6.071 | ppl 67.22 | wps 6339.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.657 | train_wall 303 | gb_free 6.1 | wall 30559
KL Stats: Epoch 93 Divergences: Uniform: 2.878515221836617 Unigram: 3.5076050183744467
2022-02-02 14:36:35 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 14:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:40:23 | INFO | train_inner | epoch 094:     48 / 64 loss=6.067, ppl=67.06, wps=6523.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.665, train_wall=475, gb_free=6.1, wall=30787
2022-02-02 14:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:42:04 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.834 | ppl 912.98 | wps 8688.2 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.289
2022-02-02 14:42:04 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 14:42:04 | INFO | train | epoch 094 | loss 6.053 | ppl 66.41 | wps 6347.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.676 | train_wall 303 | gb_free 6.1 | wall 30888
KL Stats: Epoch 94 Divergences: Uniform: 2.8848615658849384 Unigram: 3.527005481656477
2022-02-02 14:42:04 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 14:42:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:47:33 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.887 | ppl 946.72 | wps 8674.9 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.289
2022-02-02 14:47:33 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 14:47:33 | INFO | train | epoch 095 | loss 6.036 | ppl 65.61 | wps 6339.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.677 | train_wall 303 | gb_free 6.1 | wall 31217
KL Stats: Epoch 95 Divergences: Uniform: 2.8902272280723955 Unigram: 3.535081765940599
2022-02-02 14:47:33 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 14:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:49:08 | INFO | train_inner | epoch 096:     20 / 64 loss=6.03, ppl=65.34, wps=6209.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.68, train_wall=473, gb_free=6.1, wall=31312
2022-02-02 14:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:53:02 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.888 | ppl 947.5 | wps 8674 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.289
2022-02-02 14:53:02 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 14:53:02 | INFO | train | epoch 096 | loss 6.018 | ppl 64.79 | wps 6345.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.686 | train_wall 303 | gb_free 6.1 | wall 31546
KL Stats: Epoch 96 Divergences: Uniform: 2.893081209260625 Unigram: 3.5503916780630114
2022-02-02 14:53:02 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 14:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:57:30 | INFO | train_inner | epoch 097:     56 / 64 loss=6.015, ppl=64.66, wps=6516.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.694, train_wall=475, gb_free=6.1, wall=31814
2022-02-02 14:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:58:32 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.923 | ppl 971.1 | wps 8680.3 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.289
2022-02-02 14:58:32 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 14:58:32 | INFO | train | epoch 097 | loss 5.999 | ppl 63.94 | wps 6330.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.696 | train_wall 304 | gb_free 6.1 | wall 31876
KL Stats: Epoch 97 Divergences: Uniform: 2.8962856186690247 Unigram: 3.5616132638425864
2022-02-02 14:58:32 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 14:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:04:02 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.992 | ppl 1018.19 | wps 8659.4 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.289
2022-02-02 15:04:02 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:04:02 | INFO | train | epoch 098 | loss 5.978 | ppl 63.02 | wps 6335.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.671 | train_wall 304 | gb_free 6.1 | wall 32206
KL Stats: Epoch 98 Divergences: Uniform: 2.8935406128671293 Unigram: 3.5789186134372244
2022-02-02 15:04:02 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:06:16 | INFO | train_inner | epoch 099:     28 / 64 loss=5.97, ppl=62.66, wps=6200.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.678, train_wall=474, gb_free=6.1, wall=32340
2022-02-02 15:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:09:31 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.934 | ppl 977.97 | wps 8686 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.289
2022-02-02 15:09:31 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:09:31 | INFO | train | epoch 099 | loss 5.963 | ppl 62.39 | wps 6338.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.691 | train_wall 304 | gb_free 6.1 | wall 32535
KL Stats: Epoch 99 Divergences: Uniform: 2.901805576937388 Unigram: 3.5988981335416033
2022-02-02 15:09:31 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:14:39 | INFO | train_inner | epoch 100:     64 / 64 loss=5.961, ppl=62.29, wps=6480.2, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.694, train_wall=477, gb_free=6.1, wall=32843
2022-02-02 15:14:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:15:04 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.954 | ppl 991.96 | wps 8672.6 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.289
2022-02-02 15:15:04 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:15:04 | INFO | train | epoch 100 | loss 5.946 | ppl 61.63 | wps 6281 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.697 | train_wall 306 | gb_free 6.1 | wall 32868
KL Stats: Epoch 100 Divergences: Uniform: 2.9098543731360977 Unigram: 3.6073660342575864
2022-02-02 15:15:04 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:15:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:20:33 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.991 | ppl 1017.41 | wps 8669.1 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.289
2022-02-02 15:20:33 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:20:33 | INFO | train | epoch 101 | loss 5.931 | ppl 60.99 | wps 6339.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.696 | train_wall 303 | gb_free 6.1 | wall 33197
KL Stats: Epoch 101 Divergences: Uniform: 2.9131087063155703 Unigram: 3.618878391865249
2022-02-02 15:20:33 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:23:25 | INFO | train_inner | epoch 102:     36 / 64 loss=5.916, ppl=60.38, wps=6208.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.702, train_wall=475, gb_free=6.1, wall=33369
2022-02-02 15:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:26:02 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.907 | ppl 959.92 | wps 8691 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.289
2022-02-02 15:26:02 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 15:26:02 | INFO | train | epoch 102 | loss 5.915 | ppl 60.32 | wps 6347 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.715 | train_wall 303 | gb_free 6.1 | wall 33526
KL Stats: Epoch 102 Divergences: Uniform: 2.9187508898208896 Unigram: 3.6328929788104385
2022-02-02 15:26:02 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 15:26:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:31:32 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.982 | ppl 1011.33 | wps 8702.7 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.289
2022-02-02 15:31:32 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 15:31:32 | INFO | train | epoch 103 | loss 5.897 | ppl 59.57 | wps 6345.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.709 | train_wall 303 | gb_free 6.1 | wall 33856
KL Stats: Epoch 103 Divergences: Uniform: 2.9205564438794065 Unigram: 3.6434397210664238
2022-02-02 15:31:32 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 15:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:32:10 | INFO | train_inner | epoch 104:      8 / 64 loss=5.905, ppl=59.93, wps=6212.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.714, train_wall=473, gb_free=6.1, wall=33894
2022-02-02 15:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:37:01 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.979 | ppl 1009.24 | wps 8685.1 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.289
2022-02-02 15:37:01 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 15:37:01 | INFO | train | epoch 104 | loss 5.882 | ppl 58.99 | wps 6342.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.729 | train_wall 303 | gb_free 6.1 | wall 34185
KL Stats: Epoch 104 Divergences: Uniform: 2.9212537075327174 Unigram: 3.6584851158707608
2022-02-02 15:37:01 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 15:37:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:40:31 | INFO | train_inner | epoch 105:     44 / 64 loss=5.87, ppl=58.5, wps=6521.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.723, train_wall=475, gb_free=6.1, wall=34395
2022-02-02 15:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:42:30 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.979 | ppl 1009.1 | wps 8695.1 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.289
2022-02-02 15:42:30 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 15:42:30 | INFO | train | epoch 105 | loss 5.866 | ppl 58.3 | wps 6339.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.718 | train_wall 303 | gb_free 6.1 | wall 34514
KL Stats: Epoch 105 Divergences: Uniform: 2.9245230800249393 Unigram: 3.6638482401120203
2022-02-02 15:42:30 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 15:42:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:48:00 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.94 | ppl 982.16 | wps 8679.7 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.289
2022-02-02 15:48:00 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 15:48:00 | INFO | train | epoch 106 | loss 5.85 | ppl 57.66 | wps 6337.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.736 | train_wall 304 | gb_free 6.1 | wall 34844
KL Stats: Epoch 106 Divergences: Uniform: 2.9452338227154784 Unigram: 3.679258350790526
2022-02-02 15:48:00 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 15:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:49:16 | INFO | train_inner | epoch 107:     16 / 64 loss=5.851, ppl=57.72, wps=6205.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.735, train_wall=474, gb_free=6.1, wall=34920
2022-02-02 15:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:53:29 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.038 | ppl 1051.17 | wps 8632.8 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.289
2022-02-02 15:53:29 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 15:53:29 | INFO | train | epoch 107 | loss 5.837 | ppl 57.16 | wps 6343.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.729 | train_wall 303 | gb_free 6.1 | wall 35173
KL Stats: Epoch 107 Divergences: Uniform: 2.9306400184148798 Unigram: 3.6871395381990135
2022-02-02 15:53:29 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 15:53:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:57:38 | INFO | train_inner | epoch 108:     52 / 64 loss=5.829, ppl=56.84, wps=6518.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.73, train_wall=475, gb_free=6.1, wall=35422
2022-02-02 15:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:58:59 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.034 | ppl 1048.39 | wps 8704.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.289
2022-02-02 15:58:59 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 15:58:59 | INFO | train | epoch 108 | loss 5.82 | ppl 56.5 | wps 6337.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.729 | train_wall 304 | gb_free 6.1 | wall 35503
KL Stats: Epoch 108 Divergences: Uniform: 2.933804940076812 Unigram: 3.7083508014890603
2022-02-02 15:58:59 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 15:58:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:04:33 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.01 | ppl 1031.03 | wps 8561 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.289
2022-02-02 16:04:33 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:04:33 | INFO | train | epoch 109 | loss 5.806 | ppl 55.96 | wps 6256.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.736 | train_wall 307 | gb_free 6.1 | wall 35837
KL Stats: Epoch 109 Divergences: Uniform: 2.942541447100616 Unigram: 3.71173378419093
2022-02-02 16:04:33 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:04:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:06:29 | INFO | train_inner | epoch 110:     24 / 64 loss=5.799, ppl=55.69, wps=6138.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.735, train_wall=479, gb_free=6.1, wall=35953
2022-02-02 16:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:10:07 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.046 | ppl 1056.9 | wps 8562.2 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.289
2022-02-02 16:10:07 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:10:07 | INFO | train | epoch 110 | loss 5.794 | ppl 55.48 | wps 6250.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.766 | train_wall 308 | gb_free 6.1 | wall 36171
KL Stats: Epoch 110 Divergences: Uniform: 2.94572251392268 Unigram: 3.722514139616484
2022-02-02 16:10:07 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:14:56 | INFO | train_inner | epoch 111:     60 / 64 loss=5.797, ppl=55.6, wps=6441, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.771, train_wall=481, gb_free=6.1, wall=36460
2022-02-02 16:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:15:40 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.062 | ppl 1068.62 | wps 8587.7 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.289
2022-02-02 16:15:40 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:15:40 | INFO | train | epoch 111 | loss 5.781 | ppl 55 | wps 6273 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.766 | train_wall 307 | gb_free 6.1 | wall 36504
KL Stats: Epoch 111 Divergences: Uniform: 2.952039894081993 Unigram: 3.7389163333894517
2022-02-02 16:15:40 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:15:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:20:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:21:14 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.069 | ppl 1074.1 | wps 8577.3 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.289
2022-02-02 16:21:14 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:21:14 | INFO | train | epoch 112 | loss 5.765 | ppl 54.39 | wps 6243.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.771 | train_wall 308 | gb_free 6.1 | wall 36838
KL Stats: Epoch 112 Divergences: Uniform: 2.956216021532278 Unigram: 3.752253882682858
2022-02-02 16:21:14 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:23:49 | INFO | train_inner | epoch 113:     32 / 64 loss=5.752, ppl=53.88, wps=6116.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.77, train_wall=481, gb_free=6.1, wall=36993
2022-02-02 16:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:26:48 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.017 | ppl 1036.06 | wps 8531 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.289
2022-02-02 16:26:48 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 16:26:48 | INFO | train | epoch 113 | loss 5.752 | ppl 53.9 | wps 6256.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.762 | train_wall 307 | gb_free 6.1 | wall 37172
KL Stats: Epoch 113 Divergences: Uniform: 2.9588484528114463 Unigram: 3.75746776430119
2022-02-02 16:26:48 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 16:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:31:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:32:21 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.998 | ppl 1022.66 | wps 8665.2 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.289
2022-02-02 16:32:21 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 16:32:21 | INFO | train | epoch 114 | loss 5.742 | ppl 53.51 | wps 6274.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.765 | train_wall 307 | gb_free 6.1 | wall 37505
KL Stats: Epoch 114 Divergences: Uniform: 2.9649615093066966 Unigram: 3.767701849956487
2022-02-02 16:32:21 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 16:32:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:32:40 | INFO | train_inner | epoch 115:      4 / 64 loss=5.754, ppl=53.97, wps=6137.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.762, train_wall=479, gb_free=6.1, wall=37524
2022-02-02 16:37:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:37:51 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.073 | ppl 1077.13 | wps 8672.3 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.289
2022-02-02 16:37:51 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 16:37:51 | INFO | train | epoch 115 | loss 5.727 | ppl 52.95 | wps 6322.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.767 | train_wall 304 | gb_free 6.1 | wall 37835
KL Stats: Epoch 115 Divergences: Uniform: 2.953484246003802 Unigram: 3.7796055772174375
2022-02-02 16:37:51 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 16:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:41:03 | INFO | train_inner | epoch 116:     40 / 64 loss=5.717, ppl=52.61, wps=6500.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.777, train_wall=476, gb_free=6.1, wall=38027
2022-02-02 16:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:43:22 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.086 | ppl 1086.81 | wps 8641.2 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.289
2022-02-02 16:43:22 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 16:43:22 | INFO | train | epoch 116 | loss 5.718 | ppl 52.62 | wps 6311.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.798 | train_wall 305 | gb_free 6.1 | wall 38166
KL Stats: Epoch 116 Divergences: Uniform: 2.9729402942547414 Unigram: 3.782091642770035
2022-02-02 16:43:22 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 16:43:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:48:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:48:52 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.1 | ppl 1097.58 | wps 8640 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.289
2022-02-02 16:48:52 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 16:48:52 | INFO | train | epoch 117 | loss 5.703 | ppl 52.1 | wps 6325.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.781 | train_wall 304 | gb_free 6.1 | wall 38496
KL Stats: Epoch 117 Divergences: Uniform: 2.967841970195677 Unigram: 3.7990051992088754
2022-02-02 16:48:52 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 16:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:49:50 | INFO | train_inner | epoch 118:     12 / 64 loss=5.705, ppl=52.17, wps=6185.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.789, train_wall=475, gb_free=6.1, wall=38554
2022-02-02 16:53:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:54:23 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.051 | ppl 1060.73 | wps 8630.5 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.289
2022-02-02 16:54:23 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 16:54:23 | INFO | train | epoch 118 | loss 5.691 | ppl 51.65 | wps 6319.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.804 | train_wall 304 | gb_free 6.1 | wall 38827
KL Stats: Epoch 118 Divergences: Uniform: 2.9782145222292655 Unigram: 3.8115949213795806
2022-02-02 16:54:23 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 16:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:58:13 | INFO | train_inner | epoch 119:     48 / 64 loss=5.683, ppl=51.38, wps=6502.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.797, train_wall=476, gb_free=6.1, wall=39056
2022-02-02 16:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:59:53 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.032 | ppl 1046.97 | wps 8675.9 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.289
2022-02-02 16:59:53 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 16:59:53 | INFO | train | epoch 119 | loss 5.677 | ppl 51.16 | wps 6331.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.78 | train_wall 304 | gb_free 6.1 | wall 39157
KL Stats: Epoch 119 Divergences: Uniform: 2.974610281477385 Unigram: 3.819388457102295
2022-02-02 16:59:53 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 16:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:05:22 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.989 | ppl 1016.43 | wps 8696.4 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.289
2022-02-02 17:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:05:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint120.pt
2022-02-02 17:05:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint120.pt
2022-02-02 17:05:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.989) (writing took 3.639236908988096 seconds)
2022-02-02 17:05:26 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:05:26 | INFO | train | epoch 120 | loss 5.669 | ppl 50.89 | wps 6272.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.821 | train_wall 303 | gb_free 6.1 | wall 39490
KL Stats: Epoch 120 Divergences: Uniform: 2.9795897168897283 Unigram: 3.8297836337150915
2022-02-02 17:05:26 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:07:01 | INFO | train_inner | epoch 121:     20 / 64 loss=5.665, ppl=50.74, wps=6165.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.81, train_wall=473, gb_free=6.1, wall=39585
2022-02-02 17:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:10:55 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.058 | ppl 1066.18 | wps 8650 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.289
2022-02-02 17:10:55 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:10:55 | INFO | train | epoch 121 | loss 5.654 | ppl 50.36 | wps 6343.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.811 | train_wall 303 | gb_free 6.1 | wall 39819
KL Stats: Epoch 121 Divergences: Uniform: 2.9827341151883004 Unigram: 3.8415434473734456
2022-02-02 17:10:55 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:15:23 | INFO | train_inner | epoch 122:     56 / 64 loss=5.656, ppl=50.41, wps=6520, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.811, train_wall=475, gb_free=6.1, wall=40086
2022-02-02 17:16:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:16:25 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.094 | ppl 1092.77 | wps 8647.8 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.289
2022-02-02 17:16:25 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:16:25 | INFO | train | epoch 122 | loss 5.644 | ppl 50.01 | wps 6333.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.81 | train_wall 304 | gb_free 6.1 | wall 40149
KL Stats: Epoch 122 Divergences: Uniform: 2.978588301289944 Unigram: 3.848262278492907
2022-02-02 17:16:25 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:21:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:21:54 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.107 | ppl 1102.79 | wps 8666.6 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.289
2022-02-02 17:21:54 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 17:21:54 | INFO | train | epoch 123 | loss 5.634 | ppl 49.66 | wps 6339.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.818 | train_wall 303 | gb_free 6.1 | wall 40478
KL Stats: Epoch 123 Divergences: Uniform: 2.984746294978244 Unigram: 3.8611452652515963
2022-02-02 17:21:54 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 17:21:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:24:08 | INFO | train_inner | epoch 124:     28 / 64 loss=5.625, ppl=49.35, wps=6204.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.828, train_wall=474, gb_free=6.1, wall=40612
2022-02-02 17:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:27:24 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.066 | ppl 1071.74 | wps 8647.5 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.289
2022-02-02 17:27:24 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 17:27:24 | INFO | train | epoch 124 | loss 5.624 | ppl 49.33 | wps 6339.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.848 | train_wall 303 | gb_free 6.1 | wall 40808
KL Stats: Epoch 124 Divergences: Uniform: 2.995310533115507 Unigram: 3.863261822007573
2022-02-02 17:27:24 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 17:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:32:29 | INFO | train_inner | epoch 125:     64 / 64 loss=5.628, ppl=49.47, wps=6502.7, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.828, train_wall=475, gb_free=6.1, wall=41113
2022-02-02 17:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:32:55 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.11 | ppl 1104.82 | wps 8627.5 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.289
2022-02-02 17:32:55 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 17:32:55 | INFO | train | epoch 125 | loss 5.612 | ppl 48.91 | wps 6313.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.822 | train_wall 305 | gb_free 6.1 | wall 41139
KL Stats: Epoch 125 Divergences: Uniform: 2.991421706508225 Unigram: 3.8789489103114927
2022-02-02 17:32:55 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 17:32:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:38:26 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.11 | ppl 1104.87 | wps 8614.8 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.289
2022-02-02 17:38:26 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 17:38:26 | INFO | train | epoch 126 | loss 5.602 | ppl 48.56 | wps 6308.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.829 | train_wall 305 | gb_free 6.1 | wall 41470
KL Stats: Epoch 126 Divergences: Uniform: 2.996278226507858 Unigram: 3.8876536526364642
2022-02-02 17:38:26 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 17:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:41:18 | INFO | train_inner | epoch 127:     36 / 64 loss=5.587, ppl=48.07, wps=6177.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.832, train_wall=477, gb_free=6.1, wall=41642
2022-02-02 17:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:43:57 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.117 | ppl 1110.36 | wps 8613.2 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.289
2022-02-02 17:43:57 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 17:43:57 | INFO | train | epoch 127 | loss 5.591 | ppl 48.19 | wps 6311.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.835 | train_wall 305 | gb_free 6.1 | wall 41801
KL Stats: Epoch 127 Divergences: Uniform: 3.0066478058755317 Unigram: 3.894544869595192
2022-02-02 17:43:57 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 17:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:49:27 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.112 | ppl 1106.6 | wps 8660 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.289
2022-02-02 17:49:27 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 17:49:27 | INFO | train | epoch 128 | loss 5.58 | ppl 47.85 | wps 6314.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.837 | train_wall 305 | gb_free 6.1 | wall 42131
KL Stats: Epoch 128 Divergences: Uniform: 2.999154718621699 Unigram: 3.9001945943447205
2022-02-02 17:49:27 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 17:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:50:06 | INFO | train_inner | epoch 129:      8 / 64 loss=5.59, ppl=48.17, wps=6180.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.834, train_wall=476, gb_free=6.1, wall=42170
2022-02-02 17:54:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:54:58 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.129 | ppl 1120.08 | wps 8627.2 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.289
2022-02-02 17:54:58 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 17:54:58 | INFO | train | epoch 129 | loss 5.572 | ppl 47.58 | wps 6314.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.86 | train_wall 305 | gb_free 6.1 | wall 42462
KL Stats: Epoch 129 Divergences: Uniform: 3.004913625535148 Unigram: 3.910356540019598
2022-02-02 17:54:58 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 17:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:58:29 | INFO | train_inner | epoch 130:     44 / 64 loss=5.561, ppl=47.22, wps=6491.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.849, train_wall=477, gb_free=6.1, wall=42673
2022-02-02 18:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:00:29 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.107 | ppl 1102.72 | wps 8625 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.289
2022-02-02 18:00:29 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:00:29 | INFO | train | epoch 130 | loss 5.561 | ppl 47.22 | wps 6310.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.83 | train_wall 305 | gb_free 6.1 | wall 42793
KL Stats: Epoch 130 Divergences: Uniform: 3.001679517404799 Unigram: 3.9134314791446148
2022-02-02 18:00:29 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:00:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:05:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:06:00 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.091 | ppl 1090.49 | wps 8627 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.289
2022-02-02 18:06:00 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:06:00 | INFO | train | epoch 131 | loss 5.554 | ppl 46.98 | wps 6304 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.875 | train_wall 305 | gb_free 6.1 | wall 43124
KL Stats: Epoch 131 Divergences: Uniform: 3.0125916337522463 Unigram: 3.9264409752670946
2022-02-02 18:06:00 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:07:17 | INFO | train_inner | epoch 132:     16 / 64 loss=5.553, ppl=46.94, wps=6171.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.863, train_wall=476, gb_free=6.1, wall=43201
2022-02-02 18:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:11:32 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.165 | ppl 1147.95 | wps 8648.5 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.289
2022-02-02 18:11:32 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:11:32 | INFO | train | epoch 132 | loss 5.541 | ppl 46.56 | wps 6307 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.849 | train_wall 305 | gb_free 6.1 | wall 43456
KL Stats: Epoch 132 Divergences: Uniform: 3.0120629439923268 Unigram: 3.9372637950204714
2022-02-02 18:11:32 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:15:41 | INFO | train_inner | epoch 133:     52 / 64 loss=5.54, ppl=46.52, wps=6495.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.868, train_wall=477, gb_free=6.1, wall=43704
2022-02-02 18:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:17:02 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.107 | ppl 1102.86 | wps 8678.1 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.289
2022-02-02 18:17:02 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 18:17:02 | INFO | train | epoch 133 | loss 5.534 | ppl 46.32 | wps 6325.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.884 | train_wall 304 | gb_free 6.1 | wall 43786
KL Stats: Epoch 133 Divergences: Uniform: 3.010479550863233 Unigram: 3.937772635931023
2022-02-02 18:17:02 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 18:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:22:31 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.151 | ppl 1136.77 | wps 8667.7 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.289
2022-02-02 18:22:31 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 18:22:31 | INFO | train | epoch 134 | loss 5.523 | ppl 45.97 | wps 6343.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.89 | train_wall 303 | gb_free 6.1 | wall 44115
KL Stats: Epoch 134 Divergences: Uniform: 3.0080368082839755 Unigram: 3.948690772109491
2022-02-02 18:22:31 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 18:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:24:26 | INFO | train_inner | epoch 135:     24 / 64 loss=5.522, ppl=45.95, wps=6206.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.884, train_wall=474, gb_free=6.1, wall=44230
2022-02-02 18:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:28:01 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.198 | ppl 1175.01 | wps 8662.3 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.289
2022-02-02 18:28:01 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 18:28:01 | INFO | train | epoch 135 | loss 5.513 | ppl 45.66 | wps 6334.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.868 | train_wall 304 | gb_free 6.1 | wall 44445
KL Stats: Epoch 135 Divergences: Uniform: 3.015229747182149 Unigram: 3.956322853056209
2022-02-02 18:28:01 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 18:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:32:47 | INFO | train_inner | epoch 136:     60 / 64 loss=5.512, ppl=45.63, wps=6515.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.89, train_wall=475, gb_free=6.1, wall=44731
2022-02-02 18:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:33:31 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.179 | ppl 1159.31 | wps 8678.7 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.289
2022-02-02 18:33:31 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 18:33:31 | INFO | train | epoch 136 | loss 5.505 | ppl 45.41 | wps 6332.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.904 | train_wall 304 | gb_free 6.1 | wall 44775
KL Stats: Epoch 136 Divergences: Uniform: 3.0109757646898454 Unigram: 3.9663931691694194
2022-02-02 18:33:31 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 18:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:39:00 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.112 | ppl 1106.64 | wps 8651.6 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.289
2022-02-02 18:39:00 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 18:39:00 | INFO | train | epoch 137 | loss 5.496 | ppl 45.14 | wps 6333.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.914 | train_wall 304 | gb_free 6.1 | wall 45104
KL Stats: Epoch 137 Divergences: Uniform: 3.019472638607237 Unigram: 3.9702269697633787
2022-02-02 18:39:00 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 18:39:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:41:33 | INFO | train_inner | epoch 138:     32 / 64 loss=5.486, ppl=44.83, wps=6200.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.905, train_wall=474, gb_free=6.1, wall=45257
2022-02-02 18:44:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:44:30 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.15 | ppl 1136.26 | wps 8687.2 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.289
2022-02-02 18:44:30 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 18:44:30 | INFO | train | epoch 138 | loss 5.488 | ppl 44.88 | wps 6341 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.907 | train_wall 303 | gb_free 6.1 | wall 45434
KL Stats: Epoch 138 Divergences: Uniform: 3.0223725388116747 Unigram: 3.9768881148039052
2022-02-02 18:44:30 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 18:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:49:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:49:59 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.16 | ppl 1144.01 | wps 8704.9 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.289
2022-02-02 18:49:59 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 18:49:59 | INFO | train | epoch 139 | loss 5.479 | ppl 44.61 | wps 6346.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.911 | train_wall 303 | gb_free 6.1 | wall 45763
KL Stats: Epoch 139 Divergences: Uniform: 3.025936702913673 Unigram: 3.9825406705227313
2022-02-02 18:49:59 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 18:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:50:18 | INFO | train_inner | epoch 140:      4 / 64 loss=5.489, ppl=44.92, wps=6210.9, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.913, train_wall=473, gb_free=6.1, wall=45782
2022-02-02 18:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:55:28 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.162 | ppl 1145.61 | wps 8690 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.289
2022-02-02 18:55:28 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 18:55:28 | INFO | train | epoch 140 | loss 5.47 | ppl 44.33 | wps 6341.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.915 | train_wall 303 | gb_free 6.1 | wall 46092
KL Stats: Epoch 140 Divergences: Uniform: 3.0197523447655596 Unigram: 3.9969008975276616
2022-02-02 18:55:28 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 18:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:58:39 | INFO | train_inner | epoch 141:     40 / 64 loss=5.459, ppl=44, wps=6523.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.913, train_wall=475, gb_free=6.1, wall=46283
2022-02-02 19:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:00:57 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.155 | ppl 1140.04 | wps 8685.1 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.289
2022-02-02 19:00:57 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:00:57 | INFO | train | epoch 141 | loss 5.461 | ppl 44.03 | wps 6347.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.902 | train_wall 303 | gb_free 6.1 | wall 46421
KL Stats: Epoch 141 Divergences: Uniform: 3.030824418603395 Unigram: 4.001265188031762
2022-02-02 19:00:57 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:06:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:06:26 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.236 | ppl 1205.97 | wps 8672.2 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.289
2022-02-02 19:06:26 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:06:26 | INFO | train | epoch 142 | loss 5.453 | ppl 43.8 | wps 6347.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.913 | train_wall 303 | gb_free 6.1 | wall 46750
KL Stats: Epoch 142 Divergences: Uniform: 3.030391341995463 Unigram: 4.012061931586403
2022-02-02 19:06:26 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:06:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:07:24 | INFO | train_inner | epoch 143:     12 / 64 loss=5.458, ppl=43.96, wps=6213.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.91, train_wall=473, gb_free=6.1, wall=46808
2022-02-02 19:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:11:56 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.171 | ppl 1153.25 | wps 8673.9 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.289
2022-02-02 19:11:56 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 19:11:56 | INFO | train | epoch 143 | loss 5.445 | ppl 43.57 | wps 6340.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.93 | train_wall 303 | gb_free 6.1 | wall 47080
KL Stats: Epoch 143 Divergences: Uniform: 3.0329551212109305 Unigram: 4.016023261463489
2022-02-02 19:11:56 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 19:11:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:15:45 | INFO | train_inner | epoch 144:     48 / 64 loss=5.44, ppl=43.41, wps=6517.8, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.933, train_wall=475, gb_free=6.1, wall=47309
2022-02-02 19:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:17:25 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.221 | ppl 1193.29 | wps 8682.3 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.289
2022-02-02 19:17:25 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 19:17:25 | INFO | train | epoch 144 | loss 5.437 | ppl 43.33 | wps 6340.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.933 | train_wall 303 | gb_free 6.1 | wall 47409
KL Stats: Epoch 144 Divergences: Uniform: 3.0337975189202213 Unigram: 4.029350336636113
2022-02-02 19:17:25 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 19:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:22:54 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.213 | ppl 1186.61 | wps 8683.9 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.289
2022-02-02 19:22:54 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 19:22:54 | INFO | train | epoch 145 | loss 5.43 | ppl 43.1 | wps 6341.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.926 | train_wall 303 | gb_free 6.1 | wall 47738
KL Stats: Epoch 145 Divergences: Uniform: 3.0373827599442063 Unigram: 4.030722079465403
2022-02-02 19:22:54 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 19:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:24:30 | INFO | train_inner | epoch 146:     20 / 64 loss=5.427, ppl=43.01, wps=6209.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.936, train_wall=473, gb_free=6.1, wall=47834
2022-02-02 19:27:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:28:24 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.311 | ppl 1270.28 | wps 8692 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.289
2022-02-02 19:28:24 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 19:28:24 | INFO | train | epoch 146 | loss 5.424 | ppl 42.93 | wps 6341.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.954 | train_wall 303 | gb_free 6.1 | wall 48068
KL Stats: Epoch 146 Divergences: Uniform: 3.040268561917308 Unigram: 4.038444363271931
2022-02-02 19:28:24 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 19:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:32:51 | INFO | train_inner | epoch 147:     56 / 64 loss=5.421, ppl=42.86, wps=6520.5, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.946, train_wall=475, gb_free=6.1, wall=48335
2022-02-02 19:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:33:53 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.213 | ppl 1187.19 | wps 8678.4 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.289
2022-02-02 19:33:53 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 19:33:53 | INFO | train | epoch 147 | loss 5.415 | ppl 42.68 | wps 6339.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.946 | train_wall 303 | gb_free 6.1 | wall 48397
KL Stats: Epoch 147 Divergences: Uniform: 3.043955428622534 Unigram: 4.0488425911769195
2022-02-02 19:33:53 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 19:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:39:23 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.207 | ppl 1182.06 | wps 8686.7 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.289
2022-02-02 19:39:23 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 19:39:23 | INFO | train | epoch 148 | loss 5.409 | ppl 42.48 | wps 6342.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.98 | train_wall 303 | gb_free 6.1 | wall 48727
KL Stats: Epoch 148 Divergences: Uniform: 3.0427428064375945 Unigram: 4.050960025414858
2022-02-02 19:39:23 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 19:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:41:36 | INFO | train_inner | epoch 149:     28 / 64 loss=5.407, ppl=42.42, wps=6208, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.969, train_wall=473, gb_free=6.1, wall=48860
2022-02-02 19:44:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:44:52 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.248 | ppl 1215.92 | wps 8674.4 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.289
2022-02-02 19:44:52 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 19:44:52 | INFO | train | epoch 149 | loss 5.402 | ppl 42.29 | wps 6341.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.973 | train_wall 303 | gb_free 6.1 | wall 49056
KL Stats: Epoch 149 Divergences: Uniform: 3.0464387125192194 Unigram: 4.0568552332563605
2022-02-02 19:44:52 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 19:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:49:56 | INFO | train_inner | epoch 150:     64 / 64 loss=5.404, ppl=42.34, wps=6527, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.973, train_wall=473, gb_free=6.1, wall=49360
2022-02-02 19:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:50:21 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.199 | ppl 1175.72 | wps 8677 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.289
2022-02-02 19:50:21 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 19:50:21 | INFO | train | epoch 150 | loss 5.391 | ppl 41.97 | wps 6348.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.963 | train_wall 303 | gb_free 6.1 | wall 49385
KL Stats: Epoch 150 Divergences: Uniform: 3.0426877684663043 Unigram: 4.068259815718934
2022-02-02 19:50:21 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 19:50:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:55:50 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.231 | ppl 1201.65 | wps 8693.3 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.289
2022-02-02 19:55:50 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 19:55:50 | INFO | train | epoch 151 | loss 5.386 | ppl 41.83 | wps 6340 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.003 | train_wall 303 | gb_free 6.1 | wall 49714
KL Stats: Epoch 151 Divergences: Uniform: 3.0425815048928904 Unigram: 4.072017558987174
2022-02-02 19:55:50 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 19:55:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:42 | INFO | train_inner | epoch 152:     36 / 64 loss=5.372, ppl=41.41, wps=6208.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.988, train_wall=475, gb_free=6.1, wall=49886
2022-02-02 20:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:01:20 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.223 | ppl 1194.88 | wps 8671.9 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.289
2022-02-02 20:01:20 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:01:20 | INFO | train | epoch 152 | loss 5.377 | ppl 41.54 | wps 6340 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.976 | train_wall 303 | gb_free 6.1 | wall 50044
KL Stats: Epoch 152 Divergences: Uniform: 3.0404953485692916 Unigram: 4.080204011914574
2022-02-02 20:01:20 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:01:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:06:50 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.149 | ppl 1135.03 | wps 8674.8 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.289
2022-02-02 20:06:50 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 20:06:50 | INFO | train | epoch 153 | loss 5.372 | ppl 41.42 | wps 6330.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 1.01 | train_wall 304 | gb_free 6.1 | wall 50374
KL Stats: Epoch 153 Divergences: Uniform: 3.0460830460746076 Unigram: 4.078701944389293
2022-02-02 20:06:50 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 20:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:07:28 | INFO | train_inner | epoch 154:      8 / 64 loss=5.379, ppl=41.6, wps=6200.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=1.001, train_wall=474, gb_free=6.1, wall=50412
2022-02-02 20:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:12:19 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.267 | ppl 1232.04 | wps 8707.2 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.289
2022-02-02 20:12:19 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 20:12:19 | INFO | train | epoch 154 | loss 5.364 | ppl 41.17 | wps 6340.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.962 | train_wall 303 | gb_free 6.1 | wall 50703
KL Stats: Epoch 154 Divergences: Uniform: 3.043333221952808 Unigram: 4.091950981446599
2022-02-02 20:12:19 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 20:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:15:49 | INFO | train_inner | epoch 155:     44 / 64 loss=5.358, ppl=41.01, wps=6521.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.984, train_wall=475, gb_free=6.1, wall=50913
2022-02-02 20:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:17:48 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.203 | ppl 1178.75 | wps 8681.1 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.289
2022-02-02 20:17:48 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 20:17:48 | INFO | train | epoch 155 | loss 5.358 | ppl 41.02 | wps 6343.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.023 | train_wall 303 | gb_free 6.1 | wall 51032
KL Stats: Epoch 155 Divergences: Uniform: 3.048455810419888 Unigram: 4.101331331970107
2022-02-02 20:17:48 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 20:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:22:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:23:17 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.253 | ppl 1220.12 | wps 8701.3 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.289
2022-02-02 20:23:17 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 20:23:17 | INFO | train | epoch 156 | loss 5.351 | ppl 40.81 | wps 6348.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.03 | train_wall 303 | gb_free 6.1 | wall 51361
KL Stats: Epoch 156 Divergences: Uniform: 3.0499802801908515 Unigram: 4.104875417904911
2022-02-02 20:23:17 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 20:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:24:34 | INFO | train_inner | epoch 157:     16 / 64 loss=5.349, ppl=40.76, wps=6213.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.024, train_wall=473, gb_free=6.1, wall=51438
2022-02-02 20:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:28:46 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.268 | ppl 1233.29 | wps 8700.6 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.289
2022-02-02 20:28:46 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 20:28:46 | INFO | train | epoch 157 | loss 5.343 | ppl 40.6 | wps 6350.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.006 | train_wall 303 | gb_free 6.1 | wall 51690
KL Stats: Epoch 157 Divergences: Uniform: 3.0522968212446 Unigram: 4.1093536109010005
2022-02-02 20:28:46 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 20:28:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:32:54 | INFO | train_inner | epoch 158:     52 / 64 loss=5.346, ppl=40.66, wps=6529.6, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.021, train_wall=474, gb_free=6.1, wall=51938
2022-02-02 20:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:34:15 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.224 | ppl 1195.98 | wps 8698.1 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.289
2022-02-02 20:34:15 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 20:34:15 | INFO | train | epoch 158 | loss 5.339 | ppl 40.47 | wps 6345.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.029 | train_wall 303 | gb_free 6.1 | wall 52019
KL Stats: Epoch 158 Divergences: Uniform: 3.05020666842031 Unigram: 4.118585297863483
2022-02-02 20:34:15 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 20:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:39:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:39:44 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.34 | ppl 1295.87 | wps 8681.1 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.289
2022-02-02 20:39:44 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 20:39:44 | INFO | train | epoch 159 | loss 5.331 | ppl 40.25 | wps 6352.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.014 | train_wall 303 | gb_free 6.1 | wall 52348
KL Stats: Epoch 159 Divergences: Uniform: 3.050720971052878 Unigram: 4.125144936696614
2022-02-02 20:39:44 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 20:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:41:39 | INFO | train_inner | epoch 160:     24 / 64 loss=5.328, ppl=40.16, wps=6216.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.012, train_wall=473, gb_free=6.1, wall=52463
2022-02-02 20:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:45:13 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.19 | ppl 1168.17 | wps 8680.5 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.289
2022-02-02 20:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 20:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint160.pt
2022-02-02 20:45:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint160.pt
2022-02-02 20:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.19) (writing took 6.1990137539978605 seconds)
2022-02-02 20:45:20 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 20:45:20 | INFO | train | epoch 160 | loss 5.325 | ppl 40.08 | wps 6228.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.026 | train_wall 303 | gb_free 6.1 | wall 52683
KL Stats: Epoch 160 Divergences: Uniform: 3.05797675562815 Unigram: 4.1320557037671835
2022-02-02 20:45:20 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 20:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:50:05 | INFO | train_inner | epoch 161:     60 / 64 loss=5.326, ppl=40.12, wps=6450.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.052, train_wall=474, gb_free=6.1, wall=52969
2022-02-02 20:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:50:48 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.312 | ppl 1271.17 | wps 8689.5 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.289
2022-02-02 20:50:48 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 20:50:48 | INFO | train | epoch 161 | loss 5.317 | ppl 39.87 | wps 6353.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.05 | train_wall 303 | gb_free 6.1 | wall 53012
KL Stats: Epoch 161 Divergences: Uniform: 3.0581837709988164 Unigram: 4.133948640192661
2022-02-02 20:50:48 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 20:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:56:17 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.209 | ppl 1183.28 | wps 8710.7 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.289
2022-02-02 20:56:17 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 20:56:17 | INFO | train | epoch 162 | loss 5.312 | ppl 39.73 | wps 6355.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.046 | train_wall 303 | gb_free 6.1 | wall 53341
KL Stats: Epoch 162 Divergences: Uniform: 3.054970436290905 Unigram: 4.139734990534336
2022-02-02 20:56:17 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 20:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:58:49 | INFO | train_inner | epoch 163:     32 / 64 loss=5.301, ppl=39.41, wps=6220.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.055, train_wall=473, gb_free=6.1, wall=53493
2022-02-02 21:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:01:46 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.238 | ppl 1207.85 | wps 8697.6 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.289
2022-02-02 21:01:46 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 21:01:46 | INFO | train | epoch 163 | loss 5.305 | ppl 39.55 | wps 6350.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.068 | train_wall 303 | gb_free 6.1 | wall 53670
KL Stats: Epoch 163 Divergences: Uniform: 3.059768151242205 Unigram: 4.149539146643451
2022-02-02 21:01:46 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 21:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:07:15 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.267 | ppl 1232.37 | wps 8694.4 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.289
2022-02-02 21:07:15 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 21:07:15 | INFO | train | epoch 164 | loss 5.301 | ppl 39.42 | wps 6335.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.074 | train_wall 304 | gb_free 6.1 | wall 53999
KL Stats: Epoch 164 Divergences: Uniform: 3.058179001992298 Unigram: 4.148655435110905
2022-02-02 21:07:15 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 21:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:07:35 | INFO | train_inner | epoch 165:      4 / 64 loss=5.311, ppl=39.71, wps=6207.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.067, train_wall=474, gb_free=6.1, wall=54019
2022-02-02 21:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:12:44 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.294 | ppl 1255.52 | wps 8685.6 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.289
2022-02-02 21:12:44 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 21:12:44 | INFO | train | epoch 165 | loss 5.295 | ppl 39.25 | wps 6351.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.079 | train_wall 303 | gb_free 6.1 | wall 54328
KL Stats: Epoch 165 Divergences: Uniform: 3.0638714901246447 Unigram: 4.1554424105566765
2022-02-02 21:12:44 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 21:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:15:55 | INFO | train_inner | epoch 166:     40 / 64 loss=5.287, ppl=39.04, wps=6528.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.082, train_wall=474, gb_free=6.1, wall=54519
2022-02-02 21:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:18:13 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.222 | ppl 1194.49 | wps 8703 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.289
2022-02-02 21:18:13 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 21:18:13 | INFO | train | epoch 166 | loss 5.29 | ppl 39.13 | wps 6345.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.112 | train_wall 303 | gb_free 6.1 | wall 54657
KL Stats: Epoch 166 Divergences: Uniform: 3.064482594933237 Unigram: 4.157385366840252
2022-02-02 21:18:13 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 21:18:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:23:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:23:42 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.296 | ppl 1257.04 | wps 8674.9 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.289
2022-02-02 21:23:42 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 21:23:42 | INFO | train | epoch 167 | loss 5.281 | ppl 38.87 | wps 6357.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.059 | train_wall 302 | gb_free 6.1 | wall 54986
KL Stats: Epoch 167 Divergences: Uniform: 3.0665507065789517 Unigram: 4.169035044872015
2022-02-02 21:23:42 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 21:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:24:39 | INFO | train_inner | epoch 168:     12 / 64 loss=5.286, ppl=39.01, wps=6221.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.083, train_wall=472, gb_free=6.1, wall=55043
2022-02-02 21:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:29:11 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.277 | ppl 1240.77 | wps 8690.8 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.289
2022-02-02 21:29:11 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 21:29:11 | INFO | train | epoch 168 | loss 5.276 | ppl 38.75 | wps 6352.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.095 | train_wall 303 | gb_free 6.1 | wall 55315
KL Stats: Epoch 168 Divergences: Uniform: 3.0669355398805416 Unigram: 4.173234333845969
2022-02-02 21:29:11 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 21:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:32:59 | INFO | train_inner | epoch 169:     48 / 64 loss=5.271, ppl=38.6, wps=6533.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.102, train_wall=474, gb_free=6.1, wall=55543
2022-02-02 21:34:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:34:40 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.251 | ppl 1218.37 | wps 8665 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.289
2022-02-02 21:34:40 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 21:34:40 | INFO | train | epoch 169 | loss 5.271 | ppl 38.6 | wps 6352.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.099 | train_wall 303 | gb_free 6.1 | wall 55644
KL Stats: Epoch 169 Divergences: Uniform: 3.068828739592937 Unigram: 4.180351132030123
2022-02-02 21:34:40 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 21:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:39:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:40:10 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.312 | ppl 1271.35 | wps 8642.6 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.289
2022-02-02 21:40:10 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 21:40:10 | INFO | train | epoch 170 | loss 5.266 | ppl 38.47 | wps 6321.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.12 | train_wall 304 | gb_free 6.1 | wall 55974
KL Stats: Epoch 170 Divergences: Uniform: 3.0626669935369515 Unigram: 4.181792354456753
2022-02-02 21:40:10 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 21:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:41:45 | INFO | train_inner | epoch 171:     20 / 64 loss=5.264, ppl=38.42, wps=6197.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.12, train_wall=474, gb_free=6.1, wall=56069
2022-02-02 21:45:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:45:39 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.316 | ppl 1274.67 | wps 8690.1 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.289
2022-02-02 21:45:39 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 21:45:39 | INFO | train | epoch 171 | loss 5.256 | ppl 38.23 | wps 6351.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.109 | train_wall 303 | gb_free 6.1 | wall 56303
KL Stats: Epoch 171 Divergences: Uniform: 3.06769161884699 Unigram: 4.192916490636928
2022-02-02 21:45:39 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 21:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:50:05 | INFO | train_inner | epoch 172:     56 / 64 loss=5.261, ppl=38.34, wps=6537.9, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.118, train_wall=473, gb_free=6.1, wall=56569
2022-02-02 21:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:51:07 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.301 | ppl 1261.49 | wps 8700.3 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.289
2022-02-02 21:51:07 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 21:51:07 | INFO | train | epoch 172 | loss 5.254 | ppl 38.15 | wps 6358.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.135 | train_wall 303 | gb_free 6.1 | wall 56631
KL Stats: Epoch 172 Divergences: Uniform: 3.0695558189022982 Unigram: 4.1905792306594405
2022-02-02 21:51:07 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 21:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:56:36 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.327 | ppl 1284.45 | wps 8703.6 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.289
2022-02-02 21:56:36 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 21:56:36 | INFO | train | epoch 173 | loss 5.248 | ppl 38 | wps 6352.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.135 | train_wall 303 | gb_free 6.1 | wall 56960
KL Stats: Epoch 173 Divergences: Uniform: 3.0700588145893097 Unigram: 4.197005376041173
2022-02-02 21:56:36 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 21:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:58:49 | INFO | train_inner | epoch 174:     28 / 64 loss=5.239, ppl=37.76, wps=6220, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.137, train_wall=473, gb_free=6.1, wall=57093
2022-02-02 22:01:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:02:05 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.38 | ppl 1332.87 | wps 8676.9 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.289
2022-02-02 22:02:05 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 22:02:05 | INFO | train | epoch 174 | loss 5.242 | ppl 37.85 | wps 6353.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.145 | train_wall 303 | gb_free 6.1 | wall 57289
KL Stats: Epoch 174 Divergences: Uniform: 3.0657551296012326 Unigram: 4.204184549520453
2022-02-02 22:02:05 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 22:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:07:08 | INFO | train_inner | epoch 175:     64 / 64 loss=5.251, ppl=38.09, wps=6533.1, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.155, train_wall=472, gb_free=6.1, wall=57592
2022-02-02 22:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:07:33 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.326 | ppl 1283.89 | wps 8690.8 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.289
2022-02-02 22:07:33 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 22:07:33 | INFO | train | epoch 175 | loss 5.239 | ppl 37.77 | wps 6353.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.16 | train_wall 303 | gb_free 6.1 | wall 57617
KL Stats: Epoch 175 Divergences: Uniform: 3.075588703472986 Unigram: 4.20896800041622
2022-02-02 22:07:33 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 22:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:13:02 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.279 | ppl 1242.26 | wps 8698.1 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.289
2022-02-02 22:13:02 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 22:13:02 | INFO | train | epoch 176 | loss 5.235 | ppl 37.66 | wps 6353.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.177 | train_wall 303 | gb_free 6.1 | wall 57946
KL Stats: Epoch 176 Divergences: Uniform: 3.084225020406514 Unigram: 4.214209448217129
2022-02-02 22:13:02 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 22:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:15:54 | INFO | train_inner | epoch 177:     36 / 64 loss=5.221, ppl=37.3, wps=6221.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.175, train_wall=474, gb_free=6.1, wall=58118
2022-02-02 22:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:18:31 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.345 | ppl 1300.72 | wps 8714.4 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.289
2022-02-02 22:18:31 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 22:18:31 | INFO | train | epoch 177 | loss 5.227 | ppl 37.45 | wps 6356.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.158 | train_wall 303 | gb_free 6.1 | wall 58275
KL Stats: Epoch 177 Divergences: Uniform: 3.0722911767413548 Unigram: 4.210475880994936
2022-02-02 22:18:31 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 22:18:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:23:59 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.312 | ppl 1271.3 | wps 8680.2 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.289
2022-02-02 22:23:59 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 22:23:59 | INFO | train | epoch 178 | loss 5.221 | ppl 37.3 | wps 6355.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.162 | train_wall 303 | gb_free 6.1 | wall 58603
KL Stats: Epoch 178 Divergences: Uniform: 3.0801871971082964 Unigram: 4.22231274671254
2022-02-02 22:23:59 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 22:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:24:38 | INFO | train_inner | epoch 179:      8 / 64 loss=5.227, ppl=37.45, wps=6222.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.156, train_wall=472, gb_free=6.1, wall=58641
2022-02-02 22:29:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:29:28 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.303 | ppl 1263.01 | wps 8682 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.289
2022-02-02 22:29:28 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 22:29:28 | INFO | train | epoch 179 | loss 5.219 | ppl 37.24 | wps 6351.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.186 | train_wall 303 | gb_free 6.1 | wall 58932
KL Stats: Epoch 179 Divergences: Uniform: 3.079275162125819 Unigram: 4.229293998907896
2022-02-02 22:29:28 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 22:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:32:58 | INFO | train_inner | epoch 180:     44 / 64 loss=5.215, ppl=37.14, wps=6533.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.195, train_wall=474, gb_free=6.1, wall=59142
2022-02-02 22:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:34:57 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.319 | ppl 1277.49 | wps 8722 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.289
2022-02-02 22:34:57 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 22:34:57 | INFO | train | epoch 180 | loss 5.211 | ppl 37.05 | wps 6358.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.196 | train_wall 303 | gb_free 6.1 | wall 59261
KL Stats: Epoch 180 Divergences: Uniform: 3.080915788941737 Unigram: 4.238594648417927
2022-02-02 22:34:57 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 22:34:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:40:25 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.293 | ppl 1254.79 | wps 8682.9 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.289
2022-02-02 22:40:25 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 22:40:25 | INFO | train | epoch 181 | loss 5.208 | ppl 36.95 | wps 6353.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.192 | train_wall 303 | gb_free 6.1 | wall 59589
KL Stats: Epoch 181 Divergences: Uniform: 3.0798369854014025 Unigram: 4.239090971982696
2022-02-02 22:40:25 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 22:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:41:42 | INFO | train_inner | epoch 182:     16 / 64 loss=5.206, ppl=36.92, wps=6223.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.191, train_wall=472, gb_free=6.1, wall=59666
2022-02-02 22:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:45:54 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.379 | ppl 1331.28 | wps 8690.4 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.289
2022-02-02 22:45:54 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 22:45:54 | INFO | train | epoch 182 | loss 5.202 | ppl 36.81 | wps 6355.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.183 | train_wall 303 | gb_free 6.1 | wall 59918
KL Stats: Epoch 182 Divergences: Uniform: 3.0731753698730806 Unigram: 4.24490338540109
2022-02-02 22:45:54 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 22:45:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:50:02 | INFO | train_inner | epoch 183:     52 / 64 loss=5.198, ppl=36.72, wps=6533.7, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.195, train_wall=474, gb_free=6.1, wall=60166
2022-02-02 22:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:51:23 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.307 | ppl 1267.01 | wps 8707.2 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.289
2022-02-02 22:51:23 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-02 22:51:23 | INFO | train | epoch 183 | loss 5.196 | ppl 36.65 | wps 6352.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.201 | train_wall 303 | gb_free 6.1 | wall 60247
KL Stats: Epoch 183 Divergences: Uniform: 3.0804282858061676 Unigram: 4.24713350347662
2022-02-02 22:51:23 | INFO | fairseq.trainer | begin training epoch 184
2022-02-02 22:51:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:56:53 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.361 | ppl 1315.32 | wps 8366.3 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.289
2022-02-02 22:56:53 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-02 22:56:53 | INFO | train | epoch 184 | loss 5.193 | ppl 36.58 | wps 6324.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.217 | train_wall 303 | gb_free 6.1 | wall 60577
KL Stats: Epoch 184 Divergences: Uniform: 3.0769806894470837 Unigram: 4.253260254172076
2022-02-02 22:56:53 | INFO | fairseq.trainer | begin training epoch 185
2022-02-02 22:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:58:50 | INFO | train_inner | epoch 185:     24 / 64 loss=5.191, ppl=36.53, wps=6170, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.213, train_wall=476, gb_free=6.1, wall=60694
2022-02-02 23:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:02:32 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.312 | ppl 1271.22 | wps 8321.8 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.289
2022-02-02 23:02:32 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-02 23:02:32 | INFO | train | epoch 185 | loss 5.189 | ppl 36.49 | wps 6160.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.239 | train_wall 312 | gb_free 6.1 | wall 60916
KL Stats: Epoch 185 Divergences: Uniform: 3.0822800704229687 Unigram: 4.25547102722019
2022-02-02 23:02:32 | INFO | fairseq.trainer | begin training epoch 186
2022-02-02 23:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:07:27 | INFO | train_inner | epoch 186:     60 / 64 loss=5.193, ppl=36.59, wps=6324.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.257, train_wall=489, gb_free=6.1, wall=61211
2022-02-02 23:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:08:11 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.338 | ppl 1294.54 | wps 8338.2 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.289
2022-02-02 23:08:11 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-02 23:08:11 | INFO | train | epoch 186 | loss 5.184 | ppl 36.36 | wps 6156.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.266 | train_wall 312 | gb_free 6.1 | wall 61255
KL Stats: Epoch 186 Divergences: Uniform: 3.0885492872779126 Unigram: 4.263103570400531
2022-02-02 23:08:11 | INFO | fairseq.trainer | begin training epoch 187
2022-02-02 23:08:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:13:50 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.356 | ppl 1310.29 | wps 8355 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.289
2022-02-02 23:13:50 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-02 23:13:50 | INFO | train | epoch 187 | loss 5.179 | ppl 36.23 | wps 6164.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.248 | train_wall 312 | gb_free 6.1 | wall 61594
KL Stats: Epoch 187 Divergences: Uniform: 3.082496692062324 Unigram: 4.2597479699613565
2022-02-02 23:13:50 | INFO | fairseq.trainer | begin training epoch 188
2022-02-02 23:13:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:16:27 | INFO | train_inner | epoch 188:     32 / 64 loss=5.17, ppl=36, wps=6029.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.256, train_wall=487, gb_free=6.1, wall=61751
2022-02-02 23:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:19:30 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.38 | ppl 1332.24 | wps 8347.8 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.289
2022-02-02 23:19:30 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-02 23:19:30 | INFO | train | epoch 188 | loss 5.174 | ppl 36.11 | wps 6154.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.259 | train_wall 312 | gb_free 6.1 | wall 61934
KL Stats: Epoch 188 Divergences: Uniform: 3.0810015512687388 Unigram: 4.267543472716716
2022-02-02 23:19:30 | INFO | fairseq.trainer | begin training epoch 189
2022-02-02 23:19:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:25:09 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.363 | ppl 1317.09 | wps 8444.9 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.289
2022-02-02 23:25:09 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-02 23:25:09 | INFO | train | epoch 189 | loss 5.169 | ppl 35.98 | wps 6160.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.247 | train_wall 312 | gb_free 6.1 | wall 62273
KL Stats: Epoch 189 Divergences: Uniform: 3.0839581199608745 Unigram: 4.272342522939046
2022-02-02 23:25:09 | INFO | fairseq.trainer | begin training epoch 190
2022-02-02 23:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:25:28 | INFO | train_inner | epoch 190:      4 / 64 loss=5.18, ppl=36.24, wps=6026.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.248, train_wall=487, gb_free=6.1, wall=62292
2022-02-02 23:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:30:48 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.305 | ppl 1265.14 | wps 8365.3 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.289
2022-02-02 23:30:48 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-02 23:30:48 | INFO | train | epoch 190 | loss 5.165 | ppl 35.88 | wps 6151.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.249 | train_wall 313 | gb_free 6.1 | wall 62612
KL Stats: Epoch 190 Divergences: Uniform: 3.084678254125386 Unigram: 4.275413235081496
2022-02-02 23:30:48 | INFO | fairseq.trainer | begin training epoch 191
2022-02-02 23:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:34:05 | INFO | train_inner | epoch 191:     40 / 64 loss=5.159, ppl=35.73, wps=6329.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.256, train_wall=489, gb_free=6.1, wall=62809
2022-02-02 23:36:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:36:28 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.293 | ppl 1254.57 | wps 8374 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.289
2022-02-02 23:36:28 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-02 23:36:28 | INFO | train | epoch 191 | loss 5.161 | ppl 35.78 | wps 6154.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.265 | train_wall 312 | gb_free 6.1 | wall 62952
KL Stats: Epoch 191 Divergences: Uniform: 3.0855181588631337 Unigram: 4.280969816581228
2022-02-02 23:36:28 | INFO | fairseq.trainer | begin training epoch 192
2022-02-02 23:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:42:07 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.325 | ppl 1283.03 | wps 8372.8 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.289
2022-02-02 23:42:07 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-02 23:42:07 | INFO | train | epoch 192 | loss 5.158 | ppl 35.7 | wps 6159.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.322 | train_wall 312 | gb_free 6.1 | wall 63291
KL Stats: Epoch 192 Divergences: Uniform: 3.083734997420432 Unigram: 4.281873228282226
2022-02-02 23:42:07 | INFO | fairseq.trainer | begin training epoch 193
2022-02-02 23:42:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:43:06 | INFO | train_inner | epoch 193:     12 / 64 loss=5.156, ppl=35.64, wps=6025.9, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.301, train_wall=487, gb_free=6.1, wall=63350
2022-02-02 23:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:47:46 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.402 | ppl 1353.38 | wps 8353.4 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.289
2022-02-02 23:47:46 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-02 23:47:46 | INFO | train | epoch 193 | loss 5.15 | ppl 35.51 | wps 6160.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.266 | train_wall 312 | gb_free 6.1 | wall 63630
KL Stats: Epoch 193 Divergences: Uniform: 3.0845900454946586 Unigram: 4.290547329004849
2022-02-02 23:47:46 | INFO | fairseq.trainer | begin training epoch 194
2022-02-02 23:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:51:42 | INFO | train_inner | epoch 194:     48 / 64 loss=5.149, ppl=35.48, wps=6332.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.28, train_wall=489, gb_free=6.1, wall=63866
2022-02-02 23:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:53:25 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.296 | ppl 1257.56 | wps 8364.1 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.289
2022-02-02 23:53:25 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-02 23:53:25 | INFO | train | epoch 194 | loss 5.148 | ppl 35.45 | wps 6150.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.312 | train_wall 313 | gb_free 6.1 | wall 63969
KL Stats: Epoch 194 Divergences: Uniform: 3.089652274589352 Unigram: 4.2896545380949185
2022-02-02 23:53:25 | INFO | fairseq.trainer | begin training epoch 195
2022-02-02 23:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:59:05 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.361 | ppl 1314.86 | wps 8335.6 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.289
2022-02-02 23:59:05 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-02 23:59:05 | INFO | train | epoch 195 | loss 5.144 | ppl 35.35 | wps 6156.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.302 | train_wall 312 | gb_free 6.1 | wall 64308
KL Stats: Epoch 195 Divergences: Uniform: 3.0859776590857777 Unigram: 4.294233136530511
2022-02-02 23:59:05 | INFO | fairseq.trainer | begin training epoch 196
2022-02-02 23:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:00:43 | INFO | train_inner | epoch 196:     20 / 64 loss=5.144, ppl=35.37, wps=6025.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.318, train_wall=487, gb_free=6.1, wall=64407
2022-02-03 00:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:04:44 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.348 | ppl 1303.57 | wps 8368 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.289
2022-02-03 00:04:44 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 00:04:44 | INFO | train | epoch 196 | loss 5.142 | ppl 35.31 | wps 6157 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.359 | train_wall 312 | gb_free 6.1 | wall 64648
KL Stats: Epoch 196 Divergences: Uniform: 3.0853248977999765 Unigram: 4.299482229387713
2022-02-03 00:04:44 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 00:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:09:19 | INFO | train_inner | epoch 197:     56 / 64 loss=5.141, ppl=35.29, wps=6328.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.376, train_wall=489, gb_free=6.1, wall=64923
2022-02-03 00:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:10:24 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.299 | ppl 1260.25 | wps 8363.5 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.289
2022-02-03 00:10:24 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 00:10:24 | INFO | train | epoch 197 | loss 5.137 | ppl 35.19 | wps 6147.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.384 | train_wall 313 | gb_free 6.1 | wall 64987
KL Stats: Epoch 197 Divergences: Uniform: 3.0913434953516026 Unigram: 4.302780242798014
2022-02-03 00:10:24 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 00:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:16:02 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.367 | ppl 1320.24 | wps 8483.2 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.289
2022-02-03 00:16:02 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 00:16:02 | INFO | train | epoch 198 | loss 5.132 | ppl 35.06 | wps 6165.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.337 | train_wall 312 | gb_free 6.1 | wall 65326
KL Stats: Epoch 198 Divergences: Uniform: 3.088772303043235 Unigram: 4.30527336799564
2022-02-03 00:16:02 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 00:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:18:20 | INFO | train_inner | epoch 199:     28 / 64 loss=5.128, ppl=34.96, wps=6022.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.355, train_wall=488, gb_free=6.1, wall=65464
2022-02-03 00:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:21:42 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.312 | ppl 1271.53 | wps 8339.5 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.289
2022-02-03 00:21:42 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 00:21:42 | INFO | train | epoch 199 | loss 5.13 | ppl 35.01 | wps 6141.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.377 | train_wall 313 | gb_free 6.1 | wall 65666
KL Stats: Epoch 199 Divergences: Uniform: 3.0911290667822136 Unigram: 4.310557205201889
2022-02-03 00:21:42 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 00:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:26:55 | INFO | train_inner | epoch 200:     64 / 64 loss=5.135, ppl=35.13, wps=6331.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.367, train_wall=487, gb_free=6.1, wall=65979
2022-02-03 00:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:27:21 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.361 | ppl 1315.14 | wps 8349.2 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.289
2022-02-03 00:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 00:27:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint200.pt
2022-02-03 00:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint200.pt
2022-02-03 00:27:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.1_0.0_0.9_#1/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.361) (writing took 3.7556584810081404 seconds)
2022-02-03 00:27:25 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 00:27:25 | INFO | train | epoch 200 | loss 5.123 | ppl 34.85 | wps 6090.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.365 | train_wall 312 | gb_free 6.1 | wall 66009
KL Stats: Epoch 200 Divergences: Uniform: 3.0935155913610752 Unigram: 4.316573498992987
2022-02-03 00:27:25 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 00:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:33:05 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.353 | ppl 1307.44 | wps 8356.5 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.289
2022-02-03 00:33:05 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 00:33:05 | INFO | train | epoch 201 | loss 5.119 | ppl 34.75 | wps 6151.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.356 | train_wall 312 | gb_free 6.1 | wall 66349
KL Stats: Epoch 201 Divergences: Uniform: 3.094132025507467 Unigram: 4.315744295894862
2022-02-03 00:33:05 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 00:33:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:36:02 | INFO | train_inner | epoch 202:     36 / 64 loss=5.108, ppl=34.48, wps=5981.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.346, train_wall=489, gb_free=6.1, wall=66526
2022-02-03 00:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:38:44 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.413 | ppl 1363.75 | wps 8351.8 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.289
2022-02-03 00:38:44 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 00:38:44 | INFO | train | epoch 202 | loss 5.114 | ppl 34.62 | wps 6154.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.334 | train_wall 312 | gb_free 6.1 | wall 66688
KL Stats: Epoch 202 Divergences: Uniform: 3.096454348820239 Unigram: 4.325305218068007
2022-02-03 00:38:44 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 00:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:44:24 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.409 | ppl 1359.64 | wps 8378.6 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.289
2022-02-03 00:44:24 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 00:44:24 | INFO | train | epoch 203 | loss 5.113 | ppl 34.61 | wps 6150.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.415 | train_wall 313 | gb_free 6.1 | wall 67028
KL Stats: Epoch 203 Divergences: Uniform: 3.0920661059793133 Unigram: 4.3224774141392075
2022-02-03 00:44:24 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 00:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:45:03 | INFO | train_inner | epoch 204:      8 / 64 loss=5.118, ppl=34.74, wps=6020.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.388, train_wall=488, gb_free=6.1, wall=67067
2022-02-03 00:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:50:03 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.313 | ppl 1272.16 | wps 8357.8 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.289
2022-02-03 00:50:03 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 00:50:03 | INFO | train | epoch 204 | loss 5.109 | ppl 34.51 | wps 6159.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.4 | train_wall 312 | gb_free 6.1 | wall 67367
KL Stats: Epoch 204 Divergences: Uniform: 3.093592055786783 Unigram: 4.32661419278825
2022-02-03 00:50:03 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 00:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:53:39 | INFO | train_inner | epoch 205:     44 / 64 loss=5.101, ppl=34.31, wps=6333, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.424, train_wall=489, gb_free=6.1, wall=67583
2022-02-03 00:55:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:55:42 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.345 | ppl 1300.65 | wps 8371.5 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.289
2022-02-03 00:55:42 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-03 00:55:42 | INFO | train | epoch 205 | loss 5.104 | ppl 34.39 | wps 6153.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.435 | train_wall 312 | gb_free 6.1 | wall 67706
KL Stats: Epoch 205 Divergences: Uniform: 3.096254860301892 Unigram: 4.334866137913053
2022-02-03 00:55:42 | INFO | fairseq.trainer | begin training epoch 206
2022-02-03 00:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:01:22 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.363 | ppl 1316.67 | wps 8376.8 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.289
2022-02-03 01:01:22 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-03 01:01:22 | INFO | train | epoch 206 | loss 5.1 | ppl 34.3 | wps 6146.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.44 | train_wall 313 | gb_free 6.1 | wall 68046
KL Stats: Epoch 206 Divergences: Uniform: 3.096551409521158 Unigram: 4.336237529410926
2022-02-03 01:01:22 | INFO | fairseq.trainer | begin training epoch 207
2022-02-03 01:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:02:41 | INFO | train_inner | epoch 207:     16 / 64 loss=5.103, ppl=34.38, wps=6020, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.44, train_wall=488, gb_free=6.1, wall=68125
2022-02-03 01:06:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:07:01 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.32 | ppl 1278.57 | wps 8446.7 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.289
2022-02-03 01:07:01 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-03 01:07:01 | INFO | train | epoch 207 | loss 5.097 | ppl 34.23 | wps 6162.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.449 | train_wall 312 | gb_free 6.1 | wall 68385
KL Stats: Epoch 207 Divergences: Uniform: 3.0999561797445527 Unigram: 4.338820553545522
2022-02-03 01:07:01 | INFO | fairseq.trainer | begin training epoch 208
2022-02-03 01:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:11:17 | INFO | train_inner | epoch 208:     52 / 64 loss=5.096, ppl=34.2, wps=6328.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.449, train_wall=489, gb_free=6.1, wall=68641
2022-02-03 01:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:12:41 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.398 | ppl 1349.33 | wps 8388.5 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.289
2022-02-03 01:12:41 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-03 01:12:41 | INFO | train | epoch 208 | loss 5.092 | ppl 34.12 | wps 6146.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.459 | train_wall 313 | gb_free 6.1 | wall 68725
KL Stats: Epoch 208 Divergences: Uniform: 3.0946665658878847 Unigram: 4.347601947708231
2022-02-03 01:12:41 | INFO | fairseq.trainer | begin training epoch 209
2022-02-03 01:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:17:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:18:20 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 10.381 | ppl 1333.52 | wps 8355.9 | wpb 2034.1 | bsz 4 | num_updates 13376 | best_loss 9.289
2022-02-03 01:18:20 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-02-03 01:18:20 | INFO | train | epoch 209 | loss 5.089 | ppl 34.03 | wps 6160.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13376 | lr 0.000273424 | gnorm 1.46 | train_wall 312 | gb_free 6.1 | wall 69064
KL Stats: Epoch 209 Divergences: Uniform: 3.1014307682851765 Unigram: 4.352269273411682
2022-02-03 01:18:20 | INFO | fairseq.trainer | begin training epoch 210
2022-02-03 01:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:20:18 | INFO | train_inner | epoch 210:     24 / 64 loss=5.083, ppl=33.91, wps=6028.1, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=13400, lr=0.000273179, gnorm=1.452, train_wall=487, gb_free=6.1, wall=69182
2022-02-03 01:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:23:59 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 10.391 | ppl 1342.77 | wps 8371.9 | wpb 2034.1 | bsz 4 | num_updates 13440 | best_loss 9.289
2022-02-03 01:23:59 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-02-03 01:23:59 | INFO | train | epoch 210 | loss 5.084 | ppl 33.92 | wps 6153.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13440 | lr 0.000272772 | gnorm 1.438 | train_wall 312 | gb_free 6.1 | wall 69403
KL Stats: Epoch 210 Divergences: Uniform: 3.0951524597774123 Unigram: 4.348915997685933
2022-02-03 01:23:59 | INFO | fairseq.trainer | begin training epoch 211
2022-02-03 01:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:28:54 | INFO | train_inner | epoch 211:     60 / 64 loss=5.092, ppl=34.11, wps=6330.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=13500, lr=0.000272166, gnorm=1.484, train_wall=489, gb_free=6.1, wall=69698
2022-02-03 01:29:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:29:39 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 10.379 | ppl 1331.9 | wps 8353.4 | wpb 2034.1 | bsz 4 | num_updates 13504 | best_loss 9.289
2022-02-03 01:29:39 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-02-03 01:29:39 | INFO | train | epoch 211 | loss 5.084 | ppl 33.91 | wps 6154.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13504 | lr 0.000272125 | gnorm 1.504 | train_wall 312 | gb_free 6.1 | wall 69743
KL Stats: Epoch 211 Divergences: Uniform: 3.0990530830777807 Unigram: 4.348298650395325
2022-02-03 01:29:39 | INFO | fairseq.trainer | begin training epoch 212
2022-02-03 01:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:34:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:35:18 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 10.39 | ppl 1341.51 | wps 8336.7 | wpb 2034.1 | bsz 4 | num_updates 13568 | best_loss 9.289
2022-02-03 01:35:18 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-02-03 01:35:18 | INFO | train | epoch 212 | loss 5.078 | ppl 33.78 | wps 6150.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13568 | lr 0.000271483 | gnorm 1.49 | train_wall 313 | gb_free 6.1 | wall 70082
KL Stats: Epoch 212 Divergences: Uniform: 3.097152784565952 Unigram: 4.354277507919129
2022-02-03 01:35:18 | INFO | fairseq.trainer | begin training epoch 213
2022-02-03 01:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:37:55 | INFO | train_inner | epoch 213:     32 / 64 loss=5.069, ppl=33.57, wps=6022.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13600, lr=0.000271163, gnorm=1.504, train_wall=488, gb_free=6.1, wall=70239
2022-02-03 01:40:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:40:57 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 10.359 | ppl 1313.29 | wps 8379.9 | wpb 2034.1 | bsz 4 | num_updates 13632 | best_loss 9.289
2022-02-03 01:40:57 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-02-03 01:40:57 | INFO | train | epoch 213 | loss 5.074 | ppl 33.68 | wps 6158 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13632 | lr 0.000270845 | gnorm 1.516 | train_wall 312 | gb_free 6.1 | wall 70421
KL Stats: Epoch 213 Divergences: Uniform: 3.0930725090037012 Unigram: 4.357438622926321
2022-02-03 01:40:57 | INFO | fairseq.trainer | begin training epoch 214
2022-02-03 01:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:46:37 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 10.398 | ppl 1349.38 | wps 8341.9 | wpb 2034.1 | bsz 4 | num_updates 13696 | best_loss 9.289
2022-02-03 01:46:37 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-02-03 01:46:37 | INFO | train | epoch 214 | loss 5.071 | ppl 33.61 | wps 6155.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13696 | lr 0.000270211 | gnorm 1.489 | train_wall 312 | gb_free 6.1 | wall 70761
KL Stats: Epoch 214 Divergences: Uniform: 3.1005871168941694 Unigram: 4.356060558882915
2022-02-03 01:46:37 | INFO | fairseq.trainer | begin training epoch 215
2022-02-03 01:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:46:56 | INFO | train_inner | epoch 215:      4 / 64 loss=5.078, ppl=33.78, wps=6025.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=13700, lr=0.000270172, gnorm=1.49, train_wall=487, gb_free=6.1, wall=70780
2022-02-03 01:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:52:16 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 10.379 | ppl 1331.65 | wps 8392.3 | wpb 2034.1 | bsz 4 | num_updates 13760 | best_loss 9.289
2022-02-03 01:52:16 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-02-03 01:52:16 | INFO | train | epoch 215 | loss 5.068 | ppl 33.55 | wps 6156.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13760 | lr 0.000269582 | gnorm 1.528 | train_wall 312 | gb_free 6.1 | wall 71100
KL Stats: Epoch 215 Divergences: Uniform: 3.0994656531481652 Unigram: 4.364809145040635
2022-02-03 01:52:16 | INFO | fairseq.trainer | begin training epoch 216
2022-02-03 01:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:55:32 | INFO | train_inner | epoch 216:     40 / 64 loss=5.057, ppl=33.3, wps=6336.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13800, lr=0.000269191, gnorm=1.522, train_wall=488, gb_free=6.1, wall=71296
2022-02-03 01:57:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:57:55 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 10.391 | ppl 1342.98 | wps 8424.9 | wpb 2034.1 | bsz 4 | num_updates 13824 | best_loss 9.289
2022-02-03 01:57:55 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-02-03 01:57:55 | INFO | train | epoch 216 | loss 5.063 | ppl 33.44 | wps 6168.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13824 | lr 0.000268957 | gnorm 1.515 | train_wall 312 | gb_free 6.1 | wall 71439
KL Stats: Epoch 216 Divergences: Uniform: 3.1017348494362524 Unigram: 4.371477069295993
2022-02-03 01:57:55 | INFO | fairseq.trainer | begin training epoch 217
2022-02-03 01:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:03:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:03:34 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 10.412 | ppl 1362.63 | wps 8352.8 | wpb 2034.1 | bsz 4 | num_updates 13888 | best_loss 9.289
2022-02-03 02:03:34 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-02-03 02:03:34 | INFO | train | epoch 217 | loss 5.06 | ppl 33.35 | wps 6147.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13888 | lr 0.000268337 | gnorm 1.52 | train_wall 313 | gb_free 6.1 | wall 71778
KL Stats: Epoch 217 Divergences: Uniform: 3.0981708097817684 Unigram: 4.3675583034317285
2022-02-03 02:03:34 | INFO | fairseq.trainer | begin training epoch 218
2022-02-03 02:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:04:33 | INFO | train_inner | epoch 218:     12 / 64 loss=5.066, ppl=33.49, wps=6024.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13900, lr=0.000268221, gnorm=1.538, train_wall=488, gb_free=6.1, wall=71837
User defined signal 2
