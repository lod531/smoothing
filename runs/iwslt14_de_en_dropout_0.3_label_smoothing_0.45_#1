Sender: LSF System <lsfadmin@eu-g3-055>
Subject: Job 210582172: <iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:27:29 2022
Job was executed on host(s) <eu-g3-055>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:32:08 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:32:08 2022
Terminated at Wed Mar 23 10:48:28 2022
Results reported at Wed Mar 23 10:48:28 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.45 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4570.78 sec.
    Max Memory :                                 5073 MB
    Average Memory :                             3856.71 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14927.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4586 sec.
    Turnaround time :                            4859 sec.

The output (if any) follows:

2022-03-23 09:32:15 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.45, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.45, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:32:15 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:32:15 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:32:15 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:32:15 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:32:15 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:32:15 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:32:15 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:32:15 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:32:15 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:32:15 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:32:15 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:32:18 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:32:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:32:18 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:32:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:32:18 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:32:18 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:32:18 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 09:32:18 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 09:32:18 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:32:18 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:32:18 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:32:18 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:32:18 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:32:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:32:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:32:54 | INFO | train_inner | epoch 001:    103 / 157 loss=12.582, nll_loss=11.894, ppl=3804.71, wps=81061.3, ups=3.22, wpb=25152.5, bsz=988.6, num_updates=100, lr=1.25e-05, gnorm=2.001, loss_scale=16, train_wall=35, gb_free=14.6, wall=36
2022-03-23 09:32:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:33:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example hypothesis: ,,,.....
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:33:17 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the
2022-03-23 09:33:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:33:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:33:24 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:33:30 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:33:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:53 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:33:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.544 | nll_loss 10.102 | ppl 1098.67 | bleu 0.01 | wps 3924.4 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.5953732210327871 seconds)
2022-03-23 09:33:57 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:33:57 | INFO | train | epoch 001 | loss 12.313 | nll_loss 11.426 | ppl 2752.28 | wps 40717 | ups 1.62 | wpb 25154.9 | bsz 993.7 | num_updates 153 | lr 1.9125e-05 | gnorm 1.557 | loss_scale 8 | train_wall 51 | gb_free 22.4 | wall 99
2022-03-23 09:33:57 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:12 | INFO | train_inner | epoch 002:     47 / 157 loss=11.657, nll_loss=10.303, ppl=1263.47, wps=32442.4, ups=1.28, wpb=25442.4, bsz=1078.6, num_updates=200, lr=2.5e-05, gnorm=0.746, loss_scale=8, train_wall=31, gb_free=14.7, wall=114
2022-03-23 09:34:44 | INFO | train_inner | epoch 002:    147 / 157 loss=11.28, nll_loss=9.607, ppl=779.7, wps=80284.5, ups=3.19, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.808, loss_scale=8, train_wall=31, gb_free=14, wall=145
2022-03-23 09:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:50 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:34:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the.
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the.
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:35:02 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:35:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:35:08 | INFO | fairseq.tasks.translation | example hypothesis: and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:35:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:35:13 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:35:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:35:19 | INFO | fairseq.tasks.translation | example hypothesis: and and the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:35:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:35:25 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:35:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:32 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:35:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:35:34 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:35:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:35:34 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.103 | nll_loss 9.155 | ppl 569.89 | bleu 0.01 | wps 3639.5 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:35:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:35:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:35:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.6803068849840201 seconds)
2022-03-23 09:35:36 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:35:36 | INFO | train | epoch 002 | loss 11.34 | nll_loss 9.724 | ppl 845.97 | wps 39793.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.793 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 198
2022-03-23 09:35:37 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:04 | INFO | train_inner | epoch 003:     90 / 157 loss=11.14, nll_loss=9.303, ppl=631.82, wps=30375.9, ups=1.24, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.737, loss_scale=8, train_wall=30, gb_free=13.7, wall=226
2022-03-23 09:36:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example hypothesis: we the the the.
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:36:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the.
2022-03-23 09:36:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:36:37 | INFO | fairseq.tasks.translation | example hypothesis: and the the, the the the the the the the the the.
2022-03-23 09:36:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:36:42 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, it's, it's, it's, it's, it's, and it's, and it's.
2022-03-23 09:36:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:47 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's's's, it's, it's's's, it's, it's's, it's's's's's, it's's, and it's's, and it's
2022-03-23 09:36:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:53 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the, and the the the the the the, and the the the the, and the the the, and the, and and the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:36:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:59 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, it's, it's, it's, it's, it's, it's, it's's's, and the the the the the the the the the the the the the the the the the, and the the the, and the, and it's, and the the the the
2022-03-23 09:36:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:37:05 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we the the the the the the the the the the the the the the, and the, and the, and the, and the the, and the the the the the, and the the, and the the, and the the the the the the, and the the the the the, and the the the the the the the the the the the the the the the the the, and the the the the the the the the
2022-03-23 09:37:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:13 | INFO | fairseq.tasks.translation | example hypothesis: and it's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:37:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:37:15 | INFO | fairseq.tasks.translation | example hypothesis: and the, we, we, we, we, we, we, we, we, we, we, we, we, we, the the the the the, we, we, we, we, we, we, we, we, we, the the the the the the the, the the the the the the the the the the the the the the the the the the the the the the the the the, the the the the the the the the the the the the the the the the the the the the the the the the the, we, the the the the the the the, we, we, we, we, the the the the the the the, we, we, we, we, we, we, we, we, we, we, the the the the the the, we, the the the the the the the the the the the the the the the the the, we, we, we, we, we, we, the the the the the the the the the the the the the the the the
2022-03-23 09:37:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:37:15 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.979 | nll_loss 8.866 | ppl 466.71 | bleu 0.18 | wps 3523.4 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.18
2022-03-23 09:37:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:37:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:37:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.18) (writing took 1.7617807429633103 seconds)
2022-03-23 09:37:17 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:37:17 | INFO | train | epoch 003 | loss 11.1 | nll_loss 9.221 | ppl 596.83 | wps 39215.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.827 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 299
2022-03-23 09:37:17 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:37:28 | INFO | train_inner | epoch 004:     33 / 157 loss=11.026, nll_loss=9.073, ppl=538.47, wps=30559.1, ups=1.2, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=0.86, loss_scale=8, train_wall=31, gb_free=13.9, wall=310
2022-03-23 09:37:59 | INFO | train_inner | epoch 004:    133 / 157 loss=10.918, nll_loss=8.859, ppl=464.32, wps=80295.7, ups=3.18, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=0.893, loss_scale=8, train_wall=31, gb_free=12.6, wall=341
2022-03-23 09:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:38:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the that is that's the world.
2022-03-23 09:38:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example hypothesis: now, we're to're a to be to be the world of the world.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:38:22 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a to be a a to be a to be a.
2022-03-23 09:38:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:38:27 | INFO | fairseq.tasks.translation | example hypothesis: and it's a that we can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't know
2022-03-23 09:38:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:38:32 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and the world of the world, and the world of the world of the world of the world, and it's the world.
2022-03-23 09:38:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:38:38 | INFO | fairseq.tasks.translation | example hypothesis: but it's a, but it's not not not not not not not not not not not not not not not not the the world, but but but they're the world, but it's the world, but it's the world, but it's the world.
2022-03-23 09:38:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:44 | INFO | fairseq.tasks.translation | example hypothesis: and so we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can the the the to be be be be be to the the world, and that we're the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can the
2022-03-23 09:38:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:51 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:38:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example hypothesis: so, so, we're a a a a a to be a a a a a to be a a to be to be to be to be to be to be a to be a to be a to be a to be to be to be to be, and it, and it, and it, and we have to be a a a to be a a a a a a a a a a a a a a a a a a a a to be to be to be to be, and it, and it's a a a a a to be a a a a a a a a a a a a a a a a a a a a a a a a to be to be to be to be to be to be to be to be to be to be to be, and it, and it, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:54 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.759 | nll_loss 8.318 | ppl 319.14 | bleu 0.85 | wps 3745.2 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.85
2022-03-23 09:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:38:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:38:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.85) (writing took 1.7305476589826867 seconds)
2022-03-23 09:38:55 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:38:55 | INFO | train | epoch 004 | loss 10.919 | nll_loss 8.862 | ppl 465.28 | wps 40123.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.844 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 397
2022-03-23 09:38:56 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:38:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:39:19 | INFO | train_inner | epoch 005:     76 / 157 loss=10.798, nll_loss=8.616, ppl=392.28, wps=30644.5, ups=1.25, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.016, loss_scale=8, train_wall=30, gb_free=13.4, wall=421
2022-03-23 09:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:50 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world of the world in the world in the world, we're going to be the world in
2022-03-23 09:39:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:55 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the world of the world of the world of the world, the world is the world of the world of the world is the world
2022-03-23 09:39:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:40:01 | INFO | fairseq.tasks.translation | example hypothesis: so this is a lot of the world of the lot of the world of the world of the world of the world, and they're going to go to have to be the world
2022-03-23 09:40:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world of the world, and there's going to be a lot, and there's a lot of the world, and there's a lot of a lot of the lot of
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:40:13 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're not not not not not not that we're not not not not not not not not not not not not that that we're not not not not not not not not not that that that that that that that that
2022-03-23 09:40:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:40:18 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world of the world, and the world, and the world of the world, and the world, and the world, and the world, and the world, and the world, and this is the world of the world, and the world,
2022-03-23 09:40:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:40:24 | INFO | fairseq.tasks.translation | example hypothesis: but they're not to be to be that they're going to be a lot, but they're going to be the world, but they're not not not not not not not to be a lot of the world, but they're to be to be to be the world, but they're the world, but they're the world, but they're the
2022-03-23 09:40:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:30 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see that that we can see that we can see the lot of the world of the world of the world, and the world, and the world, and we can see that we can see that we can see the world, and we can see the world, and the world of the world of the world, and we can see that we can see that we can see that we can see that we can see the world of the world of the world
2022-03-23 09:40:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:38 | INFO | fairseq.tasks.translation | example hypothesis: so, "this is," "" "" "this is," "" "this is," "" this is, "" "" "this is," "this is," "" "" this is, "" "this is," this is, "this is," "" this is, "this is," that, "that," "" "" "" "" this is, "" this is, "" "" "" "" "" "" "" "" "" this is, "" "" "" "" this is, "" "" "" this is, "" "" "this is," that, "this is," this is, "" this is, "this is," "" it, "" this is, "" "" "" "" "
2022-03-23 09:40:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:40 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're a lot of the lot of the world, that we're a lot of the world, that we're a lot of the world, that we're a lot of the world, that we're a lot of the world, that we're a lot of the world, that's a lot of the world, that we're a lot of the world, that we're a lot of the world, that we're a lot of the lot of the world, that we can't have to be a lot of the world, that we're a lot of the world, that is that is that we have to have to have to be a lot of the world, that we have to be a lot of the world, that we're a lot of the world, that is to be a lot of the world, that we're a lot of the world, that is that we're a lot of the world, that is to be a lot of the world, that is that is a lot of the world, that's a lot of the
2022-03-23 09:40:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:40 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.613 | nll_loss 8.148 | ppl 283.72 | bleu 1.01 | wps 3226.5 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.01
2022-03-23 09:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.01) (writing took 1.7359548269887455 seconds)
2022-03-23 09:40:42 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:40:42 | INFO | train | epoch 005 | loss 10.715 | nll_loss 8.443 | ppl 348.13 | wps 36942.6 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 0.999 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 504
2022-03-23 09:40:43 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:48 | INFO | train_inner | epoch 006:     19 / 157 loss=10.661, nll_loss=8.335, ppl=322.95, wps=28483.3, ups=1.12, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=0.959, loss_scale=8, train_wall=30, gb_free=14.6, wall=510
2022-03-23 09:41:20 | INFO | train_inner | epoch 006:    119 / 157 loss=10.559, nll_loss=8.126, ppl=279.29, wps=80497.7, ups=3.18, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=0.867, loss_scale=8, train_wall=31, gb_free=13.7, wall=542
2022-03-23 09:41:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:35 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 09:41:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:41:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the world is the most of the world.
2022-03-23 09:41:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:41:44 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be a lot of us to be going to be two.
2022-03-23 09:41:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of there, there's a lot of the world, there's a lot of it's a lot of there's going to be a lot of there.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:54 | INFO | fairseq.tasks.translation | example hypothesis: and it's what we're going to do it's going to do it's going to do that we're going to do it's going to do it's going to do it's going to do it's going to do it's not going
2022-03-23 09:41:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:59 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, in the world, in the world, and the world, and the world, and the world in the world in the world in the world, and the world, in the world, and the world in the world, and the world,
2022-03-23 09:41:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:42:05 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to be a lot of the world, but they're going to be not not not not not going to be a lot of the world, but but they're going to be not going to be a lot of the world, but but they're going to be going to be not not not going to be a lot of the world, but
2022-03-23 09:42:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make a lot of the world, and we're going to see that we're going to see that we're going to see the world, and then we're going to see that we're going to see the world, and then we're going to make a lot of the world, and then we're going to see the world, and we're going to see the world, and we're going to see the world, and we can
2022-03-23 09:42:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:19 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to say, "it's going to say," "it's going to say," it's going to say, "" it's going to say, "" it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," "it's going to say," "" "" "" "" "" "" it's a "" it's going to say, "it's going to say," "it's going to say," "it's going to say," "" "" "" it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "" "" "" ""
2022-03-23 09:42:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:21 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of fact, we're going to be a lot of the most of the world that we're going to be a lot of the most of the world, but if you're going to be going to be a lot of the world, but it's going to be a lot of it's going to do that we're going to be a lot of the most of the most of the most of the most of the world, but it's going to be a lot of the world, but it's going to be a lot of it's going to be going to do that we're going to do that we're going to be a lot of the first first first first way to be a lot of the world, but it's going to be a lot of it's going to be a lot of the world, but it's going to be a lot of it's going to do that it's going to do that we're going to do that we're going to do that we're going to be a lot of the world, which is that
2022-03-23 09:42:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:21 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.393 | nll_loss 7.581 | ppl 191.42 | bleu 1.55 | wps 3577.2 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.55
2022-03-23 09:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 09:42:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:42:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.55) (writing took 1.7605360060115345 seconds)
2022-03-23 09:42:23 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:42:23 | INFO | train | epoch 006 | loss 10.549 | nll_loss 8.106 | ppl 275.49 | wps 39229.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 0.863 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 605
2022-03-23 09:42:23 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:43 | INFO | train_inner | epoch 007:     62 / 157 loss=10.447, nll_loss=7.897, ppl=238.35, wps=30473.2, ups=1.21, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=0.81, loss_scale=8, train_wall=30, gb_free=13.5, wall=624
2022-03-23 09:43:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:16 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 09:43:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:43:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the first thing that you're going to see the most of the most thing.
2022-03-23 09:43:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:43:24 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be able to be able to be able to be able to be able to be new new new new new new new new new new.
2022-03-23 09:43:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:43:29 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot, and there's a lot of the world, and it's a lot of the world.
2022-03-23 09:43:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:43:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're going to do it, and it's going to do that we're going to do it, and it's going to do that we're going to do it's going to do it
2022-03-23 09:43:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:43:40 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of people in the world, and in the world, and it's a lot of people in the world, and it's in the world.
2022-03-23 09:43:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:43:45 | INFO | fairseq.tasks.translation | example hypothesis: but they're not a lot of these are not, but they're going to be, but they're going to be a lot of them, but they're going to be, but they're going to be, but they're going to be a lot of them, but they're going to be, but they're going to be, but they're going
2022-03-23 09:43:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:51 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can take a lot of the world, and so we can see, and we can see that we can see the world, and then we can see the world, and then we can see the world, and then we can get a lot of the world, and then we can see it, and then we can see it is a lot of the world, and then we can see the world, and then we can see that we can see the
2022-03-23 09:43:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:59 | INFO | fairseq.tasks.translation | example hypothesis: and if you said, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "" "
2022-03-23 09:43:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:01 | INFO | fairseq.tasks.translation | example hypothesis: and if it's a lot of the world that we have to be a lot of the world, and the world, and we're going to be a lot of the world, and it's a lot of the world, which is that we're going to be a lot of the world, which is that we're going to be a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is that we're going to do that we're going to do that we're going to do that we're going to do that we're going to be a lot of the world, which is a lot of the world, which is a lot of the world, which is that we're going to be a lot of the world, which is that we're going to do that we're going to have to have to get to be a lot of the world, which is a lot of the world
2022-03-23 09:44:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:01 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.258 | nll_loss 7.315 | ppl 159.24 | bleu 2 | wps 3575.4 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2
2022-03-23 09:44:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 09:44:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:44:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:44:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.0) (writing took 1.7439710719627328 seconds)
2022-03-23 09:44:03 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:44:03 | INFO | train | epoch 007 | loss 10.391 | nll_loss 7.782 | ppl 220.15 | wps 39347.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.808 | loss_scale 8 | train_wall 48 | gb_free 14.5 | wall 705
2022-03-23 09:44:04 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:44:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:05 | INFO | train_inner | epoch 008:      5 / 157 loss=10.351, nll_loss=7.702, ppl=208.29, wps=30257.2, ups=1.21, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=0.799, loss_scale=8, train_wall=30, gb_free=13.8, wall=707
2022-03-23 09:44:36 | INFO | train_inner | epoch 008:    105 / 157 loss=10.259, nll_loss=7.513, ppl=182.65, wps=80867.8, ups=3.22, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.783, loss_scale=8, train_wall=31, gb_free=14.2, wall=738
2022-03-23 09:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:56 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the world.
2022-03-23 09:44:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example hypothesis: that's the most thing of the most thing that you know, the most most most of the most most of the most most of the most of the
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be two two new new new new new new new new new new new new new are two two two two.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a lot, and there's a, and it's a lot.
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:45:14 | INFO | fairseq.tasks.translation | example hypothesis: it's not a lot of what we're going to do, and we're going to do, and we're going to do it.
2022-03-23 09:45:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:45:19 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the people who is the people in the people in the people, and the people in the people in the people in the people, and the people in the people, and the world, and the people who is the people in the
2022-03-23 09:45:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example hypothesis: some of some people are a lot, but it's a lot of people, but it's a lot of people, but it's not a lot of people, but they can't have to be a lot, but it, but it.
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that, we can see the world, and then we can see that we can see the brain, and then we can see it's a lot of the world, and then we can see that we can see the world, and then we can see that is a lot of the world, and then we can see that we can see that we can see that we can see the brain, and then we can see the brain is, and the
2022-03-23 09:45:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example hypothesis: one: one: "you know," you know, "you know," it's one of the first thing, "it's a very," it's a, "it's a" "" "" "" and the first thing, "and the first thing," it's, "it's one of the first thing," you know, "it's one of the first is," you know, "you know," you know, "it's a" "" "" "it's one of the first thing," and the first is, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's a
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, if we've got a lot of the world, it's a lot of the way that we can see that we have to be able to be a lot of the world, and then we can see that we have to be a lot of the world, and then we have to be a lot of the world, and then we can see that we have to be a lot of the same way that we can see that we can see that we can see that we can't have to be a lot of the same time, and then we have to be able to be a lot of the same time, and then we have to be a lot of the same time that we can see that we have to be a lot of the world, and then we have to be a lot of the same time, and then we can be a lot of the world, and then we have to see that we have to be a lot of the way to be able to be a lot of the world, and then we have to be a lot of the same
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:39 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.144 | nll_loss 7.017 | ppl 129.55 | bleu 3.13 | wps 3854.5 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.13
2022-03-23 09:45:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 09:45:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:45:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:45:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.13) (writing took 1.7400836519664153 seconds)
2022-03-23 09:45:41 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:45:41 | INFO | train | epoch 008 | loss 10.274 | nll_loss 7.542 | ppl 186.4 | wps 40533.8 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.785 | loss_scale 8 | train_wall 48 | gb_free 13.6 | wall 803
2022-03-23 09:45:41 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:45:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:56 | INFO | train_inner | epoch 009:     48 / 157 loss=10.219, nll_loss=7.431, ppl=172.58, wps=32071.6, ups=1.25, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=0.723, loss_scale=8, train_wall=31, gb_free=14.5, wall=818
2022-03-23 09:46:27 | INFO | train_inner | epoch 009:    148 / 157 loss=10.154, nll_loss=7.301, ppl=157.65, wps=79971.5, ups=3.23, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.73, loss_scale=8, train_wall=31, gb_free=13.8, wall=849
2022-03-23 09:46:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:34 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in this room.
2022-03-23 09:46:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:46:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most most of the most most.
2022-03-23 09:46:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new york are going to be new new york.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:46:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a example, there's a great place, and it's where it's where it's going to be in the united states.
2022-03-23 09:46:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:46:52 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just just just just just a little bit of what's going to do.
2022-03-23 09:46:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:46:57 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as people like people like people like the people, for the people, for the people, for the most people, for the most people, for the most people, for the people, and it's the people who has been been in the most people in the most people.
2022-03-23 09:46:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:47:02 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of them, but it's a lot of course, but if you're going to see, but it's not a lot of course, but it's not a lot of course, but if it's going to go on, but it's going to go, but it's not a lot of the
2022-03-23 09:47:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the world, we can see the world, we can see that we can see that we can see the world, and then we can see that we can see the world can see that we can see the world, and then we can see the one of the world, and then we can see it's going to take the world, and then we can see the world, and then we can see the world can see that we can
2022-03-23 09:47:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:16 | INFO | fairseq.tasks.translation | example hypothesis: well, one of the one of the one of the reason is, "it's going to say," "" "and it's going to say," "" you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "it's the first thing," "" "" it's the first thing, "" it's the first thing, "well," well, "well," well, "well," "" "" it's the first thing, "it's the first thing," well, "well," it's the first thing, "it's the first thing," "" "" "" "" "" "" "" "" "
2022-03-23 09:47:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:18 | INFO | fairseq.tasks.translation | example hypothesis: so, it's still still still still, if we're going to be a lot of course, and if we're going to do that we're going to have a lot of the world, we're going to do that we're going to have to have a lot of us, and then we're going to be able to have to do that we're going to have to do that we're going to have to be a lot of the world, and then we're going to have to do that we're going to be a lot of the world, and then we're going to have to do that we're going to do that we're going to do that we're going to have to be able to do that we're going to do that we're going to be a lot of the world, and then we're going to be a lot of the same time, if we're going to do that we're going to do that we're going to have to have to be a lot of the same time, if we're going to have to be a
2022-03-23 09:47:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:18 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.979 | nll_loss 6.718 | ppl 105.28 | bleu 4.18 | wps 3729.3 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4.18
2022-03-23 09:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 09:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:47:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.18) (writing took 1.7230607660021633 seconds)
2022-03-23 09:47:20 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:47:20 | INFO | train | epoch 009 | loss 10.137 | nll_loss 7.267 | ppl 153.98 | wps 39899.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.706 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 902
2022-03-23 09:47:20 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:49 | INFO | train_inner | epoch 010:     91 / 157 loss=10.032, nll_loss=7.054, ppl=132.84, wps=30923.3, ups=1.23, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.711, loss_scale=8, train_wall=31, gb_free=14.5, wall=931
2022-03-23 09:47:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:13 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 09:48:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most, most of you know, most of here.
2022-03-23 09:48:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new york.
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:48:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a little bit, where you're going.
2022-03-23 09:48:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:48:28 | INFO | fairseq.tasks.translation | example hypothesis: it's not a little bit that we're going to do a little little bit of the brain, and what's going on.
2022-03-23 09:48:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:48:32 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people are for the people for the people, and that's a lot of people who is a lot of the time.
2022-03-23 09:48:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to see, but if you're going to see, but if you're going to see, it's going to be able to be able to be able to be able to be able to be able to be able, but if you're going to be able to be able to be able to be able to be able,
2022-03-23 09:48:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to use the information that we can see that, we can take a lot of the brain, and then we can see the brain, and then we can see the brain, and then we can see the brain, the brain, the brain, and then we can see the brain, the brain, and then we can see the brain, the brain, the brain, and then we can take a kind of the brain.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:48 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the other thing, and it's going to show me, and then it's going to be a little bit for me, and then we're going to go back to the first time, and then you know, and then we're going to go back back to the first time, and then you know, and then you know, and then you're going to the first time to the first time, and then you're going to go back to the first time, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to go back back back back back back back to the first time,
2022-03-23 09:48:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:50 | INFO | fairseq.tasks.translation | example hypothesis: and then, it's a lot of the time, and that we're going to be a lot of the time, and then we're going to get a little bit of the way that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a lot of the brain, when we have a lot of the brain, when we have a lot of the brain, when we have a lot of the same time, and then we're going to be able to get a lot of the same way that we're going to be a new way that we're going to be able to be able to be able to be able to be able to get a
2022-03-23 09:48:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:50 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.865 | nll_loss 6.45 | ppl 87.42 | bleu 6.28 | wps 4341 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.28
2022-03-23 09:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:48:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.28) (writing took 1.7926161670475267 seconds)
2022-03-23 09:48:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:48:52 | INFO | train | epoch 010 | loss 10.023 | nll_loss 7.034 | ppl 131.04 | wps 42320 | ups 1.68 | wpb 25127.3 | bsz 1014.9 | num_updates 1565 | lr 0.000195625 | gnorm 0.761 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 994
2022-03-23 09:48:53 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:04 | INFO | train_inner | epoch 011:     35 / 157 loss=10.009, nll_loss=7.003, ppl=128.24, wps=33113.4, ups=1.34, wpb=24781, bsz=994.3, num_updates=1600, lr=0.0002, gnorm=0.799, loss_scale=4, train_wall=30, gb_free=13.4, wall=1006
2022-03-23 09:49:35 | INFO | train_inner | epoch 011:    135 / 157 loss=9.854, nll_loss=6.695, ppl=103.64, wps=81374.5, ups=3.19, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.692, loss_scale=4, train_wall=31, gb_free=13.3, wall=1037
2022-03-23 09:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:46 | INFO | fairseq.tasks.translation | example hypothesis: we had this pppppon the end of the house.
2022-03-23 09:49:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:49:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the fact that most of most of most of the most most most most most most most people know here.
2022-03-23 09:49:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new technologies will be two new new new new technologies that are going to be able to be able.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a society where where where where they're going to go with a popppppppppcccccccccca.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:03 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we just just just just just just just just a few months of his head, and what's going to do.
2022-03-23 09:50:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:07 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as people like the people who were working for the number of the number of the number, and it's a number of people.
2022-03-23 09:50:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:50:12 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you are some of the bidddle of the water, but if you don't have the energy, it's not the energy, you don't need to have the energy.
2022-03-23 09:50:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use this information, we can use a kind of rereuse, and that's a kind of information.
2022-03-23 09:50:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:20 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that it's interesting, and it's interesting for me, "you know," well, "you know," well, "well," well, "you know," you know, "you know," you know, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," you know, "well," you know, "well," you know, "well," well, "well," well, "well," you know, "well," well, "well," you know, "well," you know, "you know," you know, "you know," you know, "well," you know, "you know," you know, "well," you know, "
2022-03-23 09:50:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:22 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still, and the mother is a lot of the work that we're going to be able to be a lot of the world that we're going to be able to be able to make a lot of the world.
2022-03-23 09:50:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:22 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.696 | nll_loss 6.102 | ppl 68.69 | bleu 8.59 | wps 4491.3 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.59
2022-03-23 09:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:50:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.59) (writing took 1.9082635919912718 seconds)
2022-03-23 09:50:24 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:50:24 | INFO | train | epoch 011 | loss 9.891 | nll_loss 6.771 | ppl 109.23 | wps 42852.7 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.709 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1086
2022-03-23 09:50:25 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:49 | INFO | train_inner | epoch 012:     78 / 157 loss=9.805, nll_loss=6.6, ppl=97.03, wps=33669.1, ups=1.35, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.675, loss_scale=4, train_wall=31, gb_free=14, wall=1111
2022-03-23 09:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:18 | INFO | fairseq.tasks.translation | example hypothesis: we did that in the end.
2022-03-23 09:51:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:21 | INFO | fairseq.tasks.translation | example hypothesis: that's the right. you know, most of most of most of most.
2022-03-23 09:51:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:25 | INFO | fairseq.tasks.translation | example hypothesis: new york are going to be two ways.
2022-03-23 09:51:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:51:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese chinese chinese chinese chinese chinese chinese, where they're going to go and get with the pppppppp.
2022-03-23 09:51:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:51:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a few few of his head on his head, and what's going on on on.
2022-03-23 09:51:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamase of people who came to the number of people, and the number of animals in the number of animals, and it's a few years.
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are in the top of the top, but if you don't know, it doesn't have to be able to have the energy, and if you need to need to have the energy, you need to need to need to have the energy, the energy.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, we're going to take this kind of structure, we can start to start with a kind of kind of information, and we can take the structure of the structure of the structure, and all the structure of the structure of the structure of the structure, and all the structure of the structure of the structure of the structure of the structure, and all of the structure of the structure of the structure of the structure of the structure, and the
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons that it's interesting for me, and i'm going to be able to be able to say, "well," well, "you know," you know, "you know," you know, "you know," you know, "well," well, "you know," you know, "you know," you know, "you know," you know, "you know," well, "well," well, "well," you know, "you know," well, "well," well, "well," well, "you know," well, "you're going to go to go to go to go back to be in this is that you know," well, "well," well, "well," well, "well," well, "you know," you know, "
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:56 | INFO | fairseq.tasks.translation | example hypothesis: now, in fact, the mother of the mother, and the big way that we had to look at all of the way that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:51:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:56 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.573 | nll_loss 5.75 | ppl 53.83 | bleu 9.5 | wps 4327.7 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.5
2022-03-23 09:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:51:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.5) (writing took 2.13925287098391 seconds)
2022-03-23 09:51:58 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:51:58 | INFO | train | epoch 012 | loss 9.736 | nll_loss 6.463 | ppl 88.21 | wps 42318.6 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.676 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1180
2022-03-23 09:51:58 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:05 | INFO | train_inner | epoch 013:     21 / 157 loss=9.669, nll_loss=6.328, ppl=80.35, wps=33311.1, ups=1.33, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.699, loss_scale=4, train_wall=30, gb_free=13.9, wall=1187
2022-03-23 09:52:36 | INFO | train_inner | epoch 013:    121 / 157 loss=9.616, nll_loss=6.221, ppl=74.61, wps=80688.1, ups=3.19, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.673, loss_scale=4, train_wall=31, gb_free=13.6, wall=1218
2022-03-23 09:52:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:51 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppon in the clinics.
2022-03-23 09:52:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:52:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the car that most, most of most of most of most of the most.
2022-03-23 09:52:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be a new new car that are going to be used.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, and they're going to get with a ppy.
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just going to understand a few ways on his head, and what's going on on on.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamaking people like the responsibility for the number of animals, and this is a number of animals for the animals.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:53:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic is not in the environment, but if you don't need to go to the same energy, and if you don't need your energy, and you need the energy.
2022-03-23 09:53:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this kind of structure, we can start to start with a big structure, and that's all the structure of the structure of the structure, and that's all the structure.
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example hypothesis: hth: one of the reasons, and it's interesting for me to be here for me, "yeah," well, "well," if you say, "the best time we say," the best time, "and then we say," the best time, "the best time we say," and then we've got to say, "the best time," is, "is to say," is to you have a long time. "
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:23 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother of the design, and we've got a lot of work on our work that we had to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 09:53:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:23 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.45 | nll_loss 5.47 | ppl 44.34 | bleu 11.93 | wps 5093.8 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.93
2022-03-23 09:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:53:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:53:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 11.93) (writing took 1.745904244016856 seconds)
2022-03-23 09:53:25 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:53:25 | INFO | train | epoch 013 | loss 9.602 | nll_loss 6.193 | ppl 73.16 | wps 45369.7 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.667 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1267
2022-03-23 09:53:25 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:45 | INFO | train_inner | epoch 014:     64 / 157 loss=9.528, nll_loss=6.049, ppl=66.2, wps=36089.3, ups=1.45, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.642, loss_scale=4, train_wall=30, gb_free=14, wall=1287
2022-03-23 09:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:18 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppon the clinic in the clinic.
2022-03-23 09:54:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of the doha, doha, most of most of the most most of the most of here.
2022-03-23 09:54:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new power of the two ways that are going to get two new ways.
2022-03-23 09:54:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:54:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese chinese food, where they're going to be able to be able to get with.
2022-03-23 09:54:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example hypothesis: it's pretty clear that we don't just get a couple of electrodes on his head on his head, and all of his mind are on the mind.
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:54:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamaes like the responsibility for people who came up to the number of animals, and the number of animals has become become a group.
2022-03-23 09:54:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:42 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magic of the lines in the lines, but in the same time, but if you don't need to get the energy, and the energy of the energy.
2022-03-23 09:54:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can come from a structure, we can start able to start with a different form of the structure, and the whole structure of all the information.
2022-03-23 09:54:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me for me to be here at tedtedtedtedtalk to me, "well, when we've been talking about this time, and then we've been talking to you have a long time."
2022-03-23 09:54:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the mother, and the great design part of the design of our work, and we had to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:52 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.332 | nll_loss 5.212 | ppl 37.07 | bleu 14.05 | wps 4762.3 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.05
2022-03-23 09:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:54:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.05) (writing took 1.7753219649894163 seconds)
2022-03-23 09:54:54 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:54:54 | INFO | train | epoch 014 | loss 9.453 | nll_loss 5.899 | ppl 59.66 | wps 44289.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.621 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1356
2022-03-23 09:54:54 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:57 | INFO | train_inner | epoch 015:      7 / 157 loss=9.395, nll_loss=5.782, ppl=55.01, wps=35685.1, ups=1.4, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.583, loss_scale=4, train_wall=30, gb_free=13.9, wall=1359
2022-03-23 09:55:28 | INFO | train_inner | epoch 015:    107 / 157 loss=9.327, nll_loss=5.646, ppl=50.07, wps=80899.5, ups=3.22, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.644, loss_scale=4, train_wall=31, gb_free=13.9, wall=1390
2022-03-23 09:55:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:47 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppin the clinics.
2022-03-23 09:55:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:55:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of the doha, the most most thing here.
2022-03-23 09:55:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:55:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new york.
2022-03-23 09:55:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:55:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where they're going to do with and ppink.
2022-03-23 09:55:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand what all his mind are on the mind.
2022-03-23 09:56:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the making of the responsibility of the responsibility of the responsibility, the number of animals, and this is a number of animals.
2022-03-23 09:56:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:12 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic magic is in the lines, but it doesn't go to the alalaly, if you're not going to move your energy, it doesn't need your energy, and you need the energy.
2022-03-23 09:56:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start able to start with a traditional structure that can start able to start with a big form of the shape of the structure of the information, and the whole structure of the information, and the whole structure of the whole structure.
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting to make me here for tedwomen -- that it's the best thing that someone's the best thing that we said, "well," the best revolution, "when we're working with you're working with a long revolution," well, "and then we've been working with you're working with you're working with you're working with you're working with you're working with you're working with you're working with you've got a long time."
2022-03-23 09:56:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, it's still the mother of the invention, and a big design part of the work that we had to solve the airplane, that we had to solve a unique system that we had to solve a unique system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're able to see that if we had to see that if we had to use a unique system, it's a unique system, or a unique system with a unique system, it's a unique system, or to see that if we had to see that if we had to see that if you're able to see that it's a unique system, it's a unique system, it's a unique system, it's a unique system, it's a unique system, it's a huge, or a unique system, it's a huge, if we had to see that we had to be able to see that we had
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:23 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.162 | nll_loss 4.873 | ppl 29.31 | bleu 15.87 | wps 4571.3 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.87
2022-03-23 09:56:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:56:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:56:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.87) (writing took 1.8509694910026155 seconds)
2022-03-23 09:56:25 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:56:25 | INFO | train | epoch 015 | loss 9.334 | nll_loss 5.658 | ppl 50.48 | wps 43394.2 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.605 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1447
2022-03-23 09:56:25 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:41 | INFO | train_inner | epoch 016:     50 / 157 loss=9.317, nll_loss=5.621, ppl=49.2, wps=34590.3, ups=1.36, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.56, loss_scale=4, train_wall=31, gb_free=14.3, wall=1463
2022-03-23 09:57:12 | INFO | train_inner | epoch 016:    150 / 157 loss=9.17, nll_loss=5.33, ppl=40.22, wps=80302.5, ups=3.26, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.556, loss_scale=4, train_wall=30, gb_free=14.5, wall=1494
2022-03-23 09:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:18 | INFO | fairseq.tasks.translation | example hypothesis: we made these pace in the clinic.
2022-03-23 09:57:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 09:57:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:57:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 09:57:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where they're going to be salt and salt.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:57:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrodes on his head and understand what all his thoughts are.
2022-03-23 09:57:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals, as the responsibility was grew up, and this is a number of animals.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic lines are in the field, but it may not move if you need their energy, and you don't need your energy, and you need your energy.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start able to start with a very large form of the shape of the shape of the shape, and that's what all the information is, and the information is that all the structure of the structure.
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting for me to be here at tedwomen, "well, is that it was the best thing that someone said," well, "well," if we're talking about the best revolution, "and then we've been talking about you."
2022-03-23 09:57:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:49 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother, and a lot of design that we're going to be able to see is that we had to solve the airplane was a unique result that we had to solve it.
2022-03-23 09:57:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:49 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.117 | nll_loss 4.792 | ppl 27.7 | bleu 13.46 | wps 5381.4 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 15.87
2022-03-23 09:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:57:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 09:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 09:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 13.46) (writing took 0.8499746579909697 seconds)
2022-03-23 09:57:50 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:57:50 | INFO | train | epoch 016 | loss 9.201 | nll_loss 5.391 | ppl 41.97 | wps 46575.5 | ups 1.85 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.575 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1532
2022-03-23 09:57:50 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:20 | INFO | train_inner | epoch 017:     93 / 157 loss=9.107, nll_loss=5.205, ppl=36.89, wps=37410.6, ups=1.48, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.567, loss_scale=4, train_wall=31, gb_free=14.9, wall=1562
2022-03-23 09:58:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:43 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinic in the clinic.
2022-03-23 09:58:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:58:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha doha, which probably know most of them.
2022-03-23 09:58:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create the two new new locks.
2022-03-23 09:58:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food, where happy legs are going to be salt with legs, and they're going to be defeeding.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:59:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrodes on his head and understand what all the thoughts are on the way.
2022-03-23 09:59:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:59:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like the responsibility for the life, the number of animals, the number of animals, and this is a foundation for the devaiiibia.
2022-03-23 09:59:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic lines of magnetic lines, but the sulength of the sulength, if you don't have the energy, you need to move up, and you need to move your energy.
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start to start with a traditional face with a traditional face, which is able to start able to start with a traditional form of the face of the information, and the whole structure of the structure of the structure, and the information that all the structure of the structure of the structure of the structure, and the structure of the structure of the structure of this structure of the structure, and the structure,
2022-03-23 09:59:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, "you know, for me, is to be a long time to be here, you know, you know, when you're going to say," you've been working on this time, you know, you've been working in this time, and then we've been working with you've got a long time, you've been working with you know, "you've been working with you've been working in this time, you've been working with you've got a long time, and you've got a lot of you've been working with you know, you've been working with you know, you know, you know, you've been working with a lot of you know, you've been working on this time, you know, you know, you've been working with you know, you've been working with you know,"
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:22 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a big part of the design of the work that we've had to solve is that we had to solve a unique result of the ground, and it was a unique thing that we had to solve all the problems in the ground.
2022-03-23 09:59:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:23 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.991 | nll_loss 4.519 | ppl 22.93 | bleu 16.41 | wps 4185.4 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 16.41
2022-03-23 09:59:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:59:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:59:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 09:59:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 16.41) (writing took 1.8011417230009101 seconds)
2022-03-23 09:59:24 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:59:24 | INFO | train | epoch 017 | loss 9.098 | nll_loss 5.186 | ppl 36.4 | wps 41749.7 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.561 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1626
2022-03-23 09:59:25 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:36 | INFO | train_inner | epoch 018:     36 / 157 loss=9.055, nll_loss=5.099, ppl=34.27, wps=33022, ups=1.31, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.55, loss_scale=4, train_wall=30, gb_free=14.3, wall=1638
2022-03-23 10:00:07 | INFO | train_inner | epoch 018:    136 / 157 loss=8.98, nll_loss=4.953, ppl=30.97, wps=79592.8, ups=3.21, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.522, loss_scale=4, train_wall=31, gb_free=14.1, wall=1669
2022-03-23 10:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:17 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-23 10:00:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 10:00:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that will create the two new fuels.
2022-03-23 10:00:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:00:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where happy legs will be made with salz and pace.
2022-03-23 10:00:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to just get a few electrodes on his head and understand exactly what all of his thoughts are on the ground.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the responsibility for the living responsibility, the number of living animals, and that's a foundation for the world.
2022-03-23 10:00:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic field of magnetic field, but the sulant is not going to move, if you need your energy, and you need the energy.
2022-03-23 10:00:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that can start with the great face of the face of the face, and the shape of the interfaces, and the shape of the information, and the information is that all the structure of the structure, and the structure is a structure of the structure of the structure that structure, and we can start with a structure.
2022-03-23 10:00:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's interesting and measure it, for me, "is to be a lot of time, and then in tedwomen, and then we've been working with a long time," well, "well, if we've got to support the world," and then we've been working with a coordinarily, "and then we've been working with a lot of time," and then we've been working with a lot of time, "for you've been working with a coordinarily," and then we've been talking to support for the time, "to support for example," to support for you know, "and then we've started to be a coordinarily," and then we've been working with you know, "and then we've started to be a lot of time," and then we've been working with a coordinarily,
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention of the invention, and a big part of the design of the work that we're in our plane, is that we had to solve a result that we had to solve the unique problems that were connected to the ground, and if you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:54 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.846 | nll_loss 4.236 | ppl 18.84 | bleu 20.48 | wps 4436.2 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.48
2022-03-23 10:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 10:00:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:00:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.48) (writing took 1.8883483500103466 seconds)
2022-03-23 10:00:56 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 10:00:56 | INFO | train | epoch 018 | loss 8.979 | nll_loss 4.95 | ppl 30.9 | wps 42933.4 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.505 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1718
2022-03-23 10:00:57 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 10:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:22 | INFO | train_inner | epoch 019:     79 / 157 loss=8.907, nll_loss=4.81, ppl=28.06, wps=34404.1, ups=1.34, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.47, loss_scale=4, train_wall=31, gb_free=14, wall=1744
2022-03-23 10:01:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:49 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 10:01:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 10:01:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:01:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 10:01:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:02:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are and salt with salz.
2022-03-23 10:02:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:02:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand exactly what all his thoughts are on the top.
2022-03-23 10:02:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the responsibility for the wild, the number of animals grew up again, and this is a foundation of natural protection in namibia.
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:02:13 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloods of magnetic field, but the sulens don't seem to move their energy and so forth.
2022-03-23 10:02:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face that can start with a traditional face of the face of the information and reform it through the entire structure of this structure, the whole structure of this reflection.
2022-03-23 10:02:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's interesting and measure for me here at tedwomen is that...
2022-03-23 10:02:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's mother's invention, and a big part of the design work that we're on our plane was a result of the unique problems that were connected to the ground -- all the way we had to be able to be able to use the ground of a continent, and a large part of us, and a big part of the refugegee, to see that we're going to be able to see that if you're going to use the decrease the decrease the deployment, or to be able to see that you're going to see the decrease the decrease the decrease the decrease the power system, or to be able to see that you're going to see the decrease the decrease the power of the decrease the decrease the decrease the power of the decrease the translate the decrease the translate, or a decrease the translate, or to see that you're going to see the de
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:24 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.812 | nll_loss 4.105 | ppl 17.21 | bleu 20.98 | wps 4780.6 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 20.98
2022-03-23 10:02:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 10:02:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:02:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:02:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 20.98) (writing took 1.7917148540145718 seconds)
2022-03-23 10:02:25 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 10:02:25 | INFO | train | epoch 019 | loss 8.864 | nll_loss 4.727 | ppl 26.48 | wps 44359.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.49 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1807
2022-03-23 10:02:26 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 10:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:33 | INFO | train_inner | epoch 020:     22 / 157 loss=8.818, nll_loss=4.636, ppl=24.87, wps=34953.7, ups=1.41, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.485, loss_scale=4, train_wall=30, gb_free=14.7, wall=1815
2022-03-23 10:03:04 | INFO | train_inner | epoch 020:    122 / 157 loss=8.768, nll_loss=4.539, ppl=23.25, wps=81732, ups=3.16, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.441, loss_scale=4, train_wall=31, gb_free=13.6, wall=1846
2022-03-23 10:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these weak in the clinic.
2022-03-23 10:03:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them.
2022-03-23 10:03:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 10:03:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are being served with salz and piserce.
2022-03-23 10:03:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:03:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a couple of electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 10:03:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:03:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, how people took responsibility for the wild, the number of animals grew up again, and this is a foundation of natural protection in nambia.
2022-03-23 10:03:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:43 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field are starting to start in the inside of the inner, but the sulant doesn't like if you move your energy, and so the suile.
2022-03-23 10:03:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start to start with a traditional face, the big face of the face of the face of the face and the real basic form of the information, and the whole information that comes from the information that comes from this reflective structure that comes from this reflection of this reflection.
2022-03-23 10:03:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it interesting, for me to be here at tedwomen, is that... in tedwomen is that... "yeah, at the best time, when someone said," the men who said to a table and say, "the men who are going to be interesting and measure it up with a table and measure it interesting and measure it interesting and measure it interesting and measure it interesting and measure it interesting and measure it interesting and measure it interesting and measure it interesting and measure it's interesting and measure it interesting and measure it interesting to me here at tedwomen in tedwomen who are going to be here at tedwomen in tedwomen in tedwomen who are going to be here at tedwomen who are going to be here at tedwomen in tedwomen who are going to be here at tedwomen who are going to be here at tedwomen in tedwomen,
2022-03-23 10:03:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily is still the mother of the invention, and a big part of the design work that we're going to see in our airplane is a result of it that we had to solve the unique problems that were connected to the ground -- the mother of the invention of the invention of the invention of the invention of the invention of the invention of the invention of the invention, and a big part of the design, and a big part of the design work on the design work that's still the design work on our airplane is still a big part of the airplane, and a big part of the design work that we've got to see that we've been connected to see in our airplane, and a big part of the plane, and a big part of our airplane, and a big part of our airplane is still a big part of the design work that we have to see that we've got to see that we have to see that we're either have to see that we have to see that we have to see in our airplane is still a big part of our airplane
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:55 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.742 | nll_loss 4.024 | ppl 16.27 | bleu 22.29 | wps 4467.4 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.29
2022-03-23 10:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 10:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:03:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.29) (writing took 1.8341621529543772 seconds)
2022-03-23 10:03:57 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 10:03:57 | INFO | train | epoch 020 | loss 8.766 | nll_loss 4.535 | ppl 23.18 | wps 43105.6 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.47 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1899
2022-03-23 10:03:57 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 10:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:18 | INFO | train_inner | epoch 021:     65 / 157 loss=8.719, nll_loss=4.444, ppl=21.76, wps=33840.5, ups=1.36, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.516, loss_scale=4, train_wall=30, gb_free=13.9, wall=1920
2022-03-23 10:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:51 | INFO | fairseq.tasks.translation | example hypothesis: we put these twet into the clinic.
2022-03-23 10:04:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:04:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:59 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 10:04:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:05:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs will be served with salz.
2022-03-23 10:05:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:05:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteria, how people have become responsibility for the wild animals, and this is a foundation of the conservation in namibia.
2022-03-23 10:05:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:05:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field in the inside of the inside, but the suck of the superconductor doesn't like if you're moving, because your energy needs to move, and so the suck of the superconductor.
2022-03-23 10:05:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face of the face of the face and the basic shape of that information, and through the one of the information that makes it the whole structure.
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it starts to say, "and if we're going to support the fact that we're going to have a long time with you."
2022-03-23 10:05:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:24 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the unique problems that were connected to the ground, and a lot of the things that we're going to be able to be able to see is that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do it with a safety system, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:05:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:24 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.67 | nll_loss 3.923 | ppl 15.17 | bleu 21.43 | wps 4873.3 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 22.29
2022-03-23 10:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 10:05:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:05:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:05:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 21 @ 3292 updates, score 21.43) (writing took 0.805178367998451 seconds)
2022-03-23 10:05:25 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 10:05:25 | INFO | train | epoch 021 | loss 8.705 | nll_loss 4.416 | ppl 21.35 | wps 44690.8 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.476 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1987
2022-03-23 10:05:26 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 10:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:28 | INFO | train_inner | epoch 022:      8 / 157 loss=8.708, nll_loss=4.422, ppl=21.44, wps=35184.5, ups=1.42, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.465, loss_scale=4, train_wall=30, gb_free=13.9, wall=1990
2022-03-23 10:05:59 | INFO | train_inner | epoch 022:    108 / 157 loss=8.664, nll_loss=4.338, ppl=20.22, wps=79461.8, ups=3.22, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.469, loss_scale=4, train_wall=31, gb_free=13.8, wall=2021
2022-03-23 10:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:06:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:06:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will make new golden locks that make two new pigs.
2022-03-23 10:06:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are being served with salz and pitcase.
2022-03-23 10:06:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 10:06:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:06:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people for the wild, the number of wild animals grew again. and this is a foundation of natural protection.
2022-03-23 10:06:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:41 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bars of magnetic field in the inside, but the sulaleggs don't like when they're moving, because they need their energy.
2022-03-23 10:06:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face and the basic shape of the face.
2022-03-23 10:06:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured for me at tedwomen, is that... "well, we've been working on silly."
2022-03-23 10:06:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're going to see in the plane, was a result of that we had to solve the unique problems that we had to solve on the ground.
2022-03-23 10:06:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:49 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.624 | nll_loss 3.786 | ppl 13.79 | bleu 22.65 | wps 5414.8 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 22.65
2022-03-23 10:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 10:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:06:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 22.65) (writing took 1.9735960419639014 seconds)
2022-03-23 10:06:51 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 10:06:51 | INFO | train | epoch 022 | loss 8.641 | nll_loss 4.295 | ppl 19.63 | wps 46108.9 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.446 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2073
2022-03-23 10:06:51 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 10:06:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:07 | INFO | train_inner | epoch 023:     51 / 157 loss=8.6, nll_loss=4.213, ppl=18.55, wps=37428, ups=1.47, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.382, loss_scale=4, train_wall=31, gb_free=13.8, wall=2089
2022-03-23 10:07:39 | INFO | train_inner | epoch 023:    151 / 157 loss=8.52, nll_loss=4.067, ppl=16.76, wps=81648.5, ups=3.22, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.406, loss_scale=4, train_wall=31, gb_free=13.8, wall=2120
2022-03-23 10:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:44 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:07:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:07:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create two new pigs.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz.
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 10:07:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:03 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew back. and this is a basis of natural protection in namibia.
2022-03-23 10:08:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:08:07 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic field lines are starting in the inside, but the susuperconductor doesn't like when they're moving, because their movements need energy, and so the supreme.
2022-03-23 10:08:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:12 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face of the real face and the basic form of the real face, and the basic shape of the face of the real face of the face of the real face, and the basic information that all the ports of the information that can fold all the ports of that make it all the ports of this information
2022-03-23 10:08:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it for me to be here at tedwomen, is that...
2022-03-23 10:08:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a lot of design work that we're in our aircraft, was a result that we had to solve the unique problems that were connected to the ground so that we had to solve it on the ground -- all the way that we had to be able to do it on the ground -- all the way that we're going to be able to do is to refrightened by a security system that is to use, to be able to refrightened in our aircraft, in our aircraft, or refrightened to use, in our aircraft.
2022-03-23 10:08:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:19 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.571 | nll_loss 3.683 | ppl 12.84 | bleu 24.96 | wps 4721.1 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 24.96
2022-03-23 10:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:08:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 24.96) (writing took 2.0364903090521693 seconds)
2022-03-23 10:08:21 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:08:21 | INFO | train | epoch 023 | loss 8.548 | nll_loss 4.118 | ppl 17.36 | wps 43959.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.396 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2163
2022-03-23 10:08:21 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:51 | INFO | train_inner | epoch 024:     94 / 157 loss=8.506, nll_loss=4.038, ppl=16.42, wps=34612.4, ups=1.39, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.394, loss_scale=4, train_wall=31, gb_free=13.8, wall=2193
2022-03-23 10:09:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create two new pigs.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pill.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for the wild, the number of wild animals grew again, and that's a foundation for conservation in namibia.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductors don't like it when they're moving, because their movements need energy, and so the superconducting disorders.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face and the basic form, and through the one of the information that makes the whole ports and fold.
2022-03-23 10:09:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are very interesting and measuring it to me here at tedwomen, is that... well, it was the best thing that someone said, "turn you to the men on your table and say," if the revolution starts to support you. "
2022-03-23 10:09:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to operations -- everything from a continually variable system that we can be able to be able to use in the same way, or to be able to be able to see that if you will be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:09:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:47 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.483 | nll_loss 3.491 | ppl 11.24 | bleu 27.03 | wps 4980.8 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.03
2022-03-23 10:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.03) (writing took 1.848885739047546 seconds)
2022-03-23 10:09:49 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:09:49 | INFO | train | epoch 024 | loss 8.488 | nll_loss 4.003 | ppl 16.04 | wps 44659.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.375 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2251
2022-03-23 10:09:50 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:01 | INFO | train_inner | epoch 025:     37 / 157 loss=8.435, nll_loss=3.904, ppl=14.97, wps=36058.8, ups=1.41, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.352, loss_scale=4, train_wall=30, gb_free=14, wall=2263
2022-03-23 10:10:33 | INFO | train_inner | epoch 025:    137 / 157 loss=8.468, nll_loss=3.967, ppl=15.64, wps=80200.6, ups=3.2, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.399, loss_scale=4, train_wall=31, gb_free=13.9, wall=2294
2022-03-23 10:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:10:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know.
2022-03-23 10:10:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:50 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 10:10:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:10:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frogs are served with salz and psuitcase.
2022-03-23 10:10:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on your head and understand exactly what all its thoughts are on the track.
2022-03-23 10:10:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for wildlife. and this is a basis for conservation in namibia.
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some bars of magnetic field are caught in the inside, but the superconductor doesn't like you move, because your movements need energy, and so the superconducting disorders.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial and the basic form, and we can restore it through the real form, and we can fold it through this information that refits the whole portion structure and all the fits.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be very interesting and measure for me here at tedwomen is that -- well, when dinner was best, when someone said, "turn it up the men on a table and say," if the revolution starts with you. "
2022-03-23 10:11:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're at the stest, was a result that we had to solve the unique problems that were connected to surgery that were connected to the ground -- everything from a continuously variable system and a refrightening system.
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:12 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.519 | nll_loss 3.622 | ppl 12.31 | bleu 22.55 | wps 5447.5 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.03
2022-03-23 10:11:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:11:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:11:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:11:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 22.55) (writing took 0.7830479469848797 seconds)
2022-03-23 10:11:13 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:11:13 | INFO | train | epoch 025 | loss 8.446 | nll_loss 3.927 | ppl 15.21 | wps 47098.5 | ups 1.87 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.393 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2335
2022-03-23 10:11:13 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:11:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:39 | INFO | train_inner | epoch 026:     80 / 157 loss=8.402, nll_loss=3.843, ppl=14.35, wps=38327.5, ups=1.51, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.378, loss_scale=4, train_wall=31, gb_free=14, wall=2361
2022-03-23 10:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:07 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheets in the clinic.
2022-03-23 10:12:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create two new pigs.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on your head and understand exactly what all its thoughts are on the track.
2022-03-23 10:12:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for the wild, the number of wild animals grew back, and this is a foundation for conservation in namibia.
2022-03-23 10:12:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:12:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bars of magnet fields are caught in the inside, but the superconductor doesn't like it if they're moving, because their movements are using energy, and so the superconducting disorders.
2022-03-23 10:12:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big constraints of the face and restoring the basic shape, and refuse it through the one of those ports and all the fits.
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured, for me here at tedwomen, is that -- well, in the striking dinner, when someone said, "turn to the men on your table and say," if the revolution starts to support you. "
2022-03-23 10:12:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we are at our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigering system that allows us to be able to do with a liquid traffic, and that allows us to be able to use it until we're in the aircraft, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:12:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:41 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.385 | nll_loss 3.327 | ppl 10.04 | bleu 28.88 | wps 4703.4 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.88
2022-03-23 10:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:12:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:12:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.88) (writing took 1.8590641470509581 seconds)
2022-03-23 10:12:43 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:12:43 | INFO | train | epoch 026 | loss 8.385 | nll_loss 3.812 | ppl 14.04 | wps 43746.5 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.355 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 2425
2022-03-23 10:12:44 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:51 | INFO | train_inner | epoch 027:     23 / 157 loss=8.347, nll_loss=3.741, ppl=13.37, wps=34479, ups=1.38, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.348, loss_scale=4, train_wall=30, gb_free=14.8, wall=2433
2022-03-23 10:13:22 | INFO | train_inner | epoch 027:    123 / 157 loss=8.361, nll_loss=3.767, ppl=13.61, wps=80326.7, ups=3.21, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.353, loss_scale=4, train_wall=31, gb_free=13.6, wall=2464
2022-03-23 10:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:13:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to be transformed two new pigs.
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:13:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:13:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:13:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of animals grew back. and this is a foundation for conservation in namibia.
2022-03-23 10:13:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured in the inside, but the superconductor doesn't like that if they're moving, because their movements use energy, and so the superconductor.
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is restoring the big contures of the face and the basic form, and defeat it through the theast of the information that pulls the whole portion structure and all the fits.
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that, well, when constrict dinner was best, when someone said, "turn you to your table and say," if the revolution starts to support you, "the truth is that we've already been supporting you."
2022-03-23 10:14:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to see that it in the aircraft, until we're going to be able to see the propellism.
2022-03-23 10:14:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:09 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.36 | nll_loss 3.284 | ppl 9.74 | bleu 29.07 | wps 5091.5 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.07
2022-03-23 10:14:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:14:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.07) (writing took 1.766013677988667 seconds)
2022-03-23 10:14:11 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:14:11 | INFO | train | epoch 027 | loss 8.337 | nll_loss 3.723 | ppl 13.21 | wps 45292.6 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.344 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2512
2022-03-23 10:14:11 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:32 | INFO | train_inner | epoch 028:     66 / 157 loss=8.308, nll_loss=3.667, ppl=12.7, wps=36002.1, ups=1.45, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.35, loss_scale=4, train_wall=30, gb_free=14.7, wall=2533
2022-03-23 10:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:15:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be exposed to two new pigs.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pfat.
2022-03-23 10:15:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 10:15:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for the wild, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:15:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:15:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are captured in the inside, but the superconductor doesn't like it if they use their movements because their movements use energy, and so the superconducting disorders.
2022-03-23 10:15:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big configuration of the face and the basic form, and through the theast of the information that contains the whole portion structure and all the folds.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that -- well, when i was striking dinner, it was best summarized when someone said, "turn to men on your table and say," if the revolution starts to support you. "
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our plane at the stest toes, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the aircraft, or when you're in the same way that you're going to use the propelling, or if you're going to use the propelling, you're going to see the earth until you're going to be able, you're going to use the earth until you're going to be able, you're either going to see that you're going to be able to see the earth until you're going to see the earth, you're going to see the propellyfish, you're going to use the earth, you're going to be able to use it's going to be able to be able, you're in the same time you're going to use the earth until you're going to
2022-03-23 10:15:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:38 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.32 | nll_loss 3.236 | ppl 9.42 | bleu 29.85 | wps 4768.6 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.85
2022-03-23 10:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:15:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:15:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:15:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.85) (writing took 1.8359043030068278 seconds)
2022-03-23 10:15:40 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:15:40 | INFO | train | epoch 028 | loss 8.307 | nll_loss 3.668 | ppl 12.71 | wps 44043.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.365 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2602
2022-03-23 10:15:41 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:43 | INFO | train_inner | epoch 029:      9 / 157 loss=8.317, nll_loss=3.688, ppl=12.88, wps=35090.4, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.372, loss_scale=4, train_wall=30, gb_free=13.6, wall=2605
2022-03-23 10:16:15 | INFO | train_inner | epoch 029:    109 / 157 loss=8.259, nll_loss=3.579, ppl=11.95, wps=80320.3, ups=3.2, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.324, loss_scale=4, train_wall=31, gb_free=13.6, wall=2637
2022-03-23 10:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:16:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:16:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to translate two new pigs.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pfat suitcase.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are captured in the inside, but the superconductor doesn't like it when they're moving, because their energy use, and so the superconductor disorder.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial that gives the big constructions of the face and the basic form, and reconstructions it through the theast of the information that refits the whole portion of the structure and all the fits a fold.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was very interesting and measured to me here at tedwomen is that -- well, when constrict dinner was put together the best, when somebody said, "turn to men on your table and say," if the revolution starts to be here at tedwomen, we're supporting you. "
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and a refrigeration, that allows us to use in the air to use, or if you look at the propelled or if you look at the propelled to a mechanism.
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:07 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.299 | nll_loss 3.209 | ppl 9.25 | bleu 30.16 | wps 4886.6 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.16
2022-03-23 10:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:17:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.16) (writing took 2.3371242539724335 seconds)
2022-03-23 10:17:09 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:17:09 | INFO | train | epoch 029 | loss 8.255 | nll_loss 3.572 | ppl 11.9 | wps 44389.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.329 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2691
2022-03-23 10:17:09 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:17:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:26 | INFO | train_inner | epoch 030:     52 / 157 loss=8.241, nll_loss=3.546, ppl=11.68, wps=35168.4, ups=1.4, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.32, loss_scale=4, train_wall=31, gb_free=13.9, wall=2708
2022-03-23 10:17:57 | INFO | train_inner | epoch 030:    152 / 157 loss=8.203, nll_loss=3.479, ppl=11.15, wps=81464.6, ups=3.22, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.294, loss_scale=4, train_wall=31, gb_free=14.7, wall=2739
2022-03-23 10:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:18:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that probably most of you here know.
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will be transformed two new pigs.
2022-03-23 10:18:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pfat suitcase.
2022-03-23 10:18:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 10:18:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wildlife animals grew again, and that's a basis for conservation in namibia.
2022-03-23 10:18:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured in the inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 10:18:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructures of the face and the basic shape, and then reconcile it through the one of the information that refers the whole portion structure and all the fits a fold.
2022-03-23 10:18:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to men on your table and tell them," if the revolution starts to support you. "
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable and a refrigeration system that allows us to use in the aircraft to a specific traffic, until a specific result, or a particular result that we could be able to use the unique problems that would be able to use it.
2022-03-23 10:18:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:36 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.273 | nll_loss 3.172 | ppl 9.01 | bleu 30.47 | wps 4821 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.47
2022-03-23 10:18:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:18:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:18:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:18:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.47) (writing took 1.7892752289772034 seconds)
2022-03-23 10:18:38 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:18:38 | INFO | train | epoch 030 | loss 8.213 | nll_loss 3.494 | ppl 11.27 | wps 44340.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.303 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2780
2022-03-23 10:18:39 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:18:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:09 | INFO | train_inner | epoch 031:     95 / 157 loss=8.2, nll_loss=3.471, ppl=11.09, wps=35639.9, ups=1.4, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.33, loss_scale=4, train_wall=31, gb_free=13.6, wall=2811
2022-03-23 10:19:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:19:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:19:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be exposed to two new pigs.
2022-03-23 10:19:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frogs are served with salz and pfat.
2022-03-23 10:19:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:19:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:19:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:19:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the corn like people's responsibility for the wild, the number of wild animals grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:19:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductors don't like it if they're moving, their movements use energy, and so the superconductor disorder.
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big contures of the face and the basic shape, and recover it through that information that pulls the whole porter structure and all the fits a fold.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, in striking dinner, it was the best summarized when someone said, "turn you to your table and say," if the revolution starts to support you. "the truth is that we've already started to support you for a long time."
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on at our aircraft was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the aircraft to be put on a particular traffic, or if you're going to be able to look at the same time you're going to see it.
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:06 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.244 | nll_loss 3.113 | ppl 8.65 | bleu 30.9 | wps 4782 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.9
2022-03-23 10:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:20:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.9) (writing took 2.5733197110239416 seconds)
2022-03-23 10:20:09 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:20:09 | INFO | train | epoch 031 | loss 8.193 | nll_loss 3.458 | ppl 10.99 | wps 43716 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.322 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2870
2022-03-23 10:20:09 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:22 | INFO | train_inner | epoch 032:     38 / 157 loss=8.155, nll_loss=3.387, ppl=10.46, wps=34191.7, ups=1.37, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.294, loss_scale=4, train_wall=30, gb_free=14.3, wall=2883
2022-03-23 10:20:53 | INFO | train_inner | epoch 032:    138 / 157 loss=8.165, nll_loss=3.408, ppl=10.61, wps=80745.7, ups=3.19, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.325, loss_scale=4, train_wall=31, gb_free=14.4, wall=2915
2022-03-23 10:20:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these tweep in the clinic.
2022-03-23 10:21:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:21:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and pfat.
2022-03-23 10:21:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:21:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, like people were taking responsibility for the wild, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:21:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which gives the big constructions of the face and the basic shape, and refers it through the one of the information that refers the whole porter structure and all the fone folds.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, in striking dinner, it was best summarized when someone said, "turn you to your table and tell you, 'if the revolution begins, then we support you."' "the truth is that we've been supporting you for this topic for a long time.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're stumbling at our plane was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the air, to a specific traffic, or a promoting, to the sailing, to the sailing, or a specific, to the deployment, to a state, to the deployment.
2022-03-23 10:21:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:37 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.237 | nll_loss 3.084 | ppl 8.48 | bleu 31.05 | wps 4763.4 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.05
2022-03-23 10:21:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:21:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:21:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 32 @ 5019 updates, score 31.05) (writing took 1.7799450510065071 seconds)
2022-03-23 10:21:39 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:21:39 | INFO | train | epoch 032 | loss 8.156 | nll_loss 3.389 | ppl 10.48 | wps 43530 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.31 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2961
2022-03-23 10:21:40 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:05 | INFO | train_inner | epoch 033:     81 / 157 loss=8.111, nll_loss=3.307, ppl=9.9, wps=34668.1, ups=1.38, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.303, loss_scale=4, train_wall=30, gb_free=14, wall=2987
2022-03-23 10:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:22:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 10:22:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:40 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to transcend two new pigs.
2022-03-23 10:22:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pfat suitcase.
2022-03-23 10:22:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people took responsibility for the wild, the number of wildlife animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:22:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:22:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor.
2022-03-23 10:22:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constructions of the face and the basic shape, and defeat it through the one of the information that refers the whole porter structure and all the fits a fold.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measured it to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to men on your table and say," if the revolution starts to support you, "the truth is that we've already supported you for a long time."
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on at our airplane is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable system of refrigeration and a refrigeration system that allows us to use an aircraft in the air, until the deployment of a proposal, or if you're going to be able to see the promoting mechanism.
2022-03-23 10:23:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:07 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.203 | nll_loss 3.07 | ppl 8.4 | bleu 32.09 | wps 4833.5 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.09
2022-03-23 10:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:23:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.09) (writing took 2.033333748986479 seconds)
2022-03-23 10:23:09 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:23:09 | INFO | train | epoch 033 | loss 8.131 | nll_loss 3.344 | ppl 10.16 | wps 44233.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.304 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3050
2022-03-23 10:23:09 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:17 | INFO | train_inner | epoch 034:     24 / 157 loss=8.147, nll_loss=3.372, ppl=10.35, wps=35081.7, ups=1.4, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.304, loss_scale=4, train_wall=31, gb_free=13.8, wall=3059
2022-03-23 10:23:48 | INFO | train_inner | epoch 034:    124 / 157 loss=8.09, nll_loss=3.268, ppl=9.63, wps=80307.3, ups=3.19, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.298, loss_scale=4, train_wall=31, gb_free=13.7, wall=3090
2022-03-23 10:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:24:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of goldilocks that will create the two new pigs.
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and pill suitcase.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wildlife animals grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructures of the face and the basic shape, and then we defend it through the one of the information that refers the whole porn structure and all the fits a fold.
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen is that, well, in striking dinner, it was best summarized when someone said, "turn you to the men in your table, and they say," if the revolution begins, then we support you. '"
2022-03-23 10:24:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most stumbling at our plane was a result that we had to solve the unique problems that were connected to it on the ground -- everything from a continuous variation and a refrigerator system with a refrigeration system, which allows us to use an aircraft in the gogos to be the same way, all the way to be the way to see when you see it's the decreased.
2022-03-23 10:24:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:37 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.208 | nll_loss 3.084 | ppl 8.48 | bleu 32.07 | wps 4630.9 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.09
2022-03-23 10:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:24:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:24:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.07) (writing took 0.7877477299771272 seconds)
2022-03-23 10:24:38 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:24:38 | INFO | train | epoch 034 | loss 8.105 | nll_loss 3.296 | ppl 9.82 | wps 44058.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.311 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3140
2022-03-23 10:24:39 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:00 | INFO | train_inner | epoch 035:     67 / 157 loss=8.118, nll_loss=3.32, ppl=9.99, wps=35229.2, ups=1.4, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.328, loss_scale=4, train_wall=30, gb_free=14.7, wall=3161
2022-03-23 10:25:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:25:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:25:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:40 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to translate two new pigs.
2022-03-23 10:25:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pfat suitcase.
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:25:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:25:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:25:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:25:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial face that gives the big contextures of the face and the basic shape, and enable it through the theft of that information that refers the whole por-structure and all the fed folds.
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, when dinner was best summarized when somebody said, "turn you to the men on your table and say," if the revolution starts to support you, "the truth of women is that we've already been supporting you for a long time."
2022-03-23 10:26:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're the most stumbling on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable and a cooling system of refrigeration that allows us to use an aircraft in the go-to-specific traffic to either drive the land when you can see it in the propelled mechanism.
2022-03-23 10:26:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:06 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.168 | nll_loss 3.03 | ppl 8.17 | bleu 32.21 | wps 4781.1 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.21
2022-03-23 10:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:26:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.21) (writing took 1.8272680349764414 seconds)
2022-03-23 10:26:07 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:26:07 | INFO | train | epoch 035 | loss 8.079 | nll_loss 3.247 | ppl 9.49 | wps 44254.7 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.288 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 3229
2022-03-23 10:26:08 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:26:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:11 | INFO | train_inner | epoch 036:     10 / 157 loss=8.062, nll_loss=3.219, ppl=9.31, wps=34840.1, ups=1.4, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.271, loss_scale=4, train_wall=31, gb_free=14.7, wall=3233
2022-03-23 10:26:43 | INFO | train_inner | epoch 036:    110 / 157 loss=8.062, nll_loss=3.216, ppl=9.29, wps=80258.2, ups=3.17, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.311, loss_scale=4, train_wall=31, gb_free=14.7, wall=3264
2022-03-23 10:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:01 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beetles in the clinic.
2022-03-23 10:27:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 10:27:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to create two new swells.
2022-03-23 10:27:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:27:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:27:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor is disturbing.
2022-03-23 10:27:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the size of the face and the basic shape, and then then redeploy it through the information that refers the entire porn structure and all the fone folds.
2022-03-23 10:27:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that... well, in the striking dinner, it was the best summarized when someone said, "turn you to the men on your table and tell them," if the revolution starts, we support you, "the truth, women, love, we've already been supporting you for a long time. it's already been supporting you about this topic for a long time, and it's a little bit of silly,"] ["] [unclear] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-23 10:27:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our plane is a result that we had to solve the unique problems that were connected to it on the ground -- everything from a continuous variable, and a refrigerator with the refrigerator that it allows us to use a stop machine in the go-go-go-go-traffic, or to a specially, until you're going to get the most sophisticated, all the way to the way down to the way to the way to the way to the way that's going to the way that's going to do it's going to be done, or if you're going to get it's going to make it, all the way that you're going to the way you're going to do it, all the way that you're going to the way that you're going to be able to do it's going to be able to be able to be able to be able to do it,
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:36 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.178 | nll_loss 3.009 | ppl 8.05 | bleu 32.49 | wps 4589.5 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.49
2022-03-23 10:27:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:27:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:27:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:27:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.49) (writing took 1.7803842390421778 seconds)
2022-03-23 10:27:38 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:27:38 | INFO | train | epoch 036 | loss 8.066 | nll_loss 3.224 | ppl 9.35 | wps 43518 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.312 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3320
2022-03-23 10:27:39 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:27:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:55 | INFO | train_inner | epoch 037:     53 / 157 loss=8.033, nll_loss=3.165, ppl=8.97, wps=35152.4, ups=1.38, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.3, loss_scale=4, train_wall=30, gb_free=14.7, wall=3337
2022-03-23 10:28:26 | INFO | train_inner | epoch 037:    153 / 157 loss=8.08, nll_loss=3.249, ppl=9.51, wps=79678.3, ups=3.21, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.297, loss_scale=4, train_wall=31, gb_free=13.5, wall=3368
2022-03-23 10:28:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:28:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:28:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of goldilocks that will be two new pigs.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:28:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 10:28:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:28:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:28:56 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:28:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial, which gives the big contures of the face and restore it through the basic shape of information that refers the whole porn structure and all the fine folds.
2022-03-23 10:29:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured and measured, to me here at tedwomen, is that -- well, in striking dinner, it was best summarized when someone said, "turn you to the men in your table and say," if the revolution starts, we support you. "'"' "the truth, women, love, we've already been supporting you about this topic for a long time. in this topic, we've already been supporting you for a long time." at rachspring's "at rachspring's" at the time, it's "it's a time, it's a time, it's called rachspring's a stling's" at the future, it's "
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still the mother of the invention, and a big part of the design work that we're on on our plane is a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuous variable variables and a refrigeration system with refrigeration, that it allows us to use an aircraft on our aircraft to use on our airplane on the stumber traffic, to use an aircraft in the go-go-go-go-go-to a special traffic machine, to a particular amount of passage, if you have a particular bite, if you can see it's a mechanism, if you can see it's flowing, if you can see it's going to see it, if you can see it's going to see it's going to see it, if you're going to see it, if you're going to the flowing, if you're going to see it's going to the
2022-03-23 10:29:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:07 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.153 | nll_loss 2.985 | ppl 7.91 | bleu 32.94 | wps 4601 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.94
2022-03-23 10:29:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:29:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:29:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.94) (writing took 1.8947808420052752 seconds)
2022-03-23 10:29:09 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:29:09 | INFO | train | epoch 037 | loss 8.046 | nll_loss 3.188 | ppl 9.11 | wps 43530.9 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.292 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3411
2022-03-23 10:29:09 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:39 | INFO | train_inner | epoch 038:     96 / 157 loss=8.045, nll_loss=3.185, ppl=9.09, wps=33700.2, ups=1.37, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.312, loss_scale=4, train_wall=31, gb_free=14.3, wall=3441
2022-03-23 10:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:30:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:30:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 10:30:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 10:30:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic shape, and then restore it through the one of the information that refers the whole porn structure and all the fine folds.
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn to men at your table and tell them," when the revolution starts supporting you. 'the truth is that we've been supporting you for a long time. "
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a great part of the design work that we're at our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft on our aircraft on the traffic of go-goand to a special traffic traffic traffic, until you can either see the propelled, or if you look at the prophecy of a mechanism that you can see it's either if you can see it's going to the prophearity of an aircraft that you can see it, if you see it, you can see it's going to see it's going to the case you can see it's going to the case that you can see it's going to the way you can see it's going to the case that you can see it's going to see it's going to the propelled by a mechanism that you
2022-03-23 10:30:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:36 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.15 | nll_loss 2.978 | ppl 7.88 | bleu 32.45 | wps 4779.1 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.94
2022-03-23 10:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:30:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:30:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:30:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.45) (writing took 0.8167052199714817 seconds)
2022-03-23 10:30:37 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:30:37 | INFO | train | epoch 038 | loss 8.037 | nll_loss 3.172 | ppl 9.01 | wps 44789.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.308 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3499
2022-03-23 10:30:37 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:30:50 | INFO | train_inner | epoch 039:     39 / 157 loss=7.987, nll_loss=3.08, ppl=8.46, wps=36872.8, ups=1.41, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.278, loss_scale=4, train_wall=31, gb_free=13.6, wall=3512
2022-03-23 10:31:21 | INFO | train_inner | epoch 039:    139 / 157 loss=8.03, nll_loss=3.158, ppl=8.93, wps=79831.3, ups=3.21, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.309, loss_scale=4, train_wall=31, gb_free=14.7, wall=3543
2022-03-23 10:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:30 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:31:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:31:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 10:31:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:31:39 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will be transcend two new pigs.
2022-03-23 10:31:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:31:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pill suitcase.
2022-03-23 10:31:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:31:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all your thoughts are on the track.
2022-03-23 10:31:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:31:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, like the people took responsibility for the wildlife, the number of wild animals grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:31:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:31:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, they use their movements, and so the superconducting disorder.
2022-03-23 10:31:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which gives the big constraints of the face, and refers the basic shape, and then refuse it through the most information that includes the whole pore structure and all the fine folds.
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, when dinner was stripped, it was best summarized when someone said, "turn you to men at your table and tell you," if the revolution starts to support you. "the truth, women love you is that we've already supported you about this topic for a long time. at rachel's"
2022-03-23 10:32:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a great part of the design work that we're on on our aircraft is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable and refrigeration system that allows us to use an aircraft in the stop traffic, to a particular vehicle, or if you're going to run the earth, until the decrease, or if you're going to be the decrease the decreased, or when you're on the decrease, it's going to be on the decreased in the decrease of a mechanism, it, until the decrease, it, it's going to be on the decrease, it, until the decrease, it's going to be on the decreased, or if you're on the decreased in the decrease, it's going to be on the decreased, it, it
2022-03-23 10:32:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:06 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.143 | nll_loss 2.946 | ppl 7.71 | bleu 33.03 | wps 4725.4 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.03
2022-03-23 10:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:32:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:32:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.03) (writing took 1.7997602219693363 seconds)
2022-03-23 10:32:07 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:32:07 | INFO | train | epoch 039 | loss 8.008 | nll_loss 3.118 | ppl 8.68 | wps 43707.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.289 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3589
2022-03-23 10:32:08 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:34 | INFO | train_inner | epoch 040:     82 / 157 loss=7.995, nll_loss=3.093, ppl=8.53, wps=34264.5, ups=1.38, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.262, loss_scale=4, train_wall=30, gb_free=14.1, wall=3616
2022-03-23 10:32:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:33:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:33:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:33:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to transcend two new pigs.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wildlife grew again, and that's become a foundation for conservation in namibia.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that regives the big constraints of the face and restores the basic shape, and then deploy it through the one of the information that refers the whole pore structure and all the fine.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, when i was striking dinner, it was the best summarized when someone said, "turn to the men on your table and say," if the revolution starts, then we support you, "the truth is that we've already been supporting you for a long time." at rachel carra's "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're on on our airplane at our stumber was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variable and a refrigeration system that allows us to use an aircraft in the stop and go-traffic to a special drive, or if you can see the fake, it's all the way down to the fake of a mechanism, if you can see, or if you can see the fake, if you can see it's on the car, it's on the favor of an aircraft, it, it, it, it's all the wrong mechanism, it's all the way to see it can see it, it's on the way to see it's going to see it, if you can see it's going to be on the earth, it's going to see it, it, it, it's going to see it
2022-03-23 10:33:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:36 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.144 | nll_loss 2.948 | ppl 7.71 | bleu 32.88 | wps 4752.6 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.03
2022-03-23 10:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 32.88) (writing took 0.872410818003118 seconds)
2022-03-23 10:33:37 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:33:37 | INFO | train | epoch 040 | loss 7.988 | nll_loss 3.081 | ppl 8.46 | wps 44308.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.273 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3678
2022-03-23 10:33:37 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:33:45 | INFO | train_inner | epoch 041:     25 / 157 loss=7.999, nll_loss=3.101, ppl=8.58, wps=35757.7, ups=1.4, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.289, loss_scale=4, train_wall=31, gb_free=14.4, wall=3687
2022-03-23 10:34:16 | INFO | train_inner | epoch 041:    125 / 157 loss=7.986, nll_loss=3.077, ppl=8.44, wps=79961.2, ups=3.21, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.314, loss_scale=4, train_wall=31, gb_free=13.8, wall=3718
2022-03-23 10:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:30 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:34:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:34:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:34:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:34:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will create two new swells.
2022-03-23 10:34:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:34:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:34:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:34:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:34:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:34:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:34:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:34:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:34:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:34:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constraints of the face and the basic form, and then then then then we add it through the one of the information that refers the whole pore structure and all the fine.
2022-03-23 10:34:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:35:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn to men on your table and tell them, 'if the revolution starts to support you,' the truth is that we've already supported you for a long time."
2022-03-23 10:35:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:35:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still, and a big part of the design work that we stumbled on on on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously variable and refrigerator system that allows us to use an aircraft in the stop and go-traffic, to a particular driver's aircraft, to either drive the propellum mechanism, or if you can see the decrease of an automation, or if you're on the ground, you're in the same way you're going to the same way you can see in the security field, you can see in the security field, you can see in the same way you can see in the case of an aircraft, if you can see, you can see the case of an aircraft, you're going to the same way that we're on the way that we're going to the aircraft.
2022-03-23 10:35:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:35:04 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.113 | nll_loss 2.934 | ppl 7.64 | bleu 33.24 | wps 4739.6 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.24
2022-03-23 10:35:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:35:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:35:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.24) (writing took 1.8903903780155815 seconds)
2022-03-23 10:35:06 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:35:06 | INFO | train | epoch 041 | loss 7.984 | nll_loss 3.074 | ppl 8.42 | wps 44084.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.299 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3768
2022-03-23 10:35:06 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:35:28 | INFO | train_inner | epoch 042:     68 / 157 loss=7.96, nll_loss=3.029, ppl=8.16, wps=34995.5, ups=1.39, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.276, loss_scale=4, train_wall=30, gb_free=22.4, wall=3790
2022-03-23 10:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:35:59 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-23 10:35:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:36:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 10:36:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:36:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will create two new pigs.
2022-03-23 10:36:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:36:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:36:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:36:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:36:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:36:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like humans took responsibility for the wildlife, the number of wildlife grew back up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:36:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:36:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:36:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:36:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that removes the big constraints of the face and the basic shape, and add it through the one of the information that refers the whole por-structure and all the fine folds.
2022-03-23 10:36:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:36:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn to men on your table and tell them, 'if the revolution begins, then we support you.'" the truth is that we've already supported you for a long time. at rachel carthera's "
2022-03-23 10:36:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:36:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we stumbled on on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable system with refrigerator that allows us to use an aircraft machine in the stop and go-traffic, to a special vehicle that either drives the earth, or if you can see the decrease, to the deployment of a mechanism, all the same mechanism, to the deployment of a security system that we see in a security system that's going on the ground, until the same way you see it's a security system that's a security system that's going to the deployment of a security system that's going to the earth, until you can see it's a security system that's the earth, if you see it can see it can see it's going to the earth, if you see it's going to the earth
2022-03-23 10:36:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:36:34 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.136 | nll_loss 2.94 | ppl 7.68 | bleu 32.92 | wps 4726.5 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.24
2022-03-23 10:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:36:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 32.92) (writing took 0.8707699640071951 seconds)
2022-03-23 10:36:35 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:36:35 | INFO | train | epoch 042 | loss 7.961 | nll_loss 3.031 | ppl 8.18 | wps 44509.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.278 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3857
2022-03-23 10:36:35 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:36:39 | INFO | train_inner | epoch 043:     11 / 157 loss=7.948, nll_loss=3.009, ppl=8.05, wps=35887.1, ups=1.4, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.268, loss_scale=4, train_wall=31, gb_free=13.9, wall=3861
2022-03-23 10:37:10 | INFO | train_inner | epoch 043:    111 / 157 loss=7.974, nll_loss=3.054, ppl=8.3, wps=79908, ups=3.21, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.296, loss_scale=4, train_wall=31, gb_free=13.8, wall=3892
2022-03-23 10:37:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:37:28 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:37:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:37:32 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that probably most of you know here.
2022-03-23 10:37:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:37:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will be transcend two new pigs.
2022-03-23 10:37:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:37:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:37:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:37:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 10:37:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:37:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wildlife, the number of wildlife grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:37:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:37:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:37:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:37:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial able that regives the big constraints of the face and the basic shape, and then deploy it through that information that whole por-structure and all the fine folds.
2022-03-23 10:37:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:38:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to be here for me at tedwomen is that... well, when dinner was striking, it was best summarized when someone said, "turn to men on your table and tell them, 'if the revolution starts to support you.' '" the truth, women, we've been supporting you for a long time. "
2022-03-23 10:38:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:38:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a great part of the design work that we're on on on our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable drive and a cooling system that allows us to use an aircraft in the stop and go-traffic to a particular drive that would be connected to the ground, or if you're going to be operational, or if you're going to be able to see the fastest mechanism, all the way you're going to see the way you're going to see the way you're going to see the way you're going to be able to see it.
2022-03-23 10:38:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:38:02 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.109 | nll_loss 2.92 | ppl 7.57 | bleu 33.44 | wps 4771.7 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.44
2022-03-23 10:38:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:38:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:38:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.44) (writing took 1.8714242069981992 seconds)
2022-03-23 10:38:04 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:38:04 | INFO | train | epoch 043 | loss 7.95 | nll_loss 3.01 | ppl 8.06 | wps 44149.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.286 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3946
2022-03-23 10:38:05 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:38:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:38:22 | INFO | train_inner | epoch 044:     54 / 157 loss=7.932, nll_loss=2.976, ppl=7.87, wps=34747.5, ups=1.4, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.304, loss_scale=4, train_wall=30, gb_free=14.2, wall=3964
2022-03-23 10:38:53 | INFO | train_inner | epoch 044:    154 / 157 loss=7.934, nll_loss=2.982, ppl=7.9, wps=82457.2, ups=3.23, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.266, loss_scale=4, train_wall=31, gb_free=13.8, wall=3995
2022-03-23 10:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:38:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:38:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:39:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:39:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:39:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 10:39:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:39:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog is served with salt and pepper.
2022-03-23 10:39:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:39:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:39:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:39:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew again, and this has become a basis for conservation in namibia.
2022-03-23 10:39:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:39:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder is disturbing.
2022-03-23 10:39:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:39:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refuses the big constraints of the face and the basic shape, and then we add it to it through the one of the information that refers the whole pore structure and all the fine folds.
2022-03-23 10:39:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:39:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that -- well, when rachel spring, it was best summarized when someone said, "turn to the men at your table and say," if the revolution begins, then we support you. "the truth is that we've already supported you with this topic for a long time."
2022-03-23 10:39:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:39:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on on our airplane is the stumbling, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variable and a cooling system with fluid that allows us to use an aircraft on the stop and traffic to a special drive, either when you fly the propelled, or when you see it, or when you get a mechanism, or when you see it's going to the ground, you can see it's going to the wrong.
2022-03-23 10:39:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:39:32 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.115 | nll_loss 2.905 | ppl 7.49 | bleu 33.29 | wps 4771.5 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.44
2022-03-23 10:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:39:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:39:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.29) (writing took 0.9392153099761344 seconds)
2022-03-23 10:39:33 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:39:33 | INFO | train | epoch 044 | loss 7.938 | nll_loss 2.988 | ppl 7.93 | wps 44659.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.289 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 4035
2022-03-23 10:39:33 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:40:04 | INFO | train_inner | epoch 045:     97 / 157 loss=7.917, nll_loss=2.949, ppl=7.72, wps=36022.5, ups=1.4, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.283, loss_scale=4, train_wall=31, gb_free=14.6, wall=4066
2022-03-23 10:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:40:26 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleepters in the clinic.
2022-03-23 10:40:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:40:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you are familiar with here.
2022-03-23 10:40:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:40:34 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will overcome two new swells.
2022-03-23 10:40:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:40:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:40:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:40:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what's all his thoughts on the track.
2022-03-23 10:40:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:40:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like humans took responsibility for the wildlife, the number of wildlife grew back up, and that's become a basis for conservation in namibia.
2022-03-23 10:40:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:40:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting energy disorder.
2022-03-23 10:40:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:40:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial, which gives the big constraints of the face and restores the basic shape, and adding it through that information that refers the whole por-structure and folds all the fine.
2022-03-23 10:40:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:40:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that -- well, when i was striking dinner, it was best summarized when someone said, "turn to men at your table and tell them," when the revolution begins, then we support you. "the truth, women, love, we've been supporting you for a long time."
2022-03-23 10:40:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:41:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of, and a great part of the design work that we're on on on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in stop and go-to-traffic to a special driver, or if you fly it's a mechanism, or if you see it's going to fly it, it's going to the ground, you see it's going to be refrightened by a security system that's going to be refrigeration.
2022-03-23 10:41:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:41:01 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.096 | nll_loss 2.895 | ppl 7.44 | bleu 33.6 | wps 4681.7 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.6
2022-03-23 10:41:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:41:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:41:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 45 @ 7060 updates, score 33.6) (writing took 1.8500451869913377 seconds)
2022-03-23 10:41:03 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:41:03 | INFO | train | epoch 045 | loss 7.926 | nll_loss 2.967 | ppl 7.82 | wps 43843.2 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.285 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 4125
2022-03-23 10:41:03 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:41:16 | INFO | train_inner | epoch 046:     40 / 157 loss=7.934, nll_loss=2.981, ppl=7.9, wps=33859.9, ups=1.39, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.284, loss_scale=4, train_wall=30, gb_free=14.3, wall=4138
2022-03-23 10:41:47 | INFO | train_inner | epoch 046:    140 / 157 loss=7.908, nll_loss=2.934, ppl=7.64, wps=81035.7, ups=3.19, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.27, loss_scale=4, train_wall=31, gb_free=13.6, wall=4169
2022-03-23 10:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:41:56 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:41:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:42:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:42:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:42:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 10:42:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:42:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:42:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:42:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:42:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:42:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:42:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:42:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconduction is disturbing.
2022-03-23 10:42:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:42:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that refers the big constraints of the face and the basic shape, and then then readd it through the information that refers the whole pore structure and all the fine.
2022-03-23 10:42:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:42:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, then we support you. '"'" the truth, women have already supported you for a long time. at rachel spring, and then at rachel's "
2022-03-23 10:42:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:42:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a lot of the design work that we stumbled on on our airplane was a result that we had to solve the unique problems that were connected to this, or if you're going to see the aircraft, all, from a continuous variable and refrigerator system with liquid, that allows us to use an aircraft in the stop and the car traffic, until a special passenger car car car car car car car car system, or if you're going to fly it, or if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be operated on the ground -- everything from a steady and refrigerm on the ground, and refrigerm up and refrigerated to be able to be able to be able to see it, and refrigerated, to see it,
2022-03-23 10:42:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:42:31 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.112 | nll_loss 2.898 | ppl 7.45 | bleu 33.31 | wps 4689.1 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.6
2022-03-23 10:42:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:42:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.31) (writing took 0.9388017120072618 seconds)
2022-03-23 10:42:32 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:42:32 | INFO | train | epoch 046 | loss 7.911 | nll_loss 2.939 | ppl 7.67 | wps 44365.9 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.279 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 4214
2022-03-23 10:42:32 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 10:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:42:58 | INFO | train_inner | epoch 047:     83 / 157 loss=7.898, nll_loss=2.915, ppl=7.54, wps=35198.3, ups=1.4, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.29, loss_scale=4, train_wall=31, gb_free=13.8, wall=4240
2022-03-23 10:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:43:25 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-23 10:43:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:43:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:43:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:43:33 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 10:43:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:43:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pill suitcase.
2022-03-23 10:43:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:43:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:43:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:43:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:43:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:43:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting energy is disturbing.
2022-03-23 10:43:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:43:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial able that gives the big constraints of the face and the basic form and then then then then then then adding it through that information that refers the whole pore structure and all the fine folds.
2022-03-23 10:43:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:43:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, when strictly dinner, it was best summarized when someone said, "turn to men at your table and tell them, 'when the revolution begins, then we support you.'" the truth, women, love is that we've been supporting you for a long time in this subject for a long time. at racarchel spring's "& lt; em & gt; / em & gt;
2022-03-23 10:43:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:43:59 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we stumbled on on our plane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously variable and a cooling system that allows us to use an aircraft in the stop and go-traffic until a special vehicle that drives either passes the propulsion space, or when you see in the wrong mechanism, to see the wrong way, to the deposit.
2022-03-23 10:43:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:43:59 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.08 | nll_loss 2.908 | ppl 7.51 | bleu 33.9 | wps 4833.5 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 33.9
2022-03-23 10:43:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 10:43:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:44:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt
2022-03-23 10:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_best.pt (epoch 47 @ 7374 updates, score 33.9) (writing took 1.8727586150052957 seconds)
2022-03-23 10:44:01 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 10:44:01 | INFO | train | epoch 047 | loss 7.899 | nll_loss 2.916 | ppl 7.55 | wps 44300.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.274 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 4303
2022-03-23 10:44:01 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 10:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:44:10 | INFO | train_inner | epoch 048:     26 / 157 loss=7.891, nll_loss=2.902, ppl=7.47, wps=35329, ups=1.41, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.278, loss_scale=4, train_wall=30, gb_free=13.6, wall=4311
2022-03-23 10:44:41 | INFO | train_inner | epoch 048:    126 / 157 loss=7.899, nll_loss=2.915, ppl=7.54, wps=80889.4, ups=3.15, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.258, loss_scale=4, train_wall=31, gb_free=14, wall=4343
2022-03-23 10:44:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:44:54 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beetles in the clinic.
2022-03-23 10:44:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:44:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:44:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:45:02 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 10:45:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:45:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:45:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:45:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are.
2022-03-23 10:45:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:45:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wildlife, the number of wildlife grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:45:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:45:18 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because they use their movements of energy, and the superconductor.
2022-03-23 10:45:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:45:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big constraints of the face and restores the basic shape, which refers the whole pore structure and all the fine folds.
2022-03-23 10:45:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:45:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and interesting and measured to me here at tedwomen is that... well, at striking dinner, it was best summarized when someone said, "turn to the men at your table and tell them, 'when the revolution begins, we support you.'" the truth, women, love, is that we've already supported you for a long time. "at rachel cartja," when rachel's "] ["] ["] ["] ["] [unclear] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:45:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:45:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on on on our airplane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuous variable gear and a cooling system with fluid that allows us to use an aircraft in the stop and go-traffic to a special vehicle that is either passes the propelled when you see the propelled, or when you see the propelled or when you see the aircraft on the ground, the favor of an automacy of an aircraft to the depossessional mechanism, the depossessive of an aircraft, the deposit's going to the deposits its its its its own that's going to the deployed or when you can see the falling mechanism is to the decrease the deposits its its its its its own.
2022-03-23 10:45:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:45:29 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.083 | nll_loss 2.911 | ppl 7.52 | bleu 33.7 | wps 4764.5 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 33.9
2022-03-23 10:45:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-23 10:45:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:45:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:45:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 48 @ 7531 updates, score 33.7) (writing took 0.7865406070486642 seconds)
2022-03-23 10:45:29 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 10:45:29 | INFO | train | epoch 048 | loss 7.889 | nll_loss 2.898 | ppl 7.45 | wps 44657.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.283 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 4391
2022-03-23 10:45:30 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 10:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:45:52 | INFO | train_inner | epoch 049:     69 / 157 loss=7.882, nll_loss=2.884, ppl=7.38, wps=34709, ups=1.42, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.293, loss_scale=4, train_wall=30, gb_free=14.1, wall=4413
2022-03-23 10:46:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:46:23 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:46:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:46:27 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:46:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:46:31 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks instances that will transcend two new pigs.
2022-03-23 10:46:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:46:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper are served.
2022-03-23 10:46:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:46:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:46:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:46:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like humans took responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:46:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:46:47 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a couple of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconductor disorder.
2022-03-23 10:46:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that will restore the big constraints of the face and the basic shape, and add it to the information that refers the whole por-structure and all the fine folds.
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:46:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, when constrict dinner, it was best summarized when someone said, "turn to the men in your table and tell them, 'when the revolution begins, we support you.' the truth, women have already been supporting you with this issue for a long time. 'rachel carson:" in silspring, "and then we're going to download the future of sandstone borns."
2022-03-23 10:46:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:46:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on our airplane is stumbling on, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variable gear and a cooling system that allows us to use an aircraft in the ga-go-traffic to a special vehicle that either drives the propelled, or when you see the prophecy of a mechanism or the deposit, the decrease on the ground.
2022-03-23 10:46:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:46:56 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.089 | nll_loss 2.919 | ppl 7.56 | bleu 33.55 | wps 4976.9 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 33.9
2022-03-23 10:46:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-23 10:46:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 49 @ 7688 updates, score 33.55) (writing took 0.8672400590148754 seconds)
2022-03-23 10:46:57 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 10:46:57 | INFO | train | epoch 049 | loss 7.875 | nll_loss 2.872 | ppl 7.32 | wps 45074 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.27 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4479
2022-03-23 10:46:57 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 10:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:47:01 | INFO | train_inner | epoch 050:     12 / 157 loss=7.871, nll_loss=2.868, ppl=7.3, wps=36635.8, ups=1.43, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.272, loss_scale=4, train_wall=31, gb_free=14.7, wall=4483
2022-03-23 10:47:33 | INFO | train_inner | epoch 050:    112 / 157 loss=7.862, nll_loss=2.849, ppl=7.2, wps=80918.7, ups=3.18, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.277, loss_scale=4, train_wall=31, gb_free=13.7, wall=4515
2022-03-23 10:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:47:50 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:47:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:47:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 10:47:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:47:59 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks instances that will be transcend two new pigs.
2022-03-23 10:47:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:48:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:48:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:48:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 10:48:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:48:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:48:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:48:14 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor is disturbing.
2022-03-23 10:48:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:48:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big configurations of the face and restore it through that information that includes the whole por-structure and all the fine wrinkles.
2022-03-23 10:48:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:48:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, at striking dinner, it was best summarized when someone said, "turn to the men at your table and tell them," when the revolution begins, we support you. "the truth, women, we've already supported you for a long time. at rachel spring's"
2022-03-23 10:48:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:48:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of the invention, and a lot of the design work that we're on on our plane is a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuous variable gear and a cooling system that allows us to use an aircraft in the stop and traffic to a special drive, or a flying mechanism, to the ground, to the wrong thing, to see the decrease.
2022-03-23 10:48:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:48:24 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.083 | nll_loss 2.905 | ppl 7.49 | bleu 33.75 | wps 4873.3 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 33.9
2022-03-23 10:48:24 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:48:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-23 10:48:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt
2022-03-23 10:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.45_#1/checkpoint_last.pt (epoch 50 @ 7845 updates, score 33.75) (writing took 0.8624862700235099 seconds)
2022-03-23 10:48:25 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 10:48:25 | INFO | train | epoch 050 | loss 7.867 | nll_loss 2.856 | ppl 7.24 | wps 45034.6 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.275 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 4567
2022-03-23 10:48:25 | INFO | fairseq_cli.train | done training in 4566.2 seconds
